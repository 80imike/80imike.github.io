<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维之美</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2020-08-03T02:22:59.052Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>巧用 Nginx 快速实现 HTTPS 双向认证</title>
    <link href="https://www.hi-linux.com/posts/38492.html"/>
    <id>https://www.hi-linux.com/posts/38492.html</id>
    <published>2020-08-03T01:00:00.000Z</published>
    <updated>2020-08-03T02:22:59.052Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>研究 <code>HTTPS</code> 的双向认证实现与原理，踩了不少坑，终于整个流程都跑通了，现在总结出一篇文档来，把一些心得，特别是容易踩坑的地方记录下来。</p><h2 id="1原理">1.原理</h2><p>双向认证，顾名思义，客户端和服务器端都需要验证对方的身份，在建立 <code>HTTPS</code> 连接的过程中，握手的流程比单向认证多了几步。单向认证的过程，客户端从服务器端下载服务器端公钥证书进行验证，然后建立安全通信通道。双向通信流程，客户端除了需要从服务器端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务器端给服务器端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。</p><h3 id="11-单向认证流程">1.1 单向认证流程</h3><p>单向认证流程中，服务器端保存着公钥证书和私钥两个文件，整个握手过程如下：</p><p><img src="https://www.hi-linux.com/img/linux/nginx-ssl-01.png" alt=""></p><ol><li>客户端发起建立 HTTPS 连接请求，将 SSL 协议版本的信息发送给服务器端；</li><li>服务器端将本机的公钥证书（server.crt）发送给客户端；</li><li>客户端读取公钥证书 (server.crt)，取出了服务端公钥；</li><li>客户端生成一个随机数（密钥 R），用刚才得到的服务器公钥去加密这个随机数形成密文，发送给服务端；</li><li>服务端用自己的私钥 (server.key) 去解密这个密文，得到了密钥 R</li><li>服务端和客户端在后续通讯过程中就使用这个密钥R进行通信了。</li></ol><h3 id="12-双向认证流程">1.2 双向认证流程</h3><p><img src="https://www.hi-linux.com/img/linux/nginx-ssl-02.png" alt=""></p><ol><li>客户端发起建立 HTTPS 连接请求，将 SSL 协议版本的信息发送给服务端；</li><li>服务器端将本机的公钥证书 (server.crt) 发送给客户端；</li><li>客户端读取公钥证书 (server.crt)，取出了服务端公钥；</li><li>客户端将客户端公钥证书 (client.crt) 发送给服务器端；</li><li>服务器端解密客户端公钥证书，拿到客户端公钥；</li><li>客户端发送自己支持的加密方案给服务器端；</li><li>服务器端根据自己和客户端的能力，选择一个双方都能接受的加密方案，使用客户端的公钥加密后发送给客户端；</li><li>客户端使用自己的私钥解密加密方案，生成一个随机数 R，使用服务器公钥加密后传给服务器端；</li><li>服务端用自己的私钥去解密这个密文，得到了密钥 R</li><li>服务端和客户端在后续通讯过程中就使用这个密钥R进行通信了。</li></ol><a id="more"></a><h2 id="2-证书生成">2. 证书生成</h2><p>从上一章内容中，我们可以总结出来，如果要把整个双向认证的流程跑通，最终需要五个证书文件：</p><ul><li>服务器端公钥证书：server.crt</li><li>服务器端私钥文件：server.key</li><li>客户端公钥证书：client.crt</li><li>客户端私钥文件：client.key</li><li>客户端集成证书（包括公钥和私钥，用于浏览器访问场景）：client.p12</li></ul><p>生成这一些列证书之前，我们需要先生成一个 <code>CA</code> 根证书，然后由这个 <code>CA</code> 根证书颁发服务器公钥证书和客户端公钥证书。</p><p><img src="https://www.hi-linux.com/img/linux/nginx-ssl-03.png" alt=""></p><p>我们可以全程使用 <code>Openssl</code> 来生成一些列的自签名证书，自签名证书没有通过证书机构的认证，很多浏览器会认为不安全，但我们用来实验是足够的。需要在本机安装了 <code>Openssl</code> 后才能继续本章的实验。</p><h3 id="21-生成自签名根证书">2.1 生成自签名根证书</h3><ol><li>创建根证书私钥：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl genrsa -out root.key 1024</span><br></pre></td></tr></table></figure><ol start="2"><li>创建根证书请求文件：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ openssl req -new -out root.csr -key root.key</span><br><span class="line"></span><br><span class="line">后续参数请自行填写，下面是一个例子：</span><br><span class="line"></span><br><span class="line">Country Name (2 letter code) [XX]:cn</span><br><span class="line">State or Province Name (full name) []:bj</span><br><span class="line">Locality Name (eg, city) [Default City]:bj</span><br><span class="line">Organization Name (eg, company) [Default Company Ltd]:alibaba</span><br><span class="line">Organizational Unit Name (eg, section) []:test</span><br><span class="line">Common Name (eg, your name or your servers hostname) []:www.yourdomain.com</span><br><span class="line">Email Address []:a.alibaba.com</span><br><span class="line">A challenge password []:</span><br><span class="line">An optional company name []:</span><br></pre></td></tr></table></figure><ol start="3"><li>创建根证书：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl x509 -req -in root.csr -out root.crt -signkey root.key -CAcreateserial -days 3650</span><br></pre></td></tr></table></figure><p>在创建证书请求文件的时候需要注意三点，下面生成服务器请求文件和客户端请求文件均要注意这三点：</p><ul><li>Common Name 填写证书对应的服务域名；</li><li>所有字段的填写，根证书、服务器端证书、客户端证书需保持一致</li><li>最后的密码可以直接回车跳过。</li></ul><p>经过上面三个命令行，我们最终可以得到一个签名有效期为 10 年的根证书 root.crt，后面我们可以用这个根证书去颁发服务器证书和客户端证书。</p><h3 id="22-生成自签名服务器端证书">2.2 生成自签名服务器端证书</h3><ol><li>生成服务器端证书私钥：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl genrsa -out server.key 1024</span><br></pre></td></tr></table></figure><ol start="2"><li>生成服务器证书请求文件，过程和注意事项参考根证书，本节不详述：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl req -new -out server.csr -key server.key</span><br></pre></td></tr></table></figure><ol start="3"><li>生成服务器端公钥证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl x509 -req -in server.csr -out server.crt -signkey server.key -CA root.crt -CAkey root.key -CAcreateserial -days 3650</span><br></pre></td></tr></table></figure><p>经过上面的三个命令，我们得到：</p><ul><li>server.key：服务器端的秘钥文件</li><li>server.crt：有效期十年的服务器端公钥证书，使用根证书和服务器端私钥文件一起生成</li></ul><h3 id="23-生成自签名客户端证书">2.3 生成自签名客户端证书</h3><ol><li>生成客户端证书秘钥：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl genrsa -out client.key 1024</span><br></pre></td></tr></table></figure><ol start="2"><li>生成客户端证书请求文件，过程和注意事项参考根证书，本节不详述：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl req -new -out client.csr -key client.key</span><br></pre></td></tr></table></figure><ol start="3"><li>生客户端证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl x509 -req -in client.csr -out client.crt -signkey client.key -CA root.crt -CAkey root.key -CAcreateserial -days 3650</span><br></pre></td></tr></table></figure><ol start="4"><li>生客户端 P12 格式证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl pkcs12 -export -clcerts -in client.crt -inkey client.key -out client.p12</span><br></pre></td></tr></table></figure><p>经过上面的三个命令，我们得到：</p><ul><li>client.key：客户端的私钥文件</li><li>client.crt：有效期十年的客户端证书，使用根证书和客户端私钥一起生成</li><li>client.p12：客户端 p12 格式，这个证书文件包含客户端的公钥和私钥，主要用来给浏览器访问使用</li></ul><h2 id="3nginx-配置">3.Nginx 配置</h2><p>有了上面的一些列证书，我们可以在 <code>Nginx</code> 服务器上配置双向认证的 <code>HTTPS</code> 服务了，具体配置方式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen       443 ssl;</span><br><span class="line">        server_name  www.yourdomain.com;</span><br><span class="line">        ssl                  on;  </span><br><span class="line">        ssl_certificate      &#x2F;data&#x2F;sslKey&#x2F;server.crt;  #server公钥证书</span><br><span class="line">        ssl_certificate_key  &#x2F;data&#x2F;sslKey&#x2F;server.key;  #server私钥</span><br><span class="line">        ssl_client_certificate &#x2F;data&#x2F;sslKey&#x2F;client.crt;  #客户端公钥证书</span><br><span class="line">        ssl_verify_client on;  #开启客户端证书验证  </span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>具体就是将服务器端的两个证书文件 (server.crt/server.key) 和客户端的公钥证书文件 (client.crt) 的路径配置到 <code>Nginx</code> 的 <code>server</code> 节点配置中，并且把 <code>ssl_verify_client</code> 这个参数设置为 <code>on</code>。</p><p>有一点需要注意的就是，如果客户端证书不是由根证书直接颁发的，配置中还需要加一个配置：<code>ssl_verify_depth 1</code> ;</p><p>配置完成后，执行 <code>nginx -s reload</code> 重新加载下就生效了。</p><h2 id="4curl-调用">4.curl 调用</h2><p>使用 <code>curl</code> 加上证书路径，可以直接测试 <code>Nginx</code> 的 <code>HTTPS</code> 双向认证是否配置成功。</p><ol><li>带证书的成功调用</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># --cert指定客户端公钥证书的路径</span><br><span class="line"># --key指定客户端私钥文件的路径</span><br><span class="line"># -k不校验证书的合法性，因为我们用的是自签名证书，所以需要加这个参数</span><br><span class="line"># 可以使用 -v 来观察具体的 SSL 握手过程</span><br><span class="line"></span><br><span class="line">$ curl --cert .&#x2F;client.crt --key .&#x2F;client.key https:&#x2F;&#x2F;integration-fred2.fredhuang.com -k -v</span><br><span class="line">* Rebuilt URL to: https:&#x2F;&#x2F;integration-fred2.fredhuang.com&#x2F;</span><br><span class="line">*   Trying 47.91.39.145...</span><br><span class="line">* TCP_NODELAY set</span><br><span class="line">* Connected to integration-fred2.fredhuang.com (47.91.39.145) port 443 (#0)</span><br><span class="line">* ALPN, offering h2</span><br><span class="line">* ALPN, offering http&#x2F;1.1</span><br><span class="line">* Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH</span><br><span class="line">* successfully set certificate verify locations:</span><br><span class="line">*   CAfile: &#x2F;etc&#x2F;ssl&#x2F;cert.pem</span><br><span class="line">  CApath: none</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Client hello (1):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Server hello (2):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Certificate (11):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Server key exchange (12):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Request CERT (13):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Server finished (14):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Certificate (11):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, CERT verify (15):</span><br><span class="line">* TLSv1.2 (OUT), TLS change cipher, Client hello (1):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Finished (20):</span><br><span class="line">* TLSv1.2 (IN), TLS change cipher, Client hello (1):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Finished (20):</span><br><span class="line">* SSL connection using TLSv1.2 &#x2F; ECDHE-RSA-AES128-GCM-SHA256</span><br><span class="line">* ALPN, server accepted to use h2</span><br><span class="line">* Server certificate:</span><br><span class="line">*  subject: C&#x3D;CN; ST&#x3D;BeiJing; L&#x3D;BeiJing; O&#x3D;Alibaba; OU&#x3D;Test; CN&#x3D;integration-fred2.fredhuang.com; emailAddress&#x3D;a@alibaba.com</span><br><span class="line">*  start date: Oct 30 06:43:19 2019 GMT</span><br><span class="line">*  expire date: Oct 27 06:43:19 2029 GMT</span><br><span class="line">*  issuer: C&#x3D;CN; ST&#x3D;BeiJing; L&#x3D;BeiJing; O&#x3D;Alibaba; OU&#x3D;Test; CN&#x3D;integration-fred2.fredhuang.com; emailAddress&#x3D;a@alibaba.com</span><br><span class="line">*  SSL certificate verify result: self signed certificate (18), continuing anyway.</span><br><span class="line">* Using HTTP2, server supports multi-use</span><br><span class="line">* Connection state changed (HTTP&#x2F;2 confirmed)</span><br><span class="line">* Copying HTTP&#x2F;2 data in stream buffer to connection buffer after upgrade: len&#x3D;0</span><br><span class="line">* Using Stream ID: 1 (easy handle 0x7f8ae1809a00)</span><br><span class="line">&gt; GET &#x2F; HTTP&#x2F;2</span><br><span class="line">&gt; Host: integration-fred2.fredhuang.com</span><br><span class="line">&gt; User-Agent: curl&#x2F;7.54.0</span><br><span class="line">&gt; Accept: *&#x2F;*</span><br><span class="line">&gt;</span><br><span class="line">* Connection state changed (MAX_CONCURRENT_STREAMS updated)!</span><br><span class="line">&lt; HTTP&#x2F;2 200</span><br><span class="line">&lt; server: Tengine</span><br><span class="line">&lt; date: Fri, 01 Nov 2019 11:16:39 GMT</span><br><span class="line">&lt; content-type: text&#x2F;plain;charset&#x3D;UTF-8</span><br><span class="line">&lt; content-length: 0</span><br></pre></td></tr></table></figure><ol start="2"><li>不带证书的失败调用</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">$ curl  https:&#x2F;&#x2F;integration-fred2.fredhuang.com -k -v</span><br><span class="line">* Rebuilt URL to: https:&#x2F;&#x2F;integration-fred2.fredhuang.com&#x2F;</span><br><span class="line">*   Trying 47.91.39.145...</span><br><span class="line">* TCP_NODELAY set</span><br><span class="line">* Connected to integration-fred2.fredhuang.com (47.91.39.145) port 443 (#0)</span><br><span class="line">* ALPN, offering h2</span><br><span class="line">* ALPN, offering http&#x2F;1.1</span><br><span class="line">* Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH</span><br><span class="line">* successfully set certificate verify locations:</span><br><span class="line">*   CAfile: &#x2F;etc&#x2F;ssl&#x2F;cert.pem</span><br><span class="line">  CApath: none</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Client hello (1):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Server hello (2):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Certificate (11):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Server key exchange (12):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Request CERT (13):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Server finished (14):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Certificate (11):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):</span><br><span class="line">* TLSv1.2 (OUT), TLS change cipher, Client hello (1):</span><br><span class="line">* TLSv1.2 (OUT), TLS handshake, Finished (20):</span><br><span class="line">* TLSv1.2 (IN), TLS change cipher, Client hello (1):</span><br><span class="line">* TLSv1.2 (IN), TLS handshake, Finished (20):</span><br><span class="line">* SSL connection using TLSv1.2 &#x2F; ECDHE-RSA-AES128-GCM-SHA256</span><br><span class="line">* ALPN, server accepted to use h2</span><br><span class="line">* Server certificate:</span><br><span class="line">*  subject: C&#x3D;CN; ST&#x3D;BeiJing; L&#x3D;BeiJing; O&#x3D;Alibaba; OU&#x3D;Test; CN&#x3D;integration-fred2.fredhuang.com; emailAddress&#x3D;a@alibaba.com</span><br><span class="line">*  start date: Oct 30 06:43:19 2019 GMT</span><br><span class="line">*  expire date: Oct 27 06:43:19 2029 GMT</span><br><span class="line">*  issuer: C&#x3D;CN; ST&#x3D;BeiJing; L&#x3D;BeiJing; O&#x3D;Alibaba; OU&#x3D;Test; CN&#x3D;integration-fred2.fredhuang.com; emailAddress&#x3D;a@alibaba.com</span><br><span class="line">*  SSL certificate verify result: self signed certificate (18), continuing anyway.</span><br><span class="line">* Using HTTP2, server supports multi-use</span><br><span class="line">* Connection state changed (HTTP&#x2F;2 confirmed)</span><br><span class="line">* Copying HTTP&#x2F;2 data in stream buffer to connection buffer after upgrade: len&#x3D;0</span><br><span class="line">* Using Stream ID: 1 (easy handle 0x7fcc52805e00)</span><br><span class="line">&gt; GET &#x2F; HTTP&#x2F;2</span><br><span class="line">&gt; Host: integration-fred2.fredhuang.com</span><br><span class="line">&gt; User-Agent: curl&#x2F;7.54.0</span><br><span class="line">&gt; Accept: *&#x2F;*</span><br><span class="line">&gt;</span><br><span class="line">* Connection state changed (MAX_CONCURRENT_STREAMS updated)!</span><br><span class="line">&lt; HTTP&#x2F;2 400</span><br><span class="line">&lt; server: Tengine</span><br><span class="line">&lt; date: Fri, 01 Nov 2019 11:25:28 GMT</span><br><span class="line">&lt; content-type: text&#x2F;html</span><br><span class="line">&lt; content-length: 685</span><br><span class="line">&lt;</span><br><span class="line">&lt;!DOCTYPE HTML PUBLIC &quot;-&#x2F;&#x2F;IETF&#x2F;&#x2F;DTD HTML 2.0&#x2F;&#x2F;EN&quot;&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;400 No required SSL certificate was sent&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;</span><br><span class="line">&lt;center&gt;No required SSL certificate was sent&lt;&#x2F;center&gt;</span><br><span class="line"> Sorry for the inconvenience.&lt;br&#x2F;&gt;</span><br><span class="line">Please report this message and include the following information to us.&lt;br&#x2F;&gt;</span><br><span class="line">Thank you very much!&lt;&#x2F;p&gt;</span><br><span class="line">&lt;table&gt;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;td&gt;URL:&lt;&#x2F;td&gt;</span><br><span class="line">&lt;td&gt;https:&#x2F;&#x2F;integration-fred2.fredhuang.com:444&#x2F;&lt;&#x2F;td&gt;</span><br><span class="line">&lt;&#x2F;tr&gt;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;td&gt;Server:&lt;&#x2F;td&gt;</span><br><span class="line">&lt;td&gt;cag-access-tengine011192099198.au49&lt;&#x2F;td&gt;</span><br><span class="line">&lt;&#x2F;tr&gt;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;td&gt;Date:&lt;&#x2F;td&gt;</span><br><span class="line">&lt;td&gt;2019&#x2F;11&#x2F;01 19:25:28&lt;&#x2F;td&gt;</span><br><span class="line">&lt;&#x2F;tr&gt;</span><br><span class="line">&lt;&#x2F;table&gt;</span><br><span class="line">&lt;hr&#x2F;&gt;Powered by Tengine&lt;hr&gt;&lt;center&gt;tengine&lt;&#x2F;center&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><h2 id="5java-调用">5.Java 调用</h2><p>由于使用的是自签名证书，使用 <code>ApacheHttpClient</code> 去调用的话，需要将服务器证书加入可信任证书库中，才能成功调用，也可以在代码中简单忽略证书。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd $JAVA_HOME</span><br><span class="line">$ sudo .&#x2F;bin&#x2F;keytool -import -alias ttt -keystore cacerts -file &#x2F;Users&#x2F;fred&#x2F;temp&#x2F;cert5&#x2F;server.crt</span><br></pre></td></tr></table></figure><p>将服务器端公钥证书设置为可信证书后，使用以下代码可以直接发起带客户端证书的 <code>HTTPS</code> 请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.http.HttpEntity;</span><br><span class="line">import org.apache.http.client.methods.CloseableHttpResponse;</span><br><span class="line">import org.apache.http.client.methods.HttpGet;</span><br><span class="line">import org.apache.http.conn.ssl.SSLConnectionSocketFactory;</span><br><span class="line">import org.apache.http.impl.client.CloseableHttpClient;</span><br><span class="line">import org.apache.http.impl.client.HttpClients;</span><br><span class="line">import org.apache.http.ssl.SSLContexts;</span><br><span class="line">import org.apache.http.util.EntityUtils;</span><br><span class="line"></span><br><span class="line">import javax.net.ssl.SSLContext;</span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.InputStream;</span><br><span class="line">import java.security.KeyStore;</span><br><span class="line"></span><br><span class="line">public class HttpClientWithClientCert &#123;</span><br><span class="line"></span><br><span class="line">    private final static String PFX_PATH &#x3D; &quot;&#x2F;Users&#x2F;fred&#x2F;temp&#x2F;cert5&#x2F;client.p12&quot;;    &#x2F;&#x2F;客户端证书路径</span><br><span class="line">    private final static String PFX_PWD &#x3D; &quot;123456&quot;;    &#x2F;&#x2F;客户端证书密码</span><br><span class="line"></span><br><span class="line">    public static String sslRequestGet(String url) throws Exception &#123;</span><br><span class="line">        KeyStore keyStore &#x3D; KeyStore.getInstance(&quot;PKCS12&quot;);</span><br><span class="line">        InputStream instream &#x3D; new FileInputStream(new File(PFX_PATH));</span><br><span class="line">        try &#123;</span><br><span class="line">            keyStore.load(instream, PFX_PWD.toCharArray());</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            instream.close();</span><br><span class="line">        &#125;</span><br><span class="line">        SSLContext sslcontext &#x3D; SSLContexts.custom().loadKeyMaterial(keyStore, PFX_PWD.toCharArray()).build();</span><br><span class="line">        SSLConnectionSocketFactory sslsf &#x3D; new SSLConnectionSocketFactory(sslcontext</span><br><span class="line">                , new String[] &#123; &quot;TLSv1&quot; &#125;    &#x2F;&#x2F; supportedProtocols ,这里可以按需要设置</span><br><span class="line">                , null    &#x2F;&#x2F; supportedCipherSuites</span><br><span class="line">                , SSLConnectionSocketFactory.getDefaultHostnameVerifier());</span><br><span class="line"></span><br><span class="line">        CloseableHttpClient httpclient &#x3D; HttpClients.custom().setSSLSocketFactory(sslsf).build();</span><br><span class="line">        try &#123;</span><br><span class="line">            HttpGet httpget &#x3D; new HttpGet(url);</span><br><span class="line">            &#x2F;&#x2F;httpget.addHeader(&quot;host&quot;, &quot;integration-fred2.fredhuang.com&quot;);&#x2F;&#x2F; 设置一些heander等</span><br><span class="line">            CloseableHttpResponse response &#x3D; httpclient.execute(httpget);</span><br><span class="line">            try &#123;</span><br><span class="line">                HttpEntity entity &#x3D; response.getEntity();</span><br><span class="line">                String jsonStr &#x3D; EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;);&#x2F;&#x2F;返回结果</span><br><span class="line">                EntityUtils.consume(entity);</span><br><span class="line">                return jsonStr;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                response.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            httpclient.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        System.out.println(System.getProperty(&quot;java.home&quot;));</span><br><span class="line">        System.out.println(sslRequestGet(&quot;https:&#x2F;&#x2F;integration-fred2.fredhuang.com&#x2F;test&quot;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-存疑">6. 存疑</h2><p>网上很多文章都描述到 <code>Nginx</code> 配置中的客户端证书（<code>ssl_client_certificate</code>）可以配置根证书 root.crt，然后就可以适配所有这个根证书办法的客户端公钥证书了。我试了，使用 root.crt 作为 <code>ssl_client_certificate</code> 的值，然后使用 client.crt 来访问，发现不行，<code>Nginx</code> 会报这个错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;400 The SSL certificate error&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;</span><br><span class="line">&lt;center&gt;The SSL certificate error&lt;&#x2F;center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.17.5&lt;&#x2F;center&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><p>这个特性原作者一直没有配置成功 (我也没配置成功)，有可能是配置有问题，也有可能是网上文章不靠谱，写错了。</p><blockquote><p>本文转载自：「阿里云开发者社区」，原文：<a href="https://tinyurl.com/yaamh7vf%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/yaamh7vf，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote><h2 id="扩展阅读-本文核心">扩展阅读 (本文核心)</h2><p>在原文基础上，我在分享一个你在大多数网站和搜索引擎中都找不到的很实用的小技巧，说得这么神秘到底是什么呢？</p><p>那就是使用受信证书进行双向认证，网上大多数文章介绍的实现 <code>HTTPS</code> 双向认证的文章都是使用 <code>CA</code> 自签的方式进行。虽然这能实现目的，但方法不太优雅。</p><p>在 <code>SSL</code> 证书全面普及的当下，你其实很有必要申请一个受信证书来进行 <code>HTTPS</code> 双向认证。这样看上去不但更权威，而且实现上也更便捷一些。</p><h3 id="使用受信证书进行双向认证">使用受信证书进行双向认证</h3><p>要使用受信证书进行认证的前提条件：当然是你必须有一个权威 CA 机构给你签发的证书。</p><ul><li>如果你是土豪，随便购买一个就行了。</li><li>如果你囊中羞涩，也不要紧，可以去申请一个免费的 <code>SSL</code> 证书。目前 <code>Let's Encrypt</code>、<code>阿里云</code> 都可以申请，具体方法就不在这展开了，你可以直接在公众号上搜索相关文章。</li><li>为了便于管理和多场景使用，建议直接申请通配证书。</li></ul><p>证书准备完成后，接下来当然是直接使用它。因为是受信证书，上面所有的证书自签操作都不需要了，你只需直接配置 <code>Nginx</code> 就可以了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">                listen       443 ssl;</span><br><span class="line">                access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;accesse.log  main;</span><br><span class="line">                server_name  ci.hi-linux.com;</span><br><span class="line"></span><br><span class="line">                </span><br><span class="line">                ssl_certificate      &#x2F;etc&#x2F;ssl&#x2F;certs&#x2F;hi-linux.com&#x2F;hi-linux.com.pem;</span><br><span class="line">                ssl_certificate_key  &#x2F;etc&#x2F;ssl&#x2F;certs&#x2F;hi-linux.com&#x2F;hi-linux.com.key;</span><br><span class="line">                ssl_client_certificate &#x2F;etc&#x2F;ssl&#x2F;certs&#x2F;hi-linux.com&#x2F;hi-linux.com.pem;</span><br><span class="line"></span><br><span class="line">                ssl_verify_depth 3;</span><br><span class="line">                ssl_session_timeout  5m;</span><br><span class="line">                ssl_verify_client on;</span><br><span class="line"></span><br><span class="line">                ssl_protocols  SSLv2 SSLv3 TLSv1;</span><br><span class="line">                ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;</span><br><span class="line">                ssl_prefer_server_ciphers   on;</span><br><span class="line"></span><br><span class="line">                location &#x2F; &#123;</span><br><span class="line">                        proxy_pass   http:&#x2F;&#x2F;ci&#x2F;;</span><br><span class="line">                        proxy_set_header Host $host:$server_port;</span><br><span class="line">                        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">                        proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class="line">                        &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure><blockquote><p>注意：<code>ssl_certificate</code> 指定的是证书，<code>ssl_certificate_key</code> 指定是证书对应的私钥，请自行将对应证书文件放到配置文件中指定的目录中。</p></blockquote><p>以上配置段和上面的自签证书大同小异，主要需注意的有 <code>ssl_client_certificate</code> 和 <code>ssl_verify_depth</code> 这两个参数。</p><ul><li><code>ssl_client_certificate</code> 主要用于指定客户端所使用的证书，这里可以直接使用受信证书机构签发的证书文件。</li><li><code>ssl_verify_depth</code>  这个参数是使用受信证书能成功进行客户端验证的关键，注意它的值是 <code>3</code>。</li></ul><p>因为当 <code>ssl_verify_depth</code> 设置为 <code>1</code>（ <code>Nginx</code> 的默认值）的时候，服务端只会接受直接被 <code>CA</code> 签发的客户端证书或自签名的证书。也就是说，直接尝试使用中级 <code>CA</code> 来验证客户端是无法通过的，<code>OpenSSL</code> 会自动的去找中级 <code>CA</code> 的签发者并一层层验证上去，直到找到根证书。</p><p>所以，就算将中级 <code>CA</code> 和根 <code>CA</code> 都放在信任证书列表中，由于最终 <code>ssl_verify_depth</code> 为 <code>2</code> 的缘故，验证还是通不过的。</p><p>因此，在实际使用的时候，需要注意以下两点：</p><ul><li>CA 文件中必须同时存在 中级 <code>CA</code> 和根 <code>CA</code>，必须构成完整证书链，不能少任何一个；</li><li>默认的验证深度 <code>ssl_verify_depth</code> 是 1，中级 <code>CA</code> 签发的客户端证书一律无法通过认证，需要增大该值，所以我们上面配置中 <code>ssl_verify_depth</code> 值为 <code>3</code> 。</li></ul><p>为了客户端方便导入，你同样还是需要将证书文件转换成 P12 格式。当然你还可以在转换的过程中给证书加个密码，以保证证书的安全。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl pkcs12 -export -clcerts -in hi-linux.com.pem -inkey hi-linux.com.key -out hi-linux.com-client.p12</span><br></pre></td></tr></table></figure><p>至此，<code>HTTPS</code> 双向证书的实现就讲完了，如果你还有什么更好的补充，欢迎大家积极留言交流哟！</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;研究 &lt;code&gt;HTTPS&lt;/code&gt; 的双向认证实现与原理，踩了不少坑，终于整个流程都跑通了，现在总结出一篇文档来，把一些心得，特别是容易踩坑的地方记录下来。&lt;/p&gt;
&lt;h2 id=&quot;1-原理&quot;&gt;1.原理&lt;/h2&gt;
&lt;p&gt;双向认证，顾名思义，客户端和服务器端都需要验证对方的身份，在建立 &lt;code&gt;HTTPS&lt;/code&gt; 连接的过程中，握手的流程比单向认证多了几步。单向认证的过程，客户端从服务器端下载服务器端公钥证书进行验证，然后建立安全通信通道。双向通信流程，客户端除了需要从服务器端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务器端给服务器端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。&lt;/p&gt;
&lt;h3 id=&quot;1-1-单向认证流程&quot;&gt;1.1 单向认证流程&lt;/h3&gt;
&lt;p&gt;单向认证流程中，服务器端保存着公钥证书和私钥两个文件，整个握手过程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/nginx-ssl-01.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端发起建立 HTTPS 连接请求，将 SSL 协议版本的信息发送给服务器端；&lt;/li&gt;
&lt;li&gt;服务器端将本机的公钥证书（server.crt）发送给客户端；&lt;/li&gt;
&lt;li&gt;客户端读取公钥证书 (server.crt)，取出了服务端公钥；&lt;/li&gt;
&lt;li&gt;客户端生成一个随机数（密钥 R），用刚才得到的服务器公钥去加密这个随机数形成密文，发送给服务端；&lt;/li&gt;
&lt;li&gt;服务端用自己的私钥 (server.key) 去解密这个密文，得到了密钥 R&lt;/li&gt;
&lt;li&gt;服务端和客户端在后续通讯过程中就使用这个密钥R进行通信了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;1-2-双向认证流程&quot;&gt;1.2 双向认证流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/nginx-ssl-02.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端发起建立 HTTPS 连接请求，将 SSL 协议版本的信息发送给服务端；&lt;/li&gt;
&lt;li&gt;服务器端将本机的公钥证书 (server.crt) 发送给客户端；&lt;/li&gt;
&lt;li&gt;客户端读取公钥证书 (server.crt)，取出了服务端公钥；&lt;/li&gt;
&lt;li&gt;客户端将客户端公钥证书 (client.crt) 发送给服务器端；&lt;/li&gt;
&lt;li&gt;服务器端解密客户端公钥证书，拿到客户端公钥；&lt;/li&gt;
&lt;li&gt;客户端发送自己支持的加密方案给服务器端；&lt;/li&gt;
&lt;li&gt;服务器端根据自己和客户端的能力，选择一个双方都能接受的加密方案，使用客户端的公钥加密后发送给客户端；&lt;/li&gt;
&lt;li&gt;客户端使用自己的私钥解密加密方案，生成一个随机数 R，使用服务器公钥加密后传给服务器端；&lt;/li&gt;
&lt;li&gt;服务端用自己的私钥去解密这个密文，得到了密钥 R&lt;/li&gt;
&lt;li&gt;服务端和客户端在后续通讯过程中就使用这个密钥R进行通信了。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="https://www.hi-linux.com/categories/nginx/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Nginx" scheme="https://www.hi-linux.com/tags/Nginx/"/>
    
      <category term="HTTPS" scheme="https://www.hi-linux.com/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>两个助你高效编写 Kubernetes YAML 文件的神技</title>
    <link href="https://www.hi-linux.com/posts/52035.html"/>
    <id>https://www.hi-linux.com/posts/52035.html</id>
    <published>2020-07-30T01:00:00.000Z</published>
    <updated>2020-07-30T04:49:05.917Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>我们在编写 <code>Kubernetes</code> 资源清单的时候可能会经常会忘记要创建的资源名称，即使知道了可能也不记得该资源对象有哪些属性可以使用了，特别是对于那些名称很长的资源或者属性，即使死记硬背下来隔一段时间又会忘记了。</p><p>比如现在我们要创建一个 <code>validating</code> 的 <code>admission webhook</code>，我们就需要定义一个 <code>ValidatingWebhookConfiguration</code> 的资源对象，但是可能我们不记得它的全名了。这个时候我们可以使用 <code>kubectl api-resources</code> 命令来找到我们需要的 <code>API</code> 资源。找到了正确的资源名称之后，就需要了解如何编写正确的 <code>YAML</code> 资源清单文件了，但是 <code>Kubernetes</code> 中资源对象实在是太多了，而且每一个资源对象中配置属性也是非常多的，我们不可能都能完全记住，这个时候我们也可以借助 <code>kubectl explain</code> 命令来找到完整的结构，这对于我们编写 <code>YAML</code> 资源清单文件非常有帮助。</p><h2 id="kubectl-api-resources-命令">kubectl api-resources 命令</h2><p><code>kubectl api-resources</code> 命令可以打印所有已经注册的 <code>API</code> 资源，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ Kubectl api-resources</span><br><span class="line">NAME                              SHORTNAMES                                   APIGROUP                       NAMESPACED   KIND</span><br><span class="line">bindings                                                                                                      true         Binding</span><br><span class="line">componentstatuses                 cs                                                                          false        ComponentStatus</span><br><span class="line">configmaps                        cm                                                                          true         ConfigMap</span><br><span class="line">endpoints                         ep                                                                          true         Endpoints</span><br><span class="line">events                            ev                                                                          true         Event</span><br><span class="line">limitranges                       limits                                                                      true         LimitRange</span><br><span class="line">namespaces                        ns                                                                          false        Namespace</span><br><span class="line">nodes                             no                                                                          false        Node</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>其中也会包含上面提到的 <code>ValidatingWebhookConfiguration</code> 资源：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mutatingwebhookconfigurations                                                  admissionregistration.k8s.io   false        MutatingWebhookConfiguration</span><br><span class="line">validatingwebhookconfigurations                                                admissionregistration.k8s.io   false        ValidatingWebhookConfiguration</span><br><span class="line">customresourcedefinitions         crd,crds                                     apiextensions.k8s.io           false        CustomResourceDefinition</span><br><span class="line">apiservices                                                                    apiregistration.k8s.io         false        APIService</span><br></pre></td></tr></table></figure><p>由于 <code>Kubernetes</code> 中已经注册的资源对象非常多，所以如果我们知道我们要查找的资源名称包含一些关键词的话，可以用 <code>grep</code> 来过滤:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl api-resources |grep validating</span><br><span class="line">validatingwebhookconfigurations                                                admissionregistration.k8s.io   false        ValidatingWebhookConfiguration</span><br></pre></td></tr></table></figure><p>这样就可以更精确的搜索到需要使用的资源名称了，比如我们这里就是 <code>ValidatingWebhookConfiguration</code> ，现在知道了资源对象的名称，然后可以使用 <code>kubectl explain</code> 命令来查找资源对象的属性。</p><a id="more"></a><h2 id="kubectl-explain-命令">kubectl explain 命令</h2><p><code>kubectl explain</code> 命令可以将资源对象的详细属性都展示出来，比如我们现在不知道如何去编写 <code>ValidatingWebhookConfiguration</code> ，这个时候我们可以通过命令 <code>kubectl explain ValidatingWebhookConfiguration</code> 来获取详细的信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl explain ValidatingWebhookConfiguration</span><br><span class="line">KIND:     ValidatingWebhookConfiguration</span><br><span class="line">VERSION:  admissionregistration.k8s.io&#x2F;v1</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">     ValidatingWebhookConfiguration describes the configuration of and admission</span><br><span class="line">     webhook that accept or reject and object without changing it.</span><br><span class="line"></span><br><span class="line">FIELDS:</span><br><span class="line">   apiVersion  &lt;string&gt;</span><br><span class="line">     APIVersion defines the versioned schema of this representation of an</span><br><span class="line">     object. Servers should convert recognized schemas to the latest internal</span><br><span class="line">     value, and may reject unrecognized values. More info:</span><br><span class="line">     https:&#x2F;&#x2F;git.k8s.io&#x2F;community&#x2F;contributors&#x2F;devel&#x2F;sig-architecture&#x2F;api-conventions.md#resources</span><br><span class="line"></span><br><span class="line">   kind  &lt;string&gt;</span><br><span class="line">     Kind is a string value representing the REST resource this object</span><br><span class="line">     represents. Servers may infer this from the endpoint the client submits</span><br><span class="line">     requests to. Cannot be updated. In CamelCase. More info:</span><br><span class="line">     https:&#x2F;&#x2F;git.k8s.io&#x2F;community&#x2F;contributors&#x2F;devel&#x2F;sig-architecture&#x2F;api-conventions.md#types-kinds</span><br><span class="line"></span><br><span class="line">   metadata  &lt;Object&gt;</span><br><span class="line">     Standard object metadata; More info:</span><br><span class="line">     https:&#x2F;&#x2F;git.k8s.io&#x2F;community&#x2F;contributors&#x2F;devel&#x2F;sig-architecture&#x2F;api-conventions.md#metadata.</span><br><span class="line"></span><br><span class="line">   webhooks  &lt;[]Object&gt;</span><br><span class="line">     Webhooks is a list of webhooks and the affected resources and operations.</span><br></pre></td></tr></table></figure><p>这个命令会输出顶层的属性，我们只需要明白 <code>&lt;string&gt;</code> 表示字符串，<code>&lt;Object&gt;</code> 表示对象, <code>[]</code> 表示数组即可，对象在 <code>YAML</code> 文件中就需要缩进，数组就需要通过添加一个破折号来表示一个 <code>Item</code>，对于对象和对象数组我们不知道里面有什么属性的，我们还可以继续在后面查看，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl explain ValidatingWebhookConfiguration.metadata</span><br><span class="line">KIND:     ValidatingWebhookConfiguration</span><br><span class="line">VERSION:  admissionregistration.k8s.io&#x2F;v1</span><br><span class="line"></span><br><span class="line">RESOURCE: metadata &lt;Object&gt;</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">     Standard object metadata; More info:</span><br><span class="line">     https:&#x2F;&#x2F;git.k8s.io&#x2F;community&#x2F;contributors&#x2F;devel&#x2F;sig-architecture&#x2F;api-conventions.md#metadata.</span><br><span class="line"></span><br><span class="line">     ObjectMeta is metadata that all persisted resources must have, which</span><br><span class="line">     includes all objects users must create.</span><br><span class="line"></span><br><span class="line">FIELDS:</span><br><span class="line">   annotations  &lt;map[string]string&gt;</span><br><span class="line">     Annotations is an unstructured key value map stored with a resource that</span><br><span class="line">     may be set by external tools to store and retrieve arbitrary metadata. They</span><br><span class="line">     are not queryable and should be preserved when modifying objects. More</span><br><span class="line">     info: http:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;user-guide&#x2F;annotations</span><br><span class="line"></span><br><span class="line">   ......</span><br></pre></td></tr></table></figure><p>上面输出的属性就是属于 <code>metadata</code> 这个 <code>key</code> 下面对应的对象了，有的时候如果觉得这样一层一层的去查看比较麻烦，我们还可以传入一个 <code>--recursive</code> 参数来获取所有的属性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl explain validatingwebhookconfiguration --recursive</span><br><span class="line">KIND:     ValidatingWebhookConfiguration</span><br><span class="line">VERSION:  admissionregistration.k8s.io&#x2F;v1</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">     ValidatingWebhookConfiguration describes the configuration of and admission</span><br><span class="line">     webhook that accept or reject and object without changing it.</span><br><span class="line"></span><br><span class="line">FIELDS:</span><br><span class="line">   apiVersion  &lt;string&gt;</span><br><span class="line">   kind  &lt;string&gt;</span><br><span class="line">   metadata  &lt;Object&gt;</span><br><span class="line">      annotations  &lt;map[string]string&gt;</span><br><span class="line">      clusterName  &lt;string&gt;</span><br><span class="line">      creationTimestamp  &lt;string&gt;</span><br><span class="line">      deletionGracePeriodSeconds  &lt;integer&gt;</span><br><span class="line">      deletionTimestamp  &lt;string&gt;</span><br><span class="line">      finalizers  &lt;[]string&gt;</span><br><span class="line">      generateName  &lt;string&gt;</span><br><span class="line">      generation  &lt;integer&gt;</span><br><span class="line">      labels  &lt;map[string]string&gt;</span><br><span class="line">      managedFields  &lt;[]Object&gt;</span><br><span class="line">         apiVersion  &lt;string&gt;</span><br><span class="line">         fieldsType  &lt;string&gt;</span><br><span class="line">         fieldsV1  &lt;map[string]&gt;</span><br><span class="line">         manager  &lt;string&gt;</span><br><span class="line">         operation  &lt;string&gt;</span><br><span class="line">         time  &lt;string&gt;</span><br><span class="line">      name  &lt;string&gt;</span><br><span class="line">      namespace  &lt;string&gt;</span><br><span class="line">      ownerReferences  &lt;[]Object&gt;</span><br><span class="line">         apiVersion  &lt;string&gt;</span><br><span class="line">         blockOwnerDeletion  &lt;boolean&gt;</span><br><span class="line">         controller  &lt;boolean&gt;</span><br><span class="line">         kind  &lt;string&gt;</span><br><span class="line">         name  &lt;string&gt;</span><br><span class="line">         uid  &lt;string&gt;</span><br><span class="line">      resourceVersion  &lt;string&gt;</span><br><span class="line">      selfLink  &lt;string&gt;</span><br><span class="line">      uid  &lt;string&gt;</span><br><span class="line">   webhooks  &lt;[]Object&gt;</span><br><span class="line">      admissionReviewVersions  &lt;[]string&gt;</span><br><span class="line">      clientConfig  &lt;Object&gt;</span><br><span class="line">         caBundle  &lt;string&gt;</span><br><span class="line">         service  &lt;Object&gt;</span><br><span class="line">            name  &lt;string&gt;</span><br><span class="line">            namespace  &lt;string&gt;</span><br><span class="line">            path  &lt;string&gt;</span><br><span class="line">            port  &lt;integer&gt;</span><br><span class="line">         url  &lt;string&gt;</span><br><span class="line">      failurePolicy  &lt;string&gt;</span><br><span class="line">      matchPolicy  &lt;string&gt;</span><br><span class="line">      name  &lt;string&gt;</span><br><span class="line">      namespaceSelector  &lt;Object&gt;</span><br><span class="line">         matchExpressions  &lt;[]Object&gt;</span><br><span class="line">            key  &lt;string&gt;</span><br><span class="line">            operator  &lt;string&gt;</span><br><span class="line">            values  &lt;[]string&gt;</span><br><span class="line">         matchLabels  &lt;map[string]string&gt;</span><br><span class="line">      objectSelector  &lt;Object&gt;</span><br><span class="line">         matchExpressions  &lt;[]Object&gt;</span><br><span class="line">            key  &lt;string&gt;</span><br><span class="line">            operator  &lt;string&gt;</span><br><span class="line">            values  &lt;[]string&gt;</span><br><span class="line">         matchLabels  &lt;map[string]string&gt;</span><br><span class="line">      rules  &lt;[]Object&gt;</span><br><span class="line">         apiGroups  &lt;[]string&gt;</span><br><span class="line">         apiVersions  &lt;[]string&gt;</span><br><span class="line">         operations  &lt;[]string&gt;</span><br><span class="line">         resources  &lt;[]string&gt;</span><br><span class="line">         scope  &lt;string&gt;</span><br><span class="line">      sideEffects  &lt;string&gt;</span><br><span class="line">      timeoutSeconds  &lt;integer&gt;</span><br></pre></td></tr></table></figure><p>这个命令就可以将资源对象的完整属性列出来，而且缩进格式和 <code>YAML</code> 文件基本上是一致的，这样对于我们去编写资源清单文件就更加友好了。</p><p>自从使用 <code>kubectl api-resources</code> 和 <code>kubectl explain</code> 这两个命令后，为我们编写资源清单文件节省了很多时间，工作效率大大提高了！</p><p>这么好的神技，你还不赶紧用起来吗？ 如果你还有更好的方法，欢迎大家积极留言讨论哟！</p><blockquote><p>本文转载自：「k8s技术圈」，原文：<a href="https://tinyurl.com/y4vvln2x%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/y4vvln2x，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在编写 &lt;code&gt;Kubernetes&lt;/code&gt; 资源清单的时候可能会经常会忘记要创建的资源名称，即使知道了可能也不记得该资源对象有哪些属性可以使用了，特别是对于那些名称很长的资源或者属性，即使死记硬背下来隔一段时间又会忘记了。&lt;/p&gt;
&lt;p&gt;比如现在我们要创建一个 &lt;code&gt;validating&lt;/code&gt; 的 &lt;code&gt;admission webhook&lt;/code&gt;，我们就需要定义一个 &lt;code&gt;ValidatingWebhookConfiguration&lt;/code&gt; 的资源对象，但是可能我们不记得它的全名了。这个时候我们可以使用 &lt;code&gt;kubectl api-resources&lt;/code&gt; 命令来找到我们需要的 &lt;code&gt;API&lt;/code&gt; 资源。找到了正确的资源名称之后，就需要了解如何编写正确的 &lt;code&gt;YAML&lt;/code&gt; 资源清单文件了，但是 &lt;code&gt;Kubernetes&lt;/code&gt; 中资源对象实在是太多了，而且每一个资源对象中配置属性也是非常多的，我们不可能都能完全记住，这个时候我们也可以借助 &lt;code&gt;kubectl explain&lt;/code&gt; 命令来找到完整的结构，这对于我们编写 &lt;code&gt;YAML&lt;/code&gt; 资源清单文件非常有帮助。&lt;/p&gt;
&lt;h2 id=&quot;kubectl-api-resources-命令&quot;&gt;kubectl api-resources 命令&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;kubectl api-resources&lt;/code&gt; 命令可以打印所有已经注册的 &lt;code&gt;API&lt;/code&gt; 资源，如下所示：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ Kubectl api-resources&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;NAME                              SHORTNAMES                                   APIGROUP                       NAMESPACED   KIND&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bindings                                                                                                      true         Binding&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;componentstatuses                 cs                                                                          false        ComponentStatus&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;configmaps                        cm                                                                          true         ConfigMap&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;endpoints                         ep                                                                          true         Endpoints&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;events                            ev                                                                          true         Event&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;limitranges                       limits                                                                      true         LimitRange&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;namespaces                        ns                                                                          false        Namespace&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;nodes                             no                                                                          false        Node&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;......&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中也会包含上面提到的 &lt;code&gt;ValidatingWebhookConfiguration&lt;/code&gt; 资源：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mutatingwebhookconfigurations                                                  admissionregistration.k8s.io   false        MutatingWebhookConfiguration&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;validatingwebhookconfigurations                                                admissionregistration.k8s.io   false        ValidatingWebhookConfiguration&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;customresourcedefinitions         crd,crds                                     apiextensions.k8s.io           false        CustomResourceDefinition&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;apiservices                                                                    apiregistration.k8s.io         false        APIService&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于 &lt;code&gt;Kubernetes&lt;/code&gt; 中已经注册的资源对象非常多，所以如果我们知道我们要查找的资源名称包含一些关键词的话，可以用 &lt;code&gt;grep&lt;/code&gt; 来过滤:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl api-resources |grep validating&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;validatingwebhookconfigurations                                                admissionregistration.k8s.io   false        ValidatingWebhookConfiguration&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这样就可以更精确的搜索到需要使用的资源名称了，比如我们这里就是 &lt;code&gt;ValidatingWebhookConfiguration&lt;/code&gt; ，现在知道了资源对象的名称，然后可以使用 &lt;code&gt;kubectl explain&lt;/code&gt; 命令来查找资源对象的属性。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="YAML" scheme="https://www.hi-linux.com/tags/YAML/"/>
    
  </entry>
  
  <entry>
    <title>再见 ELK，是时候拥抱下一代日志系统 Loki 了</title>
    <link href="https://www.hi-linux.com/posts/61047.html"/>
    <id>https://www.hi-linux.com/posts/61047.html</id>
    <published>2020-07-27T01:00:00.000Z</published>
    <updated>2020-07-27T04:18:14.060Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近，在对公司容器云的日志方案进行设计的时候，发现主流的 ELK 或者 EFK 比较重，再加上现阶段对于 ES 复杂的搜索功能很多都用不上，最终选择了 Grafana 开源的 Loki 日志系统。下面我们来介绍下 Loki 的一些基本概念和架构。</p><blockquote><p>Loki 是 Grafana Labs 团队最新的开源项目，是一个水平可扩展，高可用性，多租户的日志聚合系统。它的设计非常经济高效且易于操作，因为它不会为日志内容编制索引，而是为每个日志流编制一组标签，专门为 Prometheus 和 Kubernetes 用户做了相关优化。该项目受 Prometheus 启发，官方的介绍就是： <code>Like Prometheus,But For Logs.</code>，类似于 Prometheus 的日志系统。</p><p>项目地址：<a href="https://github.com/grafana/loki/" target="_blank" rel="noopener">https://github.com/grafana/loki/</a></p></blockquote><p>与其他日志聚合系统相比， Loki 具有下面的一些特性：</p><ul><li><p>不对日志进行全文索引。通过存储压缩非结构化日志和仅索引元数据，Loki 操作起来会更简单，更省成本。</p></li><li><p>通过使用与 Prometheus 相同的标签记录流对日志进行索引和分组，这使得日志的扩展和操作效率更高。</p></li><li><p>特别适合储存 Kubernetes Pod 日志; 诸如 Pod 标签之类的元数据会被自动删除和编入索引。</p></li><li><p>受 Grafana 原生支持。</p></li></ul><h2 id="背景和动机">背景和动机</h2><p>当我们的容器云运行的应用或者某个节点出现问题了，解决思路应该如下：</p><p><img src="https://www.hi-linux.com/img/linux/loki1.jpeg" alt=""></p><p>我们的监控使用的是基于 Prometheus 体系进行改造的，Prometheus 中比较重要的是 Metric 和 Alert，Metric 是来说明当前或者历史达到了某个值，Alert 设置 Metric 达到某个特定的基数触发了告警，但是这些信息明显是不够的。</p><p>我们都知道，Kubernetes 的基本单位是 Pod，Pod 把日志输出到 Stdout 和 Stderr，平时有什么问题我们通常在界面或者通过命令查看相关的日志。</p><p>举个例子：当我们的某个 Pod 的内存变得很大，触发了我们的 Alert。这时管理员，去页面查询确认是哪个 Pod 有问题，然后要确认 Pod 内存变大的原因，我们还需要去查询 Pod 的日志，如果没有日志系统，那么我们就需要到页面或者使用命令进行查询：</p><p><img src="https://www.hi-linux.com/img/linux/loki2.jpeg" alt=""></p><p>如果，这个时候应用突然挂了，这个时候我们就无法查到相关的日志了。所以需要引入日志系统，统一收集日志。而使用 ELK 的话，就需要在 Kibana 和 Grafana 之间切换，影响用户体验。所以 ，Loki 的第一目的就是最小化度量和日志的切换成本，有助于减少异常事件的响应时间和提高用户的体验。</p><a id="more"></a><h2 id="elk-存在的问题">ELK 存在的问题</h2><p>现有的很多日志采集的方案都是采用全文检索对日志进行索引（如 ELK 方案），优点是功能丰富，允许复杂的操作。但是，这些方案往往规模复杂，资源占用高，操作苦难。很多功能往往用不上，大多数查询只关注一定时间范围和一些简单的参数（如：host、service 等），使用这些解决方案就有点杀鸡用牛刀的感觉了。</p><p><img src="https://www.hi-linux.com/img/linux/loki3.jpeg" alt=""></p><p>因此，Loki 的第二个目的是，在查询语言的易操作性和复杂性之间可以达到一个权衡。</p><h2 id="成本考量">成本考量</h2><p>全文检索的方案也带来成本问题，简单的说就是全文搜索（如：ES）的倒排索引的切分和共享的成本较高。后来出现了其他不同的设计方案，如：</p><ul><li>OKlog</li></ul><p>项目地址：<a href="https://github.com/oklog/oklog" target="_blank" rel="noopener">https://github.com/oklog/oklog</a></p><p>采用最终一致的、基于网格的分布策略。这两个设计决策提供了大量的成本降低和非常简单的操作，但是查询不够方便。因此，Loki 的第三个目的是，提供一个更具成本效益的解决方案。</p><h2 id="整体架构">整体架构</h2><p>Loki 的架构如下：</p><p><img src="https://www.hi-linux.com/img/linux/loki4.jpeg" alt=""></p><p>不难看出，Loki 的架构非常简单，主要由以下 3 个部分组成：</p><ul><li><p>Loki 是主服务器，负责存储日志和处理查询。</p></li><li><p>Promtail是代理，负责收集日志并将其发送给 Loki 。</p></li><li><p>Grafana 用于 UI 展示。</p></li></ul><p>Loki 使用了和 Prometheus 一样的标签来作为索引。也就是说，你通过这些标签既可以查询日志的内容也可以查询到监控的数据，不但减少了两种查询之间的切换成本，也极大地降低了日志索引的存储。</p><p>Loki 使用与 Prometheus 相同的服务发现和标签重新标记库，编写了 Pormtail。在 Kubernetes 中 Promtail 以 DaemonSet 方式运行在每个节点中，通过 Kubernetes API 得到日志的正确元数据，并将它们发送到 Loki。下面是日志的存储架构：</p><p><img src="https://www.hi-linux.com/img/linux/loki5.jpeg" alt=""></p><h3 id="读写">读写</h3><p>日志数据的写主要依托的是 Distributor 和 Ingester 两个组件，整体的流程如下：</p><p><img src="https://www.hi-linux.com/img/linux/loki6.jpeg" alt=""></p><h3 id="distributor">Distributor</h3><p>一旦 Promtail 收集日志并将其发送给 Loki，Distributor 就是第一个接收日志的组件。由于日志的写入量可能很大，所以不能在它们传入时将它们写入数据库。这会毁掉数据库。我们需要批处理和压缩数据。</p><p>Loki 通过构建压缩数据块来实现这一点，方法是在日志进入时对其进行 Gzip 操作。组件 Ingester 是一个有状态的组件，负责构建和刷新 Chunck，当 Chunk 达到一定的数量或者时间后，刷新到存储中去。每个流的日志对应一个 Ingester，当日志到达 Distributor 后，根据元数据和 Hash 算法计算出应该到哪个 Ingester 上面。</p><p><img src="https://www.hi-linux.com/img/linux/loki7.jpeg" alt=""></p><p>此外，为了冗余和弹性，我们将其复制 n（默认情况下为 3）次。</p><h3 id="ingester">Ingester</h3><p>Ingester 接收到日志并开始构建 Chunk：</p><p><img src="https://www.hi-linux.com/img/linux/loki8.jpeg" alt=""></p><p>基本上就是将日志进行压缩并附加到 Chunk 上面。一旦 Chunk 填满（数据达到一定数量或者过了一定期限），Ingester 将其刷新到数据库。我们对块和索引使用单独的数据库，因为它们存储的数据类型不同。</p><p><img src="https://www.hi-linux.com/img/linux/loki9.jpeg" alt=""></p><p>刷新一个 Chunk 之后，Ingester 然后创建一个新的空 Chunk 并将新条目添加到该 Chunk 中。</p><h3 id="querier">Querier</h3><p>读取就非常简单了，由 Querier 负责给定一个时间范围和标签选择器，Querier 查看索引以确定哪些块匹配，并通过 Greps 将结果显示出来。它还从 Ingester 获取尚未刷新的最新数据。</p><p>对于每个查询，一个查询器将为您显示所有相关日志。实现了查询并行化，提供分布式 Grep，使即使是大型查询也是足够的。</p><p><img src="https://www.hi-linux.com/img/linux/loki10.jpeg" alt=""></p><h3 id="可扩展性">可扩展性</h3><p>Loki 的索引存储可以是 Cassandra/Bigtable/Dynamodb，而 Chuncks 可以是各种对象存储，Querier 和 Distributor 都是无状态的组件。</p><p>对于 Ingester，它虽然是有状态的。但是，当新的节点加入或者减少，整节点间的 Chunk 会重新分配，已适应新的散列环。而 Loki 底层存储的实现 Cortex 已经在实际的生产中投入使用多年了。</p><h2 id="参考链接">参考链接</h2><ol><li><p><a href="https://blog.csdn.net/Linkthaha/article/details/100575278" target="_blank" rel="noopener">https://blog.csdn.net/Linkthaha/article/details/100575278</a></p></li><li><p><a href="http://blog.csdn.net/Linkthaha/article/details/100575651" target="_blank" rel="noopener">http://blog.csdn.net/Linkthaha/article/details/100575651</a></p></li><li><p><a href="https://www.qikqiak.com/post/grafana-log-tool-loki/" target="_blank" rel="noopener">https://www.qikqiak.com/post/grafana-log-tool-loki/</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在对公司容器云的日志方案进行设计的时候，发现主流的 ELK 或者 EFK 比较重，再加上现阶段对于 ES 复杂的搜索功能很多都用不上，最终选择了 Grafana 开源的 Loki 日志系统。下面我们来介绍下 Loki 的一些基本概念和架构。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Loki 是 Grafana Labs 团队最新的开源项目，是一个水平可扩展，高可用性，多租户的日志聚合系统。它的设计非常经济高效且易于操作，因为它不会为日志内容编制索引，而是为每个日志流编制一组标签，专门为 Prometheus 和 Kubernetes 用户做了相关优化。该项目受 Prometheus 启发，官方的介绍就是： &lt;code&gt;Like Prometheus,But For Logs.&lt;/code&gt;，类似于 Prometheus 的日志系统。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/grafana/loki/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/grafana/loki/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与其他日志聚合系统相比， Loki 具有下面的一些特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;不对日志进行全文索引。通过存储压缩非结构化日志和仅索引元数据，Loki 操作起来会更简单，更省成本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过使用与 Prometheus 相同的标签记录流对日志进行索引和分组，这使得日志的扩展和操作效率更高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特别适合储存 Kubernetes Pod 日志; 诸如 Pod 标签之类的元数据会被自动删除和编入索引。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;受 Grafana 原生支持。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景和动机&quot;&gt;背景和动机&lt;/h2&gt;
&lt;p&gt;当我们的容器云运行的应用或者某个节点出现问题了，解决思路应该如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/loki1.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们的监控使用的是基于 Prometheus 体系进行改造的，Prometheus 中比较重要的是 Metric 和 Alert，Metric 是来说明当前或者历史达到了某个值，Alert 设置 Metric 达到某个特定的基数触发了告警，但是这些信息明显是不够的。&lt;/p&gt;
&lt;p&gt;我们都知道，Kubernetes 的基本单位是 Pod，Pod 把日志输出到 Stdout 和 Stderr，平时有什么问题我们通常在界面或者通过命令查看相关的日志。&lt;/p&gt;
&lt;p&gt;举个例子：当我们的某个 Pod 的内存变得很大，触发了我们的 Alert。这时管理员，去页面查询确认是哪个 Pod 有问题，然后要确认 Pod 内存变大的原因，我们还需要去查询 Pod 的日志，如果没有日志系统，那么我们就需要到页面或者使用命令进行查询：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/loki2.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果，这个时候应用突然挂了，这个时候我们就无法查到相关的日志了。所以需要引入日志系统，统一收集日志。而使用 ELK 的话，就需要在 Kibana 和 Grafana 之间切换，影响用户体验。所以 ，Loki 的第一目的就是最小化度量和日志的切换成本，有助于减少异常事件的响应时间和提高用户的体验。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Loki" scheme="https://www.hi-linux.com/categories/Loki/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Loki" scheme="https://www.hi-linux.com/tags/Loki/"/>
    
  </entry>
  
  <entry>
    <title>推荐几款快速管理 Kubernetes 多集群环境的神器</title>
    <link href="https://www.hi-linux.com/posts/25886.html"/>
    <id>https://www.hi-linux.com/posts/25886.html</id>
    <published>2020-07-20T01:00:00.000Z</published>
    <updated>2020-07-20T01:24:53.671Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Kubernetes</code> 生态在很多企业广泛应用的当下，相信很多运维和开发人员都会同时管理和维护多个 <code>Kubernetes</code> 集群，比如：开发环境、测试环境、预发布环境、生产环境等等。</p><p>为了方便管理多个环境的集群，通常都是在本地环境通过 <code>Kubernetes</code> 的客户端工具 <code>kubectl</code> 来管理多个 <code>Kubernetes</code> 集群的。这时你就需要用到各个集群的 <code>kubeconfig</code> 文件，你是不是首先想到的就是手动将多个 <code>kubeconfig</code> 配置文件合并为一个，然后通过 <code>kubectx</code> 或 <code>kubie</code> 这样的工具来快速切换上下文环境（context）来达到多集群环境的管理呢？虽然手动合并 <code>kubeconfig</code> 配置文件的方法是可行的，但是集群环境较多时或者集群环境经常变更时，这样的方法就显得很麻烦了。</p><p>今天，我们就给大家介绍几种更方便更快捷的 <code>Kubernetes</code> 多集群管理方法。首先我们来看看官方提供的实现方式：</p><h3 id="官方提供的解决方法">官方提供的解决方法</h3><p>官方目前提供了配置环境变量和通过命令行参数显示指定两种方法来解决这个问题。</p><ol><li>配置环境变量指定多个集群的 kubeconfig 文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 配置 Kubernetes 多集群，注意使用 : 隔开</span><br><span class="line">export KUBECONFIG&#x3D;$KUBECONFIG:$HOME&#x2F;.kube&#x2F;config:$HOME&#x2F;.kube&#x2F;mike-local-kubernetes.yaml:$HOME&#x2F;.kube&#x2F;dev-kubernetes.yaml:$HOME&#x2F;.kube&#x2F;test-kubernetes.yaml:$HOME&#x2F;.kube&#x2F;prod-kubernetes.yaml:$HOME&#x2F;.kube&#x2F;okteto-kube.yaml</span><br></pre></td></tr></table></figure><ol start="2"><li>通过命令行参数显示指定不同集群的 kubeconfig 文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 切换到本地集群</span><br><span class="line">kubectl get pod --kubeconfig&#x3D;$HOME&#x2F;.kube&#x2F;mike-local-kubernetes.yaml</span><br><span class="line"></span><br><span class="line"># 切换到开发集群</span><br><span class="line">kubectl get pod --kubeconfig&#x3D;$HOME&#x2F;.kube&#x2F;dev-kubernetes.yaml</span><br><span class="line"></span><br><span class="line"># 切换到测试集群</span><br><span class="line">kubectl get pod --kubeconfig&#x3D;$HOME&#x2F;.kube&#x2F;test-kubernetes.yaml</span><br><span class="line"></span><br><span class="line"># 切换到生产集群</span><br><span class="line">kubectl get pod --kubeconfig&#x3D;$HOME&#x2F;.kube&#x2F;prod-kubernetes.yaml</span><br></pre></td></tr></table></figure><p>虽然官方提供的方法，能实现多集群管理。但是不断来回切换 <code>kubeconfig</code> 配置文件或者经常手动编辑环境变量来增减多个集群的配置文件，显然还是比较麻烦的。</p><a id="more"></a><p>接下来，给大家介绍的就是本文的重点，这是一种更优雅的解决方法。</p><h3 id="通过自动合并工具实现多集群-kubeconfig-配置文件管理">通过自动合并工具实现多集群 Kubeconfig 配置文件管理</h3><p>既然手动合并太过麻烦和复杂，有没有自动合并工具呢？你别说，还真有且不此一款。下面我们来介绍下如何使用这几款好用的自动合并工具。</p><h3 id="kubecm">KubeCM</h3><p><code>KubeCM</code> 是一款使用 <code>Go</code> 语言开发的 <code>KubeConfig</code> 管理工具，功能非常的强大。它不但能实现多个 <code>KubeConfig</code> 文件的自动合并，还能很方便的管理多个 <code>Kubernetes</code> 集群环境，比如：增加、删除、重命名不同集群环境等。</p><ol><li>安装 KubeCM</li></ol><p><code>KubeCM</code> 的安装非常的简单，你只需直接下载相应平台的二进制文件解压后就可使用了，完全就是开箱即用。</p><ul><li>通过二进制文件安装</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 根据你的实际情况，下载对应平台二进制文件即可。</span><br><span class="line"></span><br><span class="line"># Linux</span><br><span class="line">$ curl -Lo kubecm.tar.gz https:&#x2F;&#x2F;github.com&#x2F;sunny0826&#x2F;kubecm&#x2F;releases&#x2F;download&#x2F;v0.8.0&#x2F;kubecm_0.8.0_Linux_x86_64.tar.gz</span><br><span class="line"># macOS</span><br><span class="line">$ curl -Lo kubecm.tar.gz https:&#x2F;&#x2F;github.com&#x2F;sunny0826&#x2F;kubecm&#x2F;releases&#x2F;download&#x2F;v0.8.0&#x2F;kubecm_0.8.0_Darwin_x86_64.tar.gz</span><br><span class="line"># Windows</span><br><span class="line">$ curl -Lo kubecm.tar.gz https:&#x2F;&#x2F;github.com&#x2F;sunny0826&#x2F;kubecm&#x2F;releases&#x2F;download&#x2F;v0.8.0&#x2F;kubecm_0.8.0_Windows_x86_64.tar.gz</span><br></pre></td></tr></table></figure><p>下载完成后，解压对应安装包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Linux &amp; macOS</span><br><span class="line">$ tar -zxvf kubecm.tar.gz kubecm</span><br><span class="line">$ sudo mv kubecm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br><span class="line"></span><br><span class="line"># Windows</span><br><span class="line"># 你可以使用做任意一款压缩软件进行解压并放到 $PATH 中</span><br><span class="line">$ unzip kubecm.tar.gz</span><br></pre></td></tr></table></figure><ul><li>通过包管理器进行安装</li></ul><p>如果你使用的是 <code>macOS</code>，还可以使用 <code>Homebrew</code> 来进行一键安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install sunny0826&#x2F;tap&#x2F;kubecm</span><br></pre></td></tr></table></figure><ol start="2"><li>使用 KubeCM</li></ol><p>为了方便演示，我们先创建一个 <code>mike-kubeconfig</code> 目录并将多个集群配置文件复制到这里。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir mike-kubeconfig</span><br><span class="line">$ cp *.yaml mike-kubeconfig&#x2F;</span><br><span class="line">$ ls mike-kubeconfig</span><br><span class="line">dev-kubernetes.yaml   mike-local-kubernetes.yaml okteto-kube.yaml</span><br></pre></td></tr></table></figure><blockquote><p>注：你可能发现了，我这里的 Kubeconfig 配置文件都是以 .yaml 结尾的，这是为了方便 Kubie 这个工具进行多集群切换。你只需按自己环境的规则管理 Kubeconfig 文件即可。</p></blockquote><ul><li>使用 KubeCM 完成自动合并</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 将指定目录中的所有 kubeconfig 配置文件合并为一个</span><br><span class="line">$ kubecm merge -f mike-kubeconfig</span><br><span class="line">Loading kubeconfig file: [mike-kubeconfig&#x2F;dev-kubernetes.yaml mike-kubeconfig&#x2F;mike-local-kubernetes.yaml mike-kubeconfig&#x2F;okteto-kube.yaml]</span><br><span class="line">Context Add: dev-kubernetes</span><br><span class="line">Context Add: mike-local-kubernetes</span><br><span class="line">Context Add: okteto-kube</span><br><span class="line"></span><br><span class="line"># 将指定目录中的所有 kubeconfig 配置文件合并为一个并且覆盖默认的 Kubeconfig 配置文件</span><br><span class="line">$ kubecm merge -f mike-kubeconfig -c</span><br></pre></td></tr></table></figure><blockquote><p>注意：是否使用 -c 参数的区别是：-c 参数生成的合并后文件名为 .kube/config，而不使用 -c 参数生成的合并后的文件名为 .kube/config.yaml。</p></blockquote><ul><li>使用 KubeCM 快速增加一个集群配置</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用 KubeCM 快速增加一个集群配置文件</span><br><span class="line">$ kubecm add -f mike-local-kubernetes.yaml</span><br><span class="line"></span><br><span class="line"># 使用 KubeCM 快速增加一个集群配置文件并指定默认命名空间</span><br><span class="line">$ kubecm add -f mike-local-kubernetes.yaml -n test</span><br></pre></td></tr></table></figure><ul><li>使用 KubeCM 快速删除一个集群配置</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 通过命令行模式删除一个集群配置</span><br><span class="line">$ kubecm delete mike-local-kubernetes</span><br></pre></td></tr></table></figure><ul><li>使用 KubeCM 快速重命名一个集群配置</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 将 dev 重命名为 test</span><br><span class="line">$ kubecm rename -o dev -n test</span><br><span class="line"># 将当前上下文重命名为 dev</span><br><span class="line">$ kubecm rename -n dev -c</span><br></pre></td></tr></table></figure><p>以上就是 <code>KubeCM</code> 的一些命令行下的常规操作，为了更高效的使用命令行。<code>KubeCM</code> 还提供了 <code>SHELL</code> 自动补全功能，只需按下面的方法简单设置一下即可。</p><ul><li>Bash</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubecm completion bash &gt; ~&#x2F;.kube&#x2F;kubecm.bash.inc</span><br><span class="line">$ printf &quot;</span><br><span class="line"># kubecm shell completion</span><br><span class="line">source &#39;$HOME&#x2F;.kube&#x2F;kubecm.bash.inc&#39;</span><br><span class="line">&quot; &gt;&gt; $HOME&#x2F;.bash_profile</span><br><span class="line">$ source $HOME&#x2F;.bash_profile</span><br></pre></td></tr></table></figure><ul><li>ZSH</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># add to $HOME&#x2F;.zshrc </span><br><span class="line">source &lt;(kubecm completion zsh)</span><br><span class="line"># or</span><br><span class="line">$ kubecm completion zsh &gt; &quot;$&#123;fpath[1]&#125;&#x2F;_kubecm&quot;</span><br></pre></td></tr></table></figure><p>到这里，你肯定以为就该结束了吧！不，你错了，<code>KubeCM</code> 不仅提供了命令行模式，它还提供更加人性化的交互模式。话不多说，直接看图：</p><p><img src="https://www.hi-linux.com/img/linux/Kubecm-Interaction.gif" alt=""></p><p>这样操作是不是更加方便了呢？除此之外，<code>KubeCM</code> 还提供了快速切换集群和命名空间的功能哟，这样一来，你完全可以省去安装文章开头提到的 <code>kubectx</code> 或 <code>kubie</code> 这类集群切换工具了呢。</p><ul><li>使用 KubeCM 快速切换到不同集群环境</li></ul><p><img src="https://www.hi-linux.com/img/linux/Kubecm-switch.gif" alt=""></p><ul><li>使用 KubeCM 快速切换到集群中的不同命名空间</li></ul><p><img src="https://www.hi-linux.com/img/linux/Kubecm-ns.gif" alt=""></p><h3 id="kubectx-contexts-manager">Kubectx Contexts Manager</h3><p><code>Kubectx.Manager</code> 和  <code>KubeCM</code> 功能类似，也是一个可以将多个 <code>kubeconfig</code> 配置文件自动合并成一个管理工具。</p><p><code>Kubectx.Manager</code> 使用 <code>Nodejs</code> 开发。在安装前，你必须先有一个 <code>Nodejs</code> 环境。<code>Nodejs</code> 的安装也挺简单的，这里就不展开讲了，可自行 <code>Google</code>。</p><p><code>Nodejs</code> 环境安装完成后，你只需运行下面的命令即可完成安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g git+https:&#x2F;&#x2F;git@github.com&#x2F;AveryanovS&#x2F;kubectx.manager</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kubemanager -&gt; &#x2F;usr&#x2F;local&#x2F;lib&#x2F;node_modules&#x2F;kubectx.manager&#x2F;cli.js</span><br><span class="line">+ kubectx.manager@1.0.0</span><br><span class="line">added 4 packages from 6 contributors in 11.208s</span><br></pre></td></tr></table></figure><p>安装完成后，我们就来演示如何合并多个 <code>kubeconfig</code> 配置文件。<code>Kubectx.Manager</code> 同样也是支持交互式操作的，你只需执行命令，然后根据一系列交互动作的提示进行操作便可轻松完成操作。</p><ol><li>使用 Kubectx.Manager 自动合并</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubemanager</span><br><span class="line">✔ Select action · merge</span><br><span class="line">✔ Path to current kube config? · &#x2F;Users&#x2F;Mike&#x2F;.kube&#x2F;config</span><br><span class="line">✔ Path to config to merge? · &#x2F;Users&#x2F;Mike&#x2F;.kube&#x2F;mike-local-kubernetes.yaml</span><br><span class="line">✔ Name of new context? · mike-local</span><br><span class="line">Context test created!</span><br><span class="line">Config file updated!</span><br></pre></td></tr></table></figure><p>下面我们来简单说说以上几步操作的作用。</p><ul><li>第一行选择 merge，表示合并。</li><li>第二行选择需要合并到哪个 Kubeconfig，也就是你最终要用的 Kubeconfig。</li><li>第三行选择需要合并的 Kubeconfig。</li><li>第四行定义合并后新加入的 Context 名称。</li></ul><ol start="2"><li>使用 Kubectx.Manager 删除指定的集群环境</li></ol><p>删除操作和合并操作类似，相信聪明的你一看就明白了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubemanager</span><br><span class="line">✔ Select action · delete</span><br><span class="line">✔ Path to current kube config? · &#x2F;Users&#x2F;Mike&#x2F;.kube&#x2F;config</span><br><span class="line">✔ Select context to delete · mike-local</span><br><span class="line">Context mike-local deleted!</span><br><span class="line">Config file updated!</span><br></pre></td></tr></table></figure><p><code>Kubectx.Manager</code> 目前仅支持以上的两种对 <code>Kubeconfig</code> 文件的管理操作，相对于 <code>KubeCM</code> 来说功能还是相对于弱一些。它并不支持多集群和多命名空间的快速切换。如果要实现多集群和多命名空间的快速切换，你还需要结合 <code>kubectx</code> 或 <code>kubie</code> 这类快速集群切换工具一并使用哟!</p><h3 id="mergekubeconfig">mergeKubeConfig</h3><p><code>mergeKubeConfig</code> 是由 <code>Python</code> 开发的类似的工具，它和 <code>KubeCM</code> 来自同一开发者。目前已停止维护，都有 <code>Go</code> 版本了，还要什么自行车呢？</p><p>这里顺手提一下纯粹是记录下它曾经存在过，哈哈！</p><p>好了，本文到此就结束了。这些神奇的小工具是不是很好的解决了你在 <code>Kubernetes</code> 多集群管理中的痛点呢？</p><p>最后，根据自己的实际情况选一个最符合你需求的使用吧。这时，你可能会惊奇的发现文中并没有这几个小工具的项目地址！</p><p>哈哈，是时候支持一波公众号了！如需以上小工具项目地址，<strong>请在公众号对话框内回复 「<code>Kubeconfig</code>」，即可获取这一系列小工具的项目下载地址。</strong></p><h3 id="参考文档">参考文档</h3><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://yq.aliyun.com/articles/695429" target="_blank" rel="noopener">https://yq.aliyun.com/articles/695429</a></p></li><li><p><a href="https://mp.weixin.qq.com/s/Sp37W-5C3YGSNf_H8HTuUA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Sp37W-5C3YGSNf_H8HTuUA</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt; 生态在很多企业广泛应用的当下，相信很多运维和开发人员都会同时管理和维护多个 &lt;code&gt;Kubernetes&lt;/code&gt; 集群，比如：开发环境、测试环境、预发布环境、生产环境等等。&lt;/p&gt;
&lt;p&gt;为了方便管理多个环境的集群，通常都是在本地环境通过 &lt;code&gt;Kubernetes&lt;/code&gt; 的客户端工具 &lt;code&gt;kubectl&lt;/code&gt; 来管理多个 &lt;code&gt;Kubernetes&lt;/code&gt; 集群的。这时你就需要用到各个集群的 &lt;code&gt;kubeconfig&lt;/code&gt; 文件，你是不是首先想到的就是手动将多个 &lt;code&gt;kubeconfig&lt;/code&gt; 配置文件合并为一个，然后通过 &lt;code&gt;kubectx&lt;/code&gt; 或 &lt;code&gt;kubie&lt;/code&gt; 这样的工具来快速切换上下文环境（context）来达到多集群环境的管理呢？虽然手动合并 &lt;code&gt;kubeconfig&lt;/code&gt; 配置文件的方法是可行的，但是集群环境较多时或者集群环境经常变更时，这样的方法就显得很麻烦了。&lt;/p&gt;
&lt;p&gt;今天，我们就给大家介绍几种更方便更快捷的 &lt;code&gt;Kubernetes&lt;/code&gt; 多集群管理方法。首先我们来看看官方提供的实现方式：&lt;/p&gt;
&lt;h3 id=&quot;官方提供的解决方法&quot;&gt;官方提供的解决方法&lt;/h3&gt;
&lt;p&gt;官方目前提供了配置环境变量和通过命令行参数显示指定两种方法来解决这个问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置环境变量指定多个集群的 kubeconfig 文件&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 配置 Kubernetes 多集群，注意使用 : 隔开&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export KUBECONFIG&amp;#x3D;$KUBECONFIG:$HOME&amp;#x2F;.kube&amp;#x2F;config:$HOME&amp;#x2F;.kube&amp;#x2F;mike-local-kubernetes.yaml:$HOME&amp;#x2F;.kube&amp;#x2F;dev-kubernetes.yaml:$HOME&amp;#x2F;.kube&amp;#x2F;test-kubernetes.yaml:$HOME&amp;#x2F;.kube&amp;#x2F;prod-kubernetes.yaml:$HOME&amp;#x2F;.kube&amp;#x2F;okteto-kube.yaml&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;通过命令行参数显示指定不同集群的 kubeconfig 文件&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 切换到本地集群&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl get pod --kubeconfig&amp;#x3D;$HOME&amp;#x2F;.kube&amp;#x2F;mike-local-kubernetes.yaml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 切换到开发集群&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl get pod --kubeconfig&amp;#x3D;$HOME&amp;#x2F;.kube&amp;#x2F;dev-kubernetes.yaml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 切换到测试集群&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl get pod --kubeconfig&amp;#x3D;$HOME&amp;#x2F;.kube&amp;#x2F;test-kubernetes.yaml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 切换到生产集群&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl get pod --kubeconfig&amp;#x3D;$HOME&amp;#x2F;.kube&amp;#x2F;prod-kubernetes.yaml&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;虽然官方提供的方法，能实现多集群管理。但是不断来回切换 &lt;code&gt;kubeconfig&lt;/code&gt; 配置文件或者经常手动编辑环境变量来增减多个集群的配置文件，显然还是比较麻烦的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>推荐 3 款超好用的 Docker 图形化管理工具</title>
    <link href="https://www.hi-linux.com/posts/279.html"/>
    <id>https://www.hi-linux.com/posts/279.html</id>
    <published>2020-07-17T01:00:00.000Z</published>
    <updated>2020-07-17T03:54:56.828Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Docker 是一项非常流行的容器技术，现在在各行各业有着广泛的使用。不过如何管理 Docker 容器是一个问题，所以我今天向大家介绍 3 款 Docker 可视化工具，希望对大家有所帮助。</p><h3 id="portainer">Portainer</h3><p>Portainer 是一款 Docker 可视化管理工具，允许我们在网页中方便的查看和管理 Docker 容器。</p><p>项目地址：<a href="https://www.portainer.io/" target="_blank" rel="noopener">https://www.portainer.io/</a></p><p><img src="https://www.hi-linux.com/img/linux/portainer-1.jpeg" alt=""></p><p>要使用 Portainer 很简单，运行下面两条命令即可。这些命令会创建一个 Portainer 专用的卷，然后在 8000 和 9000 端口创建容器并运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume create portainer_data</span><br><span class="line">$ docker run --name portainer -d -p 8000:8000 -p 9000:9000 -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock -v portainer_data:&#x2F;data portainer&#x2F;portainer</span><br></pre></td></tr></table></figure><p>然后在浏览器打开对应地址，就会发现成功运行了。第一次运行的时候需要设置账号，然后选择要管理的 Docker 主机。</p><p><img src="https://www.hi-linux.com/img/linux/portainer-2.jpeg" alt=""></p><p>设置账号</p><p><img src="https://www.hi-linux.com/img/linux/portainer-3.jpeg" alt=""></p><p>选择要管理的主机</p><p>之后就可以看到本机上运行的 Docker 容器了，点击它们还可以进行容器的管理。左边的条目可以管理卷、创建容器、查看主机信息等等。基本上该有的功能都有了，这也是我推荐的一个工具。</p><p><img src="https://www.hi-linux.com/img/linux/portainer-4.jpeg" alt=""></p><a id="more"></a><h3 id="lazydocker">LazyDocker</h3><p>LazyDocker 是基于终端的一个可视化查询工具，支持键盘操作和鼠标点击。相比 Portainer 来说可能不那么专业，不过对于开发者来说可能反而更加好用了。因为一般开发者都是使用命令行来运行 Docker，偶尔需要图形化查看的时候，就可以使用 LazyDocker 这个工具。</p><p>项目地址：<a href="https://github.com/jesseduffield/lazydocker" target="_blank" rel="noopener">https://github.com/jesseduffield/lazydocker</a></p><p><img src="https://www.hi-linux.com/img/linux/lazydocker-1.gif" alt=""></p><p>官网演示图</p><p>安装 LazyDocker 也非常简单，运行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm -it -v \</span><br><span class="line">&#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock \</span><br><span class="line">-v ~&#x2F;.config&#x2F;lazydocker:&#x2F;.config&#x2F;jesseduffield&#x2F;lazydocker \</span><br><span class="line">lazyteam&#x2F;lazydocker</span><br></pre></td></tr></table></figure><p>当然如果发现 LazyDocker 挺好用，准备经常使用的话，还可以把它做成缩写添加到 Shell 配置文件中，这样就可以将它变成一个简单的命令。</p><p>例如我用的是 zsh，就将下面这样添加到 .zshrc 文件中。以后就可以直接用 lzd 来 调用 LazyDocker 了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias lzd&#x3D;&#39;docker run --rm -it -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock -v ~&#x2F;.config&#x2F;lazydocker:&#x2F;.config&#x2F;jesseduffield&#x2F;lazydocker lazyteam&#x2F;lazydocker&#39;</span><br></pre></td></tr></table></figure><p>然后就可以在终端中查看 Docker 容器、镜像和卷的信息了。</p><p>LazyDocker 支持键盘操作和鼠标点击，直接用鼠标点击就可以查看对应信息了。</p><p><img src="https://www.hi-linux.com/img/linux/lazydocker-2.jpeg" alt=""></p><p>需要注意如果你的终端 LazyDocker 的图形显示的是乱的，不用担心，只不过是显示字体的问题。重新设置一下终端字体就可以解决了。</p><p><img src="https://www.hi-linux.com/img/linux/lazydocker-3.jpeg" alt=""></p><h3 id="docui">Docui</h3><p>Docui 同样是一个开源的终端 Docker 管理工具，形式与 Lazydocker 一样，也是 终端 UI 的形式。</p><p>Docui 和 Lazydocker 它们都有一个共同的优势，就是支持大量的快捷键，熟练后会极其便利。</p><p>项目地址：<a href="https://github.com/skanehira/docui" target="_blank" rel="noopener">https://github.com/skanehira/docui</a></p><p><img src="https://www.hi-linux.com/img/linux/docui.jpeg" alt=""></p><p>Docui 安装也是很简单的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 通过源码安装</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;skanehira&#x2F;docui.git</span><br><span class="line">$ cd docui&#x2F;</span><br><span class="line">$ GO111MODULE&#x3D;on go install</span><br><span class="line"></span><br><span class="line"># macOS 可能通过 Homebrew 安装</span><br><span class="line">$ brew tap skanehira&#x2F;docui</span><br><span class="line">$ brew install docui</span><br></pre></td></tr></table></figure><h3 id="小结">小结</h3><p>如果你是团队使用，Portainer 会比较适合，因为它有访问控制。</p><p>Lazydocker 和 Docui 都属于简单灵活的终端小工具，如果你不需要复杂的功能，或许它们会更适合你。</p><p>Docker 有很多免费的好用三方客户端工具，上面只是其中的一些，具体哪一款更适合你，还需要自行试用了解后根据实际需求来选择最适合的。</p><h3 id="参考文档">参考文档</h3><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.toutiao.com/i6780014313227682316/" target="_blank" rel="noopener">https://www.toutiao.com/i6780014313227682316/</a></li><li><a href="https://mp.weixin.qq.com/s/sbnFeAk0NvkG-3ahq6lUfg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/sbnFeAk0NvkG-3ahq6lUfg</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker 是一项非常流行的容器技术，现在在各行各业有着广泛的使用。不过如何管理 Docker 容器是一个问题，所以我今天向大家介绍 3 款 Docker 可视化工具，希望对大家有所帮助。&lt;/p&gt;
&lt;h3 id=&quot;Portainer&quot;&gt;Portainer&lt;/h3&gt;
&lt;p&gt;Portainer 是一款 Docker 可视化管理工具，允许我们在网页中方便的查看和管理 Docker 容器。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://www.portainer.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.portainer.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/portainer-1.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;要使用 Portainer 很简单，运行下面两条命令即可。这些命令会创建一个 Portainer 专用的卷，然后在 8000 和 9000 端口创建容器并运行。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ docker volume create portainer_data&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ docker run --name portainer -d -p 8000:8000 -p 9000:9000 -v &amp;#x2F;var&amp;#x2F;run&amp;#x2F;docker.sock:&amp;#x2F;var&amp;#x2F;run&amp;#x2F;docker.sock -v portainer_data:&amp;#x2F;data portainer&amp;#x2F;portainer&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后在浏览器打开对应地址，就会发现成功运行了。第一次运行的时候需要设置账号，然后选择要管理的 Docker 主机。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/portainer-2.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;设置账号&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/portainer-3.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;选择要管理的主机&lt;/p&gt;
&lt;p&gt;之后就可以看到本机上运行的 Docker 容器了，点击它们还可以进行容器的管理。左边的条目可以管理卷、创建容器、查看主机信息等等。基本上该有的功能都有了，这也是我推荐的一个工具。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/portainer-4.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>SSH 证书登录教程</title>
    <link href="https://www.hi-linux.com/posts/5424.html"/>
    <id>https://www.hi-linux.com/posts/5424.html</id>
    <published>2020-07-09T01:00:00.000Z</published>
    <updated>2020-07-09T06:04:42.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>SSH 是服务器登录工具，提供密码登录和密钥登录。</p><p>但是，SSH 还有第三种登录方法，那就是证书登录。很多情况下，它是更合理、更安全的登录方法，本文就介绍这种登录方法。</p><h2 id="一-非证书登录的缺点">一、非证书登录的缺点</h2><p>密码登录和密钥登录，都有各自的缺点。</p><p>密码登录需要输入服务器密码，这非常麻烦，也不安全，存在被暴力破解的风险。</p><p>密钥登录需要服务器保存用户的公钥，也需要用户保存服务器公钥的指纹。这对于多用户、多服务器的大型机构很不方便，如果有员工离职，需要将他的公钥从每台服务器删除。</p><h2 id="二-证书登录是什么">二、证书登录是什么？</h2><p>证书登录就是为了解决上面的缺点而设计的。它引入了一个证书颁发机构（Certificate1 authority，简称 CA），对信任的服务器颁发服务器证书，对信任的用户颁发用户证书。</p><p>登录时，用户和服务器不需要提前知道彼此的公钥，只需要交换各自的证书，验证是否可信即可。</p><p>证书登录的主要优点有两个：（1）用户和服务器不用交换公钥，这更容易管理，也具有更好的可扩展性。（2）证书可以设置到期时间，而公钥没有到期时间。针对不同的情况，可以设置有效期很短的证书，进一步提高安全性。</p><a id="more"></a><h2 id="三-证书登录的流程">三、证书登录的流程</h2><p>SSH 证书登录之前，如果还没有证书，需要生成证书。具体方法是：（1）用户和服务器都将自己的公钥，发给 CA；（2）CA 使用服务器公钥，生成服务器证书，发给服务器；（3）CA 使用用户的公钥，生成用户证书，发给用户。</p><p>有了证书以后，用户就可以登录服务器了。整个过程都是 SSH 自动处理，用户无感知。</p><p>第一步，用户登录服务器时，SSH 自动将用户证书发给服务器。</p><p>第二步，服务器检查用户证书是否有效，以及是否由可信的 CA 颁发。</p><p>第三步，SSH 自动将服务器证书发给用户。</p><p>第四步，用户检查服务器证书是否有效，以及是否由信任的 CA 颁发。</p><p>第五步，双方建立连接，服务器允许用户登录。</p><h2 id="四-生成-ca-的密钥">四、生成 CA 的密钥</h2><p>证书登录的前提是，必须有一个 CA，而 CA 本质上就是一对密钥，跟其他密钥没有不同，CA 就用这对密钥去签发证书。</p><p>虽然 CA 可以用同一对密码签发用户证书和服务器证书，但是出于安全性和灵活性，最好用不同的密钥分别签发。所以，CA 至少需要两对密钥，一对是签发用户证书的密钥，假设叫做 user_ca，另一对是签发服务器证书的密钥，假设叫做 host_ca。</p><p>使用下面的命令，生成 user_ca。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 生成 CA 签发用户证书的密钥</span><br><span class="line">$ ssh-keygen -t rsa -b 4096 -f ~&#x2F;.ssh&#x2F;user_ca -C user_ca</span><br></pre></td></tr></table></figure><p>上面的命令会在 ~/.ssh 目录生成一对密钥：user_ca（私钥）和 user_ca.pub（公钥）。</p><p>这个命令的各个参数含义如下。</p><ul><li>-t rsa：指定密钥算法 RSA。</li><li>-b 4096：指定密钥的位数是4096位。安全性要求不高的场合，这个值可以小一点，但是不应小于1024。</li><li>-f ~/.ssh/user_ca：指定生成密钥的位置和文件名。</li><li>-C user_ca：指定密钥的识别字符串，相当于注释，可以随意设置。</li></ul><p>使用下面的命令，生成 host_ca。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 生成 CA 签发服务器证书的密钥</span><br><span class="line">$ ssh-keygen -t rsa -b 4096 -f host_ca -C host_ca</span><br></pre></td></tr></table></figure><p>上面的命令会在~/.ssh目录生成一对密钥：host_ca（私钥）和 host_ca.pub（公钥）。</p><p>现在，~/.ssh 目录应该至少有四把密钥。</p><ul><li>~/.ssh/user_ca</li><li>~/.ssh/user_ca.pub</li><li>~/.ssh/host_ca</li><li>~/.ssh/host_ca.pub</li></ul><h2 id="五-ca-签发服务器证书">五、CA 签发服务器证书</h2><p>有了 CA 以后，就可以签发服务器证书了。</p><p>签发证书，除了 CA 的密钥以外，还需要服务器的公钥。一般来说，SSH 服务器（通常是sshd）安装时，已经生成密钥 /etc/ssh/ssh_host_rsa_key 了。如果没有的话，可以用下面的命令生成。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ssh-keygen -f &#x2F;etc&#x2F;ssh&#x2F;ssh_host_rsa_key -b 4096 -t rsa</span><br></pre></td></tr></table></figure><p>上面命令会在 /etc/ssh 目录，生成 ssh_host_rsa_key（私钥）和 ssh_host_rsa_key.pub（公钥）。然后，需要把服务器公钥 ssh_host_rsa_key.pub，复制或上传到 CA 所在的服务器。</p><p>上传以后，CA 就可以使用密钥 host_ca 为服务器的公钥 ssh_host_rsa_key.pub 签发服务器证书。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -s host_ca -I host.example.com -h -n host.example.com -V +52w ssh_host_rsa_key.pub</span><br></pre></td></tr></table></figure><p>上面的命令会生成服务器证书 ssh_host_rsa_key-cert.pub（服务器公钥名字加后缀-cert）。这个命令各个参数的含义如下。</p><ul><li>-s：指定 CA 签发证书的密钥。</li><li>-I：身份字符串，可以随便设置，相当于注释，方便区分证书，将来可以使用这个字符串撤销证书。</li><li>-h：指定该证书是服务器证书，而不是用户证书。</li><li>-n <a href="http://host.example.com" target="_blank" rel="noopener">host.example.com</a>：指定服务器的域名，表示证书仅对该域名有效。如果有多个域名，则使用逗号分隔。用户登录该域名服务器时，SSH 通过证书的这个值，分辨应该使用哪张证书发给用户，用来证明服务器的可信性。</li><li>-V +52w：指定证书的有效期，这里为 52 周（一年）。默认情况下，证书是永远有效的。建议使用该参数指定有效期，并且有效期最好短一点，最长不超过 52 周。</li><li>ssh_host_rsa_key.pub：服务器公钥。</li></ul><p>生成证书以后，可以使用下面的命令，查看证书的细节。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -L -f ssh_host_rsa_key-cert.pub</span><br></pre></td></tr></table></figure><p>最后，为证书设置权限。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chmod 600 ssh_host_rsa_key-cert.pub</span><br></pre></td></tr></table></figure><h2 id="六-ca-签发用户证书">六、CA 签发用户证书</h2><p>下面，再用 CA 签发用户证书。这时需要用户的公钥，如果没有的话，客户端可以用下面的命令生成一对密钥。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -f ~&#x2F;.ssh&#x2F;user_key -b 4096 -t rsa</span><br></pre></td></tr></table></figure><p>上面命令会在 ~/.ssh 目录，生成 user_key（私钥）和 user_key.pub（公钥）。</p><p>然后，将用户公钥 user_key.pub，上传或复制到 CA 服务器。接下来，就可以使用 CA 的密钥 user_ca 为用户公钥 user_key.pub 签发用户证书。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -s user_ca -I user@example.com -n user -V +1d user_key.pub</span><br></pre></td></tr></table></figure><p>上面的命令会生成用户证书 user_key-cert.pub（用户公钥名字加后缀-cert）。这个命令各个参数的含义如下。</p><ul><li>-s：指定 CA 签发证书的密钥</li><li>-I：身份字符串，可以随便设置，相当于注释，方便区分证书，将来可以使用这个字符串撤销证书。</li><li>-n user：指定用户名，表示证书仅对该用户名有效。如果有多个用户名，使用逗号分隔。用户以该用户名登录服务器时，SSH 通过这个值，分辨应该使用哪张证书，证明自己的身份，发给服务器。</li><li>-V +1d：指定证书的有效期，这里为1天，强制用户每天都申请一次证书，提高安全性。默认情况下，证书是永远有效的。</li><li>user_key.pub：用户公钥。</li></ul><p>生成证书以后，可以使用下面的命令，查看证书的细节。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -L -f user_key-cert.pub</span><br></pre></td></tr></table></figure><p>最后，为证书设置权限。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chmod 600 user_key-cert.pub</span><br></pre></td></tr></table></figure><h2 id="七-服务器安装证书">七、服务器安装证书</h2><p>CA 生成服务器证书 ssh_host_rsa_key-cert.pub 以后，需要将该证书发回服务器，可以使用下面的 scp 命令，将证书拷贝过去。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scp ~&#x2F;.ssh&#x2F;ssh_host_rsa_key-cert.pub root@host.example.com:&#x2F;etc&#x2F;ssh&#x2F;</span><br></pre></td></tr></table></figure><p>然后，将下面一行添加到服务器配置文件 /etc/ssh/sshd_config。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HostCertificate &#x2F;etc&#x2F;ssh&#x2F;ssh_host_rsa_key-cert.pub</span><br></pre></td></tr></table></figure><p>上面的代码告诉 sshd，服务器证书是哪一个文件。</p><p>重新启动 sshd。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart sshd</span><br><span class="line"># 或者</span><br><span class="line">$ sudo service sshd restart</span><br></pre></td></tr></table></figure><h2 id="八-服务器安装-ca-公钥">八、服务器安装 CA 公钥</h2><p>为了让服务器信任用户证书，必须将 CA 签发用户证书的公钥 user_ca.pub，拷贝到服务器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scp ~&#x2F;.ssh&#x2F;user_ca.pub root@host.example.com:&#x2F;etc&#x2F;ssh&#x2F;</span><br></pre></td></tr></table></figure><p>上面的命令，将 CA 签发用户证书的公钥 user_ca.pub，拷贝到 SSH 服务器的 /etc/ssh 目录。</p><p>然后，将下面一行添加到服务器配置文件 /etc/ssh/sshd_config。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TrustedUserCAKeys &#x2F;etc&#x2F;ssh&#x2F;user_ca.pub</span><br></pre></td></tr></table></figure><p>上面的做法是将 user_ca.pub 加到 /etc/ssh/sshd_config，这会产生全局效果，即服务器的所有账户都会信任 user_ca 签发的所有用户证书。</p><p>另一种做法是将 user_ca.pub 加到服务器某个账户的 ~/.ssh/authorized_keys 文件，只让该账户信任 user_ca 签发的用户证书。具体方法是打开 ~/.ssh/authorized_keys，追加一行，开头是 <code>@cert-authority principals=&quot;...&quot;</code>，然后后面加上 user_ca.pub 的内容，大概是下面这个样子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@cert-authority principals&#x3D;&quot;user&quot; ssh-rsa AAAAB3Nz...XNRM1EX2gQ&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>上面代码中，<code>principals=&quot;user&quot;</code> 指定用户登录的服务器账户名，一般就是 authorized_keys 文件所在的账户。</p><p>重新启动 sshd。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart sshd</span><br><span class="line"># 或者</span><br><span class="line">$ sudo service sshd restart</span><br></pre></td></tr></table></figure><p>至此，SSH 服务器已配置为信任 user_ca 签发的证书。</p><h2 id="九-客户端安装证书">九、客户端安装证书</h2><p>客户端安装用户证书很简单，就是从 CA 将用户证书 user_key-cert.pub 复制到客户端，与用户的密钥 user_key 保存在同一个目录即可。</p><h2 id="十-客户端安装-ca-公钥">十、客户端安装 CA 公钥</h2><p>为了让客户端信任服务器证书，必须将 CA 签发服务器证书的公钥 host_ca.pub，加到客户端的 /etc/ssh/ssh_known_hosts 文件（全局级别）或者 ~/.ssh/known_hosts 文件（用户级别）。</p><p>具体做法是打开 ssh_known_hosts 或 known_hosts 文件，追加一行，开头为 <code>@cert-authority *.example.com</code>，然后将 <code>host_ca.pub</code> 文件的内容（即公钥）粘贴在后面，大概是下面这个样子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@cert-authority *.example.com ssh-rsa AAAAB3Nz...XNRM1EX2gQ&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>上面代码中，<code>*.example.com</code> 是域名的模式匹配，表示只要服务器符合该模式的域名，且签发服务器证书的 CA 匹配后面给出的公钥，就都可以信任。如果没有域名限制，这里可以写成*。如果有多个域名模式，可以使用逗号分隔；如果服务器没有域名，可以用主机名（比如 host1,host2,host3）或者 IP 地址（比如 11.12.13.14,21.22.23.24）。</p><p>然后，就可以使用证书，登录远程服务器了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -i ~&#x2F;.ssh&#x2F;user_key user@host.example.com</span><br></pre></td></tr></table></figure><p>上面命令的 -i 参数用来指定用户的密钥。如果证书与密钥在同一个目录，则连接服务器时将自动使用该证书。</p><h2 id="十一-废除证书">十一、废除证书</h2><p>废除证书的操作，分成用户证书的废除和服务器证书的废除两种。</p><p>服务器证书的废除，用户需要在 known_hosts 文件里面，修改或删除对应的 <code>@cert-authority</code> 命令的那一行。</p><p>用户证书的废除，需要在服务器新建一个 /etc/ssh/revoked_keys 文件，然后在配置文件 sshd_config 添加一行，内容如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RevokedKeys &#x2F;etc&#x2F;ssh&#x2F;revoked_keys</span><br></pre></td></tr></table></figure><p>revoked_keys 文件保存不再信任的用户公钥，由下面的命令生成。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -kf &#x2F;etc&#x2F;ssh&#x2F;revoked_keys -z 1 ~&#x2F;.ssh&#x2F;user1_key.pub</span><br></pre></td></tr></table></figure><p>上面命令中，-z 参数用来指定用户公钥保存在 revoked_keys 文件的哪一行，这个例子是保存在第 1 行。</p><p>如果以后需要废除其他的用户公钥，可以用下面的命令保存在第 2 行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -ukf &#x2F;etc&#x2F;ssh&#x2F;revoked_keys -z 2 ~&#x2F;.ssh&#x2F;user2_key.pub</span><br></pre></td></tr></table></figure><h2 id="十二-参考链接">十二、参考链接</h2><ul><li>SSH Emergency Access, Carl Tashian</li><li>Using OpenSSH Certificate Authentication, Red Hat Enterprise Linux Deployment Guide</li><li>How to SSH Properly, Gus Luxton</li></ul><blockquote><p>本文转载自：「阮一峰的网络日志」，原文：<a href="https://tinyurl.com/yc9xrc7t%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/yc9xrc7t，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SSH 是服务器登录工具，提供密码登录和密钥登录。&lt;/p&gt;
&lt;p&gt;但是，SSH 还有第三种登录方法，那就是证书登录。很多情况下，它是更合理、更安全的登录方法，本文就介绍这种登录方法。&lt;/p&gt;
&lt;h2 id=&quot;一、非证书登录的缺点&quot;&gt;一、非证书登录的缺点&lt;/h2&gt;
&lt;p&gt;密码登录和密钥登录，都有各自的缺点。&lt;/p&gt;
&lt;p&gt;密码登录需要输入服务器密码，这非常麻烦，也不安全，存在被暴力破解的风险。&lt;/p&gt;
&lt;p&gt;密钥登录需要服务器保存用户的公钥，也需要用户保存服务器公钥的指纹。这对于多用户、多服务器的大型机构很不方便，如果有员工离职，需要将他的公钥从每台服务器删除。&lt;/p&gt;
&lt;h2 id=&quot;二、证书登录是什么？&quot;&gt;二、证书登录是什么？&lt;/h2&gt;
&lt;p&gt;证书登录就是为了解决上面的缺点而设计的。它引入了一个证书颁发机构（Certificate1 authority，简称 CA），对信任的服务器颁发服务器证书，对信任的用户颁发用户证书。&lt;/p&gt;
&lt;p&gt;登录时，用户和服务器不需要提前知道彼此的公钥，只需要交换各自的证书，验证是否可信即可。&lt;/p&gt;
&lt;p&gt;证书登录的主要优点有两个：（1）用户和服务器不用交换公钥，这更容易管理，也具有更好的可扩展性。（2）证书可以设置到期时间，而公钥没有到期时间。针对不同的情况，可以设置有效期很短的证书，进一步提高安全性。&lt;/p&gt;
    
    </summary>
    
    
      <category term="SSH" scheme="https://www.hi-linux.com/categories/SSH/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="SSH" scheme="https://www.hi-linux.com/tags/SSH/"/>
    
  </entry>
  
  <entry>
    <title>手把手教会你解决 Chrome 访问非受信证书页面时，提示「您的连接不是私密连接」错误的方法</title>
    <link href="https://www.hi-linux.com/posts/35330.html"/>
    <id>https://www.hi-linux.com/posts/35330.html</id>
    <published>2020-07-06T01:00:00.000Z</published>
    <updated>2020-07-06T06:20:14.078Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在较新版本的 <code>Chrome</code> 中访问一些未受信任的 <code>HTTPS</code> 页面时，会提示类似 <code>NET::ERR_CERT_INVALID</code> 的错误。以往旧版本中，我们可以选择跳过得以继续访问，但是新版本的 <code>Chrome</code> 中并不允许继续，且提示以下错误：</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-1.png" alt=""></p><p>经过很多种尝试后，目前发现只有两种比较有效的方法可以解决。</p><ul><li>方法一</li></ul><p>你可以在 <code>Chrome</code> 启动时加上 <code>--ignore-certificate-errors</code> 和 <code>--ignore-urlfetcher-cert-requests</code> 参数来解决该问题。</p><ol><li>Windows 用户</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&quot; --ignore-certificate-errors</span><br></pre></td></tr></table></figure><ol start="2"><li>Mac 用户</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;Applications&#x2F;Google\ Chrome.app&#x2F;Contents&#x2F;MacOS&#x2F;Google\ Chrome --ignore-certificate-errors --ignore-urlfetcher-cert-requests &amp;&gt; &#x2F;dev&#x2F;null</span><br></pre></td></tr></table></figure><p>然后重新打开 <code>Chrome</code> 并浏览您的网站，便可正常访问。</p><a id="more"></a><ul><li>方法二</li></ul><p>当出现 “您的连接不是私密” 页面时，点击高级后，并直接输入 <code>thisisunsafe</code> 关键字并回车。当你使用的 <code>Chrome</code> 版本不允许通过点击操作设置例外时，这样操作将允许将此次请求设置到安全例外中。</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-4.png" alt=""></p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-6.png" alt=""></p><blockquote><p>注意：在 Chrome 该页面上，直接键盘输入后回车，并不是在地址栏输入。</p></blockquote><p>如果你真的看不明白上面的文字描述，还可以参考下面的操作演示：</p><p><img src="https://www.hi-linux.com/img/linux/chrome-unsafessl.gif" alt=""></p><p><strong>参考文档</strong></p><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="http://www.hackdig.com/03/hack-68770.htm" target="_blank" rel="noopener">http://www.hackdig.com/03/hack-68770.htm</a></p></li><li><p><a href="https://blog.csdn.net/quanqxj/article/details/103076795" target="_blank" rel="noopener">https://blog.csdn.net/quanqxj/article/details/103076795</a></p></li><li><p><a href="https://medium.com/@dblazeski/chrome-bypass-net-err-cert-invalid-for-development-daefae43eb12" target="_blank" rel="noopener">https://medium.com/@dblazeski/chrome-bypass-net-err-cert-invalid-for-development-daefae43eb12</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在较新版本的 &lt;code&gt;Chrome&lt;/code&gt; 中访问一些未受信任的 &lt;code&gt;HTTPS&lt;/code&gt; 页面时，会提示类似 &lt;code&gt;NET::ERR_CERT_INVALID&lt;/code&gt; 的错误。以往旧版本中，我们可以选择跳过得以继续访问，但是新版本的 &lt;code&gt;Chrome&lt;/code&gt; 中并不允许继续，且提示以下错误：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;经过很多种尝试后，目前发现只有两种比较有效的方法可以解决。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方法一&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以在 &lt;code&gt;Chrome&lt;/code&gt; 启动时加上 &lt;code&gt;--ignore-certificate-errors&lt;/code&gt; 和 &lt;code&gt;--ignore-urlfetcher-cert-requests&lt;/code&gt; 参数来解决该问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Windows 用户&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;quot;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&amp;quot; --ignore-certificate-errors&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Mac 用户&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;#x2F;Applications&amp;#x2F;Google\ Chrome.app&amp;#x2F;Contents&amp;#x2F;MacOS&amp;#x2F;Google\ Chrome --ignore-certificate-errors --ignore-urlfetcher-cert-requests &amp;amp;&amp;gt; &amp;#x2F;dev&amp;#x2F;null&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后重新打开 &lt;code&gt;Chrome&lt;/code&gt; 并浏览您的网站，便可正常访问。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Chrome" scheme="https://www.hi-linux.com/categories/Chrome/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Chrome" scheme="https://www.hi-linux.com/tags/Chrome/"/>
    
  </entry>
  
  <entry>
    <title>分享一个解决 sudo 命令找不到环境变量的小技巧</title>
    <link href="https://www.hi-linux.com/posts/30418.html"/>
    <id>https://www.hi-linux.com/posts/30418.html</id>
    <published>2020-06-22T01:00:00.000Z</published>
    <updated>2020-06-22T04:44:37.009Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h3 id="如何解决-sudo-命令找不到环境变量的问题">如何解决 sudo 命令找不到环境变量的问题</h3><p>在通过 <code>sudo</code> 运行命令时，系统会默认重置环境变量为安全的环境变量，也就是说，先前设置的变量都会失效，只有少数配置文件中指定的环境变量能够保存下来。</p><p><code>sudo</code> 的配置文件是 <code>/etc/sudoers</code>，需要 <code>root</code> 权限才能读取，运行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sed &#39;&#x2F;^#&#x2F;d;&#x2F;^$&#x2F;d&#39; &#x2F;etc&#x2F;sudoers</span><br></pre></td></tr></table></figure><p><code>sudo</code> 的配置如下图所示：</p><p><img src="http://ghoulich.xninja.org/wp-content/uploads/sites/2/2017/05/image-01_sudo-conf.png" alt=""></p><p>sudo 配置文件</p><p>请注意：</p><ul><li><p>第 3 行的 <code>Defaults env_reset</code> 表示默认会重置环境变量，因此自定义的变量会在 <code>sudo</code> 环境中失效，也就不会获取正确的变量值。</p></li><li><p>第 4 行至第 8 行的 <code>env_keep</code> 配置项，用于保留部分环境变量不被重置，需要保留的变量就写入双引号之中。</p></li><li><p>第 9 行的 <code>secure_path</code> 配置项，其中包含的路径将被当做 <code>sudo</code> 环境的 <code>PATH</code> 变量使用，如果在 <code>sudo</code> 环境无法找到某些命令，那么可以将这些命令的路径加入该配置项之中。</p></li></ul><a id="more"></a><p>综上所述，<code>sudo</code> 命令找不到环境变量或命令的问题，有三种解决方法：</p><ol><li>sudo -E</li></ol><p>加上 <code>-E</code>  选项后，用户可以在 <code>sudo</code>  执行时保留当前用户已存在的环境变量，不会被 <code>sudo</code> 重置。另外，如果用户对于指定的环境变量没有权限，则会报错。</p><ol start="2"><li>修改 sudo 配置文件</li></ol><p>在内部测试机器中，安全性要求不高，总是需要加上 <code>-E</code> 参数来执行脚本，这个安全设定也不是很方便。因此，可以通过修改 <code>/etc/sudoers</code> 文件的 <code>env_keep</code> 和 <code>secure_path</code> 配置项，来指定 <code>sudo</code> 环境中需要保留的环境变量和路径。</p><p>当然你也可以用更简单粗暴的方式：直接将 <code>Defaults env_reset</code> 改成 <code>Defaults !env_reset</code> 来取消掉对 <code>PATH</code> 变量的重置，然后在 <code>.bashrc</code> 中最后添加 <code>alias sudo='sudo env PATH=$PATH'</code>。这样 <code>sudo</code> 执行命令时所搜寻的路径就是系统的 <code>PATH</code> 变量中的路径，如果你想添加其他变量方法也是类似。</p><ol start="3"><li>手动添加变量</li></ol><p>手动在脚本中设置所需的变量，在执行 <code>sudo</code> 脚本前先将所需要的变量写入到需要执行的脚本开头。</p><h3 id="参考文档">参考文档</h3><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="http://ghoulich.xninja.org/2017/05/09/how-to-find-env-variables-when-exec-sudo-commands/" target="_blank" rel="noopener">http://ghoulich.xninja.org/2017/05/09/how-to-find-env-variables-when-exec-sudo-commands/</a></p></li><li><p><a href="http://www.ibm.com/developerworks/cn/aix/library/au-sudo/index.html" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/aix/library/au-sudo/index.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;如何解决-sudo-命令找不到环境变量的问题&quot;&gt;如何解决 sudo 命令找不到环境变量的问题&lt;/h3&gt;
&lt;p&gt;在通过 &lt;code&gt;sudo&lt;/code&gt; 运行命令时，系统会默认重置环境变量为安全的环境变量，也就是说，先前设置的变量都会失效，只有少数配置文件中指定的环境变量能够保存下来。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo&lt;/code&gt; 的配置文件是 &lt;code&gt;/etc/sudoers&lt;/code&gt;，需要 &lt;code&gt;root&lt;/code&gt; 权限才能读取，运行以下命令：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ sudo sed &amp;#39;&amp;#x2F;^#&amp;#x2F;d;&amp;#x2F;^$&amp;#x2F;d&amp;#39; &amp;#x2F;etc&amp;#x2F;sudoers&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;sudo&lt;/code&gt; 的配置如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ghoulich.xninja.org/wp-content/uploads/sites/2/2017/05/image-01_sudo-conf.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;sudo 配置文件&lt;/p&gt;
&lt;p&gt;请注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;第 3 行的 &lt;code&gt;Defaults env_reset&lt;/code&gt; 表示默认会重置环境变量，因此自定义的变量会在 &lt;code&gt;sudo&lt;/code&gt; 环境中失效，也就不会获取正确的变量值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第 4 行至第 8 行的 &lt;code&gt;env_keep&lt;/code&gt; 配置项，用于保留部分环境变量不被重置，需要保留的变量就写入双引号之中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第 9 行的 &lt;code&gt;secure_path&lt;/code&gt; 配置项，其中包含的路径将被当做 &lt;code&gt;sudo&lt;/code&gt; 环境的 &lt;code&gt;PATH&lt;/code&gt; 变量使用，如果在 &lt;code&gt;sudo&lt;/code&gt; 环境无法找到某些命令，那么可以将这些命令的路径加入该配置项之中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="sudo" scheme="https://www.hi-linux.com/tags/sudo/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你解决 Chrome、IE 等浏览器无法正常访问 Kubernetes Dashboard 的问题</title>
    <link href="https://www.hi-linux.com/posts/13787.html"/>
    <id>https://www.hi-linux.com/posts/13787.html</id>
    <published>2020-06-13T01:00:00.000Z</published>
    <updated>2020-06-13T12:06:20.411Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>一般情况下，正常安装部署完 <code>Kubernetes Dashboard</code> 后，通过大多数主流浏览器（<code>Chrome</code>、<code>IE</code>、<code>Safari</code>）是不能正常访问的，唯有 <code>Firefox</code> 才能解忧。</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-1.png" alt=""></p><p>使用火狐浏览器打开后，会有一个安全风险提示。</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-2.png" alt=""></p><p>接受安全风险后，还是可以正常访问的。</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-3.png" alt=""></p><p>该问题是由于部署 <code>Kubernetes Dashboard</code> 时默认生成的证书有问题导致的。在这篇文章中，我们就来教你如何快速优雅的解决它。</p><p>既然是该书问题，那解决办法当然是生成一个新的有效证书替换掉过期的即可。</p><a id="more"></a><h3 id="通过生成新的证书永久解决">通过生成新的证书永久解决</h3><p>下面是生成 <code>Kubernetes Dashboard</code> 域名证书的几种常用方法，你可以根据自身实际情况选用任何一种就行。</p><ul><li><p>通过 <code>https://freessl.cn</code> 网站，在线生成免费 1 年的证书</p></li><li><p>通过 <code>Let’s Encrypt</code> 生成 <code>90</code> 天免费证书</p></li><li><p>通过 <code>Cert-Manager</code> 服务来生成和管理证书</p></li><li><p>通过 <code>IP</code> 直接自签一个证书</p></li></ul><p>几种方式的原理都是一样的，我们这里使用自签证书的方法来进行演示。</p><ol><li>通过自签方式生成证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个用于自签证书的目录</span><br><span class="line">$ mkdir kubernetes-dashboard-key &amp;&amp; cd kubernetes-dashboard-key</span><br><span class="line"></span><br><span class="line"># 生成证书请求的key</span><br><span class="line">$ openssl genrsa -out dashboard.key 2048</span><br><span class="line">Generating RSA private key, 2048 bit long modulus</span><br><span class="line">....................................+++</span><br><span class="line">.......................................................................+++</span><br><span class="line"></span><br><span class="line"># 生成证书请求</span><br><span class="line">$ openssl req -days 3650 -new -out dashboard.csr -key dashboard.key -subj &#39;&#x2F;CN&#x3D;192.168.100.100&#39;</span><br><span class="line"></span><br><span class="line"># 生成自签证书</span><br><span class="line">$ openssl x509 -req -in dashboard.csr -signkey dashboard.key -out dashboard.crt</span><br><span class="line">Signature ok</span><br><span class="line">subject&#x3D;&#x2F;CN&#x3D;192.168.100.100</span><br><span class="line">Getting Private key</span><br></pre></td></tr></table></figure><ol start="2"><li>使用新证书来创建一个与 Kubernetes Dashboard 部署文件中同名的 Secret</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 查找 Kubernetes 中原有证书的 Secret</span><br><span class="line">$ kubectl get secret kubernetes-dashboard-certs -n kubernetes-dashboard</span><br><span class="line">NAME                         TYPE     DATA   AGE</span><br><span class="line">kubernetes-dashboard-certs   Opaque   0      65d</span><br><span class="line"></span><br><span class="line"># 查看 Kubernetes 中原有的证书 Secret 的内容 （此步骤非必须）</span><br><span class="line">$ kubectl get  secret kubernetes-dashboard-certs -n kubernetes-dashboard -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubectl.kubernetes.io&#x2F;last-applied-configuration: |</span><br><span class="line">      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Secret&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;k8s-app&quot;:&quot;kubernetes-dashboard&quot;&#125;,&quot;name&quot;:&quot;kubernetes-dashboard-certs&quot;,&quot;namespace&quot;:&quot;kubernetes-dashboard&quot;&#125;,&quot;type&quot;:&quot;Opaque&quot;&#125;</span><br><span class="line">  creationTimestamp: &quot;2020-03-24T17:42:42Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-certs</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">  resourceVersion: &quot;20913&quot;</span><br><span class="line">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kubernetes-dashboard&#x2F;secrets&#x2F;kubernetes-dashboard-certs</span><br><span class="line">  uid: 329888d4-aa59-4c32-84d8-b88ef2ebfa32</span><br><span class="line">type: Opaque</span><br><span class="line"></span><br><span class="line"># 删除 Kubernetes 中原有的证书 Secret</span><br><span class="line">$ kubectl delete secret kubernetes-dashboard-certs -n kubernetes-dashboard</span><br><span class="line">secret &quot;kubernetes-dashboard-certs&quot; deleted</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 使用新证书创建一个同名的 Secret</span><br><span class="line">$ kubectl create secret generic kubernetes-dashboard-certs --from-file&#x3D;dashboard.key --from-file&#x3D;dashboard.crt -n kubernetes-dashboard</span><br><span class="line">secret&#x2F;kubernetes-dashboard-certs created</span><br></pre></td></tr></table></figure><blockquote><p>注意：新版的 Dashboard 的 namespace 已经是 kubernetes-dashboard 。</p></blockquote><ol start="3"><li>查找当前正在运行的 Kubernetes-Dashboard 的 Pod</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -n kubernetes-dashboard</span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-7b8b58dc8b-nw7l7   1&#x2F;1     Running   3          64d</span><br><span class="line">kubernetes-dashboard-5f5f847d57-88ssx        1&#x2F;1     Running   3          64d</span><br></pre></td></tr></table></figure><ol start="4"><li>删除现有的 Kubernetes-Dashboard 的 Pod</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete po kubernetes-dashboard-5f5f847d57-88ssx -n kubernetes-dashboard</span><br><span class="line">pod &quot;kubernetes-dashboard-5f5f847d57-88ssx&quot; deleted</span><br><span class="line"></span><br><span class="line">$ kubectl delete po dashboard-metrics-scraper-7b8b58dc8b-nw7l7 -n kubernetes-dashboard</span><br><span class="line">pod &quot;dashboard-metrics-scraper-7b8b58dc8b-nw7l7&quot; deleted</span><br></pre></td></tr></table></figure><p>如果 <code>Pod</code> 比较多的时候，你还可以使用以下这条命令批量删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -n kubernetes-dashboard | grep -v NAME | awk &#39;&#123;print &quot;kubectl delete po &quot; $1 &quot; -n kubernetes-dashboard&quot;&#125;&#39; | sh</span><br></pre></td></tr></table></figure><p>删除完成后，新的 <code>Kubernetes-Dashboard Pod</code> 会自动启动起来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -n kubernetes-dashboard</span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-7b8b58dc8b-w9zzh   1&#x2F;1     Running   0          35s</span><br><span class="line">kubernetes-dashboard-5f5f847d57-4q76w        1&#x2F;1     Running   0          53s</span><br></pre></td></tr></table></figure><p>这时，再次刷新 <code>Chrome</code> 浏览器的 <code>Dashboard</code> 页面后，先点高级：</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-4.png" alt=""></p><p>然后点击继续前往，页面就可以正常显示了。</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-5.png" alt=""></p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-6.png" alt=""></p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-7.png" alt=""></p><h3 id="临时解决方案">临时解决方案</h3><p>如果你只是想临时使用 <code>Chrome</code> 访问下 <code>Kubernetes-Dashboard</code> 或者你没有权限更换 <code>Kubernetes-Dashboard</code> 的证书，你也可以在 <code>Chrome</code> 启动时加上 <code>--ignore-certificate-errors</code> 和 <code>--ignore-urlfetcher-cert-requests</code> 参数来解决该问题。</p><ol><li>Windows 用户</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&quot; --ignore-certificate-errors</span><br></pre></td></tr></table></figure><ol start="2"><li>Mac 用户</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;Applications&#x2F;Google\ Chrome.app&#x2F;Contents&#x2F;MacOS&#x2F;Google\ Chrome --ignore-certificate-errors --ignore-urlfetcher-cert-requests &amp;&gt; &#x2F;dev&#x2F;null</span><br></pre></td></tr></table></figure><h1 id="参考文档">参考文档</h1><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://blog.51cto.com/10616534/2430512" target="_blank" rel="noopener">https://blog.51cto.com/10616534/2430512</a></li><li><a href="https://www.jianshu.com/p/8021285cc37d" target="_blank" rel="noopener">https://www.jianshu.com/p/8021285cc37d</a></li><li><a href="https://stackoverflow.com/questions/26388405/chrome-disable-ssl-checking-for-sites" target="_blank" rel="noopener">https://stackoverflow.com/questions/26388405/chrome-disable-ssl-checking-for-sites</a></li><li><a href="https://my.oschina.net/u/4407987/blog/3319315" target="_blank" rel="noopener">https://my.oschina.net/u/4407987/blog/3319315</a></li><li><a href="https://zhangguanzhang.github.io/2019/02/12/dashboard/" target="_blank" rel="noopener">https://zhangguanzhang.github.io/2019/02/12/dashboard/</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般情况下，正常安装部署完 &lt;code&gt;Kubernetes Dashboard&lt;/code&gt; 后，通过大多数主流浏览器（&lt;code&gt;Chrome&lt;/code&gt;、&lt;code&gt;IE&lt;/code&gt;、&lt;code&gt;Safari&lt;/code&gt;）是不能正常访问的，唯有 &lt;code&gt;Firefox&lt;/code&gt; 才能解忧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;使用火狐浏览器打开后，会有一个安全风险提示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;接受安全风险后，还是可以正常访问的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/Kubernetes-Dashboard-3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;该问题是由于部署 &lt;code&gt;Kubernetes Dashboard&lt;/code&gt; 时默认生成的证书有问题导致的。在这篇文章中，我们就来教你如何快速优雅的解决它。&lt;/p&gt;
&lt;p&gt;既然是该书问题，那解决办法当然是生成一个新的有效证书替换掉过期的即可。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你定制一个专属的个性化终端登陆界面</title>
    <link href="https://www.hi-linux.com/posts/51306.html"/>
    <id>https://www.hi-linux.com/posts/51306.html</id>
    <published>2020-05-28T01:00:00.000Z</published>
    <updated>2020-05-28T07:30:10.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在我们登入 macOS 的终端后，终端往往会弹出一段欢迎信息，显示登录主机、主机供应商提示等信息。但每次看到的都是同样的信息难免有些厌倦。</p><p>通过修改 Motd 文件，我们可以给 SSH 加点料，让它更加好看和有趣。</p><p>默认提示</p><p><img src="https://cdn.sspai.com/2020/03/04/119ed2f44f8c779e52e5d0b61f0572b0.png" alt=""></p><h2 id="原理">原理</h2><blockquote><p>在类 Unix 系统中，/etc/motd 是一个包含「今日消息（Message of the day）」的文件。比起电子邮件，使用 Motd 给所有用户发送消息显得更有效率。其它操作系统中也可能有这一功能，比如 Multics 中的 Motd 信息分段。/etc/motd 的内容会在用户成功登录后由 Unix 登录命令显示，整个过程发生在 Shell 登录之前。较新的类 Unix 系统可以生成动态消息。Ｍotd 也被运用在其它领域，比如 IRC 服务器、半条命系列游戏等。</p><p>来源：维基百科</p></blockquote><p>Linux 系统通过 /etc/issue、/etc/issue.net、/etc/motd 以及 /run/motd.dynamic 来显示本地或者是远程登录后的提示信息，这个提示信息通常用于向用户展示系统版本、硬件参数等信息。其中 /etc/issue、/etc/issue.net 通常在未登录终端前显示，/etc/motd、/run/motd.dynamic 则是在成功登录终端后显示。</p><p>此外还有 /etc/profile 与 /etc/profile.d/，在登录后会运行其中的脚本。</p><a id="more"></a><h2 id="哪里-get-到好康的提示信息">哪里 Get 到好康的提示信息？</h2><h3 id="asciiworld">ASCiiWorld</h3><p>在 AsciiWorld 中提供了现成的图案，左侧可按照分类来搜寻自己需要的字符画。不过 ASCiiWorld 历史悠久，上面的字符画稍显陈旧，不太符合我的审美，哈哈哈。</p><p><img src="https://cdn.sspai.com/2020/03/04/57a737ad43d131f259820d9b410d886b.png" alt=""></p><p>ASCiiWorld</p><p>网站链接：<a href="http://www.asciiworld.com/" target="_blank" rel="noopener">http://www.asciiworld.com/</a></p><h3 id="通过图片转换">通过图片转换</h3><p>V 友 Kokodayo 基于 Img2Motd 开发了网页版的 图片转 Linux Shell 彩色文本。试了一下还挺好玩的亚子，不过对图片和终端的要求有点高。图片的长宽尽量控制在 100 * 100 以内，同时尽量避免使用过于复杂的图案。</p><p><img src="https://cdn.sspai.com/2020/03/04/7eb2b4325eed153625ce2cb027fae6b8.png" alt=""></p><p>Bakaya-Motd</p><p>网站链接：<a href="https://motd.bakaya.ro/" target="_blank" rel="noopener">https://motd.bakaya.ro/</a></p><h3 id="文字特效">文字特效</h3><p>Patorjk 可以根据自己输入的文字，并选择对应的字体来生成字符画，字体种类比较丰富（老板：每天给我换 150 种，但遗憾的是生成语言仅支持英文，如果有中文生成需要的，可以考虑使用 ASCii 字符画生成器来实现。</p><p><img src="https://cdn.sspai.com/2020/03/04/aac68b477cef72eea48c0534e2b954b9.png" alt=""></p><p>Patorjk</p><p>网站链接：<a href="http://patorjk.com/software/taag/" target="_blank" rel="noopener">http://patorjk.com/software/taag/</a></p><h3 id="neofetch">Neofetch</h3><p>当然，除了静态的字符画，我们还可以选择使用一些工具来动态显示欢迎信息。</p><p>Neofetch 是一款用于显示系统信息的脚本，同类的工具还有 ScreenFetch 和 Linux_Logo。Neofetch 除了可以显示 ASCii 字符画，还可以通过 w3m-img 等运行库在终端中显示全彩图片（不过我还没折腾出来，没搞懂是终端的原因还是其它什么原因。</p><p><img src="https://cdn.sspai.com/2020/03/04/083f03f3d42afafec9aace46d31351b3.png" alt=""></p><p>Neofetch</p><blockquote><p>项目地址：<a href="https://github.com/dylanaraps/neofetch/" target="_blank" rel="noopener">https://github.com/dylanaraps/neofetch/</a></p></blockquote><ol><li>安装方法</li></ol><ul><li>Debian / Ubuntu</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ apt update &amp;&amp; apt upgrade -y</span><br><span class="line">$ apt install neofetch -y</span><br></pre></td></tr></table></figure><ul><li>CentOS / Fedora / RHEL</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ yum update &amp;&amp; yum upgrade -y</span><br><span class="line">$ yum install dnf-plugins-core -y</span><br><span class="line">$ dnf copr enable konimex&#x2F;neofetch</span><br><span class="line">$ dnf install neofetch</span><br></pre></td></tr></table></figure><ul><li>macOS</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install neofetch</span><br></pre></td></tr></table></figure><p>更多 Neofetch 的玩法可以参考 Neofetch-Wiki，比如说通过 w3m-img 展示全彩图片、显示桌面截图、修改显示信息的类型、显示主机的扩展信息等等，在此不做过多阐述。</p><ol start="2"><li>更改方法</li></ol><ul><li><p>静态 Motd：如果是从图片转换的，那么将新 Motd 更名为 motd 上传至 /etc 目录中，重新登录终端即可生效。</p></li><li><p>动态 Motd：在 Ubuntu 16.04 （其它系统同理）后，启用了动态 Motd，此时我们需要将生成的 motd 文件写入至 /etc/update-motd.d/30-banner 中的对应位置。</p></li><li><p>Neofetch：在 /etc/profile.d/ 创建一个名为 <a href="http://neofetch.sh" target="_blank" rel="noopener">neofetch.sh</a> 的脚本，填入以下内容，保存后重新登入 SSH 即可生效。</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#&#x2F;bin&#x2F;sh</span><br><span class="line">neofetch</span><br></pre></td></tr></table></figure><p>最终效果</p><p><img src="https://cdn.sspai.com/2020/03/04/dac33bf6a775a51c33826f95d30f153e.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>Patorjk</p><p><img src="https://cdn.sspai.com/2020/03/04/ae6a16a19a582d1e3cedfe06b0afff0b.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>Neofetch</p><p><img src="https://cdn.sspai.com/2020/03/04/ae6a16a19a582d1e3cedfe06b0afff0b.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>Neofetch in macOS</p><h2 id="结语">结语</h2><p>有人也许会认为修改 Motd 纯属是「徒增功耗、方向错了」，但我个人觉得，除了能够让你的终端更加有趣，还能够在你登录终端前显示主机的重要信息，避免在生产环境中「rm -rf /*」。</p><p>如果你有更多有趣、新奇的玩法，不妨在讨论区中和大家一起分享。喜欢这篇文章的话，不要忘记点赞、分享和关注哦。</p><h3 id="参考链接">参考链接</h3><ul><li><p>Linux 公社：bash的登录与欢迎信息: /etc/issue,/etc/motd</p></li><li><p>旷世的忧伤：Linux 服务器维护简易指南</p></li><li><p>Kokodayo：在 Linux Shell 的登录欢迎语里……放“图片”！</p></li></ul><blockquote><p>本文转载自：「鸟之言语」，原文：<a href="https://tinyurl.com/qqczh4n%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/qqczh4n，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在我们登入 macOS 的终端后，终端往往会弹出一段欢迎信息，显示登录主机、主机供应商提示等信息。但每次看到的都是同样的信息难免有些厌倦。&lt;/p&gt;
&lt;p&gt;通过修改 Motd 文件，我们可以给 SSH 加点料，让它更加好看和有趣。&lt;/p&gt;
&lt;p&gt;默认提示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.sspai.com/2020/03/04/119ed2f44f8c779e52e5d0b61f0572b0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在类 Unix 系统中，/etc/motd 是一个包含「今日消息（Message of the day）」的文件。比起电子邮件，使用 Motd 给所有用户发送消息显得更有效率。其它操作系统中也可能有这一功能，比如 Multics 中的 Motd 信息分段。/etc/motd 的内容会在用户成功登录后由 Unix 登录命令显示，整个过程发生在 Shell 登录之前。较新的类 Unix 系统可以生成动态消息。Ｍotd 也被运用在其它领域，比如 IRC 服务器、半条命系列游戏等。&lt;/p&gt;
&lt;p&gt;来源：维基百科&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Linux 系统通过 /etc/issue、/etc/issue.net、/etc/motd 以及 /run/motd.dynamic 来显示本地或者是远程登录后的提示信息，这个提示信息通常用于向用户展示系统版本、硬件参数等信息。其中 /etc/issue、/etc/issue.net 通常在未登录终端前显示，/etc/motd、/run/motd.dynamic 则是在成功登录终端后显示。&lt;/p&gt;
&lt;p&gt;此外还有 /etc/profile 与 /etc/profile.d/，在登录后会运行其中的脚本。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款可在线访问任意 Pod 的神器 Podtnl（无需暴露服务）</title>
    <link href="https://www.hi-linux.com/posts/57908.html"/>
    <id>https://www.hi-linux.com/posts/57908.html</id>
    <published>2020-05-26T01:00:00.000Z</published>
    <updated>2020-05-26T05:49:20.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Podtnl</code> 是一个不通过暴露 <code>Kubernetes Service</code> 服务也可以在线访问 <code>Pod</code> 的一个功能强大的 <code>CLI</code> 工具。</p><blockquote><p>项目地址：<a href="https://github.com/narendranathreddythota/podtnl" target="_blank" rel="noopener">https://github.com/narendranathreddythota/podtnl</a></p></blockquote><p><code>Podtnl</code> 使用了两个主要的概念：端口转发和隧道。<code>Podtnl</code> 使用非常简单，特别是在应用开发阶段非常有用，完全不用担心有没有创建 <code>Ingress</code>、<code>LoadBalancer</code> 等资源。</p><p><img src="https://www.hi-linux.com/img/linux/tunnel.png" alt=""></p><h3 id="podtnl-安装">Podtnl 安装</h3><p>直接下载 <code>GitHub</code> 仓库上 <code>Release</code> 的二进制文件，开箱即用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;narendranathreddythota&#x2F;podtnl&#x2F;releases&#x2F;download&#x2F;1.0&#x2F;podtnl</span><br><span class="line">$ chmod +x podtnl</span><br><span class="line">$ mv podtnl &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p>如果你使用 <code>macOS</code>，你还可以使用 <code>Homebrew</code> 进行安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ brew tap narendranathreddythota&#x2F;podtnl</span><br><span class="line">$ brew install podtnl</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="podtnl-使用">Podtnl 使用</h3><p>要使用 <code>Podtnl</code> ，你需要先提供一个隧道。目前 <code>Podtnl</code> 只支持 <code>Ngrok</code> 作为隧道提供商，所以需要提前安装配置好 <code>Ngrok</code>。你可以通过地址 <code>https://dashboard.ngrok.com/get-started/setup</code> 进行配置。</p><p>当 <code>Podtnl</code> 和 <code>Ngrok</code> 都配置好过后，即可使用 <code>Podtnl</code>。 <code>Podtnl</code> 可以使用的一些命令如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Available Flage</span><br><span class="line">  version        : Output Podtnl Version</span><br><span class="line">  provider       : Input Tunnel Provider</span><br><span class="line">  providerPath   : Input Tunnel Provider Path</span><br><span class="line">  podname        : Input Pod Name</span><br><span class="line">  protocol       : Input Type of Protocol</span><br><span class="line">  namespace      : Input Namespace</span><br><span class="line">  podport        : Input Pod Port</span><br><span class="line">  auth           : Need Authentication ? Applicable for HTTP</span><br></pre></td></tr></table></figure><p>比如：当前 <code>Kubernetes</code> 集群中在 <code>kube-ops</code> 命名空间下面有如下一个 <code>Pod</code>，容器暴露 <code>8080</code> 端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-ops</span><br><span class="line">NAME                                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">devops-name-devops-demo-7cf5fcc5c6-j76h5         1&#x2F;1     Running   0          3d14h</span><br></pre></td></tr></table></figure><p>我们就可以按照如下所示的命令来直接暴露该 <code>Pod</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ podtnl -provider ngrok -podname devops-name-devops-demo-7cf5fcc5c6-j76h5 -podport 8080 -namespace kube-ops</span><br><span class="line">[INFO] ...Tunnel provider ngrok</span><br><span class="line">[INFO] NGROK is Ready</span><br><span class="line">[INFO] Username: hBIHNsBB3G3OFQ8vj7lm8WXC17EybR59</span><br><span class="line">[INFO] Password: fRJrZs3mtvTSWLKpFa2VcxVjCw5RexbVHnxirWqPqL44K47Q4VMetM4McwFZBJFm</span><br><span class="line">Forwarding from 127.0.0.1:8080 -&gt; 8080</span><br><span class="line">Forwarding from [::1]:8080 -&gt; 8080</span><br><span class="line">[INFO] mytunnel is created and Live: -&gt; https:&#x2F;&#x2F;c13f78fe.ngrok.io</span><br></pre></td></tr></table></figure><p>然后我们可以使用上面生成的地址 <code>https://c13f78fe.ngrok.io</code> 来直接访问该 <code>Pod</code>。默认会使用 <code>Basic Auth</code> 认证方式，使用上面生成的 <code>Username</code> 和 <code>Password</code> 即可认证。</p><p>如果 <code>Pod</code> 是 <code>TCP</code> 服务需要直接暴露，则需添加 <code>protocol</code> 参数指定即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ podtnl -provider ngrok -podname orderer1-7cb4b7565-nv95k -podport 7050 -protocol tcp</span><br><span class="line"></span><br><span class="line">Expected Output:</span><br><span class="line">[INFO] ...Tunnel provider ngrok</span><br><span class="line">[INFO] NGROK is Ready</span><br><span class="line">[INFO] mytunnel is created and Live: -&gt; tcp:&#x2F;&#x2F;0.tcp.ngrok.io:10467</span><br><span class="line"></span><br><span class="line">^C[WARN] Shutting down all open tunnels..</span><br><span class="line">[DBUG] Closing tunnel in tcp:&#x2F;&#x2F;0.tcp.ngrok.io:10467</span><br></pre></td></tr></table></figure><p>更多好用的玩法，你可以去 「<a href="https://github.com/narendranathreddythota/podtnl" target="_blank" rel="noopener">Podtnl 官网</a>」进行探索哟！</p><blockquote><p>本文转载自：「k8s 技术圈」，原文：<a href="https://tinyurl.com/y6urwkgt%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/y6urwkgt，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Podtnl&lt;/code&gt; 是一个不通过暴露 &lt;code&gt;Kubernetes Service&lt;/code&gt; 服务也可以在线访问 &lt;code&gt;Pod&lt;/code&gt; 的一个功能强大的 &lt;code&gt;CLI&lt;/code&gt; 工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/narendranathreddythota/podtnl&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/narendranathreddythota/podtnl&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Podtnl&lt;/code&gt; 使用了两个主要的概念：端口转发和隧道。&lt;code&gt;Podtnl&lt;/code&gt; 使用非常简单，特别是在应用开发阶段非常有用，完全不用担心有没有创建 &lt;code&gt;Ingress&lt;/code&gt;、&lt;code&gt;LoadBalancer&lt;/code&gt; 等资源。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/tunnel.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Podtnl-安装&quot;&gt;Podtnl 安装&lt;/h3&gt;
&lt;p&gt;直接下载 &lt;code&gt;GitHub&lt;/code&gt; 仓库上 &lt;code&gt;Release&lt;/code&gt; 的二进制文件，开箱即用。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ wget https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;narendranathreddythota&amp;#x2F;podtnl&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;1.0&amp;#x2F;podtnl&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ chmod +x podtnl&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ mv podtnl &amp;#x2F;usr&amp;#x2F;local&amp;#x2F;bin&amp;#x2F;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如果你使用 &lt;code&gt;macOS&lt;/code&gt;，你还可以使用 &lt;code&gt;Homebrew&lt;/code&gt; 进行安装。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ brew tap narendranathreddythota&amp;#x2F;podtnl&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ brew install podtnl&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>内网穿透神器 ZeroTier 使用教程</title>
    <link href="https://www.hi-linux.com/posts/33914.html"/>
    <id>https://www.hi-linux.com/posts/33914.html</id>
    <published>2020-05-25T01:00:00.000Z</published>
    <updated>2020-05-25T09:18:23.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>随着可用的公网 IPv4 地址越来越少，现在的运营商基本不给家用宽带分配公网 IP 了。如果你想通过外网访问到内网的资源，目前只能采用内网穿透的软件来实现。而一般常规的内网穿透软件都需要一个公网 IP 才能正常工作，比如：「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247485670&amp;idx=1&amp;sn=df62f2df93f112a7bc0b8d7e843bbc16&amp;chksm=eac529cfddb2a0d9b0fb22324f3eaf5cffeb8e0a56d16efb87ad97d3cca6479e96e12c68eb88&amp;token=211998253&amp;lang=zh_CN#rd" target="_blank" rel="noopener">FRP</a>」 或 「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247483754&amp;idx=1&amp;sn=c701d750ea87421446ec2f3202beab33&amp;chksm=eac52043ddb2a955c282f8337d6c0fc63034f3f9e378ae1b1fcc0b53be1f20c8b4f55c159c94&amp;token=211998253&amp;lang=zh_CN#rd" target="_blank" rel="noopener">Ngork</a>」 等。这样你就不得不租用一个拥有公网 IP 的服务器才能实现上述需求，显然增加了不少使用成本。</p><p>做为一个<code>月薪 3000</code> 的屌丝怎么可能折腾得起呢？今天，我们就来介绍一款不需要公网 IP 实现内网穿透的工具 <code>ZeroTier</code> 。<code>ZeroTier</code> 是一个专门用来建立点对点虚拟专用网（<code>P2P VPN</code>）的工具，它提供在线管理界面和全平台的客户端，不需要复杂设置，只要安装客户端并加入到自己创建的网络即可。</p><blockquote><ol><li><p>官方网站地址：<a href="https://www.zerotier.com" target="_blank" rel="noopener">https://www.zerotier.com</a></p></li><li><p>项目地址：<a href="https://github.com/zerotier" target="_blank" rel="noopener">https://github.com/zerotier</a></p></li></ol></blockquote><a id="more"></a><h2 id="zerotier-原理">ZeroTier 原理</h2><p><code>ZeroTier</code> 这一类 <code>P2P VPN</code> 是在互联网的基础上将自己的所有设备组成一个私有的网络，可以理解为互联网连接的局域网。最常见的场景就是在公司可以用手机直接访问家里的 <code>NAS</code>，而且是点对点直连，数据传输并不经由第三方服务器中转。</p><p><code>Zerotier</code> 在多设备之间建立了一个 <code>Peer to Peer VPN（P2PVPN）</code> 连接，如：在笔记本电脑、台式机、嵌入式设备、云资源和应用。这些设备只需要通过 <code>ZeroTier One</code> ( ZeroTier 的客户端) 在不同设备之间建立直接连接，即使它们位于 <code>NAT</code> 之后。连接到虚拟 <code>LAN</code> 的任何计算机和设备通常通过 <code>NAT</code> 或路由器设备与 <code>Internet</code> 连接，<code>ZeroTier One</code> 使用 <code>STUN</code> 和隧道来建立 <code>NAT</code> 后设备之间的 <code>VPN</code> 直连。</p><p>简单一点说，<code>Zerotier</code> 就是通过 <code>P2P</code> 等方式实现形如交换机或路由器上 <code>LAN</code> 设备的内网互联。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/zerotier-network.png" alt=""></p><p><code>ZeroTier</code> 官方搭建了一个行星根服务器叫做 <code>地球 Earth</code>，这个行星根服务器是唯一且是免费的，它记录了所有的路径信息，一般情况下大家都直接用的这个。</p><p>行星根服务器 R 记录了所有的路径信息，设备 A 能通过 <code>ZeroTier</code> 唯一地址标识找到需要连接的设备 B。这个过程如下：</p><ol><li><p>A 想要将数据包发送到 B，但由于它没有直接路径，因此将其向上发送到 R。</p></li><li><p>如果 R 有直接链接到 B，它会转发数据包给 B。否则它会继续向上游发送数据包，直到达到行星根 (planet)。行星根知道所有节点，所以如果 B 在线，最终数据包将到达 B。</p></li><li><p>R 还向 A 发送一个消息，包含有关它如何到达 B 的提示。同时，将消息发给 B，通知 B 它如何到达 A。</p></li><li><p>A 和 B 获取它们的消息并尝试相互发送测试消息，可能会对 NAT 或状态防火墙进行穿透。如果这样可以建立直接链路，则不再需要中继。</p></li><li><p>如果无法建立直接路径，则通信可以继续中继 (速度慢)</p></li></ol><p>除此之外还有 12 个遍布全球的根服务器，这些是收费的服务。由于 Earth 在国外，如果使用免费套餐，连接时的延迟可能会很高。不过 <code>ZeroTier</code> 能自己创建根服务器 <code>月球 Moons</code>，这样我们就能在大局域网中得到更好的体验了。</p><h2 id="注册与客户端安装">注册与客户端安装</h2><h3 id="注册帐号">注册帐号</h3><p>登录官网注册即可，填写你的邮箱和密码。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/QQ20190729-220707@2x.png" alt=""></p><p>注册之后是这样的，保持默认就好。每个免费套餐可以享受 100 台设备的内网互联，一般够用了。</p><p><img src="https://www.hi-linux.com/img/linux/ZeroTier3.jpeg" alt=""></p><h3 id="网络配置">网络配置</h3><p>注册好之后，我们来建立一个 Network 并分配内网网段。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/QQ20190729-222030@2x.png" alt=""></p><p>创建一个新的网络之后，我们会得到一个 <code>Network ID</code>。这是客户端连接到行星服务器的唯一识别码，需要牢记。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/QQ20190729-222125@2x.png" alt=""></p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/QQ20190730-185605@2x.png" alt=""></p><h3 id="客户端配置">客户端配置</h3><p><code>ZeroTier</code> 支持 <code>Windows</code>、<code>macOS</code>、<code>Linux</code> 三大桌面平台，<code>iOS</code>、<code>Android</code> 两大移动平台，<code>QNAP（威连通）</code>、<code>Synology（群晖）</code>、<code>Western Digital MyCloud NAS（西部数据）</code> 三个 <code>NAS</code> 平台，还支持 <code>OpenWrt/LEDE</code> 开源路由器项目。</p><blockquote><p>下载地址：<a href="https://www.zerotier.com/download/" target="_blank" rel="noopener">https://www.zerotier.com/download/</a></p></blockquote><p>这里我们以 <code>iOS</code> 和 <code>Mac</code> 设备为例介绍一下客户端如何与 <code>Planet</code> 相连接并分配到内网地址。</p><p><code>iOS</code> 下载好 <code>ZeroTier One</code> 之后，填入刚刚的 <code>Network ID</code>，配置好 <code>VPN</code> 后就会启动连接。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/IMG_9003.png" alt=""></p><p><code>macOS</code> 使用方法同理，并且可以直接使用命令行进行操作。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/QQ20190730-194142@2x.png" alt=""></p><p>直接使用命令行进行操作的方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">$ zerotier-one -d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取地址和服务状态</span></span><br><span class="line">$ zerotier-cli status</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入、离开、列出网络</span></span><br><span class="line">$ zerotier-cli join <span class="comment"># Network ID</span></span><br><span class="line">$ zerotier-cli leave <span class="comment"># Network ID</span></span><br><span class="line">$ zerotier-cli listnetworks</span><br></pre></td></tr></table></figure><p>这时会根据 <code>MAC</code> 地址分配给设备一个唯一认证字符串 <code>Node ID</code>，可用来在 <code>Web</code> 配置界面保留该设备不被删除以及帮助我们区分设备。</p><h3 id="认证设备和组网">认证设备和组网</h3><p>回到一开始注册的网页，会发现设备列表当中新增了两台设备，在前面的方框打钩即可。根据 <code>Node ID</code> 判断设备的类型，牢记设备被分配的 <code>IP</code> 。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/QQ20190730-183819@2x.png" alt=""></p><h3 id="测试设备间互访">测试设备间互访</h3><p>为了测试不同网络访问：<code>MBP</code> 连接电信网络，<code>iPhone</code> 连接移动 <code>4G</code> 网络。</p><p><img src="https://www.newlearner.site/%E2%80%9Cwp-content/uploads%E2%80%9D/2019/07/IMG_9006-e1564489212233.png" alt=""></p><p>从图中我们可以看到已经成功连接上了 <code>Mac</code> 的 <code>SSH</code>。由于免费的根服务器在国外，可能访问速度不太稳定。</p><blockquote><p>除非你有两台路由器，一台放在家里，另一台放在公司等地，并且有大量设备连接于这两台路由器且需要内网穿透，否则不要在路由器上面部署 <code>ZeroTier</code>，仅使用单设备客户端即可。并且为了连接的稳定性，强烈建议自己部署 <code>Moon</code> 节点。</p></blockquote><h2 id="延伸阅读">延伸阅读</h2><p>上面的示例中，我们只介绍了 <code>ZeroTier</code> 的基本使用。<code>ZeroTier</code> 的功能远不止这些，如果你非常感兴趣还可以参考下面这些文档：</p><blockquote><ol><li>Openwrt 使用 ZeroTier 实现内网穿透</li></ol><p>链接：<a href="https://qingsay.com/zerotier-openwrt.html" target="_blank" rel="noopener">https://qingsay.com/zerotier-openwrt.html</a></p><ol start="2"><li>无公网 IP 搞定群晖 + ZEROTIER ONE 实现内网穿透</li></ol><p>链接 1：<a href="https://www.hao4k.cn/thread-29377-1-1.html" target="_blank" rel="noopener">https://www.hao4k.cn/thread-29377-1-1.html</a></p><p>链接 2：<a href="https://zhuanlan.zhihu.com/p/73558450" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73558450</a></p><ol start="3"><li>使用 ZeroTier 建立 IPv6 隧道</li></ol><p>链接：<a href="https://moe.best/tutorial/zerotier-ipv6.html" target="_blank" rel="noopener">https://moe.best/tutorial/zerotier-ipv6.html</a></p><ol start="4"><li>在容器中不依赖 TUN/TAP 使用 ZeroTier 实现 P2P VPN</li></ol><p>链接：<a href="http://www.senra.me/nat-traversal-series-zerotier-p2p-vpn-can-be-used-in-container-without-tuntap/" target="_blank" rel="noopener">http://www.senra.me/nat-traversal-series-zerotier-p2p-vpn-can-be-used-in-container-without-tuntap/</a></p><ol start="5"><li>Zerotier 简明教程</li></ol><p>链接：<a href="https://jiajunhuang.com/articles/2019_09_11-zerotier.md.html" target="_blank" rel="noopener">https://jiajunhuang.com/articles/2019_09_11-zerotier.md.html</a></p><ol start="6"><li>使用 Docker 创建 ZeroTier Moon 节点</li></ol><p>链接：<a href="https://www.cnblogs.com/webenh/p/11263421.html" target="_blank" rel="noopener">https://www.cnblogs.com/webenh/p/11263421.html</a></p><ol start="7"><li>Zerotier 2.0 的愿景图</li></ol><p>链接：<a href="https://www.zealic.com/2019/10/zerotier2/" target="_blank" rel="noopener">https://www.zealic.com/2019/10/zerotier2/</a></p></blockquote><h2 id="总结">总结</h2><p>从上面的介绍，我们可以看到 <code>ZeroTier</code> 在使用上非常简单、也支持多设备多平台，并且可以无需公网服务器。但由于其免费的根服务器在国外，可能网速会一定影响，建议自建私有根服务器。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://zhih.me/zerotier-getting-started/" target="_blank" rel="noopener">https://zhih.me/zerotier-getting-started/</a></p></li><li><p><a href="https://www.newlearner.site/2019/07/30/zerotier.html" target="_blank" rel="noopener">https://www.newlearner.site/2019/07/30/zerotier.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着可用的公网 IPv4 地址越来越少，现在的运营商基本不给家用宽带分配公网 IP 了。如果你想通过外网访问到内网的资源，目前只能采用内网穿透的软件来实现。而一般常规的内网穿透软件都需要一个公网 IP 才能正常工作，比如：「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247485670&amp;amp;idx=1&amp;amp;sn=df62f2df93f112a7bc0b8d7e843bbc16&amp;amp;chksm=eac529cfddb2a0d9b0fb22324f3eaf5cffeb8e0a56d16efb87ad97d3cca6479e96e12c68eb88&amp;amp;token=211998253&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;FRP&lt;/a&gt;」 或 「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247483754&amp;amp;idx=1&amp;amp;sn=c701d750ea87421446ec2f3202beab33&amp;amp;chksm=eac52043ddb2a955c282f8337d6c0fc63034f3f9e378ae1b1fcc0b53be1f20c8b4f55c159c94&amp;amp;token=211998253&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Ngork&lt;/a&gt;」 等。这样你就不得不租用一个拥有公网 IP 的服务器才能实现上述需求，显然增加了不少使用成本。&lt;/p&gt;
&lt;p&gt;做为一个&lt;code&gt;月薪 3000&lt;/code&gt; 的屌丝怎么可能折腾得起呢？今天，我们就来介绍一款不需要公网 IP 实现内网穿透的工具 &lt;code&gt;ZeroTier&lt;/code&gt; 。&lt;code&gt;ZeroTier&lt;/code&gt; 是一个专门用来建立点对点虚拟专用网（&lt;code&gt;P2P VPN&lt;/code&gt;）的工具，它提供在线管理界面和全平台的客户端，不需要复杂设置，只要安装客户端并加入到自己创建的网络即可。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;官方网站地址：&lt;a href=&quot;https://www.zerotier.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.zerotier.com&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/zerotier&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/zerotier&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="工具" scheme="https://www.hi-linux.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="ZeroTier" scheme="https://www.hi-linux.com/tags/ZeroTier/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟读懂 MySQL 四种隔离级别间的区别</title>
    <link href="https://www.hi-linux.com/posts/22448.html"/>
    <id>https://www.hi-linux.com/posts/22448.html</id>
    <published>2020-05-24T01:22:00.000Z</published>
    <updated>2020-05-24T09:38:04.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是事务">什么是事务</h2><p>事务是应用程序中一系列严密的操作，所有操作必须成功完成，否则在每个操作中所作的所有更改都会被撤消。也就是事务具有原子性，一个事务中的一系列的操作要么全部成功，要么一个都不做。</p><p>事务的结束有两种，当事务中的所以步骤全部成功执行时，事务提交。如果其中一个步骤失败，将发生回滚操作，撤消撤消之前到事务开始时的所以操作。</p><h2 id="事务的-acid">事务的 ACID</h2><p><strong>事务具有四个特征：原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）。这四个特性简称为 ACID 特性。</strong></p><ol><li>原子性：事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做</li><li>一致性：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。</li><li>隔离性：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。</li><li>持续性：也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。</li></ol><a id="more"></a><h2 id="mysql-的四种隔离级别">MySQL 的四种隔离级别</h2><p><strong>SQL 标准定义了 4 类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。</strong></p><h3 id="read-uncommitted读取未提交内容">Read Uncommitted（读取未提交内容）</h3><p>在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。</p><h3 id="read-committed读取提交内容">Read Committed（读取提交内容）</h3><p>这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 Commit，所以同一 Select 可能返回不同结果。</p><h3 id="repeatable-read可重读">Repeatable Read（可重读）</h3><p>这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的 “幻影” 行。InnoDB 和 Falcon 存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。</p><h3 id="serializable可串行化">Serializable（可串行化）</h3><p>这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。</p><p>这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：</p><p>脏读 (Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个 RollBack 了操作，则后一个事务所读取的数据就会是不正确的。</p><p>不可重复读 (Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。</p><p>幻读 (Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列 (Row) 数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。</p><p>在 MySQL 中，实现了这四种隔离级别，分别有可能产生问题如下所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-eceded962ef591d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/686/format/jpg" alt=""></p><h2 id="测试-mysql-的隔离级别">测试 MySQL 的隔离级别</h2><p>下面，将利用 MySQL 的客户端程序，我们分别来测试一下这几种隔离级别。</p><p>测试数据库为 demo，表为 test；表结构：</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-14163bb6124dd816.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/616/format/jpg" alt=""></p><p>两个命令行客户端分别为 A，B；不断改变 A 的隔离级别，在 B 端修改数据。</p><h3 id="1-将-a-的隔离级别设置为-read-uncommitted-未提交读">1. 将 A 的隔离级别设置为 Read Uncommitted (未提交读)</h3><p><img src="https://upload-images.jianshu.io/upload_images/1627454-66609deaf1f77a2f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/708/format/jpg" alt=""></p><p>A：启动事务，此时数据为初始状态</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-895da4e5af710e10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/709/format/jpg" alt=""></p><p>B：启动事务，更新数据，但不提交</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-ebdce5eedc07a388.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/jpg" alt=""></p><p>A：再次读取数据，发现数据已经被修改了，这就是所谓的 “脏读”</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-c2076c78c2f8721b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>B：回滚事务</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-4e0eb8e5b93e7508.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/jpg" alt=""></p><p>A：再次读数据，发现数据变回初始状态</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-e0c4697a63bb7756.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>经过上面的实验可以得出结论，事务 B 更新了一条记录，但是没有提交，此时事务 A 可以查询出未提交记录。造成脏读现象。未提交读是最低的隔离级别。</p><h3 id="2-将客户端-a-的事务隔离级别设置为-read-committed-已提交读">2. 将客户端 A 的事务隔离级别设置为 Read Committed (已提交读)</h3><p><img src="https://upload-images.jianshu.io/upload_images/1627454-9850c93ff1d0b87e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/713/format/jpg" alt=""></p><p>A：启动事务，此时数据为初始状态</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-895da4e5af710e10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/709/format/jpg" alt=""></p><p>B：启动事务，更新数据，但不提交</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-ebdce5eedc07a388.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/jpg" alt=""></p><p>A：再次读数据，发现数据未被修改</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-c27ffc43c74eaff7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>B：提交事务</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-e7fcfe11e7bc77f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/706/format/jpg" alt=""></p><p>A：再次读取数据，发现数据已发生变化，说明B提交的修改被事务中的A读到了，这就是所谓的 “不可重复读”</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-f75e52220936ba91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/709/format/jpg" alt=""></p><p>经过上面的实验可以得出结论，已提交读隔离级别解决了脏读的问题。但是出现了不可重复读的问题，即事务 A 在两次查询的数据不一致，因为在两次查询之间事务 B 更新了一条数据。已提交读只允许读取已提交的记录，但不要求可重复读。</p><h3 id="3-将-a-的隔离级别设置为-repeatable-read-可重复读">3. 将 A 的隔离级别设置为 Repeatable Read (可重复读)</h3><p><img src="https://upload-images.jianshu.io/upload_images/1627454-cd82123669a159e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/711/format/jpg" alt=""></p><p>A：启动事务，此时数据为初始状态</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-034eb70d85fb2765.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/708/format/jpg" alt=""></p><p>B：启动事务，更新数据，但不提交</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-ebdce5eedc07a388.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/jpg" alt=""></p><p>A：再次读取数据，发现数据未被修改</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-c27ffc43c74eaff7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>B：提交事务</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-e7fcfe11e7bc77f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/706/format/jpg" alt=""></p><p>A：再次读取数据，发现数据依然未发生变化，这说明这次可以重复读了</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-c27ffc43c74eaff7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>B：插入一条新的数据，并提交</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-0cc15096520791ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/705/format/jpg" alt=""></p><p>A：再次读取数据，发现数据依然未发生变化。虽然可以重复读了，但是却发现读的不是最新数据，这就是所谓的 “幻读”</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-c27ffc43c74eaff7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>A：提交本次事务，再次读取数据，发现读取正常了</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-34a1fc2ace6ebc23.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/706/format/jpg" alt=""></p><p>由以上的实验可以得出结论，可重复读隔离级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务不得更新该记录。但该事务不要求与其他事务可串行化，例如：当一个事务可以找到由一个已提交事务更新的记录，但是可能产生幻读问题(注意是可能，因为数据库对隔离级别的实现有所差别)。像以上的实验，就没有出现数据幻读的问题。</p><h3 id="4-将-a-的隔离级别设置为可串行化-serializable">4. 将 A 的隔离级别设置为可串行化 (Serializable)</h3><p><img src="https://upload-images.jianshu.io/upload_images/1627454-b3bdfa59a34f9f52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/705/format/jpg" alt=""></p><p>A：启动事务，此时数据为初始状态</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-a703dc5fbfa9556f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/711/format/jpg" alt=""></p><p>B：发现 B 此时进入了等待状态，原因是因为 A 的事务尚未提交，只能等待（此时，B 可能会发生等待超时）</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-f6cc3d7f422eefa5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>A：提交事务</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-7ab66d7a2ee442e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/jpg" alt=""></p><p>B：发现插入成功</p><p><img src="https://upload-images.jianshu.io/upload_images/1627454-5dd245d3cc5954f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/714/format/jpg" alt=""></p><p>Serializable 完全锁定字段，若一个事务来查询同一份数据就必须等待，直到前一个事务完成并解除锁定为止。是完整的隔离级别，会锁定对应的数据表格，因而会有效率的问题。</p><blockquote><p>来源：知乎</p><p>原文：<a href="https://url.cn/5tswojh" target="_blank" rel="noopener">https://url.cn/5tswojh</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是事务&quot;&gt;什么是事务&lt;/h2&gt;
&lt;p&gt;事务是应用程序中一系列严密的操作，所有操作必须成功完成，否则在每个操作中所作的所有更改都会被撤消。也就是事务具有原子性，一个事务中的一系列的操作要么全部成功，要么一个都不做。&lt;/p&gt;
&lt;p&gt;事务的结束有两种，当事务中的所以步骤全部成功执行时，事务提交。如果其中一个步骤失败，将发生回滚操作，撤消撤消之前到事务开始时的所以操作。&lt;/p&gt;
&lt;h2 id=&quot;事务的-ACID&quot;&gt;事务的 ACID&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;事务具有四个特征：原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）。这四个特性简称为 ACID 特性。&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;原子性：事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做&lt;/li&gt;
&lt;li&gt;一致性：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。&lt;/li&gt;
&lt;li&gt;隔离性：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。&lt;/li&gt;
&lt;li&gt;持续性：也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="MySQL" scheme="https://www.hi-linux.com/categories/MySQL/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="MySQL" scheme="https://www.hi-linux.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>谈谈支付宝架构</title>
    <link href="https://www.hi-linux.com/posts/39305.html"/>
    <id>https://www.hi-linux.com/posts/39305.html</id>
    <published>2020-05-24T01:21:00.000Z</published>
    <updated>2020-05-24T09:19:12.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="1-背景">1. 背景</h2><p>一年一度的双十一又要来了，自2008年双十一以来，在每年双十一超大规模流量的冲击上，蚂蚁金服都会不断突破现有技术的极限。2010年双11的支付峰值为2万笔/分钟，全天1280万笔支付，这个数字到2017双11时变为了25.6万笔/秒，全天14.8亿笔。在如此之大的支付TPS背后除了削峰等锦上添花的应用级优化，最解渴最实质的招数当数基于分库分表的单元化了，蚂蚁技术称之为LDC（逻辑数据中心）。本文不打算讨论具体到代码级的分析，而是尝试用最简单的描述来说明其中最大快人心的原理。我想关心分布式系统设计的人都曾被下面这些问题所困扰过：</p><ul><li><p>支付宝海量支付背后最解渴的设计是啥？换句话说，实现支付宝高TPS的最关键的设计是啥？</p></li><li><p>LDC是啥？LDC怎么实现异地多活和异地灾备的？</p></li><li><p>CAP魔咒到底是啥？P到底怎么理解？</p></li><li><p>什么是脑裂？跟CAP又是啥关系？</p></li><li><p>什么是PAXOS，它解决了啥问题？</p></li><li><p>PAXOS和CAP啥关系？PAXOS可以逃脱CAP魔咒么？</p></li><li><p>Oceanbase能逃脱CAP魔咒么？</p></li></ul><p>如果你对这些感兴趣，不妨看一场赤裸裸的论述，拒绝使用晦涩难懂的词汇，直面最本质的逻辑。</p><h2 id="2-ldc和单元化">2. LDC和单元化</h2><p>LDC（logic data center)是相对于传统的（Internet Data Center-IDC）提出的，逻辑数据中心所表达的中心思想是无论物理结构如何的分布，整个数据中心在逻辑上是协同和统一的。这句话暗含的是强大的体系设计，分布式系统的挑战就在于整体协同工作（可用性，分区容忍性）和统一（一致性）。</p><p>单元化是大型互联网系统的必然选择趋势，举个最最通俗的例子来说明单元化。我们总是说TPS很难提升，确实任何一家互联网（比如淘宝、携程、新浪）它的交易TPS顶多以十万计量（平均水平），很难往上串了，因为数据库存储层瓶颈的存在再多水平扩展的服务器都无法绕开这个瓶颈，而从整个互联网的视角看，全世界电商的交易TPS可以轻松上亿。这个例子带给我们一些思考：为啥几家互联网的TPS之和可以那么大，服务的用户数规模也极为吓人，而单个互联网的TPS却很难提升？究其本质，每家互联网都是一个独立的大型单元，他们各自服务自己的用户互不干扰。这就是单元化的基本特性，任何一家互联网公司，其想要成倍的扩大自己系统的服务能力，都必然会走向单元化之路，它的本质是分治，我们把广大的用户分为若干部分，同时把系统复制多份，每一份都独立部署，每一份系统都服务特定的一群用户，以淘宝举例，这样之后，就会有很多个淘宝系统分别为不同的用户服务，每个淘宝系统都做到十万TPS的话，N个这样的系统就可以轻松做到N*十万的TPS了。</p><p>LDC实现的关键就在于单元化系统架构设计，所以在蚂蚁内部，LDC和单元化是不分家的，这也是很多同学比较困扰的地方，看似没啥关系，实则是单元化体系设计成就了LDC。</p><blockquote><p>小结：分库分表解决的最大痛点是数据库单点瓶颈，这个瓶颈的产生是由现代二进制数据存储体系决定的（即I/O速度）。单元化只是分库分表后系统部署的一种方式，这种部署模式在灾备方面也发挥了极大的优势。</p></blockquote><a id="more"></a><h3 id="21-系统架构演化史">2.1 系统架构演化史</h3><p>几乎任何规模的互联网公司，都有自己的系统架构迭代和更新，大致的演化路径都大同小异。最早一般为了业务快速上线，所有功能都会放到一个应用里，系统架构如图 1 所示。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/monolithic-arch.jpg" alt="单应用单服务器架构"></p><p>这样的架构显然是有问题的，单机有着明显的单点效应，单机的容量和性能都是很局限的，而使用中小型机会带来大量的浪费。 随着业务发展，这个矛盾逐渐转变为主要矛盾，因此工程师们采用了以下架构。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/distributed-arch.jpg" alt="单应用多服务器单数据库架构"></p><p>这是整个公司第一次触碰到分布式，也就是对某个应用进行了水平扩容，它将多个微机的计算能力团结了起来，可以完胜同等价格的中小型机器。慢慢的，大家发现，应用服务器CPU都很正常了，但是还是有很多慢请求，究其原因，是因为单点数据库带来了性能瓶颈。于是程序员们决定使用主从结构的数据库集群，如下图所示。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/distributed-arch-with-master-slave-db.jpg" alt="单应用多服务器数据库集群架构"></p><p>其中大部分读操作可以直接访问从库，从而减轻主库的压力。然而这种方式还是无法解决写瓶颈，写依旧需要主库来处理，当业务量量级再次增高时，写已经变成刻不容缓的待处理瓶颈。这时候，分库分表方案出现了。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/distributed-sharding-arch.jpg" alt="分库分表的分布式服务架构"></p><p>分库分表不仅可以对相同的库进行拆分，还可以进行对相同的表进行拆分，对表进行拆分的方式叫做水平拆分。不同功能的表放到不同的库里，一般对应的是垂直拆分（按照业务功能进行拆分），此时一般还对应了微服务化。这种方法做到极致基本能支撑TPS在万级甚至更高的访问量了。然而随着相同应用扩展的越多，每个数据库的链接数也巨量增长，这让数据库本身的资源成为了瓶颈。这个问题产生的本质是全量数据无差别的分享了所有的应用资源，比如A用户的请求在负载均衡的分配下可能分配到任意一个应用服务器上，因而所有应用全部都要链接A用户所在的分库，数据库连接数就变成笛卡尔乘积了。在本质点说，这种模式的资源隔离性还不够彻底。要解决这个问题，就需要把识别用户分库的逻辑往上层移动，从数据库层移动到路由网关层。这样一来，从应用服务器a进来的来自A客户的所有请求必然落库到DB-A，因此a也不用链接其他的数据库实例了，这样一个单元化的雏形就诞生了。</p><blockquote><p>思考一下，应用间其实也存在交互（比如A转账给B），也就意味着，应用不需要链接其他的数据库了，但是还需要链接其他应用。如果是常见的RPC框架如dubbo等，使用的是TCP/IP协议，那么等同于把之前与数据库建立的链接，换成与其他应用之间的链接了。为啥这样就消除瓶颈了呢？首先由于合理的设计，应用间的数据交互并不巨量，其次应用间的交互可以共享TCP链接，比如A-&gt;B之间的Socket链接可以被A中的多个线程复用，而一般的数据库如MySQL则不行，所以MySQL才需要数据库链接池。</p></blockquote><p><img src="https://www.tbwork.org/image/ant-ldc-arch/unitize-arch.jpg" alt="单元化分布式服务架构"></p><p>如上图所示，但我们把整套系统打包为单元化时，每一类的数据从进单元开始就注定在这个单元被消化，由于这种彻底的隔离性，整个单元可以轻松的部署到任意机房而依然能保证逻辑上的统一。下图为一个三地五机房的部署方式。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/ant-3-city-5-center-arch.jpg" alt="三地五中心架构"></p><h3 id="22-蚂蚁单元化架构实践">2.2 蚂蚁单元化架构实践</h3><p>蚂蚁支付宝应该是国内最大的支付工具，其在双十一等活动日当日的支付TPS可达几十万级，未来这个数字可能会更大，这决定了蚂蚁单元化架构从容量要求上看必然从单机房走向多机房。另一方面，异地灾备也决定了这些IDC机房必须是异地部署的。 整体上支付宝也采用了三地五中心（IDC机房）来保障系统的可用性，跟2.1中描述的有所不同的是，支付宝将单元分成了三类（也称CRG架构）：</p><ul><li><p>RZone(Region Zone)：直译可能有点反而不好理解。实际上就是所有可以分库分表的业务系统整体部署的最小单元。每个RZone连上数据库就可以撑起一片天空，把业务跑的溜溜的。</p></li><li><p>GZone(Global Zone)：全局单元，意味着全局只有一份。部署了不可拆分的数据和服务，比如系统配置等。实际情况下，GZone异地也会部署，不过仅是用于灾备，同一时刻，只有一地GZone进行全局服务。GZone一般被RZone依赖，提供的大部分是读取服务。</p></li><li><p>CZone(City Zone)：顾名思义，这是以城市为单位部署的单元。同样部署了不可拆分的数据和服务，比如用户账号服务，客户信息服务等。理论上CZone会被RZone以比访问GZone高很多的频率进行访问。CZone是基于特定的GZone场景进行优化的一种单元，它把GZone中有些有着”写读时间差现象”的数据和服务进行了的单独部署，这样RZone只需要访问本地的CZone即可，而不是访问异地的GZone。</p></li></ul><blockquote><p>“写读时间差现象”是蚂蚁架构师们根据实践统计总结的，他们发现大部分情况下，一个数据被写入后，都会过足够长的时间后才会被访问。生活中这种例子很常见，我们办完银行卡后可能很久才会存第一笔钱；我们创建微博账号后，可能想半天才会发微博；我们下载创建淘宝账号后，可能得浏览好几分钟才会下单买东西。当然了这些例子中的时间差远远超过了系统同步时间。一般来说异地的延时在100ms以内，所以只要满足某地CZone写入数据后100ms以后才用这个数据，这样的数据和服务就适合放到CZone中。</p></blockquote><p>相信大家看到这都会问：为啥分这三种单元？其实其背后对应的是不同性质的数据，而服务不过是对数据的操作集。下面我们来根据数据性质的不同来解释支付宝的CRG架构。当下几乎所有互联网公司的分库分表规则都是根据用户ID来制定的，而围绕用户来看整个系统的数据可以分为以下两类：</p><ul><li><p>用户流水型数据：典型的有用户的订单、用户发的评论、用户的行为记录等。这些数据都是用户行为产生的流水型数据，具备天然的用户隔离性，比如A用户的App上绝对看不到B用户的订单列表。所以此类数据非常适合分库分表后独立部署服务。</p></li><li><p>用户间共享型数据：这种类型的数据又分两类。一类共享型数据是像账号、个人博客等可能会被所有用户请求访问的用户数据，比如A向B转账，A给B发消息，这时候需要确认B账号是否存在；又比如A想看B的个人博客之类的。另外一类是用户无关型数据，像商品、系统配置（汇率、优惠政策）、财务统计等这些非用户纬度的数据，很难说跟具体的某一类用户挂钩，可能涉及到所有用户。比如商品，假设按商品所在地来存放商品数据（这需要双维度分库分表），那么上海的用户仍然需要访问杭州的商品，这就又构成跨地跨zone访问了，还是达不到单元化的理想状态，而且双维度分库分表会给整个LDC运维带来复杂度提升。</p></li></ul><blockquote><p>注：网上和支付宝内部有另外一些分法，比如流水型和状态性，有时候还会分为三类：流水型、状态型和配置型。个人觉得这些分法虽然尝试去更高层次的抽象数据分类，但实际上边界很模糊，适得其反。</p></blockquote><p>直观的类比，我们可以很轻易的将上述两类数据对应的服务划分为RZone和GZone，RZone包含的就是分库分表后负责固定客户群体的服务，GZone则包含了用户间共享的公共数据对应的服务。到这里为止，一切都很完美，这也是主流的单元化话题了。</p><p>对比支付宝的CRG架构，我们一眼就发现少了C（City Zone），CZone确实是蚂蚁在单元化实践领域的一个创新点。再来分析下GZone，GZone之所以只能单地部署，是因为其数据要求被所有用户共享，无法分库分表，而多地部署会带来由异地延时引起的不一致，比如实时风控系统，如果多地部署，某个RZone直接读取本地的话，很容易读取到旧的风控状态，这是很危险的。这时蚂蚁架构师们问了自己一个问题——难道所有数据受不了延时么？这个问题像是打开了新世界的大门，通过对RZone已有业务的分析，架构师们发现80%甚至更高的场景下，数据更新后都不要求立马被读取到。也就是上文提到的”写读时间差现象”，那么这就好办了，对于这类数据，我们允许每个地区的RZone服务直接访问本地，为了给这些RZone提供这些数据的本地访问能力，蚂蚁架构师设计出了CZone。在CZone的场景下，写请求一般从GZone写入公共数据所在库，然后同步到整个OB集群，然后由CZone提供读取服务。比如支付宝的会员服务就是如此。</p><blockquote><p>即便架构师们设计了完美的CRG，但即便在蚂蚁的实际应用中，各个系统仍然存在不合理的CRG分类，尤其是CG不分的现象很常见。</p></blockquote><h2 id="3-支付宝单元化的异地多活和灾备">3. 支付宝单元化的异地多活和灾备</h2><h3 id="31-流量挑拨技术探秘简介">3.1 流量挑拨技术探秘简介</h3><p>单元化后，异地多活只是多地部署而已。比如上海的两个单元为ID范围为[00<sub>19],[40</sub>59]的用户服务，而杭州的两个单元为ID为[20~39]和[60,79]的用户服务，这样上海和杭州就是异地双活的。</p><p>支付宝对单元化的基本要求是每个单元都具备服务所有用户的能力，即——具体的那个单元服务哪些用户是可以动态配置的。所以异地双活的这些单元还充当了彼此的备份。</p><blockquote><p>发现工作中冷备热备已经被用的很乱了。最早冷备是指数据库在备份数据时需要关闭后进行备份（也叫离线备份），防止数据备份过程中又修改了，不需要关闭即在运行过程中进行数据备份的方式叫做热备(也叫在线备份)。也不知道从哪一天开始，冷备在主备系统里代表了这台备用机器是关闭状态的，只有主服务器挂了之后，备服务器才会被启动；而相同的热备变成了备服务器也是启动的，只是没有流量而已，一旦主服务器挂了之后，流量自动打到备服务器上。本文不打算用第二种理解，因为感觉有点野…</p></blockquote><p>为了做到每个单元访问哪些用户变成可配置，支付宝要求单元化管理系统具备流量到单元的可配置以及单元到DB的可配置能力，如下图所示：</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/ant-unit-request-control.jpg" alt="蚂蚁单元化流量挑拨架构"></p><p>其中spanner是蚂蚁基于nginx自研的反向代理网关，也很好理解，有些请求我们希望在反向代理层就被转发至其他IDC的spanner而无需进入后端服务，如图箭头2所示。那么对于应该在本IDC处理的请求，就直接映射到对应的RZ即可，如图箭头1。进入后端服务后，理论上如果请求只是读取用户流水型数据，那么一般不会再进行路由了。然而，对于有些场景来说，A用户的一个请求可能关联了对B用户数据的访问，比如A转账给B，A扣完钱后要调用账务系统去增加B的余额。这时候就涉及到再次的路由，同样有两个结果：跳转到其他IDC（如图箭头3）或是跳转到本IDC的其他RZone（如图箭头4）。</p><p>RZone到DB数据分区的访问这是事先配置好的，上图中RZ和DB数据分区的关系为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RZ0* --&gt; a</span><br><span class="line">RZ1* --&gt; b</span><br><span class="line">RZ2* --&gt; c</span><br><span class="line">RZ3* --&gt; d</span><br></pre></td></tr></table></figure><p>下面我们举个例子来说明整个流量挑拨的过程，假设C用户所属的数据分区是c，<a href="http://xn--Ccashier-h00m162e71qtjmspq6k9b2e8ale2bjgyb.alipay.com" target="_blank" rel="noopener">而C用户在杭州访问了cashier.alipay.com</a>（随便编的）。</p><p>（1）目前支付宝默认会按照地域来路由流量，具体的实现承载者是自研的GLSB（Global Server Load Balancing）[<a href="https://developer.alipay.com/article/1889" target="_blank" rel="noopener">https://developer.alipay.com/article/1889</a>]，它会根据请求者的IP，自动将cashier.alipay.com解析为杭州IDC的IP地址（或者跳转到IDC所在的域名）。大家自己高过网站的化应该知道大部分DNS服务商的地址都是靠人去配置的，GLSB属于动态配置域名的系统，网上也有比较火的类似产品，比如花生壳之类（建过私站的同学应该很熟悉）的。</p><p>（2）好了，到此为止，用户的请求来到了IDC-1的Spanner集群服务器上，Spanner从内存中读取到了路由配置，知道了这个请求的主体用户C所属的RZ3*不再本IDC，于是直接转到了IDC-2进行处理。</p><p>（3）进入IDC-2之后，根据流量配比规则，该请求被分配到了RZ3B进行处理。</p><p>（4）RZ3B得到请求后对数据分区c进行访问。</p><p>（5）处理完毕后原路返回。</p><p>大家应该发现问题所在了，如果再来一个这样的请求，岂不是每次都要跨地域进行调用和返回体传递？确实是存在这样的问题的，对于这种问题，支付宝架构师们决定继续把决策逻辑往用户终端推移。比如，每个IDC机房都会有自己的域名（真实情况可能不是这样命名的）: <a href="http://xn--IDC-1cashieridc-1-gd85ad64a.alipay.com" target="_blank" rel="noopener">IDC-1对应cashieridc-1.alipay.com</a> <a href="http://xn--IDC-2cashieridc-2-gd85ad64a.alipay.com" target="_blank" rel="noopener">IDC-2对应cashieridc-2.alipay.com</a> 那么请求从IDC-1涮过一遍返回时会将前端请求跳转到cashieridc-2.alipay.com去（如果是APP，只需要替换rest调用的接口域名），后面所有用户的行为都会在这个域名上发生，就避免了走一遍IDC-1带来的延时。</p><h3 id="32-支付宝灾备机制">3.2 支付宝灾备机制</h3><p>流量挑拨是灾备切换的基础和前提条件，发生灾难后的通用方法就是把陷入灾难的单元的流量重新打到正常的单元上去，这个流量切换的过程俗称切流。支付宝LDC架构下的灾备有三个层次：</p><ul><li><p>同机房单元间灾备。</p></li><li><p>同城机房间灾备。</p></li><li><p>异地机房间灾备。</p></li></ul><p>（1）同机房单元间灾备</p><p>灾难发生可能性相对最高（但其实也很小）。对LDC来说，最小的灾难就是某个单元由于一些原因（局部插座断开、线路老化、人为操作失误）宕机了。从3.1节里的图中可以看到每组RZ都有A，B两个单元，这就是用来做同机房灾备的，并且AB之间也是双活双备的，正常情况下AB两个单元共同分担所有的请求，一旦A单元挂了，B单元将自动承担A单元的流量份额。这个灾备方案是默认的。</p><p>(2) 同城机房间灾备</p><p>灾难发生可能性相对更小。这种灾难发生的原因一般是机房电线网线被挖断，或者机房维护人员操作失误导致的。在这种情况下，就需要人工的制定流量挑拨（切流）方案了。下面我们举例说明这个过程，如下图所示为上海的两个IDC机房。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/disaster-backup.jpg" alt="同城双机房灾备演练"></p><p>整个切流配置过程分两步，首先需要将陷入灾难的机房中RZone对应的数据分区的访问权配置进行修改；假设我们的方案是由IDC-2机房的RZ2和RZ3分别接管IDC-1中的RZ0和RZ1。那么首先要做的是把数据分区a，b对应的访问权从RZ0和RZ1收回，分配给RZ2和RZ3。即将（如上图所示为初始映射）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RZ0* --&gt; a</span><br><span class="line">RZ1* --&gt; b</span><br><span class="line">RZ2* --&gt; c</span><br><span class="line">RZ3* --&gt; d</span><br></pre></td></tr></table></figure><p>变为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RZ0* --&gt; &#x2F;</span><br><span class="line">RZ1* --&gt; &#x2F;</span><br><span class="line">RZ2* --&gt; a</span><br><span class="line">RZ2* --&gt; c</span><br><span class="line">RZ3* --&gt; b</span><br><span class="line">RZ3* --&gt; d</span><br></pre></td></tr></table></figure><p>然后再修改用户ID和RZ之间的映射配置。假设之前为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[00-24] --&gt; RZ0A(50%),RZOB(50%)</span><br><span class="line">[25-49] --&gt; RZ1A(50%),RZ1B(50%)</span><br><span class="line">[50-74] --&gt; RZ2A(50%),RZ2B(50%)</span><br><span class="line">[75-99] --&gt; RZ3A(50%),RZ3B(50%)</span><br></pre></td></tr></table></figure><p>那么按照灾备方案的要求，这个映射配置将变为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[00-24] --&gt; RZ2A(50%),RZ2B(50%)</span><br><span class="line">[25-49] --&gt; RZ3A(50%),RZ3B(50%)</span><br><span class="line">[50-74] --&gt; RZ2A(50%),RZ2B(50%)</span><br><span class="line">[75-99] --&gt; RZ3A(50%),RZ3B(50%)</span><br></pre></td></tr></table></figure><p>这样之后，所有流量将会被打到IDC-2中，期间部分已经向IDC-1发起请求的用户会收到失败并重试的提示。 实际情况中，整个过程并不是灾难发生后再去做的，整个切换的流程会以预案配置的形式事先准备好，推送给每个流量挑拨客户端（集成到了所有的服务和spanner中）。</p><blockquote><p>这里可以思考下，为何先切数据库映射，再切流量呢？这是因为如果先切流量，意味着大量注定失败的请求会被打到新的正常单元上去，从而影响系统的稳定性（数据库还没准备好）。</p></blockquote><p>(2) 异地机房间灾备</p><p>这个基本上跟同城机房间灾备一致（这也是单元化的优点），不再赘述。</p><h2 id="4-蚂蚁单元化架构的cap分析">4. 蚂蚁单元化架构的CAP分析</h2><h3 id="41-回顾cap">4.1 回顾CAP</h3><h4 id="411-cap的定义">4.1.1 CAP的定义</h4><p>CAP原则是指任意一个分布式系统，同时最多只能满足其中的两项，而无法同时满足三项。所谓的分布式系统，说白了就是一件事一个人做的，现在分给好几个人一起干。我们先简单回顾下CAP各个维度的含义：</p><ul><li><p>Consistency（一致性），这个理解起来很简单，就是每时每刻每个节点上的同一份数据都是一致的。这就要求任何更新都是原子的，即要么全部成功，要么全部失败。想象一下使用分布式事务来保证所有系统的原子性是多么低效的一个操作。</p></li><li><p>Availability（可用性），这个可用性看起来很容易理解，但真正说清楚的不多。我更愿意把可用性解释为：任意时刻系统都可以提供读写服务。那么举个例子，当我们用事务将所有节点锁住来进行某种写操作时，如果某个节点发生不可用的情况，会让整个系统不可用。对于分片式的NoSQL中间件集群（Redis，Memcached）来说，一旦一个分片歇菜了，整个系统的数据也就不完整了，读取宕机分片的数据就会没响应，也就是不可用了。需要说明一点，哪些选择CP的分布式系统，并不是代表可用性就完全没有了，只是可用性没有保障了。为了增加可用性保障，这类中间件往往都提供了”分片集群+复制集”的方案。</p></li><li><p>Partition tolerance（分区容忍性），这个可能也是很多文章都没说清楚的。P并不是像CA一样是一个独立的性质，它依托于CA来进行讨论。参考文献中解释道：”除非整个网络瘫痪，否则任何时刻系统都能正常工作”，言下之意是小范围的网络瘫痪，节点宕机，都不会影响整个系统的CA。我感觉这个解释听着还是有点懵逼，所以个人更愿意解释为”当节点之间网络不通时（出现网络分区），可用性和一致性仍然能得到保障”。从个人角度理解，分区容忍性又分为”可用性分区容忍性”和”一致性分区容忍性”。”出现分区时会不会影响可用性”的关键在于”需不需要所有节点互相沟通协作来完成一次事务”，不需要的话是铁定不影响可用性的，庆幸的是应该不太会有分布式系统会被设计成完成一次事务需要所有节点联动，一定要举个例子的话，全同步复制技术下的Mysql是一个典型案例。”出现分区时会不会影响一致性”的关键则在于出现脑裂时有没有保证一致性的方案，这对主从同步型数据库（MySQL、SQL Server）是致命的，一旦网络出现分区，产生脑裂，系统会出现一份数据两个值的状态，谁都不觉得自己是错的。需要说明的是，正常来说同一局域网内，网络分区的概率非常低，这也是为啥我们最熟悉的数据库（MySQL、SQL Server等）也是不考虑P的原因。</p></li></ul><p>下图为CAP之间的经典关系图：</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/cap-principle.jpg" alt="CAP 关系图"></p><p>还有个需要说明的地方，其实分布式系统很难满足CAP的前提条件是这个系统一定是有读有写的，如果只考虑读，那么CAP很容易都满足，比如一个计算器服务，接受表达式请求，返回计算结果，搞成水平扩展的分布式，显然这样的系统没有一致性问题，网络分区也不怕，可用性也是很稳的，所以可以满足CAP。</p><h4 id="412-cap分析方法">4.1.2 CAP分析方法</h4><p>先说下CA和P的关系，如果不考虑P的话，系统是可以轻松实现CA的。而P并不是一个单独的性质，它代表的是目标分布式系统有没有对网络分区的情况做容错处理。如果做了处理，就一定是带有P的，接下来再考虑分区情况下到底选择了A还是C。所以分析CAP，建议先确定有没有对分区情况做容错处理。 以下是个人总结的分析一个分布式系统CAP满足情况的一般方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">if( 不存在分区的可能性 || 分区后不影响可用性或一致性 || 有影响但考虑了分区情况-P)&#123;</span><br><span class="line">    if(可用性分区容忍性-A under P)）</span><br><span class="line">      return &quot;AP&quot;;</span><br><span class="line">    else if(一致性分区容忍性-C under P）</span><br><span class="line">      return &quot;CP&quot;;</span><br><span class="line">&#125;</span><br><span class="line">else&#123;  &#x2F;&#x2F;分区有影响但没考虑分区情况下的容错</span><br><span class="line">     if(具备可用性-A &amp;&amp; 具备一致性-C）&#123;</span><br><span class="line">         return AC;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这里说明下，如果考虑了分区容忍性，就不需要考虑不分区情况下的可用性和一致性了（大多是满足的）。</p></blockquote><h3 id="42-水平扩展应用单数据库实例的cap分析">4.2 水平扩展应用+单数据库实例的CAP分析</h3><p>让我们再来回顾下分布式应用系统的来由，早年每个应用都是单体的，跑在一个服务器上，服务器一挂，服务就不可用了。另外一方面，单体应用由于业务功能复杂，对机器的要求也逐渐变高，普通的微机无法满足这种性能和容量的要求。所以要拆！还在IBM大卖小型商用机的年代，阿里巴巴就提出要以分布式微机替代小型机。所以我们发现，分布式系统解决的最大的痛点，就是单体单机系统的可用性问题。要想高可用，必须分布式。 一家互联网公司的发展之路上，第一次与分布式相遇应该都是在单体应用的水平扩展上。也就是同一个应用启动了多个实例，连接着相同的数据库（为了简化问题，先不考虑数据库是否单点），如下图所示。</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/horizontal-scale-arch.jpg" alt="多服务单数据库"></p><p>这样的系统天然具有的就是AP（可用性和分区容忍性），一方面解决了单点导致的低可用性问题，另一方面无论这些水平扩展的机器间网络是否出现分区，这些服务器都可以各自提供服务，因为他们之间不需要进行沟通。然而，这样的系统是没有一致性可言的，想象一下每个实例都可以往数据库insert和update（注意这里还没讨论到事务），那还不乱了套。</p><p>于是我们转向了让DB去做这个事，这时候”数据库事务”就被用上了。用大部分公司会选择的Mysql来举例，用了事务之后会发现数据库又变成了单点和瓶颈。单点就像单机一样(本例子中不考虑从库模式)，理论上就不叫分布式了，如果一定要分析其CAP的话，根据4.1.2的步骤分析过程应该是这样的：</p><ul><li><p>分区容忍性：先看有没有考虑分区容忍性，或者分区后是否会有影响。单台MySQL无法构成分区，要么整个系统挂了，要么就活着。</p></li><li><p>可用性分区容忍性：分区情况下，假设恰好是该节点挂了，系统也就不可用了，所以可用性分区容忍性不满足。</p></li><li><p>一致性分区容忍性：分区情况下，只要可用，单点单机的最大好处就是一致性可以得到保障。</p></li></ul><p>因此这样的一个系统，个人认为只是满足了CP。A有但不出色，从这点可以看出，CAP并不是非黑即白的。包括常说的BASE（最终一致性）方案，其实只是C不出色，但最终也是达到一致性的，BASE在一致性上选择了退让。</p><blockquote><p>关于分布式应用+单点数据库的模式算不算纯正的分布式系统，这个可能每个人看法有点差异，上述只是我个人的一种理解，是不是分布式系统不重要，重要的是分析过程。其实我们讨论分布式，就是希望系统的可用性是多个系统多活的，一个挂了另外的也能顶上，显然单机单点的系统不具备这样的高可用特性。所以在我看来，广义的说CAP也适用于单点单机系统，单机系统是CP的。说到这里，大家似乎也发现了，水平扩展的服务应用+数据库这样的系统的CAP魔咒主要发生在数据库层，因为大部分这样的服务应用都只是承担了计算的任务（像计算器那样），本身不需要互相协作，所有写请求带来的数据的一致性问题下沉到了数据库层去解决。想象一下，如果没有数据库层，而是应用自己来保障数据一致性，那么这样的应用之间就涉及到状态的同步和交互了，Zookeeper就是这么一个典型的例子。</p></blockquote><h3 id="43-水平扩展应用主从数据库集群的cap分析">4.3 水平扩展应用+主从数据库集群的CAP分析</h3><p>上一节我们讨论了多应用实例+单数据库实例的模式，这种模式是分布式系统也好，不是分布式系统也罢，整体是偏CP的。现实中，技术人员们也会很快发现这种架构的不合理性——可用性太低了。于是如下图所示的模式成为了当下大部分中小公司所使用的架构：</p><p><img src="https://www.tbwork.org/image/ant-ldc-arch/horizontal-scale-db-arch.jpg" alt="多服务多数据库"></p><p>从上图我可以看到三个数据库实例中只有一个是主库，其他是从库。一定程度上，这种架构极大的缓解了”读可用性”问题，而这样的架构一般会做读写分离来达到更高的”读可用性”，幸运的是大部分互联网场景中读都占了80%以上，所以这样的架构能得到较长时间的广泛应用。”写可用性”可以通过 keepalived 这种HA（高可用）框架来保证主库是活着的，但仔细一想就可以明白，这种方式并没有带来性能上的可用性提升。还好，至少系统不会因为某个实例挂了就都不可用了。可用性勉强达标了，这时候的CAP分析如下：</p><ul><li><p>分区容忍性：依旧先看分区容忍性，主从结构的数据库存在节点之间的通信，他们之间需要通过心跳来保证只有一个Master。然而一旦发生分区，每个分区会自己选取一个新的Master，这样就出现了脑裂，常见的主从数据库（MySQL，Oracle等）并没有自带解决脑裂的方案。所以分区容忍性是没考虑的。</p></li><li><p>一致性：不考虑分区，由于任意时刻只有一个主库，所以一致性是满足的。</p></li><li><p>可用性：不考虑分区，HA机制的存在可以保证可用性，所以可用性显然也是满足的。</p></li></ul><p>所以这样的一个系统，我们认为它是AC的。我们再深入研究下，如果发生脑裂产生数据不一致后有一种方式可以仲裁一致性问题，是不是就可以满足P了呢。还真有尝试通过预先设置规则来解决这种多主库带来的一致性问题的系统，比如CouchDB，它通过版本管理来支持多库写入，在其仲裁阶段会通过DBA配置的仲裁规则（也就是合并规则，比如谁的时间戳最晚谁的生效）进行自动仲裁（自动合并），从而保障最终一致性（BASE），自动规则无法合并的情况则只能依赖人工决策了。</p><h3 id="44-蚂蚁单元化ldc架构cap分析">4.4 蚂蚁单元化LDC架构CAP分析</h3><h4 id="441-战胜分区容忍性">4.4.1 战胜分区容忍性</h4><p>在讨论蚂蚁LDC架构的CAP之前，我们再来想想分区容忍性有啥值得一提的，为啥很多大名鼎鼎的BASE（最终一致性）体系系统都选择损失实时一致性，而不是丢弃分区容忍性呢？</p><p>分区的产生一般有两种情况：</p><ul><li><p>某台机器宕机了，过一会儿又重启了，看起来就像失联了一段时间，像是网络不可达一样。</p></li><li><p>异地部署情况下，异地多活意味着每一地都可能会产生数据写入，而异地之间偶尔的网络延时尖刺（网络延时曲线图陡增）、网络故障都会导致小范围的网络分区产生。前文也提到过，如果一个分布式系统是部署在一个局域网内的（一个物理机房内），那么个人认为分区的概率极低，即便有复杂的拓扑，也很少会有在同一个机房里出现网络分区的情况。而异地这个概率会大大增高，所以蚂蚁的三地五中心必须需要思考这样的问题，分区容忍不能丢！同样的情况还会发生在不同ISP的机房之间（想象一下你和朋友组队玩DOTA，他在电信，你在联通）。为了应对某一时刻某个机房突发的网络延时尖刺活着间歇性失联，一个好的分布式系统一定能处理好这种情况下的一致性问题。</p></li></ul><p>那么蚂蚁是怎么解决这个问题的呢？我们在4.2的备注部分讨论过，其实LDC机房的各个单元都由两部分组成：负责业务逻辑计算的应用服务器和负责数据持久化的数据库。大部分应用服务器就像一个个计算器，自身是不对写一致性负责的，这个任务被下沉到了数据库。所以蚂蚁解决分布式一致性问题的关键就在于数据库！</p><p>想必蚂蚁的读者大概猜到下面的讨论重点了——OceanBase（下文简称OB），中国第一款自主研发的分布式数据库，一时间也确实获得了很多光环。在讨论OB前，我们先来想想Why not MySQL?</p><p>首先，就像CAP三角图中指出的，MySQL是一款满足AC但不满足P的分布式系统。试想一下，一个MySQL主从结构的数据库集群，当出现分区时，问题分区内的Slave会认为主已经挂了，所以自己成为本分区的master（脑裂），等分区问题恢复后，会产生2个主库的数据，而无法确定谁是正确的，也就是分区导致了一致性被破坏。这样的结果是严重的，这也是蚂蚁宁愿自研OceanBase的原动力之一。</p><p>那么如何才能让分布式系统具备分区容忍性呢？按照老惯例，我们从”可用性分区容忍”和”一致性分区容忍”两个方面来讨论。 (1) 可用性分区容忍性保障机制</p><p>可用性分区容忍的关键在于别让一个事务以来所有节点来完成，这个很简单，别要求所有节点共同同时参与某个事务即可。</p><p>(2) 一致性分区容忍性保障机制</p><p>老实说，都产生分区了，哪还可能获得实时一致性。但要保证最终一致性也不简单，一旦产生分区，如何保证同一时刻只会产生一份提议呢？换句话说，如何保障仍然只有一个脑呢？下面我们来看下PAXOS算法是如何解决脑裂问题的。</p><blockquote><p>这里可以发散下，所谓的”脑”其实就是具备写能力的系统，”非脑”就是只具备读能力的系统，对应了MySQL集群中的从库。</p></blockquote><p>下面是一段摘自维基百科的PAXOS定义：</p><blockquote><p>Paxos is a family of protocols for solving consensus in a network of unreliable processors (that is, processors that may fail).</p></blockquote><p>大致意思就是说，PAXOS是在一群不是特别可靠的节点组成的集群中的一种共识机制。Paxos要求任何一个提议，至少有(N/2)+1的系统节点认可，才被认为是可信的，这背后的一个基础理论是少数服从多数。想象一下，如果多数节点认可后，整个系统宕机了，重启后，仍然可以通过一次投票知道哪个值是合法的（多数节点保留的那个值）。这样的设定也巧妙的解决了分区情况下的共识问题，因为一旦产生分区，势必最多只有一个分区内的节点数量会大于等于(N/2)+1。通过这样的设计就可以巧妙的避开脑裂，当然MySQL集群的脑裂问题也是可以通过其他方法来解决的，比如同时Ping一个公共的IP，成功者继续为脑，显然这就又制造了另外一个单点。</p><blockquote><p>如果你了解过比特币或者区块链，你就知道区块链的基础理论也是PAXOS。区块链借助PAXOS对最终一致性的贡献来抵御恶意篡改。而本文涉及的分布式应用系统则是通过PAXOS来解决分区容忍性。再说本质一点，一个是抵御部分节点变坏，一个是防范部分节点失联。</p></blockquote><p>大家一听说过这样的描述——PAXOS是唯一能解决分布式一致性问题的解法。这句话越是理解越发觉得诡异，这会让人以为PAXOS逃离于CAP约束了，所以个人更愿意理解为——PAXOS是唯一一种保障分布式系统最终一致性的共识算法（所谓共识算法，就是大家都按照这个算法来操作，大家最后的结果一定相同）。PAXOS并没有逃离CAP魔咒，毕竟达成共识是(N/2)+1的节点之间的事，剩下的(N/2)-1的节点上的数据还是旧的，这时候仍然是不一致的，所以PAXOS对一致性的贡献在于经过一次事务后，这个集群里已经有部分节点保有了本次事务正确的结果（共识的结果），这个结果随后会被异步的同步到其他节点上，从而保证最终一致性。以下摘自维基百科：</p><blockquote><p>Quorums express the safety (or consistency) properties of Paxos by ensuring at least some surviving processor retains knowledge of the results.</p></blockquote><p>另外PAXOS不要求对所有节点做实时同步，实质上是考虑到了分区情况下的可用性，通过减少完成一次事务需要的参与者个数，来保障系统的可用性。</p><h4 id="442-oceanbase的cap分析">4.4.2 OceanBase的CAP分析</h4><p>上文提到过，单元化架构中的成千山万的应用就像是计算器，本身无CAP限制，其CAP限制下沉到了其数据库层，也就是蚂蚁自研的分布式数据库OceanBase（本节简称OB）。在OB体系中，每个数据库实例都具备读写能力，具体是读是写可以动态配置（参考2.2部分）。实际情况下大部分时候，对于某一类数据（固定用户号段的数据）任意时刻只有一个单元会负责写入某个节点，其他节点要么是实时库间同步，要么是异步数据同步。OB也采用了PAXOS共识协议。实时库间同步的节点(包含自己)个数至少需要(N/2)+1个，这样就可以解决分区容忍性问题。</p><p>下面我们举个马老师改英文名的例子来说明OB设计的精妙之处。假设数据库按照用户ID分库分表，马老师的用户ID对应的数据段在[0-9]，开始由单元A负责数据写入，假如马老师（用户ID假设为000）正在用支付宝APP修改自己的英文名，马老师一开始打错了，打成了Jason Ma，A单元收到了这个请求。这时候发生了分区（比如A网络断开了），我们将单元A对数据段[0,9]的写入权限转交给单元B（更改映射），马老师这次写对了，为Jack Ma。而在网络断开前请求已经进入了A，写权限转交给单元B生效后，A和B同时对[0,9]数据段进行写入马老师的英文名。假如这时候都允许写入的话就会出现不一致，A单元说我看到马老师设置了Jason Ma，B单元说我看到马老师设置了Jack Ma。然而这种情况不会发生的，A提议说我建议把马老师的英文名设置为Jason Ma时，发现没人回应它，因为出现了分区，其他节点对它来说都是不可达的，所以这个提议被自动丢弃，A心里也明白是自己分区了，会有主分区替自己完成写入任务的。同样的，B提出了将马老师的英文名改成Jack Ma后，大部分节点都响应了，所以B成功将Jack Ma写入了马老师的账号记录。假如在写权限转交给单元B后A突然恢复了，也没关系，两笔写请求同时要求获得(N/2)+1个节点的事务锁，通过no-wait设计，在B获得了锁之后，其他挣强该锁的事务都会因为失败而回滚。</p><p>下面我们分析下OB的CAP：</p><ul><li><p>分区容忍性：OB节点之间是有互相通信的（需要相互同步数据），所以存在分区问题，OB通过仅同步到部分节点来保证可用性。这一点就说明OB做了分区容错。</p></li><li><p>可用性分区容忍性：OB事务只需要同步到（N/2)+1个节点，允许其余的一小半节点分区（宕机、断网等），只要(N/2)+1个节点活着就是可用的。极端情况下，比如5个节点分成3份（2:2:1），那就确实不可用了，只是这种情况概率比较低。</p></li><li><p>一致性分区容忍性：分区情况下意味着部分节点失联了，一致性显然是不满足的。但通过共识算法可以保证当下只有一个值是合法的，并且最终会通过节点间的同步达到最终一致性。</p></li></ul><p>所以OB仍然没有逃脱CAP魔咒，产生分区的时候它变成AP+最终一致性（C）。整体来说，它是AP的，即高可用和分区容忍。</p><h2 id="5-结语">5. 结语</h2><p>个人感觉本文涉及到的知识面确实不少，每个点单独展开都可以讨论半天。回到我们紧扣的主旨来看，双十一海量支付背后技术上大快人心的设计到底是啥？我想无非是以下几点：</p><p>基于用户分库分表的RZone设计。每个用户群独占一个单元给整个系统的容量带来了爆发式增长。</p><ul><li><p>RZone在网络分区或灾备切换时OB的防脑裂设计（PAXOS）。我们知道RZone是单脑的（读写都在一个单元对应的库），而网络分区或者灾备时热切换过程中可能会产生多个脑，OB解决了脑裂情况下的共识问题（PAXOS算法）。</p></li><li><p>基于CZone的本地读设计。这一点保证了很大一部分有着“写读时间差”现象的公共数据能被高速本地访问。</p></li><li><p>剩下的那一丢丢不能本地访问只能实时访问GZone的公共配置数据，也兴不起什么风，作不了什么浪。比如用户创建这种TPS，不会高到哪里去。再比如对于实时库存数据，可以通过“页面展示查询走应用层缓存”+“实际下单时再校验”的方式减少其GZone调用量。<br>而这就是蚂蚁LDC的CRG架构，相信54.4万笔/秒还远没到LDC的上限，这个数字可以做到更高。当然双十一海量支付的成功不单单是这么一套设计所决定的，还有预热削峰等运营+技术的手段，以及成百上千的兄弟姐妹共同奋战，特此在这向各位双十一留守同学致敬。</p></li></ul><p>感谢大家的阅读，文中可能存在不足或遗漏之处，欢迎批评指正。</p><h2 id="6-参考文献">6. 参考文献</h2><ul><li><p>[1] Practice of Cloud System Administration, The: DevOps and SRE Practices for Web Services, Volume 2. Thomas A. Limoncelli, Strata R. Chalup, Christina J. Hogan.</p></li><li><p>[2] MySQL 5.7半同步复制技术. <a href="https://www.cnblogs.com/zero-gg/p/9057092.html" target="_blank" rel="noopener">https://www.cnblogs.com/zero-gg/p/9057092.html</a></p></li><li><p>[3] BASE理论分析; <a href="https://www.jianshu.com/p/f6157118e54b" target="_blank" rel="noopener">https://www.jianshu.com/p/f6157118e54b</a></p></li><li><p>[4] Keepalived; <a href="https://baike.baidu.com/item/Keepalived/10346758?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/Keepalived/10346758?fr=aladdin</a></p></li><li><p>[5] PAXOS; <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Paxos_(computer_science)</a></p></li><li><p>[6] OceanBase支撑2135亿成交额背后的技术原理; <a href="https://www.cnblogs.com/antfin/articles/10299396.html" target="_blank" rel="noopener">https://www.cnblogs.com/antfin/articles/10299396.html</a></p></li><li><p>[7] Backup; <a href="https://en.wikipedia.org/wiki/Backup" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Backup</a></p></li></ul><blockquote><p>本文转载自：「TBWORKs’ ZONE」，原文：<a href="https://url.cn/5NcT9mA%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5NcT9mA，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-背景&quot;&gt;1. 背景&lt;/h2&gt;
&lt;p&gt;一年一度的双十一又要来了，自2008年双十一以来，在每年双十一超大规模流量的冲击上，蚂蚁金服都会不断突破现有技术的极限。2010年双11的支付峰值为2万笔/分钟，全天1280万笔支付，这个数字到2017双11时变为了25.6万笔/秒，全天14.8亿笔。在如此之大的支付TPS背后除了削峰等锦上添花的应用级优化，最解渴最实质的招数当数基于分库分表的单元化了，蚂蚁技术称之为LDC（逻辑数据中心）。本文不打算讨论具体到代码级的分析，而是尝试用最简单的描述来说明其中最大快人心的原理。我想关心分布式系统设计的人都曾被下面这些问题所困扰过：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;支付宝海量支付背后最解渴的设计是啥？换句话说，实现支付宝高TPS的最关键的设计是啥？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDC是啥？LDC怎么实现异地多活和异地灾备的？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CAP魔咒到底是啥？P到底怎么理解？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;什么是脑裂？跟CAP又是啥关系？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;什么是PAXOS，它解决了啥问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PAXOS和CAP啥关系？PAXOS可以逃脱CAP魔咒么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oceanbase能逃脱CAP魔咒么？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你对这些感兴趣，不妨看一场赤裸裸的论述，拒绝使用晦涩难懂的词汇，直面最本质的逻辑。&lt;/p&gt;
&lt;h2 id=&quot;2-LDC和单元化&quot;&gt;2. LDC和单元化&lt;/h2&gt;
&lt;p&gt;LDC（logic data center)是相对于传统的（Internet Data Center-IDC）提出的，逻辑数据中心所表达的中心思想是无论物理结构如何的分布，整个数据中心在逻辑上是协同和统一的。这句话暗含的是强大的体系设计，分布式系统的挑战就在于整体协同工作（可用性，分区容忍性）和统一（一致性）。&lt;/p&gt;
&lt;p&gt;单元化是大型互联网系统的必然选择趋势，举个最最通俗的例子来说明单元化。我们总是说TPS很难提升，确实任何一家互联网（比如淘宝、携程、新浪）它的交易TPS顶多以十万计量（平均水平），很难往上串了，因为数据库存储层瓶颈的存在再多水平扩展的服务器都无法绕开这个瓶颈，而从整个互联网的视角看，全世界电商的交易TPS可以轻松上亿。这个例子带给我们一些思考：为啥几家互联网的TPS之和可以那么大，服务的用户数规模也极为吓人，而单个互联网的TPS却很难提升？究其本质，每家互联网都是一个独立的大型单元，他们各自服务自己的用户互不干扰。这就是单元化的基本特性，任何一家互联网公司，其想要成倍的扩大自己系统的服务能力，都必然会走向单元化之路，它的本质是分治，我们把广大的用户分为若干部分，同时把系统复制多份，每一份都独立部署，每一份系统都服务特定的一群用户，以淘宝举例，这样之后，就会有很多个淘宝系统分别为不同的用户服务，每个淘宝系统都做到十万TPS的话，N个这样的系统就可以轻松做到N*十万的TPS了。&lt;/p&gt;
&lt;p&gt;LDC实现的关键就在于单元化系统架构设计，所以在蚂蚁内部，LDC和单元化是不分家的，这也是很多同学比较困扰的地方，看似没啥关系，实则是单元化体系设计成就了LDC。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;小结：分库分表解决的最大痛点是数据库单点瓶颈，这个瓶颈的产生是由现代二进制数据存储体系决定的（即I/O速度）。单元化只是分库分表后系统部署的一种方式，这种部署模式在灾备方面也发挥了极大的优势。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="分布式" scheme="https://www.hi-linux.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>办公环境下实现 Kubernetes 网络互通方案</title>
    <link href="https://www.hi-linux.com/posts/55876.html"/>
    <id>https://www.hi-linux.com/posts/55876.html</id>
    <published>2020-05-24T01:20:00.000Z</published>
    <updated>2020-05-24T09:19:12.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在 <code>Kubernetes</code> 的网络模型中，基于官方默认的 <code>CNI</code> 网络插件 <code>Flannel</code>，这种 <code>Overlay Network</code>（覆盖网络）可以轻松的实现 <code>Pod</code> 间网络的互通。当我们把基于 <code>Spring Cloud</code> 的微服务迁移到 <code>K8S</code> 中后，无须任何改动，微服务 <code>Pod</code> 可以通过 <code>Eureka</code> 注册后可以互相轻松访问。除此之外，我们可以通过 <code>Ingress</code> + <code>Ingress Controller</code> ，在每个节点上，把基于 HTTP 80 端口、HTTPS 443 端口的用户请求流量引入到集群服务中。</p><p>但是实际使用中，我们出现了以下需求：</p><ul><li>办公室网络 和 <code>K8s Pod</code> 网络不通。开发在电脑完成某个微服务模块开发后，希望本地启动后，能注册到 <code>K8S</code> 中开发环境的服务中心进行调试，而不是本地起一堆依赖的服务。</li><li>办公室网络 和 <code>K8s Svc</code> 网络不通。在 <code>K8S</code> 中运行的 <code>Mysql</code>、<code>Redis</code> 等，无法通过 <code>Ingress</code> 7 层暴露，开发电脑无法通过客户端工具直接访问；如果我们通过 <code>Service</code> 的 <code>NodePort</code> 模式，会导致维护量工作量巨大。</li></ul><h3 id="网络互通配置">网络互通配置</h3><p><code>K8S</code> 集群中新加一台配置不高（2 核 4G）的 <code>Node</code> 节点（node-30）专门做路由转发，连接办公室网络和 <code>K8S</code> 集群 <code>Pod</code>、<code>Svc</code>。</p><ul><li>node-30 IP 地址 10.60.20.30</li><li>内网 DNS IP 地址 10.60.20.1</li><li>Pod 网段 10.244.0.0/24，Svc 网段 10.96.0.0/12</li><li>办公 网段 192.168.0.0/22</li></ul><p>给 node-30 节点打上污点标签（Taints），不让 <code>K8S</code> 调度 <code>Pod</code> 来占用资源：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl taint nodes node-30 forward&#x3D;node-30:NoSchedule</span><br></pre></td></tr></table></figure><a id="more"></a><p>node-30 节点，做 <code>SNAT</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 开启转发</span><br><span class="line">$ vim &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf</span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br><span class="line">$ sysctl -p</span><br><span class="line"></span><br><span class="line"># 来自办公室访问pod、service snat</span><br><span class="line">$ iptables -t nat -A POSTROUTING -s 192.168.0.0&#x2F;22 -d 10.244.0.0&#x2F;24 -j MASQUERADE</span><br><span class="line">$ iptables -t nat -A POSTROUTING -s 192.168.0.0&#x2F;22 -d 10.96.0.0&#x2F;12 -j  MASQUERADE</span><br></pre></td></tr></table></figure><p>在办公室的出口路由器上，设置静态路由，将 <code>K8S Pod</code> 和 <code>Service</code> 的网段，路由到 node-30 节点上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ip route 10.244.0.0 255.255.255.0 10.60.20.30</span><br><span class="line">$ ip route 10.96.0.0  255.240.0.0   10.60.20.30</span><br></pre></td></tr></table></figure><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-office-1.jpeg" alt=""></p><h3 id="dns-解析配置">DNS 解析配置</h3><p>以上步骤操作后，我们就可以在本地电脑通过访问 <code>Pod IP</code> 和 <code>Service IP</code> 去访问服务。但是在 <code>K8S</code> 中，由于 <code>Pod IP</code> 随时都可能在变化，<code>Service IP</code> 也不是开发、测试能轻松获取到的。我们希望内网 <code>DNS</code> 在解析 <code>*.cluster.local</code>， <code>CoreDNS</code> 寻找解析结果。</p><p>例如，我们约定将（项目A 、开发环境一 、数据库 <code>MySQL</code>）部署到 ProjectA-dev1 这个 <code>Namespace</code> 下，由于本地到 <code>K8S</code> 集群 <code>Service</code> 网络已经打通，我们在本地电脑使用 <code>MySQL</code> 客户端连接时，只需要填写 <code>mysql.ProjectA-dev1.svc.cluster.local</code> 即可，<code>DNS</code> 查询请求到了内网 <code>DNS</code> 后，走向 <code>CoreDNS</code>，从而解析出 <code>Service IP</code>。</p><p>由于内网 <code>DNS</code> 在解析 <code>*.cluster.local</code>，需要访问 <code>CoreDNS</code> 寻找解析结果。这就需要保证网络可达：</p><ul><li>方案一， 最简单的做法，我们把内网 <code>DNS</code> 架设在 node-30 这台节点上，那么他肯定访问到 <code>Kube-DNS</code> 10.96.0.10</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl  get svc  -n kube-system |grep kube-dns</span><br><span class="line">kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53&#x2F;UDP,53&#x2F;TCP   20d</span><br></pre></td></tr></table></figure><ul><li>方案二，由于我们实验场景内网 <code>DNS IP</code> 地址 10.60.20.1 ，并不在 node-30 上，我们需要打通 10.60.20.1 访问 <code>SVC</code> 网段 10.96.0.0/12 即可</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 内网DNS（IP 10.60.20.1） 添加静态路由</span><br><span class="line">$ route add -net 10.96.0.0&#x2F;12 gw 10.60.20.30</span><br><span class="line"></span><br><span class="line"># node-30（IP 10.60.20.30） 做 SNAT</span><br><span class="line">$ iptables -t nat -A POSTROUTING -s 10.60.20.1&#x2F;32 -d 10.96.0.0&#x2F;12 -j MASQUERADE</span><br></pre></td></tr></table></figure><ul><li>方案三（实验选择），由于我们实验场景内网 <code>DNS IP</code> 10.60.20.1 并不在 node-30 上，我们可以用 <code>nodeSelector</code> 在 node-30 部署一个 <code>Nginx Ingress Controller</code>， 用 4 层暴露出来 <code>CoreDNS</code> 的 TCP/UDP 53 端口。</li></ul><p>给 node-30 打上标签：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl label nodes node-30 node&#x3D;dns-l4</span><br></pre></td></tr></table></figure><p>创建一个 <code>Namespace</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create ns dns-l4</span><br></pre></td></tr></table></figure><p>在 <code>Namespace</code> dns-l4 下部署 <code>Nginx Ingress Controller</code>，选择节点 node-30，并 Tolerate (容忍）其污点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br></pre></td><td class="code"><pre><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-configuration</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: tcp-services</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  53: &quot;kube-system&#x2F;kube-dns:53&quot;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: udp-services</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  53: &quot;kube-system&#x2F;kube-dns:53&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ingress-serviceaccount</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ingress-clusterrole</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - endpoints</span><br><span class="line">      - nodes</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;extensions&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;extensions&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses&#x2F;status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ingress-role</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    resourceNames:</span><br><span class="line">      # Defaults to &quot;&lt;election-id&gt;-&lt;ingress-class&gt;&quot;</span><br><span class="line">      # Here: &quot;&lt;ingress-controller-leader&gt;-&lt;nginx&gt;&quot;</span><br><span class="line">      # This has to be adapted if you change either parameter</span><br><span class="line">      # when launching the nginx-ingress-controller.</span><br><span class="line">      - &quot;ingress-controller-leader-nginx&quot;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - endpoints</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ingress-role-nisa-binding</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: nginx-ingress-role</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nginx-ingress-serviceaccount</span><br><span class="line">    namespace: dns-l4</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ingress-clusterrole-nisa-binding</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nginx-ingress-clusterrole</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nginx-ingress-serviceaccount</span><br><span class="line">    namespace: dns-l4</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ingress-controller</span><br><span class="line">  namespace: dns-l4</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">    app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">      app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io&#x2F;name: ingress-nginx</span><br><span class="line">        app.kubernetes.io&#x2F;part-of: ingress-nginx</span><br><span class="line">      annotations:</span><br><span class="line">        prometheus.io&#x2F;port: &quot;10254&quot;</span><br><span class="line">        prometheus.io&#x2F;scrape: &quot;true&quot;</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        node: dns-l4</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      serviceAccountName: nginx-ingress-serviceaccount</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: &quot;node-30&quot;</span><br><span class="line">        operator: &quot;Exists&quot;</span><br><span class="line">        effect: &quot;NoSchedule&quot;</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx-ingress-controller</span><br><span class="line">          image: quay.io&#x2F;kubernetes-ingress-controller&#x2F;nginx-ingress-controller:0.21.0</span><br><span class="line">          args:</span><br><span class="line">            - &#x2F;nginx-ingress-controller</span><br><span class="line">            - --configmap&#x3D;$(POD_NAMESPACE)&#x2F;nginx-configuration</span><br><span class="line">            - --tcp-services-configmap&#x3D;$(POD_NAMESPACE)&#x2F;tcp-services</span><br><span class="line">            - --udp-services-configmap&#x3D;$(POD_NAMESPACE)&#x2F;udp-services</span><br><span class="line">            - --publish-service&#x3D;$(POD_NAMESPACE)&#x2F;ingress-nginx</span><br><span class="line">            - --annotations-prefix&#x3D;nginx.ingress.kubernetes.io</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              drop:</span><br><span class="line">                - ALL</span><br><span class="line">              add:</span><br><span class="line">                - NET_BIND_SERVICE</span><br><span class="line">            runAsUser: 33</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">            - name: https</span><br><span class="line">              containerPort: 443</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br></pre></td></tr></table></figure><p>部署完成后，电脑验证，是否生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup -q&#x3D;A kube-dns.kube-system.svc.cluster.local  10.60.20.30</span><br></pre></td></tr></table></figure><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-office-2.jpeg" alt=""></p><p>这里我们用轻量级的 <code>Dnsmasq</code> 来作为内网 <code>DNS</code> 配置案例，将来自内网的 <code>*.cluster.local</code> 解析请求，走 <code>KubeDNS</code> 10.60.20.30。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vim &#x2F;etc&#x2F;dnsmasq.conf</span><br><span class="line">strict-order</span><br><span class="line">listen-address&#x3D;10.60.20.1</span><br><span class="line">bogus-nxdomain&#x3D;61.139.2.69</span><br><span class="line">server&#x3D;&#x2F;cluster.local&#x2F;10.60.20.30</span><br></pre></td></tr></table></figure><p>完成以上步骤后，我们办公网络与 <code>Kubernetes</code> 网络互通的需求也就实现了，同时我们可以直接用 <code>K8S Service</code> 的域名规则去访问到 <code>K8S</code> 中的服务。</p><p><img src="https://www.hi-linux.com/img/linux/Kubernetes-office-3.jpeg" alt=""></p><blockquote><p>本文转载自：「阳明的博客」，原文：<a href="http://t.cn/EJNfDJY%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">http://t.cn/EJNfDJY，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 &lt;code&gt;Kubernetes&lt;/code&gt; 的网络模型中，基于官方默认的 &lt;code&gt;CNI&lt;/code&gt; 网络插件 &lt;code&gt;Flannel&lt;/code&gt;，这种 &lt;code&gt;Overlay Network&lt;/code&gt;（覆盖网络）可以轻松的实现 &lt;code&gt;Pod&lt;/code&gt; 间网络的互通。当我们把基于 &lt;code&gt;Spring Cloud&lt;/code&gt; 的微服务迁移到 &lt;code&gt;K8S&lt;/code&gt; 中后，无须任何改动，微服务 &lt;code&gt;Pod&lt;/code&gt; 可以通过 &lt;code&gt;Eureka&lt;/code&gt; 注册后可以互相轻松访问。除此之外，我们可以通过 &lt;code&gt;Ingress&lt;/code&gt; + &lt;code&gt;Ingress Controller&lt;/code&gt; ，在每个节点上，把基于 HTTP 80 端口、HTTPS 443 端口的用户请求流量引入到集群服务中。&lt;/p&gt;
&lt;p&gt;但是实际使用中，我们出现了以下需求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;办公室网络 和 &lt;code&gt;K8s Pod&lt;/code&gt; 网络不通。开发在电脑完成某个微服务模块开发后，希望本地启动后，能注册到 &lt;code&gt;K8S&lt;/code&gt; 中开发环境的服务中心进行调试，而不是本地起一堆依赖的服务。&lt;/li&gt;
&lt;li&gt;办公室网络 和 &lt;code&gt;K8s Svc&lt;/code&gt; 网络不通。在 &lt;code&gt;K8S&lt;/code&gt; 中运行的 &lt;code&gt;Mysql&lt;/code&gt;、&lt;code&gt;Redis&lt;/code&gt; 等，无法通过 &lt;code&gt;Ingress&lt;/code&gt; 7 层暴露，开发电脑无法通过客户端工具直接访问；如果我们通过 &lt;code&gt;Service&lt;/code&gt; 的 &lt;code&gt;NodePort&lt;/code&gt; 模式，会导致维护量工作量巨大。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;网络互通配置&quot;&gt;网络互通配置&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;K8S&lt;/code&gt; 集群中新加一台配置不高（2 核 4G）的 &lt;code&gt;Node&lt;/code&gt; 节点（node-30）专门做路由转发，连接办公室网络和 &lt;code&gt;K8S&lt;/code&gt; 集群 &lt;code&gt;Pod&lt;/code&gt;、&lt;code&gt;Svc&lt;/code&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;node-30 IP 地址 10.60.20.30&lt;/li&gt;
&lt;li&gt;内网 DNS IP 地址 10.60.20.1&lt;/li&gt;
&lt;li&gt;Pod 网段 10.244.0.0/24，Svc 网段 10.96.0.0/12&lt;/li&gt;
&lt;li&gt;办公 网段 192.168.0.0/22&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;给 node-30 节点打上污点标签（Taints），不让 &lt;code&gt;K8S&lt;/code&gt; 调度 &lt;code&gt;Pod&lt;/code&gt; 来占用资源：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl taint nodes node-30 forward&amp;#x3D;node-30:NoSchedule&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>利用 Katacoda 免费同步 Docker 镜像到 Docker Hub</title>
    <link href="https://www.hi-linux.com/posts/30618.html"/>
    <id>https://www.hi-linux.com/posts/30618.html</id>
    <published>2020-05-24T01:19:00.000Z</published>
    <updated>2020-05-24T09:07:13.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="为什么要同步">为什么要同步</h2><p>安装 kubernetes 的时候，我们需要用到 <code>gcr.io/google_containers</code> 下面的一些镜像，在国内是不能直接下载的。如果用 Self Host 方式安装，Master 上的组件除开 Kubelet 之外都用容器运行，甚至 CNI 插件也是容器运行。比如 Flannel，在 <code>quay.io/coreos</code> 下面，在国内下载非常慢。但是我们可以把这些镜像同步到我们的 Docker Hub 仓库里，再配个 Docker Hub 加速器，这样下载镜像就很快了。</p><h2 id="原理">原理</h2><p>Katacoda 是一个在线学习平台，在 Web 上提供学习需要的服务器终端，里面包含学习所需的环境，我们可以利用 <code>Docker</code> 课程的终端来同步，因为里面有 <code>Docker</code> 环境，可以执行 docker login、docker pull、docker tag、docker push 等命令来实现同步镜像。</p><p>但是手工去执行命令很麻烦，如果要同步的镜像和 Tag 比较多，手工操作那就是浪费生命。我们可以利用程序代替手工操作，不过 Katacoda 为了安全起见，不允许执行外来的二进制程序，但是可以 Shell 脚本，我写好了脚本，大家只需要粘贴进去根据自己需要稍稍修改下，然后运行就可以了。</p><a id="more"></a><h2 id="lets-do-it">Let’s Do It</h2><p>点击 <a href="https://www.katacoda.com/courses/docker/deploying-first-container" target="_blank" rel="noopener" title="Docker 课程">这里</a> 进入 Docker 课程。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1520565820/blog/k8s/katacoda-docker.png" alt=""></p><p>点击 <code>START SCENARIO</code> 或 终端右上角全屏按钮将终端放大。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1520565820/blog/k8s/katacoda-terminal.png" alt=""></p><p>安装脚本依赖的 <code>jq</code> 命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt install jq</span><br></pre></td></tr></table></figure><p>登录 Docker Hub</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker login</span><br></pre></td></tr></table></figure><p>创建脚本并赋予执行权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ touch sync</span><br><span class="line">$ chmod +x sync</span><br></pre></td></tr></table></figure><p><img src="https://res.cloudinary.com/imroc/image/upload/v1520565825/blog/k8s/katacoda-terminal2.png" alt=""></p><p>编辑脚本，可以使用自带的 vim 编辑器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim sync</span><br></pre></td></tr></table></figure><p>将脚本粘贴进去</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">#! &#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">docker_repo&#x3D;&quot;k8smirror&quot; # your docker hub username or organization name</span><br><span class="line">registry&#x3D;&quot;gcr.io&quot; # the registry of original image, e.g. gcr.io, quay.io</span><br><span class="line">repo&#x3D;&quot;google_containers&quot; # the repository name of original image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sync_one()&#123;</span><br><span class="line">  docker pull $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;$&#123;1&#125;:$&#123;2&#125;</span><br><span class="line">  docker tag $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;$&#123;1&#125;:$&#123;2&#125; docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;$&#123;1&#125;:$&#123;2&#125;</span><br><span class="line">  docker push docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;$&#123;1&#125;:$&#123;2&#125;</span><br><span class="line">  docker rmi -f $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;$&#123;1&#125;:$&#123;2&#125; docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;$&#123;1&#125;:$&#123;2&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sync_all_tags() &#123;</span><br><span class="line">  for image in $*; do</span><br><span class="line">    tags_str&#x3D;&#96;curl https:&#x2F;&#x2F;$&#123;registry&#125;&#x2F;v2&#x2F;$&#123;repo&#125;&#x2F;$image&#x2F;tags&#x2F;list | jq &#39;.tags&#39; -c | sed &#39;s&#x2F;\[&#x2F;\(&#x2F;g&#39; | sed &#39;s&#x2F;\]&#x2F;\)&#x2F;g&#39; | sed &#39;s&#x2F;,&#x2F; &#x2F;g&#39;&#96;</span><br><span class="line">    echo &quot;$image $tags_str&quot;</span><br><span class="line">    src&#x3D;&quot;</span><br><span class="line">sync_one()&#123;</span><br><span class="line">  docker pull $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">  docker tag $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125; docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">  docker push docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">  docker rmi -f $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125; docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">&#125;</span><br><span class="line">tags&#x3D;$&#123;tags_str&#125;</span><br><span class="line">echo \&quot;$image $&#123;tags_str&#125;\&quot;</span><br><span class="line">for tag in \$&#123;tags[@]&#125;</span><br><span class="line">do</span><br><span class="line">  sync_one $image \$&#123;tag&#125;</span><br><span class="line">done;&quot;</span><br><span class="line">    bash -c &quot;$src&quot;</span><br><span class="line">  done </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sync_with_tags()&#123;</span><br><span class="line">  image&#x3D;$1</span><br><span class="line">  skip&#x3D;1</span><br><span class="line">  for tag in $*; do</span><br><span class="line">    if [ $skip -eq 1 ]; then</span><br><span class="line">  skip&#x3D;0</span><br><span class="line">    else</span><br><span class="line">      sync_one $image $tag</span><br><span class="line">fi</span><br><span class="line">  done </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sync_after_tag()&#123;</span><br><span class="line">  image&#x3D;$1</span><br><span class="line">  start_tag&#x3D;$2</span><br><span class="line">  tags_str&#x3D;&#96;curl https:&#x2F;&#x2F;$&#123;registry&#125;&#x2F;v2&#x2F;$&#123;repo&#125;&#x2F;$image&#x2F;tags&#x2F;list | jq &#39;.tags&#39; -c | sed &#39;s&#x2F;\[&#x2F;\(&#x2F;g&#39; | sed &#39;s&#x2F;\]&#x2F;\)&#x2F;g&#39; | sed &#39;s&#x2F;,&#x2F; &#x2F;g&#39;&#96;</span><br><span class="line">  echo &quot;$image $tags_str&quot;</span><br><span class="line">  src&#x3D;&quot;</span><br><span class="line">sync_one()&#123;</span><br><span class="line">  docker pull $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">  docker tag $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125; docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">  docker push docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">  docker rmi -f $&#123;registry&#125;&#x2F;$&#123;repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125; docker.io&#x2F;$&#123;docker_repo&#125;&#x2F;\$&#123;1&#125;:\$&#123;2&#125;</span><br><span class="line">&#125;</span><br><span class="line">tags&#x3D;$&#123;tags_str&#125;</span><br><span class="line">start&#x3D;0</span><br><span class="line">for tag in \$&#123;tags[@]&#125;; do</span><br><span class="line">  if [ \$start -eq 1 ]; then</span><br><span class="line">    sync_one $image \$tag</span><br><span class="line">  elif [ \$tag &#x3D;&#x3D; &#39;$start_tag&#39; ]; then</span><br><span class="line">    start&#x3D;1</span><br><span class="line">  fi</span><br><span class="line">done&quot;</span><br><span class="line">  bash -c &quot;$src&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">get_tags()&#123;</span><br><span class="line">  image&#x3D;$1</span><br><span class="line">  curl https:&#x2F;&#x2F;$&#123;registry&#125;&#x2F;v2&#x2F;$&#123;repo&#125;&#x2F;$image&#x2F;tags&#x2F;list | jq &#39;.tags&#39; -c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#sync_with_tags etcd 2.0.12 2.0.13 # sync etcd:2.0.12 and etcd:2.0.13</span><br><span class="line">#sync_after_tag etcd 2.0.8 # sync tag after etcd:2.0.8</span><br><span class="line">#sync_all_tags etcd hyperkube # sync all tags of etcd and hyperkube</span><br></pre></td></tr></table></figure><p>脚本中有一些参数需要根据你自己情况修改，可以使用它自带的 <code>vim</code> 在线修改，也可以在你本地改好在粘贴上去。</p><ul><li><code>docker_repo</code> 改为你的 Docker Hub 账号组织名</li><li><code>registry</code> 改为被同步镜像所在仓库的域名</li><li><code>repo</code> 改为被同步镜像所在仓库的账号或组织名</li></ul><p>在脚本最后，可以调用写好的函数来实现镜像同步，举例：</p><ul><li>同步一个镜像中指定的一个或多个 tag</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sync_with_tags etcd 2.0.12 2.0.13</span><br></pre></td></tr></table></figure><ul><li>从某个 Tag 后面的 Tag 开始一直同步到最后（Tag 顺序按照字母数字来的，不是上传日期；Katacoda 终端用久了会断连，可能处于安全原因考虑，断开之后可以看 Tag 同步到哪一个了，然后执行类似下面的命令从断连的 Tag 开始同步）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sync_after_tag etcd 2.0.8</span><br></pre></td></tr></table></figure><p>同步一个或多个镜像的所有 Tag</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sync_all_tags etcd hyperkube</span><br></pre></td></tr></table></figure><p>最后执行脚本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;sync</span><br></pre></td></tr></table></figure><p>这就开始同步了，Katacoda 服务器在国外，下载 <a href="http://gcr.io" target="_blank" rel="noopener">gcr.io</a> 或 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 上那些镜像都很快，上传 Docker Hub 也很快。如果断连了，可以在 Docker Hub 上查最新上传的 Tag 是哪个（如：<a href="https://hub.docker.com/r/k8smirror/hyperkube/tags/" target="_blank" rel="noopener">https://hub.docker.com/r/k8smirror/hyperkube/tags/</a> 把 k8smirror 改为你的 Docker 用户名或组织名，hyperkube 改为镜像名），然后改脚本，用 sync_after_tag 这个函数继续上传。</p><blockquote><p>本文转载自：「I’m roc Blog」，原文：<a href="http://t.cn/AiW3Jpot%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">http://t.cn/AiW3Jpot，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;为什么要同步&quot;&gt;为什么要同步&lt;/h2&gt;
&lt;p&gt;安装 kubernetes 的时候，我们需要用到 &lt;code&gt;gcr.io/google_containers&lt;/code&gt; 下面的一些镜像，在国内是不能直接下载的。如果用 Self Host 方式安装，Master 上的组件除开 Kubelet 之外都用容器运行，甚至 CNI 插件也是容器运行。比如 Flannel，在 &lt;code&gt;quay.io/coreos&lt;/code&gt; 下面，在国内下载非常慢。但是我们可以把这些镜像同步到我们的 Docker Hub 仓库里，再配个 Docker Hub 加速器，这样下载镜像就很快了。&lt;/p&gt;
&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;p&gt;Katacoda 是一个在线学习平台，在 Web 上提供学习需要的服务器终端，里面包含学习所需的环境，我们可以利用 &lt;code&gt;Docker&lt;/code&gt; 课程的终端来同步，因为里面有 &lt;code&gt;Docker&lt;/code&gt; 环境，可以执行 docker login、docker pull、docker tag、docker push 等命令来实现同步镜像。&lt;/p&gt;
&lt;p&gt;但是手工去执行命令很麻烦，如果要同步的镜像和 Tag 比较多，手工操作那就是浪费生命。我们可以利用程序代替手工操作，不过 Katacoda 为了安全起见，不允许执行外来的二进制程序，但是可以 Shell 脚本，我写好了脚本，大家只需要粘贴进去根据自己需要稍稍修改下，然后运行就可以了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你用 Gitlab 和 Jenkins 构建持续集成环境</title>
    <link href="https://www.hi-linux.com/posts/55356.html"/>
    <id>https://www.hi-linux.com/posts/55356.html</id>
    <published>2020-05-24T01:18:00.000Z</published>
    <updated>2020-05-24T09:07:13.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近用到持续集成顺便总结在这里，都是用的最新版。搭建过程中还有一个 Demo，提交代码到 Gitlab 自动触发 Jenkins 任务，自动编译代码和 Docker 镜像并上传。</p><h2 id="安装运行-gitlab">安装运行 Gitlab</h2><p>Gitlab 国内安装很麻烦，用官方的源装不了，因为在国外，太慢，链接会断掉。国内清华有 Gitlab 的 Apt 和 Yum 源，但是我试过安装 CentOS 7 的 Gitlab ，到最后都会一直卡住结束不了。直接下载清华 Gitlab 的 Rpm Mirror 安装也是一样，所以我还是选择用 Docker 启动 Gitlab（提前配好 Docker Hub 加速器）</p><ul><li>准备镜像</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gitlab&#x2F;gitlab-ee:latest</span><br></pre></td></tr></table></figure><ul><li>准备 Gitlab 所需目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir gitlab</span><br><span class="line">$ cd gitlab</span><br><span class="line">$ mkdir config logs data</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>准备启动脚本</li></ul><p>替换想要的启动的端口，IP 地址替换为访问你的 Gitlab 的地址，也可以替换想要的挂载目录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ vi run</span><br><span class="line">#! &#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">sudo docker run -d --rm \</span><br><span class="line">    -p 8088:8088 \</span><br><span class="line">    --name gitlab \</span><br><span class="line">    --env GITLAB_OMNIBUS_CONFIG&#x3D;&quot;external_url &#39;http:&#x2F;&#x2F;118.24.64.246:8088&#x2F;&#39;; gitlab_rails[&#39;lfs_enabled&#39;] &#x3D; true;&quot; \</span><br><span class="line">    -v $PWD&#x2F;config:&#x2F;etc&#x2F;gitlab \</span><br><span class="line">    -v $PWD&#x2F;logs:&#x2F;var&#x2F;log&#x2F;gitlab \</span><br><span class="line">    -v $PWD&#x2F;data:&#x2F;var&#x2F;opt&#x2F;gitlab \</span><br><span class="line">    gitlab&#x2F;gitlab-ee:latest</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>赋予执行权限</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x run</span><br></pre></td></tr></table></figure><ul><li>启动 Gitlab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;run</span><br></pre></td></tr></table></figure><ul><li>查看 Gitlab 控制台输出</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs -f gitlab</span><br></pre></td></tr></table></figure><p>访问 Gitlab，打开脚本中配置的 external_url 地址，设置管理员密码和注册 Gitlab 账号，登录并添加自己的 SSH key 。创建 Repo ，git clone 到本地，后面我们提交代码到这个 Repo ，触发 Jenkins 的持续集成。</p><h2 id="安装运行-jenkins">安装运行 Jenkins</h2><p>Jenkins 建议直接安装在宿主机，不用 Docker 方式，因为持续集成需要安装各种我们用到的工具，这些工具可能后面根据需要才安装，重启不能让这些工具丢失。比如编译 Java 源码需要装 JDK 环境，编译和上传 Docker 镜像需要安装 Docker 环境，并且还需要提前 docker login 好，不然上传不了。</p><p>因为 Jenkins 用 JAVA 写的，所以确保机器上装有 JDK 或 OpenJDK 环境，准备一个 Jenkins 用的目录，下载 War 包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir jenkins </span><br><span class="line">$ wget http:&#x2F;&#x2F;mirrors.jenkins.io&#x2F;war-stable&#x2F;latest&#x2F;jenkins.war</span><br></pre></td></tr></table></figure><p>运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup java -jar jenkins.war --httpPort&#x3D;8080 &amp;&gt; jenkins.log &amp;</span><br></pre></td></tr></table></figure><p>查看 jenkins 输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tail -f jenkins.log</span><br></pre></td></tr></table></figure><p>第一次打开 Jenkins Web 界面，要求输出管理员初始密码，生成在服务器上，界面上提示有路径。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523432610/blog/ci/jenkins-initial.png" alt=""></p><p>查看密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;root&#x2F;.jenkins&#x2F;secrets&#x2F;initialAdminPassword</span><br></pre></td></tr></table></figure><p>粘贴密码并继续，安装推荐的插件，等待安装完成</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523433013/blog/ci/xsrm.png" alt=""></p><p>创建管理员，保存并完成。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523440941/blog/ci/create-admin.png" alt=""></p><p>至此，jenkins 安装完成</p><h2 id="jenkins-安装需要的插件">Jenkins 安装需要的插件</h2><p>打开 Jenkins-系统设置-管理插件。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523440424/blog/ci/manage-plugin.png" alt=""></p><p>在可选插件里选择并安装需要的插件：Git 、 GitLab 、Build Authentication Token Root （Git 插件在默认推荐插件里已安装，在可选插件列表里可能没有）。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523443519/blog/ci/install-plugin.png" alt=""></p><p>点击 “直接安装”，勾选 “安装完成后重启 Jenkins (空闲时)“，等待安装完成自动重启 Jenkins。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523443587/blog/ci/jenkins-plugin-install-and-restrart.png" alt=""></p><p>由于后面 Jenkins 的机器上需要用到 Docker，所以保证 Jenkins 所在机器安装好 Docker 并配好 Docker Hub 的加速器，并且 docker login 登录镜像要上传的仓库。</p><h2 id="gitlab-创建-repo">Gitlab 创建 Repo</h2><p>我们这里就以一个简单的 Golang 程序做实例，实现提交代码自动编译代码，然后 Docker 编译镜像并上传至 CCR （腾讯云的 Docker 镜像仓库)。</p><p>在 Gitlab 上创建空 Repo，Clone 到本地，添加三个文件。</p><ul><li>main.go （源码）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">println(&quot;hello world&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Dockerfile （编译镜像用的 Dockerfile）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest</span><br><span class="line"></span><br><span class="line">MAINTAINER roc&lt;rockerchen@tencent.com&gt;</span><br><span class="line"></span><br><span class="line">COPY bd-ci-test &#x2F;bin&#x2F;bd-ci-test</span><br><span class="line"></span><br><span class="line">CMD [&quot;bd-ci-test&quot;]</span><br></pre></td></tr></table></figure><ul><li>build （编译源码、镜像和上传镜像的脚本，替换 IMAGE 地址为要上传的地址）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#! &#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line"># 编译代码</span><br><span class="line">docker run --rm \</span><br><span class="line">  -v $PWD:&#x2F;go&#x2F;src&#x2F;bd-ci-test \</span><br><span class="line">  -w &#x2F;go&#x2F;src&#x2F;bd-ci-test \</span><br><span class="line">  golang:alpine go build</span><br><span class="line"></span><br><span class="line">IMAGE&#x3D;&quot;imroc&#x2F;bd-ci-test:latest&quot;</span><br><span class="line"></span><br><span class="line"># 编译镜像</span><br><span class="line">docker build -t $IMAGE .</span><br><span class="line"></span><br><span class="line"># 上传镜像 (请提前登录好,docker login 只需登录一次)</span><br><span class="line">docker push $IMAGE</span><br><span class="line"></span><br><span class="line"># 清理</span><br><span class="line">docker rmi $IMAGE</span><br><span class="line">rm bd-ci-test</span><br></pre></td></tr></table></figure><ul><li>给 build 脚本执行权限</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x build</span><br></pre></td></tr></table></figure><p>至此，我们的代码准备好了，先不忙提交，接下来配置 Jenkins 来做持续集成。</p><h2 id="配置-jenkins">配置 Jenkins</h2><p>新建 Jenkins 项目，选择 “构建一个自由风格的软件项目”。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523444143/blog/ci/jenkins-new-project.png" alt=""></p><p>源代码管理选 Git，Repository URL 填写你 Gitlab 上源码 Repo 的地址，Credentials 是拉取代码时需要用到的身份认证（如果你的Repo 不是公有的，没有身份认证就会报错）。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523451253/blog/ci/jenkins-git.png" alt=""></p><p>点击 Add 添加一个， Kind 选择 “Username with password”，输入 Gitlab 账号密码。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523451426/blog/ci/jenkins-credentials.png" alt=""></p><p>然后 Credentials 选择我们刚刚添加的（检测到账号密码正确就不会报错了），我们准备对 master 分支的代码做持续集成，所以 “Branches to build” 填 “*/master”。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523451601/blog/ci/jenkins-git-after.png" alt=""></p><p>构建触发器选择 “Build when a change is pushed to GitLab” （后面的 URL 是我们需要在 Gitlab 上配的 Webhook 地址），按照下面勾选。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523452134/blog/ci/jenkins-construct-trigger.png" alt=""></p><p>点开高级，“Allowd branches” 勾选 “Filter branches by regex”，填写 “master”。点 “Generate” 生成 Token，这个 Token 用于填写到 Gitlab 的 Webhook 里，Gitlab 检测到代码提交，会通知 Webhook 里填写的 Jenkins 生成的回掉 URL，并带上这个 Token，防止其它人触发 Jenkins 的持续集成。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523452257/blog/ci/jenkins-advanced-trigger.png" alt=""></p><blockquote><p>注: 复制出 URL 和 Token，我们后面配置 Gitlab 的 Webhook 会用到。</p></blockquote><p>增加构建步骤 “execute shell”。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523452676/blog/ci/jenkins-construct.png" alt=""></p><p>由于我们把持续集成的操作都写到 build 脚本了，所以直接填写执行 ./build 就可以了。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523453127/blog/ci/jenkins-build.png" alt=""></p><p>最后点击保存，至此，Jenkins 的持续集成配置好了，还需要配置 Gitlab 的 Webhook，用于代码提交通知 Jenkins。</p><h2 id="配置-gitlab-webhook">配置 Gitlab Webhook</h2><p>打开 Gitlab 的 Repo 的 Settings-Integrations。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523453629/blog/ci/gitlab-webhook.png" alt=""></p><p>URL 和 Secret Token 填写 Jenkins 项目中构建触发器部分生成的，点击 “Add webhook”，搞定！</p><h2 id="测试">测试</h2><p>现在我们可以提交代码测试一下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git add .</span><br><span class="line">$ git commit -m &quot;test&quot;</span><br><span class="line">$ git push</span><br></pre></td></tr></table></figure><p>我们可以看 Jenkins 的输出来看是否触发任务，由于我使用了一些 Docker Hub 的镜像来编译代码和镜像，如果没有提前 Pull 下来，第一次运行任务可能会比较久，等待运行结束，刷新 Jenkins 主页。</p><p>如果运行成功，从 “上次成功” 下拉选择 “控制台输出”</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523453513/blog/ci/jenkins-console-tab.png" alt=""></p><p>可以看到运行任务过程的输出。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523453516/blog/ci/jenkins-console.png" alt=""></p><p>如果都没问题，你可以看看你的镜像仓库，镜像已经成功上传，至此，这个简单的持续集成搭建完毕。</p><h2 id="附录">附录</h2><h3 id="git-submodule">Git Submodule</h3><p>如果你的项目里面还引用了其它项目，也就是 Git 的 Submodules，怎么办？甚至 Submodule 里面还要指定分支呢？</p><p>在创建 Jenkins 项目的时候，在 源码管理-Git-Additional Behaviours-Add 选择 Advanced sub-modules behaviours。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523628768/blog/ci/jekins-advanced-sub-modules.png" alt=""></p><p>勾选下面两个选项。</p><p><img src="https://res.cloudinary.com/imroc/image/upload/v1523628769/blog/ci/jenkins-additional-behaviours.png" alt=""></p><p>Submodules 的分支靠 Git 本来支持的 <code>.gitmodules</code> 文件来控制，用法举例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git submodule add -b v1 https:&#x2F;&#x2F;github.com&#x2F;imroc&#x2F;req.git ref&#x2F;req</span><br></pre></td></tr></table></figure><p>查看 <code>.gitmodules</code> 文件格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cat .gitmodules</span><br><span class="line">[submodule &quot;ref&#x2F;req&quot;]</span><br><span class="line">path &#x3D; ref&#x2F;req</span><br><span class="line">url &#x3D; https:&#x2F;&#x2F;github.com&#x2F;imroc&#x2F;req.git</span><br><span class="line">branch &#x3D; v1</span><br></pre></td></tr></table></figure><p>可以自己手动编辑或用 <code>git submodule add</code> 命令生成。</p><blockquote><p>本文转载自：「I’m roc Blog」，原文：<a href="http://t.cn/AiWDsnzq%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">http://t.cn/AiWDsnzq，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近用到持续集成顺便总结在这里，都是用的最新版。搭建过程中还有一个 Demo，提交代码到 Gitlab 自动触发 Jenkins 任务，自动编译代码和 Docker 镜像并上传。&lt;/p&gt;
&lt;h2 id=&quot;安装运行-Gitlab&quot;&gt;安装运行 Gitlab&lt;/h2&gt;
&lt;p&gt;Gitlab 国内安装很麻烦，用官方的源装不了，因为在国外，太慢，链接会断掉。国内清华有 Gitlab 的 Apt 和 Yum 源，但是我试过安装 CentOS 7 的 Gitlab ，到最后都会一直卡住结束不了。直接下载清华 Gitlab 的 Rpm Mirror 安装也是一样，所以我还是选择用 Docker 启动 Gitlab（提前配好 Docker Hub 加速器）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;准备镜像&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ docker pull gitlab&amp;#x2F;gitlab-ee:latest&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;准备 Gitlab 所需目录&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ mkdir gitlab&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ cd gitlab&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ mkdir config logs data&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Gitlab" scheme="https://www.hi-linux.com/tags/Gitlab/"/>
    
  </entry>
  
  <entry>
    <title>谈谈技术人的发展生存之道</title>
    <link href="https://www.hi-linux.com/posts/1788.html"/>
    <id>https://www.hi-linux.com/posts/1788.html</id>
    <published>2020-05-24T01:17:00.000Z</published>
    <updated>2020-05-24T08:56:22.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>这是一篇从 “人” (而非技术也非管理)的角度，聚焦于自身职业发展方方面面的文章，包括职业、学习、生产力、影响力等。</p><h2 id="拥有商业心态">拥有商业心态</h2><p>你所能犯的最大错误就是相信自己是在为别人工作，职业发展的驱动力一定是来自个体本身，而不是领导、公司，因为职业发展是属于你自己的。如果你真的想在这个充满竞争的世界里脱颖而出，那么你首先必须制订一个坚实可靠而又深思熟虑的计划，学会主动管理自己的职业生涯。</p><p>职业生涯中要做的第一件事便是，转变你的心态。而商业心态对于管理职业规划至关重要。如果你已经习惯于领取一份固定的薪酬，便会很容易导致你产生：你只是在为这家公司打工的谋生心态。尽管在你的职业生涯的某个特定时间段里，你可能确实是在为某家公司打工，但是千万不要因此固化了你的整个职业生涯。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1562990262645-1c5cf817-03dd-4b0d-82d4-55e4dca112b0.png" alt=""></p><p>那么心态该如何转变呢？首先你要把自己当作一个企业去思考，然后把雇主当作是你这个企业的一个客户。当然，你可能只有这么一个客户，你所有的收入都是从这一个客户得来的，但是这种诠释雇用关系的方式可以将你从雇佣关系的弱势地位转换成为自我治理和自我引导的主动地位，同时，心态转变后能更有利于你做出良好的商业决策。</p><a id="more"></a><h2 id="作为企业该如何思考">作为企业，该如何思考</h2><p>现在你已经把自己当作一个企业了，在这个状态下，其实你的收益并不大，至少物质上并没有给你太多好处。要想从中有所收获，你得先弄明白企业是如何思考、发展的？上个月跟我们的PMO@冰霖 有过一次闲谈，过程中印象最深的一句话是：一个企业要发展，首先要找到一个能赚钱的产品或服务，然后思考如何完善、改进，以达到更长远的发展。发展过程中，始终要考虑投入产出（成本、风险、收益、回报周期），将收益最大化。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1562994831596-1f1844d1-ef9d-4bcd-bf0d-fb9c504ae2d4.png" alt=""></p><p>把你作为一个企业，你目前以及未来能提供什么服务或产品呢？即使你刚开始思考这个问题，对你自己的职业生涯或许也会慢慢产生深远的影响。拿我来举个例子，我目前的职业是web前端工程师，那我售卖的就是前端开发技能，准确来讲，售卖的是把公司的想法实现成互联网产品人机交互的能力。企业需要持续不断地迭代、改进和完善自己的产品。你也应该这么做，通过不断学习升级打怪，去完善自我。</p><h2 id="思考未来的目标">思考未来的目标</h2><p>作为企业，出了要知道自己能提供什么服务或产品，还需要明确的业务目标。起步阶段最简单的就是在心中树立一个大 目标，然后再建立能帮你达成这个大目标的小目标。大目标并不需要那么具体，但是必须足够清晰，能够让你知道自己是在向它前进还是离它越来越远。 例如想成为一家公司的经理或主管?想在某一天走出去开拓自己的业务，研发自己的产品？</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1562994977456-d5af47d6-e8bc-41e1-9332-2dc5caaa69d5.png" alt=""></p><p>很多人认为目标太过于大，不容易实现，这也是为什么需要设立小目标的原因。实现目标的过程，就好比航海，小目标可以让你航行轨道始终控制在正确的方向上，激励你朝着更大的目标前进。大目标如果没有分解成小目标，你很容易偏离航向，迷失在茫茫大海之中。</p><p>举个例子：</p><p>职业上，我想成为一个能够影响互联网行业发展的专家。</p><p>在实现目标的过程中，我的必经之路是踏入行业，掌握行业的某种技能，考核的标准是：能够通过自己掌握的技能，实现就业。<br>经过在行业中的几年摸爬滚打，不断提升自己技术（专业能力）、积累人脉（交际能力），慢慢打磨自己向高手靠拢，衡量的标准是是否能跟其他高手/专家进行平等对话（这里的平等对话，并不是低人一等的意思，而是互相交流过程中能够相互传递信息，而不是不知所云）。<br>越往上走，你会发现你的视野正在变化，可以看到别人所看不到，能够影响甚至引领行业发展的东西正等着你去挖掘。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1562996074814-ec079c9f-721d-4ce2-afa3-baca30fd6ea8.png?x-oss-process=image/resize,w_1492" alt=""></p><p>要实现目标的整个过程，那我可能会切割成如下小目标：</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1562999854321-11ddde78-ee69-4053-b6aa-50c0f012932d.png" alt=""></p><h2 id="承担更多的责任">承担更多的责任</h2><p>逼着自己一路前行的方式方法很多，但责任是永远是鞭策你自我成长最有效的途径。如果你自驱能力很强，那我恭喜你哈。如果不是，请你在有任何机会去承担更多责任时，主动去承担，接受挑战。</p><p>很多人会问，假如没有被赋予更多责任怎么办？</p><ul><li><p>主动寻找机会。通常没有人愿意涉足的领域是搜寻机会最好的地方。以程序员来说，可能有一个没人愿意碰的遗留应用，或者代码库里的某个没人敢去碰的模块。正因为没有人愿意碰、没人敢去碰，所以没人跟你抢，这就成为了你日益强大的阵营。如果你能把沼泽变为良田，你也就展现了自己的价值。</p></li><li><p>间接承担责任。最好的方式是成为团队中其他人的导师，自愿帮助新人加速成长，为任何有需要的人提供帮助。通过介入和解决别人的问题，你不仅可以学到更多自己专业之外的知识，而且随着时间的推移，你还能在团队中逐步树立影响力。</p></li></ul><h2 id="解决问题而不是来抱怨问题">解决问题，而不是来抱怨问题</h2><p>在任何组织中，总是有很多人会告诉你为什么这个想法行不通，那个问题太难，这个问题不适合我来做，更适合谁去做。这样的人不胜枚举。千万不要成为他们中的一员。相反，你要成为那个永远能为各种问题找到解决方案，并执行落地这些解决方案以获得成果的人。成为这种人也是获得晋升的可靠方法。如果你能解决别人无法解决或不愿解决的问题，无论在哪家公司，你都能轻而易举地成为最有价值的人。</p><h2 id="掌握快速自我学习的能力">掌握快速自我学习的能力</h2><p>很多程序员被绕进了学习新技术、新编程语言、新框架的漩涡，感觉学习的压力很大，怎么爬也爬不出来。通常，这种压力是自我造成的。</p><p>在我刚出来工作的时候，我学习技术的主要途径就是买一本书，然后只有通读完全书后，我才会将自己学到的技术应用于项目实践中。这个方法，确实能学到东西，但是效率很低，在实践过程中，还得经常回顾书的内容，来弥补自己在学习过程中遗漏的问题。</p><p>通常在业务发展的过程中，技术选型是不会等待你学习好一门技术才投入到业务中的。这便迫使我们去寻找更好的自学方法，能在有限的时间内吸收、掌握所需内容即可。例如我在已有 React 开发经验的情况下，只花了 1 天左右零碎的时间，通过对比 React 与 Vue 的语法区别，然后在 JSBin (<a href="http://jsbin.com" target="_blank" rel="noopener">http://jsbin.com</a>) 中试跑 Demo，第二天便可以将 Vue 投入到项目开发中去。</p><p>这其实是一个筛选学习内容、动手操作再到学以致用的过程，这个过程可以不断循环，不断吸收更多的知识。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563001416773-405fedae-7ec7-4690-b55f-e303ca7e9a72.png" alt=""></p><p>这个方法可以高效地掌握一门技术，而无需通晓全部细节。通过在业务实践项目中不断暴漏问题、解决问题、总结问题，你会发现所有技术问题，慢慢都会收拢到一起，逐渐丰富你的经验，最终你便开始能够解决“某一类问题”，而不是“某一个问题”，随着你能够解决问题的类型越多，你融会贯通的能力就会越强。</p><h2 id="找出自己的短板并消灭它">找出自己的短板，并消灭它</h2><p>专注于自身强项，这没什么不妥，但有时候，如果弱点得不到解决，通常会成为你的职业或生活的绊脚石。我们每个人都有弱点。我们能发现并消除自身的短板越多，长久来看我们从中受益越多----可以参考木桶效益。</p><p>很遗憾的是，每个人身上大多数的短板，自己只能隐约觉察到。对于自己不知道的，你很难清楚地意识到，也很容易忽略。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563002803796-5fd0afd6-11bd-4433-96a4-ea20abf2a587.png" alt=""></p><p>那么我们如何找到自己的短板呢？旁观者清、当局者迷的道理大家都知道，但通常人都不太喜欢逆耳的声音，所以别人往往也不会很直接的指出你的短板。</p><p>这种情况下，我们可以通过如下尝试：</p><ul><li><p>自身主动与他人做对比：同样一件事情，人家做到什么程度，你能做到什么程度，人家是怎么做的，你是怎么做的，总的来说，不比不知道，一比吓一跳。通过比较你就知道自己的思路，行动的差距在哪里。</p></li><li><p>在反思中找到自己的短板：有时候做一个事情，不顺利，失败。这时候虽然很沮丧，但是如果能够在沮丧中反思自己，为什么会出现这样的错误，如果当时怎么样处理就会好一些，由此就知道缺少哪一方面的短板了。</p></li><li><p>有一两个知己朋友也会起到很大的作用，虚心吸收朋友指出的问题，并珍惜你俩的基友吧。</p></li><li><p>专注于自己的领域的同时，也有扩宽自己的视野，涉猎不同领域渠道的信息。</p></li></ul><h2 id="合理规划时间提高生产力">合理规划时间，提高生产力</h2><p>多年来，我尝试过不少提升生产力的方法，目前我用的是四象限工作事项管理法和番茄时间管理法组合的方式。</p><h3 id="番茄时间管理法">番茄时间管理法</h3><p>第一次使用番茄工作法的时候，我并没有严格做到它规定的要求。我只是每天用它来设置若干个“25分钟”的番茄钟。我并没有留意自己每天完成了几个番茄钟，也没有估算某项任务要用掉几个番茄钟；因此我并没有从中受益。只是简单认为整个方法就是让你在一个时间段内保持专注。</p><p>直到后来我决定严格地使用番茄时间管理法，发现自己潜移默化地逐渐有能力、可量化去真正评估自己每天可以完成的工作量。通过跟踪自己一天内完成了多少个番茄钟，并为每天要完成的番茄钟的数量设定目标。今后每次项目中，需要评估工作量、估算工时，便发挥了番茄时间管理法真正的威力。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563004394385-f2460f92-19e2-487b-b3e4-1fa4dc0c3a09.png" alt=""></p><h3 id="四象限工作法">四象限工作法</h3><p>那四象限工作法如何与番茄时间管理结合使用呢？</p><p>使用番茄工作法，你可以把每周看作是由有限个番茄钟组成的。想在每周完成一定数量的任务?你要搞清楚自己一周能完成多少个番茄钟，并相应地设置任务的优先级。通过计算自己完成的番茄钟的数量，可以确切知道自己一周完成了多少任务。</p><p>这里有个有意思的问题：如果你没能完成自己设定的任务，但是却用完了足够数量的番茄钟怎么办？</p><p>某些情况下，我们总是幻想着自己可以在一周内完成超出自己实际能力许多的工作，过高地估计了自己的能力而低估了完成任务所需的时间。这个时候，我们就非常有必要给各个任务项设置的优先级了，将你每周需要完成的任务按照重要、紧急划分成四类：重要紧急、重要不紧急、紧急不重要、不重要不紧急。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563004203908-40f1d81e-f0c3-469d-a020-e12ec758528f.png?x-oss-process=image/resize,w_944" alt=""></p><p>有人过来问，这两个分别是什么软件？</p><p>这个给大家介绍下哈，分别是Focus Matrix和Be Focused。 这两款软件数据是可以打通的，同时提供了手机版。</p><p><img src="https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/3e8b20818459d99ee23809e03d98bd1e.png" alt=""></p><p>当然也可以不使用软件的方式，这只是一个时间和任务管理的方法论，你也可以买一个沙漏⏳管理时间和便签管理任务，使用得当的话，也是可以达到一样效果的。</p><h2 id="打造个人影响力">打造个人影响力</h2><p>事实上个人影响力的提升一定不是一朝一夕的事情，也不是光设定目标就可以达成的。确实有许多潜移默化和机缘巧合融合在里面。我所谈的也仅仅是方法论，需要大家去践行，再去提炼和总结。这里总结了三步：</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563006995937-30960fb3-ab8a-4177-8be4-3b0fe075cf34.png" alt=""></p><p>第一步是分析自己，很多人觉得我怎么会不知道自己是个什么人呢？抱歉，绝大部分80%的人呢，都是无法认清自己，一个可以客观评价自己的人，在自我认知部分就会更精准。最简单可量化的方式就是从技能、性感等方面去绘画雷达图，从而客观的评价自己。</p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563007711443-58187a00-150e-463d-bfe5-a46699784340.png?x-oss-process=image/resize,w_482" alt=""><br><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563007735585-2b7301e7-e098-4052-b153-eb753d250f8a.png?x-oss-process=image/resize,w_436" alt=""><br><img src="https://cdn.nlark.com/yuque/0/2019/png/89257/1563007787194-0f04689a-cbc7-4e37-89c7-b5c28ba1beb6.png?x-oss-process=image/resize,w_444" alt=""></p><p>第二步就到了定位自己，这个其实跟产品的定位有点类似，为什么有些品牌可以成功，确实与其对于自身产品的高度认知和品牌价值的集中萃取，一眼就可以做识别和关联用户。那么对于我们人来说也是这样的，我知道自己是什么样的人之后，我也会清晰的知道，自己适合往什么样的方向去发展，找到自己的定位。</p><p>第三步是形成标签，在你过往的各种各样的人生经历中，你需要提取一些标签，固化自己，让自己成为斜杠青年，让陌生的人在认识你的时候，可以更快的识别。</p><blockquote><p>本文转载自：「开源中国」，原文：<a href="https://tinyurl.com/ydxxfv7u%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/ydxxfv7u，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一篇从 “人” (而非技术也非管理)的角度，聚焦于自身职业发展方方面面的文章，包括职业、学习、生产力、影响力等。&lt;/p&gt;
&lt;h2 id=&quot;拥有商业心态&quot;&gt;拥有商业心态&lt;/h2&gt;
&lt;p&gt;你所能犯的最大错误就是相信自己是在为别人工作，职业发展的驱动力一定是来自个体本身，而不是领导、公司，因为职业发展是属于你自己的。如果你真的想在这个充满竞争的世界里脱颖而出，那么你首先必须制订一个坚实可靠而又深思熟虑的计划，学会主动管理自己的职业生涯。&lt;/p&gt;
&lt;p&gt;职业生涯中要做的第一件事便是，转变你的心态。而商业心态对于管理职业规划至关重要。如果你已经习惯于领取一份固定的薪酬，便会很容易导致你产生：你只是在为这家公司打工的谋生心态。尽管在你的职业生涯的某个特定时间段里，你可能确实是在为某家公司打工，但是千万不要因此固化了你的整个职业生涯。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/89257/1562990262645-1c5cf817-03dd-4b0d-82d4-55e4dca112b0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;那么心态该如何转变呢？首先你要把自己当作一个企业去思考，然后把雇主当作是你这个企业的一个客户。当然，你可能只有这么一个客户，你所有的收入都是从这一个客户得来的，但是这种诠释雇用关系的方式可以将你从雇佣关系的弱势地位转换成为自我治理和自我引导的主动地位，同时，心态转变后能更有利于你做出良好的商业决策。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="思想" scheme="https://www.hi-linux.com/tags/%E6%80%9D%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>浅谈 MySQL 优化实施方案</title>
    <link href="https://www.hi-linux.com/posts/34535.html"/>
    <id>https://www.hi-linux.com/posts/34535.html</id>
    <published>2020-05-24T01:16:00.000Z</published>
    <updated>2020-05-24T08:56:22.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在进行 MySQL 的优化之前必须要了解的就是 MySQL 的查询过程，很多的查询优化工作实际上就是遵循一些原则让 MySQL 的优化器能够按照预想的合理方式运行而已。</p><p><img src="https://images2017.cnblogs.com/blog/1190037/201801/1190037-20180106134347674-1416660436.png" alt=""></p><p>图 - MySQL查询过程</p><h3 id="优化的哲学">优化的哲学</h3><p>优化有风险，涉足需谨慎</p><h4 id="优化可能带来的问题">优化可能带来的问题</h4><ul><li>优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统。</li><li>优化手段本来就有很大的风险，只不过你没能力意识到和预见到！</li><li>任何的技术可以解决一个问题，但必然存在带来一个问题的风险！</li><li>对于优化来说解决问题而带来的问题,控制在可接受的范围内才是有成果。</li><li>保持现状或出现更差的情况都是失败！</li></ul><h4 id="优化的需求">优化的需求</h4><ul><li>稳定性和业务可持续性,通常比性能更重要！</li><li>优化不可避免涉及到变更，变更就有风险！</li><li>优化使性能变好，维持和变差是等概率事件！</li><li>切记优化,应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化！</li><li>所以优化工作,是由业务需要驱使的！！！</li></ul><h4 id="优化由谁参与">优化由谁参与</h4><p>在进行数据库优化时，应由数据库管理员、业务部门代表、应用程序架构师、应用程序设计人员、应用程序开发人员、硬件及系统管理员、存储管理员等，业务相关人员共同参与。</p><h3 id="优化思路">优化思路</h3><h4 id="优化什么">优化什么</h4><p>在数据库优化上有两个主要方面：即安全与性能。</p><ul><li>安全 —&gt; 数据可持续性</li><li>性能 —&gt; 数据的高性能访问</li></ul><h4 id="优化的范围有哪些">优化的范围有哪些</h4><p><em>存储、主机和操作系统方面:</em></p><ul><li>主机架构稳定性</li><li>I/O 规划及配置</li><li>Swap 交换分区</li><li>OS 内核参数和网络问题</li></ul><p><em>应用程序方面:</em></p><ul><li>应用程序稳定性</li><li>SQL语句性能</li><li>串行访问资源</li><li>性能欠佳会话管理</li><li>这个应用适不适合用 MySQL</li></ul><p><em>数据库优化方面:</em></p><ul><li>内存</li><li>数据库结构(物理&amp;逻辑)</li><li>实例配置</li></ul><blockquote><p>说明：不管是在，设计系统，定位问题还是优化，都可以按照这个顺序执行。</p></blockquote><h4 id="优化维度">优化维度</h4><p><em>数据库优化维度有四个:</em></p><p>硬件、系统配置、数据库表结构、SQL及索引</p><p><img src="https://images2017.cnblogs.com/blog/1190037/201801/1190037-20180108160315254-1073768194.png" alt=""></p><p><em>优化选择</em></p><ul><li>优化成本:硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引</li><li>优化效果:硬件&lt;系统配置&lt;数据库表结构&lt;SQL及索引</li></ul><h3 id="优化工具有啥">优化工具有啥？</h3><h4 id="数据库层面">数据库层面</h4><p>检查问题常用工具</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql</span><br><span class="line">msyqladmin                                 mysql客户端，可进行管理操作</span><br><span class="line">mysqlshow                                  功能强大的查看shell命令</span><br><span class="line">show [SESSION | GLOBAL] variables          查看数据库参数信息</span><br><span class="line">SHOW [SESSION | GLOBAL] STATUS             查看数据库的状态信息</span><br><span class="line">information_schema                         获取元数据的方法</span><br><span class="line">SHOW ENGINE INNODB STATUS                  Innodb引擎的所有状态</span><br><span class="line">SHOW PROCESSLIST                           查看当前所有连接session状态</span><br><span class="line">explain                                    获取查询语句的执行计划</span><br><span class="line">show index                                 查看表的索引信息</span><br><span class="line">slow-log                                   记录慢查询语句</span><br><span class="line">mysqldumpslow                              分析slowlog文件的</span><br></pre></td></tr></table></figure><p>不常用但好用的工具</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">zabbix                  监控主机、系统、数据库（部署zabbix监控平台）</span><br><span class="line">pt-query-digest         分析慢日志</span><br><span class="line">mysqlslap               分析慢日志</span><br><span class="line">sysbench                压力测试工具</span><br><span class="line">mysql profiling         统计数据库整体状态工具    </span><br><span class="line">Performance Schema      mysql性能状态统计的数据</span><br><span class="line">workbench               管理、备份、监控、分析、优化工具（比较费资源）</span><br></pre></td></tr></table></figure><h4 id="数据库层面问题解决思路">数据库层面问题解决思路</h4><p><em>一般应急调优的思路：</em></p><p>针对突然的业务办理卡顿，无法进行正常的业务处理！需要立马解决的场景！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1、show processlist</span><br><span class="line">2、explain  select id ,name from stu where name&#x3D;&#39;clsn&#39;; # ALL  id name age  sex</span><br><span class="line"></span><br><span class="line">            select id,name from stu  where id&#x3D;2-1 函数 结果集&gt;30;</span><br><span class="line"></span><br><span class="line">　　　 show index from table;</span><br><span class="line"></span><br><span class="line">3、通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题</span><br><span class="line">4、show status  like &#39;%lock%&#39;;    # 查询锁状态</span><br><span class="line">kill SESSION_ID;   # 杀掉有问题的session</span><br></pre></td></tr></table></figure><p><em>常规调优思路：</em></p><p>针对业务周期性的卡顿，例如:在每天 10-11 点业务特别慢，但是还能够使用，过了这段时间就好了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、查看 slowlog，分析 slowlog，分析出查询慢的语句。</span><br><span class="line">2、按照一定优先级，进行一个一个的排查所有慢语句。</span><br><span class="line">3、分析 top sql，进行 explain 调试，查看语句执行时间。</span><br><span class="line">4、调整索引或语句本身。</span><br></pre></td></tr></table></figure><h4 id="系统层面">系统层面</h4><p><em>CPU 方面</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vmstat、sar top、htop、nmon、mpstat</span><br></pre></td></tr></table></figure><p><em>内存</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">free 、ps -aux</span><br></pre></td></tr></table></figure><p><em>IO设备（磁盘、网络）</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iostat 、 ss  、 netstat 、 iptraf、iftop、lsof</span><br></pre></td></tr></table></figure><p>vmstat 命令说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Procs：r 显示有多少进程正在等待 CPU 时间。b 显示处于不可中断的休眠的进程数量。在等待 I&#x2F;O。</span><br><span class="line">Memory：swpd 显示被交换到磁盘的数据块的数量。未被使用的数据块，用户缓冲数据块，用于操作系统的数据块的数量。</span><br><span class="line">Swap：操作系统每秒从磁盘上交换到内存和从内存交换到磁盘的数据块的数量。s1 和 s0 最好是 0。</span><br><span class="line">Io：每秒从设备中读入 b1 的写入到设备 b0 的数据块的数量。反映了磁盘 I&#x2F;O。</span><br><span class="line">System：显示了每秒发生中断的数量 (in) 和上下文交换 (cs) 的数量。</span><br><span class="line">Cpu：显示用于运行用户代码，系统代码，空闲，等待 I&#x2F;O 的 CPU 时间。</span><br></pre></td></tr></table></figure><p>iostat 命令说明:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">实例命令：  iostat -dk 1 5</span><br><span class="line">　　　　    iostat -d -k -x 5 （查看设备使用率（%util）和响应时间（await））</span><br><span class="line"></span><br><span class="line">tps：该设备每秒的传输次数。“一次传输”意思是“一次I&#x2F;O请求”。多个逻辑请求可能会被合并为“一次I&#x2F;O请求”。</span><br><span class="line">iops ：硬件出厂的时候，厂家定义的一个每秒最大的 IO 次数。</span><br><span class="line">&quot;一次传输&quot;请求的大小是未知的。</span><br><span class="line">kB_read&#x2F;s：每秒从设备（drive expressed）读取的数据量。</span><br><span class="line">KB_wrtn&#x2F;s：每秒向设备（drive expressed）写入的数据量。</span><br><span class="line">kB_read：读取的总数据量。</span><br><span class="line">kB_wrtn：写入的总数量数据量，这些单位都为Kilobytes。</span><br></pre></td></tr></table></figure><h4 id="系统层面问题解决办法">系统层面问题解决办法</h4><p>你认为到底负载高好，还是低好呢？</p><p>在实际的生产中，一般认为 Cpu 只要不超过 90% 都没什么问题 。</p><p>当然不排除下面这些特殊情况：</p><ul><li>问题一：Cpu 负载高，IO 负载低</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">内存不够</span><br><span class="line"></span><br><span class="line">磁盘性能差</span><br><span class="line"></span><br><span class="line">1. SQL 问题 ------&gt; 去数据库层，进一步排查 SQL 问题</span><br><span class="line">2. IO 出问题了（磁盘到临界了、Raid 设计不好、Raid 降级、锁、在单位时间内 TPS 过高）</span><br><span class="line">3. TPS 过高: 大量的小数据 IO、大量的全表扫描</span><br></pre></td></tr></table></figure><ul><li>问题二：IO 负载高，Cpu 负载低</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">大量小的 IO 写操作：</span><br><span class="line"></span><br><span class="line">1. autocommit   ，产生大量小 IO</span><br><span class="line">2. IO&#x2F;PS,磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的 IO 次数。</span><br><span class="line"></span><br><span class="line">大量大的IO 写操作</span><br><span class="line"></span><br><span class="line">1. SQL问题的几率比较大</span><br></pre></td></tr></table></figure><ul><li>问题三：IO 和 Cpu 负载都很高</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 硬件不够了或 SQL 存在问题</span><br></pre></td></tr></table></figure><h3 id="基础优化">基础优化</h3><h4 id="优化思路">优化思路</h4><p><em>定位问题点吮吸</em></p><p>硬件 --&gt; 系统 --&gt; 应用 --&gt; 数据库 --&gt; 架构（高可用、读写分离、分库分表）</p><p><em>处理方向</em></p><p>明确优化目标、性能和安全的折中、防患未然。</p><h4 id="硬件优化">硬件优化</h4><ul><li>主机方面：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">根据数据库类型，主机 CPU 选择、内存容量选择、磁盘选择：</span><br><span class="line"></span><br><span class="line">1. 平衡内存和磁盘资源。</span><br><span class="line">2. 随机的 I&#x2F;O 和顺序的 I&#x2F;O。</span><br><span class="line">3. 主机 RAID卡的 BBU (Battery Backup Unit) 关闭。</span><br></pre></td></tr></table></figure><ul><li>Cpu 的选择：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Cpu 的两个关键因素：核数、主频，根据不同的业务类型进行选择：</span><br><span class="line"></span><br><span class="line">1. Cpu 密集型：计算比较多，OLTP--&gt;主频很高的 Cpu、核数还要多。</span><br><span class="line">2. IO 密集型：查询比较多，OLAP--&gt;核数要多，主频不一定高的。</span><br></pre></td></tr></table></figure><ul><li>内存的选择：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. OLAP 类型数据库，需要更多内存，和数据获取量级有关。</span><br><span class="line">2. OLTP 类型数据一般内存是 Cpu 核心数量的 2 倍到 4 倍，没有最佳实践。</span><br></pre></td></tr></table></figure><ul><li>存储方面：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1. 根据存储数据种类的不同，选择不同的存储设备。</span><br><span class="line">2. 配置合理的 RAID 级别(Raid5、Raid10、热备盘)。</span><br><span class="line">3. 对于操作系统来讲，不需要太特殊的选择，最好做好冗余（Raid 1）（SSD、SAS 、SATA）</span><br><span class="line">4. Raid卡：主机 Raid 卡选择：</span><br><span class="line">  4.1 实现操作系统磁盘的冗余（Raid 1）。</span><br><span class="line">  4.2 平衡内存和磁盘资源。</span><br><span class="line">  4.3  随机的 I&#x2F;O 和顺序的 I&#x2F;O。</span><br><span class="line">  4.4 主机 Raid卡的 BBU (Battery Backup Unit) 要关闭。</span><br></pre></td></tr></table></figure><ul><li>网络设备方面：</li></ul><p>使用流量支持更高的网络设备（交换机、路由器、网线、网卡、HBA卡）。</p><blockquote><p>注意：以上这些规划应该在初始设计系统时就应该考虑好。</p></blockquote><h4 id="服务器硬件优化">服务器硬件优化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、物理状态灯。</span><br><span class="line">2、自带管理设备：远程控制卡（FENCE 设备：IPMI、ILO、IDARC），开关机、硬件监控。</span><br><span class="line">3、第三方的监控软件、设备（Snmp、Agent）对物理设施进行监控。</span><br><span class="line">4、存储设备：自带的监控平台。EMC2（HP 收购了）、日立（hds）、IBM低端 OEM hds，高端存储是自己技术，华为存储。</span><br></pre></td></tr></table></figure><h4 id="系统优化">系统优化</h4><ul><li>Cpu：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 基本不需要调整，在硬件选择方面下功夫即可。</span><br></pre></td></tr></table></figure><ul><li>内存：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 基本不需要调整，在硬件选择方面下功夫即可。</span><br></pre></td></tr></table></figure><ul><li>Swap：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. MySQL 尽量避免使用 Swap。</span><br><span class="line">2. 阿里云的服务器中默认swap为0</span><br></pre></td></tr></table></figure><ul><li>IO ：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. Raid、No LVM、 Ext 4或 XFS、SSD、IO 调度策略。</span><br></pre></td></tr></table></figure><ul><li>Swap 调整方法</li></ul><p>要关闭 Swap 分区，可使用以下方法</p><ol><li>临时关闭方法</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修改 /proc/sys/vm/swappiness 的内容改成 0 。</span><br></pre></td></tr></table></figure><ol start="2"><li>永久关闭方法</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/sysctl.conf 文件中添加 vm.swappiness=0 。</span><br></pre></td></tr></table></figure><p>这个参数决定了 Linux 是倾向于使用 Swap，还是倾向于释放文件系统 Cache。在内存紧张的情况下，数值越低越倾向于释放文件系统Cache。</p><p>当然，这个参数只能减少使用 Swap 的概率，并不能避免 Linux 使用 Swap。</p><ul><li>开启 O_DIRECT 模式</li></ul><p>修改 MySQL 的配置参数 innodb_flush_method，这种情况下，InnoDB 的 Buffer Pool 会直接绕过文件系统 Cache 来访问磁盘，但是 Redo log 依旧会使用文件系统 Cache。</p><p>值得注意的是，Redo log 是覆写模式的，即使使用了文件系统的 Cache，也不会占用太多。</p><ul><li>IO 调度策略</li></ul><ol><li>临时修改为 deadline</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ echo deadline&gt;&#x2F;sys&#x2F;block&#x2F;sda&#x2F;queue&#x2F;scheduler</span><br></pre></td></tr></table></figure><ol start="2"><li>永久修改</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vi /boot/grub/grub.conf</span><br><span class="line"></span><br><span class="line">更改到如下内容:</span><br><span class="line"></span><br><span class="line">kernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet</span><br></pre></td></tr></table></figure><h4 id="系统参数调整">系统参数调整</h4><p><em>Linux 系统内核参数优化</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/sysctl.conf</span><br><span class="line"><span class="comment"># 用户端口范围</span></span><br><span class="line">net.ipv4.ip_local_port_range = 1024 65535  </span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 4096 </span><br><span class="line">net.ipv4.tcp_fin_timeout = 30 </span><br><span class="line"><span class="comment"># 系统最大文件句柄，控制的是能打开文件最大数量</span></span><br><span class="line">fs.file-max=65535</span><br></pre></td></tr></table></figure><p><em>用户限制参数</em></p><p>（MySQL 可以不设置以下配置）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vim    &#x2F;etc&#x2F;security&#x2F;limits.conf </span><br><span class="line">    * soft nproc 65535</span><br><span class="line">    * hard nproc 65535</span><br><span class="line">    * soft nofile 65535</span><br><span class="line">    * hard nofile 65535</span><br></pre></td></tr></table></figure><h4 id="应用优化">应用优化</h4><ol><li>业务应用和数据库应用独立。</li><li>安装图形界面的服务器不要启动图形界面  runlevel 3 。</li><li>防火墙：Iptables、Selinux 等其他无用服务(关闭)。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">chkconfig --level 23456 acpid off</span><br><span class="line">chkconfig --level 23456 anacron off</span><br><span class="line">chkconfig --level 23456 autofs off</span><br><span class="line">chkconfig --level 23456 avahi-daemon off</span><br><span class="line">chkconfig --level 23456 bluetooth off</span><br><span class="line">chkconfig --level 23456 cups off</span><br><span class="line">chkconfig --level 23456 firstboot off</span><br><span class="line">chkconfig --level 23456 haldaemon off</span><br><span class="line">chkconfig --level 23456 hplip off</span><br><span class="line">chkconfig --level 23456 ip6tables off</span><br><span class="line">chkconfig --level 23456 iptables  off</span><br><span class="line">chkconfig --level 23456 isdn off</span><br><span class="line">chkconfig --level 23456 pcscd off</span><br><span class="line">chkconfig --level 23456 sendmail  off</span><br><span class="line">chkconfig --level 23456 yum-updatesd  off</span><br></pre></td></tr></table></figure><p>另外，思考将来我们的业务是否真的需要 MySQL，还是使用其他种类的数据库。用数据库的最高境界就是不用数据库。</p><h3 id="数据库优化">数据库优化</h3><p>SQL优化方向：执行计划、索引、SQL 改写。</p><p>架构优化方向：高可用架构、高性能架构、分库分表。</p><h4 id="数据库参数优化">数据库参数优化</h4><ol><li>实例整体（高级优化，扩展）</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">thread_concurrency       # 并发线程数量个数</span><br><span class="line">sort_buffer_size         # 排序缓存</span><br><span class="line">read_buffer_size         # 顺序读取缓存</span><br><span class="line">read_rnd_buffer_size     # 随机读取缓存</span><br><span class="line">key_buffer_size          # 索引缓存</span><br><span class="line">thread_cache_size        # (1G—&gt;8, 2G—&gt;16, 3G—&gt;32, &gt;3G—&gt;64)</span><br></pre></td></tr></table></figure><ol start="2"><li><p>连接层（基础优化）</p><p>设置合理的连接客户和连接方式</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">max_connections           # 最大连接数，看交易笔数设置    </span><br><span class="line">max_connect_errors        # 最大错误连接数，能大则大</span><br><span class="line">connect_timeout           # 连接超时</span><br><span class="line">max_user_connections      # 最大用户连接数</span><br><span class="line">skip-name-resolve         # 跳过域名解析</span><br><span class="line">wait_timeout              # 等待超时</span><br><span class="line">back_log                  # 可以在堆栈中的连接数量</span><br></pre></td></tr></table></figure><ol start="3"><li>SQL层（基础优化）</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query_cache_size： 查询缓存   &gt;&gt;&gt;  OLAP类型数据库,需要重点加大此内存缓存，但是一般不会超过GB。对于经常被修改的数据，缓存会立马失效。我们可以使用内存数据库（Redis、Memecache），替代它的相应功能。</span><br></pre></td></tr></table></figure><h4 id="存储引擎层-innodb-基础优化参数">存储引擎层（ Innodb 基础优化参数）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">default-storage-engine</span><br><span class="line">innodb_buffer_pool_size       # 没有固定大小，50% 测试值，看看情况再微调。但是尽量设置不要超过物理内存 70%。</span><br><span class="line">innodb_file_per_table&#x3D;(1,0)</span><br><span class="line">innodb_flush_log_at_trx_commit&#x3D;(0,1,2) # 1 是最安全的，0 是性能最高，2折中。</span><br><span class="line">binlog_sync</span><br><span class="line">Innodb_flush_method&#x3D;(O_DIRECT, fdatasync)</span><br><span class="line">innodb_log_buffer_size        # 100M 以下。</span><br><span class="line">innodb_log_file_size          # 100M 以下。</span><br><span class="line">innodb_log_files_in_group     # 5个成员以下,一般 2-3 个够用（iblogfile 0-N）。</span><br><span class="line">innodb_max_dirty_pages_pct   # 达到百分之 75 的时候刷写内存脏页到磁盘。</span><br><span class="line">log_bin</span><br><span class="line">max_binlog_cache_size         # 可以不设置。</span><br><span class="line">max_binlog_size               # 可以不设置。</span><br><span class="line">innodb_additional_mem_pool_size    #小于2G内存的机器，推荐值是 20 M。32G 内存以上 100M。</span><br></pre></td></tr></table></figure><h3 id="参考文献">参考文献</h3><p>[1]  <a href="https://www.cnblogs.com/zishengY/p/6892345.html" target="_blank" rel="noopener">https://www.cnblogs.com/zishengY/p/6892345.html</a><br>[2]  <a href="https://www.jianshu.com/p/d7665192aaaf" target="_blank" rel="noopener">https://www.jianshu.com/p/d7665192aaaf</a></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;p&gt;在进行 MySQL 的优化之前必须要了解的就是 MySQL 的查询过程，很多的查询优化工作实际上就是遵循一些原则让 MySQL 的优化器能够按照预想的合理方式运行而已。&lt;/p&gt;
&lt;p&gt;&lt;img
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="MySQL" scheme="https://www.hi-linux.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>浅谈中台</title>
    <link href="https://www.hi-linux.com/posts/22676.html"/>
    <id>https://www.hi-linux.com/posts/22676.html</id>
    <published>2020-05-24T01:15:00.000Z</published>
    <updated>2020-05-24T08:56:22.000Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="背景">背景</h2><p>自从阿里巴巴现任CEO逍遥子在2015年提出”大中台，小前台”战略以来，关于”什么是中台”，可谓是一石激起千层浪，大量文章在描述什么是中台。而不懂的人看完后依旧是云里雾里，我们经常听到一些词：”业务中台”，”技术中台”, “系统中台”等，我相信很多同学都会懵逼。今天我们就来彻底的理解下什么是中台和中台战略。</p><h2 id="中台的本质理解">中台的本质理解</h2><p>凡是能帮助我们快速的生产产品而不需要大量重复性研发的系统，就可以称之为中台。这句话同样适用于硬件产品。举个例子，苹果公司的手机生产线平台，早期每次设计出一款新的苹果手机时都需要对生产线上的机器人做大量修改才能满足生产一款新iphone的需求。随着科技进步，苹果对生产线做了升级。每次设计师设计出新的iphone时，只需要在一个系统中进行任务编排和参数配置，整个生产线即可投入新款iphone的生产之中，这样的一套生产线平台就可以称之为”Iphone生产中台”。</p><p>为了进一步的解释中台，了解它的词性，我们来理解下一个日常生活中经常用到的词——”帮手”，我们经常这么说：</p><ul><li><p>王强真是我的好帮手，每次做手术时，他都知道我下一步想要什么。</p></li><li><p>你给我找个帮手来，帮我把电视抬上楼。</p></li><li><p>这个打蛋器真是家庭主妇的好帮手。</p></li></ul><a id="more"></a><p>我们几乎不会这么去问”什么是帮手”，显得很傻。同样的，真正了解了什么是中台和中台的词性后，我们也不太会问”什么是中台”。而换些问法就对了：</p><ul><li><p>你们公司发布新产品这么快，是用了什么产品中台？</p></li><li><p>你们公司技术开发一个新应用这么快，系统中台应该建设的不错吧！</p></li><li><p>这次我们接入支付功能这么快，多亏了你们支付中台。</p></li></ul><p>所以中台系统最为本质的含义，就是低成本高效率生产产品的系统。金融公司隔三差五的就能生成一个新的贷款产品，这就依赖强大的产品中台；公司一周就开发一个新业务应用，这就很可能是得益于其系统中台的强大；阿里内部强调的系统中台建设，就是将支付、商品、会员等经典的电商领域系统做到足够通用和可编排，减少重复的开发成本，任何对接系统中台的应用就是使用了某个中台的产品。比如接入了支付中台，代表的就是使用了一个支付产品（需要一定的视角转换），具体的接入可能包含申请账号，配置和编排支付流程，投入使用等。</p><h2 id="中台的形式和建设之路">中台的形式和建设之路</h2><p>首先，中台并不拘泥于其存在形式，它可以是PaaS，SaaS或者是PaaS+SaaS，也可能就是一个后台网站，甚至是一个PC应用。记住它的本质：低成本高效率生产新产品。 所以中台战略适用于任意规模的公司，用编程思想来看，这就是一种提高复用性的设计，降低的是研发成本，提高的快速试错和上线的能力。不过需要说明的是，大公司的中台战略和小公司的中台战略大概率是不一样的，用大公司的中台战略去指导小公司的研发是不现实的，也是不明智的。 一般来说，中台建设过程分一下几个步骤：</p><ol><li><p>定义需要快速变化、试错和上线的产品。(如果您都无法清晰的定义自己的产品是啥，那估计是走偏了)。</p></li><li><p>分析产品的属性，哪些是通用的，哪些又是多变的。</p></li><li><p>研发生产产品所需的通用逻辑，用开放式的设计来兼容那些多变的属性。</p></li></ol><p>有同学会提出一开始考虑不到位，很大概率设计的中台不够通用。确实是这样的，中台设计的优秀度很大程度依赖于设计师的经验。中台建设也不是一触而就的，更多的是在对过往工作总结后高度的沉淀和抽象。说到这里估计很多开发同学会产生共鸣了，这和写代码的要求很像。再谈阿里的中台战略，阿里作为一个定位为经济体的大集团公司，其各个BU业务五花八门，并且每个BU都有自己的研发团队。而大部分BU为电商，这就意味着存在大量功能相同的系统，比如订单、商品、支付、会员等。面对如此大的研发成本重合，高层进行了反思——如果将这些通用的逻辑抽象出来，把个性化部分做成配置化，那么一来会节省大量的研发成本（时间和资金），二来可以快速的生产各种业务前台，便于商业模式验证、快速试错或快速占领市场。</p><p>放到小公司，阿里的这种中台建设之路就不适用了，为每个领域去开发一套中台是一件非常奢侈的事。小公司应该聚焦自生的产品，建设具有有限通用性的中台。</p><p>说到这里，中台建设是不是更像一条企业对象优化自生生产过程的必经之路呢？</p><blockquote><p>本文转载自：「TBWORKs’ ZONE」，原文：<a href="https://url.cn/5YLXBrq%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5YLXBrq，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;自从阿里巴巴现任CEO逍遥子在2015年提出”大中台，小前台”战略以来，关于”什么是中台”，可谓是一石激起千层浪，大量文章在描述什么是中台。而不懂的人看完后依旧是云里雾里，我们经常听到一些词：”业务中台”，”技术中台”, “系统中台”等，我相信很多同学都会懵逼。今天我们就来彻底的理解下什么是中台和中台战略。&lt;/p&gt;
&lt;h2 id=&quot;中台的本质理解&quot;&gt;中台的本质理解&lt;/h2&gt;
&lt;p&gt;凡是能帮助我们快速的生产产品而不需要大量重复性研发的系统，就可以称之为中台。这句话同样适用于硬件产品。举个例子，苹果公司的手机生产线平台，早期每次设计出一款新的苹果手机时都需要对生产线上的机器人做大量修改才能满足生产一款新iphone的需求。随着科技进步，苹果对生产线做了升级。每次设计师设计出新的iphone时，只需要在一个系统中进行任务编排和参数配置，整个生产线即可投入新款iphone的生产之中，这样的一套生产线平台就可以称之为”Iphone生产中台”。&lt;/p&gt;
&lt;p&gt;为了进一步的解释中台，了解它的词性，我们来理解下一个日常生活中经常用到的词——”帮手”，我们经常这么说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;王强真是我的好帮手，每次做手术时，他都知道我下一步想要什么。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你给我找个帮手来，帮我把电视抬上楼。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这个打蛋器真是家庭主妇的好帮手。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="分布式" scheme="https://www.hi-linux.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
</feed>
