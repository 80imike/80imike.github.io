<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维之美</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2020-05-23T14:36:13.098Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>5 分钟读透 HTTP 的前世今生</title>
    <link href="https://www.hi-linux.com/posts/49917.html"/>
    <id>https://www.hi-linux.com/posts/49917.html</id>
    <published>2020-05-23T02:14:00.000Z</published>
    <updated>2020-05-23T14:36:13.098Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>HTTP (Hypertext transfer protocol) 翻译成中文是超文本传输协议，是互联网上重要的一个协议。由欧洲核子研究委员会 CERN 的英国工程师 Tim Berners-Lee v 发明的，同时他也是 WWW 的发明人，最初的主要是用于传递通过 HTML 封装过的数据。在 1991 年发布了 HTTP 0.9 版，在 1996 年发布 1.0 版。1997 年是 1.1 版，1.1 版也是到今天为止传输最广泛的版本（初始 RFC 2068 在 1997 年发布， 然后在 1999 年被 RFC 2616 取代，再在 2014 年被 RFC 7230/7231/7232/7233/7234/7235 取代）。2015 年发布了 2.0 版，其极大的优化了 HTTP/1.1 的性能和安全性，而 2018 年发布的 3.0 版，继续优化 HTTP/2，激进地使用 UDP 取代 TCP 协议。目前，HTTP/3 在 2019 年 9 月 26 日 被 Chrome、Firefox、和 Cloudflare 支持。所以我想写下这篇文章，简单地说一下 HTTP 的前世今生，让大家学到一些知识，并希望可以在推动一下 HTTP 标准协议的发展。</p><h2 id="http-09-10">HTTP 0.9 / 1.0</h2><p>0.9 和 1.0 这两个版本，就是最传统的 Request – Response 的模式了。HTTP 0.9 版本的协议简单到极点，请求时不支持请求头，只支持 GET 方法，没了。HTTP 1.0 扩展了 0.9 版，其中主要增加了几个变化：</p><ul><li><p>在请求中加入了 HTTP 版本号，如：GET /coolshell/index.html HTTP/1.0</p></li><li><p>HTTP 开始有 Header了，不管是 Request 还是 Response 都有 Header 了。</p></li><li><p>增加了 HTTP Status Code 标识相关的状态码。</p></li><li><p>还有 Content-Type 可以传输其它的文件了。</p></li></ul><p>我们可以看到，HTTP 1.0 开始让这个协议变得很文明了，一种工程文明。因为：</p><ul><li><p>一个协议有没有版本管理，是一个工程化的象征。</p></li><li><p>Header 可以说是把元数据和业务数据解耦，也可以说是控制逻辑和业务逻辑的分离。</p></li><li><p>Status Code 的出现可以让请求双方以及第三方的监控或管理程序有了统一的认识。最关键是还是控制错误和业务错误的分离。</p></li></ul><blockquote><p>注：国内很多公司 HTTP 无论对错只返回 200，这种把 HTTP Status Code 全部抹掉完全是一种工程界的倒退</p></blockquote><p>但是，HTTP 1.0 性能上有一个很大的问题，那就是每请求一个资源都要新建一个 TCP 链接。而且是串行请求，所以就算网络变快了，打开网页的速度也还是很慢。所以，HTTP 1.0 应该是一个必须要淘汰的协议了。</p><a id="more"></a><h2 id="http11">HTTP/1.1</h2><p>HTTP/1.1 主要解决了 HTTP 1.0 的网络性能的问题，以及增加了一些新的东西：</p><ul><li><p>可以设置 Keepalive 来让 HTTP 重用 TCP 链接，重用 TCP 链接可以省了每次请求都要在广域网上进行的 TCP 的三次握手的巨大开销。这是所谓的 “<strong>HTTP 长链接</strong>” 或是 “<strong>请求响应式的 HTTP 持久链接</strong>”。英文叫 HTTP Persistent Connection.</p></li><li><p>然后支持 Pipeline 网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。（注：非幂等的 POST 方法或是有依赖的请求是不能被 Pipeline 化的）</p></li><li><p>支持 Chunked Responses，也就是说，在 Response 的时候，不必说明 Content-Length 这样，客户端就不能断连接，直到收到服务端的 EOF 标识。这种技术又叫 “<strong>服务端 Push 模型</strong>”，或是 “<strong>服务端 Push 式的 HTTP 持久链接</strong>”</p></li><li><p>还增加了 Cache Control 机制。</p></li><li><p>协议头注增加了 Language、Encoding、Type 等等头，让客户端可以跟服务器端进行更多的协商。</p></li><li><p>还正式加入了一个很重要的头 —— HOST 这样的话，服务器就知道你要请求哪个网站了。因为可以有多个域名解析到同一个 IP 上，要区分用户是请求的哪个域名，就需要在 HTTP 的协议中加入域名的信息，而不是被 DNS 转换过的 IP 信息。</p></li><li><p>正式加入了 OPTIONS 方法，其主要用于 CORS – Cross Origin Resource Sharing 应用。</p></li></ul><p>HTTP/1.1 应该分成两个时代，一个是 2014 年前，一个是 2014 年后。因为 2014 年 HTTP/1.1 有了一组 RFC（7230 /7231/7232/7233/7234/7235），这组 RFC 又叫 “HTTP/2 预览版”。其中影响 HTTP 发展的是两个大的需求：</p><ul><li><p>一个需要是加大了 HTTP 的安全性，这样就可以让 HTTP 应用得广泛。比如，使用 TLS 协议。</p></li><li><p>另一个是让 HTTP 可以支持更多的应用，在 HTTP/1.1 下，HTTP 已经支持四种网络协议：</p><ul><li><p>传统的短链接。</p></li><li><p>可重用 TCP 的的长链接模型。</p></li><li><p>服务端 Push 的模型。</p></li><li><p>WebSocket 模型。</p></li></ul></li></ul><p>自从 2005 年以来，整个世界的应用 API 越来多，这些都造就了整个世界在推动 HTTP 的前进。我们可以看到，<strong>自 2014 的 HTTP/1.1 以来，这个世界基本的应用协议的标准基本上都是向 HTTP 看齐了。也许 2014 年前，还有一些专用的 RPC 协议。但是 2014 年以后，HTTP 协议的增强，让我们实在找不出什么理由不向标准靠拢，还要重新发明轮子了。</strong></p><h2 id="http2">HTTP/2</h2><p>虽然 HTTP/1.1 已经开始变成应用层通讯协议的一等公民了，但是还是有性能问题，虽然 HTTP/1.1 可以重用 TCP 链接，但是请求还是一个一个串行发的，需要保证其顺序。然而，大量的网页请求中都是些资源类的东西，这些东西占了整个 HTTP 请求中最多的传输数据量。所以，理论上来说，如果能够并行这些请求，那就会增加更大的网络吞吐和性能。</p><p>另外，HTTP/1.1 传输数据时，是以文本的方式。借助耗 CPU 的 Zip 压缩的方式减少网络带宽，但是耗了前端和后端的 CPU。这也是为什么很多 RPC 协议诟病 HTTP 的一个原因，就是数据传输的成本比较大。</p><p>其实，在 2010 年时，Google 就在搞一个实验型的协议，这个协议叫 SPDY。这个协议成为了 HTTP/2 的基础（也可以说成 HTTP/2 就是 SPDY 的复刻）。HTTP/2 基本上解决了之前的这些性能问题，其和 HTTP/1.1 最主要的不同是：</p><ul><li><p>HTTP/2 是一个二进制协议，增加了数据传输的效率。</p></li><li><p>HTTP/2 是可以在一个 TCP 链接中并发请求多个 HTTP 请求，移除了 HTTP/1.1 中的串行请求。</p></li><li><p>HTTP/2 会压缩头，如果你同时发出多个请求，他们的头是一样的或是相似的。那么，协议会帮你消除重复的部分。这就是所谓的 HPACK 算法（参看 RFC 7541 附录 A）</p></li><li><p>HTTP/2 允许服务端在客户端放 Cache，又叫服务端 Push，也就是说，你没有请求的东西，我服务端可以先送给你放在你的本地缓存中。比如，你请求 X，我服务端知道 X 依赖于 Y，虽然你没有的请求 Y，但我把 Y 跟着 X 的请求一起返回客户端。</p></li></ul><p>对于这些性能上的改善，在 Medium 上有篇文章 “ HTTP/2: the difference between HTTP/1.1, benefits and how to use it (<a href="https://url.cn/5Ij0hXz" target="_blank" rel="noopener">https://url.cn/5Ij0hXz</a>) ” 你可看一下相关的细节说明和测试。</p><p>当然，还需要注意到的是 HTTP/2 的协议复杂度比之前所有的 HTTP 协议的复杂度都上升了许多许多。其内部还有很多看不见的东西，比如其需要维护一个 “优先级树” 来用于来做一些资源和请求的调度和控制。如此复杂的协议，自然会产生一些不同的声音，或是降低协议的可维护和可扩展性。所以也有一些争议。尽管如此，HTTP/2 还是很快地被世界所采用。</p><p>HTTP/2 是 2015 年推出的。其发布后，Google 宣布移除对 SPDY 的支持，拥抱标准的 HTTP/2。过了一年后，就有 8.7% 的网站开启了 HTTP/2，根据这份报告 (<a href="https://url.cn/5YOuflM" target="_blank" rel="noopener">https://url.cn/5YOuflM</a>)  ，截止至本文发布时（2019 年 10 月 1 日）， 在全世界范围内已经有 41% 的网站开启了 HTTP/2。</p><p>HTTP/2 的官方组织在 Github 上维护了一份各种语言对 HTTP/2 的实现列表，大家可以去看看。</p><p>我们可以看到，HTTP/2 在性能上对 HTTP 有质的提高。所以，HTTP/2 被采用的也很快。<strong>如果你在你的公司内负责架构的话，HTTP/2 是你一个非常重要的需要推动的一个事。除了因为性能上的问题，推动标准落地也是架构师的主要职责。因为，你企业内部的架构越标准，你可以使用到开源软件，或是开发方式就会越有效率。跟随着工业界的标准的发展，你的企业会非常自然的享受到标准所带来的红利。</strong></p><h2 id="http3">HTTP/3</h2><p>然而，这个世界没有完美的解决方案。HTTP/2 也不例外，其主要的问题是：若干个 HTTP 的请求在复用一个 TCP 的连接，底层的 TCP 协议是不知道上层有多少个 HTTP 的请求的。所以，一旦发生丢包，造成的问题就是所有的 HTTP 请求都必需等待这个丢了的包被重传回来，哪怕丢的那个包不是我这个 HTTP 请求的。因为 TCP 底层是没有这个知识了。</p><p>这个问题又叫 Head-of-Line Blocking 问题，这也是一个比较经典的流量调度的问题。这个问题最早主要的发生的交换机上。下图来自 Wikipedia。</p><p><img src="https://coolshell.cn/wp-content/uploads/2019/10/HOL_blocking.png" alt=""></p><p>图中，左边的是输入队列。其中的 1、2、3、4 表示四个队列，四个队列中的 1、2、3、4 要去右边的 Output 的端口号。此时，第一个队列和第三个队列都要写右边的第四个端口。然后，一个时刻只能处理一个包。所以，一个队列只能在那等另一个队列写完。其此时的 3 号或 1 号端口是空闲的，而队列中的要去 1 和 3 号端口号的数据，被第四号端口给 Block 住了。这就是所谓的 HOL Blocking 问题。</p><p>HTTP/1.1 中的 Pipeline 中如果有一个请求 Block 了，那么队列后请求也统统被 Block 住了；HTTP/2 多请求复用一个 TCP 连接，一旦发生丢包就会 Block 住所有的 HTTP 请求。这样的问题很讨厌。好像基本无解了。</p><p>是的 TCP 是无解了，但是 UDP 是有解的 ！<strong>于是 HTTP/3 破天荒地把 HTTP 底层的 TCP 协议改成了 UDP！</strong></p><p>然后又是 Google 家的协议进入了标准 – QUIC （Quick UDP Internet Connections）。接下来是 QUIC 协议的几个重要的特性，为了讲清楚这些特性，我需要带着问题来讲（注：下面的网络知识，如果你看不懂的话，你需要学习一下 《TCP/IP 详解》 一书（ 在我写 Blog 的这 15 年里，这本书推荐了无数次了），或是看一下本站的 《 TCP 的那些事》。）：</p><ul><li><p>首先是上面的 Head-of-Line Blocking 问题，在 UDP 的世界中，这个就没了。这个应该比较好理解，因为 UDP 不管顺序，不管丢包（当然，QUIC 的一个任务是要像 TCP 的一个稳定，所以 QUIC 有自己的丢包重传的机制）</p></li><li><p>TCP 是一个无私的协议，也就是说，如果网络上出现拥塞，大家都会丢包，于是大家都会进入拥塞控制的算法中。这个算法会让所有人都 “冷静” 下来，然后进入一个 “慢启动” 的过程，包括在 TCP 连接建立时，这个慢启动也在，所以导致 TCP 性能迸发地比较慢。QUIC 基于 UDP，使用更为激进的方式。同时，QUIC 有一套自己的丢包重传和拥塞控制的协议，一开始 QUIC 是重新实现 TCP 的 CUBIC 算法。但是随着 BBR 算法的成熟（BBR 也在借鉴 CUBIC 算法的数学模型），QUIC 也可以使用 BBR 算法。这里，多说几句，**从模型来说，以前的 TCP 的拥塞控制算法玩的是数学模型，而新型的 TCP 拥塞控制算法是以 BBR 为代表的测量模型。**理论上来说，后者会更好，但 QUIC 的团队在一开始觉得 BBR 不如 CUBIC 的算法好，所以没有用。现在的 BBR 2.x 借鉴了 CUBIC 数学模型让拥塞控制更公平。这里有文章大家可以一读 “TCP BBR : Magic dust for network performance.” (<a href="https://url.cn/5awu1ey" target="_blank" rel="noopener">https://url.cn/5awu1ey</a>)</p></li><li><p>接下来，现在要建立一个 HTTPS 的连接。先是 TCP 的三次握手，然后是 TLS 的三次握手，要整出六次网络交互，一个连接才建好。虽说 HTTP/1.1 和 HTTP/2 的连接复用解决这个问题，但是基于 UDP 后，UDP 也得要实现这个事。于是 QUIC 直接把 TCP 的和 TLS 的合并成了三次握手（对此，在 HTTP/2 的时候，是否默认开启 TLS 业内是有争议的。反对派说，TLS 在一些情况下是不需要的，比如企业内网的时候。而支持派则说，TLS 的那些开销，什么也不算了）。</p></li></ul><p><img src="https://coolshell.cn/wp-content/uploads/2019/10/http-request-over-quic@2x.png" alt=""></p><p>所以，QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。</p><p>但是对于 UDP 还是有一些挑战的，这个挑战主要来自互联网上的各种网络设备。这些设备根本不知道是什么 QUIC，他们看 QUIC 就只能看到的就是 UDP，所以，在一些情况下，UDP 就是有问题的。</p><ul><li><p>比如在 NAT 的环境下，如果是 TCP 话，NAT 路由或是代理服务器，可以通过记录 TCP 的四元组（源地址、源端口、目标地址、目标端口）来做连接映射的。然而，在 UDP 的情况下不行了。于是，QUIC 引入了个叫 Connection ID 的不透明的 ID 来标识一个链接，用这种业务 ID 很爽的一个事是，如果你从你的 3G/4G 的网络切到 WiFi网络（或是反过来），你的链接不会断，因为我们用的是 Connection ID，而不是四元组。</p></li><li><p>然而就算引用了 Connection ID，也还是会有问题，比如一些不够 “聪明” 的等价路由交换机。这些交换机会通过四元组来做 Hash 把你的请求的 IP 转到后端的实际的服务器上。然而，他们不懂 Connection ID，只懂四元组。这么导致属于同一个 Connection ID 但是四元组不同的网络包就转到了不同的服务器上，这就是导致数据不能传到同一台服务器上，数据不完整，链接只能断了。所以，你需要更聪明的算法（可以参看 Facebook 的 Katran 开源项目 ）</p></li></ul><p>好了，就算搞定上面的东西，还有一些业务层的事没解。这个事就是 HTTP/2 的头压缩算法 HPACK，HPACK 需要维护一个动态的字典表来分析请求的头中哪些是重复的，HPACK 的这个数据结构需要在 Encoder 和 Decoder 端同步这个东西。在 TCP 上，这种同步是透明的，然而在 UDP 上这个事不好干了。所以，这个事也必需要重新设计了，基于 QUIC 的 QPACK 就出来了，利用两个附加的 QUIC Steam，一个用来发送这个字典表的更新给对方，另一个用来 Ack 对方发过来的 Update。</p><p>目前看下来，HTTP/3 目前看上去没有太多的协议业务逻辑上的东西，更多是 HTTP/2 + QUIC 协议。但 HTTP/3 因为动到了底层协议，所以，在普及方面上可能会比 HTTP/2 要慢的多的多。但是，可以看到 QUIC 协议的强大。细思及恐，QUIC 这个协议真对 TCP 是个威胁，如果 QUIC成熟了，TCP 是不是会有可能成为历史呢？</p><p>未来十年，让我们看看 UDP 是否能够逆袭 TCP……</p><blockquote><p>来源：酷壳</p><p>原文：<a href="https://url.cn/56Z548W" target="_blank" rel="noopener">https://url.cn/56Z548W</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HTTP (Hypertext transfer protocol) 翻译成中文是超文本传输协议，是互联网上重要的一个协议。由欧洲核子研究委员会 CERN 的英国工程师 Tim Berners-Lee v 发明的，同时他也是 WWW 的发明人，最初的主要是用于传递通过 HTML 封装过的数据。在 1991 年发布了 HTTP 0.9 版，在 1996 年发布 1.0 版。1997 年是 1.1 版，1.1 版也是到今天为止传输最广泛的版本（初始 RFC 2068 在 1997 年发布， 然后在 1999 年被 RFC 2616 取代，再在 2014 年被 RFC 7230/7231/7232/7233/7234/7235 取代）。2015 年发布了 2.0 版，其极大的优化了 HTTP/1.1 的性能和安全性，而 2018 年发布的 3.0 版，继续优化 HTTP/2，激进地使用 UDP 取代 TCP 协议。目前，HTTP/3 在 2019 年 9 月 26 日 被 Chrome、Firefox、和 Cloudflare 支持。所以我想写下这篇文章，简单地说一下 HTTP 的前世今生，让大家学到一些知识，并希望可以在推动一下 HTTP 标准协议的发展。&lt;/p&gt;
&lt;h2 id=&quot;HTTP-0-9-1-0&quot;&gt;HTTP 0.9 / 1.0&lt;/h2&gt;
&lt;p&gt;0.9 和 1.0 这两个版本，就是最传统的 Request – Response 的模式了。HTTP 0.9 版本的协议简单到极点，请求时不支持请求头，只支持 GET 方法，没了。HTTP 1.0 扩展了 0.9 版，其中主要增加了几个变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在请求中加入了 HTTP 版本号，如：GET /coolshell/index.html HTTP/1.0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HTTP 开始有 Header了，不管是 Request 还是 Response 都有 Header 了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加了 HTTP Status Code 标识相关的状态码。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有 Content-Type 可以传输其它的文件了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以看到，HTTP 1.0 开始让这个协议变得很文明了，一种工程文明。因为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一个协议有没有版本管理，是一个工程化的象征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Header 可以说是把元数据和业务数据解耦，也可以说是控制逻辑和业务逻辑的分离。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Status Code 的出现可以让请求双方以及第三方的监控或管理程序有了统一的认识。最关键是还是控制错误和业务错误的分离。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;注：国内很多公司 HTTP 无论对错只返回 200，这种把 HTTP Status Code 全部抹掉完全是一种工程界的倒退&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是，HTTP 1.0 性能上有一个很大的问题，那就是每请求一个资源都要新建一个 TCP 链接。而且是串行请求，所以就算网络变快了，打开网页的速度也还是很慢。所以，HTTP 1.0 应该是一个必须要淘汰的协议了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="HTTP" scheme="https://www.hi-linux.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>全平台去广告神器 AdGuard Home 使用指南</title>
    <link href="https://www.hi-linux.com/posts/55203.html"/>
    <id>https://www.hi-linux.com/posts/55203.html</id>
    <published>2020-05-23T02:13:00.000Z</published>
    <updated>2020-05-23T14:31:50.736Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-adguard-home">什么是 AdGuard Home</h2><p><code>AdGuard Home</code> 是一款全网广告拦截与反跟踪软件，<code>AdGuard Home</code> 项目是著名广告拦截器提供商 <code>AdGuard</code> 开源的一个 <code>DNS Server</code> 版本。<code>AdGuard Home</code> 可以将广告与追踪相关的域名屏蔽，同时你不再需要安装任何客户端软件。<code>AdGuard Home</code> 的工作原理是在 <code>DNS</code> 的域名解析过程里拦截网页上的广告。</p><p>简单来说 <code>AdGuard Home</code> 是一个支持广告过滤和家长控制的开源公共 <code>DNS</code> 服务，如同 Google 的公共 DNS 服务 8.8.8.8。<code>AdGuard Home</code> 同时也支持 <code>DNS over TLS</code> 和 <code>DNS over HTTPS</code>。</p><blockquote><p>项目地址：<a href="https://github.com/AdguardTeam/AdGuardHome" target="_blank" rel="noopener">https://github.com/AdguardTeam/AdGuardHome</a></p></blockquote><p><strong>AdGuard Home 的主要功能介绍</strong></p><ul><li>拦截随处可见的广告</li><li>注重隐私保护</li><li>家庭保护模式</li><li>自定义过滤规则</li></ul><p>在继续讲解前，我们先来看一看 <code>AdGuard Home</code> 强大的功能演示和管理后台。</p><p><img src="https://camo.githubusercontent.com/5e2bfa17c27773b70ca99ddd3b70995f15d24b62/68747470733a2f2f63646e2e616467756172642e636f6d2f7075626c69632f416467756172642f436f6d6d6f6e2f616467756172645f686f6d652e676966" alt=""></p><a id="more"></a><h2 id="安装-adguard-home">安装 AdGuard Home</h2><p><code>AdGuard Home</code> 使用 <code>Golang</code> 开发，具有良好的原生跨平台性。它可以部署在 <code>X86</code> 架构的各种操作系统上，也可以部署在树莓派上，甚至你还可以借助 <code>Docker</code> 部署在群晖 <code>NAS</code> 上。</p><h3 id="使用预编译的二进制版本安装">使用预编译的二进制版本安装</h3><p>这里我们以 <code>Linux</code> 系统为例，其它系统可参考官方帮助文档：<a href="https://github.com/AdguardTeam/AdGuardHome/wiki/Getting-Started#installation" target="_blank" rel="noopener">https://github.com/AdguardTeam/AdGuardHome/wiki/Getting-Started#installation</a> 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 下载并解压 AdGuard Home</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;AdguardTeam&#x2F;AdGuardHome&#x2F;releases&#x2F;download&#x2F;v0.98.1&#x2F;AdGuardHome_linux_amd64.tar.gz</span><br><span class="line">$ tar -zxvf AdGuardHome_linux_amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 为了方便使用，我们将二进制文件拷贝到 PATH 所包含的位置</span><br><span class="line">$ cd AdGuardHome_linux_amd64</span><br><span class="line">$ cp .&#x2F;AdGuardHome &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br><span class="line"></span><br><span class="line"># 启动 AdGuard Home</span><br><span class="line">$ AdGuardHome</span><br></pre></td></tr></table></figure><p>上面的方法，很显然是在前台运行的。前台运行必然还是存在一些弊端的，比如：当前 <code>SHELL</code> 中断必然会引起程序中断等。如果你想长期稳定的运行 <code>AdGuard Home</code>，最后好方法必然是将 <code>AdGuard Home</code> 运行成一个服务。要想将 <code>AdGuard Home</code> 在各平台部署为服务也是很简单的，只需运行下面这一条命令就可实现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Linux 下使用的服务管理器是 systemd 、Upstart 或 SysV，macOS 下使用的服务管理器是 Launchd。</span><br><span class="line">$ AdGuardHome -s install</span><br></pre></td></tr></table></figure><p><code>AdGuard Home</code> 服务安装后好，你可以使用以下命令来管理它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 启动 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s start</span><br><span class="line"></span><br><span class="line"># 停止 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s stop</span><br><span class="line"></span><br><span class="line"># 重启 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s restart</span><br><span class="line"></span><br><span class="line"># 查看 AdGuardHome 服务状态</span><br><span class="line">$ AdGuardHome -s status</span><br><span class="line"></span><br><span class="line"># 卸载 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s uninstall</span><br></pre></td></tr></table></figure><h3 id="使用-docker-来安装">使用 Docker 来安装</h3><p>如果你会一点点 <code>Docker</code> 知识的话，我们当然还是建议你直接使用 <code>Docker</code> 来安装。虽然通过预编译的二进制版本安装已经很简单了，但如果使用 <code>Docker</code> 来安装，你会发现仅仅只需一条指令就可以搞定了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull adguard&#x2F;adguardhome</span><br><span class="line"># -v 参数后面指定的宿主机上的目录主要用作永久保存 AdGuard Home 的数据文件和配置文件，可自行根据实际情况修改。</span><br><span class="line">$ docker run --name adguardhome -v &#x2F;home&#x2F;mike&#x2F;workdir:&#x2F;opt&#x2F;adguardhome&#x2F;work -v &#x2F;home&#x2F;mike&#x2F;confdir:&#x2F;opt&#x2F;adguardhome&#x2F;conf -p 53:53&#x2F;tcp -p 53:53&#x2F;udp -p 67:67&#x2F;udp -p 68:68&#x2F;tcp -p 68:68&#x2F;udp -p 80:80&#x2F;tcp -p 443:443&#x2F;tcp -p 853:853&#x2F;tcp -p 3000:3000&#x2F;tcp -d adguard&#x2F;adguardhome</span><br></pre></td></tr></table></figure><p>你可能会发现上面一共是两条指令，前面不是说好了是一条指令的吗？是不是发现被骗了，我怎么可能骗你呢，这绝对是不可能的！其实这两条指令，你只需直接执行第 2 条指令就可以完成所有安装操作了。这里分开写出来仅仅是为了完整演示 <code>Docker</code> 整个运行过程，能让一些还不会 <code>Docker</code> 的同学能更容易理解一些。前面既然啰嗦了这么多，这里就再延伸说一点 <code>Docker</code> 容器的基本管理操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 启动 AdGuard Home 容器</span><br><span class="line">$ docker start adguardhome</span><br><span class="line"># 停止 AdGuard Home 容器</span><br><span class="line">$ docker stop adguardhome</span><br><span class="line"># 删除 AdGuard Home 容器</span><br><span class="line">$ docker rm adguardhome</span><br></pre></td></tr></table></figure><h2 id="使用-adguard-home">使用 AdGuard Home</h2><h3 id="使用默认配置来设置-adguard-home">使用默认配置来设置 AdGuard Home</h3><p>运行 <code>AdGuard Home</code> 后，我们需要通过浏览器打开 <code>http://IP:3000</code> 对 <code>AdGuard Home</code> 进行初始化设置。首次初始化会要求设置服务运行端口、账号、密码等信息，配置过程中设置的密码一定请牢记，下次登录管理后台时需要使用。</p><p><img src="https://i.loli.net/2019/09/23/NVETKdawnmg6GPu.png" alt=""></p><p>首先，我们点击 “开始配置” ，来设定网页管理界面和 <code>DNS</code> 服务的端口。</p><p><img src="https://i.loli.net/2019/09/23/FSiKwDLA7ChbJfk.png" alt=""></p><p>其次，点击 “下一步” 后，为 <code>AdGuard Home</code> 网页管理界面设置一个用户名和密码。</p><p><img src="https://i.loli.net/2019/09/23/V2KAUfmzZuqpbwD.png" alt=""></p><p>最后，点击 “下一步” 后，<code>AdGuard Home</code> 会展示以上配置的汇总信息。</p><p><img src="https://i.loli.net/2019/09/23/PLgy2jYkM6SzQRf.png" alt=""></p><p>至此，使用 <code>AdGuard Home</code> 默认配置的设置就算大功告成了。</p><p><img src="https://i.loli.net/2019/09/23/jY15gNKiPO7Lm6U.png" alt=""></p><p>使用 <code>AdGuard Home</code> 默认配置设置完成后，我们可以在「仪表盘」上看到 <code>DNS</code> 查询次数、被过滤器封锁的网站、查询 <code>DNS</code> 请求的客户端 <code>IP</code> 地址等等信息。</p><p><img src="https://i.loli.net/2019/09/23/3EM9k7nOCfRPxFz.png" alt=""></p><h3 id="adguard-home-配置进阶">AdGuard Home 配置进阶</h3><p><code>AdGuard Home</code> 默认的配置比较简单，为了更强力地拦截广告，我们可以对 <code>AdGuard Home</code> 配置进行一些优化。</p><ol><li>常规设置</li></ol><p><code>AdGuard Home</code> 默认配置的情况下只勾选了「使用过滤器和 Hosts 文件以拦截指定域名」这一个选项，你可以根据自身情况决定是否启用「使用 AdGuard 浏览安全网页服务」、「使用 AdGuard 家长控制服务」和「强制安全搜索」等特性。</p><p>不仅如此，你还可以很方便的屏蔽一些比较流行的网站。当然这些网站本来对我们都是不可用的，也就不用多此一举进行设置了，哈哈！</p><p><img src="https://i.loli.net/2019/09/23/lLYJex6vNqcI4V3.png" alt=""></p><ol start="2"><li>设置上游 DNS</li></ol><p><code>AdGuard Home</code> 默认使用 <code>Cloudflare</code> 的 <code>DNS over HTTPS</code> 作为上游服务器。如果你在国内使用 <code>Cloudflare DNS</code> 做为上游 <code>DNS</code>，可能延迟会比较高。</p><p>我们可以设置为国内的公共 <code>DNS</code>，如：腾讯的 <code>119.29.29.29</code>、阿里的 <code>223.5.5.5</code> 和 <code>114.114.114.114</code> 等，但坏处是这些国内公共 <code>DNS</code> 暂时不支持 <code>DNS over TLS</code>。</p><p>这里有一个比较折中的解决方法就是通过启用 「通过同时查询所有上游服务器以使用并行查询加速解析」选项来在每次查询的时候对所有的上游 <code>DNS</code> 同时查询，以加速解析速度。</p><p><img src="https://i.loli.net/2019/09/23/1wTb4msXYcCGudM.png" alt=""></p><ol start="3"><li>过滤器</li></ol><p>虽然 <code>AdGuard Home</code> 本身内置了比较知名的 <code>AdGuard</code>、<code>AdAway</code> 广告过滤规则，但这些规则在国内显然有点水土不服。如果你想要更完美的实现广告屏蔽还需要自己添加规则，比较幸运的是 <code>AdGuard Home</code> 是可以兼容 <code>Adblock</code> 过滤规则语法的。这样，你就可以很方便的使用一些比较知名的 <code>Adblock</code> 过滤规则，比如：由 <code>Adblock Plus</code> 团队维护的 <code>EasyList</code>。</p><p><img src="https://i.loli.net/2019/09/23/5n8tdDEMjAkwNPa.png" alt=""></p><p><img src="https://i.loli.net/2019/09/23/OGxDdmcSplTyn8M.png" alt=""></p><p>目前好用的广告过滤规则还是有很多的，它们都针对不同的用途。下面推荐一些比较常用的：</p><blockquote><ol><li>EasyList China : 国内网站广告过滤的主规则。</li></ol><p>链接：<a href="https://easylist-downloads.adblockplus.org/easylistchina.txt" target="_blank" rel="noopener">https://easylist-downloads.adblockplus.org/easylistchina.txt</a></p><ol start="2"><li>EasyPrivacy : EasyPrivacy 是隐私保护，不被跟踪。</li></ol><p>链接：<a href="https://easylist-downloads.adblockplus.org/easyprivacy.txt" target="_blank" rel="noopener">https://easylist-downloads.adblockplus.org/easyprivacy.txt</a></p><ol start="3"><li>CJX’s Annoyance List : 过滤烦人的自我推广，并补充 EasyPrivacy 隐私规则。</li></ol><p>链接：<a href="https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt" target="_blank" rel="noopener">https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt</a></p><ol start="4"><li>广告净化器规则 : 支持国内大部分视频网站的广告过滤。</li></ol><p>链接：<a href="http://tools.yiclear.com/ChinaList2.0.txt" target="_blank" rel="noopener">http://tools.yiclear.com/ChinaList2.0.txt</a></p><ol start="5"><li>I don’t care about cookies : 我不关心 Cookie 的问题，屏蔽网站的 cookies 相关的警告。</li></ol><p>链接：<a href="https://www.i-dont-care-about-cookies.eu/abp/" target="_blank" rel="noopener">https://www.i-dont-care-about-cookies.eu/abp/</a></p></blockquote><p>除了使用已有的过滤规则外，当然你也可以根据自己的需求自定义过滤规则，要自定义过滤规则其实也很简单。</p><p><img src="https://i.loli.net/2019/09/23/FmdDSCTjuae5I41.png" alt=""></p><p>下面是自定义过滤规则的一些语法说明。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">||example.org^ – 拦截 example.org 域名及其所有子域名</span><br><span class="line">@@||example.org^ – 放行 example.org 及其所有子域名</span><br><span class="line">127.0.0.1 example.org – 将会把 example.org（但不包括它的子域名）解析到 127.0.0.1。</span><br><span class="line">! 注释符号，表示这是一行注释</span><br><span class="line"># 这也是注释符号，同样表示这是一行注释</span><br><span class="line">&#x2F;REGEX&#x2F; – 正则表达式模式</span><br></pre></td></tr></table></figure><p>更多规则可以参考官方帮助文档：<a href="https://kb.adguard.com/en/general/dns-filtering-syntax" target="_blank" rel="noopener">https://kb.adguard.com/en/general/dns-filtering-syntax</a></p><ol start="4"><li>查询日志</li></ol><p><code>AdGuard Home</code> 管理界面中也为我们提供了 <code>DNS</code> 请求日志查询功能，在这里，我们不但能看见所有设备最近 5000 条的 <code>DNS</code> 请求日志记录。你还可以根据 <code>DNS</code> 请求日志记录来针对某个域名进行快速的拦截和放行操作。</p><p><img src="https://i.loli.net/2019/09/23/POtxW5feJ13rYuI.png" alt=""></p><ol start="5"><li>调整配置参数，以提升 QPS 能力</li></ol><p><code>AdGuard Home</code> 所有的配置参数都保存在一个名为 <code>AdGuardHome.yaml</code> 的配置文件中。这个配置文件默认路径通常为 <code>AdGuard Home</code> 二进制文件 <code>AdGuardHome</code> 所在的目录，比如：<code>/usr/local/bin/AdGuardHome.yaml</code>。</p><p>这里我们只需调整以下两个参数，就是可以明显提升 <code>AdGuard Home</code> 的 <code>QPS</code>  能力。</p><ul><li><p>ratelimit : <code>DDoS</code> 保护，客户端每秒接收的数据包数。默认值是 20，建议禁用该参数（将值改为 0）。</p></li><li><p>blocked_response_ttl : <code>TTL</code> 缓存时间，默认值是 10，建议设置为 60 。</p></li></ul><p>这里在把 <code>AdGuard Home</code> 的配置文件完整版本也展示一下，有兴趣的同学可以自行研究下其它参数的用途哟！。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">$ cat AdGuardHome.yaml</span><br><span class="line"></span><br><span class="line">bind_host: 0.0.0.0</span><br><span class="line">bind_port: 80</span><br><span class="line">auth_name: mike</span><br><span class="line">auth_pass: &quot;123456&quot;</span><br><span class="line">language: zh-cn</span><br><span class="line">rlimit_nofile: 0</span><br><span class="line">dns:</span><br><span class="line">  bind_host: 0.0.0.0</span><br><span class="line">  port: 53</span><br><span class="line">  protection_enabled: true</span><br><span class="line">  filtering_enabled: true</span><br><span class="line">  blocking_mode: nxdomain</span><br><span class="line">  blocked_response_ttl: 60</span><br><span class="line">  querylog_enabled: true</span><br><span class="line">  ratelimit: 0</span><br><span class="line">  ratelimit_whitelist: []</span><br><span class="line">  refuse_any: true</span><br><span class="line">  bootstrap_dns:</span><br><span class="line">  - 1.1.1.1:53</span><br><span class="line">  - 1.0.0.1:53</span><br><span class="line">  all_servers: true</span><br><span class="line">  allowed_clients: []</span><br><span class="line">  disallowed_clients: []</span><br><span class="line">  blocked_hosts: []</span><br><span class="line">  parental_block_host: &quot;&quot;</span><br><span class="line">  safebrowsing_block_host: &quot;&quot;</span><br><span class="line">  blocked_services: []</span><br><span class="line">  parental_sensitivity: 13</span><br><span class="line">  parental_enabled: true</span><br><span class="line">  safesearch_enabled: true</span><br><span class="line">  safebrowsing_enabled: true</span><br><span class="line">  resolveraddress: &quot;&quot;</span><br><span class="line">  rewrites: []</span><br><span class="line">  upstream_dns:</span><br><span class="line">  - https:&#x2F;&#x2F;1.1.1.1&#x2F;dns-query</span><br><span class="line">  - https:&#x2F;&#x2F;1.0.0.1&#x2F;dns-query</span><br><span class="line">  - 119.29.29.29</span><br><span class="line">  - 223.5.5.5</span><br><span class="line">tls:</span><br><span class="line">  enabled: false</span><br><span class="line">  server_name: &quot;&quot;</span><br><span class="line">  force_https: false</span><br><span class="line">  port_https: 443</span><br><span class="line">  port_dns_over_tls: 853</span><br><span class="line">  certificate_chain: &quot;&quot;</span><br><span class="line">  private_key: &quot;&quot;</span><br><span class="line">filters:</span><br><span class="line">- enabled: true</span><br><span class="line">  url: https:&#x2F;&#x2F;adguardteam.github.io&#x2F;AdGuardSDNSFilter&#x2F;Filters&#x2F;filter.txt</span><br><span class="line">  name: AdGuard Simplified Domain Names filter</span><br><span class="line">  id: 1</span><br><span class="line">- enabled: false</span><br><span class="line">  url: https:&#x2F;&#x2F;adaway.org&#x2F;hosts.txt</span><br><span class="line">  name: AdAway</span><br><span class="line">  id: 2</span><br><span class="line">- enabled: false</span><br><span class="line">  url: https:&#x2F;&#x2F;hosts-file.net&#x2F;ad_servers.txt</span><br><span class="line">  name: hpHosts - Ad and Tracking servers only</span><br><span class="line">  id: 3</span><br><span class="line">- enabled: false</span><br><span class="line">  url: https:&#x2F;&#x2F;www.malwaredomainlist.com&#x2F;hostslist&#x2F;hosts.txt</span><br><span class="line">  name: MalwareDomainList.com Hosts List</span><br><span class="line">  id: 4</span><br><span class="line">- enabled: true</span><br><span class="line">  url: https:&#x2F;&#x2F;easylist-downloads.adblockplus.org&#x2F;easylistchina.txt</span><br><span class="line">  name: EasyList China</span><br><span class="line">  id: 1569209532</span><br><span class="line">user_rules:</span><br><span class="line">- &#39;@@mps.ts&#39;</span><br><span class="line">dhcp:</span><br><span class="line">  enabled: false</span><br><span class="line">  interface_name: &quot;&quot;</span><br><span class="line">  gateway_ip: &quot;&quot;</span><br><span class="line">  subnet_mask: &quot;&quot;</span><br><span class="line">  range_start: &quot;&quot;</span><br><span class="line">  range_end: &quot;&quot;</span><br><span class="line">  lease_duration: 86400</span><br><span class="line">  icmp_timeout_msec: 1000</span><br><span class="line">clients: []</span><br><span class="line">log_file: &quot;&quot;</span><br><span class="line">verbose: false</span><br><span class="line">schema_version: 4</span><br></pre></td></tr></table></figure><h3 id="设置客户端-dns">设置客户端 DNS</h3><p>所有以上设置完成后，最后当然是修改所有客户端的 <code>DNS</code> 设置，来享用 <code>AdGuard Home</code> 带来的强大的去广告功能。</p><p>这个其实真的不用写，我想聪明的你应该都知道这个怎么设置。写这个标题仅仅是为了保持文档完整性，如果你真的不会设置，那就请自行使用「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247488197&amp;idx=1&amp;sn=1f722503d5f18ab8c6f4d9ba768d983b&amp;chksm=eac533ecddb2bafa6044ce24599ebd20b6fd1cd083a31b53d16730f35daaaffbbb902fc8d449&amp;token=614394592&amp;lang=zh_CN#rd" target="_blank" rel="noopener">一些好用</a>」的搜索引擎搜索相关方法吧！</p><h2 id="总结">总结</h2><p><code>AdGuard Home</code> 不但支持了 <code>macOS</code>、<code>Windows</code>、<code>Linux</code>、树莓派等多个系统平台，也提供了二进制和 <code>Docker</code> 的部署方式，让安装变得非常简单。<code>AdGuard Home</code> 自身提供的强大和直观的管理和统计系统，让它使用起来也是非常方便的。如果你打算自建一个支持去广告功能的公共 <code>DNS</code>，<code>AdGuard Home</code> 是非常值得一试的不二选择。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/56804257" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56804257</a></p></li><li><p><a href="https://www.xiaoz.me/archives/12318" target="_blank" rel="noopener">https://www.xiaoz.me/archives/12318</a></p></li><li><p><a href="https://www.yangcs.net/posts/adguard-home/" target="_blank" rel="noopener">https://www.yangcs.net/posts/adguard-home/</a></p></li><li><p><a href="https://github.com/AdguardTeam/AdGuardHome#getting-started" target="_blank" rel="noopener">https://github.com/AdguardTeam/AdGuardHome#getting-started</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-AdGuard-Home&quot;&gt;什么是 AdGuard Home&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AdGuard Home&lt;/code&gt; 是一款全网广告拦截与反跟踪软件，&lt;code&gt;AdGuard Home&lt;/code&gt; 项目是著名广告拦截器提供商 &lt;code&gt;AdGuard&lt;/code&gt; 开源的一个 &lt;code&gt;DNS Server&lt;/code&gt; 版本。&lt;code&gt;AdGuard Home&lt;/code&gt; 可以将广告与追踪相关的域名屏蔽，同时你不再需要安装任何客户端软件。&lt;code&gt;AdGuard Home&lt;/code&gt; 的工作原理是在 &lt;code&gt;DNS&lt;/code&gt; 的域名解析过程里拦截网页上的广告。&lt;/p&gt;
&lt;p&gt;简单来说 &lt;code&gt;AdGuard Home&lt;/code&gt; 是一个支持广告过滤和家长控制的开源公共 &lt;code&gt;DNS&lt;/code&gt; 服务，如同 Google 的公共 DNS 服务 8.8.8.8。&lt;code&gt;AdGuard Home&lt;/code&gt; 同时也支持 &lt;code&gt;DNS over TLS&lt;/code&gt; 和 &lt;code&gt;DNS over HTTPS&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/AdguardTeam/AdGuardHome&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/AdguardTeam/AdGuardHome&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;AdGuard Home 的主要功能介绍&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拦截随处可见的广告&lt;/li&gt;
&lt;li&gt;注重隐私保护&lt;/li&gt;
&lt;li&gt;家庭保护模式&lt;/li&gt;
&lt;li&gt;自定义过滤规则&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在继续讲解前，我们先来看一看 &lt;code&gt;AdGuard Home&lt;/code&gt; 强大的功能演示和管理后台。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/5e2bfa17c27773b70ca99ddd3b70995f15d24b62/68747470733a2f2f63646e2e616467756172642e636f6d2f7075626c69632f416467756172642f436f6d6d6f6e2f616467756172645f686f6d652e676966&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具" scheme="https://www.hi-linux.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="AdGuard" scheme="https://www.hi-linux.com/tags/AdGuard/"/>
    
  </entry>
  
  <entry>
    <title>你不可错过的 GitHub 万星大厂技术面试宝典</title>
    <link href="https://www.hi-linux.com/posts/62964.html"/>
    <id>https://www.hi-linux.com/posts/62964.html</id>
    <published>2020-05-23T02:12:00.000Z</published>
    <updated>2020-05-23T14:27:20.909Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近，GitHub 上有一个很火的项目，截止目前，该项目已获得 17000+ Star。该项目主要介绍了阿里巴巴、华为、百度、腾讯、美团、字节跳动、滴滴、京东等知名互联网公司的技术面试题。</p><p>项目地址：<a href="https://github.com/0voice/interview_internal_reference" target="_blank" rel="noopener">https://github.com/0voice/interview_internal_reference</a></p><p><img src="https://i.loli.net/2019/08/13/eVwcFCO2GyQaBl6.png" alt=""></p><p>这份面试题库共分为 20 个篇章，其中第一部分(前面 8 章)是以公司为区分，总结了各大互联网公司的技术面试题和答案，第二部分是按照面试题的知识点进行了专题总结。</p><p><img src="https://i.loli.net/2019/08/13/OEMTDy3q9vgHoYc.png" alt=""></p><a id="more"></a><p>在第一部分，我们可以看到这些知名互联网公司的面试题。以排在最前面的阿里巴巴为例子，我们可以看到这里面收集了 37 个面试题。</p><p><img src="https://i.loli.net/2019/08/13/XWd3HFr9afBp2EM.png" alt=""></p><p>打开这些面试题，我们不仅可以能看到题目，而且还能看到对应出题人和参考答案。如：打开第一题：「如何实现一个高效的单向链表逆序输出？」，我们看到的内容如下：</p><p><img src="https://i.loli.net/2019/08/13/hO1PZCYojliyk7n.png" alt=""></p><p>第二部分分为了 12 个技术专题，分别是 MySQL 篇、Redis 篇、MongDB 篇、Zookeeper 篇、Nginx 篇、算法篇、内存篇、CPU 篇、磁盘篇、网络通信篇、安全篇和并发篇。这里面针对每个专题，整理了一些经常会遇到的面试题。</p><p>例如：MySQL 篇包含的题目如下：</p><p><img src="https://i.loli.net/2019/08/13/TQFAOmVLlgBSvKo.png" alt=""></p><p>和上面一样，这里也同样给出了题目和对应的参考答案。打开上图的第一个题目，我们可以看到如下内容：</p><p><img src="https://i.loli.net/2019/08/13/nixwrBMXPOkGA65.png" alt=""></p><p>虽然这只是一个非常简单的概念题，但由此我们也可以看到，这份题库给出的答案非常详细，不仅对问题中提出的概念进行了解释，还用具体的例子进行了说明，方便大家容易理解和记忆。</p><p>更多详细内容此处不再赘述，还在等什么呢？一分耕耘一分收获，有兴趣的读者赶快收藏起这份资源开始学习吧！</p><blockquote><p>来源：雷锋网</p><p>原文：<a href="http://t.cn/AiHU2MuN" target="_blank" rel="noopener">http://t.cn/AiHU2MuN</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，GitHub 上有一个很火的项目，截止目前，该项目已获得 17000+ Star。该项目主要介绍了阿里巴巴、华为、百度、腾讯、美团、字节跳动、滴滴、京东等知名互联网公司的技术面试题。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/0voice/interview_internal_reference&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/0voice/interview_internal_reference&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/08/13/eVwcFCO2GyQaBl6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这份面试题库共分为 20 个篇章，其中第一部分(前面 8 章)是以公司为区分，总结了各大互联网公司的技术面试题和答案，第二部分是按照面试题的知识点进行了专题总结。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/08/13/OEMTDy3q9vgHoYc.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>GitHub Actions 入门教程</title>
    <link href="https://www.hi-linux.com/posts/59009.html"/>
    <id>https://www.hi-linux.com/posts/59009.html</id>
    <published>2020-05-23T02:11:00.000Z</published>
    <updated>2020-05-23T14:25:00.834Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>GitHub Actions 是 GitHub 的持续集成服务，于 2018 年 10 月推出。</p><p>这些天，我一直在试用，觉得它非常强大，有创意，比 Travis CI 玩法更多。</p><p>本文是一个简单教程，演示如何使用 GitHub Actions 自动发布一个 React 应用到 GitHub Pages。</p><h2 id="github-actions-是什么">GitHub Actions 是什么？</h2><p>大家知道，持续集成由很多操作组成，比如抓取代码、运行测试、登录远程服务器，发布到第三方服务等等。GitHub 把这些操作就称为 actions。</p><p>很多操作在不同项目里面是类似的，完全可以共享。GitHub 注意到了这一点，想出了一个很妙的点子，允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。</p><p>如果你需要某个 action，不必自己写复杂的脚本，直接引用他人写好的 action 即可，整个持续集成过程，就变成了一个 actions 的组合。这就是 GitHub Actions 最特别的地方。</p><p>GitHub 做了一个官方市场，可以搜索到他人提交的 actions。另外，还有一个 awesome actions 的仓库，也可以找到不少 action。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091105.jpg" alt=""></p><p>上面说了，每个 action 就是一个独立脚本，因此可以做成代码仓库，使用 userName/repoName 的语法引用 action。比如，actions/setup-node 就表示 <a href="http://github.com/actions/setup-node" target="_blank" rel="noopener">github.com/actions/setup-node</a> 这个仓库，它代表一个 action，作用是安装 Node.js。事实上，GitHub 官方的 actions 都放在 <a href="http://github.com/actions" target="_blank" rel="noopener">github.com/actions</a> 里面。</p><p>既然 actions 是代码仓库，当然就有版本的概念，用户可以引用某个具体版本的 action。下面都是合法的 action 引用，用的就是 Git 的指针概念，详见官方文档。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">actions&#x2F;setup-node@74bc508 # 指向一个 commit</span><br><span class="line">actions&#x2F;setup-node@v1.0    # 指向一个标签</span><br><span class="line">actions&#x2F;setup-node@master  # 指向一个分支</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="基本概念">基本概念</h2><p>GitHub Actions 有一些自己的术语。</p><p>（1）workflow （工作流程）：持续集成一次运行的过程，就是一个 workflow。</p><p>（2）job （任务）：一个 workflow 由一个或多个 jobs 构成，含义是一次持续集成的运行，可以完成多个任务。</p><p>（3）step（步骤）：每个 job 由多个 step 构成，一步步完成。</p><p>（4）action （动作）：每个 step 可以依次执行一个或多个命令（action）。</p><h2 id="workflow-文件">workflow 文件</h2><p>GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的 .github/workflows 目录。</p><p>workflow 文件采用 YAML 格式，文件名可以任意取，但是后缀名统一为 .yml，比如 foo.yml。一个库可以有多个 workflow 文件。GitHub 只要发现 .github/workflows 目录里面有 .yml 文件，就会自动运行该文件。</p><p>workflow 文件的配置字段非常多，详见官方文档。下面是一些基本字段。</p><p><strong>（1）name</strong></p><p>name 字段是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name: GitHub Actions Demo</span><br></pre></td></tr></table></figure><p><strong>（2）on</strong></p><p>on 字段指定触发 workflow 的条件，通常是某些事件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">on: push</span><br></pre></td></tr></table></figure><p>上面代码指定，push 事件触发 workflow。</p><p>on 字段也可以是事件的数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">on: [push, pull_request]</span><br></pre></td></tr></table></figure><p>上面代码指定，push 事件或 pull_request 事件都可以触发 workflow。</p><p>完整的事件列表，请查看官方文档。除了代码库事件，GitHub Actions 也支持外部事件触发，或者定时运行。</p><p><strong>（3）on.&lt;push|pull_request&gt;.&lt;tags|branches&gt;</strong></p><p>指定触发事件时，可以限定分支或标签。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">on:</span><br><span class="line">  push:</span><br><span class="line">    branches:    </span><br><span class="line">      - master</span><br></pre></td></tr></table></figure><p>上面代码指定，只有 master 分支发生 push 事件时，才会触发 workflow。</p><p><strong>（4）jobs.&lt;job_id&gt;.name</strong></p><p>workflow 文件的主体是 jobs 字段，表示要执行的一项或多项任务。</p><p>jobs 字段里面，需要写出每一项任务的 job_id，具体名称自定义。job_id 里面的 name 字段是任务的说明。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  my_first_job:</span><br><span class="line">    name: My first job</span><br><span class="line">  my_second_job:</span><br><span class="line">    name: My second job</span><br></pre></td></tr></table></figure><p>上面代码的 jobs 字段包含两项任务，job_id 分别是 my_first_job 和 my_second_job。</p><p><strong>（5）jobs.&lt;job_id&gt;.needs</strong></p><p>needs 字段指定当前任务的依赖关系，即运行顺序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  job1:</span><br><span class="line">  job2:</span><br><span class="line">    needs: job1</span><br><span class="line">  job3:</span><br><span class="line">    needs: [job1, job2]</span><br></pre></td></tr></table></figure><p>上面代码中，job1 必须先于 job2 完成，而 job3 等待 job1 和 job2 的完成才能运行。因此，这个 workflow 的运行顺序依次为：job1、job2、job3。</p><p><strong>（6）jobs.&lt;job_id&gt;.runs-on</strong></p><p>runs-on 字段指定运行所需要的虚拟机环境。它是必填字段。目前可用的虚拟机如下。</p><ul><li><p>ubuntu-latest，ubuntu-18.04 或 ubuntu-16.04</p></li><li><p>windows-latest，windows-2019 或 windows-2016</p></li><li><p>macOS-latest 或 macOS-10.14</p></li></ul><p>下面代码指定虚拟机环境为 ubuntu-18.04。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runs-on: ubuntu-18.04</span><br></pre></td></tr></table></figure><p><strong>（7）jobs.&lt;job_id&gt;.steps</strong></p><p>steps 字段指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定以下三个字段。</p><ul><li><p>jobs.&lt;job_id&gt;.steps.name：步骤名称。</p></li><li><p>jobs.&lt;job_id&gt;.steps.run：该步骤运行的命令或者 action。</p></li><li><p>jobs.&lt;job_id&gt;.steps.env：该步骤所需的环境变量。</p></li></ul><p>下面是一个完整的 workflow 文件的范例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">name: Greeting from Mona</span><br><span class="line">on: push</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  my-job:</span><br><span class="line">    name: My Job</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">    - name: Print a greeting</span><br><span class="line">      env:</span><br><span class="line">        MY_VAR: Hi there! My name is</span><br><span class="line">        FIRST_NAME: Mona</span><br><span class="line">        MIDDLE_NAME: The</span><br><span class="line">        LAST_NAME: Octocat</span><br><span class="line">      run: |</span><br><span class="line">        echo $MY_VAR $FIRST_NAME $MIDDLE_NAME $LAST_NAME.</span><br></pre></td></tr></table></figure><p>上面代码中，steps 字段只包括一个步骤。该步骤先注入四个环境变量，然后执行一条 Bash 命令。</p><h2 id="实例react-项目发布到-github-pages">实例：React 项目发布到 GitHub Pages</h2><p>下面是一个实例，通过 GitHub Actions 构建一个 React 项目，并发布到 GitHub Pages。最终代码都在这个仓库里面，发布后的参考网址为 <a href="http://ruanyf.github.io/github-actions-demo%E3%80%82" target="_blank" rel="noopener">ruanyf.github.io/github-actions-demo。</a></p><p>第一步，GitHub Actions 目前还处在测试阶段，需要到这个网址申请测试资格。申请以后，可能需要几天才能通过。据说，2019 年 11 月就会放开。</p><p>获得资格后，仓库顶部的菜单会出现 Actions 一项。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091106.jpg" alt=""></p><p>第二步，这个示例需要将构建成果发到 GitHub 仓库，因此需要 GitHub 密钥。按照官方文档，生成一个密钥。然后，将这个密钥储存到当前仓库的 Settings/Secrets 里面。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091107.jpg" alt=""></p><p>上图是储存秘密的环境变量的地方。环境变量的名字可以随便起，这里用的是 ACCESS_TOKEN。如果你不用这个名字，后面脚本里的变量名也要跟着改。</p><p>第三步，本地计算机使用 create-react-app，生成一个标准的 React 应用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ npx create-react-app github-actions-demo</span><br><span class="line">$ cd github-actions-demo</span><br></pre></td></tr></table></figure><p>第四步，在这个仓库的 .github/workflows 目录，生成一个 workflow 文件，名字可以随便取，这个示例是 ci.yml。</p><p>我们选用一个别人已经写好的 action：JamesIves/github-pages-deploy-action，它提供了 workflow 的范例文件，直接拷贝过来就行了（查看源码）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">name: GitHub Actions Build and Deploy Demo</span><br><span class="line">on:</span><br><span class="line">  push:</span><br><span class="line">    branches:</span><br><span class="line">      - master</span><br><span class="line">jobs:</span><br><span class="line">  build-and-deploy:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">    - name: Checkout</span><br><span class="line">      uses: actions&#x2F;checkout@master</span><br><span class="line"></span><br><span class="line">    - name: Build and Deploy</span><br><span class="line">      uses: JamesIves&#x2F;github-pages-deploy-action@master</span><br><span class="line">      env:</span><br><span class="line">        ACCESS_TOKEN: $&#123;&#123; secrets.ACCESS_TOKEN &#125;&#125;</span><br><span class="line">        BRANCH: gh-pages</span><br><span class="line">        FOLDER: build</span><br><span class="line">        BUILD_SCRIPT: npm install &amp;&amp; npm run build</span><br></pre></td></tr></table></figure><p>上面这个 workflow 文件的要点如下。</p><ol><li><p>整个流程在 master 分支发生 push 事件时触发。</p></li><li><p>只有一个 job，运行在虚拟机环境 ubuntu-latest。</p></li><li><p>第一步是获取源码，使用的 action 是actions/checkout。</p></li><li><p>第二步是构建和部署，使用的 action 是JamesIves/github-pages-deploy-action。</p></li><li><p>第二步需要四个环境变量，分别为 GitHub 密钥、发布分支、构建成果所在目录、构建脚本。其中，只有 GitHub 密钥是秘密变量，需要写在双括号里面，其他三个都可以直接写在文件里。</p></li></ol><p>第五步，保存上面的文件后，将整个仓库推送到 GitHub。</p><p>GitHub 发现了 workflow 文件以后，就会自动运行。你可以在网站上实时查看运行日志，日志默认保存 30 天。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091108.jpg" alt=""></p><p>等到 workflow 运行结束，访问 GitHub Page，会看到构建成果已经发上网了。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091109.jpg" alt=""></p><p>以后，每次修改后推送源码，GitHub Actions 都会自动运行，将构建产物发布到网页。</p><h2 id="参考链接">参考链接</h2><ol><li><p>GitHub Pages 官方文档</p></li><li><p>Github Actions for web apps, Luke Boyle</p></li><li><p>My First Week With GitHub Actions, Adam Zolyak</p></li></ol><blockquote><p>来源：阮一峰的网络日志</p><p>原文：<a href="https://tinyurl.com/y3zfap8m" target="_blank" rel="noopener">https://tinyurl.com/y3zfap8m</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GitHub Actions 是 GitHub 的持续集成服务，于 2018 年 10 月推出。&lt;/p&gt;
&lt;p&gt;这些天，我一直在试用，觉得它非常强大，有创意，比 Travis CI 玩法更多。&lt;/p&gt;
&lt;p&gt;本文是一个简单教程，演示如何使用 GitHub Actions 自动发布一个 React 应用到 GitHub Pages。&lt;/p&gt;
&lt;h2 id=&quot;GitHub-Actions-是什么？&quot;&gt;GitHub Actions 是什么？&lt;/h2&gt;
&lt;p&gt;大家知道，持续集成由很多操作组成，比如抓取代码、运行测试、登录远程服务器，发布到第三方服务等等。GitHub 把这些操作就称为 actions。&lt;/p&gt;
&lt;p&gt;很多操作在不同项目里面是类似的，完全可以共享。GitHub 注意到了这一点，想出了一个很妙的点子，允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。&lt;/p&gt;
&lt;p&gt;如果你需要某个 action，不必自己写复杂的脚本，直接引用他人写好的 action 即可，整个持续集成过程，就变成了一个 actions 的组合。这就是 GitHub Actions 最特别的地方。&lt;/p&gt;
&lt;p&gt;GitHub 做了一个官方市场，可以搜索到他人提交的 actions。另外，还有一个 awesome actions 的仓库，也可以找到不少 action。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.wangbase.com/blogimg/asset/201909/bg2019091105.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面说了，每个 action 就是一个独立脚本，因此可以做成代码仓库，使用 userName/repoName 的语法引用 action。比如，actions/setup-node 就表示 &lt;a href=&quot;http://github.com/actions/setup-node&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github.com/actions/setup-node&lt;/a&gt; 这个仓库，它代表一个 action，作用是安装 Node.js。事实上，GitHub 官方的 actions 都放在 &lt;a href=&quot;http://github.com/actions&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github.com/actions&lt;/a&gt; 里面。&lt;/p&gt;
&lt;p&gt;既然 actions 是代码仓库，当然就有版本的概念，用户可以引用某个具体版本的 action。下面都是合法的 action 引用，用的就是 Git 的指针概念，详见官方文档。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;actions&amp;#x2F;setup-node@74bc508 # 指向一个 commit&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;actions&amp;#x2F;setup-node@v1.0    # 指向一个标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;actions&amp;#x2F;setup-node@master  # 指向一个分支&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>推荐几个 Linux 下快速分析内存占用的工具</title>
    <link href="https://www.hi-linux.com/posts/42797.html"/>
    <id>https://www.hi-linux.com/posts/42797.html</id>
    <published>2020-05-23T02:10:00.000Z</published>
    <updated>2020-05-23T14:23:04.843Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>一个经常被问到的 <code>Linux</code> 问题：为啥 <code>Linux</code> 系统没运行多少程序，显示的可用内存这么少？</p><p>其实 <code>Linux</code> 与 <code>Windows</code> 的内存管理不同，会尽量缓存内存以提高读写性能，通常叫做 <code>Cache Memory</code>。</p><p>比较老的资料都会介绍 <code>Linux</code> 的 <code>Cache</code> 占用很多并没有关系，因为 <code>Linux</code> 会尽可能利用内存进行缓存。但是缓存的回收也是需要资源的，比较好的一篇文章是 Poor Zorro 写的 <code>Linux</code> 内存中的 Cache 真的能被回收么？。</p><p>虽然大部分情况下我们看到 <code>Cache</code> 占用很高时是没有问题的，但是我们还是想弄清楚到底是哪个程序把 <code>Cache</code> 弄的那么高，这居然不是一件容易的事。</p><p>内核的模块在分配资源的时候，为了提高效率和资源的利用率，都是透过 <code>Slab</code> 来分配的。<code>Slab</code> 为结构性缓存占用内存，该项也经常占用很大的内存。不过借助 <code>slabtop</code> 工具，我们可以很方便的显示内核片缓存信息，该工具可以更直观的显示 <code>/proc/slabinfo</code> 下的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 显示了一台机器缓存中占用对象的情况</span><br><span class="line">$ slabtop -s c </span><br><span class="line">Active &#x2F; Total Objects (% used)    : 856448 &#x2F; 873737 (98.0%)</span><br><span class="line"> Active &#x2F; Total Slabs (% used)      : 19737 &#x2F; 19737 (100.0%)</span><br><span class="line"> Active &#x2F; Total Caches (% used)     : 67 &#x2F; 89 (75.3%)</span><br><span class="line"> Active &#x2F; Total Size (% used)       : 141806.80K &#x2F; 145931.33K (97.2%)</span><br><span class="line"> Minimum &#x2F; Average &#x2F; Maximum Object : 0.01K &#x2F; 0.17K &#x2F; 8.00K</span><br><span class="line">  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ&#x2F;SLAB CACHE SIZE NAME</span><br><span class="line">416949 416949 100%    0.10K  10691 39     42764K buffer_head</span><br><span class="line">  5616   5545  98%    2.00K    351 16     11232K kmalloc-2048</span><br><span class="line">  9114   8990  98%    1.02K    294 31 9408K ext4_inode_cache</span><br><span class="line"> 12404  12404 100%    0.57K    443 28 7088K radix_tree_node</span><br><span class="line"> 10800  10731  99%    0.58K    400 27 6400K inode_cache</span><br><span class="line"> 31290  29649  94%    0.19K    745 42 5960K dentry</span><br><span class="line">  3552   3362  94%    1.00K    111 32 3552K kmalloc-1024</span><br><span class="line">  1100   1055  95%    2.84K    100 11 3200K task_struct</span><br><span class="line">  1649   1481  89%    1.88K     97 17 3104K TCP</span><br><span class="line"> 27000  27000 100%    0.11K    750 36 3000K sysfs_dir_cache</span><br><span class="line">  1380   1269  91%    2.06K     92 15 2944K sighand_cache</span><br></pre></td></tr></table></figure><p>虽然上面的命令显示了 <code>Cache</code> 中 <code>Slab</code> 的情况，但是还是没有显示什么程序占用的 <code>Cache</code>。</p><a id="more"></a><h2 id="方案一使用-pcstat-来实现">方案一：使用 Pcstat 来实现</h2><p>经过搜索，发现 <code>linux-ftools</code> 这个工具可以显示某个文件占用的 <code>Cache</code> 的情况, <code>fincore</code> 只是它其中的一个工具。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ fincore [options] files...</span><br><span class="line">  --pages&#x3D;false      Do not print pages</span><br><span class="line">  --summarize        When comparing multiple files, print a summary report</span><br><span class="line">  --only-cached      Only print stats for files that are actually in cache.</span><br><span class="line">https:&#x2F;&#x2F;colobu.com&#x2F;2017&#x2F;03&#x2F;07&#x2F;what-is-in-linux-cached&#x2F;root@xxxxxx:&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;blogindex# fincore --pages&#x3D;false --summarize --only-cached * </span><br><span class="line">stats for CLUSTER_LOG_2010_05_21.MYI: file size&#x3D;93840384 , total pages&#x3D;22910 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;0.004365 </span><br><span class="line">stats for CLUSTER_LOG_2010_05_22.MYI: file size&#x3D;417792 , total pages&#x3D;102 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;0.980392 </span><br><span class="line">stats for CLUSTER_LOG_2010_05_23.MYI: file size&#x3D;826368 , total pages&#x3D;201 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;0.497512 </span><br><span class="line">stats for CLUSTER_LOG_2010_05_24.MYI: file size&#x3D;192512 , total pages&#x3D;47 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;2.127660 </span><br><span class="line">stats for CLUSTER_LOG_2010_06_03.MYI: file size&#x3D;345088 , total pages&#x3D;84 , cached pages&#x3D;43 , cached size&#x3D;176128, cached perc&#x3D;51.190476 </span><br><span class="line">stats for CLUSTER_LOG_2010_06_04.MYD: file size&#x3D;1478552 , total pages&#x3D;360 , cached pages&#x3D;97 , cached size&#x3D;397312, cached perc&#x3D;26.944444 </span><br><span class="line">stats for CLUSTER_LOG_2010_06_04.MYI: file size&#x3D;205824 , total pages&#x3D;50 , cached pages&#x3D;29 , cached size&#x3D;118784, cached perc&#x3D;58.000000 </span><br><span class="line">stats for COMMENT_CONTENT_2010_06_03.MYI: file size&#x3D;100051968 , total pages&#x3D;24426 , cached pages&#x3D;10253 , cached size&#x3D;41996288, cached perc&#x3D;41.975764 </span><br><span class="line">stats for COMMENT_CONTENT_2010_06_04.MYD: file size&#x3D;716369644 , total pages&#x3D;174894 , cached pages&#x3D;79821 , cached size&#x3D;326946816, cached perc&#x3D;45.639645 </span><br><span class="line">stats for COMMENT_CONTENT_2010_06_04.MYI: file size&#x3D;56832000 , total pages&#x3D;13875 , cached pages&#x3D;5365 , cached size&#x3D;21975040, cached perc&#x3D;38.666667 </span><br><span class="line">stats for FEED_CONTENT_2010_06_03.MYI: file size&#x3D;1001518080 , total pages&#x3D;244511 , cached pages&#x3D;98975 , cached size&#x3D;405401600, cached perc&#x3D;40.478751 </span><br><span class="line">stats for FEED_CONTENT_2010_06_04.MYD: file size&#x3D;9206385684 , total pages&#x3D;2247652 , cached pages&#x3D;1018661 , cached size&#x3D;4172435456, cached perc&#x3D;45.321117 </span><br><span class="line">stats for FEED_CONTENT_2010_06_04.MYI: file size&#x3D;638005248 , total pages&#x3D;155763 , cached pages&#x3D;52912 , cached size&#x3D;216727552, cached perc&#x3D;33.969556 </span><br><span class="line">stats for FEED_CONTENT_2010_06_04.frm: file size&#x3D;9840 , total pages&#x3D;2 , cached pages&#x3D;3 , cached size&#x3D;12288, cached perc&#x3D;150.000000 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_03.MYI: file size&#x3D;1035290624 , total pages&#x3D;252756 , cached pages&#x3D;108563 , cached size&#x3D;444674048, cached perc&#x3D;42.951700 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_04.MYD: file size&#x3D;55619712720 , total pages&#x3D;13579031 , cached pages&#x3D;6590322 , cached size&#x3D;26993958912, cached perc&#x3D;48.533080 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_04.MYI: file size&#x3D;659397632 , total pages&#x3D;160985 , cached pages&#x3D;54304 , cached size&#x3D;222429184, cached perc&#x3D;33.732335 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_04.frm: file size&#x3D;10156 , total pages&#x3D;2 , cached pages&#x3D;3 , cached size&#x3D;12288, cached perc&#x3D;150.000000 </span><br><span class="line">---</span><br><span class="line">total cached size: 32847278080</span><br></pre></td></tr></table></figure><p><code>fincore</code> 的工作原理是将指定文件的相应 <code>Inode Data</code> 与 <code>Kernel</code> 的 <code>Page Cache Table</code> 做对比，如果 <code>Page Cache Table</code> 有这个 <code>Inode</code> 信息，就找到该 <code>Inode</code> 对应的 <code>Data Block</code> 的大小。</p><p>因为 <code>Kernel</code> 的 <code>Page Cache Table</code> 只存储 <code>Data Block</code> 的引用而不是文件名，即文件的 <code>Inode</code> 信息。所以并没有任何一个工具运行一次就可以找出所有的文件使用缓存的情况。所以使用 <code>linux-fincore</code> 这个工具也只能加文件名来判断该文件是否被缓存，如果缓存，大小是多少。问题是你不能随便猜哪个文件是否被缓存吧。</p><p><code>Shanker</code> 提供了一个脚本来解决此问题，那就是查看哪些进程使用的物理内存最多，就找到该进程打开的文件，然后用 <code>fincore</code> 来查看这些文件的缓存使用率。</p><p>这个办法在大部分情况下都可以找到占用 <code>Cache</code> 较多的程序和进程。脚本内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#Author: Shanker</span><br><span class="line">#Time: 2016&#x2F;06&#x2F;08</span><br><span class="line">#set -e</span><br><span class="line">#set -u</span><br><span class="line"></span><br><span class="line">#you have to install linux-fincore</span><br><span class="line">if [ ! -f &#x2F;usr&#x2F;local&#x2F;bin&#x2F;linux-fincore ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;You haven&#39;t installed linux-fincore yet&quot;</span><br><span class="line">    exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#find the top 10 processs&#39; cache file</span><br><span class="line">ps -e -o pid,rss|sort -nk2 -r|head -10 |awk &#39;&#123;print $1&#125;&#39;&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">#find all the processs&#39; cache file</span><br><span class="line">#ps -e -o pid&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.files ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.files is exist, removing now &quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.files</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">    lsof -p $line 2&gt;&#x2F;dev&#x2F;null|awk &#39;&#123;print $9&#125;&#39; &gt;&gt;&#x2F;tmp&#x2F;cache.files </span><br><span class="line">done&lt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.fincore ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.fincore is exist, removing now&quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.fincore</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for i in &#96;cat &#x2F;tmp&#x2F;cache.files&#96;</span><br><span class="line">do</span><br><span class="line">    if [ -f $i ]</span><br><span class="line">    then</span><br><span class="line">        echo $i &gt;&gt;&#x2F;tmp&#x2F;cache.fincore</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">linux-fincore -s  &#96;cat &#x2F;tmp&#x2F;cache.fincore&#96;</span><br><span class="line">rm -f &#x2F;tmp&#x2F;cache.&#123;pids,files,fincore&#125;</span><br></pre></td></tr></table></figure><p>比较遗憾的是，<code>linux-ftools</code> 目前已经不再维护了。在新版本的操作系统上没法编译好这个程序，所以这个方法失效了。</p><p>再次通过万能的 <code>Google</code> 搜索，后来我找到了 <code>pcstat</code> 这个工具，<code>pcstat</code> 使用 Go 语言开发，功能基本和 <code>linux-ftools</code> 一样 。</p><blockquote><p>项目地址：<a href="https://github.com/tobert/pcstat" target="_blank" rel="noopener">https://github.com/tobert/pcstat</a></p></blockquote><p>然后我修改了 <code>Shanker</code> 的脚本，让它使用 <code>pcstat</code> 来进行处理，这样就可以很好的找到 <code>Cache</code> 所占用的情况。修改后的脚本如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">#you have to install pcstat</span><br><span class="line">if [ ! -f &#x2F;data0&#x2F;brokerproxy&#x2F;pcstat ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;You haven&#39;t installed pcstat yet&quot;</span><br><span class="line">    echo &quot;run \&quot;go get github.com&#x2F;tobert&#x2F;pcstat\&quot; to install&quot;</span><br><span class="line">    exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#find the top 10 processs&#39; cache file</span><br><span class="line">ps -e -o pid,rss|sort -nk2 -r|head -10 |awk &#39;&#123;print $1&#125;&#39;&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">#find all the processs&#39; cache file</span><br><span class="line">#ps -e -o pid&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.files ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.files is exist, removing now &quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.files</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">    lsof -p $line 2&gt;&#x2F;dev&#x2F;null|awk &#39;&#123;print $9&#125;&#39; &gt;&gt;&#x2F;tmp&#x2F;cache.files </span><br><span class="line">done&lt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.pcstat ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.pcstat is exist, removing now&quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.pcstat</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for i in &#96;cat &#x2F;tmp&#x2F;cache.files&#96;</span><br><span class="line">do</span><br><span class="line">    if [ -f $i ]</span><br><span class="line">    then</span><br><span class="line">        echo $i &gt;&gt;&#x2F;tmp&#x2F;cache.pcstat</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">&#x2F;data0&#x2F;brokerproxy&#x2F;pcstat  &#96;cat &#x2F;tmp&#x2F;cache.pcstat&#96;</span><br><span class="line">rm -f &#x2F;tmp&#x2F;cache.&#123;pids,files,pcstat&#125;</span><br></pre></td></tr></table></figure><p>脚本运行成功后的显示结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+------------------------------------------+----------------+------------+-----------+---------+</span><br><span class="line">| Name                                     | Size (bytes)   | Pages      | Cached    | Percent |</span><br><span class="line">|------------------------------------------+----------------+------------+-----------+---------|</span><br><span class="line">| &#x2F;data0&#x2F;abcasyouknow&#x2F;0307&#x2F;abc             | 10060771       | 2457       | 2457      | 100.000 |</span><br><span class="line">| &#x2F;data0&#x2F;abcasyouknow&#x2F;0307&#x2F;logs&#x2F;abc.log    | 1860           | 1          | 1         | 100.000 |</span><br><span class="line">| &#x2F;data0&#x2F;abcasyouknow&#x2F;0307&#x2F;logs&#x2F;uuid.log   | 326326364      | 79670      | 79670     | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;bin&#x2F;bash                            | 960384         | 235        | 194       | 082.553 |</span><br><span class="line">| &#x2F;usr&#x2F;lib&#x2F;locale&#x2F;locale-archive           | 106065056      | 25895      | 211       | 000.815 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libnss_files-2.17.so          | 58288          | 15         | 15        | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libc-2.17.so                  | 2107760        | 515        | 336       | 065.243 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libdl-2.17.so                 | 19512          | 5          | 5         | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libtinfo.so.5.9               | 174520         | 43         | 42        | 097.674 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;ld-2.17.so                    | 164336         | 41         | 41        | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;gconv&#x2F;gconv-modules.cache     | 26254          | 7          | 7         | 100.000 |</span><br><span class="line">+------------------------------------------+----------------+------------+-----------+---------+</span><br></pre></td></tr></table></figure><p>从结果我们可以看到 <code>uuid.log</code> 占用 <code>Cache</code> 比较多。这个文件是打开的，程序一直在往里面写日志，Linux 应该是把它缓存了。</p><h2 id="方案二使用-vmtouch-来实现">方案二：使用 Vmtouch 来实现</h2><p>除了上面提到的 <code>pcstat</code> 工具外，你还可以使用 <code>vmtouch</code> 来实现同样的目的。<code>vmtouch</code> 是一个可以查询到缓存的文件和目录，并且能把文件推入缓存或者驱逐出缓存的工具。</p><blockquote><p>项目地址：<a href="https://github.com/hoytech/vmtouch" target="_blank" rel="noopener">https://github.com/hoytech/vmtouch</a></p></blockquote><h3 id="安装-vmtouch">安装 Vmtouch</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;hoytech&#x2F;vmtouch</span><br><span class="line">$ cd vmtouch</span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure><h3 id="使用-vmtouch">使用 Vmtouch</h3><ol><li>vmtouch 命令语法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch</span><br><span class="line">vmtouch: no files or directories specified</span><br><span class="line"></span><br><span class="line">vmtouch v1.0.2 - the Virtual Memory Toucher by Doug Hoyte</span><br><span class="line">Portable file system cache diagnostics and control</span><br><span class="line"></span><br><span class="line">Usage: vmtouch [OPTIONS] ... FILES OR DIRECTORIES ...</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -t touch pages into memory</span><br><span class="line">  -e evict pages from memory</span><br><span class="line">  -l lock pages in physical memory with mlock(2)</span><br><span class="line">  -L lock pages in physical memory with mlockall(2)</span><br><span class="line">  -d daemon mode</span><br><span class="line">  -m max file size to touch</span><br><span class="line">  -p use the specified portion instead of the entire file</span><br><span class="line">  -f follow symbolic links</span><br><span class="line">  -h also count hardlinked copies</span><br><span class="line">  -w wait until all pages are locked (only useful together with -d)</span><br><span class="line">  -v verbose</span><br><span class="line">  -q quiet</span><br></pre></td></tr></table></figure><ol start="2"><li>一些使用的例子</li></ol><p>由于 <code>vmtouch</code> 直接支持目录级查询，所以使用起来简单得多了。</p><ul><li>查看 /tmp 目录在内存中的缓存</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch &#x2F;tmp&#x2F;</span><br><span class="line">vmtouch: WARNING: skipping non-regular file: &#x2F;tmp&#x2F;ssh-GgJnCEkWMQC2&#x2F;agent.1068</span><br><span class="line"></span><br><span class="line">           Files: 17</span><br><span class="line">     Directories: 7</span><br><span class="line">  Resident Pages: 4780&#x2F;4780  18M&#x2F;18M  100%</span><br><span class="line">         Elapsed: 0.001006 seconds</span><br></pre></td></tr></table></figure><p>如果需要查看更详细信息，可以使用 <code>-v</code> 参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -v &#x2F;tmp&#x2F;</span><br></pre></td></tr></table></figure><ul><li>查看一个文件被缓存了多少</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -v ~&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb </span><br><span class="line">&#x2F;home&#x2F;neo&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb</span><br><span class="line">[                                            ] 0&#x2F;132</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">  Resident Pages: 0&#x2F;132  0&#x2F;528K  0%</span><br><span class="line">         Elapsed: 0.000117 seconds</span><br></pre></td></tr></table></figure><ul><li>把指定的文件缓存起来</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -vt ~&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb </span><br><span class="line">&#x2F;home&#x2F;neo&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb</span><br><span class="line">[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO] 132&#x2F;132</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">   Touched Pages: 132 (528K)</span><br><span class="line">         Elapsed: 0.007935 seconds</span><br></pre></td></tr></table></figure><ul><li>把缓存中指定的数据驱逐出去</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -ve ~&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb </span><br><span class="line">Evicting &#x2F;home&#x2F;neo&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">   Evicted Pages: 132 (528K)</span><br><span class="line">         Elapsed: 0.000109 seconds</span><br></pre></td></tr></table></figure><p>更多关于 <code>vmtouch</code> 使用的具体信息，你可以参考官网：<a href="https://hoytech.com/vmtouch/" target="_blank" rel="noopener">https://hoytech.com/vmtouch/</a> 。</p><p>如果你还有更多 <code>Linux</code> 下查看 <code>Cache</code> 或 <code>Buffer</code> 占用的方法，请直接留言告诉我们哟！</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://colobu.com/2017/03/07/what-is-in-linux-cached/" target="_blank" rel="noopener">https://colobu.com/2017/03/07/what-is-in-linux-cached/</a></li><li><a href="https://www.cnblogs.com/langdashu/p/5953222.html" target="_blank" rel="noopener">https://www.cnblogs.com/langdashu/p/5953222.html</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一个经常被问到的 &lt;code&gt;Linux&lt;/code&gt; 问题：为啥 &lt;code&gt;Linux&lt;/code&gt; 系统没运行多少程序，显示的可用内存这么少？&lt;/p&gt;
&lt;p&gt;其实 &lt;code&gt;Linux&lt;/code&gt; 与 &lt;code&gt;Windows&lt;/code&gt; 的内存管理不同，会尽量缓存内存以提高读写性能，通常叫做 &lt;code&gt;Cache Memory&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;比较老的资料都会介绍 &lt;code&gt;Linux&lt;/code&gt; 的 &lt;code&gt;Cache&lt;/code&gt; 占用很多并没有关系，因为 &lt;code&gt;Linux&lt;/code&gt; 会尽可能利用内存进行缓存。但是缓存的回收也是需要资源的，比较好的一篇文章是 Poor Zorro 写的 &lt;code&gt;Linux&lt;/code&gt; 内存中的 Cache 真的能被回收么？。&lt;/p&gt;
&lt;p&gt;虽然大部分情况下我们看到 &lt;code&gt;Cache&lt;/code&gt; 占用很高时是没有问题的，但是我们还是想弄清楚到底是哪个程序把 &lt;code&gt;Cache&lt;/code&gt; 弄的那么高，这居然不是一件容易的事。&lt;/p&gt;
&lt;p&gt;内核的模块在分配资源的时候，为了提高效率和资源的利用率，都是透过 &lt;code&gt;Slab&lt;/code&gt; 来分配的。&lt;code&gt;Slab&lt;/code&gt; 为结构性缓存占用内存，该项也经常占用很大的内存。不过借助 &lt;code&gt;slabtop&lt;/code&gt; 工具，我们可以很方便的显示内核片缓存信息，该工具可以更直观的显示 &lt;code&gt;/proc/slabinfo&lt;/code&gt; 下的内容。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 显示了一台机器缓存中占用对象的情况&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ slabtop -s c &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Active &amp;#x2F; Total Objects (% used)    : 856448 &amp;#x2F; 873737 (98.0%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Active &amp;#x2F; Total Slabs (% used)      : 19737 &amp;#x2F; 19737 (100.0%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Active &amp;#x2F; Total Caches (% used)     : 67 &amp;#x2F; 89 (75.3%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Active &amp;#x2F; Total Size (% used)       : 141806.80K &amp;#x2F; 145931.33K (97.2%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Minimum &amp;#x2F; Average &amp;#x2F; Maximum Object : 0.01K &amp;#x2F; 0.17K &amp;#x2F; 8.00K&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ&amp;#x2F;SLAB CACHE SIZE NAME&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;416949 416949 100%    0.10K  10691	 39     42764K buffer_head&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  5616   5545  98%    2.00K    351	 16     11232K kmalloc-2048&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  9114   8990  98%    1.02K    294	 31	 9408K ext4_inode_cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 12404  12404 100%    0.57K    443	 28	 7088K radix_tree_node&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 10800  10731  99%    0.58K    400	 27	 6400K inode_cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 31290  29649  94%    0.19K    745	 42	 5960K dentry&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  3552   3362  94%    1.00K    111	 32	 3552K kmalloc-1024&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1100   1055  95%    2.84K    100	 11	 3200K task_struct&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1649   1481  89%    1.88K     97	 17	 3104K TCP&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 27000  27000 100%    0.11K    750	 36	 3000K sysfs_dir_cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1380   1269  91%    2.06K     92	 15	 2944K sighand_cache&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;虽然上面的命令显示了 &lt;code&gt;Cache&lt;/code&gt; 中 &lt;code&gt;Slab&lt;/code&gt; 的情况，但是还是没有显示什么程序占用的 &lt;code&gt;Cache&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>分享几种终端下快速获取公网 IP 地址的技巧</title>
    <link href="https://www.hi-linux.com/posts/62581.html"/>
    <id>https://www.hi-linux.com/posts/62581.html</id>
    <published>2020-05-23T02:09:00.000Z</published>
    <updated>2020-05-23T14:23:04.830Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在排除网络问题，建立新连接或配置防火墙时，了解设备的 IP 地址很重要。</p><p>IP 地址可以分为两类，公用和私有(专用)。公用 IP 是唯一的 IP 地址，可以从 Internet 访问。专用 IP 地址保留供您专用网络内部使用，而不会直接暴露给 Internet。此外，有两种类型的 IP 地址，即 IP 版本4（IPv4）和 IP 版本6（IPv6）。</p><p>本文将介绍几种确定 Linux 系统的公共 IP 地址和私有 IP 地址的不同方法。</p><h2 id="查找你的私有-ip-地址">查找你的私有 IP 地址</h2><p>专用 IP 地址不可通过 Internet 路由，并且只能在本地网络内工作。通常，专用 IP 地址是由路由器分配给本地网络中的每个设备的。这为本地网络中的设备（例如电话、笔记本电脑、智能电视、打印机、媒体中心等）提供了唯一的 IP 地址。本地网络上的设备通过 NAT（网络地址转换）连接到 Internet。</p><p>以下 IPv4 地址范围是为专用网络保留的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br></pre></td></tr></table></figure><p>你可以通过使用诸如 <code>ip</code>、<code>ifconfig</code> 或 <code>hostname</code> 命令查询网络堆栈确定系统的私有 IP 地址。</p><p>在 Linux 中，用于显示和配置网络接口的标准工具是 <code>ip</code>。</p><p>要显示所有网络接口和关联的 IP 地址的列表，请键入以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip addr</span><br></pre></td></tr></table></figure><p>输出如下所示。专用 IP 地址突出显示。</p><p><img src="https://linuxize.com/post/how-to-find-ip-address-linux/private-ip.jpg" alt=""></p><p>你还可以使用以下命令来显示私有 IP 地址：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hostname -I</span><br><span class="line"></span><br><span class="line">$ ifconfig</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="查找你的公共-ip-地址">查找你的公共 IP 地址</h2><p>公共 IP 地址是分配给网络设备的全球可路由 IP 地址，它允许直接访问 Internet。它们由其 ISP 分配给设备，并且每个设备都有唯一的公共 IP 地址。公用 IP 地址由家庭路由器、Web 服务器、邮件服务器等使用。</p><p>确定公共 IP 地址可以通过 <code>HTTP/HTTPS</code> 或 <code>DNS</code> 协议联系远程服务器，并从远程服务器响应中获取 IP 地址。</p><p>如果你是在没有 GUI 的 Linux 服务器上获取你分配到的公网 IP 地址，你可以使用命令行工具 <code>dig</code>、<code>curl</code> 和 <code>wget</code> 等来获取。</p><p>大多数 DNS 提供商（例如：OpenDNS 和 Google）都允许你查询其服务器并获取你的公共 IP 地址。你可以使用以下任何命令来获取公网 IP：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ dig ANY +short @resolver2.opendns.com myip.opendns.com</span><br><span class="line"></span><br><span class="line">$ dig ANY +short @resolver2.opendns.com myip.opendns.com</span><br><span class="line"></span><br><span class="line">$ dig ANY +short @ns1-1.akamaitech.net ANY whoami.akamai.net</span><br></pre></td></tr></table></figure><p>另外，有许多在线 <code>HTTP/HTTPS</code> 服务可以返回你的公共 IP 地址。这里是其中的一些：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ curl -s http://tnx.nl/ip</span><br><span class="line"></span><br><span class="line">$ curl -s https://checkip.amazonaws.com</span><br><span class="line"></span><br><span class="line">$ curl -s api.infoip.io/ip</span><br><span class="line"></span><br><span class="line">$ curl -s ip.appspot.com</span><br><span class="line"></span><br><span class="line">$ wget -O - -q https://icanhazip.com/</span><br></pre></td></tr></table></figure><p>为了方便使用，你还可以创建一个别名来方便查询。例如，你可以在 <code>~/.bashrc</code> 和 <code>~/.zshrc</code> 中添加以下别名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> pubip=<span class="string">'dig ANY +short @resolver2.opendns.com myip.opendns.com'</span></span><br></pre></td></tr></table></figure><p>现在，你要查找公共 IP 时，只需键入 <code>pubip</code> 命令即可。</p><h2 id="结论">结论</h2><p>至此，我们向你展示了通过几种不同的命令和在线服来查找私有和公共 IP 地址的方法，希望对你有所帮助！</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://url.cn/5eJaO9n" target="_blank" rel="noopener">https://url.cn/5eJaO9n</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在排除网络问题，建立新连接或配置防火墙时，了解设备的 IP 地址很重要。&lt;/p&gt;
&lt;p&gt;IP 地址可以分为两类，公用和私有(专用)。公用 IP 是唯一的 IP 地址，可以从 Internet 访问。专用 IP 地址保留供您专用网络内部使用，而不会直接暴露给 Internet。此外，有两种类型的 IP 地址，即 IP 版本4（IPv4）和 IP 版本6（IPv6）。&lt;/p&gt;
&lt;p&gt;本文将介绍几种确定 Linux 系统的公共 IP 地址和私有 IP 地址的不同方法。&lt;/p&gt;
&lt;h2 id=&quot;查找你的私有-IP-地址&quot;&gt;查找你的私有 IP 地址&lt;/h2&gt;
&lt;p&gt;专用 IP 地址不可通过 Internet 路由，并且只能在本地网络内工作。通常，专用 IP 地址是由路由器分配给本地网络中的每个设备的。这为本地网络中的设备（例如电话、笔记本电脑、智能电视、打印机、媒体中心等）提供了唯一的 IP 地址。本地网络上的设备通过 NAT（网络地址转换）连接到 Internet。&lt;/p&gt;
&lt;p&gt;以下 IPv4 地址范围是为专用网络保留的：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;10.0.0.0/8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.0.0/12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192.168.0.0/16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;你可以通过使用诸如 &lt;code&gt;ip&lt;/code&gt;、&lt;code&gt;ifconfig&lt;/code&gt; 或 &lt;code&gt;hostname&lt;/code&gt; 命令查询网络堆栈确定系统的私有 IP 地址。&lt;/p&gt;
&lt;p&gt;在 Linux 中，用于显示和配置网络接口的标准工具是 &lt;code&gt;ip&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;要显示所有网络接口和关联的 IP 地址的列表，请键入以下命令：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ip addr&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;输出如下所示。专用 IP 地址突出显示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://linuxize.com/post/how-to-find-ip-address-linux/private-ip.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;你还可以使用以下命令来显示私有 IP 地址：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hostname -I&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ ifconfig&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="终端" scheme="https://www.hi-linux.com/tags/%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>几种 Docker 和 Kubernetes 镜像源不可用的解决方法</title>
    <link href="https://www.hi-linux.com/posts/3814.html"/>
    <id>https://www.hi-linux.com/posts/3814.html</id>
    <published>2020-05-23T02:08:00.000Z</published>
    <updated>2020-05-23T14:23:04.828Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>由于众所周知的原因， Docker 官方镜像仓库和 Google 镜像仓库在国内访问速度很慢或者不可用。这样就给我们在部署和使用 Kubernetes 时带来了极大的不便。今天我们就来介绍几种方法，可以让你愉快的解决该问题。</p><p>既然是网络方面的问题，解决该问题的思路就很简单了，当然是使用国内可用的镜像源。这里为大家推荐两个好用的国内镜像源：Azure 中国镜像源和中科大镜像源。</p><p><strong>Azure 中国镜像源</strong></p><ul><li><p>Azure 中国镜像源地址：<a href="http://mirror.azure.cn/" target="_blank" rel="noopener">http://mirror.azure.cn/</a></p></li><li><p>Azure 中国镜像源 Github 地址：<a href="https://github.com/Azure/container-service-for-azure-china" target="_blank" rel="noopener">https://github.com/Azure/container-service-for-azure-china</a></p></li><li><p>镜像源配置说明：<a href="http://mirror.azure.cn/help/gcr-proxy-cache.html" target="_blank" rel="noopener">http://mirror.azure.cn/help/gcr-proxy-cache.html</a></p></li></ul><p><strong>中科大镜像源</strong></p><ul><li><p>中科大镜像源地址：<a href="http://mirrors.ustc.edu.cn/" target="_blank" rel="noopener">http://mirrors.ustc.edu.cn/</a></p></li><li><p>中科大镜像源 Github 地址：<a href="https://github.com/ustclug/mirrorrequest" target="_blank" rel="noopener">https://github.com/ustclug/mirrorrequest</a></p></li><li><p>镜像源配置说明：<a href="https://github.com/ustclug/mirrorrequest/issues/187" target="_blank" rel="noopener">https://github.com/ustclug/mirrorrequest/issues/187</a></p></li></ul><a id="more"></a><h2 id="使用镜像源加速-dockerio-镜像仓库">使用镜像源加速 <a href="http://Docker.io" target="_blank" rel="noopener">Docker.io</a> 镜像仓库</h2><p><a href="http://hub.docker.com" target="_blank" rel="noopener">hub.docker.com</a> 是 Docker 官方镜像仓库，也是我们平时在使用 Docker 过程使用最多的一个镜像仓库。该镜像仓库平时拉取速度通常就只有几十 Kb，非常的慢，使用起来严重影响了工作效率。</p><p>既然现在国内有镜像源可用，我们当然直接使国内镜像源便可。下面分别对其使用方法进行介绍。</p><ul><li>如果在 Docker 官方仓库拉取的是官方镜像</li></ul><p>拉取方法类似如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull xxx:yyy</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;library&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;library&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><ul><li>如果在 Docker 官方仓库拉取的镜像是私有仓库</li></ul><p>拉取方法类似如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull xxx&#x2F;yyy:zz</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;xxx&#x2F;yyy:zz</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;xxx&#x2F;yyy:zz</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 mysql:5.7 和 360cloud/wayne 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;library&#x2F;mysql:5.7</span><br><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;360cloud&#x2F;wayne</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;library&#x2F;mysql:5.7</span><br><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;360cloud&#x2F;wayne</span><br></pre></td></tr></table></figure><blockquote><p>注：首次拉取时可能会有 <code>Error:image library/mysql:5.7 not found</code> 类似报错，这说明镜像源中没有缓存该镜像。这个属于正常现像，因为加速镜像都是先从官方镜像仓库进行拉取的，然后缓存到本地。遇到这种情况，你可以尝试多拉取几次即可。</p></blockquote><h2 id="使用镜像源加速-gcrio-镜像仓库">使用镜像源加速 <a href="http://gcr.io" target="_blank" rel="noopener">gcr.io</a> 镜像仓库</h2><ul><li>如果拉取的 Google 镜像仓库中容器镜像类似如下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.io&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.azk8s.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 <a href="http://gcr.io/kubernetes-helm/tiller:v2.9.1" target="_blank" rel="noopener">gcr.io/kubernetes-helm/tiller:v2.9.1</a> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;kubernetes-helm&#x2F;tiller:v2.9.1</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull gcr.azk8s.cn&#x2F;kubernetes-helm&#x2F;tiller:v2.9.1</span><br></pre></td></tr></table></figure><h2 id="使用镜像源加速-k8sgcrio-镜像仓库">使用镜像源加速 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a> 镜像仓库</h2><p>部署或使用 Kubernetes 时我们会使用到很多相关的镜像，而这些镜像通常会使用 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a> 这个镜像仓库。</p><p>其实 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a> 就是 <a href="http://gcr.io/google-containers" target="_blank" rel="noopener">gcr.io/google-containers</a> 下面的容器镜像，这样我们也可以使用中科大镜像源或者 Azure 中国镜像源来对此进行加速。</p><ul><li>如果我们拉取的 Kubernetes 所需容器镜像类似以下形式：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull k8s.gcr.io&#x2F;xxx:yyy</span><br><span class="line"></span><br><span class="line"># 相当于</span><br><span class="line">$ docker pull gcr.io&#x2F;google-containers&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;google-containers&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.azk8s.cn&#x2F;google-containers&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 <a href="http://k8s.gcr.io/addon-resizer:1.8.3" target="_blank" rel="noopener">k8s.gcr.io/addon-resizer:1.8.3</a> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;google-containers&#x2F;addon-resizer:1.8.3</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull gcr.azk8s.cn&#x2F;google-containers&#x2F;addon-resizer:1.8.3</span><br></pre></td></tr></table></figure><h2 id="使用镜像源加速-quayio-镜像仓库">使用镜像源加速 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 镜像仓库</h2><p>部署或使用 Kubernetes 相关周边组件或生态时我们经常会从 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 镜像仓库拉取镜像。<a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 默认情况下在国内也是不可用的，同样我们也可以通过中科大镜像源和 Azure 中国镜像源进行加速访问。</p><ul><li>如果我们拉取的 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 下所需容器镜像类似以下形式：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull quay.io&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull quay.mirrors.ustc.edu.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull quay.azk8s.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 <a href="http://quay.io/coreos/kube-state-metrics:v1.5.0" target="_blank" rel="noopener">quay.io/coreos/kube-state-metrics:v1.5.0</a> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull quay.mirrors.ustc.edu.cn&#x2F;coreos&#x2F;kube-state-metrics:v1.5.0</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull quay.azk8s.cn&#x2F;coreos&#x2F;kube-state-metrics:v1.5.0</span><br></pre></td></tr></table></figure><h2 id="一些自动化工具">一些自动化工具</h2><p>上面我们讲解和演示了如何使用中科大和 Azure 中国镜像源加速拉取镜像的方法。不过这些方法都是手动的，还不够方便。下面将介绍两个小工具，让你可以更加方便和快速的使用这些镜像源。</p><h3 id="docker-wrapper">docker-wrapper</h3><p>一个 Python 编写的工具脚本，可以替代系统的 Docker 命令，自动从 Azure 中国拉取镜像并自动 Tag 为目标镜像和删除 Azure 镜像，一气呵成。</p><p>项目地址：<a href="https://github.com/silenceshell/docker_wrapper" target="_blank" rel="noopener">https://github.com/silenceshell/docker_wrapper</a></p><p><strong>docker-wrapper 安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;silenceshell&#x2F;docker-wrapper.git</span><br><span class="line">$ sudo cp docker-wrapper&#x2F;docker-wrapper.py &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p><strong>docker-wrapper 使用</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker-wrapper pull k8s.gcr.io&#x2F;kube-apiserver:v1.14.1</span><br><span class="line">$ docker-wrapper pull gcr.io&#x2F;google_containers&#x2F;kube-apiserver:v1.14.1</span><br><span class="line">$ docker-wrapper pull nginx</span><br><span class="line">$ docker-wrapper pull silenceshell&#x2F;godaddy:0.0.2</span><br></pre></td></tr></table></figure><h3 id="azk8spull">azk8spull</h3><p>一个 Shell 编写的脚本，这个脚本功能和 docker-wrapper 类似。同样可以自动从 Azure 中国拉取镜像并自动 Tag 为目标镜像和删除 Azure 镜像。</p><p>项目地址：<a href="https://github.com/xuxinkun/littleTools#azk8spull" target="_blank" rel="noopener">https://github.com/xuxinkun/littleTools#azk8spull</a></p><p><strong>azk8spull 安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;xuxinkun&#x2F;littleTools</span><br><span class="line">$ cd littleTools</span><br><span class="line">$ chmod +x install.sh</span><br><span class="line">$ .&#x2F;install.sh</span><br></pre></td></tr></table></figure><p><strong>azk8spull 使用</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ azk8spull quay.io&#x2F;kubernetes-ingress-controller&#x2F;nginx-ingress-controller:0.24.1</span><br><span class="line">$ azk8spull k8s.gcr.io&#x2F;pause-amd64:3.1</span><br></pre></td></tr></table></figure><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://ieevee.com/tech/2019/03/02/azure-gcr-proxy.html" target="_blank" rel="noopener">https://ieevee.com/tech/2019/03/02/azure-gcr-proxy.html</a></p></li><li><p><a href="https://www.cnblogs.com/xuxinkun/p/11025020.html" target="_blank" rel="noopener">https://www.cnblogs.com/xuxinkun/p/11025020.html</a></p></li><li><p><a href="https://www.ilanni.com/?p=14534" target="_blank" rel="noopener">https://www.ilanni.com/?p=14534</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;由于众所周知的原因， Docker 官方镜像仓库和 Google 镜像仓库在国内访问速度很慢或者不可用。这样就给我们在部署和使用 Kubernetes 时带来了极大的不便。今天我们就来介绍几种方法，可以让你愉快的解决该问题。&lt;/p&gt;
&lt;p&gt;既然是网络方面的问题，解决该问题的思路就很简单了，当然是使用国内可用的镜像源。这里为大家推荐两个好用的国内镜像源：Azure 中国镜像源和中科大镜像源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Azure 中国镜像源&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Azure 中国镜像源地址：&lt;a href=&quot;http://mirror.azure.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirror.azure.cn/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Azure 中国镜像源 Github 地址：&lt;a href=&quot;https://github.com/Azure/container-service-for-azure-china&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/Azure/container-service-for-azure-china&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;镜像源配置说明：&lt;a href=&quot;http://mirror.azure.cn/help/gcr-proxy-cache.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirror.azure.cn/help/gcr-proxy-cache.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;中科大镜像源&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;中科大镜像源地址：&lt;a href=&quot;http://mirrors.ustc.edu.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirrors.ustc.edu.cn/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;中科大镜像源 Github 地址：&lt;a href=&quot;https://github.com/ustclug/mirrorrequest&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/ustclug/mirrorrequest&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;镜像源配置说明：&lt;a href=&quot;https://github.com/ustclug/mirrorrequest/issues/187&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/ustclug/mirrorrequest/issues/187&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款 Github 命令行管理神器 Hub</title>
    <link href="https://www.hi-linux.com/posts/28689.html"/>
    <id>https://www.hi-linux.com/posts/28689.html</id>
    <published>2020-05-23T02:07:00.000Z</published>
    <updated>2020-05-23T14:23:04.839Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>对于大多数使用 <code>Git</code> 作为版本管理的技术人员来说，应该都接触过 <code>GitHub</code>。 <code>GitHub</code> 就像技术人员的淘宝一样，里面充满了好东西，时时刻刻都可能给你惊喜！</p><p>很多人可能不仅在 <code>GitHub</code> 上寻找合适的车轮子，还可能会为造车轮子贡献自己的力量，往往会使用一些基本操作来完成，典型的为：</p><ul><li><p>Fork</p></li><li><p>PR (pull request)</p></li></ul><p>当然，如果你是项目的维护者，还会使用 <code>Merge</code> 等操作。</p><p>但是，我想很少人会使用过 <code>GitHub</code> 的命令行接口 <code>Hub</code>， 通常的操作我们都可以通过友好的 <code>Web</code> 界面，点几个按钮来完成，简单实用！所以很少有需求会迫切需要一个命令行工具来完成这些操作，但是如果需要批量操作时 (比如：清除多个 <code>Repositories</code> 的时候)，你会发现一个一个在 Web 上来操作的确不够高效。这时如果有命令行工具可以快速进行批量操作，那就是极好的。</p><p>今天就给大家推荐一个 <code>GitHub</code> 的命令行工具 <code>Hub</code>，其官方主页上是这样介绍的：</p><blockquote><p>git + hub = github</p></blockquote><p><code>Hub</code> 命令是对 <code>Git</code> 命令的一层封装，利用 <code>GitHub</code> 的 <code>API</code> 可以轻松的扩展 <code>Git</code> 的能力，比如常见的 <code>Pull Requests</code> 都可以通过命令行来实现。</p><blockquote><p>项目地址：<a href="https://github.com/github/hub" target="_blank" rel="noopener">https://github.com/github/hub</a></p></blockquote><a id="more"></a><h2 id="安装-hub">安装 Hub</h2><p><code>Hub</code> 的安装很简单，基本上所有的主流平台上都支持一键安装。</p><p><img src="https://i.loli.net/2019/10/30/ENKUdWsF7COuqLx.png" alt=""></p><blockquote><p>由于 <code>Hub</code> 是对 <code>Git</code> 命令的封装，安装前请保证机器上的 <code>Git</code> 版本在 <code>1.7.3</code> 或以上。</p></blockquote><p>如果你使用平台不在上面列表中，你也可以直接在官方项目的 <a href="https://github.com/github/hub/releases" target="_blank" rel="noopener">Releases 页面</a>下载 <code>Hub</code> 的二进制包进行安装。</p><p>为了快速实现通过二进制包安装，你还可以使用下面这个脚本来简化操作步骤。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里以 Linux 平台为例，如果是其它版本或平台，只需简单替换 VERSION 变量和对应文件名前缀即可。</span></span><br><span class="line">VERSION=<span class="string">"2.12.8"</span></span><br><span class="line">wget https://github.com/github/hub/releases/download/v<span class="variable">$VERSION</span>/hub-linux-amd64-<span class="variable">$VERSION</span>.tgz</span><br><span class="line">tar xzvf hub-linux-amd64-<span class="variable">$VERSION</span>.tgz</span><br><span class="line">sudo ./hub-linux-amd64-<span class="variable">$VERSION</span>/install</span><br></pre></td></tr></table></figure><h2 id="配置-hub">配置 Hub</h2><p>当第一次和 <code>GitHub</code> 有交互时会弹出用户名和密码用来生成 <code>OAuth Token</code>，<code>Token</code> 保存在 <code>~/.config/hub</code> 文件中。或者你也可以通过 <code>GITHUB_TOKEN</code> 环境变量来进行授权，其值是拥有 <code>Repo</code> 权限的 <code>Access Token</code>。</p><p>如果你使用的是 <code>ZSH</code>，还可以给 <code>Hub</code> 配置一个自动完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup autocomplete for zsh:</span></span><br><span class="line">mkdir -p ~/.zsh/completions</span><br><span class="line">cp ./hub-linux-amd64-<span class="variable">$VERSION</span>/etc/hub.zsh_completion ~/.zsh/completions/_hub</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"fpath=(~/.zsh/completions <span class="variable">$fpath</span>)"</span> &gt;&gt; ~/.zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"autoload -U compinit &amp;&amp; compinit"</span> &gt;&gt; ~/.zshrc</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"eval "</span>$(hub <span class="built_in">alias</span> -s)<span class="string">""</span> &gt;&gt; ~/.zshrc</span><br></pre></td></tr></table></figure><h2 id="使用-hub">使用 Hub</h2><h3 id="常用命令介绍">常用命令介绍</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">usage: git [--version] [--<span class="built_in">help</span>] [-C &lt;path&gt;] [-c name=value]</span><br><span class="line">           [--<span class="built_in">exec</span>-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]</span><br><span class="line">           [-p | --paginate | --no-pager] [--no-replace-objects] [--bare]</span><br><span class="line">           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]</span><br><span class="line">           &lt;<span class="built_in">command</span>&gt; [&lt;args&gt;]</span><br><span class="line"></span><br><span class="line">These are common Git commands used <span class="keyword">in</span> various situations:</span><br><span class="line"></span><br><span class="line">start a working area (see also: git <span class="built_in">help</span> tutorial)</span><br><span class="line">   <span class="built_in">clone</span>      Clone a repository into a new directory <span class="comment"># 使用 hub clone 命令，可以省去指定 GitHub 端仓库的部分。</span></span><br><span class="line">   init       Create an empty Git repository or reinitialize an existing one</span><br><span class="line"></span><br><span class="line">work on the current change (see also: git <span class="built_in">help</span> everyday)</span><br><span class="line">   add        Add file contents to the index</span><br><span class="line">   mv         Move or rename a file, a directory, or a symlink</span><br><span class="line">   reset      Reset current HEAD to the specified state</span><br><span class="line">   rm         Remove files from the working tree and from the index</span><br><span class="line"></span><br><span class="line">examine the <span class="built_in">history</span> and state (see also: git <span class="built_in">help</span> revisions)</span><br><span class="line">   bisect     Use binary search to find the commit that introduced a bug</span><br><span class="line">   grep       Print lines matching a pattern</span><br><span class="line">   <span class="built_in">log</span>        Show commit logs</span><br><span class="line">   show       Show various types of objects</span><br><span class="line">   status     Show the working tree status</span><br><span class="line"></span><br><span class="line">grow, mark and tweak your common <span class="built_in">history</span></span><br><span class="line">   branch     List, create, or delete branches</span><br><span class="line">   checkout   Switch branches or restore working tree files</span><br><span class="line">   commit     Record changes to the repository</span><br><span class="line">   diff       Show changes between commits, commit and working tree, etc</span><br><span class="line">   merge      Join two or more development histories together</span><br><span class="line">   rebase     Reapply commits on top of another base tip</span><br><span class="line">   tag        Create, list, delete or verify a tag object signed with GPG</span><br><span class="line"></span><br><span class="line">collaborate (see also: git <span class="built_in">help</span> workflows)</span><br><span class="line">   fetch      Download objects and refs from another repository</span><br><span class="line">   pull       Fetch from and integrate with another repository or a <span class="built_in">local</span> branch</span><br><span class="line">   push       Update remote refs along with associated objects   <span class="comment"># hub push 命令支持通知向多个远程仓库进行 push 操作。</span></span><br><span class="line"></span><br><span class="line"><span class="string">'git help -a'</span> and <span class="string">'git help -g'</span> list available subcommands and some</span><br><span class="line">concept guides. See <span class="string">'git help &lt;command&gt;'</span> or <span class="string">'git help &lt;concept&gt;'</span></span><br><span class="line">to <span class="built_in">read</span> about a specific subcommand or concept.</span><br><span class="line"></span><br><span class="line">These GitHub commands are provided by hub:</span><br><span class="line"></span><br><span class="line">   browse         Open a GitHub page <span class="keyword">in</span> the default browser</span><br><span class="line">   ci-status      Show the CI status of a commit</span><br><span class="line">   compare        Open a compare page on GitHub</span><br><span class="line">   create         Create this repository on GitHub and add GitHub as origin <span class="comment"># hub create 命令适用于本地已经创建仓库，但 GitHub 端没有创建仓库的情况。</span></span><br><span class="line">   fork           Make a fork of a remote repository on GitHub and add as remote <span class="comment"># hub fork 命令的功能与 GitHub 页面的 Fork 按钮相同。</span></span><br><span class="line">   issue          List or create issues</span><br><span class="line">   pr             Work with pull requests</span><br><span class="line">   pull-request   Open a pull request on GitHub <span class="comment"># hub  pull-request 命令为我们提供了创建 Pull Request 的功能，利用这个命令可以在不访问 GitHub 页面的情况下创建 Pull Request。</span></span><br><span class="line">   release        List or create releases</span><br></pre></td></tr></table></figure><h3 id="使用实例">使用实例</h3><p>这里以一个开源项目贡献者的身份为例，你可以使用命令来拉取代码、浏览页面、<code>Fork Repos</code> 和提交 <code>Pull Requests</code> 等等。</p><ol><li>Fork 一个项目</li></ol><p>要在 <code>GitHub</code> 上进行开发，往往会基于一个已有的开源项目，所以首先需要 <code>Fork</code> 这个项目。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ hub <span class="built_in">clone</span> github/hub</span><br><span class="line">Cloning into <span class="string">'hub'</span>...</span><br><span class="line">remote: Counting objects: 10646, <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (24/24), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 10646 (delta 4), reused 0 (delta 0)</span><br><span class="line">Receiving objects: 100% (10646/10646), 3.25 MiB | 58.00 KiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (6302/6302), <span class="keyword">done</span>.</span><br><span class="line">Checking connectivity... <span class="keyword">done</span>.</span><br><span class="line">$ <span class="built_in">cd</span> hub/</span><br><span class="line">$ hub fork</span><br><span class="line">Updating chengweiv5</span><br><span class="line">From git://github.com/github/hub</span><br><span class="line"> * [new branch]      1.11-stable -&gt; chengweiv5/1.11-stable</span><br><span class="line"> * [new branch]      1.12-stable -&gt; chengweiv5/1.12-stable</span><br><span class="line"> * [new branch]      gh-pages   -&gt; chengweiv5/gh-pages</span><br><span class="line"> * [new branch]      master     -&gt; chengweiv5/master</span><br><span class="line"> * [new branch]      skip_completion_script_for_windows -&gt; chengweiv5/skip_completion_script_for_windows</span><br><span class="line">new remote: chengweiv5</span><br></pre></td></tr></table></figure><p>这里和 <code>Web</code> 上的操作有点不同，从 <code>Web</code> 上是首先找到一个项目，然后点击一下 <code>Fork</code>， 然后会在自己的空间内创建这个项目。</p><p>而使用 <code>Hub</code>, 则首先是 <code>Clone</code> 下来原有的项目（以 <code>hub</code> 项目为例，<code>hub clone github/hub</code>），然后再执行 <code>Fork</code> 子命令。完成后，可以看到本地添加了一个 <code>Remote</code>，而且通过 <code>Web</code> 页面也可以看到自己的空间里已经添加了一个叫 <code>hub</code> 的项目，<code>Fork</code> 自 <code>github/hub</code>。</p><ol start="2"><li>PR (Pull Request)</li></ol><p>在本地完成一些开发后，可能想要将 <code>Patch</code> 提交给 <code>Upstream</code> 项目，在 <code>GitHub</code> 中，向上游提交 <code>Patch</code> 通过 <code>PR</code> 来完成。下面我们以 <code>sb2nov/mac-setup</code> 为例，来看一看整体过程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ hub <span class="built_in">clone</span> sb2nov/mac-setup</span><br><span class="line">Cloning into <span class="string">'mac-setup'</span>...</span><br><span class="line">remote: Counting objects: 1635, <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (49/49), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 1635 (delta 33), reused 0 (delta 0)</span><br><span class="line">Receiving objects: 100% (1635/1635), 3.69 MiB | 59.00 KiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (941/941), <span class="keyword">done</span>.</span><br><span class="line">Checking connectivity... <span class="keyword">done</span>.</span><br><span class="line">$ <span class="built_in">cd</span> mac-setup</span><br><span class="line">$ hub fork</span><br></pre></td></tr></table></figure><p>完成 <code>Fork</code> 后，将文档进行一个小修改，<code>diff</code> 如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ git diff</span><br><span class="line">diff --git a/SystemPreferences/README.md b/SystemPreferences/README.md</span><br><span class="line">index a148d74..a7ff953 100644</span><br><span class="line">--- a/SystemPreferences/README.md</span><br><span class="line">+++ b/SystemPreferences/README.md</span><br><span class="line">@@ -1,7 +1,7 @@</span><br><span class="line"> <span class="comment"># System Preferences</span></span><br><span class="line"> </span><br><span class="line"> First thing you need to <span class="keyword">do</span>, on any OS actually, is update the system! For that: **Apple Icon &gt; Software Update.**</span><br><span class="line">-Also upgrade your OS incase you want to work on the latest OS. Mavericks is a free upgrade so please check that.</span><br><span class="line">+Also upgrade your OS incase you want to work on the latest OS. Yosemite is a free upgrade so please check that.</span><br><span class="line"> </span><br><span class="line"> If this is a new computer, there are a couple tweaks you would like to make to the System Preferences. Feel free to follow these, or to ignore them, depending on your personal preferences.</span><br></pre></td></tr></table></figure><p><code>git pull-request</code> 会检查你在 <code>GitHub</code> 上的自己的项目和上游项目相应的 <code>Branch</code> 是否有不同。所以，首先将这个修改提交到自己的项目中，<code>Push</code> 就行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ git commit -asm <span class="string">"Yosemite is the latest Mac OS X now"</span></span><br><span class="line">$ git push chengweiv5</span><br><span class="line">Counting objects: 4, <span class="keyword">done</span>.</span><br><span class="line">Delta compression using up to 4 threads.</span><br><span class="line">Compressing objects: 100% (3/3), <span class="keyword">done</span>.</span><br><span class="line">Writing objects: 100% (4/4), 391 bytes | 0 bytes/s, <span class="keyword">done</span>.</span><br><span class="line">Total 4 (delta 2), reused 0 (delta 0)</span><br><span class="line">To git@github.com:chengweiv5/mac-setup.git</span><br><span class="line">   16df764..e25031f  master -&gt; master</span><br></pre></td></tr></table></figure><p>然后，提交 <code>PR</code>，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hub pull-request </span><br><span class="line">https://github.com/sb2nov/mac-setup/pull/27</span><br></pre></td></tr></table></figure><blockquote><p>注：为了统一命令操作，你可以直接将 <code>Hub</code> 命令设置为 <code>Git</code> 命令的别名，让执行 <code>Git</code> 操作的时候实际上是在执行 <code>Hub</code> 命令。别名设置方法如下：<code>eval &quot;$(hub alias -s)&quot;</code> 。</p></blockquote><p>除了以上例子外，<code>Hub</code> 还有许多有用的命令，比如：打开浏览器查看项目、<code>Merge PR</code>，新建 <code>Repo</code> 等等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># open the current project's issues page</span></span><br><span class="line">$ hub browse -- issues</span><br><span class="line">→ open https://github.com/github/hub/issues</span><br><span class="line"></span><br><span class="line"><span class="comment"># open another project's wiki</span></span><br><span class="line">$ hub browse mojombo/jekyll wiki</span><br><span class="line">→ open https://github.com/mojombo/jekyll/wiki</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new repository</span></span><br><span class="line">$ hub create sinatra/recipes</span><br><span class="line">[ repo created <span class="keyword">in</span> GitHub organization ]</span><br><span class="line">&gt; git remote add -f origin git@github.com:sinatra/recipes.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete an existing repository</span></span><br><span class="line">$ hub delete sinatra/recipes</span><br><span class="line">[ repo deleted <span class="keyword">in</span> GitHub organization ]</span><br></pre></td></tr></table></figure><p>这里就不再一一介绍了， 感兴趣的读者可以参考 <code>Hub</code> 官方文档进一步探索更多好玩好用的高级功能。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://www.jianshu.com/p/10b6e8d9420f" target="_blank" rel="noopener">https://www.jianshu.com/p/10b6e8d9420f</a></p></li><li><p><a href="http://www.chengweiyang.cn/2015/01/24/learn-github-hub/" target="_blank" rel="noopener">http://www.chengweiyang.cn/2015/01/24/learn-github-hub/</a></p></li><li><p><a href="http://einverne.github.io/post/2018/10/use-hub-command-to-interact-with-github.html" target="_blank" rel="noopener">http://einverne.github.io/post/2018/10/use-hub-command-to-interact-with-github.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于大多数使用 &lt;code&gt;Git&lt;/code&gt; 作为版本管理的技术人员来说，应该都接触过 &lt;code&gt;GitHub&lt;/code&gt;。 &lt;code&gt;GitHub&lt;/code&gt; 就像技术人员的淘宝一样，里面充满了好东西，时时刻刻都可能给你惊喜！&lt;/p&gt;
&lt;p&gt;很多人可能不仅在 &lt;code&gt;GitHub&lt;/code&gt; 上寻找合适的车轮子，还可能会为造车轮子贡献自己的力量，往往会使用一些基本操作来完成，典型的为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Fork&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PR (pull request)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然，如果你是项目的维护者，还会使用 &lt;code&gt;Merge&lt;/code&gt; 等操作。&lt;/p&gt;
&lt;p&gt;但是，我想很少人会使用过 &lt;code&gt;GitHub&lt;/code&gt; 的命令行接口 &lt;code&gt;Hub&lt;/code&gt;， 通常的操作我们都可以通过友好的 &lt;code&gt;Web&lt;/code&gt; 界面，点几个按钮来完成，简单实用！所以很少有需求会迫切需要一个命令行工具来完成这些操作，但是如果需要批量操作时 (比如：清除多个 &lt;code&gt;Repositories&lt;/code&gt; 的时候)，你会发现一个一个在 Web 上来操作的确不够高效。这时如果有命令行工具可以快速进行批量操作，那就是极好的。&lt;/p&gt;
&lt;p&gt;今天就给大家推荐一个 &lt;code&gt;GitHub&lt;/code&gt; 的命令行工具 &lt;code&gt;Hub&lt;/code&gt;，其官方主页上是这样介绍的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;git + hub = github&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Hub&lt;/code&gt; 命令是对 &lt;code&gt;Git&lt;/code&gt; 命令的一层封装，利用 &lt;code&gt;GitHub&lt;/code&gt; 的 &lt;code&gt;API&lt;/code&gt; 可以轻松的扩展 &lt;code&gt;Git&lt;/code&gt; 的能力，比如常见的 &lt;code&gt;Pull Requests&lt;/code&gt; 都可以通过命令行来实现。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/github/hub&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/github/hub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款免费访问谷歌的神器</title>
    <link href="https://www.hi-linux.com/posts/37040.html"/>
    <id>https://www.hi-linux.com/posts/37040.html</id>
    <published>2020-05-23T02:06:00.000Z</published>
    <updated>2020-05-23T14:23:04.842Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在「​<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247488197&amp;idx=1&amp;sn=1f722503d5f18ab8c6f4d9ba768d983b&amp;chksm=eac533ecddb2bafa6044ce24599ebd20b6fd1cd083a31b53d16730f35daaaffbbb902fc8d449&amp;token=524204938&amp;lang=zh_CN#rd" target="_blank" rel="noopener">推荐几个不追踪隐私的搜索引擎</a>」一文中我们介绍了几个在国内比百度好用的搜索引擎，但是这几个搜索引擎目前都还处于起步阶段，还是有很多不完善的地方。</p><p>对于大多技术人来说，遇到技术问题时，可能更多的还是需要：“Google 一下”。但由于众所周知的原因，在国内 Google 是不可用的，今天就给大家推荐一个简单易用神器「谷歌访问助手」。</p><blockquote><p>「谷歌访问助手」是一款专门为谷歌浏览器制作的浏览器插件，该插件可以解决无法访问谷歌搜索、谷歌商店、Gmail 邮箱、Google+ 等谷歌服务的问题，同时也能解决 Chrome 扩展无法自动更新的问题。</p></blockquote><p>不过该插件在不付费的情况下只能免费使用 12 小时，超过 12 小时之后就必须锁定你浏览器主页后，才能继续使用。</p><p>这样使用起来用户体验肯定是不友好的，有什么办法能解决呢？办法肯定是有的，注册成为付费用户当然是最简单的办法。</p><p>但如果你囊中羞涩也不是无法解决的，本文就为大家带来了一款可免费使用的神器「谷歌访问助手破解版」，该插件破除了 12 小时的限制。安装完成后，就可以直接访问。无需锁定任何主页，非常好用。</p><p>项目地址：<a href="https://github.com/haotian-wang/google-access-helper" target="_blank" rel="noopener">https://github.com/haotian-wang/google-access-helper</a></p><a id="more"></a><h2 id="安装谷歌访问助手破解版">安装谷歌访问助手破解版</h2><p><img src="https://i.loli.net/2019/08/13/zrMQBK6LIgWYe5P.jpg" alt=""></p><p>由于是破解版插件，固然是不能在应用商店直接安装的。首先你得手动下载该插件，方法有如下两种：</p><ol><li>克隆该项目仓库到本地</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 克隆项目仓库</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;haotian-wang&#x2F;google-access-helper.git</span><br></pre></td></tr></table></figure><ol start="2"><li>在仓库 Releases 页面下载打包好的压缩文件后进行解压。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 直接下载打包好的压缩文件并解压</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;haotian-wang&#x2F;google-access-helper&#x2F;archive&#x2F;v2.3.0.zip</span><br><span class="line">$ unzip google-access-helper-2.3.0.zip</span><br></pre></td></tr></table></figure><p>新版本 Chrome 目前已禁止使用 CRX 方式直接安装第三方插件应用，当下较为直接的安装方法就是在开发者模式下加载本插件。具体步骤如下：</p><ol><li><p>在 Chrome 地址栏输入 <code>chrome://extensions</code> 打开扩展程序管理器。</p></li><li><p>勾选开发者模式。</p></li><li><p>点击加载已解压的扩展程序，选择「谷歌访问助手破解版」插件所在目录。</p></li></ol><p><img src="https://i.loli.net/2019/08/13/KHv8JweBuVkWLoz.png" alt=""></p><p>如果你觉得上面的文字版安装方法讲得不够形象，也可以参考「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247487694&amp;idx=1&amp;sn=48c42b84005298bf10c0948583f3a28f&amp;chksm=eac531e7ddb2b8f1f71f3c60c346430542b01f5938b4619e36711ecd615a18912ff81bd7d05b&amp;token=524204938&amp;lang=zh_CN#rd" target="_blank" rel="noopener">推荐 10 款让你的 Chrome 浏览器功能更强大的插件</a>」一文中的图文版教程。</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://github.com/haotian-wang/google-access-helper" target="_blank" rel="noopener">https://github.com/haotian-wang/google-access-helper</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在「​&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247488197&amp;amp;idx=1&amp;amp;sn=1f722503d5f18ab8c6f4d9ba768d983b&amp;amp;chksm=eac533ecddb2bafa6044ce24599ebd20b6fd1cd083a31b53d16730f35daaaffbbb902fc8d449&amp;amp;token=524204938&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;推荐几个不追踪隐私的搜索引擎&lt;/a&gt;」一文中我们介绍了几个在国内比百度好用的搜索引擎，但是这几个搜索引擎目前都还处于起步阶段，还是有很多不完善的地方。&lt;/p&gt;
&lt;p&gt;对于大多技术人来说，遇到技术问题时，可能更多的还是需要：“Google 一下”。但由于众所周知的原因，在国内 Google 是不可用的，今天就给大家推荐一个简单易用神器「谷歌访问助手」。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;「谷歌访问助手」是一款专门为谷歌浏览器制作的浏览器插件，该插件可以解决无法访问谷歌搜索、谷歌商店、Gmail 邮箱、Google+ 等谷歌服务的问题，同时也能解决 Chrome 扩展无法自动更新的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不过该插件在不付费的情况下只能免费使用 12 小时，超过 12 小时之后就必须锁定你浏览器主页后，才能继续使用。&lt;/p&gt;
&lt;p&gt;这样使用起来用户体验肯定是不友好的，有什么办法能解决呢？办法肯定是有的，注册成为付费用户当然是最简单的办法。&lt;/p&gt;
&lt;p&gt;但如果你囊中羞涩也不是无法解决的，本文就为大家带来了一款可免费使用的神器「谷歌访问助手破解版」，该插件破除了 12 小时的限制。安装完成后，就可以直接访问。无需锁定任何主页，非常好用。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/haotian-wang/google-access-helper&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/haotian-wang/google-access-helper&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="谷歌" scheme="https://www.hi-linux.com/tags/%E8%B0%B7%E6%AD%8C/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款全功能 SFTP 服务器 SFTPGo</title>
    <link href="https://www.hi-linux.com/posts/185.html"/>
    <id>https://www.hi-linux.com/posts/185.html</id>
    <published>2020-05-23T02:05:00.000Z</published>
    <updated>2020-05-23T14:23:04.841Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>SFTPGo</code> 是一个全功能和高度可配置的 <code>SFTP</code> 服务器软件，这是 <code>Github</code> 上作者对这个软件的介绍。</p><blockquote><p>Full featured and highly configurable SFTP server software</p><p>项目地址：<a href="https://github.com/drakkan/sftpgo" target="_blank" rel="noopener">https://github.com/drakkan/sftpgo</a></p></blockquote><p>整体使用下来也名副其实，符合我的需求。但是因为官网上安装引导文档比较含糊，就记录一下自己折腾的过程。</p><p>以下的操作过程均基于一个全新安装的 <code>Ubuntu 18.04.2 LTS (Bionic Beaver)</code> 操作系统，按道理 <code>Debian</code> 也适用。</p><p>因为我自己只想配置一个独立的 <code>SFTP</code> 服务器，利用 <code>SFTPGo</code> 来协助管理账号，所以没有使用 <code>MySQL</code> / <code>PostreSQL</code> 之类的数据库，而选用了 <code>SQLite 3.x</code>.</p><h2 id="安装-sftpgo">安装 SFTPGo</h2><h3 id="sftpgo-需要的系统环境">SFTPGo 需要的系统环境</h3><ol><li><p>需要 <code>Go 1.12</code> 版本以上</p></li><li><p>需要一个数据库 ( <code>MySQL</code> / <code>PostreSQL</code> / <code>SQLite</code> )</p></li><li><p>如果需要运行 <code>Cli</code> 测试脚本，还需要 <code>Python</code> 环境和 <code>Request</code> 库。</p></li><li><p><code>Git</code> 命令</p></li></ol><a id="more"></a><h3 id="安装相关环境依赖">安装相关环境依赖</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository ppa:longsleep&#x2F;golang-backports</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install golang-go sqlite3 python3 python3-pip git</span><br></pre></td></tr></table></figure><h3 id="安装-sftpgo">安装 SFTPGo</h3><p>很简单，只需要执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go get -u github.com&#x2F;drakkan&#x2F;sftpgo</span><br></pre></td></tr></table></figure><p>然后在你的 <code>$GOPATH/bin/</code> 下找到 <code>sftpgo</code> 命令，如果你不知道你的 <code>$GOPATH</code> 目录，请执行 <code>go env</code> 查看你的环境变量。</p><p>这样就算安装完成了，但是具体要使用的话，还需要简单配置一下。</p><h2 id="配置-sftpgo">配置 SFTPGo</h2><h3 id="创建配置文件">创建配置文件</h3><p>首先，软链接或者移动 <code>$GOPATH/bin/sftpgo</code> 到 <code>/usr/bin/</code> 目录，使得系统能够找到 <code>sftpgo</code> 命令，下面是软链的方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ln -s $GOPATH&#x2F;bin&#x2F;sftpgo &#x2F;usr&#x2F;bin&#x2F;sftpgo</span><br></pre></td></tr></table></figure><p>接着，创建配置文件夹和添加 <code>SFTPGo</code> 的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir -p &#x2F;etc&#x2F;sftpgo &amp;&amp; cd &#x2F;etc&#x2F;sftpgo</span><br><span class="line">$ sudo wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;drakkan&#x2F;sftpgo&#x2F;master&#x2F;sftpgo.conf</span><br><span class="line"># sftpgo.conf 文件配置内容</span><br><span class="line">$ cat &#x2F;etc&#x2F;sftpgo&#x2F;sftpgo.conf</span><br><span class="line">&#123;</span><br><span class="line">  &quot;sftpd&quot;: &#123;</span><br><span class="line">    &quot;bind_port&quot;: 2022,</span><br><span class="line">    &quot;bind_address&quot;: &quot;&quot;,</span><br><span class="line">    &quot;idle_timeout&quot;: 15,</span><br><span class="line">    &quot;max_auth_tries&quot;: 0,</span><br><span class="line">    &quot;umask&quot;: &quot;0022&quot;,</span><br><span class="line">    &quot;banner&quot;: &quot;SFTPGo&quot;,</span><br><span class="line">    &quot;upload_mode&quot;: 0,</span><br><span class="line">    &quot;actions&quot;: &#123;</span><br><span class="line">      &quot;execute_on&quot;: [],</span><br><span class="line">      &quot;command&quot;: &quot;&quot;,</span><br><span class="line">      &quot;http_notification_url&quot;: &quot;&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;keys&quot;: []</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;data_provider&quot;: &#123;</span><br><span class="line">    &quot;driver&quot;: &quot;sqlite&quot;,</span><br><span class="line">    &quot;name&quot;: &quot;sftpgo.db&quot;,</span><br><span class="line">    &quot;host&quot;: &quot;&quot;,</span><br><span class="line">    &quot;port&quot;: 5432,</span><br><span class="line">    &quot;username&quot;: &quot;&quot;,</span><br><span class="line">    &quot;password&quot;: &quot;&quot;,</span><br><span class="line">    &quot;sslmode&quot;: 0,</span><br><span class="line">    &quot;connection_string&quot;: &quot;&quot;,</span><br><span class="line">    &quot;users_table&quot;: &quot;users&quot;,</span><br><span class="line">    &quot;manage_users&quot;: 1,</span><br><span class="line">    &quot;track_quota&quot;: 2</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;httpd&quot;: &#123;</span><br><span class="line">    &quot;bind_port&quot;: 8080,</span><br><span class="line">    &quot;bind_address&quot;: &quot;127.0.0.1&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="创建-sftpgo-相关数据库">创建 SFTPGo 相关数据库</h3><p>下载数据库文件并导入数据库，数据库文件可以放在任何地方。我为了方便演示，就一同放在了 <code>/etc/sftpgo</code> 目录下面。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;etc&#x2F;sftpgo</span><br><span class="line">$ sudo wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;drakkan&#x2F;sftpgo&#x2F;master&#x2F;sql&#x2F;sqlite&#x2F;20190706.sql</span><br><span class="line">$ sudo wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;drakkan&#x2F;sftpgo&#x2F;master&#x2F;sql&#x2F;sqlite&#x2F;20190728.sql</span><br><span class="line">$ sudo sqlite3 sftpgo.db &lt; 20190706.sql</span><br><span class="line">sqlite&gt; .exit</span><br><span class="line">$ sudo sqlite3 sftpgo.db &lt; 20190728.sql</span><br><span class="line">sqlite&gt; .exit</span><br></pre></td></tr></table></figure><p>但是我在直接使用迁移文件的时候报错了，貌似是不支持某个操作。</p><p>所以我直接合并了两条 <code>SQL</code> 语句，直接在库里面执行了。操作过程如下：（如果上面的操作出错了再尝试执行下面的，正常跳过这一步）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;etc&#x2F;sftpgo</span><br><span class="line">$ sudo rm sftpgo.db</span><br><span class="line">$ sudo sqlite3 sftpgo.db</span><br><span class="line">sqlite&gt; CREATE TABLE &quot;users&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;username&quot; varchar(255) NOT NULL UNIQUE, &quot;password&quot; varchar(255) NULL, &quot;public_key&quot; text NULL, &quot;home_dir&quot; varchar(255) NOT NULL, &quot;uid&quot; integer NOT NULL, &quot;gid&quot; integer NOT NULL, &quot;max_sessions&quot; integer NOT NULL, &quot;quota_size&quot; bigint NOT NULL, &quot;quota_files&quot; integer NOT NULL, &quot;permissions&quot; text NOT NULL, &quot;used_quota_size&quot; bigint NOT NULL, &quot;used_quota_files&quot; integer NOT NULL, &quot;last_quota_update&quot; bigint NOT NULL, &quot;upload_bandwidth&quot; integer NOT NULL, &quot;download_bandwidth&quot; integer NOT NULL);</span><br><span class="line">sqlite&gt; .table</span><br><span class="line">users</span><br><span class="line">sqlite&gt;</span><br></pre></td></tr></table></figure><p>这样数据库就算创建完成了。</p><blockquote><p>注：关于 <code>SQLite</code> 的操作说明请查看 SQLite 教程: <a href="https://www.runoob.com/sqlite/sqlite-tutorial.html" target="_blank" rel="noopener">https://www.runoob.com/sqlite/sqlite-tutorial.html</a></p></blockquote><h3 id="配置-sftpgo-的-systemd-服务">配置 SFTPGo 的 Systemd 服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;etc&#x2F;systemd&#x2F;system</span><br><span class="line">$ sudo wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;drakkan&#x2F;sftpgo&#x2F;master&#x2F;init&#x2F;sftpgo.service</span><br><span class="line">$ sudo systemctl daemon-reload</span><br><span class="line">$ sudo systemctl enable sftpgo.service</span><br><span class="line">$ sudo systemctl start sftpgo.service</span><br><span class="line">$ sudo systemctl status sftpgo.service</span><br></pre></td></tr></table></figure><p>上面的步骤操作完后，你就可以看到 <code>sftpgo.service</code> 的运行状态了。以下为 <code>sftpgo.service</code> 内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ cat  &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;sftpgo.service</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;SFTPGo sftp server</span><br><span class="line">After&#x3D;network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User&#x3D;root</span><br><span class="line">Group&#x3D;root</span><br><span class="line">Type&#x3D;simple</span><br><span class="line">WorkingDirectory&#x3D;&#x2F;etc&#x2F;sftpgo</span><br><span class="line">Environment&#x3D;SFTPGO_CONFIG_DIR&#x3D;&#x2F;etc&#x2F;sftpgo&#x2F;</span><br><span class="line">Environment&#x3D;SFTPGO_LOG_FILE_PATH&#x3D;&#x2F;var&#x2F;log&#x2F;sftpgo.log</span><br><span class="line">EnvironmentFile&#x3D;-&#x2F;etc&#x2F;sftpgo&#x2F;sftpgo.env</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;sftpgo</span><br><span class="line">KillMode&#x3D;mixed</span><br><span class="line">Restart&#x3D;always</span><br><span class="line">RestartSec&#x3D;10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>到这里，我们的 <code>SFTPGo</code> 软件就已经运行起来了，并且开启了一个 <code>127.0.0.1:8080</code> 的服务，我们可以通过它提供的 <code>REST API</code> 来进行 <code>SFTP</code> 的用户管理工作。</p><blockquote><p>注：因为安全的原因，这个服务只允许内网访问，如果想开放到外网，请自行搭建 <code>Nginx</code> / <code>Caddy</code> 等反向代理工具代理一下就行。</p></blockquote><h2 id="使用-sftpgo-rest-api">使用 SFTPGo REST API</h2><p>官方暂时没有提供管理操作面板，只提供了一个简单的基于 <code>Python</code> 的 <code>Cli</code> 工具 <code>sftpgo_api_cli</code>，这里就简单演示一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd ~</span><br><span class="line">$ sudo mkdir -p &#x2F;data&#x2F;sftp&#x2F;</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;drakkan&#x2F;sftpgo&#x2F;raw&#x2F;master&#x2F;scripts&#x2F;sftpgo_api_cli.py</span><br><span class="line">$ pip3 install requests</span><br><span class="line">$ python3 sftpgo_api_cli.py add_user test_username --password &quot;test_pwd&quot; --home_dir&#x3D;&quot;&#x2F;data&#x2F;sftp&#x2F;test_username&quot; --uid 33 --gid 1000 --max_sessions 2 --quota_size 0 --quota_files 0 --permissions * --upload_bandwidth 100 --download_bandwidth 60</span><br><span class="line">$ python3 sftpgo_api_cli.py get_users</span><br></pre></td></tr></table></figure><p>上面操作完成后，就简单创建了一个名为 <code>test_username</code> 的用户 ，并且把目录限制在 <code>/data/sftp/test_username</code> 下面。然后你可以用 <code>SFTP</code> 客户端 <code>FileZilla</code> 来测试一下，是否可以正常连接和上传。</p><p>更多详细的相关说明可以看官方 sftpgo_api_cli 使用文档：<a href="https://github.com/drakkan/sftpgo/tree/master/scripts" target="_blank" rel="noopener">https://github.com/drakkan/sftpgo/tree/master/scripts</a></p><h2 id="其他文档与相关配置说明">其他文档与相关配置说明</h2><ol><li><p>SFTPGo</p></li><li><p>REST API CLI client</p></li></ol><blockquote><p>来源：跨出界</p><p>原文：<a href="https://tinyurl.com/yxsebcv5" target="_blank" rel="noopener">https://tinyurl.com/yxsebcv5</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;SFTPGo&lt;/code&gt; 是一个全功能和高度可配置的 &lt;code&gt;SFTP&lt;/code&gt; 服务器软件，这是 &lt;code&gt;Github&lt;/code&gt; 上作者对这个软件的介绍。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Full featured and highly configurable SFTP server software&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/drakkan/sftpgo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/drakkan/sftpgo&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;整体使用下来也名副其实，符合我的需求。但是因为官网上安装引导文档比较含糊，就记录一下自己折腾的过程。&lt;/p&gt;
&lt;p&gt;以下的操作过程均基于一个全新安装的 &lt;code&gt;Ubuntu 18.04.2 LTS (Bionic Beaver)&lt;/code&gt; 操作系统，按道理 &lt;code&gt;Debian&lt;/code&gt; 也适用。&lt;/p&gt;
&lt;p&gt;因为我自己只想配置一个独立的 &lt;code&gt;SFTP&lt;/code&gt; 服务器，利用 &lt;code&gt;SFTPGo&lt;/code&gt; 来协助管理账号，所以没有使用 &lt;code&gt;MySQL&lt;/code&gt; / &lt;code&gt;PostreSQL&lt;/code&gt; 之类的数据库，而选用了 &lt;code&gt;SQLite 3.x&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;安装-SFTPGo&quot;&gt;安装 SFTPGo&lt;/h2&gt;
&lt;h3 id=&quot;SFTPGo-需要的系统环境&quot;&gt;SFTPGo 需要的系统环境&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;需要 &lt;code&gt;Go 1.12&lt;/code&gt; 版本以上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要一个数据库 ( &lt;code&gt;MySQL&lt;/code&gt; / &lt;code&gt;PostreSQL&lt;/code&gt; / &lt;code&gt;SQLite&lt;/code&gt; )&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果需要运行 &lt;code&gt;Cli&lt;/code&gt; 测试脚本，还需要 &lt;code&gt;Python&lt;/code&gt; 环境和 &lt;code&gt;Request&lt;/code&gt; 库。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Git&lt;/code&gt; 命令&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="SFTPGo" scheme="https://www.hi-linux.com/tags/SFTPGo/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟带你领略号称瑞士军刀的网络工具神器 Netcat</title>
    <link href="https://www.hi-linux.com/posts/29704.html"/>
    <id>https://www.hi-linux.com/posts/29704.html</id>
    <published>2020-05-23T02:04:00.000Z</published>
    <updated>2020-05-23T14:23:04.840Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Netcat（或 NC ）是一个命令行实用程序，它使用 TCP 或 UDP 协议跨网络连接读取和写入数据。它是网络和系统管理员中最强大的工具之一，被视为网络工具的瑞士军刀。</p><p>Netcat 是跨平台的，可用于 <code>Linux</code>、<code>macOS</code>、<code>Windows</code> 和 <code>BSD</code>。你可以使用 Netcat 调试和监视网络连接、扫描打开的端口、传输数据、作为代理等等。Netcat 软件包已预安装在 macOS 和大多数 Linux 发行版（如：Ubuntu）上。</p><h2 id="netcat-语法">Netcat 语法</h2><p>Netcat 命令的最基本语法采用以下形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc [options] host port</span><br></pre></td></tr></table></figure><p>在 Ubuntu 上，您可以使用 netcat 或 nc。它们都是 Netcat 的 openBSD 版本的符号链接。</p><p>默认情况下，Netcat 将尝试启动与指定主机和端口的 TCP 连接。如果要建立 UDP 连接，请使用以下 <code>-u</code> 选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -u host port</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="端口扫描">端口扫描</h2><p>扫描端口是 Netcat 最常见的用途之一。您可以扫描单个端口或端口范围。</p><p>例如，要扫描范围为 20-80 的开放端口，可以使用以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v 10.10.8.8 20-80</span><br></pre></td></tr></table></figure><p><code>-z</code> 选项将告诉 nc 你仅扫描打开的端口，而不向其发送任何数据，并使用 <code>-v</code> 提供更多详细信息。</p><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">nc: connect to 10.10.8.8 port 20 (tcp) failed: Connection refused</span><br><span class="line">nc: connect to 10.10.8.8 port 21 (tcp) failed: Connection refused</span><br><span class="line">Connection to 10.10.8.8 22 port [tcp&#x2F;ssh] succeeded!</span><br><span class="line">nc: connect to 10.10.8.8 port 23 (tcp) failed: Connection refused</span><br><span class="line">...</span><br><span class="line">nc: connect to 10.10.8.8 port 79 (tcp) failed: Connection refused</span><br><span class="line">Connection to 10.10.8.8 80 port [tcp&#x2F;http] succeeded!</span><br></pre></td></tr></table></figure><p>如果只想打印带有开放端口的行，则可以使用 <code>grep</code> 命令过滤结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v 10.10.8.8 20-80 2&gt;&amp;1 | grep succeeded</span><br><span class="line">Connection to 10.10.8.8 22 port [tcp&#x2F;ssh] succeeded!</span><br><span class="line">Connection to 10.10.8.8 80 port [tcp&#x2F;http] succeeded!</span><br></pre></td></tr></table></figure><p>你也可以使用 Netcat 查找服务器软件及其版本。例如，如果你在默认的 SSH 端口 22 上向服务器发送 <code>EXIT</code> 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ echo &quot;EXIT&quot; | nc 10.10.8.8 22</span><br></pre></td></tr></table></figure><p>将输出如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SSH-2.0-OpenSSH_7.6p1 Ubuntu-4</span><br><span class="line">Protocol mismatch.</span><br></pre></td></tr></table></figure><p>要扫描 UDP 端口，只需将 <code>-u</code> 选项添加到命令中，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v -u 10.10.8.8 20-80</span><br></pre></td></tr></table></figure><p>在大多数情况下，对于复杂的端口扫描，<code>Nmap</code> 是比 <code>Netcat</code> 更好的工具。</p><h2 id="通过-netcat-发送文件">通过 Netcat 发送文件</h2><p>通过创建基本的客户端/服务器模型，可以使用 Netcat 将数据从一台主机传输到另一台主机。</p><p>通过将 Netcat 在接收主机上的特定端口上监听（使用 <code>-l</code> 选项），然后与其他主机建立常规 TCP 连接并通过该主机发送文件。</p><p>在接收时，运行以下命令，它将打开端口 5555 进行传入连接，并将输出重定向到文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -l 5555 &gt; file_name</span><br></pre></td></tr></table></figure><p>从发送主机连接到接收主机并发送文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc receiving.host.com 5555 &lt; file_name</span><br></pre></td></tr></table></figure><p>如果要传输目录，可以使用 <code>tar</code> 在源主机上归档目录，并在目标主机上提取归档。</p><p>在接收主机上，设置 Netcat 工具以监听端口 5555 上的传入连接。传入数据通过管道传递到 <code>tar</code> 命令，该命令将提取存档：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -l 5555 | tar xzvf -</span><br></pre></td></tr></table></figure><p>在发送主机上的目录通过连接到 nc 接收主机上的监听进程来发送数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar czvf - &#x2F;path&#x2F;to&#x2F;dir | nc receiving.host.com 5555</span><br></pre></td></tr></table></figure><p>您可以在两端观察传输进度。完成后，键入 <code>CTRL+C</code> 以关闭连接。</p><h2 id="创建一个简单的聊天服务器">创建一个简单的聊天服务器</h2><p>在两个或多个主机之间创建在线聊天的过程与传输文件的方法是基本相同的。</p><p>在第一台主机上启动一个 Netcat 进程以侦听端口 5555：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -l 5555</span><br></pre></td></tr></table></figure><p>在第二台主机上，运行以下命令以连接到侦听端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc first.host.com 5555</span><br></pre></td></tr></table></figure><p>现在，如果你键入一条消息并按回车，它将同时显示在两台主机上。</p><p>要关闭连接，请键入 <code>CTRL+C</code>。</p><h2 id="执行-http-请求">执行 HTTP 请求</h2><p>尽管有许多更好的 HTTP 请求工具，例如：<code>curl</code>，你也可以使用 Netcat 将各种请求发送到远程服务器。</p><p>例如，要从 OpenBSD 网站检索 Netcat 的手册页，请输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ printf &quot;GET &#x2F;nc.1 HTTP&#x2F;1.1\r\nHost: man.openbsd.org\r\n\r\n&quot; | nc man.openbsd.org 80</span><br></pre></td></tr></table></figure><p>请求完成后，包括 HTTP 标头和 HTML 代码的完整响应将在终端中打印。</p><h2 id="结论">结论</h2><p>在本教程中，你学习了如何使用 Netcat 实用程序建立和测试 TCP 和 UDP 连接。如果你需要更多信息，请访问 Netcat 手册页，并阅读有关 Netcat 命令的所有其他强大选项的信息。</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://url.cn/5MTjaKh" target="_blank" rel="noopener">https://url.cn/5MTjaKh</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Netcat（或 NC ）是一个命令行实用程序，它使用 TCP 或 UDP 协议跨网络连接读取和写入数据。它是网络和系统管理员中最强大的工具之一，被视为网络工具的瑞士军刀。&lt;/p&gt;
&lt;p&gt;Netcat 是跨平台的，可用于 &lt;code&gt;Linux&lt;/code&gt;、&lt;code&gt;macOS&lt;/code&gt;、&lt;code&gt;Windows&lt;/code&gt; 和 &lt;code&gt;BSD&lt;/code&gt;。你可以使用 Netcat 调试和监视网络连接、扫描打开的端口、传输数据、作为代理等等。Netcat 软件包已预安装在 macOS 和大多数 Linux 发行版（如：Ubuntu）上。&lt;/p&gt;
&lt;h2 id=&quot;Netcat-语法&quot;&gt;Netcat 语法&lt;/h2&gt;
&lt;p&gt;Netcat 命令的最基本语法采用以下形式：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;nc [options] host port&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在 Ubuntu 上，您可以使用 netcat 或 nc。它们都是 Netcat 的 openBSD 版本的符号链接。&lt;/p&gt;
&lt;p&gt;默认情况下，Netcat 将尝试启动与指定主机和端口的 TCP 连接。如果要建立 UDP 连接，请使用以下 &lt;code&gt;-u&lt;/code&gt; 选项：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ nc -u host port&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Netcat" scheme="https://www.hi-linux.com/tags/Netcat/"/>
    
  </entry>
  
  <entry>
    <title>如何在不杀进程的前提下关闭一个 TCP Socket 连接</title>
    <link href="https://www.hi-linux.com/posts/62556.html"/>
    <id>https://www.hi-linux.com/posts/62556.html</id>
    <published>2020-05-23T02:03:00.000Z</published>
    <updated>2020-05-23T13:50:06.369Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>要在线关闭一个 TCP Socket 连接，你可能会说很简单，<code>netstat -antp</code> 找到连接，<code>kill</code> 掉这个进程就行了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># netstat -antp|grep 6789</span><br><span class="line">tcp        0      0 1.1.1.1:59950      1.1.1.2:6789        ESTABLISHED 45059&#x2F;ceph-fuse</span><br><span class="line"># kill 45059</span><br></pre></td></tr></table></figure><p>连接确实关掉了，进程也跟着一起杀死了。达不到 “在线” 的要求。</p><p>有没有办法不杀死进程，但还是可以关闭 Socket 连接呢？</p><p>我们知道，在编码的时候，要关闭一个 Socket，只要调用 close 函数就可以了，但是进程在运行着呢，怎么让它调用 close 呢？</p><p>在 superuser 上看到一个很棒的方法，原理就是 <code>gdb attach</code> 到进程上下文，然后 call close($fd)。</p><a id="more"></a><ol><li>使用 <code>netstat</code> 找到进程</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># netstat -antp|grep 6789</span><br><span class="line">tcp        0      0 1.1.1.1:59950      1.1.1.2:6789        ESTABLISHED 45059&#x2F;ceph-fuse</span><br></pre></td></tr></table></figure><p>如上，进程 pid 为 45059。</p><ol start="2"><li>使用 <code>lsof</code> 找到进程 45059 打开的所有文件描述符，并找到对应的 Socket 连接。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># lsof -np 45059</span><br><span class="line">COMMAND     PID USER   FD   TYPE             DEVICE SIZE&#x2F;OFF       NODE NAME</span><br><span class="line">ceph-fuse 45059 root  rtd    DIR                8,2     4096          2 &#x2F;</span><br><span class="line">ceph-fuse 45059 root  txt    REG                8,2  6694144    1455967 &#x2F;usr&#x2F;bin&#x2F;ceph-fuse</span><br><span class="line">ceph-fuse 45059 root  mem    REG                8,2   510416    2102312 &#x2F;usr&#x2F;lib64&#x2F;libfreeblpriv3.so</span><br><span class="line">...</span><br><span class="line">ceph-fuse 45059 root   12u  IPv4         1377072656      0t0        TCP 1.1.1.1:59950-&gt;1.1.1.2:smc-https (ESTABLISHED)</span><br></pre></td></tr></table></figure><p>其中 12u 就是上面对应 Socket 连接的文件描述符。</p><ol start="3"><li>gdb 连接到进程</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gdb -p 45059</span><br></pre></td></tr></table></figure><ol start="4"><li>关闭 Socket 连接</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) call close(12u)</span><br></pre></td></tr></table></figure><p>Socket 连接就可以关闭了，但是进程 45059 还是好着的。</p><p>你可能会问，什么时候会用到这个特性呢？场景还是比较多的，比如你想测试下应用是否会自动重连 MySQL，通过这个办法就可以比较方便的测试了。</p><blockquote><p>来源：Zlatan Eevee</p><p>原文：<a href="http://t.cn/AijmTykM" target="_blank" rel="noopener">http://t.cn/AijmTykM</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;要在线关闭一个 TCP Socket 连接，你可能会说很简单，&lt;code&gt;netstat -antp&lt;/code&gt; 找到连接，&lt;code&gt;kill&lt;/code&gt; 掉这个进程就行了。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# netstat -antp|grep 6789&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 1.1.1.1:59950      1.1.1.2:6789        ESTABLISHED 45059&amp;#x2F;ceph-fuse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# kill 45059&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;连接确实关掉了，进程也跟着一起杀死了。达不到 “在线” 的要求。&lt;/p&gt;
&lt;p&gt;有没有办法不杀死进程，但还是可以关闭 Socket 连接呢？&lt;/p&gt;
&lt;p&gt;我们知道，在编码的时候，要关闭一个 Socket，只要调用 close 函数就可以了，但是进程在运行着呢，怎么让它调用 close 呢？&lt;/p&gt;
&lt;p&gt;在 superuser 上看到一个很棒的方法，原理就是 &lt;code&gt;gdb attach&lt;/code&gt; 到进程上下文，然后 call close($fd)。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟理解微博云原生技术实践之路</title>
    <link href="https://www.hi-linux.com/posts/25333.html"/>
    <id>https://www.hi-linux.com/posts/25333.html</id>
    <published>2020-05-23T02:01:00.000Z</published>
    <updated>2020-05-23T13:50:06.368Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>现在越来越多的企业开始全面拥抱云计算，开始关注云原生技术。从管理物理数据中心到使用云主机，我们不用再关心基础运维。从云主机到 Kubernetes 容器，我们不用再关心机器的管理。云上抽象层级越高，就越少人需要关心底层问题，企业就能够节省大量的人力成本与资源投入。云原生技术就是更高一层的抽象，CNCF 对云原生技术的定义是：</p><blockquote><p>有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展应用。通过容器、服务网格、微服务、不可变基础设施和声明式API等技术，构建容错性好、易于管理和便于观察的松耦合系统。</p></blockquote><p>例如 FaaS 架构，开发者可以完全不用考虑服务器，构建并运行应用程序和服务。还有面向开源架构的的云原生技术，与提供 MySQL, Redis 云服务类似，提供基于 Spring Cloud、Dubbo、HSF 等开源微服务架构的应用管理服务，开发者无需考虑部署、监控、运维的问题。</p><p>微博也一直在致力于推动基础设施云原生化，我们围绕 Kubernetes 构建面向容器的云原生基础设施，形成了物理数据中心加多个公有云的混合云 Kubernetes 平台，提供秒级伸缩能力。构建开箱即用的 CI/CD 体系，依托云原生伸缩能力，保证大量的 Job 稳定运行，让开发人员摆脱代码发布泥沼。接下介绍这几方面的实践经验。</p><h2 id="物理数据中心-kubernetes-化">物理数据中心 Kubernetes 化</h2><p>面向单机器的基础设施架构已经无法发挥云的最大优势。把容器按照服务颗粒度进行管理，每个服务对应一组虚拟机，虽然基础运维通过 IaaS 层抽象得到了极大简化，但是业务的运维成本依然很高，业务 SRE 需要维护复杂的设备配置脚本，管理不同服务设备配置的差异性，需要 7 * 24 小时对故障设备进行干预。而且资源利用率无法最大化，服务池是按设备划分，一个新设备添加到服务池后只能被这个服务使用，它的冗余的计算能力并不能为其他服务使用。另外不同业务容器运行在不同的机器上，容器网络架构更关注性能而非隔离性，通常会采用 Host 模式，这也提高了服务混合部署的运维成本。</p><p>基础设施只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势。目前 Kubernetes 已经容器编排系统的事实标准，提供面向应用的容器集群部署和管理系统，消除物理（虚拟）机，网络和存储基础设施的负担。同时 CNCF 推出一致性认证，推动各公有云厂商提供标准的 Kubernetes 服务，这就确保通过 Kubernetes 部署的应用在不同云厂商之间具有可迁移性，避免被厂商锁定。</p><p>之前提到微博的容器会独占物理机的网络协议栈，虽然能够做到网络效率的最大化，但是会导致多容器部署时出现端口冲突，无法满足 Kubernetes 动态编排的需求。为了解决端口冲突问题，我们首先测试了 vxlan 网络架构，因为其数据平面需要进行封装、解封操作，网络性能损耗超过5%，并不满足微博后端服务对网络性能的要求。最后我们评估可行的网络方案有两种 MacVlan 和 Calico BGP。</p><p>其中 MacVlan 成熟稳定，通过机房上联交换机改为 Vlan Trunk 模式，在物理机上创建 MacVlan 网卡子接口，通过 CNI 插件将虚拟网卡插入 Pause 容器中，实现容器网络与物理网络打通。容器的网络通信直接通过 MacVlan 物理子接口，发出的报文在网卡上打 VlanTag，数据平面基本没有性能损耗。控制平面因需要对所有上联交换机进行 Vlan Trunk 改造，工作量较大，所以这个方案仅针对高配物理机所在网络进行了改造。</p><p>Calico BGP 是可以同时实现数据平面 0 损耗与控制平面自动化的容器网络解决方案。与 MacVlan 实现的扁平二层网络不同，Calico 在每个节点上部署 BGP Client 与 Reflector 实现了一个扁平的三层网络，每个节点发布的路由状态由 Felix 维护。不过由于 Felix 采用 iptables 实现路由 ACLs 功能，对性能存在一定影响。因为物理数据中心不面向外部用户开放，所以 ACLs 功能对微博是可以去除的，我们对 Calico 进行了优化，去除 iptables 依赖。</p><p><img src="https://catrixs.github.io/images/calico_acls.png" alt=""></p><p>微博也主动回馈 Kubernetes 社区，也包括为 Kubernetes 代码库做贡献，例如修复多租户下网络隔离TC资源泄露问题。</p><p>之前的运维是面向物理机的，所以物理机上存在很多运维工具，如日志推送、域名解析、时钟同步、定时任务等。业务通过 Kubernetes 编排后，以上的功能都需要进行容器化改造。例如在容器中使用 systemd 会涉及到提权问题，在实践过程中发现用 systemd 如果权限控制不当会造成容器被 Kill 的情况。所以我们单独开发了兼容 linux crontab 语法的定时任务工具 gorun，把这个工具集成在了运维容器里面。</p><p>因为业务容器会产生大量日志，出于 I/O 性能考虑，同时为了方便快速定位，日志会存储于本地 PVC 中，支持配额管理，避免一个容器把磁盘写满。运维基础设施容器通过监听文件，对老旧日志进行压缩清理，性能 Profile 日志会在本地进行统计计算后通过 UDP 协议推送到 Graphite 或 Prometheus。对于关键日志，会通过 Flume 推送到 Kafka 集群，而且支持失败重传，保证日志的一致性。</p><p><img src="https://catrixs.github.io/images/pod_log.jpg" alt=""></p><p>通过对运维容器化后，所有业务 Pod 都具备相同的运维能力，形成标准化的监控报警、运维决策、流量切换、服务降级，异常封杀、日志查询的服务保障体系，服务可运维性大幅度提升。</p><a id="more"></a><h2 id="容器编排">容器编排</h2><p>Kubernetes 的 Deployment 支持 Pod 自我修复，滚动升级和回滚，扩容和缩容，这些特性都是云原生基础设施必备的。但是 Kubernetes 设计原则中对集群的管理尤其是服务升级过程中保持“无损”升级，对 Deployment 进行滚动升级，会创建新 Pod 替换老 Pod，以保证 Deployment 中 Pod 的副本数量。原有里面的IP地址和滚动升级之前的IP地址是不会相同的。而如果集群够大，一次滚动发布就会导致负载均衡变更 （集群副本数／滚动发布步长）次。对于微博服务来说，频繁变更会导致这个负载均衡辖下，所以后端实例的接口不稳定。</p><p>微博实现了常备 Pod 的 In-place Rolling Updates 功能，根据业务冗余度及业务实际需要来调整上线的步长，上线过程中保持容器的IP不变，减少在上线过程中业务的抖动。因为业务的启动需要一定时间，不能按照容器启停来做步长控制，我们利用 Kubernetes 容器生命周期管理的 liveness/readiness probe 实现容器提供服务的状态，避免了上线过程中容器大面积重启的问题。同时优化了 Kubernetes 的 postStar 的原生实现，因为原生里面只调用一次，不管成功与否都会杀掉容器，改成不成功会按照指定的次数或时间进行重试。IP 的静态分配使用 Calico CNI 实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: wb_service</span><br><span class="line">  annotations:</span><br><span class="line">      &quot;cni.projectcalico.org&#x2F;ipAddrs&quot;: &quot;[\&quot;10.142.0.50\&quot;]&quot;</span><br></pre></td></tr></table></figure><p>Kubernetes 的编排策略相对灵活，分为三个阶段，初筛阶段用于筛选出符合基本要求的物理机节点，优选阶段用于得到在初筛的节点里面根据策略来完成选择最优节点。在优选完毕之后，还有一个绑定过程，用于把Pod和物理机进行绑定，锁定机器上的资源。这三步完成之后，位于节点上的 kubelet 才开始创建 Pod。在实际情况中，把物理机上的容器迁移到 Kubernetes，需要保持容器的部署结构尽量一致，例如一个服务池中每台物理机上分配部署了 <code>wb_service_a和wb_service_b</code> 两个容器，可以通过 podAffinity 来完成服务混部的编排：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: wb_service_b</span><br><span class="line">  annotations:</span><br><span class="line">      &quot;cni.projectcalico.org&#x2F;ipAddrs&quot;: &quot;[\&quot;10.142.0.50\&quot;]&quot;</span><br><span class="line">  labels:</span><br><span class="line">  service: wb_service_b</span><br><span class="line">spec:</span><br><span class="line">affinity:</span><br><span class="line">podAffinity:</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">  - labelSelector:</span><br><span class="line">      matchExpressions:</span><br><span class="line">      - key: service</span><br><span class="line">        operator: In</span><br><span class="line">        values: [&quot;wb_service_a&quot;]</span><br><span class="line">    topologyKey: &quot;kubernetes.io&#x2F;hostname&quot;</span><br></pre></td></tr></table></figure><p>一些比较复杂的，运维复杂的集群，通过 Kubernetes Operator 进行容器编排。Operator 是由 CoreOS 开发的，用来扩展 Kubernetes API，特定的应用程序控制器，它用来创建、配置和管理复杂的有状态应用，如数据库、缓存和监控系统。Operator基于Kubernetes的资源和控制器概念之上构建，但同时又包含了应用程序特定的领域知识。Operator 可以将运维人员对软件操作的知识给代码化，同时利用 Kubernetes 强大的抽象来管理大规模的软件应用。例如 CacheService 的运维是比较复杂的，需要资源编排，数据同步，HA 结构编排，备份与恢复，故障恢复等等。通过实现 CacheService Operator 可以让开发一通过声明式的 Yaml 文件即可创建、配置、管理复杂的 Cache 集群。CacheService Operator 支持：</p><ol><li><p>创建/销毁：通过 Yaml 声明 CacheService 规格，即可通过 Kubernetes 一键部署，删除</p></li><li><p>伸缩：可以修改 Yaml 中声明的副本数量，Operator 实现扩容，配置主从结构，挂载域名等操作</p></li><li><p>备份：Operator 根据 Yaml 中声明的备份机制，实现自动的备份功能，例如定期备份，错峰备份等</p></li><li><p>升级：实现不停机版本升级，并支持回滚</p></li><li><p>故障恢复：单机故障时，自动 HA 切换，同时恢复副本数量，并自动恢复主从结构</p></li></ol><p>复杂的应用在 Kubernetes 上部署，服务数量众多，服务间的依赖关系也比较复杂，每个服务都有自己的资源文件，并且可以独立的部署与伸缩，这给采用 Kubernetes 做应用编排带来了诸多挑战：</p><ol><li><p>管理、编辑与更新大量的 Yaml 配置文件，</p></li><li><p>部署一个含有大量配置文件的复杂 Kubernetes 应用，例如上面提到的 CacheService Operator</p></li><li><p>参数化配置模板支持多个环境</p></li></ol><p>Helm 可以解决这些问题。Helm 把 Kubernetes 资源（如Pods, Deployments, Services等) 打包到一个 Chart 中，实现可配置的发布是通过模板加配置文件，动态生成资源清单文件。</p><h2 id="弹性伸缩">弹性伸缩</h2><p>在云时代，弹性已经成为新常态。而且微博的社交媒体属性，不可提前预期的突发峰值是家常便饭，所以基础设施不但需要具备弹性，而且需要具备在短时间内提供足够资源的能力。Kubernetes 基于容器技术在启动时间方面比虚拟机更具优势，省去了虚拟机创建、环境初始化、配置管理等诸多环节，直接拉起业务 Pod，扩容时间可以从分钟级缩短到秒级。</p><p>而且峰值流量突发时，运维、开发同学可能是在吃饭、睡觉、休假，这个时候靠人为干预肯定是来不及的，所以系统需要自动做出扩容决策。对于复杂的分布式系统，实现自动决策需要解决两个问题，一个是容量决策，一个是依赖关系。Kubernetes 的 HPA (Horizontal Pod Autoscaling) 可以根据 Metric 自动伸缩一个 Deployment 中的 Pod 数量。HPA 由一个控制循环实现，循环周期由 horizontal-pod-autoscaler-sync-period 标志指定（默认是 30 秒）。在每个周期内，查询 HPA 中定义的资源利用率。并且在扩容前会有一个冷静期，一般是 5 分钟（可通过horizontal-pod-autoscaler-downscale-stabilization参数设置），然后通过下面的公式进行扩缩容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desired &#x3D; ceil[current * ( currentMetric &#x2F; desiredMetric )]</span><br></pre></td></tr></table></figure><p>但是这种容量决策存在两个问题。因为突发峰值流量上涨迅速，上述扩容机制第一次扩容往往扩不到位，触发连续多次扩容，导致服务在流量上涨期间一直处于过载状态，影响服务SLA。另一个问题是冷静期问题，如果冷静期过长，会导致峰值流量无法得到及时扩容，冷静期过短会错把抖动当做峰值，造成不必要的成本浪费。第三个问题是复杂的业务系统依赖关系复杂，每个服务根据各自指标进行伸缩，由于上面还未伸缩流量被挡在了上游，下游这时感知不到准确流量趋势，从整体应用角度看很容易出现上游泄洪下游被淹的问题。</p><p>微博整体的弹性伸缩架构是基于混合云的架构，内网私有云，公有云虚机，云 Kubernetes 一体化 Kubernetes 弹性集群，实现快速自动化资源调度，解决了跨 IDC 调度、定制的调度算法与策略、容量评估、服务间扩容依赖关系等，构建了全链路，压测，指标，报警，干预多维度的能力：</p><ol><li><p>全链路是构建一个应用整体的容量决策体系，各服务不再独自判定容量，而是根据全链路容量指标作出一致性扩容决策</p></li><li><p>压测可以帮助了解目前部署的冗余情况，合理的设定扩容公式，避免多次重复性扩容</p></li><li><p>指标体系是要从成千上万个 Metric 中抽象出可以作为决策的依据，打通负载均衡，Web 服务，数据库资源等多维度指标</p></li><li><p>报警及时多路径触达，避免单点</p></li><li><p>干预不但要支持快速伸缩，还应支持快速优雅降级，为服务扩容争取时间</p></li></ol><h2 id="cicd">CI/CD</h2><p>云计算技术的普及，研发流程也随之变化，越来越多的组织和团队开始接受 DevOps 理念。持续集成（CI）和持续交付（CD）是 DevOps 的基石。但是 CI/CD 在实际落地过程中存在诸多困难，导致实际效果不理想。以 CI 为例，开发同学应该对“顺利的话，会有大约 100 个失败的测试” 这种情形并不陌生。由于开发环境与测试环境并不一致等诸多因素，CI 经常出现不相干的偶发失败，长此以往开发同学会默认选择忽略 CI 环节的报错警告，最终导致 CI/CD 沦为一句口号。</p><p>利用云原生的声明性基础架构，可以将应用系统的和应用程序存放在 Git 的版本控制库中，每个开发人员都可以提交拉取请求代码，轻松在 Kubernetes 上部署应用程序和运维任务，开发人员可以更高效地将注意力集中在创建新功能而不是运维相关任务上。基于 Git 的持续交付流水线，有诸多优势和特点：</p><ol><li><p>版本控制的声明性容器编排，Kubermetes 作为一个云原生的工具，可以把它的 “声明性” 看作是 “代码”，声明意味着配置由一组事实而不是一组指令组成，例如，“有十个 Redis 服务器”，而不是 “启动十个 Redis 服务器，告诉我它是否有效”</p></li><li><p>Git 作为事实的唯一真实来源，任何能够被描述的内容都必须存储在 Git 库中，包括系统相关的：策略，代码，配置，甚至监控事件</p></li><li><p>与其他工具相结合，例如监控系统可以方便地监控集群，以及检查比较实际环境的状态与代码库上的状态是否一致</p></li></ol><p>目前大多数 CI/CD 工具都使用基于推送的模型。基于推送的流水线意味着代码从 CI 系统开始，通过一系列构建测试等最终生成镜像，最后手动使用 “kubectl” 将部署到 Kubernetes 集群。程序员是最不喜欢开发流程被打断，多个系统间的切换会极大影响程序员的开发效率。所以我们通过 CI 和 IDE 结合，把 CI 流程融入到开发自测环节中，让程序员可以进行面向 CI 的测试驱动开发，提高对交付代码质量的信心。</p><p>CI/CD 流水线是围绕程序员经常使用的 GitLab 构建，程序员可以对 Merge Request 的 CI 结果一目了然，避免了在多个系统间来回切换。每次代码提交都要执行基于分支的完整 CI 流程，借助云原生的弹性能力和共享存储，解决了大量并发的 Job 的计算资源瓶颈，同时缓解了 Job 间共享数据的带宽压力以及网络传输延时。</p><p><img src="https://catrixs.github.io/images/ci_cd.png" alt=""></p><p>持续部署要比持续集成更加复杂。部署流程中依赖人工的环节非常多，例如灰度是由运维部署到生产环境部分机器，验证需要依靠开发和运维同学经验检查新版本各项指标是否正常，滚动发布与回滚也需要运维同学全程干预。金丝雀部署可以有效规避风险，在生产环境的基础设施中小范围的部署新的应用代码，如果没有错误，新版本才逐渐推广到整个服务，而不用一次性从老版本切换到新版本。不过如何验证没有错误是比较有挑战的，微服务依赖复杂、部署范围广、指标维度多，是最易出错，最耗时的环节。我们针对这个问题，开发了智能时序数据异常识别服务，覆盖操作系统，JVM，资源 SLA，业务 SLA 的上千维度指标。它不但可以自动准确识别异常识别，性能衰减等人工经验能够发现的问题，也能够识别如资源不合理访问等人工很难察觉的问题。现在的 CD 流程包含部署、集成测试、金丝雀验证、滚动发布、回滚自动化环节。</p><h2 id="weibo-mesh">Weibo Mesh</h2><p>Service Mesh 并不是什么新的技术，它所关注的高性能、高可用、服务发现和治理等有服务化的一天就已经存在，社区也不乏这方面的最佳实践。不过之前主要是两种方式，一种是微服务 RPC 框架形式，例如 Motan, gRPC, Thrift, Dubbo 等。传统微服务框架有诸多弊端：</p><ol><li><p>升级困难，框架、SDK 的与业务代码强绑定</p></li><li><p>多语言问题，各种语言的服务治理能力天差地别，服务质量体系难以统一</p></li></ol><p>还有一种是集中式 Proxy 形式，例如 Nginx, Twemproxy, SQL Proxy 等。虽然 Proxy 的形式一定程度上解决了胖客户端的问题，没有了升级问题，多语言可以统一接入。但是在性能方面的损耗，对于耗时较长的请求来说还可以接受，但这在服务间调用这种毫秒级请求时，性能是不能容忍的，而且服务的拆分势必导致整个体系内耗时随着微服务规模的扩大而剧增，而且 Proxy 本身很容易成为整个系统中的瓶颈点。所以经常可以看到后端服务是同时使用 Proxy 和 RPC 的情况。</p><p>而 Cloud Native 会催生出如此火爆的 Service Mesh，最主要的因素是 Kubernetes 使基础设施的标准化，大家发现之前这些很重的 RPC 框架可以抽离出来，原本需要增加维护的复杂性被 Kubernetes 解决掉了，跨语言、服务治理等收益凸显出来。而且 Mesh 的 SideCard 形式，相比 Proxy 在请求耗时方面优势也相当明显。</p><p><img src="https://philcalcado.com/img/service-mesh/6-b.png" alt=""></p><p>图片来自：Pattern: Service Mesh</p><p>微博将 Motan RPC 胖客户端实现的治理功能下沉到 Agent 上，服务注册和发现依赖微博自研 Vintage 命名和配置服务，对服务的订阅和发现来建立服务间依赖的逻辑网络。业务与 的通信协议保持一致，Agent 支持 HTTP 和 RPC 的调用，业务只需把原有的调用指向 Agent 即可，不需要改造业务代码。在跨语言通信协议设计方面，Google 的 Protocol Buffers（pb）序列化能够提供优秀的跨语言序列化能力，但是在一是老旧 HTTP 迁移到 pb 协议的改造成本过高，二是部分语言（例如 PHP） 在做复杂 pb 对象序列化时性能比较差，甚至比 json 序列化还要慢 3 倍左右。微博实现了全新语言无关的通信协议 Motan2 和跨语言友好的数据序列化协议 Simple 来应对跨语言。</p><p>除了代理 Service 的能力外，Mesh 体系提供了缓存、队列等服务化代理，业务方可以与依赖缓存、队列资源治理解耦的能力。可以大幅提高那些治理能力比较薄弱的业务和语言的架构水平。随着云原生技术的日趋完善，会有越来越多的基础设施从原有的 SDK 中抽象出来。未来数据库访问会以 Database Mesh 形式提供访问，封装数据分片、读写分离、从库负载均衡、熔断、链路采集能力，例如 Google Cloud SQL 提供本地 Proxy，业务方无需将 IP 地址列入白名单或配置 SSL，即可安全地访问 Cloud SQL。</p><blockquote><p>来源：Fatrix’s Blog</p><p>原文：<a href="https://url.cn/5fdD1qF" target="_blank" rel="noopener">https://url.cn/5fdD1qF</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在越来越多的企业开始全面拥抱云计算，开始关注云原生技术。从管理物理数据中心到使用云主机，我们不用再关心基础运维。从云主机到 Kubernetes 容器，我们不用再关心机器的管理。云上抽象层级越高，就越少人需要关心底层问题，企业就能够节省大量的人力成本与资源投入。云原生技术就是更高一层的抽象，CNCF 对云原生技术的定义是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展应用。通过容器、服务网格、微服务、不可变基础设施和声明式API等技术，构建容错性好、易于管理和便于观察的松耦合系统。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如 FaaS 架构，开发者可以完全不用考虑服务器，构建并运行应用程序和服务。还有面向开源架构的的云原生技术，与提供 MySQL, Redis 云服务类似，提供基于 Spring Cloud、Dubbo、HSF 等开源微服务架构的应用管理服务，开发者无需考虑部署、监控、运维的问题。&lt;/p&gt;
&lt;p&gt;微博也一直在致力于推动基础设施云原生化，我们围绕 Kubernetes 构建面向容器的云原生基础设施，形成了物理数据中心加多个公有云的混合云 Kubernetes 平台，提供秒级伸缩能力。构建开箱即用的 CI/CD 体系，依托云原生伸缩能力，保证大量的 Job 稳定运行，让开发人员摆脱代码发布泥沼。接下介绍这几方面的实践经验。&lt;/p&gt;
&lt;h2 id=&quot;物理数据中心-Kubernetes-化&quot;&gt;物理数据中心 Kubernetes 化&lt;/h2&gt;
&lt;p&gt;面向单机器的基础设施架构已经无法发挥云的最大优势。把容器按照服务颗粒度进行管理，每个服务对应一组虚拟机，虽然基础运维通过 IaaS 层抽象得到了极大简化，但是业务的运维成本依然很高，业务 SRE 需要维护复杂的设备配置脚本，管理不同服务设备配置的差异性，需要 7 * 24 小时对故障设备进行干预。而且资源利用率无法最大化，服务池是按设备划分，一个新设备添加到服务池后只能被这个服务使用，它的冗余的计算能力并不能为其他服务使用。另外不同业务容器运行在不同的机器上，容器网络架构更关注性能而非隔离性，通常会采用 Host 模式，这也提高了服务混合部署的运维成本。&lt;/p&gt;
&lt;p&gt;基础设施只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势。目前 Kubernetes 已经容器编排系统的事实标准，提供面向应用的容器集群部署和管理系统，消除物理（虚拟）机，网络和存储基础设施的负担。同时 CNCF 推出一致性认证，推动各公有云厂商提供标准的 Kubernetes 服务，这就确保通过 Kubernetes 部署的应用在不同云厂商之间具有可迁移性，避免被厂商锁定。&lt;/p&gt;
&lt;p&gt;之前提到微博的容器会独占物理机的网络协议栈，虽然能够做到网络效率的最大化，但是会导致多容器部署时出现端口冲突，无法满足 Kubernetes 动态编排的需求。为了解决端口冲突问题，我们首先测试了 vxlan 网络架构，因为其数据平面需要进行封装、解封操作，网络性能损耗超过5%，并不满足微博后端服务对网络性能的要求。最后我们评估可行的网络方案有两种 MacVlan 和 Calico BGP。&lt;/p&gt;
&lt;p&gt;其中 MacVlan 成熟稳定，通过机房上联交换机改为 Vlan Trunk 模式，在物理机上创建 MacVlan 网卡子接口，通过 CNI 插件将虚拟网卡插入 Pause 容器中，实现容器网络与物理网络打通。容器的网络通信直接通过 MacVlan 物理子接口，发出的报文在网卡上打 VlanTag，数据平面基本没有性能损耗。控制平面因需要对所有上联交换机进行 Vlan Trunk 改造，工作量较大，所以这个方案仅针对高配物理机所在网络进行了改造。&lt;/p&gt;
&lt;p&gt;Calico BGP 是可以同时实现数据平面 0 损耗与控制平面自动化的容器网络解决方案。与 MacVlan 实现的扁平二层网络不同，Calico 在每个节点上部署 BGP Client 与 Reflector 实现了一个扁平的三层网络，每个节点发布的路由状态由 Felix 维护。不过由于 Felix 采用 iptables 实现路由 ACLs 功能，对性能存在一定影响。因为物理数据中心不面向外部用户开放，所以 ACLs 功能对微博是可以去除的，我们对 Calico 进行了优化，去除 iptables 依赖。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://catrixs.github.io/images/calico_acls.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;微博也主动回馈 Kubernetes 社区，也包括为 Kubernetes 代码库做贡献，例如修复多租户下网络隔离TC资源泄露问题。&lt;/p&gt;
&lt;p&gt;之前的运维是面向物理机的，所以物理机上存在很多运维工具，如日志推送、域名解析、时钟同步、定时任务等。业务通过 Kubernetes 编排后，以上的功能都需要进行容器化改造。例如在容器中使用 systemd 会涉及到提权问题，在实践过程中发现用 systemd 如果权限控制不当会造成容器被 Kill 的情况。所以我们单独开发了兼容 linux crontab 语法的定时任务工具 gorun，把这个工具集成在了运维容器里面。&lt;/p&gt;
&lt;p&gt;因为业务容器会产生大量日志，出于 I/O 性能考虑，同时为了方便快速定位，日志会存储于本地 PVC 中，支持配额管理，避免一个容器把磁盘写满。运维基础设施容器通过监听文件，对老旧日志进行压缩清理，性能 Profile 日志会在本地进行统计计算后通过 UDP 协议推送到 Graphite 或 Prometheus。对于关键日志，会通过 Flume 推送到 Kafka 集群，而且支持失败重传，保证日志的一致性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://catrixs.github.io/images/pod_log.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过对运维容器化后，所有业务 Pod 都具备相同的运维能力，形成标准化的监控报警、运维决策、流量切换、服务降级，异常封杀、日志查询的服务保障体系，服务可运维性大幅度提升。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="云原生" scheme="https://www.hi-linux.com/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>漫谈云计算、虚拟化、容器化</title>
    <link href="https://www.hi-linux.com/posts/2749.html"/>
    <id>https://www.hi-linux.com/posts/2749.html</id>
    <published>2020-05-23T02:00:00.000Z</published>
    <updated>2020-05-23T13:50:06.370Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h3 id="什么是云计算">什么是云计算？</h3><p>1.1 云计算概念</p><p>云计算是最近几年才兴起的概念，但是这样的需求其实早都有了，现阶段广为接受的是美国国家标准与技术研究院（NIST）定义：云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。</p><p>云计算最基本的特性是：“按使用量付费”、“资源共享池”和多租户隔离。</p><p>1.2 云计算的特点</p><ul><li>超大规模</li></ul><p>云具有相当的规模，Google 云计算已经拥有 100 多万台服务器， Amazon、IBM、微软、Yahoo 等的云均拥有几十万台服务器。企业私有云一般拥有数百上千台服务器。云能赋予用户前所未有的计算能力。</p><ul><li>虚拟化</li></ul><p>云计算支持用户在任意位置、使用各种终端获取应用服务。所请求的资源来自云，而不是固定的有形的实体。应用在云中某处运行，但实际上用户无需了解、也不用担心应用运行的具体位置。只需要一台笔记本或者一个手机，就可以通过网络服务来实现我们需要的一切，甚至包括超级计算这样的任务。</p><ul><li>高可靠性</li></ul><p>云使用了数据多副本容错、计算节点同构可互换等措施来保障服务的高可靠性，使用云计算比使用本地计算机可靠。</p><ul><li>通用性</li></ul><p>云计算不针对特定的应用，在云的支撑下可以构造出千变万化的应用，同一个云可以同时支撑不同的应用运行。</p><ul><li>高可扩展性</li></ul><p>云的规模可以动态伸缩，满足应用和用户规模增长的需要。</p><ul><li>按需服务</li></ul><p>云是一个庞大的资源池，你按需购买;云可以像自来水，电，煤气那样计费。</p><ul><li>极其廉价</li></ul><p>由于云的特殊容错措施可以采用极其廉价的节点来构成云，云的自动化集中式管理使大量企业无需负担日益高昂的数据中心管理成本，云的通用性使资源的利用率较之传统系统大幅提升，因此用户可以充分享受云的低成本优势，经常只要花费几百美元、几天时间就能完成以前需要数万美元、数月时间才能完成的任务。</p><ul><li>潜在的危险性</li></ul><p>云计算服务除了提供计算服务外，还必然提供了存储服务。但是云计算服务当前垄断在私人机构(企业)手中，而他们仅仅能够提供商业信用。对于政府机构、商业机构(特别像银行这样持有敏感数据的商业机构)对于选择云计算服务应保持足够的警惕。一旦商业用户大规模使用私人机构提供的云计算服务，无论其技术优势有多强，都不可避免地让这些私人机构以数据(信息)的重要性挟制整个社会。</p><p>对于信息社会而言，信息是至关重要的。另一方面，云计算中的数据对于数据所有者以外的其他用户云计算用户是保密的，但是对于提供云计算的商业机构而言确实毫无秘密可言。所有这些潜在的危险，是商业机构和政府机构选择云计算服务、特别是国外机构提供的云计算服务时，不得不考虑的一个重要的前提。</p><a id="more"></a><p>1.3  云计算的分类</p><ul><li>公有云：只有使用权，使用的时候进行按需付费。但数据放在别人家。数据安全没有保障。而且银行不会使用公有云，金融行业不要使用公有云。公有云的核心属性是共享资源服务。</li><li>私有云：自己的机房搭建的云，私有云有局限性，资源固定；数据比较安全。私有云的核心属性是专有资源。</li><li>混合云：主要任务放到私有云，临时需要时利用混合云，它将公有云和私有云进行混合匹配，以获得最佳的效果，这种个性的解决方案，达到二既省钱又安全的目的。</li></ul><p>1.4 云计算分层</p><p>云计算也是层的，大概有以下几种：</p><p><img src="https://images2015.cnblogs.com/blog/936003/201612/936003-20161213225505511-661553597.png" alt=""></p><ul><li>传统 IT</li></ul><p>基本所有的都需要自行管理，比如：网络、存储、服务器、虚拟化，操作系统、中间件、运行环境、数据、应用等。</p><ul><li>IaaS: Infrastructure-as-a-Service（基础设施即服务）</li></ul><p>IaaS 主要作用是提供虚拟机或者其他资源作为服务提供给用户。</p><ul><li>PaaS: Platform-as-a-Service（平台即服务）</li></ul><p>PaaS, 中文名为平台即服务。如果以传统计算机架构中 “硬件+操作系统/开发工具+应用软件” 的观点来看待，那么云计算的平台层应该提供类似操作系统和开发工具的功能。实际上也的确如此，PaaS 定位于通过互联网为用户提供一整套开发、运行和运行应用软件的支撑平台。就像在个人计算机软件开发模式下，程序员可能会在一台装有 Windows 或 Linux 操作系统的计算机上使用开发工具开发并部署应用软件一样。PaaS 某些时候也叫做中间件，主要作用是提供一个开发和运行平台给用户。</p><ul><li>SaaS: Software-as-a-Service（软件即服务）</li></ul><p>SaaS，软件即服务。简单地说，就是一种通过互联网提供软件服务的软件应用模式。在这种模式下，用户不需要再花费大量投资用于硬件、软件和开发团队的建设，只需要支付一定的租赁费用，就可以通过互联网享受到相应的服务，而且整个系统的维护也由厂商负责。</p><p>如果要用一句话来概括 IaaS、PaaS 和 SaaS 的话，那就是：如果把云计算比喻成一部手机，那么 IaaS 就是硬件，你要自己写代码研发系统才能用；PaaS 是手机系统，你要实现什么功能还是要装各种软件；SaaS 就是硬件+系统+软件，你要干什么一句话就能解决。</p><h3 id="什么是虚拟化">什么是虚拟化？</h3><p>2.1 虚拟化概念</p><p>虚拟化是通过软件手段对计算机硬件资源镜像整合管理和再分配的一种技术，常用的手段有基于虚拟机的虚拟化和基于容器的虚拟化。</p><p>2.2 虚拟化技术分类</p><p>2.2.1 按应用场景分类</p><ul><li>操作系统虚拟化</li><li>应用程序虚拟化</li><li>桌面应用虚拟化</li><li>存储虚拟化</li><li>网络虚拟化</li></ul><p>2.2.2 按照应用模式分类</p><ul><li>一对多：其中将一个物理服务器划分为多个虚拟服务器，这是典型的服务器整合模式。</li><li>多对一：其中整合了多个虚拟服务器，并将它们作为一个资源池，这是典型的网格计算模式。</li><li>多对多：将前两种模式结合在一起。</li></ul><p>2.2.3 按硬件资源调用模式分类</p><p><img src="https://images2015.cnblogs.com/blog/936003/201612/936003-20161214132509308-445646843.png" alt=""></p><ul><li>全虚拟化</li></ul><p>全虚拟化，虚拟化操作系统与底层硬件完全隔离。由中间的 Hypervisor 层转化虚拟化客户操作系统对底层硬件的调用代码，全虚拟化无需更改客户端操作系统，并兼容性好。典型代表有：Vmware Workstation、KVM。</p><ul><li>半虚拟化</li></ul><p>半虚拟化，在虚拟客户操作系统中加入特定的虚拟化指令，通过这些指令可以直接通过 Hypervisor 层调用硬件资源，免除有 Hypervisor 层转换指令的性能开销。半虚拟化的典型代表 Microsoft Hyper-V、Vmware 的 vSphere。</p><blockquote><p>注：针对 IO 层面半虚拟化要比全虚拟化要好，因为磁盘 IO 多一层必定会慢。一般说 IO 就是网络 IO 和磁盘 IO，因为这两个相对而言是比较慢的。</p></blockquote><p>2.3 基于虚拟机（Hypervisor-based）的虚拟化</p><p>它通过一个软件层的封装，提供和物理硬件相同的输入输出表现。实现了操作系统和计算机硬件的解耦，将 OS 和计算机间从 1 对 1 变成了多对多（实际上是 1 对多）的关系。该软件层称为虚拟机管理器（VMM / Hypervisor），它可以直接运行在裸机上（Xen、VMware EXSi），也可以运行在操作系统上（KVM、VMware Workstation）。这项技术已经很成熟了,（发展了40 多年），但仍然存在以下几个问题：</p><ul><li>在虚拟机上运行了一个完整的操作系统（GuestOS），在其下执行的还有虚拟化层和宿主机操作系统，一定比直接在物理机上运行相同的服务性能差；</li><li>有 GuestOS 的存在，虚拟机镜像往往有几个 G 到几十个 G，占用的存储空间大，便携性差；</li><li>想要使用更多硬件资源，需要启动一台新的虚拟机。要等待 GuesOS 启动，可能需要几十秒到几分钟不等。</li></ul><p>实际使用场景中，我们使用虚拟化技术其实是为了按需分配资源来完成服务的部署和使用，同时对服务所依赖的环境进行隔离，不被其它服务感知或干扰。为此启动一个 GuestOS 并不是必需的，为什么不考虑让多个虚拟机公用一个操作系统内核，只隔离开服务运行环境同时控制服务使用的系统资源呢？基于容器的虚拟化就是这样一种技术。</p><p>2.4 基于容器的虚拟化</p><p>容器是没有 GuestOS 的轻量级虚拟机，多个容器共享一个 OS 内核，容器中包含需要部署的应用和它依赖的系统环境，容器大小通常只有几十到几百 MB。由于共享操作系统内核，所以容器依赖于底层的操作系统，各个操作系统大都有自己的容器技术和容器工具。</p><p>Docker 是一个 Linux 容器管理工具，随着 Docker 的兴起，Linux 容器技术也是当下最时兴的容器虚拟化技术。Linux 容器工具有很多，OpenVZ、LXC、Docker、Rocket、Lmctfy 等等，大都是基于 Linux 内核提供的两个机制：Cgroups（实现资源按需分配）和 Namespace（实现任务隔离）。</p><p>2.5 二种虚拟化技术的区别</p><ul><li>虚拟机技术已经发展了很多年，虚拟机和虚拟化层间的接口、虚拟机镜像格式等都已经标准化了。相应的管理工具、分布式集群管理工具都有比较完善的解决方案，而容器最近几年才兴起，配套技术和标准还在完善中；</li><li>虚拟机由于有 GuestOS 存在，可以和宿主机运行不同 OS，而容器只能支持和宿主机内核相同的操作系统；</li><li>虚拟机由于有 VMM 的存在，虚拟机之间、虚拟机和宿主机之间隔离性很好。而容器之间公用宿主机的内核，共享系统调用和一些底层的库，隔离性相对较差；</li><li>容器比虚拟机明显更轻量级，对宿主机操作系统而言，容器就跟一个进程差不多。因此容器有着更快的启动速度（秒级甚至更快），更高密度的存储和使用（镜像小）、更方便的集群管理等优点。同时由于没有 GuestOS 存在，在容器中运行应用和直接在宿主机上几乎没有性能损失，比虚拟机明显性能上有优势。</li></ul><h3 id="云计算和虚拟化差别">云计算和虚拟化差别</h3><p>对云计算和虚拟化差别的描述，有一句经典的话：虚拟化是云计算构建资源池的一个主要方式。只要这句话你理解透了就知道他俩的关系了。</p><p>简单来说，云计算是一个概念，而不是具体技术。虚拟化是一种具体技术，指把硬件资源虚拟化，实现隔离性、可扩展性、安全性、资源可充分利用等特点的产品。</p><p>目前云计算，大多是依赖虚拟化，通过把多台服务器实体虚拟化后，构成一个资源池，实现共同计算，共享资源。也就是现在所谓云计算，其实这个词提出来之前，过去的服务器集群就已经实现这些功能了，只不过没有现在那么先进而已。</p><p>3.1 各领域代表的产品</p><ul><li><p>云计算架构的开源产品是 OpenStack，OpenStack 是一个由 NASA 和 Rackspace 合作研发并发起的，以 Apache 许可证授权的自由软件和开放源代码项目。</p></li><li><p>虚拟机的虚拟化：VM 的商业付费 vSphere 或者开源的 KVM。</p></li><li><p>容器的虚拟化：Docker。</p></li></ul><p>3.2 OpenStack</p><p>Openstack 是众多技术的组合体，有涉及网络组件的 Neutron，有涉及 Dashboard 的 Horizon，也有涉及计算资源分配的 Nova。</p><p>虚拟化技术只是其中一个涉及到资源池构建的方式。当然你也可以用其它方式构建资源池,比如物理机还有容器。</p><p>Openstack 经过几年十几个版本的更迭，已经拥有了 Keystone、Nova、Neutron、Cinder、Glance、Swift、Heat、Ceilometer 等等组件，比较完整的提供了一个云平台应有的各个模块。</p><p>3.3 在云计算中，不同层的选型</p><p>选取基于虚拟机的虚拟化呢，还是基于容器的虚拟化。早期由于容器技术的不完善，云计算只有虚拟机这一种选择。</p><p>随着现在容器技术兴起，基于容器的虚拟化性能更高，交付速度快，方便管理，而且资源利用率高，看起来是比虚拟机更好的方案。但是它现有的两个比较大的缺点（隔离性不够强、操作系统依赖性）让他无法完全替代 VM，对于 SaaS 用户和部分 PaaS 用户而言这两个缺点可能不那么明显。现阶段 Container 和云计算主要结合的场景也是在 SaaS 和 PaaS 中，事实上大多数 SaaS 和 PaaS 服务提供商都使用了容器技术。</p><p>但是对于 IaaS 的用户来说，他们租用的是基础设施。上面承载着他们自己运行的系统和服务，隔离性不强意味着安全性和可信性不高。在这种情况下大客户们，肯定是不放心的。同时操作系统依赖性也是限制 Container 在 IaaS 层应用的一个主要问题，也是绝大多数解决方案都是将Container 运行在 VM 上的原因，这样 Container 性能好的优势实际上在云上根本发挥不出来，优点只有启动快了。</p><h3 id="参考文档">参考文档</h3><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="http://t.cn/Ai98v0mw" target="_blank" rel="noopener">http://t.cn/Ai98v0mw</a></li><li><a href="http://t.cn/E5fCarY" target="_blank" rel="noopener">http://t.cn/E5fCarY</a></li><li><a href="http://t.cn/EzJpfCn" target="_blank" rel="noopener">http://t.cn/EzJpfCn</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是云计算？&quot;&gt;什么是云计算？&lt;/h3&gt;
&lt;p&gt;1.1 云计算概念&lt;/p&gt;
&lt;p&gt;云计算是最近几年才兴起的概念，但是这样的需求其实早都有了，现阶段广为接受的是美国国家标准与技术研究院（NIST）定义：云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。&lt;/p&gt;
&lt;p&gt;云计算最基本的特性是：“按使用量付费”、“资源共享池”和多租户隔离。&lt;/p&gt;
&lt;p&gt;1.2 云计算的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;超大规模&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云具有相当的规模，Google 云计算已经拥有 100 多万台服务器， Amazon、IBM、微软、Yahoo 等的云均拥有几十万台服务器。企业私有云一般拥有数百上千台服务器。云能赋予用户前所未有的计算能力。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;虚拟化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算支持用户在任意位置、使用各种终端获取应用服务。所请求的资源来自云，而不是固定的有形的实体。应用在云中某处运行，但实际上用户无需了解、也不用担心应用运行的具体位置。只需要一台笔记本或者一个手机，就可以通过网络服务来实现我们需要的一切，甚至包括超级计算这样的任务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高可靠性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云使用了数据多副本容错、计算节点同构可互换等措施来保障服务的高可靠性，使用云计算比使用本地计算机可靠。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通用性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算不针对特定的应用，在云的支撑下可以构造出千变万化的应用，同一个云可以同时支撑不同的应用运行。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高可扩展性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云的规模可以动态伸缩，满足应用和用户规模增长的需要。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按需服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云是一个庞大的资源池，你按需购买;云可以像自来水，电，煤气那样计费。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;极其廉价&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于云的特殊容错措施可以采用极其廉价的节点来构成云，云的自动化集中式管理使大量企业无需负担日益高昂的数据中心管理成本，云的通用性使资源的利用率较之传统系统大幅提升，因此用户可以充分享受云的低成本优势，经常只要花费几百美元、几天时间就能完成以前需要数万美元、数月时间才能完成的任务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;潜在的危险性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算服务除了提供计算服务外，还必然提供了存储服务。但是云计算服务当前垄断在私人机构(企业)手中，而他们仅仅能够提供商业信用。对于政府机构、商业机构(特别像银行这样持有敏感数据的商业机构)对于选择云计算服务应保持足够的警惕。一旦商业用户大规模使用私人机构提供的云计算服务，无论其技术优势有多强，都不可避免地让这些私人机构以数据(信息)的重要性挟制整个社会。&lt;/p&gt;
&lt;p&gt;对于信息社会而言，信息是至关重要的。另一方面，云计算中的数据对于数据所有者以外的其他用户云计算用户是保密的，但是对于提供云计算的商业机构而言确实毫无秘密可言。所有这些潜在的危险，是商业机构和政府机构选择云计算服务、特别是国外机构提供的云计算服务时，不得不考虑的一个重要的前提。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>又一款好用的 Kubernetes 集群终端管理工具 Kubebox</title>
    <link href="https://www.hi-linux.com/posts/53405.html"/>
    <id>https://www.hi-linux.com/posts/53405.html</id>
    <published>2020-05-23T01:50:00.000Z</published>
    <updated>2020-05-23T04:51:38.875Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-kubebox">什么是 Kubebox</h2><p>Kubebox 是 <code>Kubernetes</code> 集群的终端控制台，允许使用界面管理和监控集群实时状态。Kubebox 可显示 Pod 资源使用情况、集群监视和容器日志等。此外，用户可轻松导航到所需的命名空间并执行到所需容器，以便快速排障或恢复。</p><blockquote><p>项目地址：<a href="https://github.com/astefanutti/kubebox" target="_blank" rel="noopener">https://github.com/astefanutti/kubebox</a></p></blockquote><h2 id="安装-kubebox">安装 KubeBox</h2><p>KubeBox 安装非常的简单，只需根据不同平台下载对应的二进制文件就可以了。</p><h3 id="下载二进制文件">下载二进制文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Linux</span><br><span class="line">$ curl -Lo kubebox https:&#x2F;&#x2F;github.com&#x2F;astefanutti&#x2F;kubebox&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;kubebox-linux &amp;&amp; chmod +x kubebox</span><br><span class="line"></span><br><span class="line"># OSX</span><br><span class="line">$ curl -Lo kubebox https:&#x2F;&#x2F;github.com&#x2F;astefanutti&#x2F;kubebox&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;kubebox-macos &amp;&amp; chmod +x kubebox</span><br><span class="line"></span><br><span class="line"># Windows</span><br><span class="line">$ curl -Lo kubebox.exe https:&#x2F;&#x2F;github.com&#x2F;astefanutti&#x2F;kubebox&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;kubebox-windows.exe</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="运行-kubebox">运行 KubeBox</h3><p>下载完成二进制文件后，我们只需直接执行就可以运行 KubeBox。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;kubebox</span><br></pre></td></tr></table></figure><p>执行成功之后，我们将会看到如下图一样的运行界面。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox1.png" alt=""></p><p>如果你觉得上面的方法太麻烦，当然你也可以使用 <code>Docker</code> 一键启动 Kubebox 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --rm -v ~&#x2F;.kube&#x2F;:&#x2F;home&#x2F;node&#x2F;.kube&#x2F;:ro astefanutti&#x2F;kubebox</span><br></pre></td></tr></table></figure><blockquote><p>注意：KubeBox 需要依赖本地的 <code>Kuberctl</code> 才能正常启动。你需要提前将 Kubernetes Master 节点下的 Kubeconfig 配置文件放在你所在机器的 <code>~/.kube/</code> 目录下，并修改 config 文件中 Server 的 IP 为你本地可访问的 IP 地址，或者设置环境变量 <code>KUBECONFIG</code>。</p></blockquote><h2 id="kubebox-的基本使用">KubeBox 的基本使用</h2><h3 id="1-kubebox-常用操作方式">1. KubeBox 常用操作方式</h3><ol><li><p>按回车键可进行条目选择。</p></li><li><p>按 M 键可查看内存使用情况。</p></li><li><p>按 C 键可查看 CPU 使用情况。</p></li><li><p>按 T 键可查看网络使用情况。</p></li><li><p>按 R 键可进入 CMD 命令终端。</p></li><li><p>按 Q 键直接退出 KubeBox。</p></li></ol><p>更多操作说明可参考下图中的详细说明。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox2.png" alt=""></p><h3 id="2-操作-namespace">2. 操作 Namespace</h3><p>你可以使用 「⬆️⬇️」选择需要操作的 Namespace，按「回车键」确认选择。如果需要再次唤起 Namespace 选项，你可以按「N 键」。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox3.png" alt=""></p><h3 id="3-操作-pod">3. 操作 Pod</h3><p>进入具体的 Namespace 空间后，你可以使用「⬆️⬇️」 选择指定的 Pod，按「回车键」确认选择，此时会显示 Pod 的如下信息。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox4.png" alt=""></p><p>此时你可以对 Pod 进行以下操作。</p><ol><li><p>按「M 键」查看内存使用的具体情况。</p></li><li><p>按「C 键」查看 CPU 使用的具体情况。</p></li><li><p>按「T 键」查看网络使用的具体情况。</p></li><li><p>鼠标点击 Logs 框后，按 「⬆️⬇️」键滚动浏览日志文件。</p></li></ol><h3 id="4-操作容器">4. 操作容器</h3><p>鼠标点击 Pods 框后，你可以按「⬆️⬇️」键选中指定的容器，然后按「R 键」进入容器。如果需要退出容器，你可以输入 <code>exit</code> 命令进行退出。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox5.png" alt=""></p><h3 id="5-debug-选项">5. Debug 选项</h3><p>按「⬅️➡️」键可以进行 Namespace 和 Debug 的菜单切换，或者直接按「2 键」进入 Debug 选项卡。这里将记录一些你在 Kubebox 上的操作日志。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox6.png" alt=""></p><h2 id="kubebox-web-模式">Kubebox Web 模式</h2><p>Kubebox 不但可以直接运行在终端，你也可以将它直接部署到 Kubernetes 集群中。下面是一个部署的 YAML 资源文件示例，你也可以根据自身实际情况修改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"># Create Service Account</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Create ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: admin-user</span><br><span class="line">    namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Deploy Kubebox</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-box</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-box</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: kube-box</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-box</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: admin-user</span><br><span class="line">      containers:</span><br><span class="line">        - image: astefanutti&#x2F;kubebox:server</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          name: kube-box</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8080</span><br><span class="line">              protocol: TCP</span><br><span class="line">---</span><br><span class="line"># Expose kubebox service</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name:  kube-box-service</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      targetPort: 8080</span><br><span class="line">      nodePort: 30001</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app:  kube-box</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure><p>部署完成后，你可以直接通过 Web 的方式对其进行访问，其默认访问地址为：<code>http://&lt;kubernetes-master-ip&gt;:30001/</code>。</p><p>如果你觉得部署太复杂，你也可以先通过官方的演示地址 <code>https://kube.sh/</code> 提前体验下。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://www.jianshu.com/p/d7c3cae2214f" target="_blank" rel="noopener">https://www.jianshu.com/p/d7c3cae2214f</a></p></li><li><p><a href="https://blog.csdn.net/qq_21816375/article/details/90765673" target="_blank" rel="noopener">https://blog.csdn.net/qq_21816375/article/details/90765673</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Kubebox&quot;&gt;什么是 Kubebox&lt;/h2&gt;
&lt;p&gt;Kubebox 是 &lt;code&gt;Kubernetes&lt;/code&gt; 集群的终端控制台，允许使用界面管理和监控集群实时状态。Kubebox 可显示 Pod 资源使用情况、集群监视和容器日志等。此外，用户可轻松导航到所需的命名空间并执行到所需容器，以便快速排障或恢复。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/astefanutti/kubebox&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/astefanutti/kubebox&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;安装-KubeBox&quot;&gt;安装 KubeBox&lt;/h2&gt;
&lt;p&gt;KubeBox 安装非常的简单，只需根据不同平台下载对应的二进制文件就可以了。&lt;/p&gt;
&lt;h3 id=&quot;下载二进制文件&quot;&gt;下载二进制文件&lt;/h3&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# Linux&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ curl -Lo kubebox https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;astefanutti&amp;#x2F;kubebox&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v0.6.1&amp;#x2F;kubebox-linux &amp;amp;&amp;amp; chmod +x kubebox&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# OSX&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ curl -Lo kubebox https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;astefanutti&amp;#x2F;kubebox&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v0.6.1&amp;#x2F;kubebox-macos &amp;amp;&amp;amp; chmod +x kubebox&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Windows&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ curl -Lo kubebox.exe https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;astefanutti&amp;#x2F;kubebox&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v0.6.1&amp;#x2F;kubebox-windows.exe&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Kubebox" scheme="https://www.hi-linux.com/tags/Kubebox/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟学会写一个自己的 Prometheus Exporter</title>
    <link href="https://www.hi-linux.com/posts/10846.html"/>
    <id>https://www.hi-linux.com/posts/10846.html</id>
    <published>2020-05-23T01:40:00.000Z</published>
    <updated>2020-05-23T04:17:04.473Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>去年底我写了一个阿里云云监控的 Prometheus Exporter, 后续迭代的过程中有一些经验总结, 这篇文章就将它们串联起来做一个汇总, 讲讲为什么要写 Exporter 以及怎么写一个好用的 Exporter?</p><h2 id="何为-prometheus-exporter">何为 Prometheus Exporter?</h2><p>Prometheus 监控基于一个很简单的模型: 主动抓取目标的指标接口(HTTP 协议)获取监控指标, 再存储到本地或远端的时序数据库. Prometheus 对于指标接口有一套固定的格式要求, 格式大致如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># HELP http_requests_total The total number of HTTP requests.</span><br><span class="line"># TYPE http_requests_total counter</span><br><span class="line">http_requests_total&#123;method&#x3D;&quot;post&quot;,code&#x3D;&quot;200&quot;&#125; 1027</span><br><span class="line">http_requests_total&#123;method&#x3D;&quot;post&quot;,code&#x3D;&quot;400&quot;&#125;    3</span><br></pre></td></tr></table></figure><p>对于自己写的代码, 我们当然可以使用 Prometheus 的 SDK 暴露出上述格式的指标. 但对于大量现有服务, 系统甚至硬件, 它们并不会暴露 Prometheus 格式的指标. 比如说:</p><ul><li>Linux 的很多指标信息以文件形式记录在 /proc/ 下的各个目录中, 如 /proc/meminfo 里记录内存信息, /proc/stat 里记录 CPU 信息;</li><li>Redis 的监控信息需要通过 INFO 命令获取;</li><li>路由器等硬件的监控信息需要通过 `SNMP** 协议获取;</li><li>…</li></ul><a id="more"></a><p>要监控这些目标, 我们有两个办法, 一是改动目标系统的代码, 让它主动暴露 Prometheus 格式的指标, 当然, 对于上述几个场景这种办法完全是不现实的. 这时候就只能采用第二种办法:</p><ol><li>编写一个代理服务, 将其它监控信息转化为 Prometheus 格式的指标</li></ol><p>这个代理服务的基本运作方式, 可以用下面这张图来表示:</p><p><img src="https://aleiwu.com/img/exporter/exporter.png" alt=""></p><p>而这样的代理服务, 就称作 Prometheus Exporter, 对于上面那些常见的情形, 社区早就写好了成熟的 Exporter, 它们就是 node_exporter, redis_exporter 和 snmp_exporter.</p><h2 id="为什么要写-exporter">为什么要写 Exporter?</h2><p>嗯, 写 exporter 可以把监控信息接进 Prometheus, 那为什么非要接进 Prometheus 呢?</p><p>我们不妨以阿里云云监控为例, 看看接进 Prometheus 的好处都有啥:</p><p>阿里云免费提供了一部分云监控服务, 但云监控的免费功能其实很有限, 没办法支持这些痛点场景:</p><ul><li>Adhoc TopN 查询: 比如”找到当前对公网带宽消耗最大的 10 台服务器”;</li><li>容量规划: 比如”分析过去一个月某类型服务的资源用量”;</li><li>高级报警: 比如”对比过去一周的指标值, 根据标准差进行报警”;</li><li>整合业务监控: 业务的监控信息存在于另一套监控系统中, 两套系统的看板, 警报都很难联动;</li></ul><p>幸好, 云监控提供了获取监控信息的 API, 那么我们很自然地就能想到: 只要写一个阿里云云监控的 Exporter, 不就能将阿里云的监控信息整合到 Prometheus 体系当中了吗?</p><p>当然, Exporter 就是做这个的!</p><p>集成到 Prometheus 监控之后, 借助 PromQL 强大的表达能力和 Alertmanager, Grafana 的强大生态, 我们不仅能实现所有监控信息的整合打通, 还能获得更丰富的报警选择和更强的看板能力. 下面就是一个对 RDS 进行 TopN 查询的例子:</p><p><img src="https://aleiwu.com/img/exporter/RDS.png" alt=""></p><p>这个动机对于其它类型的 Exporter 也都是适用的: 当一个系统本身暴露了监控信息, 却又无法接入 Prometheus, 我们就可以考虑写一个 exporter 把它接进来了.</p><h2 id="写一个好用的-exporter">写一个好用的 Exporter</h2><p>类似 “阿里云 Exporter” 这种形式的 Exporter 是非常好写的, 逻辑就是一句话:</p><ol><li>写一个 Web 服务, 每当 Prometheus 请求我们这个服务问我们要指标的时候, 我们就请求云监控的 API 获得监控信息, 再转化为 Prometheus 的格式返回出去;<br>但这样写完之后仅仅是”能用”, 要做到”好用”, 还有诸多考量.</li></ol><h2 id="从文档开始">从文档开始</h2><p>Prometheus 官方文档中 Writing Exporter 这篇写得非常全面, 假如你要写 exporter 推荐先通读一遍, 限于篇幅, 这里只概括一下:</p><ul><li>做到开箱即用(默认配置就可以直接开始用)</li><li>推荐使用 YAML 作为配置格式</li><li>指标使用下划线命名</li><li>为指标提供 HELP String (指标上的 # HELP 注释, 事实上这点大部分 exporter 都没做好)</li><li>为 Exporter 本身的运行状态提供指标</li><li>可以提供一个落地页</li></ul><p>下面几节中, 也会有和官方文档重复的部分, 但会略去理论性的部分(官方文档已经说的很好了), 着重讲实践例子.</p><h2 id="可配置化">可配置化</h2><p>官方文档里讲了 Exporter 需要开箱即用, 但其实这只是基本需求, 在开箱即用的基础上, 一个良好的 Exporter 需要做到高度可配置化. 这是因为大部分 Exporter 暴露的指标中, 真正会用到的大概只有 20%, 冗余的 80% 指标不仅会消耗不必要的资源还会拖累整体的性能. 对于一般的 Exporter 而言, BP 是默认只提供必要的指标, 并且提供 extra 和 filter 配置, 允许用户配置额外的指标抓取和禁用一部分的默认指标. 而对于阿里云 Exporter 而言, 由于阿里云有数十种类型的资源(RDS, ECS, SLB…), 因此我们无法推测用户到底希望抓哪些监控信息, 因此只能全部交给用户配置. 当然, 项目还是提供了包含 SLB, RDS, ECS 和 Redis 的默认配置文件, 尽力做到开箱即用.</p><h2 id="info-指标">Info 指标</h2><p>针对指标标签(Label), 我们考虑两点: “唯一性” 和 “可读性”:</p><p>“唯一性”: 对于指标, 我们应当只提供有”唯一性” 的(Label), 比如说我们暴露出 “ECS 的内存使用” 这个指标. 这时, “ECS ID” 这个标签就可以唯一区分所有的指标. 这时我们假如再加入 “IP”, “操作系统”, “名字” 这样的标签并不会增加额外的区分度, 反而会在某些状况下造成一些问题. 比方说某台 ECS 的名字变了, 那么在 Prometheus 内部就会重新记录一个时间序列, 造成额外的开销和部分 PromQL 计算的问题, 比如下面的示意图:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">序列A &#123;id&#x3D;&quot;foo&quot;, name&#x3D;&quot;旧名字&quot;&#125; ..................</span><br><span class="line">序列B &#123;id&#x3D;&quot;foo&quot;, name&#x3D;&quot;新名字&quot;&#125;                   .................</span><br></pre></td></tr></table></figure><p>“可读性”: 上面的论断有一个例外, 那就是当标签涉及”可读性”时, 即使它不贡献额外的区分度, 也可以加上. 比如 “IP” 这样的标签, 假如我们只知道 ECS ID 而不知道 IP, 那么根本对不上号, 排查问题也会异常麻烦.</p><p>可以看到, 唯一性和可读性之间其实有一些权衡, 那么有没有更好的办法呢?</p><p>答案就是 Info 指标(Info Metric). 单独暴露一个指标, 用 label 来记录实例的”额外信息”, 比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ecs_info&#123;id&#x3D;&quot;foo&quot;, name&#x3D;&quot;DIO&quot;, os&#x3D;&quot;linux&quot;, region&#x3D;&quot;hangzhou&quot;, cpu&#x3D;&quot;4&quot;, memory&#x3D;&quot;16GB&quot;, ip&#x3D;&quot;188.188.188.188&quot;&#125; 1</span><br></pre></td></tr></table></figure><p>这类指标的值习惯上永远为 1, 它们并记录实际的监控值, 仅仅记录 ecs 的一些额外信息. 而在使用的时候, 我们就可以通过 PromQL 的 “Join”(group_left) 语法将这些信息加入到最后的查询结果中:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 这条 PromQL 将 aliyun_meta_rds_info 中记录的描述和状态从添加到了 aliyun_acs_rds_dashboard_MemoryUsage 中</span><br><span class="line">aliyun_acs_rds_dashboard_MemoryUsage </span><br><span class="line">    * on (instanceId) group_left(DBInstanceDescription,DBInstanceStatus) </span><br><span class="line">    aliyun_meta_rds_info</span><br></pre></td></tr></table></figure><p>阿里云 Exporter 就大量使用了 Info 指标这种模式来提供实例的详细信息, 最后的效果就是监控指标本身非常简单, 只需要一个 ID 标签, 而看板上的信息依然非常丰富:</p><p><img src="https://aleiwu.com/img/exporter/ECS-detail.png" alt=""></p><h2 id="记录-exporter-本身的信息">记录 Exporter 本身的信息</h2><p>任何时候元监控(或者说自监控)都是首要的, 我们不可能依赖一个不被监控的系统去做监控. 因此了解怎么监控 exporter 并在编写时考虑到这点尤为重要.</p><p>首先, 所有的 Prometheus 抓取目标都有一个 up 指标用来表明这个抓取目标能否被成功抓取. 因此, 假如 exporter 挂掉或无法正常工作了, 我们是可以从相应的 up 指标立刻知道并报警的.</p><p>但 up 成立的条件仅仅是指标接口返回 200 并且内容可以被解析, 这个粒度太粗了. 假设我们用 exporter 监控了好几个不同的模块, 其中有几个模块的指标无法正常返回了, 这时候 up 就帮不上忙了.</p><p>因此一个 BP 就是针对各个子模块, 甚至于各类指标, 记录细粒度的 up 信息, 比如阿里云 exporter 就选择了为每类指标都记录 up 信息:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aliyun_acs_rds_dashboard_MemoryUsage&#123;id&#x3D;&quot;foo&quot;&#125; 1233456</span><br><span class="line">aliyun_acs_rds_dashboard_MemoryUsage&#123;id&#x3D;&quot;bar&quot;&#125; 3215123</span><br><span class="line"></span><br><span class="line">aliyun_acs_rds_dashboard_MemoryUsage_up 1</span><br></pre></td></tr></table></figure><p>当 aliyun_acs_rds_dashboard_MemoryUsage_up 这个指标出现 0 的时候, 我们就能知道 aliyun rds 内存信息的抓取不正常, 需要报警出来人工介入处理了.</p><p>另外, 阿里云的指标抓取 API 是有流控和每月配额的, 因此阿里云 exporter 里还记录了各种抓取请求的次数和响应时间的分布, 分别用于做用量的规划和基于响应时间的监控报警. 这也是”监控 exporter”本身的一个例子.</p><h2 id="设计落地页">设计落地页</h2><p>用过 node_exporter 的会知道, 当访问它的主页, 也就是根路径 / 时, 它会返回一个简单的页面, 这就是 exporter 的落地页(Landing Page).</p><p>落地页什么都可以放, 我认为最有价值的是放文档和帮助信息(或者放对应的链接). 而文档中最有价值的莫过于对于每个指标项的说明, 没有人理解的指标没有任何价值.</p><h2 id="可选-一键起监控">可选: 一键起监控</h2><p>这一点超出了 exporter 本身的范畴, 但确确实实是 exporter “好用” 的一个极大助力. exporter 本身是无法单独使用的, 而现实情况是 Prometheus, Grafana, Alertmanager 再对接 Slack, 钉钉啥的, 这一套假如需要从头搭建, 还是有一定的门槛(用 k8s 的话至少得看一下 helm chart 吧), 甚至于有些时候想搭建监控的是全栈(gan)工程师, 作为全公司的独苗, 很可能更多的精力需要花在跟进前端的新技术上(不我没有黑前端…). 这时候, 一个一键拉起整套监控系统的命令诱惑力是非常大的.</p><p>要一键拉起整套监控栈, 首先 kubernetes 就不考虑了, 能无痛部署生产级 kubernetes 集群的大佬不会需要这样的命令. 这时候, 反倒凉透的 docker-compose 是一个很好的选择. 还是以阿里云 exporter 为例, 仓库提供的 docker-compose stack 里提供了 Prometheus, aliyun-exporter, Grafana(看板), Alertmanager(发警报), alertmanager-dingtalk-webhook(适配 alertmanager 的警报到钉钉机器人) 的一键部署并且警报规则和 Grafana 看板页一并配置完毕. 这么一来, 只要用户有一台装了 docker 的机器, 他就能在5分钟之内打开 Grafana 看到这些效果(还有钉钉警报…假如这位用户的服务器不太健康的话):</p><p><img src="https://aleiwu.com/img/exporter/stack.gif" alt=""></p><p>当然了, 想要稳固地部署这套架构, 还是需要多机做高可用或者直接扔到 k8s, swarm 这样的编排系统上. 但假如没有”一键部署”的存在, 很多对 Prometheus 生态不熟悉的开发者就会被拒之门外; 另外, 对于有经验的用户, “一键部署”也能帮助他们快速理解这个 exporter 的特性, 帮助他们判断是否需要启用这个组件.</p><h2 id="结语">结语</h2><p>你可能已经看出来了, 这篇文章的本意是打广告(当然, 我已经非常努力地写了我所认为的”干货”!). aliyun-exporter 这个项目其实最开始只是我练习 Python 用的, 但在前几天碰到一位用户告诉我他们在生产中使用了这个项目, 这给了莫大的鼓舞, 正好我还没有在公开场合 Promote 过这个项目, 因此这周就捞一把, 希望项目本身或这些衍生出来的经验中有一样能帮到大家吧.</p><blockquote><p>来源：Aylei’s Blog</p><p>原文：<a href="http://j.mp/2QkCn8T" target="_blank" rel="noopener">http://j.mp/2QkCn8T</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;去年底我写了一个阿里云云监控的 Prometheus Exporter, 后续迭代的过程中有一些经验总结, 这篇文章就将它们串联起来做一个汇总, 讲讲为什么要写 Exporter 以及怎么写一个好用的 Exporter?&lt;/p&gt;
&lt;h2 id=&quot;何为-Prometheus-Exporter&quot;&gt;何为 Prometheus Exporter?&lt;/h2&gt;
&lt;p&gt;Prometheus 监控基于一个很简单的模型: 主动抓取目标的指标接口(HTTP 协议)获取监控指标, 再存储到本地或远端的时序数据库. Prometheus 对于指标接口有一套固定的格式要求, 格式大致如下:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# HELP http_requests_total The total number of HTTP requests.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# TYPE http_requests_total counter&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;http_requests_total&amp;#123;method&amp;#x3D;&amp;quot;post&amp;quot;,code&amp;#x3D;&amp;quot;200&amp;quot;&amp;#125; 1027&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;http_requests_total&amp;#123;method&amp;#x3D;&amp;quot;post&amp;quot;,code&amp;#x3D;&amp;quot;400&amp;quot;&amp;#125;    3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;对于自己写的代码, 我们当然可以使用 Prometheus 的 SDK 暴露出上述格式的指标. 但对于大量现有服务, 系统甚至硬件, 它们并不会暴露 Prometheus 格式的指标. 比如说:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux 的很多指标信息以文件形式记录在 /proc/ 下的各个目录中, 如 /proc/meminfo 里记录内存信息, /proc/stat 里记录 CPU 信息;&lt;/li&gt;
&lt;li&gt;Redis 的监控信息需要通过 INFO 命令获取;&lt;/li&gt;
&lt;li&gt;路由器等硬件的监控信息需要通过 `SNMP** 协议获取;&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/categories/Prometheus/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>推荐一个 Linux 计划任务 Crontab 在线生成器</title>
    <link href="https://www.hi-linux.com/posts/23704.html"/>
    <id>https://www.hi-linux.com/posts/23704.html</id>
    <published>2020-05-23T01:30:00.000Z</published>
    <updated>2020-05-23T04:12:40.611Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Linux / Unix</code> 系统里有一个很方便的程序「例行性计划任务」（Crontab），接触过的朋友一定不陌生。Crontab 主要是让系统去执行一些固定时间要自动进行的例行性工作，最常用的例如备份资料、移除暂存文件、更新或重新启动等等。如果将某个周期执行一次的指令写进 <code>Crontab</code>，它就会随着系统时间的推移在你指定的时间自动执行，减少每次都必须重复执行相同工作的麻烦。</p><p><code>Crontab</code> 有几种设定方法，最直观的是在图形化控制台（例如 <code>cPanel</code>）上操作，一般使用者可能会在命令行编辑 <code>/etc/crontab</code> 文件。但令我困扰的是 <code>Crontab</code> 时间格式写法有些复杂，如果没有参考说明文档就很难写出正确格式。或者你想要让计划任务时间更细粒度、更有弹性，你就必须知道怎么样以标准格式来描述要执行某个例行性工作的时间。</p><p>最近无意间发现一个很好用的免费工具「<code>Crontab.guru</code>」，它是一个更快速、更简单的在线计划任务编辑器。无须额外下载安装任何程序，只要依照 <code>Crontab.guru</code> 指定每列的时间，就可以快速完成计划任务时间的设定。它除了会以英文来描述这个时间，让使用者更容易理解外，你只要将结果复制粘贴到 <code>Crontab</code> 就能设定好指定的计划任务。</p><p>下面我们将以图文方式来叙述「<code>Crontab.guru</code>」工具的使用方法。</p><blockquote><ol><li><p>网站名称：Crontab.guru</p></li><li><p>网站链接：<a href="https://crontab.guru/" target="_blank" rel="noopener">https://crontab.guru/</a></p></li></ol></blockquote><a id="more"></a><h2 id="使用方法">使用方法</h2><ol><li>STEP 1</li></ol><p>开启 <code>Crontab.guru</code> 网站后，主要功能就在网站上方，也就是你看到的那一条可编辑列。</p><p><img src="https://i2.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1242.png" alt=""></p><p>预设情况每次开启 <code>Crontab.guru</code> 网站时都会自动跳出一组计划任务时间写法。你可以注意看一下每一个数字底下都会有对应的单位，由左至右分别是分钟、小时、日、月和周。下方还会告诉你这些列的表示法，例如可以用 <code>*</code> 代表任何数值、以 <code>,</code> 分隔多个数值等等。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1243.png" alt=""></p><ol start="2"><li>STEP 2</li></ol><p>前面我们有说过 <code>Crontab.guru</code> 本身就是一个简单方便的 <code>Crontab</code> 编辑器，因此使用者可以直接选取数字将它改成你要的计划时间。在编辑时 <code>Crontab.guru</code> 还会同步在上方「描述」标示出这个数值代表的意思，例如：下图我在编辑的「21」是代表 <code>hour</code>，也就是指晚上九点 。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1247.png" alt=""></p><p>每列都有不同的表达方式，例如加上 <code>,</code> 逗号来分隔多个数值、加上 <code>*</code> 代表任何数值，也能使用 <code>–</code> 来描述某个区间，修改时底下会告诉你可以使用的数值有那一些。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1247-1.png" alt=""></p><ol start="3"><li>STEP 3</li></ol><p>如果要描述「0 0,12 1 */2 *」这样复杂的计划任务，或许你很难马上理解过来。<code>Crontab.guru</code> 的好处是它会转为英文描述显示于网站上方，我们就能很清楚知道这是指「每两个月的第一天当日的 0 点、12 点」。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1248.png" alt=""></p><p>如果你想知道一些固定的时间写法范本，<code>Crontab.guru</code> 也有一个「Examples」页面。里面收录许多范例，例如：每小时、每半天、每周、每季或每半年等等。</p><h2 id="总结">总结</h2><p>至此，利用 <code>Crontab.guru</code> 快速设定计划任务的方法就介绍完了。最后在这里再推荐另一个类似的在线计划任务生成工具 <code>Linux Crontab Generator</code>，它的使用方法和 <code>Crontab.guru</code> 类似，但功能更加强大！</p><blockquote><p>项目地址：<a href="https://helloacm.com/crontab-generator/" target="_blank" rel="noopener">https://helloacm.com/crontab-generator/</a></p></blockquote><p><img src="https://i.loli.net/2019/11/12/Q8Gr37qzdpuh4mD.png" alt=""></p><blockquote><p>来源：免费资源网络社群</p><p>原文：<a href="https://url.cn/5SzHje6" target="_blank" rel="noopener">https://url.cn/5SzHje6</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Linux / Unix&lt;/code&gt; 系统里有一个很方便的程序「例行性计划任务」（Crontab），接触过的朋友一定不陌生。Crontab 主要是让系统去执行一些固定时间要自动进行的例行性工作，最常用的例如备份资料、移除暂存文件、更新或重新启动等等。如果将某个周期执行一次的指令写进 &lt;code&gt;Crontab&lt;/code&gt;，它就会随着系统时间的推移在你指定的时间自动执行，减少每次都必须重复执行相同工作的麻烦。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Crontab&lt;/code&gt; 有几种设定方法，最直观的是在图形化控制台（例如 &lt;code&gt;cPanel&lt;/code&gt;）上操作，一般使用者可能会在命令行编辑 &lt;code&gt;/etc/crontab&lt;/code&gt; 文件。但令我困扰的是 &lt;code&gt;Crontab&lt;/code&gt; 时间格式写法有些复杂，如果没有参考说明文档就很难写出正确格式。或者你想要让计划任务时间更细粒度、更有弹性，你就必须知道怎么样以标准格式来描述要执行某个例行性工作的时间。&lt;/p&gt;
&lt;p&gt;最近无意间发现一个很好用的免费工具「&lt;code&gt;Crontab.guru&lt;/code&gt;」，它是一个更快速、更简单的在线计划任务编辑器。无须额外下载安装任何程序，只要依照 &lt;code&gt;Crontab.guru&lt;/code&gt; 指定每列的时间，就可以快速完成计划任务时间的设定。它除了会以英文来描述这个时间，让使用者更容易理解外，你只要将结果复制粘贴到 &lt;code&gt;Crontab&lt;/code&gt; 就能设定好指定的计划任务。&lt;/p&gt;
&lt;p&gt;下面我们将以图文方式来叙述「&lt;code&gt;Crontab.guru&lt;/code&gt;」工具的使用方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;网站名称：Crontab.guru&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;网站链接：&lt;a href=&quot;https://crontab.guru/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://crontab.guru/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Crontab" scheme="https://www.hi-linux.com/tags/Crontab/"/>
    
  </entry>
  
  <entry>
    <title>推荐一个强大到可让任何程序秒变系统服务的神器 EasyService</title>
    <link href="https://www.hi-linux.com/posts/9752.html"/>
    <id>https://www.hi-linux.com/posts/9752.html</id>
    <published>2020-05-23T01:20:00.000Z</published>
    <updated>2020-05-23T04:05:17.728Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-easyservice">什么是 EasyService</h2><p>如果你的 <code>Windows</code> 程序需要在后台长期运行，而且你希望它在开机后用户登录之前就自动运行、且在用户注销之后也不停止，那么你需要将程序注册为一个系统服务。</p><p>然而，在 <code>Windows</code> 下编写一个可注册为系统服务的程序并不是一件简单的事情。首先，程序必须是二进制的可执行程序，这就排除了脚本语言和虚拟机语言；其次，程序必须按系统服务的格式编写，过程相当繁琐。</p><p><code>EasyService</code> 是一个可以将常规程序注册为系统服务的工具，体积只有 16KB 。你可以按常规的方法编写程序，然后用 <code>EasyService</code> 注册为一个系统服务，这样你的程序就可以在开机后用户登录之前自动运行、且在用户注销之后也不会停止。</p><p>如果你需要在 <code>Windows</code> 系统下部署网站、<code>API</code> 或其他需要长期在后台运行的服务， <code>EasyService</code> 将是一个很有用的工具。</p><blockquote><p>项目地址：<a href="https://github.com/pandolia/easy-service/" target="_blank" rel="noopener">https://github.com/pandolia/easy-service/</a></p></blockquote><a id="more"></a><h3 id="easyservice-实现原理">EasyService 实现原理</h3><p><code>EasyService</code> 实质是将自己（<code>svc.exe</code>）注册为一个系统服务，此服务启动时，会读取 <code>svc.conf</code> 中的配置。然后创建一个子进程运行 <code>Worker</code> 中指定的程序及命令行参数并监视该子进程。如果发现子进程停止运行，会重新启动一个子进程。而当此服务停止时，会向子进程的标准输入中写入数据 “<code>exit</code>” ，并等待子进程退出，如果等待时间超过 10 秒，则直接终止子进程。</p><h2 id="使用-easyservice">使用 EasyService</h2><ol><li><code>EasyService</code> 对程序仅有一个强制要求和一个建议。</li></ol><ul><li><p>强制要求： 程序应持续运行</p></li><li><p>建议： 当程序的标准输入接收到 “<code>exit</code>” 后在 10 秒之内退出</p></li></ul><p>这类型典型的程序有很多，比如：命令行内网穿透 <code>frp</code> 工具、各种 <code>Nodejs</code>、<code>Python</code> 小工具等等。</p><ol start="2"><li>安装 EasyService</li></ol><p>安装 <code>EasyService</code> 的前提是系统已安装 <code>.NetFramework 4.0</code> （大部分 <code>Windows</code> 系统都已自带）。然后你就可以通过下面的地址下载对应的安装程序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;pandolia&#x2F;easy-service&#x2F;archive&#x2F;master.zip</span><br></pre></td></tr></table></figure><ol start="3"><li>编辑配置文件</li></ol><p>解压上面的安装压缩包，然后打开 <code>svc.conf</code> 文件，并根据需求修改配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 需要注册成 Windows 系统服务的名称，不能与系统中已有服务重名</span><br><span class="line">ServiceName: An Easy Service</span><br><span class="line"></span><br><span class="line"># 需要运行的可执行程序及命令行参数</span><br><span class="line">Worker: node index.js</span><br><span class="line"></span><br><span class="line"># 程序运行的工作目录，请确保该目录已存在</span><br><span class="line">WorkingDir: worker</span><br><span class="line"></span><br><span class="line"># 输出目录，程序运行过程的输出将会写到这个目录下面，请确保该目录已存在</span><br><span class="line">OutFileDir: outfiles</span><br><span class="line"></span><br><span class="line"># 程序输出的编码形式，如果不确定，请设为空或 none</span><br><span class="line">WorkerEncoding: utf8</span><br></pre></td></tr></table></figure><ol start="4"><li>注册成为一个服务</li></ol><p>用管理员账号登录系统后，在 <code>svc.exe</code> 所在的目录下打开命令行窗口。</p><ul><li><p>首先，运行 <code>svc check</code> 命令检查配置是否合法。</p></li><li><p>其次，运行 <code>svc test-worker</code> 命令测试 <code>Worker</code> 程序是否能正常运行。</p></li></ul><p>测试无误后，接着执行以下命令。</p><ul><li>运行 <code>svc install</code> 命令注册并启动系统服务，此时你的程序就已经开始运行了。即便用户注销也不会停止运行，且系统开机后、用户登录之前就会自动运行。你在服务管理控制台中也可以查看已注册的服务。</li></ul><blockquote><p>注意：<code>Windows 10</code> 系统下，需要先在开始菜单中搜索 <code>cmd</code> 命令。然后右键以管理员身份运行后，再切换到 <code>svc.conf</code> 所在的目录并执行以上命令。</p></blockquote><p>如果要在命令行下管理新注册的服务，你可以使用以下这些命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ svc stop # 停止一个服务</span><br><span class="line">$ svc start # 启动一个服务</span><br><span class="line">$ svc restart # 重启一个服务</span><br><span class="line">$ svc remove # 删除一个服务</span><br></pre></td></tr></table></figure><ol start="5"><li>注册多个服务</li></ol><p>如果需要注册多个服务，你可以先新建多个目录，并将 <code>svc.exe</code> 和 <code>svc.conf</code> 拷贝到这些目录。然后修改各目录 <code>svc.conf</code> 文件中的服务名和程序名等内容。最后，再在这些目录下以管理员权限打开命令行窗口执行 <code>svc check|test-worker|install</code> 等命令就可以了。需要注意的是：</p><ul><li><p>不同目录下的服务名不能相同，也不能和系统已有的服务同名。</p></li><li><p>配置文件中的 <code>Worker/WorkingDir/OutFileDir</code> 都是相对于该配置文件的路径。</p></li><li><p>注册服务之前，<code>WorkingDir/OutFileDir</code> 所指定的目录必须先创建好。</p></li></ul><p>至此，如何利用 <code>EasyService</code> 快速注册一个服务的方法就介绍完了，你学会了吗？</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://github.com/pandolia/easy-service" target="_blank" rel="noopener">https://github.com/pandolia/easy-service</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-EasyService&quot;&gt;什么是 EasyService&lt;/h2&gt;
&lt;p&gt;如果你的 &lt;code&gt;Windows&lt;/code&gt; 程序需要在后台长期运行，而且你希望它在开机后用户登录之前就自动运行、且在用户注销之后也不停止，那么你需要将程序注册为一个系统服务。&lt;/p&gt;
&lt;p&gt;然而，在 &lt;code&gt;Windows&lt;/code&gt; 下编写一个可注册为系统服务的程序并不是一件简单的事情。首先，程序必须是二进制的可执行程序，这就排除了脚本语言和虚拟机语言；其次，程序必须按系统服务的格式编写，过程相当繁琐。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EasyService&lt;/code&gt; 是一个可以将常规程序注册为系统服务的工具，体积只有 16KB 。你可以按常规的方法编写程序，然后用 &lt;code&gt;EasyService&lt;/code&gt; 注册为一个系统服务，这样你的程序就可以在开机后用户登录之前自动运行、且在用户注销之后也不会停止。&lt;/p&gt;
&lt;p&gt;如果你需要在 &lt;code&gt;Windows&lt;/code&gt; 系统下部署网站、&lt;code&gt;API&lt;/code&gt; 或其他需要长期在后台运行的服务， &lt;code&gt;EasyService&lt;/code&gt; 将是一个很有用的工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/pandolia/easy-service/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/pandolia/easy-service/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Windows" scheme="https://www.hi-linux.com/categories/Windows/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="EasyService" scheme="https://www.hi-linux.com/tags/EasyService/"/>
    
      <category term="Windows" scheme="https://www.hi-linux.com/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>分享一些让你提升命令行效率的 Bash 快捷键( 强烈建议收藏！)</title>
    <link href="https://www.hi-linux.com/posts/33391.html"/>
    <id>https://www.hi-linux.com/posts/33391.html</id>
    <published>2020-05-23T01:10:00.000Z</published>
    <updated>2020-05-23T03:59:53.200Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>做为一个 <code>Linux</code> 用户，一定经常和命令行打交道。而绝大多数 <code>Linux</code> 发行版默认的 <code>Shell</code> 都是 <code>Bash</code>，本文将给大家介绍一些 <code>Bash</code> 中非常实用的快捷键操作方法。你只要掌握了这些快捷键后，将极大的提高你的命令行操作效率，让你在使用 <code>SHELL</code> 的时候效率可以快得飞起来。</p><h2 id="编辑命令">编辑命令</h2><ul><li><p><code>Ctrl + a</code>：移到命令行首</p></li><li><p><code>Ctrl + e</code> ：移到命令行尾</p></li><li><p><code>Ctrl + f</code> ：按字符前移（右向）</p></li><li><p><code>Ctrl + b</code> ：按字符后移（左向）</p></li><li><p><code>Alt + f</code> ：按单词前移（右向）</p></li><li><p><code>Alt + b</code> ：按单词后移（左向）</p></li><li><p><code>Ctrl + xx</code>：在命令行首和光标之间移动</p></li><li><p><code>Ctrl + u</code> ：从光标处删除至命令行首</p></li><li><p><code>Ctrl + k</code> ：从光标处删除至命令行尾</p></li><li><p><code>Ctrl + w</code> ：从光标处删除至字首</p></li><li><p><code>Alt + d</code> ：从光标处删除至字尾</p></li><li><p><code>Ctrl + d</code> ：删除光标处的字符</p></li><li><p><code>Ctrl + h</code> ：删除光标前的字符</p></li><li><p><code>Ctrl + y</code> ：粘贴至光标后</p></li><li><p><code>Alt + c</code> ：从光标处更改为首字母大写的单词</p></li><li><p><code>Alt + u</code> ：从光标处更改为全部大写的单词</p></li><li><p><code>Alt + l</code> ：从光标处更改为全部小写的单词</p></li><li><p><code>Ctrl + t</code> ：交换光标处和之前的字符</p></li><li><p><code>Alt + t</code> ：交换光标处和之前的单词</p></li><li><p><code>Alt + Backspace</code>：与 <code>Ctrl + w</code> 相同，分隔符有些差别。</p></li></ul><a id="more"></a><h2 id="重新执行命令">重新执行命令</h2><ul><li><p><code>Ctrl + r</code>：逆向搜索命令历史</p></li><li><p><code>Ctrl + g</code>：从历史搜索模式退出</p></li><li><p><code>Ctrl + p</code>：历史中的上一条命令</p></li><li><p><code>Ctrl + n</code>：历史中的下一条命令</p></li><li><p><code>Alt + .</code>：使用上一条命令的最后一个参数</p></li></ul><h2 id="控制命令">控制命令</h2><ul><li><p><code>Ctrl + l</code>：清屏</p></li><li><p><code>Ctrl + o</code>：执行当前命令，并选择上一条命令</p></li><li><p><code>Ctrl + s</code>：阻止屏幕输出</p></li><li><p><code>Ctrl + q</code>：允许屏幕输出</p></li><li><p><code>Ctrl + c</code>：终止命令</p></li><li><p><code>Ctrl + z</code>：挂起命令</p></li></ul><h2 id="bang-命令">Bang (!) 命令</h2><ul><li><p><code>!!</code>：执行上一条命令</p></li><li><p><code>!blah</code>：执行最近的以 <code>blah</code> 开头的命令，如 <code>!ls</code></p></li><li><p><code>!blah:p</code>：仅打印输出，而不执行</p></li><li><p><code>!$</code>：上一条命令的最后一个参数，与 <code>Alt + .</code> 相同</p></li><li><p><code>!$:p</code>：打印输出 <code>!$</code> 的内容</p></li><li><p><code>!*</code>：上一条命令的所有参数</p></li><li><p><code>!*:p</code>：打印输出 <code>!*</code> 的内容</p></li><li><p><code>^blah</code>：删除上一条命令中的 <code>blah</code></p></li><li><p><code>^blah^foo</code>：将上一条命令中的 <code>blah</code> 替换为 <code>foo</code></p></li><li><p><code>^blah^foo^</code>：将上一条命令中所有的 <code>blah</code> 都替换为 <code>foo</code></p></li></ul><p><strong>友情提示：</strong></p><ol><li><p>以上介绍的大多数 <code>Bash</code> 快捷键仅当在 <code>Emacs</code> 编辑模式时有效。若你将 <code>Bash</code> 配置为 <code>VI</code> 编辑模式，那将遵循 <code>VI</code>  的按键绑定。<code>Bash</code> 默认为 <code>Emacs</code> 编辑模式，如果你的 <code>Bash</code> 不在 <code>Emacs</code> 编辑模式，可通过 <code>set -o emacs</code> 进行设置。</p></li><li><p><code>^S</code>、<code>^Q</code>、<code>^C</code>、<code>^Z</code> 是由终端设备处理的，可用 <code>stty</code> 命令设置。</p></li></ol><blockquote><p>来源：LinuxTOY</p><p>原文：<a href="https://url.cn/5Sj2PRE" target="_blank" rel="noopener">https://url.cn/5Sj2PRE</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;做为一个 &lt;code&gt;Linux&lt;/code&gt; 用户，一定经常和命令行打交道。而绝大多数 &lt;code&gt;Linux&lt;/code&gt; 发行版默认的 &lt;code&gt;Shell&lt;/code&gt; 都是 &lt;code&gt;Bash&lt;/code&gt;，本文将给大家介绍一些 &lt;code&gt;Bash&lt;/code&gt; 中非常实用的快捷键操作方法。你只要掌握了这些快捷键后，将极大的提高你的命令行操作效率，让你在使用 &lt;code&gt;SHELL&lt;/code&gt; 的时候效率可以快得飞起来。&lt;/p&gt;
&lt;h2 id=&quot;编辑命令&quot;&gt;编辑命令&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + a&lt;/code&gt;：移到命令行首&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + e&lt;/code&gt; ：移到命令行尾&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + f&lt;/code&gt; ：按字符前移（右向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + b&lt;/code&gt; ：按字符后移（左向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + f&lt;/code&gt; ：按单词前移（右向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + b&lt;/code&gt; ：按单词后移（左向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + xx&lt;/code&gt;：在命令行首和光标之间移动&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + u&lt;/code&gt; ：从光标处删除至命令行首&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + k&lt;/code&gt; ：从光标处删除至命令行尾&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + w&lt;/code&gt; ：从光标处删除至字首&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + d&lt;/code&gt; ：从光标处删除至字尾&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + d&lt;/code&gt; ：删除光标处的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + h&lt;/code&gt; ：删除光标前的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + y&lt;/code&gt; ：粘贴至光标后&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + c&lt;/code&gt; ：从光标处更改为首字母大写的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + u&lt;/code&gt; ：从光标处更改为全部大写的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + l&lt;/code&gt; ：从光标处更改为全部小写的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + t&lt;/code&gt; ：交换光标处和之前的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + t&lt;/code&gt; ：交换光标处和之前的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + Backspace&lt;/code&gt;：与 &lt;code&gt;Ctrl + w&lt;/code&gt; 相同，分隔符有些差别。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>推荐一个强大的环境变量管理工具 direnv</title>
    <link href="https://www.hi-linux.com/posts/8174.html"/>
    <id>https://www.hi-linux.com/posts/8174.html</id>
    <published>2020-05-23T01:00:00.000Z</published>
    <updated>2020-05-23T03:54:11.650Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>direnv</code> 是一个强大的环境变量管理工具，可以帮助我们简化环境变量管理。它可以根据当前目录自动加载或卸载环境变量，允许不同项目使用特定的环境变量。</p><p>项目地址：<a href="https://github.com/direnv/direnv/releases" target="_blank" rel="noopener">https://github.com/direnv/direnv/releases</a></p><h2 id="direnv-安装">direnv 安装</h2><p><code>direnv</code> 是基于 Go 语言开发，原生支持多平台，安装起来也是很简单的。</p><ol><li>通过二进制版本安装</li></ol><p>这里以 <code>Linux</code> 平台为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget -c https:&#x2F;&#x2F;github.com&#x2F;direnv&#x2F;direnv&#x2F;releases&#x2F;download&#x2F;v2.20.0&#x2F;direnv.linux-amd64</span><br><span class="line">$ mv direnv.linux-amd64 direnv</span><br><span class="line">$ sudo mv direnv &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p>如果你使用的是其它平台，可在官方项目地址的 Releases 页面自行下载对应操作系统的文件。</p><a id="more"></a><ol start="2"><li>配置以及集成 Shell</li></ol><p>针对不同的 Shell 使用不同的 Hook 方式进行关联，这里我们说说最常用的两种 Bash 和 ZSH。</p><ul><li>Bash</li></ul><p>如果你使用的是 Bash，直接运行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;$(direnv hook bash)&quot;</span><br></pre></td></tr></table></figure><p>如果你想长期使用 <code>direnv</code>，可以将以上命令加入到 <code>~/.bashrc</code> 文件中。</p><ul><li>ZSH</li></ul><p>如果你使用的是 ZSH，直接运行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;$(direnv hook zsh)&quot;</span><br></pre></td></tr></table></figure><p>同样，如果你需要长期使用 <code>direnv</code>，可以将以上命令加入到 <code>~/.zshrc</code> 文件中。</p><p>到这里，安装就算完成了，下面我们看看怎么使用吧。</p><h2 id="direnv-使用">direnv 使用</h2><p>这里我们创建两个目录，分别叫 myenv1 和 myenv2，然后我们测试分别进入不同目录时自动切换环境变量。</p><ol><li>在 myenv1 目录下创建一个 <code>.envrc</code> 文件，并设置了一个环境变量并打印欢迎消息，内容如下：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim .envrc</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">export myenv&#x3D;myenv1</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m#               Welcome to $myenv                #\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br></pre></td></tr></table></figure><ol start="2"><li>同样也在 myenv2 目录下创建一个 <code>.envrc</code> 文件，并设置了一个环境变量并打印欢迎消息，内容如下：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim .envrc</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">export myenv&#x3D;myenv2</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m#               Welcome to $myenv                #\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br></pre></td></tr></table></figure><p>这里需要注意一下，在编辑文件保存退出时会提示下面的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">direnv: error .envrc is blocked. Run &#96;direnv allow&#96; to approve its content.</span><br></pre></td></tr></table></figure><p>此时，我们需要使用下面命令使修改生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ direnv allow</span><br></pre></td></tr></table></figure><ol start="3"><li>下面看看分别进入 myenv1 和 myenv2 目录时环境变量的变化。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 进行 myenv1 目录</span><br><span class="line">$ cd myenv1</span><br><span class="line">direnv: loading .envrc</span><br><span class="line">##################################################</span><br><span class="line">#               Welcome to myenv1                #</span><br><span class="line">##################################################</span><br><span class="line">direnv: export +myenv</span><br><span class="line"></span><br><span class="line">$ env | grep myenv</span><br><span class="line">DIRENV_DIR&#x3D;-&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv1</span><br><span class="line">PWD&#x3D;&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv1</span><br><span class="line">myenv&#x3D;myenv1</span><br><span class="line"></span><br><span class="line"># 进行 myenv2 目录</span><br><span class="line">$ cd myenv2</span><br><span class="line">direnv: loading .envrc</span><br><span class="line">##################################################</span><br><span class="line">#               Welcome to myenv2                #</span><br><span class="line">##################################################</span><br><span class="line">direnv: export +myenv</span><br><span class="line"></span><br><span class="line">$ env | grep myenv</span><br><span class="line">DIRENV_DIR&#x3D;-&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv2</span><br><span class="line">PWD&#x3D;&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv2</span><br><span class="line">myenv&#x3D;myenv2</span><br></pre></td></tr></table></figure><p>至此，<code>direnv</code> 的基本功能就演示完了。但 <code>direnv</code> 的功能远不止这些，更多的高级功能如果你有兴趣可以自行发掘。</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.cnblogs.com/rongfengliang/p/10730008.html" target="_blank" rel="noopener">https://www.cnblogs.com/rongfengliang/p/10730008.html</a></li><li><a href="https://www.jianshu.com/p/efbc215f65ef" target="_blank" rel="noopener">https://www.jianshu.com/p/efbc215f65ef</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;direnv&lt;/code&gt; 是一个强大的环境变量管理工具，可以帮助我们简化环境变量管理。它可以根据当前目录自动加载或卸载环境变量，允许不同项目使用特定的环境变量。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/direnv/direnv/releases&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/direnv/direnv/releases&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;direnv-安装&quot;&gt;direnv 安装&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;direnv&lt;/code&gt; 是基于 Go 语言开发，原生支持多平台，安装起来也是很简单的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过二进制版本安装&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里以 &lt;code&gt;Linux&lt;/code&gt; 平台为例：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ wget -c https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;direnv&amp;#x2F;direnv&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v2.20.0&amp;#x2F;direnv.linux-amd64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ mv direnv.linux-amd64 direnv&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ sudo mv direnv &amp;#x2F;usr&amp;#x2F;local&amp;#x2F;bin&amp;#x2F;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如果你使用的是其它平台，可在官方项目地址的 Releases 页面自行下载对应操作系统的文件。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
</feed>
