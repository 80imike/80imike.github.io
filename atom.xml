<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>奇妙的 Linux 世界</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2021-08-31T01:57:15.938Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>两个 99% 的人都遇到过的 Kubernetes 故障处理技巧</title>
    <link href="https://www.hi-linux.com/posts/19507.html"/>
    <id>https://www.hi-linux.com/posts/19507.html</id>
    <published>2021-08-30T01:00:00.000Z</published>
    <updated>2021-08-31T01:57:15.938Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>随着微服务的不断推进，使用 k8s 集群越来越多，越来越深入，随之而来会遇到一系列的问题，本文向大家介绍实际使用 k8s 遇到的一些问题以及解决方法。</p><h2><span id="问题一修复-k8s-内存泄露问题">问题一：修复 K8S 内存泄露问题</span></h2><h3><span id="问题描述">问题描述</span></h3><ol><li>当 k8s 集群运行日久以后，有的 node 无法再新建 pod，并且出现如下错误，当重启服务器之后，才可以恢复正常使用。查看 pod 状态的时候会出现以下报错。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">applying cgroup … caused: mkdir …no space left on device</span><br></pre></td></tr></table></figure><p>或者在 describe pod 的时候出现 cannot allocate memory。</p><p>这时候你的 k8s 集群可能就存在内存泄露的问题了，当创建的 pod 越多的时候内存会泄露的越多，越快。</p><ol start="2"><li>具体查看是否存在内存泄露</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;memory.kmem.slabinfo</span><br></pre></td></tr></table></figure><p>当出现 cat: /sys/fs/cgroup/memory/kubepods/memory.kmem.slabinfo: Input/output error 则说明不存在内存泄露的情况 如果存在内存泄露会出现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slabinfo - version: 2.1</span><br><span class="line"># name            &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt;</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="解决方案">解决方案</span></h3><ol><li><p>解决方法思路：关闭 runc 和 kubelet 的 kmem，因为升级内核的方案改动较大，此处不采用。</p></li><li><p>kmem 导致内存泄露的原因：</p></li></ol><p>内核对于每个 cgroup 子系统的的条目数是有限制的，限制的大小定义在 kernel/cgroup.c #L139，当正常在 cgroup 创建一个 group 的目录时，条目数就加 1。我们遇到的情况就是因为开启了 kmem accounting 功能，虽然 cgroup 的目录删除了，但是条目没有回收。这样后面就无法创建 65535 个 cgroup 了。也就是说，在当前内核版本下，开启了 kmem accounting 功能，会导致 memory cgroup 的条目泄漏无法回收。</p><h4><span id="21-编译-runc">2.1 编译 runc</span></h4><ul><li>配置 go 语言环境</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;dl.google.com&#x2F;go&#x2F;go1.12.9.linux-amd64.tar.gz</span><br><span class="line">$ tar xf go1.12.9.linux-amd64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line"></span><br><span class="line"># 写入bashrc</span><br><span class="line">$ vim ~&#x2F;.bashrc</span><br><span class="line">$ export GOPATH&#x3D;&quot;&#x2F;data&#x2F;Documents&quot;</span><br><span class="line">$ export GOROOT&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;go&quot;</span><br><span class="line">$ export PATH&#x3D;&quot;$GOROOT&#x2F;bin:$GOPATH&#x2F;bin:$PATH&quot;</span><br><span class="line">$ export GO111MODULE&#x3D;off</span><br><span class="line"></span><br><span class="line"># 验证</span><br><span class="line">$ source ~&#x2F;.bashrc</span><br><span class="line">$ go env</span><br></pre></td></tr></table></figure><ul><li>下载 runc 源码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p &#x2F;data&#x2F;Documents&#x2F;src&#x2F;github.com&#x2F;opencontainers&#x2F;</span><br><span class="line">$ cd &#x2F;data&#x2F;Documents&#x2F;src&#x2F;github.com&#x2F;opencontainers&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;opencontainers&#x2F;runc</span><br><span class="line">$ cd runc&#x2F;</span><br><span class="line">$ git checkout v1.0.0-rc9  # 切到v1.0.0-rc9 tag</span><br></pre></td></tr></table></figure><ul><li>编译</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装编译组件</span><br><span class="line">$ sudo yum install libseccomp-devel</span><br><span class="line">$ make BUILDTAGS&#x3D;&#39;seccomp nokmem&#39;</span><br><span class="line"># 编译完成之后会在当前目录下看到一个runc的可执行文件,等kubelet编译完成之后会将其替换</span><br></pre></td></tr></table></figure><h4><span id="22-编译-kubelet">2.2 编译 kubelet</span></h4><ul><li>下载 kubernetes 源码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p &#x2F;root&#x2F;k8s&#x2F;</span><br><span class="line">$ cd &#x2F;root&#x2F;k8s&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line">$ cd kubernetes&#x2F;</span><br><span class="line">$ git checkout v1.15.3</span><br></pre></td></tr></table></figure><ul><li>制作编译环境的镜像(Dockerfile 如下)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:centos7.3.1611</span><br><span class="line"></span><br><span class="line">ENV GOROOT &#x2F;usr&#x2F;local&#x2F;go</span><br><span class="line">ENV GOPATH &#x2F;usr&#x2F;local&#x2F;gopath</span><br><span class="line">ENV PATH &#x2F;usr&#x2F;local&#x2F;go&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line">RUN yum install rpm-build which where rsync gcc gcc-c++ automake autoconf libtool make -y \</span><br><span class="line">    &amp;&amp; curl -L https:&#x2F;&#x2F;studygolang.com&#x2F;dl&#x2F;golang&#x2F;go1.12.9.linux-amd64.tar.gz | tar zxvf - -C &#x2F;usr&#x2F;local</span><br></pre></td></tr></table></figure><ul><li>在制作好的 go 环境镜像中来进行编译 kubelet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker run  -it --rm   -v &#x2F;root&#x2F;k8s&#x2F;kubernetes:&#x2F;usr&#x2F;local&#x2F;gopath&#x2F;src&#x2F;k8s.io&#x2F;kubernetes   build-k8s:centos-7.3-go-1.12.9-k8s-1.15.3   bash</span><br><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;gopath&#x2F;src&#x2F;k8s.io&#x2F;kubernetes</span><br><span class="line">#编译</span><br><span class="line">$ GO111MODULE&#x3D;off KUBE_GIT_TREE_STATE&#x3D;clean KUBE_GIT_VERSION&#x3D;v1.15.3 make kubelet GOFLAGS&#x3D;&quot;-tags&#x3D;nokmem&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li>替换原有的 runc 和 kubelet</li></ol><ul><li>将原有 runc 和 kubelet 备份</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;kubelet &#x2F;home&#x2F;kubelet</span><br><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;docker-runc &#x2F;home&#x2F;docker-runc</span><br></pre></td></tr></table></figure><ul><li>停止 docker 和 kubelet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop docker</span><br><span class="line">$ systemctl stop kubelet</span><br></pre></td></tr></table></figure><ul><li>将编译好的 runc 和 kubelet 进行替换</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cp kubelet &#x2F;usr&#x2F;bin&#x2F;kubelet</span><br><span class="line">$ cp kubelet &#x2F;usr&#x2F;local&#x2F;bin&#x2F;kubelet</span><br><span class="line">$ cp runc &#x2F;usr&#x2F;bin&#x2F;docker-runc</span><br></pre></td></tr></table></figure><ul><li>检查 kmem 是否关闭前需要将此节点的 pod 杀掉重启或者重启服务器,当结果为 0 时成功</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;burstable&#x2F;memory.kmem.usage_in_bytes</span><br></pre></td></tr></table></figure><ul><li>检查是否还存在内存泄露的情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;memory.kmem.slabinfo</span><br></pre></td></tr></table></figure><h2><span id="问题二k8s-证书过期问题的两种处理方法">问题二：k8s 证书过期问题的两种处理方法</span></h2><h3><span id="前情提要">前情提要</span></h3><p>公司测试环境的 k8s 集群使用已经很长时间了,突然有一天开发联系我说 k8s 集群无法访问，开始以为是测试环境的机器磁盘空间不够了，导致组件异常或者把开发使用的镜像自动清理掉了，但是当登上机器去查验的时候发现不是这个原因。当时觉得也很疑惑。因为开发环境使用人数较少，不应该会出问题，所以就去查验 log 的相关报错信息。</p><h3><span id="问题现象">问题现象</span></h3><p>出现 k8s api 无法调取的现象，使用 kubectl 命令获取资源均返回如下报错:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Unable to connect to the server: x509: certificate has expired or is not yet valid</span><br></pre></td></tr></table></figure><p>经网上搜索之后发现应该是 k8s 集群的证书过期了，使用命令排查证书的过期时间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm alpha certs check-expiration</span><br></pre></td></tr></table></figure><p>发现确实是证书过期了</p><h3><span id="相关介绍以及问题解决">相关介绍以及问题解决</span></h3><p>因为我们是使用 kubeadm 部署的 k8s 集群，所以更新起证书也是比较方便的，默认的证书时间有效期是一年，我们集群的 k8s 版本是 1.15.3 版本是可以使用以下命令来更新证书的，但是一年之后还是会到期，这样就很麻烦，所以我们需要了解一下 k8s 的证书，然后我们来生成一个时间很长的证书，这样我们就可以不用去总更新证书了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm alpha certs renew all --config&#x3D;kubeadm.yaml</span><br><span class="line">$ systemctl restart kubelet</span><br><span class="line">$ kubeadm init phase kubeconfig all --config kubeadm.yaml</span><br><span class="line"># 然后将生成的配置文件替换,重启 kube-apiserver、kube-controller、kube-scheduler、etcd 这4个容器即可</span><br></pre></td></tr></table></figure><p>另外 kubeadm 会在控制面板升级的时候自动更新所有证书，所以使用 kubeadm 搭建的集群最佳的做法是经常升级集群，这样可以确保你的集群保持最新状态并保持合理的安全性。但是对于实际的生产环境我们可能并不会去频繁的升级集群，所以这个时候我们就需要去手动更新证书。</p><p>下面我们通过调用 k8s 的 api 来实现更新一个 10 年的证书</p><p>首先在 <code>/etc/kubernetes/manifests/kube-controller-manager.yaml</code> 文件加入配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    # 设置证书有效期为 10年</span><br><span class="line">    - --experimental-cluster-signing-duration&#x3D;87600h</span><br><span class="line">    - --client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br></pre></td></tr></table></figure><p>修改完成后 kube-controller-manager 会自动重启生效。然后我们需要使用下面的命令为 Kubernetes 证书 API 创建一个证书签名请求。如果您设置例如 cert-manager 等外部签名者，则会自动批准证书签名请求（CSRs）。否者，您必须使用 kubectl certificate 命令手动批准证书。以下 kubeadm 命令输出要批准的证书名称，然后等待批准发生：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 需要将全部 pending 的证书全部批准</span><br><span class="line">$ kubeadm alpha certs renew all --use-api --config kubeadm.yaml &amp;</span><br></pre></td></tr></table></figure><p>我们还不能直接重启控制面板的几个组件，这是因为使用 kubeadm 安装的集群对应的 etcd 默认是使用的 /etc/kubernetes/pki/etcd/ca.crt 这个证书进行前面的，而上面我们用命令 kubectl certificate approve 批准过后的证书是使用的默认的 /etc/kubernetes/pki/ca.crt 证书进行签发的，所以我们需要替换 etcd 中的 ca 机构证书:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 先拷贝静态 Pod 资源清单</span><br><span class="line">$ cp -r &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F; &#x2F;etc&#x2F;kubernetes&#x2F;manifests.bak</span><br><span class="line">$ vi &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;etcd.yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    # 修改为 CA 文件</span><br><span class="line">    - --peer-trusted-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">    - --trusted-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">......</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: &#x2F;var&#x2F;lib&#x2F;etcd</span><br><span class="line">      name: etcd-data</span><br><span class="line">    - mountPath: &#x2F;etc&#x2F;kubernetes&#x2F;pki  # 更改证书目录</span><br><span class="line">      name: etcd-certs</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: &#x2F;etc&#x2F;kubernetes&#x2F;pki  # 将 pki 目录挂载到 etcd 中去</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: &#x2F;var&#x2F;lib&#x2F;etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-data</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>由于 kube-apiserver 要连接 etcd 集群，所以也需要重新修改对应的 etcd ca 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vi &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-apiserver.yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    # 将etcd ca文件修改为默认的ca.crt文件</span><br><span class="line">    - --etcd-cafile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>除此之外还需要替换 requestheader-client-ca-file 文件，默认是 /etc/kubernetes/pki/front-proxy-ca.crt 文件，现在也需要替换成默认的 CA 文件，否则使用聚合 API，比如安装了 metrics-server 后执行 kubectl top 命令就会报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.crt</span><br><span class="line">$ cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.key</span><br></pre></td></tr></table></figure><p>这样我们就得到了一个 10 年证书的 k8s 集群，还可以通过重新编译 kubeadm 来实现一个 10 年证书的，这个我没有尝试，不过在初始化集群的时候也是一个方法。</p><blockquote><p>本文转载自：「 知乎 」，原文：<a href="https://tinyurl.com/h9yet6sd" target="_blank" rel="noopener">https://tinyurl.com/h9yet6sd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着微服务的不断推进，使用 k8s 集群越来越多，越来越深入，随之而来会遇到一系列的问题，本文向大家介绍实际使用 k8s 遇到的一些问题以及解决方法。&lt;/p&gt;
&lt;h2 id=&quot;问题一：修复-K8S-内存泄露问题&quot;&gt;问题一：修复 K8S 内存泄露问题&lt;/h2&gt;
&lt;h3 id=&quot;问题描述&quot;&gt;问题描述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;当 k8s 集群运行日久以后，有的 node 无法再新建 pod，并且出现如下错误，当重启服务器之后，才可以恢复正常使用。查看 pod 状态的时候会出现以下报错。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;applying cgroup … caused: mkdir …no space left on device&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;或者在 describe pod 的时候出现 cannot allocate memory。&lt;/p&gt;
&lt;p&gt;这时候你的 k8s 集群可能就存在内存泄露的问题了，当创建的 pod 越多的时候内存会泄露的越多，越快。&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;具体查看是否存在内存泄露&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ cat &amp;#x2F;sys&amp;#x2F;fs&amp;#x2F;cgroup&amp;#x2F;memory&amp;#x2F;kubepods&amp;#x2F;memory.kmem.slabinfo&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当出现 cat: /sys/fs/cgroup/memory/kubepods/memory.kmem.slabinfo: Input/output error 则说明不存在内存泄露的情况 如果存在内存泄露会出现&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;slabinfo - version: 2.1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# name            &amp;lt;active_objs&amp;gt; &amp;lt;num_objs&amp;gt; &amp;lt;objsize&amp;gt; &amp;lt;objperslab&amp;gt; &amp;lt;pagesperslab&amp;gt; : tunables &amp;lt;limit&amp;gt; &amp;lt;batchcount&amp;gt; &amp;lt;sharedfactor&amp;gt; : slabdata &amp;lt;active_slabs&amp;gt; &amp;lt;num_slabs&amp;gt; &amp;lt;sharedavail&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>服务网格除了 Istio，其实你还可以有其它 8 种选择</title>
    <link href="https://www.hi-linux.com/posts/1629.html"/>
    <id>https://www.hi-linux.com/posts/1629.html</id>
    <published>2021-08-26T01:00:00.000Z</published>
    <updated>2021-08-26T01:32:52.275Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>哪种服务网格最适合你的企业？近年来，Kubernetes 服务网格框架数量增加迅速，使得这成为一个棘手的问题。</p><p>下面将介绍 9 种较受欢迎的用以支撑微服务开发的服务网格框架，每种方案都给出了其适用场景。</p><h2><span id="什么是服务网格">什么是服务网格</span></h2><p>服务网格近年来有很高的话题度，背后的原因是什么？</p><p>微服务已经成为一种灵活快速的开发方式。然而，随着微服务数量成倍数地增长，开发团队开始遇到了部署和扩展性上的问题。</p><p>容器和 Kubernetes 这样的容器编排系统 ，将运行时和服务一起打包进镜像，调度容器到合适的节点，运行容器。这个方案可以解决开发团队遇到的不少问题[1]。然而，在这个操作流程中仍存在短板：如何管理服务间的通信。</p><p>在采用服务网格的场景下，以一种和应用代码解耦的方式，增强了应用间统一的网络通信能力。服务网格扩展了集群的管理能力，增强可观测性、服务发现、负载均衡、IT 运维监控及应用故障恢复等功能。</p><a id="more"></a><h2><span id="服务网格概览">服务网格概览</span></h2><p>服务网格一直有很高的热度。正如 Linkerd 的作者 William Morgan 所提到[2]的：“服务网格本质上无非就是和应用捆绑在一起的用户空间代理。” 此说法相当简洁，他还补充道，“如果你能透过噪音看清本质，服务网格能给你带来实实在在的重要价值。”</p><p>Envoy 是许多服务网格框架的核心组件，是一个通用的开源代理，常被用于 Pod 内的 sidecar 以拦截流量。也有服务网格使用另外的代理方案。</p><p>若论具体服务网格方案的普及程度，Istio 和 Linkerd 获得了更多的认可。也有其它可选项，包括 Consul Connect，Kuma，AWS App Mesh和OpenShift。下文会阐述9种服务网格提供的关键特性。</p><p><strong>Istio</strong></p><p>Istio 是基于 Envoy 构建的一个可扩展的开源服务网格。开发团队可以通过它连接、加密、管控和观察应用服务。Istio 于 2017 年开源，目前 IBM、Google、Lyft 仍在对其进行持续维护升级。Lyft 在 2017 年把 Envoy 捐赠给了 CNCF。</p><p>Istio 花了不少时间去完善增强它的功能特性。Istio 的关键特性包括负载均衡、流量路由、策略创建、可度量性及服务间认证。</p><p>Istio 有两个部分组成：数据平面和控制平面。数据平面负责处理流量管理，通过 Envoy 的 sidecar 代理来实现流量路由和服务间调用。控制平面是主要由开发者用来配置路由规则和观测指标。</p><p>Istio 观测指标是细粒度的属性，其中包含和服务行为相关的特定数据值。下面是个样例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">request.path: xyz&#x2F;abc </span><br><span class="line">request.size: 234 </span><br><span class="line">request.time: 12:34:56.789 04&#x2F;17&#x2F;2017 </span><br><span class="line">source.ip: [192 168 0 1] </span><br><span class="line">destination.service.name: example</span><br></pre></td></tr></table></figure><p>与其他服务网格相比，Istio 胜在其平台成熟度以及通过其 Dashbaord</p><p>着重突出的服务行为观测和业务管理功能，然而也因为这些高级特性和复杂的配置流程，Istio 可能并不如其它一些替代方案那样容易上手。</p><p><strong>Linkerd</strong></p><p>按照官网的说法，Linkerd 是一个轻量级、安全优先的 Kubernetes 服务网格。它的创建流程快到让人难以置信（据称在 Kubernetes 安装只需要 60 秒），这是大多数开发者喜闻乐见的。Linkerd 并没有采用基于 Envoy 的构建方案。而是使用了一个基于 Rust 的高性能代理 linkerd2-proxy，这个代理是专门为 Linkerd 服务网格编写的。</p><p>Linkerd 由社区驱动，是 100% 的 Apache 许可开源项目。它还是 CNCF 孵化项目。Linkerd 始于 2016 年，维护者也花了不少时间去解决其中的缺陷。</p><p>使用 Linkerd 服务网格，应用服务可以增强其可靠性、可观测性及其在 Kubernetes 上部署的安全性。举个例子，可观测性的增强可以帮助用户解决服务间的延迟问题。使用 Linkerd 不要求用户做很多代码调整或是花费大量时间写 YAML 配置文件。可靠的产品特性和正向的开发者使用回馈，使得 Linkerd 成为服务网格中一个强有力的竞争者。</p><p><strong>Consul Connect</strong></p><p>Consul Connect 是来自 HashiCorp 的服务网格，专注于路由和分段，通过应用级的 sidecar 代理来提供服务间的网络特性。Consult Connect 侧重于应用安全，提供应用间的双向 TLS 连接以实现授权和加密。</p><p>Consult Connect 独特的一点是提供了两种代理模式。一种是它内建的代理，同时它还支持 Envoy 方案。Connect 强调可观测性，集成了例如 Prometheus 这样的工具来监控来自 sidecar 代理的数据。Consul Connect 可以灵活地满足开发者使用需求。比如，它提供了多种方式注册服务：可以从编排系统注册，可以通过配置文件，通过 API 调用，或是命令行工具。</p><p><strong>Kuma</strong></p><p>Kuma 来源于 Kong，自称是一个非常好用的服务网格替代方案。Kuma 是一个基于 Envoy 的平台无关的控制平面。Kuma 提供了安全、观测、路由等网络特性，同时增强了服务间的连通性。Kuma 同时支持 Kubernetes 和虚拟机。</p><p>Kuma 让人感兴趣的一点是，它的企业版可以通过一个统一控制面板来运维管理多个互相隔离独立的服务网格。这项能力可以满足安全要求高的使用场景。既符合隔离的要求，又实现集中控制。</p><p>Kuma 也是相对容易安装的一个方案。因为它预先内置了不少策略。这些策略覆盖了常见需求，例如路由，双向 TLS，故障注入，流量控制，加密等场景。</p><p>Kuma 原生兼容 Kong，对于那些已经采用 Kong API 管理的企业组织，Kuma 是个非常自然而然的候选方案。</p><p><strong>Maesh</strong></p><p>Maesh 是来自 Containous 的容器原生的服务网格，标榜自己是比市场其它服务网格更轻量级更易用的方案。和很多基于 Envoy 构建的服务网格不同，Maesh 采用了 Traefik， 一个开源的反向代理和负载均衡器。</p><p>Maesh 并没有采用 sidecar 的方式进行代理，而是在每个节点部署一个代理终端。这样做的好处是不需要去编辑 Kubernetes 对象，同时可以让用户有选择性地修改流量，Maesh 相比其他服务网格侵入性更低。Maesh 支持的配置方式：在用户服务对象上添加注解或是在服务网格对象上添加注解来实现配置。</p><p>实际上，SMI 是一种新的服务网格规范格式，对 SMI 的支持 Maesh 独有的一大亮点。随着 SMI 在业界逐渐被采用，可以提高可扩展性和减缓供应商绑定的担忧。</p><p>Maesh 要求 Kubernetes 1.11 以上的版本，同时集群里安装了 CoreDNS/KubeDNS。这篇安装指南[3]演示了如何通过 Helm v3 快速安装 Maesh。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add maesh https:&#x2F;&#x2F;containous.github.io&#x2F;maesh&#x2F;charts </span><br><span class="line">$ helm repo update </span><br><span class="line">$ helm install maesh maesh&#x2F;maesh</span><br></pre></td></tr></table></figure><p><strong>ServiceComb-mesher</strong></p><p>Apache 软件基金会形容旗下的 ServiceComb-mesher “是一款用 Go 语言实现的高性能服务网格”。Mesher 基于一个非常受欢迎的 Go 语言微服务开发框架 Go Chassis[4] 来设计实现。因此，它沿袭了 Go Chassis 的一些特性如服务发现、负载均衡、错误容忍、路由管理和分布式追踪等特性。</p><p>Mesher 采用了 sidecar 方式；每个服务有一个 Mesher sidecar 代理。开发人员通过 Admin API 和 Mesher 交互，查看运行时信息。Mesher 同时支持 HTTP 和 gRPC，可快速移植到不同的基础设施环境，包括 Docker、Kubernetes、虚拟机和裸金属机环境。</p><p><strong>Network Service Mesh（NSM）</strong></p><p>Network Service Mesh（NSM）是一款专门为 telcos 和 ISPs 设计的服务网格。它提供了一层级用以增强服务在 Kubernetes 的低层级网络能力。NSM 目前是 CNCF 的沙箱项目。</p><p>根据 NSM 的文档说明，“经常接触 L2/L3 层的网络运维人员抱怨说，适合他们的下一代架构的容器网络解决方案几乎没有”。</p><p>因此，NSM 在设计时就考虑到一些不同使用场景，尤其是网络协议不同和网络配置混杂的场景。这使得 NSM 对某些特殊场景具备相当吸引力，例如边缘计算、5G 网络和 IOT 设备等场景。NSM 使用简单直接的 API 接口去实现容器和外部端点的之间的通信。</p><p>和其他服务网格相比，NSM 工作在另一个不同的网络层。VMware 形容 NSM“专注于连接”。GitHub 的文档[5]演示了 NSM 是如何与 Envoy协同工作的。</p><p><strong>AWS App Mesh</strong></p><p>AWS APP Mesh 为开发者提供了“适用于不同服务的应用层的网络”。它接管了服务的所有网络流量，使用开源的 Envoy 代理去控制容器的流量出入。AWS App Mesh 支持 HTTP/2 gRPC。</p><p>AWS App Mesh 对于那些已经将容器平台深度绑定 AWS 的公司而言，会是相当不错的服务网格方案。AWS 平台包括 AWS Fargate，Amazon Elastic Container Service，Amazon Elastic Kubernetes Service（EKS），Amazon Elastic Compute Cloud（EC2），Kubernetes on EC2，包括 AWS App Mesh 不需要付额外费用。</p><p>AWS App Mesh 和 AWS 生态内的监控工具无缝兼容。这些工具包括 CloudWatch 和 AWS X-Ray，以及一些来自第三方供应商的工具。因为 AWS 计算服务支持 AWS Outposts，AWS App Mesh 可以和混合云和已经部署的应用良好兼容。</p><p>AWS App Mesh 的缺点可能是使得开发者深度绑定了单一供应商方案，相对闭源，可扩展性缺失。</p><p><strong>OpenShift Service Mesh by Red Hat</strong></p><p>OpenShift 是来自红帽的一款帮助用户“连接、管理、观测微服务应用”的容器管理平台。OpenShift 预装了不少提升企业能力的组件，也被形容为企业级的混合云 Kubernetes 平台。</p><p>OpenShift Service Mesh 基于开源的 Istio 构建，具备 Isito 的控制平面和数据平面等特性。OpenShift 利用两款开源工具来增强 Isito 的追踪能力和可观测性。OpenShift 使用 Jaeger 实现分布式追踪，更好地跟踪请求是如何在服务间调用处理的。</p><p>另一方面，OpenShift 使用了 Kiali 来增强微服务配置、流量监控、跟踪分析等方面的可观测性。</p><h2><span id="如何选择">如何选择</span></h2><p>正如文中所提到的，可供选择的服务网格方案[6]有很多，同时还有新的方案在涌现。当然，每一种方案在技术实现上都略有不同。选择一款合适的服务网格，主要考虑的因素包括，你能接受它带来多大的侵入性，它的安全性如何，以及平台成熟度等。</p><p>以下几点可以帮助 DevOps 团队选择一款适合他们场景的服务网格：</p><ul><li>是否依赖Envoy。Envoy 有一个活跃的社区生态。开源，同时是许多服务网格的底座。Envoy 具备的丰富特性使得其成为一个很难绕过的因素。</li><li>具体使用场景。服务网格为微服务而生。如果你的应用是一个单体的庞然大物，那你在服务网格上的投入可能达不到预期的收益。如果不是所有应用都部署在 Kubernetes，则应该优先考虑平台无关的方案。</li><li>现有容器管理平台。有些企业已经使用了特定供应商的生态来解决容器编排问题，例如 AWS 的 EKS，红帽的 OpenShift，Consul。沿袭原有的生态，可以继承并拓展原有的特性。而这些可能是开源方案所不能提供的。</li><li>所在行业。许多服务网格不是为特定行业专门设计的。Kuma 统一管理多个隔离服务网格的能力可能更适用于收到高度管制的金融行业。底层网络 telcos 和 ISPs 则更应该考虑 Network Service Mesh。</li><li>对可视化的要求。可观测性是服务网格的核心能力之一。考虑进一步定制和更深度能力的团队应该优先考虑 Istio 或 Consul。</li><li>是否遵循开发标准。遵循开发标准使得你的平台更具备前瞻性和可扩展性。这使得企业会倾向于采用支持 SMI 的方案，Maesh 或其他基金会孵化的项目如 Linkerd。</li><li>是否重视用户体验。考虑运维人员的易用性是评判新工具的关键指标。这方 Linkerd 似乎在开发者中间口碑不错。</li><li>团队准备。评估你的团队所具备的资源和技术储备，在技术选型时决定你们适合用基于 Envoy 的 Istio，或是供应商抽象封装的方案，例如 OpenShift。</li></ul><p>这些考虑因素没有覆盖到全部场景。此处仅是抛砖引玉，引起读者的思考。希望读完上面所列的服务网格清单，和相关的决策因素之后，你们的团队能找到新的方法去改善微服务应用的网络特性。</p><p>相关链接：</p><ol><li><a href="https://techbeacon.com/app-dev-testing/3-reasons-why-you-should-always-run-microservices-apps-containers" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/3-reasons-why-you-should-always-run-microservices-apps-containers</a></li><li><a href="https://buoyant.io/service-mesh-manifesto/" target="_blank" rel="noopener">https://buoyant.io/service-mesh-manifesto/</a></li><li><a href="https://docs.mae.sh/quickstart/" target="_blank" rel="noopener">https://docs.mae.sh/quickstart/</a></li><li><a href="https://github.com/go-chassis/go-chassis" target="_blank" rel="noopener">https://github.com/go-chassis/go-chassis</a></li><li><a href="https://github.com/networkservicemesh/examples/tree/master/examples/envoy_interceptor" target="_blank" rel="noopener">https://github.com/networkservicemesh/examples/tree/master/examples/envoy_interceptor</a></li><li><a href="https://techbeacon.com/app-dev-testing/make-your-app-architecture-cloud-native-service-mesh" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/make-your-app-architecture-cloud-native-service-mesh</a></li></ol><p>原文链接：<a href="https://techbeacon.com/app-dev-testing/9-open-source-service-meshes-compared" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/9-open-source-service-meshes-compared</a></p><blockquote><p>本文转载自：「  分布式实验室 」，原文：<a href="https://tinyurl.com/4xsy53bd" target="_blank" rel="noopener">https://tinyurl.com/4xsy53bd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;哪种服务网格最适合你的企业？近年来，Kubernetes 服务网格框架数量增加迅速，使得这成为一个棘手的问题。&lt;/p&gt;
&lt;p&gt;下面将介绍 9 种较受欢迎的用以支撑微服务开发的服务网格框架，每种方案都给出了其适用场景。&lt;/p&gt;
&lt;h2 id=&quot;什么是服务网格&quot;&gt;什么是服务网格&lt;/h2&gt;
&lt;p&gt;服务网格近年来有很高的话题度，背后的原因是什么？&lt;/p&gt;
&lt;p&gt;微服务已经成为一种灵活快速的开发方式。然而，随着微服务数量成倍数地增长，开发团队开始遇到了部署和扩展性上的问题。&lt;/p&gt;
&lt;p&gt;容器和 Kubernetes 这样的容器编排系统 ，将运行时和服务一起打包进镜像，调度容器到合适的节点，运行容器。这个方案可以解决开发团队遇到的不少问题[1]。然而，在这个操作流程中仍存在短板：如何管理服务间的通信。&lt;/p&gt;
&lt;p&gt;在采用服务网格的场景下，以一种和应用代码解耦的方式，增强了应用间统一的网络通信能力。服务网格扩展了集群的管理能力，增强可观测性、服务发现、负载均衡、IT 运维监控及应用故障恢复等功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Istio" scheme="https://www.hi-linux.com/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>超给力，一款简单又实用的免费 GitHub 加速神器</title>
    <link href="https://www.hi-linux.com/posts/8698.html"/>
    <id>https://www.hi-linux.com/posts/8698.html</id>
    <published>2021-08-25T01:00:00.000Z</published>
    <updated>2021-08-25T02:41:30.820Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天给大家推荐一个堪称 GitHub 加速神器的开源项目。</p><p>这个开源项目就是：<strong>FastGitHub</strong>，它主要解决 GitHub 打不开、用户头像无法加载、releases 无法上传下载、git-clone、git-pull、git-push 失败等问题。</p><p>该项目的好处就是专门针对 GitHub 访问速度慢的问题，具有合法性，可靠性，稳定性。最重要的是它是免费的，而且不需要外网服务器资源。</p><h2><span id="fastgithub-加速原理">FastGitHub 加速原理</span></h2><ul><li>修改本机的 <code>DNS</code> 服务指向 FastGithub 自身</li><li>解析匹配的域名为 <code>FastGithub</code> 自身的 IP</li><li>请求安全 <code>DNS</code> 服务 (<code>dnscrypt-proxy</code>) 获取相应域名的 <code>IP</code></li><li>选择最优的 <code>IP</code> 进行 <code>SSH</code> 或 <code>HTTPS</code> 反向代理</li></ul><blockquote><ul><li><p>开源项目地址：<a href="https://github.com/dotnetcore/FastGithub" target="_blank" rel="noopener">https://github.com/dotnetcore/FastGithub</a></p></li><li><p>开源项目作者：.NET Core Community</p></li></ul></blockquote><h2><span id="使用方法">使用方法</span></h2><h3><span id="1-安装-fastgithub">1. 安装 FastGithub</span></h3><h4><span id="本地环境安装">本地环境安装</span></h4><p>运行 <code>FastGithub</code> 程序，本机的网络适配器的 <code>DNS</code> 会自动变成 127.0.0.1。</p><p>如果网络适配器的 <code>DNS</code> 没有变成 <code>127.0.0.1</code>，请手工修改网络适配器的 <code>DNS</code>。</p><blockquote><p>注： Linux 和 macOS 系统需要手动修改。</p></blockquote><h4><span id="局域网服务器安装推荐">局域网服务器安装(推荐)</span></h4><ul><li>在 Linux 服务器上运行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ yum install libicu # 安装依赖包</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;dotnetcore&#x2F;FastGithub&#x2F;releases&#x2F;download&#x2F;1.1.8&#x2F;FastGithub_linux-x64.zip</span><br><span class="line">$ unzip FastGithub_linux-x64.zip</span><br><span class="line">$ cd  FastGithub_linux-x64</span><br><span class="line">$ .&#x2F;FastGithub</span><br></pre></td></tr></table></figure><ul><li>在 Windows 服务器上运行</li></ul><p>以管理员身份运行 <code>cmd</code>，键入如下命令，其中 <code>D:\Softs</code> 为软件实际目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\Softs\FastGithub.exe start &#x2F;&#x2F; 以 Windows 服务安装并启动</span><br><span class="line">D:\Softs\FastGithub.exe stop &#x2F;&#x2F; 卸载并删除 Windows 服务</span><br></pre></td></tr></table></figure><h3><span id="2-使用-fastgithub">2. 使用 FastGithub</span></h3><p>FastGithub 安装完成后， 通过浏览器访问 <code>http://127.0.0.1</code> 或 <code>https://127.0.0.1</code> 以及所在机器的其它 IP 进入 FastGithub 的 Dashboard。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210824134508736-2021-08-24-HDI4u9.png" alt></p><p>接下来，根据实际情况按 <code>Dashboard</code> 页面的提示进行简单设置后，便可高速访问 Github。</p><ol><li>手工修改你电脑的 <code>DNS</code> 服务器的 IP 为 <code>127.0.0.1</code> 或局域网服务器的 <code>IP</code>。</li><li>手工下载和安装 <code>FastGithub.cer</code> 到受信任的根证书颁发机构</li></ol><p><img src="https://img.hi-linux.com/staticfile/image-20210824135233117-2021-08-24-0EnZhv.png" alt></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;p&gt;今天给大家推荐一个堪称 GitHub 加速神器的开源项目。&lt;/p&gt;
&lt;p&gt;这个开源项目就是：&lt;strong&gt;FastGitHub&lt;/strong&gt;，它主要解决 GitHub 打不开、用户头像无法加载、releases
        
      
    
    </summary>
    
    
      <category term="GitHub" scheme="https://www.hi-linux.com/categories/GitHub/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>6 张图带你搞懂 CI/CD 流水线</title>
    <link href="https://www.hi-linux.com/posts/22785.html"/>
    <id>https://www.hi-linux.com/posts/22785.html</id>
    <published>2021-08-20T01:00:00.000Z</published>
    <updated>2021-08-20T08:11:43.614Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>在CI/CD和DevOps领域中，持续交付和持续部署是一个老生常谈的话题。持续集成这个术语最早是在1994年由Grady Booch提出。微服务提出者Martin Flower在2014年发表的论文《Microservice》中也对软件开发持续集成提供了可参考原则。持续集成是借助工具对软件项目进行持续的自动化的编译打包构建测试发布，来检查软件交付质量的一种行为。而持续部署是基于持续交付的优势自动将经过测试的代码推入生产环境的过程。下文从细节描述了持续集成和持续部署各阶段的关键步骤，以下是原文。</p></blockquote><p>本文将探讨CI（持续集成）/CD（持续部署）流程中的各个阶段；以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。</p><p>CI/CD流水线工作流包括CI/CD流程开始时所有阶段等一系列步骤，负责创建自动、连贯的软件交付模型。</p><p>通过CI/CD流水线，软件研发可以实现从代码签入、测试、构建和部署直至生产阶段都在流水线中向前推进。此概念之所以高大上，是因为一旦实施了流水线，就可以将其部分或全部自动化，从而加快开发流程并减少错误。换句话说，CI/CD流水线使企业可以更轻松地应对软件的自动、快速、持续交付。</p><p>DevOps工程师经常会将CI/CD各阶段的和其CI/CD流水线混淆。尽管不同的工具可以将每个复杂阶段自动化完成分阶段的CI/CD，但是整体CI/CD软件链仍然可能由于不可避免的人工干预而中断。因此我们首先需要了解CI/CD流程中的各个阶段，以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。</p><a id="more"></a><h2><span id="cicd-阶段理解参与者-流程-技术">CI/CD 阶段：理解参与者、流程、技术</span></h2><p>企业应用程序开发参与者通常由开发人员，测试人员/QA工程师，运维工程师以及SRE（站点可靠性工程师）或IT运营团队组成。他们紧密合作，目标是高质量软件交付。CI/CD是两个独立过程的组合：持续集成和持续部署。下面列出了每个步骤中的主要步骤：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210616154923127-2021-06-16-Fyhe7J.png" alt></p><h2><span id="持续集成">持续集成</span></h2><p>持续集成（CI）是构建软件和完成初始测试的过程。持续部署（CD）是将代码与基础设施相结合的过程，确保完成所有测试并遵循策略，然后将代码部署到预期环境中。当然，许多公司也有自己特有流程，但主要步骤如下。</p><p><strong>CI：代码提交阶段</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616154929212-2021-06-16-5XICGL.png" alt></p><ul><li><p>参与者：开发工程师，数据库管理员（DBA），基础架构团队</p></li><li><p>技术：GitHub，GitLab，SVM，BitBucket</p></li><li><p>流程：代码提交阶段也称为版本控制。提交是将开发人员编写的最新代码变更发送到代码存储库的操作。开发人员编写的代码的每个版本都被无限期地存储。在与合作者讨论和审查变更之后，开发人员将编写代码，并在软件需求、特性增强、bug修复或变更请求完成后提交。管理编辑和提交变更的存储库称为源代码管理工具（配置管理工具）。在开发人员提交代码（代码推送请求）后，代码更改被合并到主线代码分支中，这些主线代码分支存储在GitHub这样的中央存储库中。</p></li></ul><p><strong>CI：静态代码检查阶段</strong></p><ul><li><p>参与者：开发工程师，数据库管理员（DBA），基础架构团队</p></li><li><p>技术：GitHub，GitLab，SVM，BitBucket</p></li><li><p>流程：开发人员编写代码并将其推送到存储库后，系统将自动触发以启动下一个代码分析过程。开发过程中存在这种情况：提交的代码可以构建成功，但在部署期间构建失败。无论从机器还是人力资源的利用率而言，这都是一个缓慢而昂贵的过程。因此必须检查代码中的静态策略。SAST（静态应用程序安全性测试）：SAST是一种白盒测试方法，可以使用SonarQube，Veracode，Appscan等SAST工具从内部检查代码，以发现软件缺陷，漏洞和弱点（例如SQL注入等）。这是一个快速检查过程，其中检查代码是否存在语法错误。尽管此阶段缺少检查运行时错误的功能，但该功能将在以后的阶段中执行。</p></li></ul><p>将额外的策略检查加入自动化流水线中可以显著减少流程中稍后发现的错误数量。</p><p><strong>CI：构建</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412585-2021-06-16-Ji7Bgv.png" alt></p><ul><li><p>参与者：开发工程师</p></li><li><p>技术：Jenkins，Bamboo CI，Circle CI，Travis CI，Maven，Azure DevOps</p></li><li><p>流程：持续集成过程的目标是提交的代码持续构建为二进制文件或构建产物。通过持续集成来检查添加的新模块是否与现有模块兼容，不仅有助于更快地发现bug，还有助于减少验证新代码更改的时间。构建工具可以根据几乎所有编程语言的源代码创建可执行文件或包（.exe，.dll，.jar等）。在构建过程中，还可以生成SQL脚本，配合基础设施配置文件一起进行测试。简而言之，构建阶段就是编译应用程序的阶段。Artifactory存储、构建验证测试和单元测试也可以作为构建过程的一部分。</p></li></ul><p>构建验证测试（BVT）/冒烟测试/单元测试：</p><p>创建构建后立即执行冒烟测试。BVT将检查所有模块是否正确集成，以及程序的关键功能是否正常运行。这样做的目的是拒绝严重损坏的应用程序，以使QA团队不会在安装和测试软件应用程序步骤浪费时间。</p><p>在完成这些检查后，将向流水线中执行UT（单元测试），以进一步减少生产中的故障。单元测试可验证开发人员编写的单个单元或组件是否按预期执行。</p><p>构建产物存储：</p><p>一旦构建就绪，程序包就会存储在称为Artifactory或Repository工具的中央数据库。随着每天构建量的增加，跟踪所有构建产物也会变得愈加困难。因此，一旦生成并验证了构建产物，就将其发送到存储库进行存储管理。诸如Jfrog Artifactory之类的存储库工具可用于存储诸如.rar，.war，.exe，Msi等之类的二进制文件。测试人员可以从此处手动进行选择，并在测试环境中部署构建产物以进行测试。</p><p><strong>CI：测试阶段</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412605-2021-06-16-52oF9C.png" alt></p><ul><li><p>参与者：测试人员、QA</p></li><li><p>技术：Selenium，Appium，Jmeter，SOAP UI，Tarantula</p></li><li><p>过程：发布构建过程后的一系列自动测试将验证代码的准确性。此阶段可帮助避免生产中的错误。根据构建的大小，此检查可能持续数秒至数小时。对于由多个团队提交和构建代码的大型组织，这些检查在并行环境中运行，以节省宝贵的时间并尽早将错误通知开发人员。</p></li></ul><p>测试人员（或称为QA工程师）基于用户描述的测试用例和场景设置自动化测试用例。他们执行回归分析、压力测试来检查与预期输出的偏差。测试中涉及的活动有完整性测试、集成测试、压力测试。这是一个高层次测试方法。在这个阶段，可以发现开发人员忽视的某些代码问题。</p><p>集成测试：</p><p>集成测试是使用Cucumber、Selenium等工具执行的，在这些工具中，单个应用程序模块被组合起来并作为一组进行测试，同时评估其是否符合指定的功能需求。在集成测试之后，需要有人批准该组中的更新集应该移到下一个阶段，这通常是性能测试。这个验证过程可能很麻烦，但它是整个过程的一个重要部分。验证这个过程业界有很多优秀的方案。</p><p>性能和压力测试：</p><p>Selenium、JMeter等自动化测试工具也可执行性能和压力测试，以检查应用程序在面对高负载时是否稳定和性能良好。该测试流程通常不会在每个更新提交上运行，因为完整的压力测试是长期运行的。当发布主要的新功能时，将对多个更新进行分组，并完成完整的性能测试。在单个更新被转移到下一阶段的情况下，流水线可能将金丝雀测试加入作为可选。</p><h2><span id="持续部署bake和部署">持续部署：Bake和部署</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412635-2021-06-16-lr0ZjG.png" alt></p><ul><li><p>参与者：基础架构工程师，SRE，运维工程师</p></li><li><p>技术：Spinnaker，Argo CD，Tekton CD</p></li><li><p>过程：在测试阶段完成之后，可以部署到服务器的标准代码准备就绪。在部署到生产中之前，它们将被部署到产品团队内部使用的测试环境或beta环境。在将构建移至这些环境之前，构建必须经过Bake和Deploy的子阶段。这两个阶段都是Spinnaker所支持存在的。</p></li></ul><p><strong>CD：Bake</strong></p><p>Baking是指在生产时使用当前配置从源代码创建不可变的镜像实例。这些配置可能是数据库更改和其他基础结构更新之类的事情。Spinnaker可以触发Jenkins执行此任务，并且某些组织更喜欢使用Packer。</p><p><strong>CD：部署</strong></p><p>Spinnaker自动将已bake的镜像发送到部署阶段。这是将服务器组设置为部署到集群的位置。与上述测试过程类似，在部署阶段将执行功能相同的过程。首先将部署移至测试阶段，然后最终移至生产环境，以进行批准和检查。这个处理过程可以由Spinnaker等工具支持。</p><p><strong>CD：验证</strong></p><p>这也是团队优化整个CI/CD流程的关键位置。因为现在已经进行了如此多的测试，所以失败很少见。但是，此时必须尽快解决所有故障，以最大程度地减少对最终客户的影响。团队也应该考虑使流程的这一部分自动化。</p><p>使用蓝绿部署、金丝雀分析、滚动更新等策略部署到产品。在部署阶段，将监视正在运行的应用程序以验证当前部署是否正确或是否需要回滚。</p><p><strong>CD：监控</strong></p><ul><li><p>参与者：站点可靠性工程师（SRE）、运营团队</p></li><li><p>技术：Zabbix、Nagios、Prometheus、Elastic Search、Splunk、Appdynamics、Tivoli</p></li><li><p>过程：为了使软件发行版具有故障安全性和健壮性，在生产环境中跟踪发行版的运行状况至关重要。应用程序监视工具将跟踪性能指标，例如CPU利用率和发行版延迟。日志分析器将扫描由底层中间件和操作系统产生的大量日志，以识别行为并跟踪问题的根源。如果生产中出现任何问题，将通知利益相关者以确保生产环境的安全性和可靠性。此外，监视阶段可帮助组织收集有关其新软件更改如何为收入贡献的情报，帮助基础设施团队跟踪系统行为趋势并进行容量规划。</p></li></ul><h2><span id="持续交付cd反馈和协作工具">持续交付（CD）：反馈和协作工具</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210616154942237-2021-06-16-o4hfIX.png" alt></p><ul><li><p>参与者：站点可靠性工程师（SRE）、运营和维护团队。</p></li><li><p>技术：JIRA、ServiceNow、Slack、电子邮件、Hipchat。</p></li><li><p>过程：DevOps团队的目标是更快地持续发布，然后不断减少错误和性能问题。这是通过不时地通过发送电子邮件向开发人员、项目经理提供有关新版本的质量和性能的反馈。通常情况下，反馈系统是整个软件交付过程的一部分。因此，交付中的任何更改都会频繁地录入系统，以便交付团队可以对它采取行动。</p></li></ul><h2><span id="总结">总结</span></h2><p>企业必须评估一个整体的持续交付解决方案，该解决方案可以自动化或促进上述这些阶段的自动化。</p><p>原文链接：<a href="https://www.opsmx.com/blog/what-is-a-ci-cd-pipeline/" target="_blank" rel="noopener">https://www.opsmx.com/blog/what-is-a-ci-cd-pipeline/</a></p><blockquote><p>本文转载自：「 分布式实验室 」，原文：<a href="https://tinyurl.com/5dtbbk3x" target="_blank" rel="noopener">https://tinyurl.com/5dtbbk3x</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在CI/CD和DevOps领域中，持续交付和持续部署是一个老生常谈的话题。持续集成这个术语最早是在1994年由Grady Booch提出。微服务提出者Martin Flower在2014年发表的论文《Microservice》中也对软件开发持续集成提供了可参考原则。持续集成是借助工具对软件项目进行持续的自动化的编译打包构建测试发布，来检查软件交付质量的一种行为。而持续部署是基于持续交付的优势自动将经过测试的代码推入生产环境的过程。下文从细节描述了持续集成和持续部署各阶段的关键步骤，以下是原文。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文将探讨CI（持续集成）/CD（持续部署）流程中的各个阶段；以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。&lt;/p&gt;
&lt;p&gt;CI/CD流水线工作流包括CI/CD流程开始时所有阶段等一系列步骤，负责创建自动、连贯的软件交付模型。&lt;/p&gt;
&lt;p&gt;通过CI/CD流水线，软件研发可以实现从代码签入、测试、构建和部署直至生产阶段都在流水线中向前推进。此概念之所以高大上，是因为一旦实施了流水线，就可以将其部分或全部自动化，从而加快开发流程并减少错误。换句话说，CI/CD流水线使企业可以更轻松地应对软件的自动、快速、持续交付。&lt;/p&gt;
&lt;p&gt;DevOps工程师经常会将CI/CD各阶段的和其CI/CD流水线混淆。尽管不同的工具可以将每个复杂阶段自动化完成分阶段的CI/CD，但是整体CI/CD软件链仍然可能由于不可避免的人工干预而中断。因此我们首先需要了解CI/CD流程中的各个阶段，以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevOps" scheme="https://www.hi-linux.com/categories/DevOps/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="DevOps" scheme="https://www.hi-linux.com/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>如何有效的在 60 秒内进行 Linux 服务器性能故障分析</title>
    <link href="https://www.hi-linux.com/posts/21098.html"/>
    <id>https://www.hi-linux.com/posts/21098.html</id>
    <published>2021-08-18T01:00:00.000Z</published>
    <updated>2021-08-18T02:23:32.294Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>感谢前辈，光荣属于前辈。</p></blockquote><p>掌握一些性能优化工具和方法，这就需要在工作中不断地积累；计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。</p><p>虽然监控工具可以帮助我们解决大多数问题，但我们有时需要登录实例并运行一些标准的 Linux 性能工具。</p><blockquote><p>来看 Netflix 性能工程团队的这篇博文：<a href="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55" target="_blank" rel="noopener">https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55</a></p></blockquote><p>看他们通过十条命令在一分钟内对机器性能问题进行诊断。在 60 秒内，您可以通过运行以下十个命令，对系统资源使用情况和正在运行的进程有一个高层次的了解。寻找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。饱和是指资源的负载超出其处理能力的情况，可以作为请求队列的长度或等待时间来公开。</p><a id="more"></a><p>当我们把 Linux 操作系统所有的关键一级计数器找完之后，就会得到这样一张图：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210722112925483-2021-07-22-hI8hui.jpg" alt></p><p>这些命令的输出，有助于快速定位性能瓶颈。主要检查出图中标红的计数器，所有资源（CPU、内存、磁盘 IO 等）的利用率（utilization）、饱和度（saturation）和错误（error）度量，也就是 Brendan Gregg 提出的 USE 方法。</p><blockquote><p>The USE Method: <a href="https://www.brendangregg.com/usemethod.html" target="_blank" rel="noopener">https://www.brendangregg.com/usemethod.html</a></p></blockquote><p><img src="https://img.hi-linux.com/staticfile/640-20210722112925497-2021-07-22-I7bgnm.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">uptime</span><br><span class="line">dmesg | tail</span><br><span class="line">vmstat 1</span><br><span class="line">mpstat -P ALL 1</span><br><span class="line">pidstat 1</span><br><span class="line">iostat -xz 1</span><br><span class="line">free -m</span><br><span class="line">sar -n DEV 1</span><br><span class="line">sar -n TCP,ETCP 1</span><br><span class="line">top</span><br></pre></td></tr></table></figure><p>下面我们来逐一介绍下这些命令，有关这些命令更多的参数和说明，请参照命令的手册。</p><h2><span id="uptime">uptime</span></h2><p>这个命令可以快速查看机器的负载情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ uptime</span><br><span class="line">23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02</span><br></pre></td></tr></table></figure><ul><li><p>在 Linux 系统中，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的。这些数据可以让我们对系统资源使用有一个宏观的了解。</p></li><li><p>命令的输出分别表示 1 分钟、5 分钟、15 分钟的平均负载情况。通过这三个数据，可以了解服务器负载是在趋于紧张还是区域缓解。如果 1 分钟平均负载很高，而 15 分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查 CPU 资源都消耗在了哪里。反之，如果 15 分钟平均负载很高，1 分钟平均负载较低，则有可能是 CPU 资源紧张时刻已经过去。</p></li><li><p>上面例子中的输出，可以看见最近 1 分钟的平均负载非常高，且远高于最近 15 分钟负载，因此我们需要继续排查当前系统中有什么进程消耗了大量的资源。可以通过下文将会介绍的 vmstat、mpstat 等命令进一步排查。</p></li></ul><h2><span id="dmesg-tail">dmesg | tail</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg | tail</span><br><span class="line">[1880957.563150] perl invoked oom-killer: gfp_mask&#x3D;0x280da, order&#x3D;0, oom_score_adj&#x3D;0</span><br><span class="line">[...]</span><br><span class="line">[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child</span><br><span class="line">[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB</span><br><span class="line">[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.</span><br></pre></td></tr></table></figure><p>这将查看最近 10 条系统消息（如果有）。查找可能导致性能问题的错误。上面的示例包括 oom-killer 和 TCP 丢弃请求。不要错过这一步！dmesg 总是值得检查。这些日志可以帮助排查性能问题。</p><h2><span id="vmstat">vmstat</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vmstat 1</span><br><span class="line">procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line">r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line">34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0</span><br><span class="line">32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0</span><br><span class="line">32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0</span><br><span class="line">32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0</span><br><span class="line">32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。后面跟的参数 1，表示每秒输出一次统计信息，表头提示了每一列的含义，这里介绍一些和性能调优相关的列：</p><ul><li>r：等待在 CPU 资源的进程数量。这个数据比平均负载更加能够体现 CPU 负载情况，数据中不包含等待 IO 的进程。如果这个数值大于机器 CPU 核数，那么机器的 CPU 资源已经饱和。</li><li>free：系统可用内存数（以千字节为单位），如果剩余内存不足，也会导致系统性能问题。下文介绍到的 free 命令，可以更详细的了解系统内存的使用情况。</li><li>si, so：交换区写入和读取的数量。如果这个数据不为 0，说明系统已经在使用交换区（swap），机器物理内存已经不足。</li><li>us, sy, id, wa, st：这些都代表了 CPU 时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）、IO 等待时间（wait）和被偷走的时间（stolen，一般被其他虚拟机消耗）。</li></ul><p>上述这些 CPU 时间，可以让我们很快了解 CPU 是否处于繁忙状态。一般情况下，如果用户时间和系统时间相加非常大，CPU 处于忙于执行指令。如果 IO 等待时间很长，那么系统的瓶颈可能在磁盘 IO。示例命令的输出可以看见，大量 CPU 时间消耗在用户态，也就是用户应用程序消耗了 CPU 时间。这不一定是性能问题，需要结合 r 队列，一起分析。</p><h2><span id="mpstat-p-all-1">mpstat -P ALL 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ mpstat -P ALL 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015  _x86_64_ (32 CPU)</span><br><span class="line">07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle</span><br><span class="line">07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78</span><br><span class="line">07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99</span><br><span class="line">07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00</span><br><span class="line">07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00</span><br><span class="line">07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><p>该命令可以显示每个 CPU 的占用情况，如果有一个 CPU 占用率特别高，那么有可能是一个单线程应用程序引起的。</p><h2><span id="pidstat-1">pidstat 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ pidstat 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015    _x86_64_    (32 CPU)</span><br><span class="line"></span><br><span class="line">07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos&#x2F;0</span><br><span class="line">07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave</span><br><span class="line">07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java</span><br><span class="line">07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java</span><br><span class="line">07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java</span><br><span class="line">07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat</span><br><span class="line"></span><br><span class="line">07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave</span><br><span class="line">07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java</span><br><span class="line">07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java</span><br><span class="line">07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass</span><br><span class="line">07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>pidstat 命令输出进程的 CPU 占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个 JAVA 进程占用了将近 1600% 的 CPU 时间，既消耗了大约 16 个 CPU 核心的运算资源。</p><h2><span id="iostat-xz-1">iostat -xz 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ iostat -xz 1</span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.13    0.00    0.10    0.01    0.00   99.76</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.62    0.03    0.89     0.57     7.97    18.52     0.00    0.68    1.96    0.64   0.60   0.06</span><br><span class="line">vdb               0.00     0.02    0.00    0.38     0.05     2.64    14.12     0.00    0.84    0.46    0.84   0.54   0.02</span><br><span class="line">dm-0              0.00     0.00    0.00    0.40     0.01     2.75    13.62     0.00    0.98    0.37    0.98   0.35   0.01</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.25    0.00    0.00    0.00    0.00   99.75</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.00    0.00    1.00     0.00     4.00     8.00     0.00    0.00    0.00    0.00   1.00   0.10</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.00    0.00    0.00    0.00    0.00  100.00</span><br></pre></td></tr></table></figure><p>iostat 命令主要用于查看机器磁盘 IO 情况。该命令输出的列，主要含义是：</p><ul><li>r/s, w/s, rkB/s, wkB/s：分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。</li><li>await：IO 操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括 IO 等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。</li><li>avgqu-sz：向设备发出的请求平均数量。如果这个数值大于 1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。</li><li>%util：设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过 60，可能会影响 IO 性能（可以参照 IO 操作平均等待时间）。如果到达 100%，说明硬件设备已经饱和。</li></ul><p>如果显示的是逻辑设备的数据，那么设备利用率不代表后端实际的硬件设备已经饱和。值得注意的是，即使 IO 性能不理想，也不一定意味应用程序会出现性能问题，可以利用诸如预读取、写缓存等策略提升应用性能。</p><h2><span id="free-m">free –m</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ free -m</span><br><span class="line">            total       used       free     shared    buffers     cached</span><br><span class="line">Mem:        245998      24545     221453         83         59        541</span><br><span class="line">-&#x2F;+ buffers&#x2F;cache:      23944     222053</span><br><span class="line">Swap:            0          0          0</span><br></pre></td></tr></table></figure><p>free 命令可以查看系统内存的使用情况，-m 参数表示按照兆字节展示。最后两列分别表示用于 IO 缓存的内存数，和用于文件系统页缓存的内存数。需要注意的是，第二行 -/+ buffers/cache，看上去缓存占用了大量内存空间。这是 Linux 系统的内存使用策略，尽可能的利用内存，如果应用程序需要内存，这部分内存会立即被回收并分配给应用程序。因此，这部分内存一般也被当成是可用内存。如果可用内存非常少，系统可能会动用交换区（如果配置了的话），这样会增加 IO 开销（可以在 iostat 命令中体现），降低系统性能。</p><h2><span id="sar-n-dev-1">sar -n DEV 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n DEV 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015     _x86_64_    (32 CPU)</span><br><span class="line">12:16:48 AM     IFACE   rxpck&#x2F;s   txpck&#x2F;s    rxkB&#x2F;s    txkB&#x2F;s   rxcmp&#x2F;s   txcmp&#x2F;s  rxmcst&#x2F;s   %ifutil</span><br><span class="line">12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM     IFACE   rxpck&#x2F;s   txpck&#x2F;s    rxkB&#x2F;s    txkB&#x2F;s   rxcmp&#x2F;s   txcmp&#x2F;s  rxmcst&#x2F;s   %ifutil</span><br><span class="line">12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>sar 命令在这里可以查看网络设备的吞吐率。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。如示例输出中，eth0 网卡设备，吞吐率大概在 22 Mbytes/s，既 176 Mbits/sec，没有达到 1Gbit/sec 的硬件上限。</p><h2><span id="sar-n-tcpetcp-1">sar -n TCP,ETCP 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n TCP,ETCP 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015    _x86_64_    (32 CPU)</span><br><span class="line">12:17:19 AM  active&#x2F;s passive&#x2F;s    iseg&#x2F;s    oseg&#x2F;s</span><br><span class="line">12:17:20 AM      1.00      0.00  10233.00  18846.00</span><br><span class="line">12:17:19 AM  atmptf&#x2F;s  estres&#x2F;s retrans&#x2F;s isegerr&#x2F;s   orsts&#x2F;s</span><br><span class="line">12:17:20 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:17:20 AM  active&#x2F;s passive&#x2F;s    iseg&#x2F;s    oseg&#x2F;s</span><br><span class="line">12:17:21 AM      1.00      0.00   8359.00   6039.00</span><br><span class="line">12:17:20 AM  atmptf&#x2F;s  estres&#x2F;s retrans&#x2F;s isegerr&#x2F;s   orsts&#x2F;s</span><br><span class="line">12:17:21 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>sar 命令在这里用于查看 TCP 连接状态，其中包括：</p><ul><li>active/s：每秒本地发起的 TCP 连接数，既通过 connect 调用创建的 TCP 连接；</li><li>passive/s：每秒远程发起的 TCP 连接数，即通过 accept 调用创建的 TCP 连接；</li><li>retrans/s：每秒 TCP 重传数量；</li></ul><p>TCP 连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP 重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。重传会严重影响tcp的效率，可以使用Brendan Gregg开发的一个轻量级tcp重传抓取工具: tcpretrans。</p><h2><span id="top">top</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92</span><br><span class="line">Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie</span><br><span class="line">%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers</span><br><span class="line">KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java</span><br><span class="line"> 4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave</span><br><span class="line">66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top</span><br><span class="line"> 5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java</span><br><span class="line"> 4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java</span><br><span class="line">    1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init</span><br><span class="line">    2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd</span><br><span class="line">    3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd&#x2F;0</span><br><span class="line">    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker&#x2F;0:0H</span><br><span class="line">    6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker&#x2F;u256:0</span><br><span class="line">    8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched</span><br></pre></td></tr></table></figure><p>top 命令包含了前面好几个命令的检查的内容。比如系统负载情况（uptime）、系统内存使用情况（free）、系统 CPU 使用情况（vmstat）等。因此通过这个命令，可以相对全面的查看系统负载的来源。同时，top 命令支持排序，可以按照不同的列排序，方便查找出诸如内存占用最多的进程、CPU 占用率最高的进程等。但是，top 命令相对于前面一些命令，输出是一个瞬间值，如果不持续盯着，可能会错过一些线索。这时可能需要暂停 top 命令刷新，来记录和比对数据。</p><h2><span id="总结">总结</span></h2><p>排查 Linux 服务器性能问题还有很多工具，上面介绍的一些命令，可以帮助我们快速的定位问题。例如前面的示例输出，多个证据证明有 JAVA 进程占用了大量 CPU 资源，之后的性能调优就可以针对应用程序进行。</p><blockquote><p>本文转载自：「 运维开发故事 」，原文：<a href="https://tinyurl.com/rsyjhzhw" target="_blank" rel="noopener">https://tinyurl.com/rsyjhzhw</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;感谢前辈，光荣属于前辈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;掌握一些性能优化工具和方法，这就需要在工作中不断地积累；计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。&lt;/p&gt;
&lt;p&gt;虽然监控工具可以帮助我们解决大多数问题，但我们有时需要登录实例并运行一些标准的 Linux 性能工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;来看 Netflix 性能工程团队的这篇博文：&lt;a href=&quot;https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看他们通过十条命令在一分钟内对机器性能问题进行诊断。在 60 秒内，您可以通过运行以下十个命令，对系统资源使用情况和正在运行的进程有一个高层次的了解。寻找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。饱和是指资源的负载超出其处理能力的情况，可以作为请求队列的长度或等待时间来公开。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="性能分析" scheme="https://www.hi-linux.com/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你如何给 Docker 开启 IPv6 网络支持</title>
    <link href="https://www.hi-linux.com/posts/47610.html"/>
    <id>https://www.hi-linux.com/posts/47610.html</id>
    <published>2021-08-09T01:00:00.000Z</published>
    <updated>2021-08-09T01:29:41.122Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Docker 默认是不开启 IPv6 支持的，但是我们某些业务往往又需要 IPv6 的支持，特别是 IPv6 普及大势所趋，本文主要介绍的是如何开启 Docker 桥接网络 IPv6 支持，这篇文章具体操作仅供参考，建议以官方文档为准。</p><p>本文最重要的先决条件是主机商已经分配给你一个公网 IPv6 地址段，我们可以通过查看主机控制面板中信息、询问主机供应商或者直接SSH登录主机使用命令<code>ip -f inet6 addr show eth0</code>获取。命令方式获取的 ipv6 地址输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">6: eth0:  mtu 9000 </span><br><span class="line">    inet6 2607:f0d0:1002:51::4&#x2F;64 scope global </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::230:48ff:fe33:bc33&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>其中<code>inet6 2607:f0d0:1002:51::4/64 scope global</code>这行指示的IPv6地址是我们需要的目标地址，注意我们这里选取的是公网IP，也就是后面<code>scope global</code>指示的，大家注意到后续还有一个fe80 开头的 IPv6 地址，这个后面没有 global，也就是通常意义内网 IPv6，本文不使用，当然读者可以根据实际需要选择内网 IPv6 继续参照下面介绍的步骤完成操作。</p><a id="more"></a><h2><span id="1-ipv6-地址段划分">1、IPv6 地址段划分</span></h2><p>Docker 可以配置多个虚拟网络，对于 IPv4 来说通过形如 <code>172.17.0.1/16</code>、<code>172.18.0.1/16</code>、<code>172.19.0.1/16</code> 这样内网私有IP地址段配置多个 IPv4 虚拟网段，那么同样的道理 IPv6 也建议划分多个段，如果手动划分不便，可以通过<a href="https://subnettingpractice.com/ipv6_subnetting.html" target="_blank" rel="noopener">IPv6 Subnetting Calculator</a>自动划分，如下图所示：</p><p><img src="https://img.hi-linux.com/staticfile/img-5ymjj9clsstvpr9p16zumuy8g-2021-06-22-onzc0g.png" alt></p><p>比如刚才的 IPv6 地址划分为 4 个网段如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2607:f0d0:1002:51::&#x2F;66</span><br><span class="line">2607:f0d0:1002:51:4000::&#x2F;66</span><br><span class="line">2607:f0d0:1002:51:8000::&#x2F;66</span><br><span class="line">2607:f0d0:1002:51:c000::&#x2F;66</span><br></pre></td></tr></table></figure><h2><span id="2-配置默认-docker-ipv6">2、配置默认 Docker IPv6</span></h2><p>编辑 Docker 配置文件<code>/etc/docker/daemon.json</code>，如果该文件不存在，请手动建立。配置文件内容如下，如果你已有的配置文件缺少相应的配置项，添加上即可，没有必要完全覆盖内容。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"experimental"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"ipv6"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"ip6tables"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"fixed-cidr-v6"</span>: <span class="string">"2607:f0d0:1002:51::/66"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里<code>ip6tables</code>是指由 Docker 自动配置 IPv6 的防火墙规则，如果你希望自己手动配置，请改为 false 或者移除此项，否则容器将无法连接 IPv6 网络；<code>fixed-cidr-v6</code> 则是我们划分的子网段的第一个，这里仅作示例请读者根据实际情况修改。</p><p>完成配置后请使用<code>systemctl restart docker</code>重启docker服务生效。完成此步后 Docker 算是完成对于 IPv6 的支持了。</p><h2><span id="3-配置-docker-compose-的-ipv6-支持可选">3、配置 Docker Compose 的 IPv6 支持（可选）</span></h2><p>这个主要是我编排容器时用的比较多，这里也记录一下作为一个备忘吧。</p><p>Docker Compose 的配置文件内容关于 IPv6 部分重点是网络节配置，如果另外配置网络的话，必须选择与默认<code>daemon.json</code>不同的 IPv6 子网段，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">networks:</span><br><span class="line">  example:</span><br><span class="line">    enable_ipv6: true</span><br><span class="line">    driver: bridge</span><br><span class="line">    driver_opts:</span><br><span class="line">      com.docker.network.enable_ipv6: &quot;true&quot;</span><br><span class="line">    ipam:</span><br><span class="line">      config:</span><br><span class="line">       - subnet: 172.23.0.0&#x2F;16</span><br><span class="line">       - subnet: &quot;2607:f0d0:1002:51:4000::&#x2F;66&quot;</span><br><span class="line">         gateway:2607:f0d0:1002:51:4000::1</span><br></pre></td></tr></table></figure><p>这里<code>example</code>网络我们通过配置开启IPv6支持，其中网络段配置IPv4是<code>172.23.0.0/16</code>，IPv6选用余下的第二个网段<code>2607:f0d0:1002:51:4000::/66</code>注意这里<strong>不能</strong>和<code>daemon.json</code>配置的 IPv6 网段一样。这里的 IP 配置同样是一个示例，读者请根据实际情况进行修改。</p><h2><span id="参考资料">参考资料</span></h2><ul><li><a href="https://docs.docker.com/config/daemon/ipv6/" target="_blank" rel="noopener">Enable IPv6 support</a></li></ul><blockquote><p>本文转载自：「 王晔的博客 」，原文：<a href="https://tinyurl.com/4y22pxx6" target="_blank" rel="noopener">https://tinyurl.com/4y22pxx6</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker 默认是不开启 IPv6 支持的，但是我们某些业务往往又需要 IPv6 的支持，特别是 IPv6 普及大势所趋，本文主要介绍的是如何开启 Docker 桥接网络 IPv6 支持，这篇文章具体操作仅供参考，建议以官方文档为准。&lt;/p&gt;
&lt;p&gt;本文最重要的先决条件是主机商已经分配给你一个公网 IPv6 地址段，我们可以通过查看主机控制面板中信息、询问主机供应商或者直接SSH登录主机使用命令&lt;code&gt;ip -f inet6 addr show eth0&lt;/code&gt;获取。命令方式获取的 ipv6 地址输出如下：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;6: eth0:  mtu 9000 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    inet6 2607:f0d0:1002:51::4&amp;#x2F;64 scope global &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       valid_lft forever preferred_lft forever&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    inet6 fe80::230:48ff:fe33:bc33&amp;#x2F;64 scope link &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       valid_lft forever preferred_lft forever&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中&lt;code&gt;inet6 2607:f0d0:1002:51::4/64 scope global&lt;/code&gt;这行指示的IPv6地址是我们需要的目标地址，注意我们这里选取的是公网IP，也就是后面&lt;code&gt;scope global&lt;/code&gt;指示的，大家注意到后续还有一个fe80 开头的 IPv6 地址，这个后面没有 global，也就是通常意义内网 IPv6，本文不使用，当然读者可以根据实际需要选择内网 IPv6 继续参照下面介绍的步骤完成操作。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes v1.22.0 正式发布，众多 API 和功能被移除</title>
    <link href="https://www.hi-linux.com/posts/43527.html"/>
    <id>https://www.hi-linux.com/posts/43527.html</id>
    <published>2021-08-05T01:00:00.000Z</published>
    <updated>2021-08-05T04:21:06.065Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>我们兴奋地向大家宣布，Kubernetes 在 2021 年内的第二个版本、即 1.22 版本已经正式来临！</p><p>新版本包含 53 项增强功能：其中13项功能已升级至稳定版，24 项功能顺利步入 beta 阶段，16 项功能刚刚开始 alpha 阶段。另有 3 项功能被彻底弃用。</p><p>今年 4 月，Kubernetes 的发布周期已经正式由每年4次调整为每年3次。而1.22版本正是调整之后的首个长周期发布版本。随着Kubernetes的逐渐成熟，每个发布周期中包含的增强功能数量一直在持续增加。这意味着贡献者社区及发布工程团队需要在两个版本之间完成更多开发工作，而新版本中的大量全新功能也会给最终用户社区带来一定的学习压力。</p><p>有鉴于此，Kubernetes 的发布节奏由一年四次调整为一年三次能够带来更好的均衡效果，包括贡献与版本管理、社区规划升级并为用户提供更舒适的更新上手体验。</p><a id="more"></a><h2><span id="版本要点">版本要点</span></h2><p><strong>Server-side Apply 迎来 GA 通用版本</strong></p><p>Server-side Apply[1]是一种面向 Kubernetes API 服务器的全新字段所有权及对象合并算法。Server-side Apply 通过声明式配置帮助用户及控制器管理其资源，包括以声明方式创建及/或修改对象、发送明确指定的意图等等。经过数个版本的测试之后，Server-side Apply 现已正式进入 GA 通用版阶段。</p><p><strong>外部凭证提供程序迎来稳定版</strong></p><p>自 1.11 版本以来，对 Kubernetes 客户端凭证插件的支持就一直处于测试阶段。而随着 Kubernetes 1.22 的推出，这项功能逐步趋于稳定。其中的 GA 功能集现在包括对交互式登录流程插件提供更好的支持，同时修复了多项 bug。感兴趣的插件作者可以参考 sample-exec-plugin[2] 以了解更多详细信息。</p><p><strong>etcd 更新至 3.5.0</strong></p><p>Kubernetes的默认后端存储etcd获得了3.5.0新版本。新版本改进了安全性、性能、监控以及开发者体验，修复了多项bug，同时带来了迁移为结构化日志记录与内置日志轮替等重要新功能。3.5.0版本还提出详尽的后续发展路线图，探索如何更好地解决流量过载问题。感兴趣的朋友可以参考<a href="http://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&amp;mid=2649730822&amp;idx=1&amp;sn=cbe9049035712f58e465f4108703168d&amp;chksm=88939065bfe419739df224da1c33bf8f9b9ef49ebe136cfdb2cf36e0470b8fa1c46e2d184eaa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">3.5.0发布公告</a>中的完整变更清单。</p><p><strong>用于内存资源的 Quality of Service（QoS）</strong></p><p>最初，Kubernetes使用的是 v1 cgroups API。通过这种设计，Pod的QoS类将仅可用于CPU资源（例如cpu_shares）。如今，Kubernetes 1.22版以alpha测试的形式使用cgroups v2 API控制内存分配与隔离，希望在内存资源发生争用时提高工作负载与节点的可用性、改善容器生命周期的可预测性。</p><p><strong>节点系统交换支持</strong></p><p>每一位系统管理员或Kubernetes用户在设置和使用 Kubernetes 时，都会不约而同地禁用掉交换空间。随着 Kubernetes 1.22 版本的发布，新的 alpha 功能已可支持运行具有交换内存的节点。这项变更使得管理员能够选择在Linux节点上配置交换，并将一部分块存储视为额外的虚拟内存。</p><p><strong>Windows 增强与功能</strong></p><p>SIG Windows继续为不断发展壮大的开发者社区提供支持，并在1.22新版本中发布了自己的开发环境。这些新工具支持多种CNI提供程序并能够在多个平台上顺畅运行。通过编译Windows kubelet与kube-proxy，再配合日常构建的其他Kubernetes组件，新版本为用户带来一种从零开始使用全新Windows功能的新方法。</p><p>CSI对Windows节点的支持也在1.22版本中达到GA通用阶段。另外，Kubernetes 1.22迎来了新的alpha功能——Windows特权容器。为了在Windows节点上使用CSI存储，CSIProxy允许我们将CSI节点插件部署为非特权Pod，并使用代理在节点上执行特权存储操作。</p><p><strong>seccomp 默认配置</strong></p><p>Kubelet以alpha功能的形式提供默认seccomp配置功能，同时附带新的命令行标志与配置。在使用时，这项新功能可提供集群范围内的seccomp默认值，并使用RuntimeDefault seccompt配置取代默认情况下的Unconfined，从而大大增强了Kubernetes部署的默认安全性。凭借更出色的默认工作负载安全效果，管理员们终于可以睡个好觉了。若需了解这项功能的更多详细信息，请参阅官方seccomp教程[3]。</p><p><strong>使用 kubeadm 提升控制平面安全</strong></p><p>这项新的alpha功能允许我们以非root用户身份运行kubeadm控制平面组件。长久以来，kubeadm一直要求采取这样一种安全措施。要实际体验，你需要在kubeadm中启用特定的RootlessControlPlane feature gate。在使用这项alpha功能部署集群时，你的控制平面将以较低权限运行。</p><p>对于kubeadm，Kubernetes 1.22还带来了新的v1beta3配置API。此次迭代带来了多项社区期待已久的功能，同时弃用了部分现有功能。v1beta3将成为目前的首选API版本；但v1beta2 API仍然正常可用，并未在1.22版中被淘汰。</p><h2><span id="主要变化">主要变化</span></h2><p><strong>删除了几个已弃用的 beta API</strong></p><p>1.22版本中删除了许多已经弃用的beta API，并发布这些API的GA通用版本。全部现有对象均可通过稳定的API进行交互。此次删除涉及 Ingress，IngressClass，Lease，APIService，ValidatingWebhookConfiguration，MutatingWebhookConfiguration，CustomResourceDefinition，TokenReview，SubjectAccessReview以及 CertificateSigningRequest API的beta版本。</p><p>关于完整清单，请参阅已弃用API迁移指南[4]以及博文《1.22版本中的Kubernetes API与功能删除：你需要了解的一切[5]》。</p><p><strong>临时容器的 API 变更与改进</strong></p><p>用于创建临时容器的 API 在 1.22 版本中也发生了变化。临时容器功能现为alpha版且默认禁用，新的API也不再响应客户端对旧有API的使用请求。</p><p>在稳定功能方面，kubectl 工具遵循 Kubernetes 版本倾斜策略，但kubectl v1.21及更早版本无法支持临时容器的新API。如果你打算使用kubectl debug创建临时容器，且你的集群运行有Kubernetes 1.22，则无法使用kubectl v1.21或更早版本完成这项操作。如果你希望将 kubectl debug 与多个集群版本混合使用，请务必将 kubectl 更新至1.22。</p><h2><span id="其他更新">其他更新</span></h2><p><strong>更新至稳定版</strong></p><ul><li>限定服务账户令牌数量</li><li>CSI服务账户令牌</li><li>Windows对CSI插件的支持</li><li>对于在操作中使用已弃用API的警告机制</li><li>清退PodDisruptionBudget</li></ul><p><strong>重要功能更新</strong></p><ul><li>引入新的 PodSecurity 准入 alpha 功能，用以替代原有 PodSecurityPolicy</li><li>The Momory Manager 进入 beta 阶段</li><li>推出新的alpha功能，用于实现 API Server Tracing</li><li>kubeadm配置格式迎来新的 v1beta3 版本</li><li>用于 PersistentVolumes 的通用数据填充器已提供 alpha 版</li><li>Kubernetes 控制平面现可始终使用 CronJobs v2 控制器</li><li>作为 alpha 功能，所有 Kubernetes 节点组件（包括 kubelet、kube-proxy 与容器运行时）都能够以非 root 用户身份运行</li></ul><h2><span id="发布说明">发布说明</span></h2><p>请点击此处[6]查看 1.22 版本的完整发布说明信息。</p><h2><span id="发布时间">发布时间</span></h2><p>Kubernetes 1.22 现已开放下载[7]并正式登陆GitHub[8]。</p><h2><span id="版本徽标">版本徽标</span></h2><p><img src="https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNmJEu8ECBEibyEwsP7eqc3IicbGd65ga9tP2X1g6RGkB4zIsJuw0qdwRc4UCuiaLwkl4XDOWltlzq7mQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p>面对新冠疫情、自然灾害与倦怠情绪的重重挑战，Kubernetes 1.22 仍然拿出了 53 项增强功能，这也使其成为迄今为止更新量最大的 Kubernetes 版本。这样辉煌的成就，离不开发布团队成员们的辛勤努力、热情奉献以及Kubernetes生态系统中杰出贡献者们的不懈支持。1.22 版本发布徽标提醒我们要不断突破新的极限、创造新的纪录。谨以此标，献给每一位发布团队成员、攀登者与前瞻者！</p><p>徽标由 Boris Zotkin 设计。作为 MathWorks的Mac/Linux 管理员，Boris 热爱生活中平淡简单的一切，喜欢与家人共度时光。这里再次感谢这位乐观技术人贡献的精美作品！</p><p>相关链接：</p><ol><li><a href="https://kubernetes.io/docs/reference/using-api/server-side-apply/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/using-api/server-side-apply/</a></li><li><a href="https://github.com/ankeesler/sample-exec-plugin" target="_blank" rel="noopener">https://github.com/ankeesler/sample-exec-plugin</a></li><li><a href="https://kubernetes.io/docs/tutorials/clusters/seccomp/#enable-the-use-of-runtimedefault-as-the-default-seccomp-profile-for-all-workloads" target="_blank" rel="noopener">https://kubernetes.io/docs/tutorials/clusters/seccomp/#enable-the-use-of-runtimedefault-as-the-default-seccomp-profile-for-all-workloads</a></li><li><a href="https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22</a></li><li><a href="https://blog.k8s.io/2021/07/14/upcoming-changes-in-kubernetes-1-22/" target="_blank" rel="noopener">https://blog.k8s.io/2021/07/14/upcoming-changes-in-kubernetes-1-22/</a></li><li><a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.22.md" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.22.md</a></li><li><a href="https://kubernetes.io/releases/download/" target="_blank" rel="noopener">https://kubernetes.io/releases/download/</a></li><li><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.22.0" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/releases/tag/v1.22.0</a></li></ol><p>原文链接：<a href="https://kubernetes.io/blog/2021/08/04/kubernetes-1-22-release-announcement/" target="_blank" rel="noopener">https://kubernetes.io/blog/2021/08/04/kubernetes-1-22-release-announcement/</a></p><blockquote><p>本文转载自：「 分布式实验室 」，原文：<a href="https://tinyurl.com/4dpzmp5c" target="_blank" rel="noopener">https://tinyurl.com/4dpzmp5c</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们兴奋地向大家宣布，Kubernetes 在 2021 年内的第二个版本、即 1.22 版本已经正式来临！&lt;/p&gt;
&lt;p&gt;新版本包含 53 项增强功能：其中13项功能已升级至稳定版，24 项功能顺利步入 beta 阶段，16 项功能刚刚开始 alpha 阶段。另有 3 项功能被彻底弃用。&lt;/p&gt;
&lt;p&gt;今年 4 月，Kubernetes 的发布周期已经正式由每年4次调整为每年3次。而1.22版本正是调整之后的首个长周期发布版本。随着Kubernetes的逐渐成熟，每个发布周期中包含的增强功能数量一直在持续增加。这意味着贡献者社区及发布工程团队需要在两个版本之间完成更多开发工作，而新版本中的大量全新功能也会给最终用户社区带来一定的学习压力。&lt;/p&gt;
&lt;p&gt;有鉴于此，Kubernetes 的发布节奏由一年四次调整为一年三次能够带来更好的均衡效果，包括贡献与版本管理、社区规划升级并为用户提供更舒适的更新上手体验。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>美国安全局 NSA、CISA 发布 Kubernetes 安全加固指南(内附免费下载地址)</title>
    <link href="https://www.hi-linux.com/posts/51218.html"/>
    <id>https://www.hi-linux.com/posts/51218.html</id>
    <published>2021-08-05T01:00:00.000Z</published>
    <updated>2021-08-05T04:21:06.067Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Kubernetes 最初由谷歌公司的工程师开发，随后由云原生计算基金会开源，它是当前最流行的容器协作软件。Kubernetes 主要用于基于云的基础设施内部，便于系统管理员使用软件容器部署新的 IT 资源。</p><p>Kubernetes 的攻击目标通常有以下三个原因：<strong>数据窃取、计算能力窃取或拒绝服务</strong>。传统上，数据盗窃是主要动机；然而，由于 Kubernetes 和 Docker 模型和传统的单片软件平台之间存在巨大不同，因此很多系统管理员在安全配置 Kubernetes 方面问题颇多。多年来，多款密币挖掘僵尸网络都在攻击这类配置错误问题。威胁行动者扫描互联网上被暴露的未认证的 Kubernetes 管理功能或者扫描在大型 Kubernetes 集群（如 Argo Workflow 或 Kubeflow）上运行的应用程序，获得对 Kubernetes 后端的访问权限，之后利用这种权限在受害者云基础设施上部署密币挖掘应用。这些攻击早在 2017 年初就已发生，而现在已发展为多个团伙为了利用同一个配置错误的集群而大打出手。</p><a id="more"></a><p>美国国家安全局 (NSA) 和网络安全与基础设施安全局 (CISA) 近日发布了一份 59 页的网络安全技术报告『Kubernetes 安全加固指南』。该报告详细介绍了对 Kubernetes 环境的威胁，并提供了配置指南以最大限度地降低风险。</p><p>CISA 和 NSA 发布的这份指南旨在为系统管理员提供关于未来 Kubernetes 配置的安全基线，以避免遭受此类攻击。另外除了基本的配置指南外，这份报告还详述了企业和政府机构可采取的基本缓解措施，阻止或限制 Kubernetes 安全事件的严重性，包括：</p><ul><li><p>扫描容器和 Pods，查找漏洞或配置错误问题。</p></li><li><p>尽可能以最小权限运行容器和 Pods。</p></li><li><p>使用网络分割来控制攻陷事件造成的损害。</p></li><li><p>使用防火墙来限制不必要的网络连接和加密以保护机密性。</p></li><li><p>使用强认证和授权限制用户和管理员访问权限以及限制攻击面。</p></li><li><p>使用日志审计，以便管理员能够监控活动并收到关于潜在恶意活动的警报。</p></li><li><p>定期审计所有的 Kubernetes 设置并使用漏洞扫描确保安全风险得到控制，补丁已应用。</p></li></ul><p>NSA 和 CISA 的这份指南侧重于安全挑战，并建议系统管理员尽可能强化他们的环境。NSA 发布此指南是支持美国国防部、国防工业基地和国家安全系统的使命的一部分。</p><p><strong>如需『 美国安全局 Kubernetes 安全加固指南 』 PDF 版，可在公众号对话框回复关键字：「<code>K8s-Hardening-Guidance</code>」免费获取。</strong></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes 最初由谷歌公司的工程师开发，随后由云原生计算基金会开源，它是当前最流行的容器协作软件。Kubernetes 主要用于基于云的基础设施内部，便于系统管理员使用软件容器部署新的 IT 资源。&lt;/p&gt;
&lt;p&gt;Kubernetes 的攻击目标通常有以下三个原因：&lt;strong&gt;数据窃取、计算能力窃取或拒绝服务&lt;/strong&gt;。传统上，数据盗窃是主要动机；然而，由于 Kubernetes 和 Docker 模型和传统的单片软件平台之间存在巨大不同，因此很多系统管理员在安全配置 Kubernetes 方面问题颇多。多年来，多款密币挖掘僵尸网络都在攻击这类配置错误问题。威胁行动者扫描互联网上被暴露的未认证的 Kubernetes 管理功能或者扫描在大型 Kubernetes 集群（如 Argo Workflow 或 Kubeflow）上运行的应用程序，获得对 Kubernetes 后端的访问权限，之后利用这种权限在受害者云基础设施上部署密币挖掘应用。这些攻击早在 2017 年初就已发生，而现在已发展为多个团伙为了利用同一个配置错误的集群而大打出手。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>巧用 Xpanes 实现多服务器批量管理</title>
    <link href="https://www.hi-linux.com/posts/36685.html"/>
    <id>https://www.hi-linux.com/posts/36685.html</id>
    <published>2021-08-04T01:00:00.000Z</published>
    <updated>2021-08-04T02:29:35.927Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>由 Tmux 提供支持的终极终端分屏器！</strong></p></blockquote><p>虽然我们已经可以使用 <code>tmux</code> 进行屏幕的分割和切换，但是如果需要对一批服务器进行操作的话，就只能一个一个的登录和执行了。如果使用过 <code>Xshell</code> 或者其他远程工具的话，肯定是使用过这个功能特性的，一次命令输出可以在登录的多个远程终端上面执行。现在我们可以使用 <code>tmux-xpanes</code> 来完成同样的事情了，撒花！</p><a id="more"></a><h2><span id="特点介绍">特点介绍</span></h2><blockquote><p>the features about xpanes</p></blockquote><ul><li>Split tmux window into multiple panes</li><li>将 tmux 窗口拆分为多个窗格<ul><li>Construct command lines &amp; execute them on the panes</li><li>构造命令行并在窗格上执行它们</li></ul></li><li>Runnable from outside of tmux session</li><li>Runnable from inside of tmux session</li><li>Record operation log</li><li>记录操作日志</li><li>Flexible layout arrangement for panes</li><li>窗格的灵活布局安排<ul><li>Select layout presets</li><li>选择布局预设</li><li>Set columns or rows as you like</li><li>根据需要设置列或行</li></ul></li><li>Display pane title on each pane</li><li>在每个窗格上显示窗格标题</li><li>Generate command lines from standard input (Pipe mode)</li><li>标准输入(管道模式)生成命令行</li></ul><h2><span id="工具安装">工具安装</span></h2><blockquote><p>requirements: bash3.2+ and tmux1.8+</p></blockquote><ul><li>macOS</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install tmux-xpanes</span><br></pre></td></tr></table></figure><ul><li>CentOS</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-$(rpm --<span class="built_in">eval</span> %rhel).noarch.rpm</span><br><span class="line">$ sudo yum install xpanes</span><br></pre></td></tr></table></figure><ul><li>Ubuntu</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install software-properties-common</span><br><span class="line">$ sudo add-apt-repository ppa:greymd/tmux-xpanes</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install tmux-xpanes</span><br></pre></td></tr></table></figure><ul><li>Manual</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download with wget</span></span><br><span class="line">$ wget https://raw.githubusercontent.com/greymd/tmux-xpanes/v4.1.3/bin/xpanes -O ./xpanes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Put it under PATH and make it executable.</span></span><br><span class="line">$ sudo install -m 0755 xpanes /usr/<span class="built_in">local</span>/bin/xpanes</span><br></pre></td></tr></table></figure><ul><li>Zsh Completion</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Clone the repository</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/greymd/tmux-xpanes.git /path/to/tmux-xpanes</span><br><span class="line"></span><br><span class="line"><span class="comment"># ~/.zshrc.</span></span><br><span class="line">$ <span class="built_in">source</span> /path/to/tmux-xpanes/completion.zsh</span><br></pre></td></tr></table></figure><h2><span id="工具帮助">工具帮助</span></h2><blockquote><p>tmux-xpanes is alias of xpanes</p></blockquote><ul><li>[Normal mode1] Outside of tmux session<ul><li>当 <code>tmux</code> 没有打开且 <code>xpanes</code> 在终端上执行时，<code>xpanes</code> 的行为如下:</li><li>它新建一个 tmux 会话，并在会话上新建窗口</li><li>此外，它将窗口分隔为多个窗格</li><li>最后，将会话附加上去</li></ul></li><li>[Normal mode2] Inside of tmux session<ul><li>当 <code>tmux</code> 已经打开并在现有的 <code>tmux</code> 会话上执行 <code>xpanes</code> 时，该命令的行为如下:</li><li>它会在现有活动会话上新建一个窗口</li><li>此外，它将窗口分隔为多个窗格</li><li>最后，窗口将处于活动状态</li></ul></li><li>[Pipe mode] Inside of tmux session &amp; Accepting standard input<ul><li>当 <code>xpanes</code> 在正常模式 <code>2</code> 下接受标准输入时，<code>xpanes</code> 的行为将是一个特殊的称为“管道模式”的行为。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">  xpanes [OPTIONS] [argument ...]</span><br><span class="line"></span><br><span class="line">Usage(Pipe mode):</span><br><span class="line">  <span class="built_in">command</span> ... | xpanes [OPTIONS] [&lt;<span class="built_in">command</span>&gt; ...]</span><br><span class="line"></span><br><span class="line">OPTIONS:</span><br><span class="line">  -h,--<span class="built_in">help</span>                    Display this <span class="built_in">help</span> and <span class="built_in">exit</span>.</span><br><span class="line">  -V,--version                 Output version information and <span class="built_in">exit</span>.</span><br><span class="line">  -B &lt;begin-command&gt;           Run &lt;begin-command&gt; before processing &lt;<span class="built_in">command</span>&gt; <span class="keyword">in</span> each pane. Multiple options are allowed.</span><br><span class="line">  -c &lt;<span class="built_in">command</span>&gt;                 Set &lt;<span class="built_in">command</span>&gt; to be executed <span class="keyword">in</span> each pane. Default is `<span class="built_in">echo</span> &#123;&#125;`.</span><br><span class="line">  -d,--desync                  Make synchronize-panes option off <span class="keyword">in</span> new window.</span><br><span class="line">  -e                           Execute given arguments as is. Same as -c <span class="string">'&#123;&#125;'</span></span><br><span class="line">  -I &lt;repstr&gt;                  Replacing one or more occurrences of &lt;repstr&gt; <span class="keyword">in</span> <span class="built_in">command</span> provided by -c or -B. Default is `&#123;&#125;`.</span><br><span class="line">  -C NUM,--cols=NUM            Number of columns of window layout.</span><br><span class="line">  -R NUM,--rows=NUM            Number of rows of window layout.</span><br><span class="line">  -l &lt;layout&gt;                  Set the preset of window layout. Recognized layout arguments are:</span><br><span class="line">                               t    tiled</span><br><span class="line">                               eh   even-horizontal</span><br><span class="line">                               ev   even-vertical</span><br><span class="line">                               mh   main-horizontal</span><br><span class="line">                               mv   main-vertical</span><br><span class="line">  -n &lt;number&gt;                  Set the maximum number of &lt;argument&gt; taken <span class="keyword">for</span> each pane.</span><br><span class="line">  -s                           Speedy mode: Run <span class="built_in">command</span> without opening an interactive shell.</span><br><span class="line">  -ss                          Speedy mode AND close a pane automatically at the same time as process exiting.</span><br><span class="line">  -S &lt;socket-path&gt;             Set a full alternative path to the server socket.</span><br><span class="line">  -t                           Display each argument on the each pane is border as their title.</span><br><span class="line">  -x                           Create extra panes <span class="keyword">in</span> the current active window.</span><br><span class="line">  --<span class="built_in">log</span>[=&lt;directory&gt;]          Enable logging and store <span class="built_in">log</span> files to ~/.cache/xpanes/logs or &lt;directory&gt;.</span><br><span class="line">  --<span class="built_in">log</span>-format=&lt;FORMAT&gt;        Make name of <span class="built_in">log</span> files follow &lt;FORMAT&gt;. Default is `[:ARG:].<span class="built_in">log</span>.%Y-%m-%d_%H-%M-%S`.</span><br><span class="line">  --ssh                        Same as `-t -s -c <span class="string">'ssh -o StrictHostKeyChecking=no &#123;&#125;'</span>`.</span><br><span class="line">  --stay                       Do not switch to new window.</span><br><span class="line">  --bulk-cols=NUM1[,NUM2 ...]  Set number of columns on multiple rows (i.e, <span class="string">"2,2,2"</span> represents 2 cols x 3 rows).</span><br><span class="line">  --debug                      Print debug message.</span><br></pre></td></tr></table></figure><h2><span id="使用介绍">使用介绍</span></h2><blockquote><p>介绍 xpanes 工具的使用方式和简单工作模式！</p></blockquote><p><img src="https://img.hi-linux.com/staticfile/learn-tmux-xpanes-tools-01-20210709162820791-2021-07-09-mNvwzx.gif" alt="使用xpanes来并发执行命令"></p><table><thead><tr><th style="text-align:left">编号</th><th style="text-align:left">参数</th><th style="text-align:left">含义解释</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong><code>-d</code></strong></td><td style="text-align:left">打开的窗口不同步输出命令</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong><code>-c</code></strong></td><td style="text-align:left">包含需要执行的命令</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong><code>-I</code></strong></td><td style="text-align:left">用来指定占位符</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong><code>-t</code></strong></td><td style="text-align:left">可以在每个窗格边框上显示每个参数</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong><code>--ssh</code></strong></td><td style="text-align:left">助于忽略 openssh 的警报消息</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><strong><code>--log</code></strong></td><td style="text-align:left">记录 SSH 连接多个主机并进行日志操作</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><strong><code>-s</code></strong></td><td style="text-align:left">将不会创建新的交互式 shell 命令</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><strong><code>-ss</code></strong></td><td style="text-align:left">屏蔽信息</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left"><strong><code>-x</code></strong></td><td style="text-align:left">可以在现有窗口上创建新窗格</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left"><strong><code>-e</code></strong></td><td style="text-align:left">可以在不同的窗格上执行不同的命令</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left"><strong><code>-B</code></strong></td><td style="text-align:left">可以对每个窗格进行预处理</td></tr><tr><td style="text-align:left">12</td><td style="text-align:left"><strong><code>-C</code></strong></td><td style="text-align:left">来控制窗口的列</td></tr><tr><td style="text-align:left">13</td><td style="text-align:left"><strong><code>-R</code></strong></td><td style="text-align:left">来控制窗口的行</td></tr><tr><td style="text-align:left">14</td><td style="text-align:left"><strong><code>--bulk-cols</code></strong></td><td style="text-align:left">指定对应每一行的列数</td></tr></tbody></table><ul><li>执行如下命令，将使用 <code>tmux</code> 工具打开四个窗口，分别执行 <code>echo n</code> 的命令。执行完成之后，我们就可以在任意一个窗口执行命令，其他窗口均会同步执行该命令。</li><li>默认情况下，执行 <code>xpanes</code> 命令之后，从键盘输入在多个窗格中是同步的。当我们使用完成之后，可以使用 <code>exit</code> 命令来退出所有打开的窗口。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个效果等同</span></span><br><span class="line">$ xpanes &#123;1..4&#125;</span><br><span class="line">$ xpanes 1 2 3 4</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 1                       │$ <span class="built_in">echo</span> 2                       │</span><br><span class="line">│1                              │2                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 3                       │$ <span class="built_in">echo</span> 4                       │</span><br><span class="line">│3                              │4                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br></pre></td></tr></table></figure><ul><li>如果希望，打开的窗口不同步输出命令的话，可以使用 <code>-d/--desync</code> 参数。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -d</span></span><br><span class="line">$ xpanes -d 1 2 3 4</span><br></pre></td></tr></table></figure><ul><li><code>xpanes</code> 的基本选项之一 <code>-c</code> 参数，用于表示需要执行的命令。我们使用 <code>-c</code> 参数将 <code>seq</code> 命令包裹在内，其中 <code>{}</code> 表示需要被替换的参数。这个占位符可以使用 <code>-I</code> 参数来指定。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -c</span></span><br><span class="line">$ xpanes -c <span class="string">'seq &#123;&#125;'</span> 1 2 3 4</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ seq 1                        │$ seq 2                        │</span><br><span class="line">│1                              │1                              │</span><br><span class="line">│                               │2                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ seq 3                        │$ seq 4                        │</span><br><span class="line">│1                              │1                              │</span><br><span class="line">│2                              │2                              │</span><br><span class="line">│3                              │3                              │</span><br><span class="line">│                               │4                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># -I</span></span><br><span class="line">$ xpanes -I@ -c <span class="string">'seq @'</span> 1 2 3 4</span><br><span class="line"></span><br><span class="line"><span class="comment"># -c</span></span><br><span class="line">$ xpanes -c <span class="string">"ssh myuser@&#123;&#125;"</span> host1 host2</span><br><span class="line">$ xpanes -c <span class="string">"ssh -t &#123;&#125; bash -ci 'll'"</span> host-&#123;1,2,3&#125;</span><br><span class="line">$ xpanes -c <span class="string">"tail -f &#123;&#125;"</span> /var/<span class="built_in">log</span>/apache/&#123;error,access&#125;.<span class="built_in">log</span> /var/<span class="built_in">log</span>/application/&#123;error,access&#125;.<span class="built_in">log</span></span><br><span class="line">$ xpanes -c <span class="string">"ssh user@host tail -f &#123;&#125;"</span> /var/<span class="built_in">log</span>/apache/&#123;error,access&#125;.<span class="built_in">log</span> /var/<span class="built_in">log</span>/application/&#123;error,access&#125;.<span class="built_in">log</span></span><br></pre></td></tr></table></figure><ul><li>使用 <code>--ssh</code> 选项有助于忽略 <code>openssh</code> 的警报消息，即不需要回答是/否的问题。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个效果等同</span></span><br><span class="line">$ xpanes --ssh myuser1@host1 myuser2@host2</span><br><span class="line">$ xpanes -t -s -c <span class="string">"ssh -o StrictHostKeyChecking=no &#123;&#125;"</span> myuser1@host1 myuser2@host2</span><br></pre></td></tr></table></figure><ul><li>使用 <code>--log</code> 选项可以记录 <code>SSH</code> 连接多个主机并进行日志操作。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes --<span class="built_in">log</span>=~/operation_log -c <span class="string">"ssh &#123;&#125;"</span> user1@host1 user2@host2</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ ssh user1@host1              │ $ ssh user2@host2             │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line">$ ls ~/operation_log/</span><br><span class="line">user1@host1-1.log.2017-03-15_21-30-07</span><br><span class="line">user2@host2-1.log.2017-03-15_21-30-07</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-s</code> 选项，<code>xpanes</code> 将不会创建新的交互式 <code>shell</code> 命令。这样的好处在于，打开多个新窗格需要很长时间(默认登录 <code>shell</code> 会加载 <code>.zshrc</code> 配置等事情)，不想在 <code>shell</code> 历史记录中留下命令。</li><li>当每个进程结束时，将显示 <strong>“窗格已死…”</strong> 之类的确认消息。如果需要禁用该消息的输出，可以使用 <code>-ss</code> 代替 <code>-s</code> 来进行屏蔽。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes -s -c <span class="string">"seq &#123;&#125;"</span> 2 3 4 5</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line">│1                                         │1                                         │</span><br><span class="line">│2                                         │2                                         │</span><br><span class="line">│Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │3                                         │</span><br><span class="line">│                                          │Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line">│1                                         │1                                         │</span><br><span class="line">│2                                         │2                                         │</span><br><span class="line">│3                                         │3                                         │</span><br><span class="line">│4                                         │4                                         │</span><br><span class="line">│Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │5                                         │</span><br><span class="line">│                                          │Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 屏蔽信息</span></span><br><span class="line">$ xpanes -ss -c <span class="string">"seq &#123;&#125;"</span> 2 3 4 5</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-t</code> 参数，可以在每个窗格边框上显示每个参数。它叫做“窗格标题”。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标题</span></span><br><span class="line">$ xpanes -t -c <span class="string">"ping &#123;&#125;"</span> 192.168.1.&#123;5..8&#125;</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line">│ping 192.168.1.5                          │ping 192.168.1.6                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+---192.168.1.5----------------------------+---192.168.1.6----------------------------+</span><br><span class="line">│ping 192.168.1.7                          │ping 192.168.1.8                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+---192.168.1.7----------------------------+---192.168.1.8----------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-x</code> 参数，可以在现有窗口上创建新窗格。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># before</span></span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$                              │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│ $ xpanes -x 4 5 6                                             │</span><br><span class="line">│                                                               │</span><br><span class="line">│                                                               │</span><br><span class="line">│                                                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># after</span></span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$                              │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ xpanes -x 4 5 6              │$ <span class="built_in">echo</span> 4                       │</span><br><span class="line">│$                              │4                              │</span><br><span class="line">│                               │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 5                       │$ <span class="built_in">echo</span> 6                       │</span><br><span class="line">│5                              │6                              │</span><br><span class="line">│$                              │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-e</code> 参数，可以在不同的窗格上执行不同的命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个效果等同</span></span><br><span class="line">$ xpanes -e <span class="string">"top"</span> <span class="string">"vmstat 1"</span> <span class="string">"watch -n 1 free"</span></span><br><span class="line">$ xpanes -I@ -c <span class="string">"@"</span> <span class="string">"top"</span> <span class="string">"vmstat 1"</span> <span class="string">"watch -n 1 free"</span></span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ top                          │$ vmstat 1                    │</span><br><span class="line">│                               │                              │</span><br><span class="line">│                               │                              │</span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ watch -n 1 free                                             │</span><br><span class="line">│                                                              │</span><br><span class="line">│                                                              │</span><br><span class="line">+--------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-B</code> 参数，可以对每个窗格进行预处理，<code>-B</code> 选项允许在处理 <code>-c</code> 选项之前执行另一条命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes -B <span class="string">'echo Preprocessing'</span> -c <span class="string">'echo Test'</span> _</span><br><span class="line">+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> Preprocessing           │</span><br><span class="line">│Preprocessing                  │</span><br><span class="line">│$ <span class="built_in">echo</span> Test                    │</span><br><span class="line">│Test                           │</span><br><span class="line">│                               │</span><br><span class="line">+-------------------------------+</span><br><span class="line"></span><br><span class="line">$ xpanes -B <span class="string">'echo Pre1'</span> -B <span class="string">'echo Pre2'</span> -B <span class="string">'echo Pre3'</span> -c <span class="string">'echo &#123;&#125;'</span> A B C D</span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> Pre1                    │$ <span class="built_in">echo</span> Pre1                   │</span><br><span class="line">│Pre1                           │Pre1                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre2                    │$ <span class="built_in">echo</span> Pre2                   │</span><br><span class="line">│Pre2                           │Pre2                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre3                    │$ <span class="built_in">echo</span> Pre3                   │</span><br><span class="line">│Pre3                           │Pre3                          │</span><br><span class="line">│$ <span class="built_in">echo</span> A                       │$ <span class="built_in">echo</span> B                      │</span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> Pre1                    │$ <span class="built_in">echo</span> Pre1                   │</span><br><span class="line">│Pre1                           │Pre1                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre2                    │$ <span class="built_in">echo</span> Pre2                   │</span><br><span class="line">│Pre2                           │Pre2                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre3                    │$ <span class="built_in">echo</span> Pre3                   │</span><br><span class="line">│Pre3                           │Pre3                          │</span><br><span class="line">│$ <span class="built_in">echo</span> C                       │$ <span class="built_in">echo</span> D                      │</span><br><span class="line">+-------------------------------+------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-C</code> 和 <code>-R</code> 参数，来控制窗口的列和行。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes -C 2 AAA BBB CCC DDD</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> AAA                    │$ <span class="built_in">echo</span> BBB                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> CCC                    │$ <span class="built_in">echo</span> DDD                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line"></span><br><span class="line">$ xpanes -R 5 AAA BBB CCC DDD EEE FFF GGG HHH</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> AAA                    │$ <span class="built_in">echo</span> BBB                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> CCC                    │$ <span class="built_in">echo</span> DDD                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> EEE                    │$ <span class="built_in">echo</span> FFF                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> GGG                                                   │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> HHH                                                   │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>--bulk-cols</code> 参数可以接受逗号分隔的数字，每个数字对应每一行的列数。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes --bulk-cols=1,3,1,2,5 &#123;A..L&#125;</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> A                                                     │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> B            │$ <span class="built_in">echo</span> C            │$ <span class="built_in">echo</span> D           │</span><br><span class="line">│                    │                    │                   │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> E                                                     │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> F                      │$ <span class="built_in">echo</span> G                      │</span><br><span class="line">│                              │                              │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> H     │$ <span class="built_in">echo</span> I    │$ <span class="built_in">echo</span> J    │$ <span class="built_in">echo</span> K   │$ <span class="built_in">echo</span> L │</span><br><span class="line">│             │            │            │           │         │</span><br><span class="line">+-------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li>当 <code>xpanes</code> 命令接受标准输入时，将激活管道模式。在这种模式下，<code>xpanes</code> 的行为类似于 <code>UNIX</code> 系统的 <code>xargs</code> 命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ seq 3 | xpanes</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 1                      │$ <span class="built_in">echo</span> 2                      │</span><br><span class="line">│1                             │2                             │</span><br><span class="line">│                              │                              │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 3                                                     │</span><br><span class="line">│3                                                            │</span><br><span class="line">│                                                             │</span><br><span class="line">│                                                             │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line"></span><br><span class="line">$ seq 4 | xpanes seq</span><br><span class="line">$ seq 4 | xpanes -c <span class="string">'seq &#123;&#125;'</span></span><br><span class="line">$ cat ~/.ssh/config | awk <span class="string">'$1=="Host"&#123;print $2&#125;'</span> | xpanes ssh</span><br></pre></td></tr></table></figure><ul><li>恢复断开连接的会话，即出现异常情况的话，终端断开连接，我们也可以使用 <code>xpanes</code> 来恢复 <code>Tmux</code> 会话。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认情况会创建：~/.cache/xpanes/socket.&lt;PID&gt;</span></span><br><span class="line">$ ls ~/.cache/xpanes/socket.*</span><br><span class="line">/home/user/.cache/xpanes/socket.1234</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话恢复</span></span><br><span class="line">$ tmux -S /home/user/.cache/xpanes/socket.1234 attach</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-S</code> 参数，与他人共享终端会话</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 与他人共享终端会话 - user1</span></span><br><span class="line">[user1@host] $ xpanes -S /home/user1/mysocket a b c d ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 与他人共享终端会话 - user2</span></span><br><span class="line">[user2@host] $ tmux -S /home/user1/mysocket attach</span><br></pre></td></tr></table></figure><h2><span id="一个彩蛋">一个彩蛋</span></h2><blockquote><p>Let’s play!</p></blockquote><ul><li>terminal-parrot</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yes terminal-parrot | head -n 25 | xpanes -e</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/learn-tmux-xpanes-tools-03-2021-07-09-O0WfZo.gif" alt="使用xpanes来并发执行命令 - terminal-parrot"></p><ul><li>sl</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yes <span class="string">'sl -l'</span> | head | xpanes -elev</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/learn-tmux-xpanes-tools-02-2021-07-09-umfszo.gif" alt="使用xpanes来并发执行命令 - sl"></p><h2><span id="参考文档">参考文档</span></h2><ul><li><a href="https://github.com/greymd/tmux-xpanes" target="_blank" rel="noopener">github tmux-xpanes</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客]」，原文：<a href="https://tinyurl.com/y6jrmejf" target="_blank" rel="noopener">https://tinyurl.com/y6jrmejf</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;由 Tmux 提供支持的终极终端分屏器！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;虽然我们已经可以使用 &lt;code&gt;tmux&lt;/code&gt; 进行屏幕的分割和切换，但是如果需要对一批服务器进行操作的话，就只能一个一个的登录和执行了。如果使用过 &lt;code&gt;Xshell&lt;/code&gt; 或者其他远程工具的话，肯定是使用过这个功能特性的，一次命令输出可以在登录的多个远程终端上面执行。现在我们可以使用 &lt;code&gt;tmux-xpanes&lt;/code&gt; 来完成同样的事情了，撒花！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Xpanes" scheme="https://www.hi-linux.com/tags/Xpanes/"/>
    
  </entry>
  
  <entry>
    <title>一次由 Kubernetes HostPort 引发的服务故障排错记实</title>
    <link href="https://www.hi-linux.com/posts/43908.html"/>
    <id>https://www.hi-linux.com/posts/43908.html</id>
    <published>2021-08-03T01:00:00.000Z</published>
    <updated>2021-08-03T04:43:39.254Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近排查了一个 Kubernetes 中使用了 hostport 后遇到比较坑的问题，奇怪的知识又增加了。</p><h2><span id="问题背景">问题背景</span></h2><p>集群环境为 K8s v1.15.9，cni 指定了 flannel-vxlan 跟 portmap, kube-proxy 使用 mode 为 ipvs，集群 3 台 master,同时也是 node，这里以 node-1,node-2,node-3 来表示。</p><p>集群中有 2 个 mysql, 部署在两个 ns 下，mysql 本身不是问题重点，这里就不细说，这里以 mysql-A,mysql-B 来表示。</p><p>mysql-A 落在 node-1 上，mysql-B  落在 node-2 上， <strong>两个数据库svc名跟用户、密码完全不相同</strong></p><a id="more"></a><p>出现诡异的现象这里以一张图来说明会比较清楚一些:</p><p><img src="https://img.hi-linux.com/staticfile/20210729220711-2021-08-02-7dLd8i.png" alt></p><p>其中绿线的表示访问没有问题，红线表示连接Mysql-A提示用户名密码错误</p><p>特别诡异的是，当在 Node-2 上通过 svc 访问 Mysql-A 时，输入 Mysql-A 的用户名跟密码提示密码错误，密码确认无疑，但当输入 Mysql-B 的用户名跟密码，居然能够连接上，看了下数据，连上的是 Mysql-B 的数据库，给人的感觉就是请求转到了 Mysql-A, 最后又转到了 Mysql-B，当时让人大跌眼镜。</p><p>碰到诡异的问题那就排查吧，排查的过程倒是不费什么事，最主要的是要通过这次踩坑机会挖掘一些奇怪的知识出来。</p><h2><span id="排查过程">排查过程</span></h2><p>既然在 Node-1 上连接 Mysql-A/Mysql-B 都没有问题，那基本可以排查是 Mysql-A 的问题</p><p>经实验，在 Node-2 上所有的服务想要连 Mysql-A 时，都有这个问题，但是访问其它的服务又都没有问题，说明要么是 mysql-A 的 3306 这个端口有问题，通过上一步应该排查了 mysql-A 的问题，那问题只能出在 Node-2 上</p><p>在 k8s 中像这样的请求转发出现诡异现象，当排除了一些常见的原因之外，最大的嫌疑就是 iptables 了，作者遇到过多次</p><p>这次也不例外，虽然当前集群使用的 ipvs， 但还是照例看下 iptables 规则，查看 Node-2 上的 iptables 与 Node-1 的 iptables 比对，结果有蹊跷, 在 Node-2 上发现有以下的规则在其它节点上没有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-A CNI-DN-xxxx -p tcp -m tcp --dport 3306 -j DNAT --to-destination 10.224.0.222:3306</span><br><span class="line">-A CNI-HOSTPORT-DNAT -m comment --comment &quot;dnat name&quot;: \&quot;cni0\&quot; id: \&quot;xxxxxxxxxxxxx\&quot;&quot; -j CNI-DN-xxx</span><br><span class="line">-A CNI-HOSTPORT-SNAT -m comment --comment &quot;snat name&quot;: \&quot;cni0\&quot; id: \&quot;xxxxxxxxxxxxx\&quot;&quot; -j CNI-SN-xxx</span><br><span class="line">-A CNI-SN-xxx -s 127.0.0.1&#x2F;32 -d 10.224.0.222&#x2F;32 -p tcp -m tcp --dport 80 -j MASQUERADE</span><br></pre></td></tr></table></figure><p>其中 10.224.0.222 为 Mysql-B 的 pod ip, xxxxxxxxxxxxx 经查实为 Mysql-B 对应的 pause 容器的id</p><p>从上面的规则总结一下就是目的为 3306 端口的请求都会转发到 10.224.0.222 这个地址，即 Mysql-B</p><p>看到这里，作者明白了为什么在 Node-2 上去访问 Node-1 上 Mysql-A 的 3306 会提示密码错误而输入 Mysql-B 的密码却可以正常访问</p><p>虽然两个 mysql 的 svc 名不一样，但上面的 iptables 只要目的端口是 3306 就转发到 Mysql-B 了，当请求到达 mysql 后，使用正确的用户名密码自然可以登录成功</p><p>原因是找到了，但是又引出来了更多的问题?</p><ol><li>这几条规则是谁入到 iptables 中的？</li><li>怎么解决呢，是不是删掉就可以?</li></ol><h2><span id="问题复现">问题复现</span></h2><p>同样是 Mysql，为何 Mysql-A 没有呢? 那么比对一下这两个 Mysql 的部署差异</p><p>比对发现, 除了用户名密码，ns 不一样外，Mysql-B 部署时使用了 hostPort=3306, 其它的并无异常</p><p>难道是因为 hostPort ？</p><p>作者日常会使用 NodePort，倒却是没怎么在意 hostPort,也就停留在 hostPort 跟 NodePort 的差别在于 NodePort 是所有 Node 上都会开启端口，而 hostPort 只会在运行机器上开启端口，由于 hostPort 使用的也少，也就没太多关注，网上短暂搜了一番，描述的也不是很多，看起来大家也用的不多</p><p>那到底是不是因为 hostPort 呢?</p><p><strong>Talk is cheap, show me the code</strong></p><p>通过实验来验证，这里简单使用了三个nginx来说明问题, 其中两个使用了 hostPort，这里特意指定了不同的端口，其它的都完全一样，发布到集群中，yaml 文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-hostport2</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-hostport2</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: nginx-hostport2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: nginx-hostport2</span><br><span class="line">    spec:</span><br><span class="line">      nodeName: spring-38</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:latest</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">              hostPort: 31123</span><br></pre></td></tr></table></figure><p>Finally,问题复现:</p><p><img src="https://img.hi-linux.com/staticfile/20210728133243-2021-08-02-FIx5Us.png" alt></p><p>可以肯定，这些规则就是因为使用了 hostPort 而写入的,但是 <strong>由谁写入的这个问题还是没有解决?</strong></p><h2><span id="罪魁祸首">罪魁祸首</span></h2><p>作者开始以为这些 iptables 规则是由 kube-proxy 写入的, 但是查看 kubelet 的源码并未发现上述规则的关键字</p><p>再次实验及结合网上的探索，可以得到以下结论:</p><p>首先从 kubernetes 的官方发现以下描述:</p><blockquote><p>The CNI networking plugin supports <code>hostPort</code>. You can use the official <a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/portmap" target="_blank" rel="noopener">portmap</a> plugin offered by the CNI plugin team or use your own plugin with portMapping functionality.</p></blockquote><blockquote><p>If you want to enable <code>hostPort</code> support, you must specify <code>portMappings capability</code> in your <code>cni-conf-dir</code>. For example:<br>{<br>“name”: “k8s-pod-network”,<br>“cniVersion”: “0.3.0”,<br>“plugins”: [<br>{<br># …其它的plugin<br>}<br>{<br>“type”: “portmap”,<br>“capabilities”: {“portMappings”: true}<br>}<br>]<br>}</p><p>参考: <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/</a></p></blockquote><p><strong>也就是如果使用了 hostPort， 是由 portmap 这个 cni 提供 portMapping 能力，同时，如果想使用这个能力，在配置文件中一定需要开启 portmap，这个在作者的集群中也开启了，这点对应上了</strong></p><p>另外一个比较重要的结论是:</p><blockquote><p>The CNI ‘portmap’ plugin, used to setup HostPorts for CNI, inserts rules at the front of the iptables nat chains; which take precedence over the KUBE- SERVICES chain. Because of this, the HostPort/portmap rule could match incoming traffic even if there were better fitting, more specific service definition rules like NodePorts later in the chain</p><p>参考: <a href="https://ubuntu.com/security/CVE-2019-9946" target="_blank" rel="noopener">https://ubuntu.com/security/CVE-2019-9946</a></p></blockquote><p><strong>翻译过来就是使用 hostPort 后，会在 iptables 的 nat 链中插入相应的规则，而且这些规则是在 KUBE- SERVICES 规则之前插入的，也就是说会优先匹配 hostPort 的规则，我们常用的 NodePort 规则其实是在 KUBE- SERVICES 之中，也排在其后</strong></p><p>从 portmap 的源码中果然是可以看到相应的代码</p><p><img src="https://img.hi-linux.com/staticfile/20210729225847-2021-08-02-aHFg9f.png" alt></p><p>感兴趣的可以的<a href="https://github.com/containernetworking/plugins.git" target="_blank" rel="noopener"> plugins </a>项目的 meta/portmap/portmap.go 中查看完整的源码</p><p>所以，<strong>最终是调用portmap写入的这些规则.</strong></p><h2><span id="端口占用">端口占用</span></h2><p>进一步实验发现，hostport 可以通过 iptables 命令查看到， 但是无法在 ipvsadm 中查看到</p><p><strong>使用 lsof/netstat 也查看不到这个端口,这是因为 hostport 是通过 iptables 对请求中的目的端口进行转发的，并不是在主机上通过端口监听</strong></p><p><img src="https://img.hi-linux.com/staticfile/20210728133203-2021-08-02-TYPI7H.png" alt></p><p>既然 lsof 跟 netstat 都查不到端口信息，那这个端口相当于没有处于 listen 状态?</p><p>如果这时再部署一个 hostport 指定相同端口的应用会怎么样呢?</p><p>结论是: <strong>使用 hostPort 的应用在调度时无法调度在已经使用过相同 hostPort 的主机上，也就是说，在调度时会考虑 hostport</strong></p><p>如果强行让其调度在同一台机器上，那么就会出现以下错误，如果不删除的话，这样的错误会越来越多，吓的作者赶紧删了.</p><p><img src="https://img.hi-linux.com/staticfile/20210728132630-2021-08-02-B7YGwm.png" alt></p><p>如果这个时候创建一个 nodePort 类型的 svc， 端口也为 31123,结果会怎么样呢?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-nodeport2</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-nodeport2</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: nginx-nodeport2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: nginx-nodeport2</span><br><span class="line">    spec:</span><br><span class="line">      nodeName: spring-38</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:latest</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-nodeport2</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">    nodePort: 31123</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: nginx-nodeport2</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/20210728133425-2021-08-02-Tsej5S.png" alt></p><p>可以发现，NodePort 是可以成功创建的，同时监听的端口也出现了.</p><p><strong>从这也可以说明使用 hostposrt 指定的端口并没有 listen 主机的端口，要不然这里就会提示端口重复之类</strong></p><p>那么问题又来了，同一台机器上同时存在有 hostPort 跟 nodePort 的端口，这个时候如果 curl 31123 时， 访问的是哪一个呢?</p><p>经多次使用 curl 请求后，均是使用了 hostport 那个 nginx pod 收到请求</p><p><strong>原因还是因为 KUBE-NODE-PORT 规则在 KUBE-SERVICE 的链中是处于最后位置，而 hostPort 通过 portmap 写入的规则排在其之前</strong></p><p><img src="https://img.hi-linux.com/staticfile/20210728142725-2021-08-02-JE3uRL.png" alt></p><p>因此会先匹配到 hostport 的规则，自然请求就被转到 hostport 所在的 pod 中，这两者的顺序是没办法改变的，因此无论是 hostport 的应用发布在前还是在后都无法影响请求转发</p><p>另外再提一下，<strong>hostport 的规则在 ipvsadm 中是查询不到的，而 nodePort 的规则则是可以使用 ipvsadm 查询得到</strong></p><h2><span id="问题解决">问题解决</span></h2><p>要想把这些规则删除，可以直接将 hostport 去掉，那么规则就会随着删除,比如下图中去掉了一个 nginx 的 hostport</p><p><img src="https://img.hi-linux.com/staticfile/20210727230931-2021-08-02-DHTY1f.png" alt></p><p>另外使用较多的 port-forward 也是可以进行端口转发的，它又是个什么情况呢? 它其实使用的是 socat 及 netenter 工具，网上看到一篇文章，原理写的挺好的，感兴趣的可以看一看</p><blockquote><p>参考: <a href="https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html" target="_blank" rel="noopener">https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html</a></p></blockquote><h2><span id="生产建议">生产建议</span></h2><p>一句话，生产环境除非是 <strong>必要且无他法</strong>，不然<strong>一定不要使用hostport</strong>，除了会影响调度结果之外，还会出现上述问题，可能造成的后果是非常严重的。</p><h2><span id="参考文章">参考文章</span></h2><ul><li><a href="https://www.qikqiak.com/post/how-to-use-ipvs-in-kubernetes/" target="_blank" rel="noopener">https://www.qikqiak.com/post/how-to-use-ipvs-in-kubernetes/</a></li><li><a href="https://serenafeng.github.io/2020/03/26/kube-proxy-in-iptables-mode/" target="_blank" rel="noopener">https://serenafeng.github.io/2020/03/26/kube-proxy-in-iptables-mode/</a></li><li><a href="https://zhuanlan.zhihu.com/p/94418251" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/94418251</a></li><li><a href="https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/" target="_blank" rel="noopener">https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/</a></li><li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/</a></li><li><a href="https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html" target="_blank" rel="noopener">https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html</a></li></ul><blockquote><p>本文转载自：「 Z.S.K.'s Records 」，原文：<a href="https://tinyurl.com/35dczb5d" target="_blank" rel="noopener">https://tinyurl.com/35dczb5d</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近排查了一个 Kubernetes 中使用了 hostport 后遇到比较坑的问题，奇怪的知识又增加了。&lt;/p&gt;
&lt;h2 id=&quot;问题背景&quot;&gt;问题背景&lt;/h2&gt;
&lt;p&gt;集群环境为 K8s v1.15.9，cni 指定了 flannel-vxlan 跟 portmap, kube-proxy 使用 mode 为 ipvs，集群 3 台 master,同时也是 node，这里以 node-1,node-2,node-3 来表示。&lt;/p&gt;
&lt;p&gt;集群中有 2 个 mysql, 部署在两个 ns 下，mysql 本身不是问题重点，这里就不细说，这里以 mysql-A,mysql-B 来表示。&lt;/p&gt;
&lt;p&gt;mysql-A 落在 node-1 上，mysql-B  落在 node-2 上， &lt;strong&gt;两个数据库svc名跟用户、密码完全不相同&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>再见 Kubernetes，是时候拥抱下一代轻量级容器编排平台 K0s 了！</title>
    <link href="https://www.hi-linux.com/posts/9354.html"/>
    <id>https://www.hi-linux.com/posts/9354.html</id>
    <published>2021-08-02T01:00:00.000Z</published>
    <updated>2021-08-02T01:39:16.131Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>最近两年一直在使用 kubeadm 部署 kubernetes 集群，总体来说配合一些自己小脚本还有一些自动化工具还算是方便；但是全容器化稳定性确实担忧，也遇到过莫名其妙的证书过期错误，最后重启大法解决这种问题；所以也在探索比较方便的二进制部署方式，比如这个 k0s。</p></blockquote><h2><span id="k0s-介绍">k0s 介绍</span></h2><blockquote><p>The Simple, Solid &amp; Certified Kubernetes Distribution.</p></blockquote><p>k0s 可以认为是一个下游的 Kubernetes 发行版，与原生 Kubernetes 相比，k0s 并未阉割大量 Kubernetes 功能；k0s 主要阉割部分基本上只有 <strong>树内 Cloud provider</strong>，其他的都与原生 Kubernetes 相同。</p><p><strong>k0s 自行编译 Kubernetes 源码生成 Kubernetes 二进制文件，然后在安装后将二进制文件释放到宿主机再启动；这种情况下所有功能几乎与原生 Kubernetes 没有差异。</strong></p><h2><span id="k0sctl-使用">k0sctl 使用</span></h2><p>k0sctl 是 k0s 为了方便快速部署集群所提供的工具，有点类似于 kubeadm，但是其扩展性要比 kubeadm 好得多。在多节点的情况下，k0sctl 通过 ssh 连接目标主机然后按照步骤释放文件并启动 Kubernetes 相关服务，从而完成集群初始化。</p><a id="more"></a><h3><span id="21-使用-k0sctl-安装集群">2.1 使用 k0sctl 安装集群</span></h3><p>安装过程中会自动下载相关镜像，需要保证所有节点可以科学上网，如何离线安装我们后面讲解。<strong>安装前，你需要保证目标机器的 hostname 为非域名形式，否则可能会出现一些问题。</strong> 以下是一个简单的启动集群示例:</p><ul><li>首先安装 k0sctl</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装 k0sctl</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;k0sproject&#x2F;k0sctl&#x2F;releases&#x2F;download&#x2F;v0.9.0&#x2F;k0sctl-linux-x64</span><br><span class="line">$ chmod +x k0sctl-linux-x64</span><br><span class="line">$ mv k0sctl-linux-x64 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;k0sctl</span><br></pre></td></tr></table></figure><ul><li>然后编写 k0sctl.yaml 配置文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">$ vi k0sctl.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.12</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.13</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.14</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.15</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">  k0s:</span><br><span class="line">    version: 1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          address: 10.0.0.11</span><br><span class="line">          port: 6443</span><br><span class="line">          k0sApiPort: 9443</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">        storage:</span><br><span class="line">          type: etcd</span><br><span class="line">          etcd:</span><br><span class="line">            peerAddress: 10.0.0.11</span><br><span class="line">        network:</span><br><span class="line">          kubeProxy:</span><br><span class="line">            disabled: false</span><br><span class="line">            mode: ipvs</span><br></pre></td></tr></table></figure><p>当然你也可以通过 <code>k0sctl init --k0s  &gt; k0sctl.yaml</code> 命令直接生成。</p><ul><li>最后执行 <code>k0sctl apply</code> 命令安装即可</li></ul><blockquote><p>安装前确保你的操作机器可以 SSH 免密登陆所有目标机器。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ k0sctl apply -c k0sctl.yaml</span><br><span class="line"></span><br><span class="line">⠀⣿⣿⡇⠀⠀⢀⣴⣾⣿⠟⠁⢸⣿⣿⣿⣿⣿⣿⣿⡿⠛⠁⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀█████████ █████████ ███</span><br><span class="line">⠀⣿⣿⡇⣠⣶⣿⡿⠋⠀⠀⠀⢸⣿⡇⠀⠀⠀⣠⠀⠀⢀⣠⡆⢸⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀███          ███    ███</span><br><span class="line">⠀⣿⣿⣿⣿⣟⠋⠀⠀⠀⠀⠀⢸⣿⡇⠀⢰⣾⣿⠀⠀⣿⣿⡇⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀███          ███    ███</span><br><span class="line">⠀⣿⣿⡏⠻⣿⣷⣤⡀⠀⠀⠀⠸⠛⠁⠀⠸⠋⠁⠀⠀⣿⣿⡇⠈⠉⠉⠉⠉⠉⠉⠉⠉⢹⣿⣿⠀███          ███    ███</span><br><span class="line">⠀⣿⣿⡇⠀⠀⠙⢿⣿⣦⣀⠀⠀⠀⣠⣶⣶⣶⣶⣶⣶⣿⣿⡇⢰⣶⣶⣶⣶⣶⣶⣶⣶⣾⣿⣿⠀█████████    ███    ██████████</span><br><span class="line"></span><br><span class="line">k0sctl 0.0.0 Copyright 2021, k0sctl authors.</span><br><span class="line">Anonymized telemetry of usage will be sent to the authors.</span><br><span class="line">By continuing to use k0sctl you agree to these terms:</span><br><span class="line">https:&#x2F;&#x2F;k0sproject.io&#x2F;licenses&#x2F;eula</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Connect to hosts</span><br><span class="line">INFO [ssh] 10.0.0.15:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.11:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.12:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.14:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.13:22: connected</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Detect host operating systems</span><br><span class="line">INFO [ssh] 10.0.0.11:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.12:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.14:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.13:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.15:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Prepare hosts</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Gather host facts</span><br><span class="line">INFO [ssh] 10.0.0.11:22: discovered ens33 as private interface</span><br><span class="line">INFO [ssh] 10.0.0.13:22: discovered ens33 as private interface</span><br><span class="line">INFO [ssh] 10.0.0.12:22: discovered ens33 as private interface</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Download k0s on hosts</span><br><span class="line">INFO [ssh] 10.0.0.11:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.13:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.12:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.15:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.14:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>稍等片刻后带有三个 Master 和两个 Node 的集群将安装完成:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ k1.node ➜ ~ k0s kubectl get node -o wide</span><br><span class="line">NAME      STATUS   ROLES    AGE   VERSION       INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span><br><span class="line">k1.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.11     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k2.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.12     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k3.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.13     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k4.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.14     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k5.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.15     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br></pre></td></tr></table></figure><blockquote><p>注意: 目标机器 hostname 不应当为域名形式，这里的样例是已经修复了这个问题</p></blockquote><h3><span id="22-k0sctl-的扩展方式">2.2 k0sctl 的扩展方式</span></h3><p>与 kubeadm 不同，k0sctl 几乎提供了所有安装细节的可定制化选项，其通过三种行为来完成扩展:</p><ul><li><strong>文件上传:</strong> k0sctl 允许定义在安装前的文件上传，在安装之前 k0sctl 会把已经定义的相关文件全部上传到目标主机，包括不限于 k0s 本身二进制文件、离线镜像包、其他安装文件、其他辅助脚本等。</li><li><strong>Manifests 与 Helm:</strong> 当将特定的文件上传到 master 节点的 <code>/var/lib/k0s/manifests</code> 目录时，k0s 在安装过程中会自动应用这些配置，类似 kubelet 的 static pod 一样，只不过 k0s 允许全部资源(包括不限于 deployment、daemonset、namespace 等)；同样也可以直接在 <code>k0sctl.yaml</code> 添加 Helm 配置，k0s 也会以同样的方式帮你管理。</li><li><strong>辅助脚本:</strong> 可以在每个主机下配置 <code>hooks</code> 选项来实现执行一些特定的脚本(文档里没有，需要看源码)，以便在特定情况下做点骚操作。</li></ul><h3><span id="23-k0sctl-使用离线镜像包">2.3 k0sctl 使用离线镜像包</span></h3><p>基于上面的扩展，k0s 还方便的帮我们集成了离线镜像包的自动导入，我们只需要定义一个文件上传，将镜像包上传到 <code>/var/lib/k0s/images/</code> 目录后，k0s 会自定将其倒入到 containerd 中而无需我们手动干预:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    # files 配置将会在安装前将相关文件上传到目标主机</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      # 在该目录下的 image 压缩包将会被自动导入到 containerd 中</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p><strong>关于 image 压缩包(bundle_file)如何下载以及自己自定义问题请参考官方 <a href="https://docs.k0sproject.io/v1.21.2+k0s.1/airgap-install/" target="_blank" rel="noopener">Airgap install</a> 文档。</strong></p><p><img src="https://img.hi-linux.com/staticfile/LJIS7j-2021-07-30-GcLOTb.png" alt></p><h3><span id="24-切换-cni-插件">2.4 切换 CNI 插件</span></h3><p>默认情况下 k0s 内部集成了两个 CNI 插件: Calico 和 kube-router。如果我们需要使用其他的 CNI 插件，例如 Flannel，我们只需要将默认的 CNI 插件设置为 <code>custom</code>，然后将 Flannel 的部署 YAML 上传到一台 master 的 <code>/var/lib/k0s/manifests</code> 目录即可，k0s 会自动帮我门执行 <code>apply -f xxxx.yaml</code> 这种操作。</p><p>下面是切换到 Flannel 的样例，需要注意的是 Flannel 官方镜像不会帮你安装 CNI 的二进制文件，我们需要借助文件上传自己安装(<a href="https://github.com/containernetworking/plugins/releases" target="_blank" rel="noopener">CNI GitHub 插件下载地址</a>):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    files:</span><br><span class="line">    # 将 flannel 的 yaml 放到 manifests 里(需要单独创建一个目录)</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">    # 自己安装一下 CNI 插件</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  k0s:</span><br><span class="line">    version: v1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          address: 10.0.0.11</span><br><span class="line">          port: 6443</span><br><span class="line">          k0sApiPort: 9443</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">        storage:</span><br><span class="line">          type: etcd</span><br><span class="line">        network:</span><br><span class="line">          podCIDR: 10.244.0.0&#x2F;16</span><br><span class="line">          serviceCIDR: 10.96.0.0&#x2F;12</span><br><span class="line">          # 这里指定 CNI 为 custom 自定义类型，这样</span><br><span class="line">          # k0s 就不会安装 calico&#x2F;kube-router 了</span><br><span class="line">          provider: custom</span><br></pre></td></tr></table></figure><h3><span id="25-上传-k0s-二进制文件">2.5 上传 k0s 二进制文件</span></h3><p>除了普通文件、镜像压缩包等，默认情况下 k0sctl 在安装集群时还会在目标机器上下载 k0s 二进制文件；当然在离线环境下这一步也可以通过一个简单的配置来实现离线上传:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    # 声明需要上传二进制文件</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    # 指定二进制文件位置</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h3><span id="26-更换镜像版本">2.6 更换镜像版本</span></h3><p>默认情况下 k0s 版本号与 Kubernetes 保持一致，但是如果期望某个组件使用特定的版本，则可以直接配置这些内置组件的镜像名称:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">......</span><br><span class="line">  k0s:</span><br><span class="line">    version: v1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          address: 10.0.0.11</span><br><span class="line">          port: 6443</span><br><span class="line">          k0sApiPort: 9443</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">        # 指定内部组件的镜像使用的版本</span><br><span class="line">        images:</span><br><span class="line">          #konnectivity:</span><br><span class="line">          #  image: us.gcr.io&#x2F;k8s-artifacts-prod&#x2F;kas-network-proxy&#x2F;proxy-agent</span><br><span class="line">          #  version: v0.0.21</span><br><span class="line">          #metricsserver:</span><br><span class="line">          #  image: gcr.io&#x2F;k8s-staging-metrics-server&#x2F;metrics-server</span><br><span class="line">          #  version: v0.3.7</span><br><span class="line">          kubeproxy:</span><br><span class="line">            image: k8s.gcr.io&#x2F;kube-proxy</span><br><span class="line">            version: v1.21.3</span><br><span class="line">          #coredns:</span><br><span class="line">          #  image: docker.io&#x2F;coredns&#x2F;coredns</span><br><span class="line">          #  version: 1.7.0</span><br><span class="line">          #calico:</span><br><span class="line">          #  cni:</span><br><span class="line">          #    image: docker.io&#x2F;calico&#x2F;cni</span><br><span class="line">          #    version: v3.18.1</span><br><span class="line">          #  node:</span><br><span class="line">          #    image: docker.io&#x2F;calico&#x2F;node</span><br><span class="line">          #    version: v3.18.1</span><br><span class="line">          #  kubecontrollers:</span><br><span class="line">          #    image: docker.io&#x2F;calico&#x2F;kube-controllers</span><br><span class="line">          #    version: v3.18.1</span><br><span class="line">          #kuberouter:</span><br><span class="line">          #  cni:</span><br><span class="line">          #    image: docker.io&#x2F;cloudnativelabs&#x2F;kube-router</span><br><span class="line">          #    version: v1.2.1</span><br><span class="line">          #  cniInstaller:</span><br><span class="line">          #    image: quay.io&#x2F;k0sproject&#x2F;cni-node</span><br><span class="line">          #    version: 0.1.0</span><br><span class="line">          default_pull_policy: IfNotPresent</span><br><span class="line">          #default_pull_policy: Never</span><br></pre></td></tr></table></figure><h3><span id="27-调整-master-组件参数">2.7 调整 master 组件参数</span></h3><p>熟悉 Kubernetes 的应该清楚，master 上三大组件: apiserver、controller、scheduler 管控整个集群；在 k0sctl 安装集群的过程中也允许自定义这些组件的参数，这些调整通过修改使用的 <code>k0sctl.yaml</code> 配置文件完成。</p><ul><li><code>spec.api.extraArgs</code>: 用于自定义 kube-apiserver 的自定义参数(kv map)</li><li><code>spec.scheduler.extraArgs</code>: 用于自定义 kube-scheduler 的自定义参数(kv map)</li><li><code>spec.controllerManager.extraArgs</code>: 用于自定义 kube-controller-manager 自定义参数(kv map)</li><li><code>spec.workerProfiles</code>: 用于覆盖 kubelet-config.yaml 中的配置，该配置最终将于默认的 kubelet-config.yaml 合并</li></ul><p>除此之外在 <code>Host</code> 配置中还有一个 <code>InstallFlags</code> 配置用于传递 k0s 安装时的其他配置选项。</p><h2><span id="k0s-ha-搭建">K0s HA 搭建</span></h2><blockquote><p>上面的第二部分主要都是介绍 k0sctl 一些基础功能，为的就是给下面这部分 HA 生产级部署做铺垫。</p></blockquote><p>就目前来说，k0s HA 仅支持独立负载均衡器的 HA 架构。 <strong>即外部需要有一个高可用的 4 层负载均衡器，其他所有 Node 节点链接这个负载均衡器实现 master 的高可用。</strong> 在使用 k0sctl 命令搭建 HA 集群时很简单，只需要添加一个外部负载均衡器地址即可。</p><p>以下是一个完整的，全离线状态下的 HA 集群搭建配置。</p><h3><span id="31-外部负载均衡器">3.1 外部负载均衡器</span></h3><p><strong>在搭建之前我们假设已经有一个外部的高可用的 4 层负载均衡器，且负载均衡器已经负载了以下端口:</strong></p><ul><li><code>6443(for Kubernetes API)</code>: 负载均衡器 6443 负载所有 master 节点的 6443</li><li><code>9443 (for controller join API)</code>: 负载均衡器 9443 负载所有 master 节点的 9443</li><li><code>8132 (for Konnectivity agent)</code>: 负载均衡器 8132 负载所有 master 节点的 8132</li><li><code>8133 (for Konnectivity server)</code>: 负载均衡器 8133 负载所有 master 节点的 8133</li></ul><p>以下为一个 Nginx 4 层代理的样例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">error_log syslog:server&#x3D;unix:&#x2F;dev&#x2F;log notice;</span><br><span class="line"></span><br><span class="line">worker_processes auto;</span><br><span class="line">events &#123;</span><br><span class="line">multi_accept on;</span><br><span class="line">use epoll;</span><br><span class="line">worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line">    upstream kube_apiserver &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:6443;</span><br><span class="line">        server 10.0.0.12:6443;</span><br><span class="line">        server 10.0.0.13:6443;</span><br><span class="line">    &#125;</span><br><span class="line">    upstream konnectivity_agent &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:8132;</span><br><span class="line">        server 10.0.0.12:8132;</span><br><span class="line">        server 10.0.0.13:8132;</span><br><span class="line">    &#125;</span><br><span class="line">    upstream konnectivity_server &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:8133;</span><br><span class="line">        server 10.0.0.12:8133;</span><br><span class="line">        server 10.0.0.13:8133;</span><br><span class="line">    &#125;</span><br><span class="line">    upstream controller_join_api &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:9443;</span><br><span class="line">        server 10.0.0.12:9443;</span><br><span class="line">        server 10.0.0.13:9443;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:6443;</span><br><span class="line">        proxy_pass    kube_apiserver;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:8132;</span><br><span class="line">        proxy_pass    konnectivity_agent;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:8133;</span><br><span class="line">        proxy_pass    konnectivity_server;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:9443;</span><br><span class="line">        proxy_pass    controller_join_api;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="32-搭建-k0s-ha-集群">3.2 搭建 K0s HA 集群</span></h3><p>以下为 k0sctl 的 HA + 离线部署样例配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    # role 支持的值</span><br><span class="line">    # &#39;controller&#39; 单 master</span><br><span class="line">    # &#39;worker&#39; 单 worker</span><br><span class="line">    # &#39;controller+worker&#39; master 和 worker 都运行 </span><br><span class="line">    role: controller+worker</span><br><span class="line">    </span><br><span class="line">    # 从本地 上传 k0s bin 文件，不要在目标机器下载</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    </span><br><span class="line">    # 上传其他文件</span><br><span class="line">    files:</span><br><span class="line">    # 上传 flannel 配置，使用自定的 flannel 替换内置的 calico</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">    </span><br><span class="line">    # 上传打包好的 image 镜像包，k0s 会自动导入到 containerd</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    </span><br><span class="line">    # 使用 flannel 后每个机器要上传对应的 CNI 插件</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.12</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.13</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.14</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.15</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  k0s:</span><br><span class="line">    version: v1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          # 此处填写外部的负载均衡器地址，所有 kubelet 会链接这个地址</span><br><span class="line">          externalAddress: 10.0.0.20</span><br><span class="line">          # 不要忘了为外部负载均衡器添加 api 证书的 SAN</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">          - 10.0.0.20</span><br><span class="line">        # 存储类型使用 etcd，etcd 集群由 k0s 自动管理</span><br><span class="line">        storage:</span><br><span class="line">          type: etcd</span><br><span class="line">        network:</span><br><span class="line">          podCIDR: 10.244.0.0&#x2F;16</span><br><span class="line">          serviceCIDR: 10.96.0.0&#x2F;12</span><br><span class="line">          # 网络插件使用 custom，然后让 flannel 接管</span><br><span class="line">          provider: custom</span><br><span class="line">          kubeProxy:</span><br><span class="line">            disabled: false</span><br><span class="line">            # 开启 kubelet 的 ipvs 模式</span><br><span class="line">            mode: ipvs</span><br><span class="line">        # 不发送任何匿名统计信息</span><br><span class="line">        telemetry:</span><br><span class="line">          enabled: false</span><br><span class="line">        images:</span><br><span class="line">          default_pull_policy: IfNotPresent</span><br></pre></td></tr></table></figure><p>最后只需要执行 <code>k0sctl apply -c k0sctl.yaml</code> 稍等几分钟集群就搭建好了，安装过程中可以看到相关文件的上传流程:</p><p><img src="https://img.hi-linux.com/staticfile/4rQzJU-2021-07-30-x6oYQu.png" alt></p><h3><span id="33-证书续签和管理">3.3 证书续签和管理</span></h3><p>kubeadm 集群默认证书有效期是一年，到期要通过 kubeadm 重新签署。k0s 集群也差不多一样，但是不同的是 k0s 集群更加暴力。<strong>只要 CA(默认 10年) 不丢，k0s 每次重启都强行重新生成一年有效期的证书，所以在 HA 的环境下，快到期时重启一下 k0s 服务就行。</strong></p><p><strong>k0sctl 安装完的集群默认只有一个 <code>k0scontroller.service</code> 服务，master、node 上所有服务都由这个服务启动，所以到期之前 <code>systemctl restart k0scontroller.service</code> 一下就行。</strong></p><h2><span id="集群备份和恢复">集群备份和恢复</span></h2><p>k0sctl 提供了集群备份和恢复功能，默认情况下只需要执行 <code>k0sctl backup</code> 即可完成集群备份，该命令会在当前目录下生成一个 <code>k0s_backup_TIMESTAMP.tar.gz</code> 备份文件。</p><p>需要恢复集群时使用 <code>k0sctl apply --restore-from k0s_backup_TIMESTAMP.tar.gz</code> 命令进行恢复即可；需要注意的是恢复命令等同于在新机器重新安装集群，所以有一定风险。</p><p><strong>注：经过连续两天的测试，感觉这个备份恢复功能并不算靠谱，还是推荐使用 Velero 备份集群。</strong></p><h2><span id="其他高级功能">其他高级功能</span></h2><h3><span id="51-etcd-替换">5.1 Etcd 替换</span></h3><p>在小规模集群场景下可能并不需要特别完善的 Etcd 作为存储，k0s 借助于 kine 库可以实现使用 SQLite 或 MySQL 等传统数据库作为集群存储；如果想要切换存储只需要调整 <code>k0sctl.yaml</code> 配置即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s</span><br><span class="line">spec:</span><br><span class="line">  storage:</span><br><span class="line">    type: kine</span><br><span class="line">    kine:</span><br><span class="line">      dataSource: &quot;sqlite:&#x2F;&#x2F;&#x2F;var&#x2F;lib&#x2F;k0s&#x2F;db&#x2F;state.db?more&#x3D;rwc&amp;_journal&#x3D;WAL&amp;cache&#x3D;shared&quot;</span><br></pre></td></tr></table></figure><h3><span id="52-集群用户管理">5.2 集群用户管理</span></h3><p>使用 k0sctl 搭建的集群通过 <code>k0s</code> 命令可以很方便的为集群添加用户，以下是添加样例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ k0s kubeconfig create --groups &quot;system:masters&quot; testUser &gt; k0s.config</span><br></pre></td></tr></table></figure><h3><span id="53-containerd-配置">5.3 Containerd 配置</span></h3><p>在不做配置的情况下 k0s 集群使用默认的 Containerd 配置，如果需要自己定义特殊配置，可以在安装时通过文件上传方式将 Containerd 配置文件上传到 <code>/etc/k0s/containerd.toml</code> 位置，该配置将会被 k0s 启动的 Containerd 读取并使用。</p><h2><span id="总结">总结</span></h2><p>k0s 是个不错的项目，对于二进制宿主机部署 Kubernetes 集群很方便，由于其直接采用 Kubernetes 二进制文件启动，所以基本没有功能阉割，而 k0sctl 又为自动化安装提供了良好的扩展性，所以值得一试。不过目前来说 k0s 在细节部分还有一定瑕疵，比如 <code>konnectivity</code> 服务在安装时无法选择性关闭等。k0s 综合来说是个不错的工具，也推荐看看源码，里面很多设计很新颖也比较利于了解集群引导过程。</p><blockquote><p>本文转载自：「 bleem 」，原文：<a href="https://tinyurl.com/puyt7f7d" target="_blank" rel="noopener">https://tinyurl.com/puyt7f7d</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;最近两年一直在使用 kubeadm 部署 kubernetes 集群，总体来说配合一些自己小脚本还有一些自动化工具还算是方便；但是全容器化稳定性确实担忧，也遇到过莫名其妙的证书过期错误，最后重启大法解决这种问题；所以也在探索比较方便的二进制部署方式，比如这个 k0s。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;k0s-介绍&quot;&gt;k0s 介绍&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The Simple, Solid &amp;amp; Certified Kubernetes Distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;k0s 可以认为是一个下游的 Kubernetes 发行版，与原生 Kubernetes 相比，k0s 并未阉割大量 Kubernetes 功能；k0s 主要阉割部分基本上只有 &lt;strong&gt;树内 Cloud provider&lt;/strong&gt;，其他的都与原生 Kubernetes 相同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;k0s 自行编译 Kubernetes 源码生成 Kubernetes 二进制文件，然后在安装后将二进制文件释放到宿主机再启动；这种情况下所有功能几乎与原生 Kubernetes 没有差异。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;k0sctl-使用&quot;&gt;k0sctl 使用&lt;/h2&gt;
&lt;p&gt;k0sctl 是 k0s 为了方便快速部署集群所提供的工具，有点类似于 kubeadm，但是其扩展性要比 kubeadm 好得多。在多节点的情况下，k0sctl 通过 ssh 连接目标主机然后按照步骤释放文件并启动 Kubernetes 相关服务，从而完成集群初始化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>一文搞懂 4 种常用的 Kubernetes 容器</title>
    <link href="https://www.hi-linux.com/posts/16821.html"/>
    <id>https://www.hi-linux.com/posts/16821.html</id>
    <published>2021-07-30T01:00:00.000Z</published>
    <updated>2021-07-30T08:34:23.759Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>截止目前 Kubernetes 1.18，Kubernetes 已经支持标准容器，Sidecar 容器，Init 容器，Ephemeral 容器 4 种类型的 Containers。本文我们详细介绍一下这 4 种容器的特性以及使用场景。</p><p><img src="https://pic2.zhimg.com/80/v2-fac0971dbc8d39235d81ffb07eb9c7cd_720w.jpg" alt></p><h2><span id="标准容器和-sidecar-容器">标准容器和 Sidecar 容器</span></h2><p>在  Kubernetes 1.18 之前，这两种容器从 Kubernetes 管理的角度来看，并没有什么区别。只不过人为从功能上做了区分。</p><p><img src="https://img.hi-linux.com/staticfile/v2-7240d284cc8376172e49e8105953d726_720w-2021-06-25-Spz7c6.jpg" alt></p><h3><span id="使用-sidecar-容器模块化具有的优点">使用 Sidecar 容器（模块化）具有的优点</span></h3><ul><li>加速应用程序开发，因为容器可以在团队甚至更大的社区之间重复使用</li><li>整理专家知识，因为每个人都在一个容器化的实现上进行协作，该实现反映了最佳实践，而不是无数种功能大致相同的自家生产的不同容器</li><li>启用敏捷团队，因为容器边界是自然边界，是团队职责的契约</li><li>提供关注点分离，并专注于特定功能，以减少意大利面条的依赖性和不可测的组件</li></ul><h3><span id="对于-sidecar-容器一般来说主要体现在以下-4-种角色">对于 Sidecar 容器一般来说主要体现在以下 4 种角色：</span></h3><ul><li>代理</li></ul><p>例如现在 Istio 中 的 Envoy。</p><p><img src="https://img.hi-linux.com/staticfile/v2-b134721a06da744cea35d5a399a3d857_720w-2021-06-25-ihOQPI.jpg" alt></p><p>通过这种 Sidercar 模式，代理可以拦截进出主容器的流量从而 Istio 可以提取有关流量行为的大量信号作为属性。 Istio 可以使用这些属性来执行策略决策，并将其发送到监视系统以提供有关整个网格行为的信息。</p><p>Sidecar 代理模型还允许您将 Istio 功能添加到现有部署中，而无需重新构造或重写代码。</p><ul><li>适配器</li></ul><p>适配器容器对输出进行标准化。考虑监视 N 个不同应用程序的任务。可以使用不同的导出监视数据的方式来构建每个应用程序。（例如 JMX，StatsD，特定于应用程序的统计信息），但每个监控系统都希望其收集的监控数据具有一致且统一的数据模型。</p><p>通过使用复合容器的适配器模式，您可以通过创建 Pod 来将来自不同系统的异构监视数据转换为一个统一的表示形式，该 Pod 将应用程序容器与知道如何进行转换的适配器分组在一起。同样，由于这些 Pod 共享名称空间和文件系统，因此这两个容器的协调非常简单明了。</p><p><img src="https://pic1.zhimg.com/80/v2-eab449fd16b6fb03512cbb7c6153fd60_720w.jpg" alt></p><ul><li>增强主容器功能</li></ul><p>Sidecar 容器扩展并增强了 “主” 容器，它们可以使用现有的容器并使它们变得更好。</p><p>例如，考虑一个运行 Nginx Web 服务器的容器。添加另一个将文件系统与 Git 存储库同步的容器，在这些容器之间共享文件系统，并且您已经构建了 Git Push-to-deploy。但是您已经以模块化的方式完成了此工作，其中 Git 同步器可以由不同的团队构建，并且可以在许多不同的Web服务器（Apache，Python，Tomcat等）上重复使用。</p><p>由于这种模块化，您只需编写和测试 Git 同步器一次，即可在众多应用程序中重复使用它。而且，如果有人编写它，您甚至不需要这样做。</p><ul><li>实现辅助功能</li></ul><p>这种场景一般出现在 DevOps 中。比如将收集日志的组件以 Sidecar 的方式部署，实现收集日志的用途，或是部署一个 Sidecar 组件从配置中心监听配置变化，实时更新本地配置。</p><h3><span id="生命周期">生命周期</span></h3><p>Sidecar 容器的所有问题都与容器生命周期相关性有关。由于和 Pod 中的常规容器之间没有区别，因此无法控制哪个容器首先启动或最后终止，但是先正确运行 Sidecar 容器通常是应用程序容器正确运行的要求。</p><p>从 1.18 版本开始，K8S 内置的 Sidecar 功能将确保 Sidecar 容器在正常业务流程开始之前就启动并运行，即通过更改 Pod 的启动生命周期，在 Init 容器完成后启动 Sidecar 容器，在 Sidecar 容器就绪后启动业务容器，从启动流程上保证顺序性。</p><p><img src="https://img.hi-linux.com/staticfile/v2-1389722cbb68cad9a4673ca4f3d918d7_b-2021-06-25-1nAhaU.jpg" alt></p><p>通过更改 Pod 规范中的 <code>container.lifecycle.type</code> 将容器标记为 Sidecar 类型：<code>Sidecar</code>，默认为 <code>Standard</code>，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: bookings-v1-b54bc7c9c-v42f6</span><br><span class="line">  labels:</span><br><span class="line">    app: demoapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: bookings</span><br><span class="line">    image: banzaicloud&#x2F;allspark:0.1.1</span><br><span class="line">    ...</span><br><span class="line">  - name: istio-proxy</span><br><span class="line">    image: docker.io&#x2F;istio&#x2F;proxyv2:1.4.3</span><br><span class="line">    lifecycle:</span><br><span class="line">      type: Sidecar</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><h2><span id="init-容器">Init 容器</span></h2><p>在 Kubernetes 中，Init 容器是在同一 Pod 中的其他容器之前开始并执行的容器。它旨在为 Pod 上托管的主应用程序执行初始化逻辑。例如，创建必要的用户帐户，执行数据库迁移，创建数据库结构等。</p><p>Init 容器与普通的容器非常像，除了如下两点：</p><ul><li>它们总是运行到完成。</li><li>每个都必须在下一个启动之前成功完成。</li></ul><h3><span id="与普通容器的不同之处">与普通容器的不同之处</span></h3><p></p><ul><li>Init 容器支持应用容器的全部字段和特性，包括资源限制、数据卷和安全设置。 然而，Init 容器对资源请求和限制的处理稍有不同。</li><li>同时 Init 容器不支持 Readiness Probe，因为它们必须在 Pod 就绪之前运行完成。</li><li>如果为一个 Pod 指定了多个 Init 容器，这些容器会按顺序逐个运行。每个 Init 容器必须运行成功，下一个才能够运行。当所有的 Init 容器运行完成时，Kubernetes 才会为 Pod 初始化应用容器并像平常一样运行。</li></ul><h3><span id="init-容器作用">Init 容器作用</span></h3><p>因为 Init 容器具有与应用容器分离的单独镜像，其启动相关代码具有如下优势：</p><ul><li>Init 容器可以包含一些安装过程中应用容器中不存在的实用工具或个性化代码。例如，没有必要仅为了在安装过程中使用类似 sed、 awk、 python 或 dig 这样的工具而去FROM 一个镜像来生成一个新的镜像。</li><li>Init 容器可以安全地运行这些工具，避免这些工具导致应用镜像的安全性降低。</li><li>应用镜像的创建者和部署者可以各自独立工作，而没有必要联合构建一个单独的应用镜像。</li><li>Init 容器能以不同于Pod内应用容器的文件系统视图运行。因此，Init容器可具有访问 Secrets 的权限，而应用容器不能够访问。</li><li>由于 Init 容器必须在应用容器启动之前运行完成，因此 Init 容器提供了一种机制来阻塞或延迟应用容器的启动，直到满足了一组先决条件。一旦前置条件满足，Pod内的所有的应用容器会并行启动。</li></ul><h3><span id="创建-initcontainer-时应考虑一些注意事项">创建 InitContainer 时应考虑一些注意事项：</span></h3><ul><li>它们总是在 Pod 中的其他容器之前执行。因此，它们不应包含需要很长时间才能完成的复杂逻辑。启动脚本通常很小而简洁。如果发现要向初始化容器添加太多逻辑，则应考虑将其中的一部分移至应用程序容器本身。</li><li>初始化容器按顺序启动和执行。除非一个初始化容器被成功执行，否则下一个初始化容器不会被开始执行。因此，如果启动任务很长，则可以考虑将其分为多个步骤，每个步骤都由一个初始化容器处理，以便您知道哪些步骤失败。</li><li>如果任何初始化容器失败，则将重新启动整个 Pod（除非您将 restartPolicy 设置为 Never）。重新启动 Pod 意味着再次重新执行所有容器，包括任何初始化容器。因此，您可能需要确保启动逻辑允许多次执行而不会导致重复。例如，如果数据库迁移已经完成，则应仅忽略再次执行迁移命令。</li><li>初始化容器是延迟应用程序初始化直到一个或多个依赖项可用的很好的选择。例如，如果您的应用程序依赖于施加API请求速率限制的 API，则您可能需要等待一段时间才能接收来自该 API 的响应。在应用程序容器中实现此逻辑可能很复杂；因为它需要与健康和就绪状态探测器结合使用。一种更简单的方法是创建一个初始化容器，该容器要等到API准备好后才能成功退出。只有在初始化容器成功完成其工作之后，应用程序容器才会启动。</li><li>初始化容器不能像应用程序容器那样使用运行状况和就绪探针。原因是它们要成功启动和退出，就像 Jobs 和 CronJobs 的行为一样。</li><li>同一Pod 上的所有容器共享相同的卷和网络。您可以利用此功能在应用程序及其初始化容器之间共享数据。</li></ul><blockquote><p>正如我们刚刚讨论的那样，Init 容器总是比同一个 Pod 上的其他应用程序容器先启动。结果，调度程序对 Init 容器的资源和限制赋予了更高的优先级。必须仔细考虑这种行为，因为这可能会导致不良后果。例如，如果您有一个初始化容器和一个应用程序容器，并且将初始化容器的资源和限制设置为高于应用程序容器的资源和限制，那么只有在有一个可用节点满足初始化的情况下，才调度整个 Pod 容器要求。换句话说，即使有一个未使用的节点可以在其中运行应用程序容器，但如果初始化容器具有该节点可以处理的更高资源先决条件，则 Pod 也不会部署到该节点。因此，在定义初始化容器的请求和限制时，您应尽可能严格。最佳做法是，除非绝对必要，否则请勿将这些参数设置为高于应用程序容器的值。</p></blockquote><h3><span id="使用-init-容器">使用 Init 容器</span></h3><p>下面的例子定义了一个具有 2 个 Init 容器的简单 Pod。 第一个等待 myservice 启动，第二个等待 mydb 启动。 一旦这两个 Init容器 都启动完成，Pod 将启动 spec 区域中的应用容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: myapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp-container</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: init-myservice</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &quot;until nslookup myservice.$(cat &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done&quot;]</span><br><span class="line">  - name: init-mydb</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &quot;until nslookup mydb.$(cat &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done&quot;]</span><br></pre></td></tr></table></figure><p>这是 Kubernetes 1.6 版本的新语法，尽管老的 annotation 语法仍然可以使用。我们已经把 Init 容器的声明移到 spec 中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: myapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp-container</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: init-myservice</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#39;]</span><br><span class="line">  - name: init-mydb</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#39;]</span><br></pre></td></tr></table></figure><p>1.5 版本的语法在 1.6 版本仍然可以使用，但是我们推荐使用 1.6 版本的新语法。 在 Kubernetes 1.6 版本中，Init 容器在 API 中新建了一个字段。 虽然期望使用 beta 版本的 annotation，但在未来发行版将会被废弃掉。</p><p>在所有的 Init 容器没有成功之前，Pod 将不会变成 Ready 状态。 Init 容器的端口将不会在 Service 中进行聚集。 正在初始化中的 Pod 处于 Pending 状态，但应该会将条件 Initializing 设置为 true。</p><p>如果 Pod 重启，所有 Init 容器必须重新执行。</p><p>对 Init 容器 spec 的修改，被限制在容器 image 字段中。 更改 Init 容器的 image 字段，等价于重启该 Pod。</p><h3><span id="ephemeral-容器">Ephemeral 容器</span></h3><p>临时容器与其他容器的不同之处在于，它们缺少对资源或执行的保证，并且永远不会自动重启，因此不适用于构建应用程序。临时容器使用与常规容器相同的 <code>ContainerSpec</code> 段进行描述，但许多字段是不相容且不允许的。</p><ul><li>临时容器没有端口配置，因此像 <code>ports</code>，<code>livenessProbe</code>，<code>readinessProbe</code> 这样的字段是不允许的。</li><li>Pod 资源分配是不可变的，因此 <code>resources</code> 配置是不允许的。</li><li>有关允许字段的完整列表，请参见<a href="https://link.zhihu.com/?target=https%3A//kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/%23ephemeralcontainer-v1-core">临时容器参考文档</a>。</li></ul><p>临时容器是使用 API 中的一种特殊的 <code>ephemeralcontainers</code> 处理器进行创建的，而不是直接添加到 <code>pod.spec</code> 段，因此无法使用 <code>kubectl edit</code> 来添加一个临时容器。</p><p>与常规容器一样，将临时容器添加到 Pod 后，将不能更改或删除临时容器。</p><h3><span id="为什么我们需要-ephemeral-容器">为什么我们需要 Ephemeral 容器？</span></h3><p>我们知道容器的优点是它们通过使用不变方法提供所有必需的依赖项来运行隔离的进程。通过仅将所需的依赖项添加到镜像中，容器可以降低攻击面并提供更快的启动和部署。使用 “distroless” 方法构建容器镜像（基于 Scratch ），通过仅包含已编译的应用程序二进制文件，将容器镜像提升到了一个新的水平。与普通的容器镜像不同，它们不基于任何种类的 Linux 发行版，因此不包含任何其他可通过 <code>kubectl exec</code>  执行以进行故障排除的二进制文件和工具。这就决定了该容器有助于提供安全可靠的运行时环境，但也很难在问题发生时进行调试。</p><p>在这种情况下，临时容器发挥作用。它们实现了调试容器附加到主进程的功能，然后你可以用于调试任何类型的问题。调试容器可以基于任何镜像，因此可以根据您的需求进行定制。您可以构建自己的调试镜像，其中包含特殊的调试二进制文件或仅包含 curl，OpenSSL 和 MongoDB客户端之类的工具。但是，您也可以选择Linux发行版（如Ubuntu）或仅运行Busybox镜像，这两个镜像都已经包含了许多有用的工具。</p><h3><span id="如何使用临时容器">如何使用临时容器？</span></h3><p>临时容器是alpha功能，因此默认情况下处于禁用状态。您将需要激活以下功能门才能使用它们：</p><ul><li>临时容器</li><li>PodShareProcessNamespace（v1.16中的beta版，因此默认情况下已启用）</li></ul><p>本节中的示例演示了临时容器如何出现在 API 中。 通常，您可以使用 <code>kubectl</code> 插件进行故障排查，从而自动化执行这些步骤。</p><p>临时容器是使用 Pod 的 <code>ephemeralcontainers</code> 子资源创建的，可以使用 <code>kubectl --raw</code> 命令进行显示。首先描述临时容器被添加为一个 <code>EphemeralContainers</code> 列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">    &quot;kind&quot;: &quot;EphemeralContainers&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;example-pod&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;ephemeralContainers&quot;: [&#123;</span><br><span class="line">        &quot;command&quot;: [</span><br><span class="line">            &quot;sh&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;image&quot;: &quot;busybox&quot;,</span><br><span class="line">        &quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;,</span><br><span class="line">        &quot;name&quot;: &quot;debugger&quot;,</span><br><span class="line">        &quot;stdin&quot;: true,</span><br><span class="line">        &quot;tty&quot;: true,</span><br><span class="line">        &quot;terminationMessagePolicy&quot;: &quot;File&quot;</span><br><span class="line">    &#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用如下命令更新已运行的临时容器 <code>example-pod</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl replace --raw &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;example-pod&#x2F;ephemeralcontainers  -f ec.json</span><br></pre></td></tr></table></figure><p>这将返回临时容器的新列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;kind&quot;:&quot;EphemeralContainers&quot;,</span><br><span class="line">   &quot;apiVersion&quot;:&quot;v1&quot;,</span><br><span class="line">   &quot;metadata&quot;:&#123;</span><br><span class="line">      &quot;name&quot;:&quot;example-pod&quot;,</span><br><span class="line">      &quot;namespace&quot;:&quot;default&quot;,</span><br><span class="line">      &quot;selfLink&quot;:&quot;&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;example-pod&#x2F;ephemeralcontainers&quot;,</span><br><span class="line">      &quot;uid&quot;:&quot;a14a6d9b-62f2-4119-9d8e-e2ed6bc3a47c&quot;,</span><br><span class="line">      &quot;resourceVersion&quot;:&quot;15886&quot;,</span><br><span class="line">      &quot;creationTimestamp&quot;:&quot;2019-08-29T06:41:42Z&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;ephemeralContainers&quot;:[</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;name&quot;:&quot;debugger&quot;,</span><br><span class="line">         &quot;image&quot;:&quot;busybox&quot;,</span><br><span class="line">         &quot;command&quot;:[</span><br><span class="line">            &quot;sh&quot;</span><br><span class="line">         ],</span><br><span class="line">         &quot;resources&quot;:&#123;</span><br><span class="line"></span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;terminationMessagePolicy&quot;:&quot;File&quot;,</span><br><span class="line">         &quot;imagePullPolicy&quot;:&quot;IfNotPresent&quot;,</span><br><span class="line">         &quot;stdin&quot;:true,</span><br><span class="line">         &quot;tty&quot;:true</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以使用以下命令查看新创建的临时容器的状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod example-pod</span><br><span class="line">...</span><br><span class="line">Ephemeral Containers:</span><br><span class="line">  debugger:</span><br><span class="line">    Container ID:  docker:&#x2F;&#x2F;cf81908f149e7e9213d3c3644eda55c72efaff67652a2685c1146f0ce151e80f</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable:&#x2F;&#x2F;busybox@sha256:9f1003c480699be56815db0f8146ad2e22efea85129b5b5983d0e0fb52d9ab70</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sh</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Thu, 29 Aug 2019 06:42:21 +0000</span><br><span class="line">    Ready:          False</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:         &lt;none&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以使用以下命令连接到新的临时容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl attach -it example-pod -c debugger</span><br></pre></td></tr></table></figure><p>如果启用了进程命名空间共享，则可以查看该 Pod 所有容器中的进程。 例如，运行上述 <code>attach</code> 操作后，在调试器容器中运行 <code>ps</code> 操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在 &quot;debugger&quot; 临时容器内中运行此 shell 命令</span><br><span class="line">$ ps auxww</span><br></pre></td></tr></table></figure><p>运行命令后，输出类似于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 &#x2F;pause</span><br><span class="line">    6 root      0:00 nginx: master process nginx -g daemon off;</span><br><span class="line">   11 101       0:00 nginx: worker process</span><br><span class="line">   12 101       0:00 nginx: worker process</span><br><span class="line">   13 101       0:00 nginx: worker process</span><br><span class="line">   14 101       0:00 nginx: worker process</span><br><span class="line">   15 101       0:00 nginx: worker process</span><br><span class="line">   16 101       0:00 nginx: worker process</span><br><span class="line">   17 101       0:00 nginx: worker process</span><br><span class="line">   18 101       0:00 nginx: worker process</span><br><span class="line">   19 root      0:00 &#x2F;pause</span><br><span class="line">   24 root      0:00 sh</span><br><span class="line">   29 root      0:00 ps auxww</span><br></pre></td></tr></table></figure><h3><span id="总结">总结</span></h3><p>本文简单介绍了标准容器，Sidecar 容器，Init 容器，Ephemeral 容器 4 种类型的 Containers。随着 Kubernetes 日益普及，我们需要充分掌握这几种类型容器原理和使用方法，才能更好地服务业务。</p><p>此外 Sidecar 容器将会成为未来软件交付的一种新的方式，参照 Dapr 等，不同的团队提供自己的功能容器，然后选择性注入 Sidecar 到主业务容器，实现解耦。</p><h2><span id="参考文档">参考文档</span></h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://zhuanlan.zhihu.com/p/145233597" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/145233597</a></li><li><a href="https://cloud.tencent.com/developer/article/1645954" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1645954</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;p&gt;截止目前 Kubernetes 1.18，Kubernetes 已经支持标准容器，Sidecar 容器，Init 容器，Ephemeral 容器 4 种类型的 Containers。本文我们详细介绍一下这 4
        
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>超赞，腾讯开源运维必备海量服务器管理系统！</title>
    <link href="https://www.hi-linux.com/posts/4224.html"/>
    <id>https://www.hi-linux.com/posts/4224.html</id>
    <published>2021-07-27T01:00:00.000Z</published>
    <updated>2021-07-28T01:17:17.351Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天推荐的这个项目是「bk-job」—— 蓝鲸作业平台 (Job)，一套腾讯开源的运维脚本管理系统，具备海量任务并发处理能力。</p><p>除了支持脚本执行、文件分发、定时任务等一系列基础运维场景以外，还支持通过流程调度能力将零碎的单个任务组装成一个自动化作业流程；</p><p>而每个作业都可做为一个原子节点，提供给上层或周边系统/平台使用，实现跨系统调度自动化。</p><a id="more"></a><h2><span id="优势">优势</span></h2><ul><li><p>安全可靠的高危命令检测能力</p></li><li><p>完善的脚本版本管理</p></li><li><p>作业编排，一切皆场景</p></li><li><p>原汁原味的 Cron 定时任务</p></li><li><p>高扩展性的文件源管理能力</p></li></ul><p><code>bk-job</code> 提供了快速执行、任务编排、定时执行等核心服务，多重组合，满足企业不同场景的需求：</p><ul><li><p>快速执行：提供临时性且多变的快速一次性操作入口，用完即走</p></li><li><p>任务编排：对于重复性的操作组合，可以通过编排功能将其沉淀为 “作业”，方便管理和使用</p></li><li><p>定时执行：支持用户按业务逻辑诉求设置周期性或一次性的定期执行计划</p></li><li><p>脚本管理：将脚本以云化模式统一管理，更好的支持作业编排和周边系统调度的灵活度</p></li><li><p>账号管理：管理服务器 OS 的执行账户，如 Linux 的 root，Windows 的 administrator 等等</p></li><li><p>消息通知：满足业务按管理需求设置任务不同状态的执行结果消息通知</p></li><li><p>文件源管理：开放文件源对接插件能力，满足从不同文件系统类型拉取文件并传输的诉求</p></li><li><p>运营分析：提供平台的运营统计数据展示，助力管理员更全方位的了解平台的运行情况</p></li><li><p>平台管理：丰富的平台管理员工具，包括但不仅限于信息更改、消息渠道设置、高危语句检测规则、功能限制设置、公共脚本管理、后台服务状态展示等等</p></li></ul><h2><span id="架构设计">架构设计</span></h2><p><img src="https://img.hi-linux.com/staticfile/architecture-2021-07-15-b41cpq.png" alt></p><p>更多项目详情请查看项目地址：<a href="https://github.com/Tencent/bk-job" target="_blank" rel="noopener">https://github.com/Tencent/bk-job</a></p><blockquote><p>本文转载自：「 GitHub 精选 」，原文：<a href="https://tinyurl.com/6cudv978%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/6cudv978，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天推荐的这个项目是「bk-job」—— 蓝鲸作业平台 (Job)，一套腾讯开源的运维脚本管理系统，具备海量任务并发处理能力。&lt;/p&gt;
&lt;p&gt;除了支持脚本执行、文件分发、定时任务等一系列基础运维场景以外，还支持通过流程调度能力将零碎的单个任务组装成一个自动化作业流程；&lt;/p&gt;
&lt;p&gt;而每个作业都可做为一个原子节点，提供给上层或周边系统/平台使用，实现跨系统调度自动化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="开源" scheme="https://www.hi-linux.com/categories/%E5%BC%80%E6%BA%90/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="腾迅" scheme="https://www.hi-linux.com/tags/%E8%85%BE%E8%BF%85/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>微软开源自有云服务器专属 Linux 发行版 CBL-Mariner，可在 GitHub 免费下载！</title>
    <link href="https://www.hi-linux.com/posts/9114.html"/>
    <id>https://www.hi-linux.com/posts/9114.html</id>
    <published>2021-07-23T01:00:00.000Z</published>
    <updated>2021-07-23T07:43:18.687Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>近年来，微软对 Linux 的爱越来越多，这已经不是什么秘密了–看看 Windows Subsystem for Linux 就是一个例子。尽管如此，在得知微软还有自己的 Linux 发行版时，你还是可能会感到惊讶。</p></blockquote><p>微软近日开源了一款内部使用的 Linux 发行版——CBL-Mariner（CBL 即 Common Base Linux）。CBL-Mariner 不是桌面 Linux 而是服务器端 Linux，它被用于微软的云基础设施以及边缘产品和服务。CBL-Mariner 旨在为这些设备和服务提供一个一致的平台，并增强微软在 Linux 更新方面与时俱进的能力。</p><p><img src="https://img.hi-linux.com/staticfile/maxresdefault-2021-07-22-yRdZjc.jpg" alt></p><p>CBL-Mariner 的设计理念是通过提供一组小的通用核心软件包来满足云和边缘服务的普遍需求，同时允许各团队在通用核心之上根据需要引入额外的软件包。它是轻量级的发行版，只消耗非常小的磁盘和内存资源，可作为容器或容器主机使用。</p><p>CBL-Mariner 遵循 “默认安全(secure-by-default)” 原则，操作系统的大多数方面都以安全为重点。它包含加固内核、签名更新、ASLR、基于编译器的加固和防篡改日志等众多功能。所有 CBL-Mariner 安全功能都已罗列在 GitHub Repo 中。</p><p><strong>CBL-Mariner 软件包系统是基于 RPM 的，软件包更新系统同时使用 dnf 和 tdnf，后者全称 Tiny DNF，是一个基于 dnf 的软件包管理器，来自 VMware 的 Photon OS。</strong></p><p>CBL-Mariner 还支持基于镜像的更新机制，其使用 RPM-OSTree 来实现，rpm-ostree 是一个基于OSTree 的开源工具，用于管理可启动的、不可变的、版本化的文件系统树。rpm-ostree 背后的想法是使用一个客户-服务器架构，以可靠的方式保持 Linux 主机的更新和与最新的软件包同步。</p><p>微软表示，开源 CBL-Mariner Linux 发行版是他们对广泛的 Linux 技术不断增加投资的一部分，就如同此前的 SONiC, Azure Sphere OS 和 Windows Subsystem for Linux (WSL) 等项目。此外这也是微软对开源承诺的兑现，以及对 Linux 社区的回馈。微软还表示，CBL-Mariner 不会改变他们对任何现有第三方 Linux 发行版的态度或承诺。</p><blockquote><p>项目地址：<a href="https://github.com/microsoft/CBL-Mariner" target="_blank" rel="noopener">https://github.com/microsoft/CBL-Mariner</a></p></blockquote><p>根据微软 Azure 团队成员 Juan Manuel Rey 的介绍，CBL-Mariner 由 WSL2 团队创造，但目前没有提供 ISO 镜像，需要自己进行构建。</p><p><img src="https://img.hi-linux.com/staticfile/8f06c7d5-3d30-40d4-b611-270fd3cc8cd0-2021-07-22-S9ksIe.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/22f55ae0-d3ae-4488-b4ab-89536a8623f2-2021-07-22-9D2rI6.png" alt></p><p>详细教程可参考：</p><blockquote><ol><li><a href="https://linuxiac.com/microsoft-cbl-mariner-linux-1/" target="_blank" rel="noopener">https://linuxiac.com/microsoft-cbl-mariner-linux-1/</a></li><li><a href="https://blog.jreypo.io/2021/07/09/a-look-into-cbl-mariner-microsoft-internal-linux-distribution/" target="_blank" rel="noopener">https://blog.jreypo.io/2021/07/09/a-look-into-cbl-mariner-microsoft-internal-linux-distribution/</a></li></ol></blockquote><p>如果你觉得上面的英文文档看起来比较费劲，也可以看看下面这篇中文文档：</p><blockquote><ol><li><a href="https://blog.csdn.net/aw77520/article/details/118958510" target="_blank" rel="noopener">https://blog.csdn.net/aw77520/article/details/118958510</a></li></ol></blockquote><p><strong>参考文档</strong></p><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://mp.weixin.qq.com/s/1d7tP_kKfXHrmqKYeyxyKA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/1d7tP_kKfXHrmqKYeyxyKA</a></li><li><a href="https://www.cnbeta.com/articles/tech/1152045.htm" target="_blank" rel="noopener">https://www.cnbeta.com/articles/tech/1152045.htm</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;近年来，微软对 Linux 的爱越来越多，这已经不是什么秘密了–看看 Windows Subsystem for Linux 就是一个例子。尽管如此，在得知微软还有自己的 Linux
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微软" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E8%BD%AF/"/>
    
      <category term="CBL-Mariner" scheme="https://www.hi-linux.com/tags/CBL-Mariner/"/>
    
  </entry>
  
  <entry>
    <title>两个 Docker 使用神技，99% 的人都不知道！</title>
    <link href="https://www.hi-linux.com/posts/47156.html"/>
    <id>https://www.hi-linux.com/posts/47156.html</id>
    <published>2021-07-22T01:00:00.000Z</published>
    <updated>2021-07-22T01:38:22.462Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近发现两个非常好用的工具，一个是 <code>runlike</code>，一个是 <code>whaler</code></p><ul><li><p><code>runlike</code>：通过容器打印出容器的启动命令</p></li><li><p><code>whaler</code>：通过镜像导出<code>dockerfile</code></p></li></ul><p>听起来是不是想说 <code>N...B...</code> 哈哈，那就走起？</p><a id="more"></a><h2><span id="找回-docker-容器运行的命令">找回 Docker 容器运行的命令</span></h2><p>平时可能因为测试或者一些规范的操作方式导致启动一个容器，忘记了这个容器的启动命令是什么了，又需要找回来在别的机器上创建的时候，就很麻烦，可能很多人会想到通过 <code>docker inspect</code> 分析输出的 json 文件中的<code>volume</code>、<code>ports</code>、<code>Env</code>等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect $container_name</span><br></pre></td></tr></table></figure><p>这个命令应该是很熟悉的，查看容器的基本信息。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712102727538-2021-07-12-TYza77.jpg" alt></p><p>虽然这样也能找到运行容器的命令，但是依旧还需要时间去整理，因此这里分享一个可以直接打印运行命令的工具<strong>runlike</strong>[1]，在runlike传递一个容器名称，就会直接打印出该容器的运行命令。<code>runlike</code>使用起来非常方便，可以直接通过<code>pip</code>安装，也可以通过容器方式免安装使用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># pip</span><br><span class="line">$ pip install runlike</span><br><span class="line"># by docker</span><br><span class="line">$ alias runlike&#x3D;&quot;docker run --rm -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock assaflavie&#x2F;runlike&quot;</span><br></pre></td></tr></table></figure><p>下面还是通过上面那个容器测试一下是否可以:</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712101519855-2021-07-12-8zSm4J.jpg" alt></p><p>这样使用起来就方便很多了。关于 <code>runlike</code> 一些其他的选项，可以直接通过<code>--help</code>学习。</p><h2><span id="从镜像导出dockerfile">从镜像导出Dockerfile</span></h2><p>平时可能会构建很多不同的镜像，比如维护一些基础Docker镜像、想查看一些公开仓库的Docker镜像是怎么构建的，或因为长时间不维护找不到当时构建镜像的 Dockerfile，或者因为网络无法查看时，能从镜像导出Dockerfile就显得很重要，这里可以通过 <strong>whaler</strong>[2] 来快速的导出. 这里我们依旧不安装，通过容器化的方式使用dfimage命令，便于使用，我们将该命令写成命令别名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># alias export docker image to dockerfile</span><br><span class="line">$ alias whaler&#x3D;&quot;docker run -t --rm -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock:ro pegleg&#x2F;whaler&quot;</span><br></pre></td></tr></table></figure><p>然后通过<code>whaler</code>命令输出 <code>pegleg/whaler</code> 镜像的dockerfile文件:</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712102326684-2021-07-12-58iXFO.jpg" alt></p><p>这样就输出<code>pegleg/whaler</code>这个镜像的 Dockerfile 大致的内容了，还是彩色的输出呢？哈哈，有心了。从上图可以看到输出的 Dockerfile 也与<code>平常写的不太一样</code>，可以在 Github 上看下仓库内的 Dockerfile 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">FROM golang:1.14.4 AS builder</span><br><span class="line">WORKDIR $GOPATH</span><br><span class="line">RUN go get -u github.com&#x2F;P3GLEG&#x2F;Whaler</span><br><span class="line">WORKDIR $GOPATH&#x2F;src&#x2F;github.com&#x2F;P3GLEG&#x2F;Whaler</span><br><span class="line">RUN export CGO_ENABLED&#x3D;0 &amp;&amp; go build .</span><br><span class="line">RUN cp Whaler &#x2F;root&#x2F;Whaler</span><br><span class="line"></span><br><span class="line">FROM alpine:3.12.0</span><br><span class="line">WORKDIR &#x2F;root&#x2F;</span><br><span class="line">COPY --from&#x3D;builder &#x2F;root&#x2F;Whaler .</span><br><span class="line">ENTRYPOINT [&quot;.&#x2F;Whaler&quot;]</span><br></pre></td></tr></table></figure><p>由 Dockerfile 来看，这个 <code>whaler</code> 采用的多阶段构建，所以无法输出 <code>--from=builder</code> 的构建内容，这个锅 <code>whaler</code> 不背，我们可以换一个镜像看看：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712102331953-2021-07-12-0wmUwI.jpg" alt></p><p>这个就显示的很自然，很有熟悉的味道了。<code>whaler</code> 支持同时分析多个镜像等等功能，这里就不在说了，感兴趣的可以自己看一下。至于 <code>whaler</code> 是怎么实现的，其实看一下源码就明白了。</p><blockquote><p>本文转载自：「 云原生生态圈 」，原文：<a href="https://tinyurl.com/wbm4x5aw" target="_blank" rel="noopener">https://tinyurl.com/wbm4x5aw</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近发现两个非常好用的工具，一个是 &lt;code&gt;runlike&lt;/code&gt;，一个是 &lt;code&gt;whaler&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;runlike&lt;/code&gt;：通过容器打印出容器的启动命令&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;whaler&lt;/code&gt;：通过镜像导出&lt;code&gt;dockerfile&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;听起来是不是想说 &lt;code&gt;N...B...&lt;/code&gt; 哈哈，那就走起？&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>如何优雅的在 Linux 下开机自动重启脚本</title>
    <link href="https://www.hi-linux.com/posts/36782.html"/>
    <id>https://www.hi-linux.com/posts/36782.html</id>
    <published>2021-07-21T01:00:00.000Z</published>
    <updated>2021-07-21T02:10:39.790Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="简介">简介</span></h2><p>经常碰到机器断电之后需要重启一大堆服务，为了防止这种事情发生，设置开机自启的脚本十分的重要，我们习惯性的做法就是编写一个重启脚本，然后在 <code>/etc/rc.local</code> 中去完成开机执行。例如下面这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;etc&#x2F;rc.local</span><br><span class="line">bash &#x2F;root&#x2F;script&#x2F;restart.sh</span><br></pre></td></tr></table></figure><p>这样的方法虽然可行，但并不优雅。今天我们就给大家介绍两种更好的实现方式：</p><h2><span id="通过-crontab-实现">通过 Crontab 实现</span></h2><p>Crontab 可以使用 <code>@reboot</code> 来执行主机启动之后的命令。首先在命令行输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br></pre></td></tr></table></figure><p>然后添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@reboot &#x2F;root&#x2F;script&#x2F;restart.sh</span><br></pre></td></tr></table></figure><p>完成后，这个脚本就可以在重启的时候自动执行了。其它的一些进阶玩法：</p><ul><li>在启动完成后的指定时间内运行脚本</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在启动 5 分钟后运行指定脚本</span><br><span class="line">@reboot sleep 300 &amp;&amp; &#x2F;home&#x2F;wwwjobs&#x2F;clean-static-cache.sh</span><br></pre></td></tr></table></figure><h2><span id="通过-systemd-实现">通过 Systemd 实现</span></h2><p>首先编写一个名为 restart 的 Systemd 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ vim &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;restart.service</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;restart</span><br><span class="line">After&#x3D;default.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart&#x3D;&#x2F;root&#x2F;script&#x2F;restart.sh</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;default.target</span><br></pre></td></tr></table></figure><p>然后启用这个 Systemd 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl enable restart.service</span><br></pre></td></tr></table></figure><p>完成后，这个服务对应的脚本就可以自动开机自启了。</p><h2><span id="参考文档">参考文档</span></h2><ul><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://tinyurl.com/6ryafefw" target="_blank" rel="noopener">https://tinyurl.com/6ryafefw</a></li><li><a href="https://www.cyberciti.biz/faq/linux-execute-cron-job-after-system-reboot/" target="_blank" rel="noopener">https://www.cyberciti.biz/faq/linux-execute-cron-job-after-system-reboot/</a></li></ul></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;h2&gt;&lt;span id=&quot;简介&quot;&gt;简介&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;经常碰到机器断电之后需要重启一大堆服务，为了防止这种事情发生，设置开机自启的脚本十分的重要，我们习惯性的做法就是编写一个重启脚本，然后在
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款面向开发者友好的 Kubernetes 持续交付工作流管理软件 Devtron</title>
    <link href="https://www.hi-linux.com/posts/45793.html"/>
    <id>https://www.hi-linux.com/posts/45793.html</id>
    <published>2021-07-15T01:00:00.000Z</published>
    <updated>2021-07-15T08:28:23.181Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Devtron(<a href="https://devtron.ai" target="_blank" rel="noopener">https://devtron.ai</a>) 是用 go 编写的用于 Kubernetes 交付工作流管理的开源软件。它被设计为一个自我服务平台，以开发者友好的方式在 Kubernetes 上运维和维护应用程序（AppOps）。</p><blockquote><p>仓库地址：<a href="https://github.com/devtron-labs/devtron" target="_blank" rel="noopener">https://github.com/devtron-labs/devtron</a></p></blockquote><a id="more"></a><h2><span id="特性">🎉 特性</span></h2><ul><li><p>零代码软件交付工作流</p><ul><li>了解 kubernetes、测试、CD、SecOps 等领域的工作流，这样你就不必写脚本。</li><li>可重复使用和可组合的组件，使工作流易于构建使用。</li></ul></li><li><p>多云部署</p><ul><li>天然支持部署到多个 kubernetes 集群上</li></ul></li><li><p>轻松实现开发-安全-运维一体化</p><ul><li>全局、集群、环境和应用的多层次安全策略，实现高效的分层策略管理</li><li>行为驱动的安全策略</li><li>kubernetes 资源定义策略和异常情况</li><li>定义事件的策略，以便更快地解决问题</li></ul></li><li><p>应用程序调试面板</p><ul><li>所有历史的 kubernetes 事件都集中在一个地方</li><li>安全地访问所有清单，如 secret、configmap</li><li>cpu、ram、http 状态码和延迟等应用指标，并进行新旧对比</li><li>使用 grep 和 json 搜索日志</li><li>事件和日志之间的智能关联性</li></ul></li><li><p>企业级的安全性和合规性</p><ul><li>细粒度的访问控制；控制谁可以编辑配置，谁可以部署</li><li>审计日志，了解谁做了什么，什么时候做的</li><li>所有 CI 和 CD 事件的历史记录</li><li>影响应用程序的 Kubernetes 事件</li><li>相关的云事件及其对应用程序的影响</li><li>先进的工作流程策略，如分支环境，确保构建和部署管道的安全</li></ul></li><li><p>了解 Gitops</p><ul><li>通过 API 和 UI 暴露的 Gitops，使你不必与 Git 客户端交互</li><li>由 postgres 支持的 Gitops 更容易分析</li><li>实施比 git 更精细的访问控制</li></ul></li><li><p>业务洞察</p><ul><li>部署指标来衡量敏捷过程的成功，它可以捕捉到 mttr、变更失败率、部署频率、部署规模等。</li><li>审计日志以了解失败的原因</li><li>监测跨部署的变化，并轻松恢复</li></ul></li></ul><h2><span id="安装">🚀 安装</span></h2><p>默认的安装配置会使用 MinIO 来存储构建日志和缓存，可以直接使用下面的命令进行安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add devtron https:&#x2F;&#x2F;helm.devtron.ai</span><br><span class="line">$ helm install devtron devtron&#x2F;devtron-operator --create-namespace --namespace devtroncd \</span><br><span class="line">--set secrets.POSTGRESQL_PASSWORD&#x3D;change-me</span><br></pre></td></tr></table></figure><p>但是官方的安装方式会从 GitHub 上面去下载很多脚本进行初始化，由于某些原因，可能我们没办法正常访问，这里我已经将所有的安装脚本和代码同步到了 <code>gitee</code> 上面，不用担心安装不上了。</p><p>首先 clone 安装脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;gitee.com&#x2F;cnych&#x2F;devtron-installation-script.git</span><br><span class="line">$ cd devtron-installation-script</span><br></pre></td></tr></table></figure><p>这里我们使用 Helm3 来进行安装，我们只需要安装 <code>devtron-operator</code> 即可帮我们自动安装 devtron 了，命令如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ helm upgrade --install devtron .&#x2F;charts&#x2F;devtron --create-namespace --namespace devtroncd</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: &#x2F;Users&#x2F;ych&#x2F;.kube&#x2F;config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: &#x2F;Users&#x2F;ych&#x2F;.kube&#x2F;config</span><br><span class="line">W0624 11:00:57.798698 56125 warnings.go:67] apiextensions.k8s.io&#x2F;v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io&#x2F;v1 CustomResourceDefinition</span><br><span class="line">W0624 11:00:59.829583 56125 warnings.go:67] apiextensions.k8s.io&#x2F;v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io&#x2F;v1 CustomResourceDefinition</span><br><span class="line">NAME: devtron</span><br><span class="line">LAST DEPLOYED: Thu Jun 24 11:01:00 2021</span><br><span class="line">NAMESPACE: devtroncd</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line"></span><br><span class="line">1. Run the following command to get the default admin password. Default username is admin</span><br><span class="line"></span><br><span class="line">   kubectl -n devtroncd get secret devtron-secret -o jsonpath&#x3D;&#39;&#123;.data.ACD_PASSWORD&#125;&#39; | base64 -d</span><br><span class="line"></span><br><span class="line">2. You can watch the progress of Devtron microservices installation by the following command</span><br><span class="line"></span><br><span class="line">   kubectl -n devtroncd get installers installer-devtron -o jsonpath&#x3D;&#39;&#123;.status.sync.status&#125;&#39;</span><br></pre></td></tr></table></figure><p>上面的命令会帮我们创建一个用于安装 devtron 的 Pod，该 Pod 会去读取我们的 <code>installaction-script</code> 脚本进行初始化安装，这个安装过程需要花一点时间，不过需要注意的是需要提供一个默认的 StorageClass，否则 MinIO 对应的 PVC 没办法绑定，也就安装不成功了，我这里是在代码仓库中明确指定的一个名为 <code>nfs-storage</code> 的 StorageClass，正常安装后会产生很多 Pod：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113548589-2021-06-30-Zl4ugu.jpg" alt="devtron pods"></p><p>为了访问方便我这里还创建了一个 IngressRoute 对象用来绑定 Dashboard：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># devtron-ingressroute.yaml</span><br><span class="line">apiVersion: traefik.containo.us&#x2F;v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: devtron</span><br><span class="line">  namespace: devtroncd</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - web</span><br><span class="line">  routes:</span><br><span class="line">    - kind: Rule</span><br><span class="line">      match: Host(&#96;devtron.k8s.local&#96;)</span><br><span class="line">      services:</span><br><span class="line">        - name: devtron-service</span><br><span class="line">          port: 80</span><br></pre></td></tr></table></figure><p>创建完成后我们就可以通过域名（提前做好解析）就可以访问 devtron 了。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630130148000-2021-06-30-tQSDbk.jpg" alt="login devtron"></p><p>登录的时候使用的默认用户名为 <code>admin</code>，密码则可以使用上面安装 Helm Charts 的时候的提示命令获取:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n devtroncd get secret devtron-secret -o jsonpath&#x3D;&#39;&#123;.data.ACD_PASSWORD&#125;&#39; | base64 -d</span><br></pre></td></tr></table></figure><p>登录后就可以进入到 Dashboard 的主页了：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113548607-2021-06-30-W9dUld.jpg" alt></p><p>进入 Dashboard 后我们还需要做一些配置才能使用，比如添加 Docker 镜像仓库、配置 gitops 等。具体使用方法可以参考官方文档说明 <a href="https://docs.devtron.ai" target="_blank" rel="noopener">https://docs.devtron.ai</a>，后续我们再提供一个详细的使用文档。</p><blockquote><p>本文转载自：「 Github爱好者 」，原文：<a href="https://tinyurl.com/4y93htj9" target="_blank" rel="noopener">https://tinyurl.com/4y93htj9</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Devtron(&lt;a href=&quot;https://devtron.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://devtron.ai&lt;/a&gt;) 是用 go 编写的用于 Kubernetes 交付工作流管理的开源软件。它被设计为一个自我服务平台，以开发者友好的方式在 Kubernetes 上运维和维护应用程序（AppOps）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;仓库地址：&lt;a href=&quot;https://github.com/devtron-labs/devtron&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/devtron-labs/devtron&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Devtron" scheme="https://www.hi-linux.com/tags/Devtron/"/>
    
  </entry>
  
  <entry>
    <title>GitHub 访问慢？手把手教你几招解决它！</title>
    <link href="https://www.hi-linux.com/posts/50785.html"/>
    <id>https://www.hi-linux.com/posts/50785.html</id>
    <published>2021-07-12T01:00:00.000Z</published>
    <updated>2021-07-13T03:08:10.355Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>由于众所周知的原因，在国内的网络环境下，访问 Github 时，网络会阻断或者很慢。本文提供了若干访问方法。</p></blockquote><h2><span id="1-使用-github-mirror-下载">1. 使用 Github Mirror 下载</span></h2><p>直接在 GitHub 仓库前面拼接 Proxy 地址，不同的 Mirror 拼接方式可能有所不同。下面以拉取 <a href="https://github.com/shaowenchen/scripts" target="_blank" rel="noopener">https://github.com/shaowenchen/scripts</a> 仓库为例。</p><ul><li><a href="https://mirror.ghproxy.com/" target="_blank" rel="noopener">https://mirror.ghproxy.com</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;mirror.ghproxy.com&#x2F;https:&#x2F;&#x2F;github.com&#x2F;shaowenchen&#x2F;scripts</span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com.cnpmjs.org/" target="_blank" rel="noopener">https://github.com.cnpmjs.org</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com.cnpmjs.org&#x2F;shaowenchen&#x2F;scripts</span><br></pre></td></tr></table></figure><a id="more"></a><h2><span id="2-通过-gitee-导入-github-项目">2. 通过 Gitee 导入 GitHub 项目</span></h2><p>可以参考文档: <a href="https://gitee.com/help/articles/4284" target="_blank" rel="noopener">GitHub仓库快速导入Gitee及同步更新</a>, 将 GitHub 仓库导入 Gitee。然后使用 Gitee 的地址拉取代码。</p><blockquote><p>文档链接：<a href="https://gitee.com/help/articles/4284" target="_blank" rel="noopener">https://gitee.com/help/articles/4284</a></p></blockquote><h2><span id="3-配置-github-host-地址">3. 配置 Github Host 地址</span></h2><p>打开 <a href="https://www.ipaddress.com/" target="_blank" rel="noopener">https://www.ipaddress.com/</a> 查询 <a href="https://github.com.ipaddress.com/" target="_blank" rel="noopener">github.com</a> 的 IP 地址</p><p>编辑本地 /etc/hosts 文件，添加如下内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">140.82.112.4 github.com</span><br></pre></td></tr></table></figure><p>或者直接使用开源项目 GitHub520 获取最新的 IP 地址。</p><blockquote><p>项目地址：<a href="https://github.com/521xueweihan/GitHub520" target="_blank" rel="noopener">https://github.com/521xueweihan/GitHub520</a></p></blockquote><p>接着就可以拉取代码了，但是速度并不会很快，因为 Github 用的是美国 IP。</p><h2><span id="4-配置命令行代理">4. 配置命令行代理</span></h2><p>如果有可用的代理服务，那么在本地 Terminal 中配置代理即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Proxy</span><br><span class="line">function proxy_off()&#123;</span><br><span class="line">    unset http_proxy</span><br><span class="line">    unset HTTP_PROXY</span><br><span class="line">    unset https_proxy</span><br><span class="line">    unset HTTPS_PROXY</span><br><span class="line">    echo -e &quot;已关闭代理&quot;</span><br><span class="line">&#125;</span><br><span class="line">function proxy_on()&#123;</span><br><span class="line">    export http_proxy&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    export HTTP_PROXY&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    export https_proxy&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    export HTTPS_PROXY&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    echo -e &quot;已开启代理&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「陈少文的网站」，原文：<a href="https://tinyurl.com/4tubycn9" target="_blank" rel="noopener">https://tinyurl.com/4tubycn9</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;由于众所周知的原因，在国内的网络环境下，访问 Github 时，网络会阻断或者很慢。本文提供了若干访问方法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-使用-Github-Mirror-下载&quot;&gt;1. 使用 Github Mirror 下载&lt;/h2&gt;
&lt;p&gt;直接在 GitHub 仓库前面拼接 Proxy 地址，不同的 Mirror 拼接方式可能有所不同。下面以拉取 &lt;a href=&quot;https://github.com/shaowenchen/scripts&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/shaowenchen/scripts&lt;/a&gt; 仓库为例。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://mirror.ghproxy.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mirror.ghproxy.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git clone https:&amp;#x2F;&amp;#x2F;mirror.ghproxy.com&amp;#x2F;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;shaowenchen&amp;#x2F;scripts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com.cnpmjs.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com.cnpmjs.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git clone https:&amp;#x2F;&amp;#x2F;github.com.cnpmjs.org&amp;#x2F;shaowenchen&amp;#x2F;scripts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/categories/WireGuard/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>Wintun：一款惊艳的 WireGuard 虚拟网卡接口驱动</title>
    <link href="https://www.hi-linux.com/posts/42946.html"/>
    <id>https://www.hi-linux.com/posts/42946.html</id>
    <published>2021-07-07T01:00:00.000Z</published>
    <updated>2021-07-08T08:13:31.352Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>前一段时间，一直在找寻 Windows 操作系统上的虚拟网卡接口，主要是为了搭建隧道使用。但是 Windows 操作系统不像 Linux 操作系统，它的代码不开源，导致这方面的资料很少，因此花费了较长时间来寻找相关实现框架，最终找到了两款开源项目的虚拟接口驱动：</p><ul><li>Wireguard 项目的 Wintun 接口[1]</li><li>OpenVPN 的 Tap 接口[2]</li></ul><p>这两个项目都是非常出名的搭建隧道的开源 V.P.N 项目。由于目前对 openVPN 项目不太了解，也没有适配 Tap 接口，因此这里重点介绍下 WinTun 接口。此接口实现我是非常非常的喜欢，喜欢到简直不要不要的。</p><a id="more"></a><h2><span id="简介">简介</span></h2><p>说到 Wintun 项目，就不得不说到它的父亲：WireGuard 项目（以下简称 WG）。<strong>Github 传送门</strong>[3]</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113612450-2021-06-30-Tfcrxr.png" alt></p><p>WG 项目作为开源 V.P.N 项目，不同于 OpenVPN, Openswan, Strongswan 等，它的实现非常简介，Linux 内核代码实现不到 4000 行。相对于上述的三个 “按行收费” 的项目（代码 10 万行起步），它简直是太简洁了。故而得到了众多好评，其中就包括 Linux 鼻祖：Linus Torvalds。他的评价如下：</p><blockquote><p>Btw, on an unrelated issue: I see that Jason actually made the pull request to have wireguard included in the kernel.</p><p>Can I just once again state my love for it and hope it gets merged soon? Maybe the code isn’t perfect, but I’ve skimmed it, and compared to the horrors that are OpenVPN and IPSec, it’s a work of art.</p><p>Linus</p></blockquote><p>简而言之就是：<strong>劳资稀罕你，要把你合入我的 Linux 项目中</strong>。因此 Linux 内核自 5.6 之后便自带 WG 隧道功能，配置非常的简单。通过几行代码便可以完成一个 WG 隧道：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip link add dev wg0 type wireguard</span><br><span class="line">$ ip address add dev wg0 10.0.0.1&#x2F;24</span><br><span class="line">$ wg set wg0 listen-port 51820 private-key .&#x2F;private.key peer NIk5TyDpRDoU9tfIckTTXCsz1eht2aEmdN7l0Q31ow0&#x3D; allowed-ips 10.0.0.2&#x2F;32 endpoint 192.168.1.5:51820</span><br><span class="line">$ ip link set dev wg0 up</span><br></pre></td></tr></table></figure><p>配置非常简单。除此之外，还提供了 Windows 客户端，这也是此项目为何包含 Wintun 虚拟网络接口的原因。</p><p>客户端页面也是非常简洁，没有多余的东西 (<strong>客户端链接</strong>[4])：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113622279-2021-06-30-pTYDow.png" alt></p><p>客户端上隧道协商成功之后，会根据隧道名称建立一个虚拟网卡，隧道拆除后接口自动删除。由于我的隧道名称为 Tun-1，因此在 “控制版面” 的“网络连接”中出现了一个 Tun-1 的网络接口：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113627967-2021-06-30-a6Sb0B.png" alt></p><p>好了，下面开始介绍此虚拟网络接口。</p><h2><span id="wintun-虚拟网络接口">WinTun 虚拟网络接口</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210630113633922-2021-06-30-rnV9d1.png" alt></p><ul><li><p><strong>Github 传送门</strong>[5]</p></li><li><p><strong>wintun 官网传送门</strong>[6]</p></li></ul><p>常见的 <strong>windwos 的接口驱动开发</strong>[7]、安装比较复杂。常见的驱动安装包有：.inf 文件、.sys 文件、.cat 文件; 除此之外还涉及驱动程序签名，否则无法安装成功。尤其在开发调试阶段，每次都得签名，太磨叽了。</p><p>但是 WinTun 接口用法<strong>非常简单高效</strong>。<strong>非常简单高效</strong>。<strong>非常简单高效</strong>。</p><blockquote><ol><li>引入头文件：wintun.h</li><li>加载动态库，解析动态库中的函数指针</li></ol></blockquote><p>它通过<strong>动态库</strong>中方式来提供接口，我们可以加载此动态库，然后调用动态库中的函数指针来完成虚拟接口的创建、销毁、收发数据包等工作。此外<strong>它提供了一个示例供大家学习</strong>[8]，我便是通过参考开源代码中的示例（example.c），将 Wintun 接口移植到我的工程之中。非常简单，我太喜欢它了。</p><p>实例代码就 400 行，其中大部分为 log 信息，供大家查看程序运行状态和报文收发信息。</p><h3><span id="加载动态库中的函数指针">加载动态库中的函数指针</span></h3><p>此函数的作用：</p><ul><li><strong>加载动态库，获取到动态库中的函数指针，后面通过函数指针来操作虚拟网卡接口。</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">static HMODULE</span><br><span class="line">InitializeWintun(void)</span><br><span class="line">&#123;</span><br><span class="line">    HMODULE Wintun &#x3D;</span><br><span class="line">        LoadLibraryExW(L&quot;wintun.dll&quot;, NULL, LOAD_LIBRARY_SEARCH_APPLICATION_DIR | LOAD_LIBRARY_SEARCH_SYSTEM32);</span><br><span class="line">    if (!Wintun)</span><br><span class="line">        return NULL;</span><br><span class="line">#define X(Name, Type) ((Name &#x3D; (Type)GetProcAddress(Wintun, #Name)) &#x3D;&#x3D; NULL)</span><br><span class="line">    if (X(WintunCreateAdapter, WINTUN_CREATE_ADAPTER_FUNC) || X(WintunDeleteAdapter, WINTUN_DELETE_ADAPTER_FUNC) ||</span><br><span class="line">        X(WintunDeletePoolDriver, WINTUN_DELETE_POOL_DRIVER_FUNC) || X(WintunEnumAdapters, WINTUN_ENUM_ADAPTERS_FUNC) ||</span><br><span class="line">        X(WintunFreeAdapter, WINTUN_FREE_ADAPTER_FUNC) || X(WintunOpenAdapter, WINTUN_OPEN_ADAPTER_FUNC) ||</span><br><span class="line">        X(WintunGetAdapterLUID, WINTUN_GET_ADAPTER_LUID_FUNC) ||</span><br><span class="line">        X(WintunGetAdapterName, WINTUN_GET_ADAPTER_NAME_FUNC) ||</span><br><span class="line">        X(WintunSetAdapterName, WINTUN_SET_ADAPTER_NAME_FUNC) ||</span><br><span class="line">        X(WintunGetRunningDriverVersion, WINTUN_GET_RUNNING_DRIVER_VERSION_FUNC) ||</span><br><span class="line">        X(WintunSetLogger, WINTUN_SET_LOGGER_FUNC) || X(WintunStartSession, WINTUN_START_SESSION_FUNC) ||</span><br><span class="line">        X(WintunEndSession, WINTUN_END_SESSION_FUNC) || X(WintunGetReadWaitEvent, WINTUN_GET_READ_WAIT_EVENT_FUNC) ||</span><br><span class="line">        X(WintunReceivePacket, WINTUN_RECEIVE_PACKET_FUNC) ||</span><br><span class="line">        X(WintunReleaseReceivePacket, WINTUN_RELEASE_RECEIVE_PACKET_FUNC) ||</span><br><span class="line">        X(WintunAllocateSendPacket, WINTUN_ALLOCATE_SEND_PACKET_FUNC) || X(WintunSendPacket, WINTUN_SEND_PACKET_FUNC))</span><br><span class="line">#undef X</span><br><span class="line">    &#123;</span><br><span class="line">        DWORD LastError &#x3D; GetLastError();</span><br><span class="line">        FreeLibrary(Wintun);</span><br><span class="line">        SetLastError(LastError);</span><br><span class="line">        return NULL;</span><br><span class="line">    &#125;</span><br><span class="line">    return Wintun;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="main-函数">main() 函数</span></h3><p>作用：</p><ul><li><strong>通过函数指针创建虚拟网卡</strong></li><li><strong>创建虚拟网卡的收发线程</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">int</span><br><span class="line">main(void)</span><br><span class="line">&#123;</span><br><span class="line">    HMODULE Wintun &#x3D; InitializeWintun();</span><br><span class="line">    if (!Wintun)</span><br><span class="line">        return LogError(L&quot;Failed to initialize Wintun&quot;, GetLastError());</span><br><span class="line">    WintunSetLogger(ConsoleLogger);</span><br><span class="line">    Log(WINTUN_LOG_INFO, L&quot;Wintun library loaded&quot;);</span><br><span class="line">    WintunEnumAdapters(L&quot;Example&quot;, PrintAdapter, 0);</span><br><span class="line"></span><br><span class="line">    DWORD LastError;</span><br><span class="line">    HaveQuit &#x3D; FALSE;</span><br><span class="line">    QuitEvent &#x3D; CreateEventW(NULL, TRUE, FALSE, NULL);</span><br><span class="line">    if (!QuitEvent)</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogError(L&quot;Failed to create event&quot;, GetLastError());</span><br><span class="line">        goto cleanupWintun;</span><br><span class="line">    &#125;</span><br><span class="line">    if (!SetConsoleCtrlHandler(CtrlHandler, TRUE))</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogError(L&quot;Failed to set console handler&quot;, GetLastError());</span><br><span class="line">        goto cleanupQuit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    GUID ExampleGuid &#x3D; &#123; 0xdeadbabe, 0xcafe, 0xbeef, &#123; 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef &#125; &#125;;</span><br><span class="line">    WINTUN_ADAPTER_HANDLE Adapter &#x3D; WintunOpenAdapter(L&quot;Example&quot;, L&quot;Demo&quot;);</span><br><span class="line">    if (!Adapter)</span><br><span class="line">    &#123;</span><br><span class="line">        Adapter &#x3D; WintunCreateAdapter(L&quot;Example&quot;, L&quot;Demo&quot;, &amp;ExampleGuid, NULL);</span><br><span class="line">        if (!Adapter)</span><br><span class="line">        &#123;</span><br><span class="line">            LastError &#x3D; GetLastError();</span><br><span class="line">            LogError(L&quot;Failed to create adapter&quot;, LastError);</span><br><span class="line">            goto cleanupQuit;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    DWORD Version &#x3D; WintunGetRunningDriverVersion();</span><br><span class="line">    Log(WINTUN_LOG_INFO, L&quot;Wintun v%u.%u loaded&quot;, (Version &gt;&gt; 16) &amp; 0xff, (Version &gt;&gt; 0) &amp; 0xff);</span><br><span class="line"></span><br><span class="line">    MIB_UNICASTIPADDRESS_ROW AddressRow;</span><br><span class="line">    InitializeUnicastIpAddressEntry(&amp;AddressRow);</span><br><span class="line">    WintunGetAdapterLUID(Adapter, &amp;AddressRow.InterfaceLuid);</span><br><span class="line">    AddressRow.Address.Ipv4.sin_family &#x3D; AF_INET;</span><br><span class="line">    AddressRow.Address.Ipv4.sin_addr.S_un.S_addr &#x3D; htonl((10 &lt;&lt; 24) | (6 &lt;&lt; 16) | (7 &lt;&lt; 8) | (7 &lt;&lt; 0)); &#x2F;* 10.6.7.7 *&#x2F;</span><br><span class="line">    AddressRow.OnLinkPrefixLength &#x3D; 24; &#x2F;* This is a &#x2F;24 network *&#x2F;</span><br><span class="line">    LastError &#x3D; CreateUnicastIpAddressEntry(&amp;AddressRow);</span><br><span class="line">    if (LastError !&#x3D; ERROR_SUCCESS &amp;&amp; LastError !&#x3D; ERROR_OBJECT_ALREADY_EXISTS)</span><br><span class="line">    &#123;</span><br><span class="line">        LogError(L&quot;Failed to set IP address&quot;, LastError);</span><br><span class="line">        goto cleanupAdapter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    WINTUN_SESSION_HANDLE Session &#x3D; WintunStartSession(Adapter, 0x400000);</span><br><span class="line">    if (!Session)</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogLastError(L&quot;Failed to create adapter&quot;);</span><br><span class="line">        goto cleanupAdapter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Log(WINTUN_LOG_INFO, L&quot;Launching threads and mangling packets...&quot;);</span><br><span class="line"></span><br><span class="line">    HANDLE Workers[] &#x3D; &#123; CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)ReceivePackets, (LPVOID)Session, 0, NULL),</span><br><span class="line">                         CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)SendPackets, (LPVOID)Session, 0, NULL) &#125;;</span><br><span class="line">    if (!Workers[0] || !Workers[1])</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogError(L&quot;Failed to create threads&quot;, GetLastError());</span><br><span class="line">        goto cleanupWorkers;</span><br><span class="line">    &#125;</span><br><span class="line">    WaitForMultipleObjectsEx(_countof(Workers), Workers, TRUE, INFINITE, TRUE);</span><br><span class="line">    LastError &#x3D; ERROR_SUCCESS;</span><br><span class="line"></span><br><span class="line">cleanupWorkers:</span><br><span class="line">    HaveQuit &#x3D; TRUE;</span><br><span class="line">    SetEvent(QuitEvent);</span><br><span class="line">    for (size_t i &#x3D; 0; i &lt; _countof(Workers); ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        if (Workers[i])</span><br><span class="line">        &#123;</span><br><span class="line">            WaitForSingleObject(Workers[i], INFINITE);</span><br><span class="line">            CloseHandle(Workers[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    WintunEndSession(Session);</span><br><span class="line">cleanupAdapter:</span><br><span class="line">    WintunDeleteAdapter(Adapter, FALSE, NULL);</span><br><span class="line">    WintunFreeAdapter(Adapter);</span><br><span class="line">cleanupQuit:</span><br><span class="line">    SetConsoleCtrlHandler(CtrlHandler, FALSE);</span><br><span class="line">    CloseHandle(QuitEvent);</span><br><span class="line">cleanupWintun:</span><br><span class="line">    FreeLibrary(Wintun);</span><br><span class="line">    return LastError;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>收发报文的接口操作也非常简单，但是与 windows 网络协议栈之间的关系仍需要继续摸索。</p><h3><span id="特别说明">特别说明</span></h3><p>Wintun 接口是严格意义上的 3 层逻辑接口。原文如下：</p><blockquote><p>Wintun is a very simple and minimal TUN driver for the Windows kernel, which provides userspace programs with a simple network adapter for reading and writing packets. It is akin to Linux’s /dev/net/tun and BSD’s /dev/tun. Originally designed for use in WireGuard, Wintun is meant to be generally useful for a wide variety of layer 3 networking protocols and experiments. The driver is open source, so anybody can inspect and build it. Due to Microsoft’s driver signing requirements, we provide precompiled and signed versions that may be distributed with your software. The goal of the project is to be as simple as possible, opting to do things in the most pure and straight-forward way provided by NDIS.</p></blockquote><p>这里出现了一个小小的问题：<strong>Wireshark 上无法抓取此接口报文</strong>。如果想看封装后的报文信息，则需要单独记录日志而非抓包来完成。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113648931-2021-06-30-rB5kXq.png" alt></p><p>导致这个问题原因没有找到，我认为是：<strong>wireshark 抓取的报文是二层报文 (一个完整的以太网帧)，而 3 层逻辑接口上的报文尚未封装以太网帧，故无法抓取此接口。这只是个人猜测，根本原因不得而知。</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113654931-2021-06-30-0mF6hi.png" alt></p><p>好了，基本介绍完毕，重新表达下我对 WireGuard 和 WinTun 的态度：<strong>劳资稀罕你，very 喜欢。</strong></p><blockquote><p>原文链接：<a href="https://blog.csdn.net/s2603898260/article/details/117389372" target="_blank" rel="noopener">https://blog.csdn.net/s2603898260/article/details/117389372</a></p></blockquote><h3><span id="脚注">脚注</span></h3><p>[1]Wireguard 项目的 Wintun 接口: <em><a href="https://github.com/WireGuard" target="_blank" rel="noopener">https://github.com/WireGuard</a></em></p><p>[2]OpenVPN 的 Tap 接口: <em><a href="https://github.com/Toney-Sun/openvpn" target="_blank" rel="noopener">https://github.com/Toney-Sun/openvpn</a></em></p><p>[3]Github 传送门: <em><a href="https://github.com/WireGuard" target="_blank" rel="noopener">https://github.com/WireGuard</a></em></p><p>[4]客户端链接: <em><a href="https://www.wireguard.com/install/" target="_blank" rel="noopener">https://www.wireguard.com/install/</a></em></p><p>[5]Github 传送门: <em><a href="https://github.com/Toney-Sun/wintun" target="_blank" rel="noopener">https://github.com/Toney-Sun/wintun</a></em></p><p>[6]wintun 官网传送门: <em><a href="https://www.wintun.net/" target="_blank" rel="noopener">https://www.wintun.net/</a></em></p><p>[7]windwos 的接口驱动开发: <em><a href="https://docs.microsoft.com/zh-cn/windows-hardware/drivers/install/components-of-a-driver-package" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/windows-hardware/drivers/install/components-of-a-driver-package</a></em></p><p>[8]它提供了一个示例供大家学习: <em><a href="https://git.zx2c4.com/wintun/tree/example/example.c" target="_blank" rel="noopener">https://git.zx2c4.com/wintun/tree/example/example.c</a></em></p><blockquote><p>本文转载自：「云原生实验室」，原文：<a href="https://tinyurl.com/y6mv2ym2" target="_blank" rel="noopener">https://tinyurl.com/y6mv2ym2</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一段时间，一直在找寻 Windows 操作系统上的虚拟网卡接口，主要是为了搭建隧道使用。但是 Windows 操作系统不像 Linux 操作系统，它的代码不开源，导致这方面的资料很少，因此花费了较长时间来寻找相关实现框架，最终找到了两款开源项目的虚拟接口驱动：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wireguard 项目的 Wintun 接口[1]&lt;/li&gt;
&lt;li&gt;OpenVPN 的 Tap 接口[2]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个项目都是非常出名的搭建隧道的开源 V.P.N 项目。由于目前对 openVPN 项目不太了解，也没有适配 Tap 接口，因此这里重点介绍下 WinTun 接口。此接口实现我是非常非常的喜欢，喜欢到简直不要不要的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/categories/WireGuard/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/tags/WireGuard/"/>
    
  </entry>
  
  <entry>
    <title>写给 Linux 小白用户的命令行极简教程</title>
    <link href="https://www.hi-linux.com/posts/38789.html"/>
    <id>https://www.hi-linux.com/posts/38789.html</id>
    <published>2021-07-06T01:00:00.000Z</published>
    <updated>2021-07-06T04:38:08.156Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>电脑图形化的交互方式对用户使用来说更加的友好，而对于命令行的操作方式来说，通常会有更加高的学习曲线。但你不得不承认，使用图形化的界面会需要更多的计算资源，而且通常来说是比较难通过脚本的方式进行自动化的。</p><p>所以我们要辩证的来看这个问题，图形界面操作方式虽好，但是对于工程师来说，如果我们要更高效的完成我们的工作，命令行是一个比较好的通过自动化的方式提高我们工作效率的方式。</p><p>今天要推荐的开源项目汇总了我们日常会使用的命令行的列表，并增加了有趣的讲解方式，相信能够帮助你很好的入门命令行操作方式。</p><a id="more"></a><p><img src="https://img.hi-linux.com/staticfile/image-20210630104614098-2021-06-30-j5qxxN.png" alt></p><p>以上是一个目录列表，基本覆盖了日常经常用到的，如果能使用上一定会极大提高你的效率。</p><p>以下是对搜索文档的命令解释：</p><p><img src="https://img.hi-linux.com/staticfile/image-20210630104542733-2021-06-30-F5F6qf.png" alt></p><p>更多详情请查看 <code>You-Dont-Need-GUI</code> 开源项目链接：<a href="https://github.com/you-dont-need/You-Dont-Need-GUI" target="_blank" rel="noopener">https://github.com/you-dont-need/You-Dont-Need-GUI</a></p><blockquote><p>本文转载自：「 GitHub 精选 」，原文：<a href="https://tinyurl.com/hehuhfjj" target="_blank" rel="noopener">https://tinyurl.com/hehuhfjj</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;电脑图形化的交互方式对用户使用来说更加的友好，而对于命令行的操作方式来说，通常会有更加高的学习曲线。但你不得不承认，使用图形化的界面会需要更多的计算资源，而且通常来说是比较难通过脚本的方式进行自动化的。&lt;/p&gt;
&lt;p&gt;所以我们要辩证的来看这个问题，图形界面操作方式虽好，但是对于工程师来说，如果我们要更高效的完成我们的工作，命令行是一个比较好的通过自动化的方式提高我们工作效率的方式。&lt;/p&gt;
&lt;p&gt;今天要推荐的开源项目汇总了我们日常会使用的命令行的列表，并增加了有趣的讲解方式，相信能够帮助你很好的入门命令行操作方式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
</feed>
