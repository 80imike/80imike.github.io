<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>奇妙的 Linux 世界</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2022-11-18T12:25:09.888Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>互联网时代的大容量数据备份方案</title>
    <link href="https://www.hi-linux.com/posts/16568.html"/>
    <id>https://www.hi-linux.com/posts/16568.html</id>
    <published>2022-11-15T01:00:00.000Z</published>
    <updated>2022-11-18T12:25:09.888Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="0前言">0.前言</span></h2><p>在互联网时代之前，“数据”这个概念似乎并不算抽象。无论是文字、照片还是磁带光盘，想要对他们进行备份不外乎复印、拷贝和储存这些手段。然而进入互联网时代之后（或者说是计算机时代），“数据”这一概念慢慢的开始抽象起来，不再与实体相关联。与此同时，数据的持久化储存也不再像往日那般依靠物理的方式来进行，转而便成了0和1的组合在各种存储介质中流动。</p><p>然而各类存储介质故障的不可预知性让人们开始重新审视数据备份这件小事。俗话说鸡蛋不要放在同一个篮子里，对于备份而言亦是如此。无论本地如何进行备份和冗余，一份远程副本都是非常必要的。本文将尝试收集市面较为知名的存储服务商，并进行比较以供参考。考虑到稳定性、隐私等方面的原因，国内网盘类服务商将不予考虑。</p><p>本文与所提及的任何服务商均无利益关系，请放心食用。相关价格均为常规正价，不含闪促、秒杀等。</p><a id="more"></a><h2><span id="1国内对象存储">1.国内·对象存储</span></h2><p>有关于什么是对象存储，之前的<a href="https://roov.org/2021/11/backup-nas-using-cos/" target="_blank" rel="noopener">这篇文章</a>中已经有过介绍，这里便不再重复说明。通常而言对象存储类服务的计费模式为：容量费用+操作费用+下载费用。对于个人数据备份而言，操作费用几乎可以忽略。而下载费用本文中按照5年全量取回一次的价格，均摊到月来计算。</p><p>由于国内服务商各类型的促销活动较多，实际成本可能更低。</p><h3><span id="11-腾讯云cos">1.1 腾讯云COS</span></h3><p><img src="https://img.hi-linux.com/staticfile/16a166fd39131aa120eae50ab366697b970ac4b444b0-So1nR8-20221116120602037-2022-11-16-v7m4lc.webp" alt></p><p><a href="https://cloud.tencent.com/act/cps/redirect?redirect=10042&amp;cps_key=25c451b71f39a37c7941e062fc1fb2f3" target="_blank" rel="noopener">链接直达</a>（含AFF）</p><p>腾讯云 COS 目前国内涵盖了北京、上海，广州等七个地域以及海外的十三个地域，不过国内和海外为分别计费。存储等级分为：标准、低频，归档和深度归档等，价格依次降低。但除标准存储外，其他等级均有额外的数据取回费用和一定的存储限制，具体可以参见官网。</p><p>按照预先购买标准存储资源包的存储成本：</p><ul><li>500G：￥39.53/月，￥42.32/月（五年全量取回一次平均到月，下同）</li><li>1T：￥79.75/月，￥85.25/月</li><li>2T：￥157.08/月，￥167.91/月</li><li>5T：￥386.66/月，￥413.33/月</li></ul><h3><span id="12-阿里云oss">1.2 阿里云OSS</span></h3><p><img src="https://img.hi-linux.com/staticfile/aliyun-2022-11-16-u1qNxE.webp" alt></p><p><a href="https://www.aliyun.com/product/oss?userCode=pmweg1o2" target="_blank" rel="noopener">链接直达</a>（含AFF）</p><p>阿里云 OSS 同样也是国内和国外地域分别计费，存储等级分为：标准、低频，归档以及冷归档。与腾讯云 COS 不同，阿里云允许用户在本地冗余和同城冗余之间进行选择，相应的价格也有少许差别。</p><p>按照预先购买标准存储（本地冗余）资源包的存储成本：</p><ul><li>500G：￥54/月，￥58.12/月（五年全量取回一次平均到月，下同）</li><li>1T：￥111/月，￥118.92/月</li><li>2T：￥221/月，￥236.5/月</li><li>5T：￥523/月，￥562.58/月</li></ul><h3><span id="13-京东云">1.3 京东云</span></h3><p><img src="https://img.hi-linux.com/staticfile/nIVAgx-2022-11-16-7Vkj2r.jpg" alt></p><p><a href="https://www.jdcloud.com/cn/products/object-storage-service" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>京东云对象存储目前仅有国内四个地域，但是兼容 S3 协议，与各类 NAS 系统和同步软件都能良好适配。</p><p>预付费资源包没有单独的 1T ，2T 选项，故直接按照 500G 的倍率来计算。</p><ul><li>500G：￥56/月，￥59.22/月（五年全量取回一次平均到月，下同）</li><li>1T：￥112/月，￥118.43/月</li><li>2T：￥224/月，￥236.83/月</li><li>5T：￥550/月，￥582.17/月</li></ul><h3><span id="14-百度云">1.4 百度云</span></h3><p><img src="https://img.hi-linux.com/staticfile/cloudbaidu-20221116120607418-2022-11-16-HcXATX.webp" alt></p><p><a href="https://cloud.baidu.com/product/bos.html" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>此处所提到的百度云并非“百度云盘”，而是百度智能云所提供的对象存储 BOS 服务。百度云 BOS 也兼容 S3 协议。考虑到综合口碑和声誉，个人不推荐。</p><p>需要注意百度云 BOS 的预付费资源包各地域不通用，需要单独购买。</p><ul><li>500G：￥53.8/月，￥57.8/月（五年全量取回一次平均到月，下同）</li><li>1T：￥110/月，￥118.18/月</li><li>2T：￥220/月，￥236.37/月</li><li>5T：￥550/月，￥590.92/月</li></ul><h3><span id="15-小结">1.5 小结</span></h3><p>作为面向商业用户为主的对象存储服务，在国内的商业环境下总体价格并不便宜，价格完全无法与面向个人用户为主的网盘相比较。但在稳定性、速度、可靠性方面对象存储无疑是远超各种网盘的。对于个人用户而言，500G 以内的备份需求可以首选考虑国内厂商的对象存储服务，在成本可控的前提下获得最好的速度和体验。</p><p>腾讯云无论是预付费资源包还是按量计费的价格均显著低于其他厂商，建议可以优先考虑。</p><h2><span id="2国外对象存储">2.国外对象存储</span></h2><p>虽然国外服务商的对象存储服务在速度上无法和国内相提并论，但价格更加亲民，可谓是便宜大碗。并且不像国内厂商喜欢玩各种促销套路，一般直接明盘实价。考虑到速度上的短板，价格高于 $10/TB 每月的本文就不做收录了。</p><p>以下服务商均兼容 S3 协议。</p><h3><span id="21-backblaze-b2">2.1 Backblaze B2</span></h3><p><img src="https://img.hi-linux.com/staticfile/JFlJmD-2022-11-16-qcixZJ.jpg" alt></p><p><a href="https://www.backblaze.com/b2/cloud-storage.html" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>老牌数据服务商 Backblaze 很多人应该都不陌生，他每年都会发布自己的硬盘统计报告。Backblaze B2 便是其下的对象存储服务，有美国西海岸和荷兰两个存储地域，用户在注册时会自动进行分配。</p><p>如果使用 Cloudflare CDN 进行数据下载、取回则流量费为0。</p><ul><li>存储：$0.005/GB/Month 下载：$0.01/GB</li><li>500G：$2.5/月，$2.58/月（五年全量取回一次平均到月，下同）</li><li>1T：$5/月，$5.17/月</li><li>2T：$10/月，$10.33/月</li><li>5T：$25/月，$25.83/月</li></ul><h3><span id="22-wasabi">2.2 Wasabi</span></h3><p><img src="https://img.hi-linux.com/staticfile/Wasabi_Logo-1-2022-11-16-hgOSK5.webp" alt></p><p><a href="https://wasabi.com/cloud-storage-pricing/#three-info" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>Wasabi 是一家成立于2017年的美国公司，目前估值超过11亿美元。其对象存储服务在北美、欧洲，亚太各有四个地域可选，但价格略有波动。</p><p>Wasabi 对下载流量执行有限免费模式：每月的下载量如果不超过数据总储量是可被接受的，反之则可能会被限制或暂停服务。除此之外 Wasabi 还有最短储存期限为90天的限定，即存储 1GB 随即删除也会被收取90天 * 1GB 的存储费用。</p><ul><li>存储：$0.0059 GB/mo（北美、欧洲）$0.0068 GB/mo（亚太）</li><li>500G：$2.95/月，$3.4/月（亚太，下同）</li><li>1T：$5.99/月，$6.99/月</li><li>2T：$11.98/月，$13.98/月</li><li>5T：$29.95/月，$34.95/月</li></ul><h3><span id="23-scaleway">2.3 Scaleway</span></h3><p><img src="https://img.hi-linux.com/staticfile/csbh2-122f8-20221116120624790-2022-11-16-mTZv9Z.png" alt></p><p><a href="https://www.scaleway.com/en/object-storage/" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>Scaleway 前身为 <a href="http://online.net" target="_blank" rel="noopener">online.net</a> ，是一家1999年成立于法国的公司，主营业务有计算和存储等。其对象存储服务目前仅有欧洲的三个地域可选，但低频存储等级（Scaleway Glacier）不额外收取取回费用，也没有最短存储时间限制。但申请取回最长需要等待24小时。</p><ul><li>存储：€0.0127/GB/month（标准）€0.002/GB/month（低频）</li><li>500G：$6.35/月，$1/月（低频，下同）</li><li>1T：$12.7/月，$2/月</li><li>2T：$25.4/月，$4/月</li><li>5T：$63.5/月，$10/月</li></ul><h3><span id="24-ovh">2.4 OVH</span></h3><p><img src="https://img.hi-linux.com/staticfile/OVH-Logo-2022-11-16-M5wsQy.webp" alt></p><p><a href="https://www.ovhcloud.com/en-au/public-cloud/object-storage/" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>虽然之前经历了机房起火事件，不过 OVH 的业务似乎并没有受到多大影响。其下对象存储服务仅提供法国地域，价格未含税。</p><ul><li>存储：$0.008 /month/GB（标准）下载：$0.011 /GB</li><li>500G：$4/月，$4.09/月（五年全量取回一次平均到月，下同）</li><li>1T：$8/月，$8.18/月</li><li>2T：$16/月，$16.37/月</li><li>5T：$40/月，$40.92/月</li></ul><h3><span id="25-小结">2.5 小结</span></h3><p>部分国外服务商的对象存储服务价格确实不错，如果数据量大或者担心隐私问题的话也可以考虑。</p><h2><span id="3国外存储类产品">3.国外存储类产品</span></h2><p>除了对象存储之外，这里也收集列出一些存储类的产品作为对比和参考。其中部分产品可能并不是为数据备份所设计，本身并没有冗余和高可靠性，需要多加留意。</p><h3><span id="31-hetzner">3.1 Hetzner</span></h3><p><img src="https://img.hi-linux.com/staticfile/ChdrpN-2022-11-16-f0Swit.jpg" alt></p><p><a href="https://www.hetzner.com/storage/storage-box" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>Hetzner 旗下专门的存储类产品有两个，分别是 <a href="https://roov.org/2022/02/hetzner-storage-box-review/" target="_blank" rel="noopener">Storage box</a> 和 Storage share 。前者 reizhi 之前有做过评测，性价比相当出众。后者则更多的是面向多人团队协作共享，价格稍高一些。</p><p>以下为 Storage box 的价格：</p><ul><li>1T：$3.2/月</li><li>5T：$10.9/月</li></ul><p>如果你恰巧财力雄厚而又需要巨量的存储容量，也可以考虑拍卖服务器。通常 4x10TB 服务器价格在51欧元附近，即便组 RAID5 后单位容量价格依然无可匹敌。</p><h3><span id="32-microsoft-365-family">3.2 Microsoft 365 Family</span></h3><p><img src="https://img.hi-linux.com/staticfile/Untitled-Header-1-2022-11-16-IZLbH6.webp" alt></p><p><a href="https://www.microsoft.com/en-us/microsoft-365/p/microsoft-365-family/cfq7ttc0k5dm" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>Microsoft 365 前身是 Office 365，其中家庭方案价格为$9.99/月，支持创建6个子账号，每个子账号拥有 1TB OneDrive 容量。除此之外还带有 Office 三件套授权，如果正好有需要的话还是非常划算的。</p><p>Onedrive 官方客户端虽然不怎么好用，但好在可以通过 rclone 进行挂载，在 Linux 下使用也很方便。唯独不方便的是 6TB 需要拆分到六个账号，无法一号独占。</p><h3><span id="33-google-workspace">3.3 Google workspace</span></h3><p><img src="https://img.hi-linux.com/staticfile/VFC7iD-2022-11-16-BpDtYM.jpg" alt></p><p><a href="https://workspace.google.com/intl/tr/" target="_blank" rel="noopener">链接直达</a>（不含AFF）</p><p>Google workspace 是 Google 旗下的云协作办公解决方案，其中随附的一项功能便是 Google Drive。由于里拉汇率走低，土耳其区企业标准版 workspace 的价格目前相当不错。但未来是否能够继续保持低价位尚不可知。</p><ul><li>商务标准版：₺94/2TB，发文时约合$5.05</li><li>企业标准版：₺156/5TB，发文时约合$8.38</li></ul><h3><span id="34-各类存储vps">3.4 各类存储VPS</span></h3><p><img src="https://img.hi-linux.com/staticfile/33U3Fu-2022-11-16-CZckXK.jpg" alt></p><p>如果使用 VPS 进行数据备份则需要使用者具有一定的 Linux 操作知识，门槛相对较高。此外 VPS 服务本身的稳定性难以和大型厂商的云服务相提并论，仅少量收录但并不作为推荐。</p><p>当然，有能力的话也可以使用 MinIO 自行搭建多机灾备对象存储系统。</p><ul><li>hosthatch: $5/1TB/month $9/2TB/month $20/5TB/month</li><li>servarica: $10/3TB/month</li><li>leveloneservers: $4.25/1TB/month $8.5/2TB/month</li><li>time4vps: €3.99/1TB/month €6.49/2TB/month</li><li>buyvm: $5/1TB/month $10/2TB/month （单独存储块价格）</li><li>等等</li></ul><h3><span id="35-小结">3.5 小结</span></h3><p>第三部分所提到的服务商除了各类 VPS 之外，也都算是行业巨头。虽然网盘本身并不对数据安全做任何保证，但根据以往历史经验来看应该不存在特别高的风险，对于个人备份来说问题不大。此外 Onedrive 和 Google Drive 都支持通过 rclone 对接，无论 NAS 还是 Linux 均可以比较方便的接入。</p><h2><span id="4总结">4.总结</span></h2><p>对于个人用户而言异地备份的选择依据无非两点：使用成本和易用性（包括连接速度），而前者与存储容量直接相关。根据对备份容量的需求，reizhi 个人给出如下建议：</p><ul><li>100 ~ 500G ：如不排斥国内服务商直接选择腾讯云即可，如果遇到活动大促，年付或半年付还能够以更低的价格成交；</li><li>500G ~ 1T：容量从 500G 往上之后国外对象存储服务的价格开始显现出优势，建议可以优先考虑 Backblaze，Hetzner 可以作为备选。</li><li>2T ~ 5T：以目前的汇率来计算 Google workspace 无疑是最优选择，但缺点是国内无法直连，需要科学。Microsoft 365 可以作为备选，但多账号需要切换略为不便。</li><li>5T 以上：这应该超出了个人用户正常所需的备份容量范围，但如果确实有需要的话，可以考虑 Scaleway Glacier。</li></ul><blockquote><p>本文转载自：「 reizhi 」，原文：<a href="https://url.hi-linux.com/NyGpo" target="_blank" rel="noopener">https://url.hi-linux.com/NyGpo</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;0-前言&quot;&gt;0.前言&lt;/h2&gt;
&lt;p&gt;在互联网时代之前，“数据”这个概念似乎并不算抽象。无论是文字、照片还是磁带光盘，想要对他们进行备份不外乎复印、拷贝和储存这些手段。然而进入互联网时代之后（或者说是计算机时代），“数据”这一概念慢慢的开始抽象起来，不再与实体相关联。与此同时，数据的持久化储存也不再像往日那般依靠物理的方式来进行，转而便成了0和1的组合在各种存储介质中流动。&lt;/p&gt;
&lt;p&gt;然而各类存储介质故障的不可预知性让人们开始重新审视数据备份这件小事。俗话说鸡蛋不要放在同一个篮子里，对于备份而言亦是如此。无论本地如何进行备份和冗余，一份远程副本都是非常必要的。本文将尝试收集市面较为知名的存储服务商，并进行比较以供参考。考虑到稳定性、隐私等方面的原因，国内网盘类服务商将不予考虑。&lt;/p&gt;
&lt;p&gt;本文与所提及的任何服务商均无利益关系，请放心食用。相关价格均为常规正价，不含闪促、秒杀等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="备份" scheme="https://www.hi-linux.com/tags/%E5%A4%87%E4%BB%BD/"/>
    
  </entry>
  
  <entry>
    <title>如何优雅关闭与重启生产级 Kubernetes 集群</title>
    <link href="https://www.hi-linux.com/posts/17602.html"/>
    <id>https://www.hi-linux.com/posts/17602.html</id>
    <published>2022-11-09T01:00:00.000Z</published>
    <updated>2022-11-16T03:38:20.962Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="前言">前言</span></h2><p>在日常对 Kubernetes 集群运行维护的过程中，您可能需要临时的关闭或者是重启 Kubernetes 集群对集群进行维护，本文将介绍如何去安全的关闭 K8s 集群以及如何重新启动集群。</p><h2><span id="日常节点运维方式">日常节点运维方式</span></h2><p>关闭 K8s 集群是个危险的操作！在关闭集群之前，您必须完全了解这个操作所带来的后果。首先，我们要对集群内的应用、客户定义资源 CRD 和 Etcd 进行备份，然后再进行重启或关闭集群的操作。在通常运维的情况下，建议您驱逐维护节点，而非重启整个集群。在这里，我们也把驱逐维护节点命令放在下面供您参考。</p><a id="more"></a><p>首先，确定想要移出的节点的名称。可以用以下命令列出集群中的所有节点:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br></pre></td></tr></table></figure><p>接下来，告诉 Kubernetes 需要移出的节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl drain &lt;node name&gt;</span><br></pre></td></tr></table></figure><p>一旦它返回（没有报错）， 你就可以下线此节点（或者等价地在云平台上，删除支持该节点的虚拟机）。如果要在维护操作期间将节点留在集群中，则需要运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl uncordon &lt;node name&gt;</span><br></pre></td></tr></table></figure><p>然后告诉 Kubernetes，它可以继续在此节点上调度新的 Pods。</p><h2><span id="在进行集群关闭前的准备工作">在进行集群关闭前的准备工作</span></h2><p>备份是最最重要的准备工作，保障应用可以重新正常服务为目的各种操作都是必须的。做一个你自己的计划清单，在重要的步骤之前确认好。</p><ul><li>主机之间已经设置 SSH 免密登录</li><li>集群内应用的备份</li><li>集群内客户自定义资源的备份</li><li>集群内 Etcd 的备份</li></ul><h2><span id="关闭-kubernetes-集群">关闭 Kubernetes 集群</span></h2><blockquote><p><strong>再次提示</strong><br>在关闭集群前，请您务按照我们推荐的方法备份集群的数据与应用，以便在重新启动集群时如果遇到任何问题，可以通过备份还原集群与应用。<br>使用本教程中的方法可以平稳关闭集群，但数据损坏的可能性仍然存在。</p></blockquote><p>首先，我们要获取节点列表</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k8snodes=$(kubectl get nodes -o name)</span><br></pre></td></tr></table></figure><p>然后,我们就要关闭节点了，您可以可一台一台的关闭。或运行以下脚本关闭节点:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> <span class="variable">$&#123;k8snodes[@]&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"==== Shut down <span class="variable">$node</span> ===="</span></span><br><span class="line">    ssh <span class="variable">$node</span> sudo shutdown -h 1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><blockquote><p>注意: 前提条件是主机之间已经设置 SSH 免密登录。</p></blockquote><p>此时，您就可以关闭其他的集群依赖项，对集群进行维护操作啦。</p><h2><span id="kubernetes-集群重启">Kubernetes 集群重启</span></h2><p>在重启后，我们需要仔细检查所有节点和核心组件的状态，并确保一切就绪。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes -o wide</span><br><span class="line">NAME        STATUS   ROLES                  AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME</span><br><span class="line">mars-k8s1   Ready    control-plane,master   17d   v1.21.0   172.16.60.60   &lt;none&gt;        Ubuntu 20.04.1 LTS   5.11.0-40-generic   docker://20.10.10</span><br><span class="line">mars-k8s2   Ready    &lt;none&gt;                 17d   v1.21.0   172.16.60.61   &lt;none&gt;        Ubuntu 20.04.1 LTS   5.11.0-40-generic   docker://20.10.10</span><br><span class="line">mars-k8s3   Ready    &lt;none&gt;                 17d   v1.21.0   172.16.60.62   &lt;none&gt;        Ubuntu 20.04.1 LTS   5.11.0-40-generic   docker://20.10.10</span><br><span class="line"></span><br><span class="line">$ kubectl get svc -n kube-system</span><br><span class="line">NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">kube-dns         ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   17d</span><br><span class="line">metrics-server   ClusterIP   10.111.227.248   &lt;none&gt;        443/TCP                  17d</span><br><span class="line"></span><br><span class="line">$ kubectl get pod -n kube-system</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-558bd4d5db-h7jqc            1/1     Running   2          17d</span><br><span class="line">coredns-558bd4d5db-wj4bn            1/1     Running   2          17d</span><br><span class="line">etcd-mars-k8s1                      1/1     Running   2          17d</span><br><span class="line">kube-apiserver-mars-k8s1            1/1     Running   3          17d</span><br><span class="line">kube-controller-manager-mars-k8s1   1/1     Running   2          17d</span><br><span class="line">kube-flannel-ds-677dg               1/1     Running   2          17d</span><br><span class="line">kube-flannel-ds-bxhx6               1/1     Running   3          17d</span><br><span class="line">kube-flannel-ds-r5pqf               1/1     Running   2          17d</span><br><span class="line">kube-proxy-6w52h                    1/1     Running   2          17d</span><br><span class="line">kube-proxy-p8zfp                    1/1     Running   2          17d</span><br><span class="line">kube-proxy-v8t7j                    1/1     Running   2          17d</span><br><span class="line">kube-scheduler-mars-k8s1            1/1     Running   2          17d</span><br><span class="line">metrics-server-5f9459b95c-dtzbf     1/1     Running   2          17d</span><br></pre></td></tr></table></figure><h2><span id="kubernetes-集群重启维护避坑指南">Kubernetes 集群重启维护避坑指南</span></h2><p>说点儿心里话，运维有时要看运气，这不是开玩笑，在我的职业生涯中看到了也学到了很多，在过去我有幸支持了多个国家的数据灾备业务。包括：韩国，日本，中港台，及东南亚各个 Region 的客户公司，在运维做 IT 架构变更的时候，买烧猪祭奠关二爷有时真的需要，我们不了解的事情还有很多，要保持敬畏。所以备份吧，多备份几次！！！</p><p>在我们这个时代人定胜天的神迹比比皆是。但是所谓割接，割下来，接不上的情况也屡见不鲜。通常情况下，重新启动 Kubernetes 集群后就可以继续正常使用，但是由于意外情况，该集群可能不可用。例如：</p><ul><li>关闭集群过程中 Etcd 数据损坏或是节点故障，这在 Bare Metal K8s Node 上很常见。</li><li>网络错误，这就需要检查所有集群依赖项的状态，一定用好监控工具，一步一步的查，别怕麻烦，要确保所有集群依赖项均已就绪。</li><li>应用的问题，节点是启动了，K8s 也好好的，应用不能对外提供服务，这时一系列的排错是最考验人的，所以备份恢复吧。这样可以确保 RTO。</li></ul><h2><span id="参考链接">参考链接</span></h2><ol><li><a href="https://www.data2clouds.com/?p=118" target="_blank" rel="noopener">Kasten 实战系列备份K8S云原生应用</a></li><li><a href="https://www.data2clouds.com/?p=205" target="_blank" rel="noopener">Kasten k10 提高系列 02 - 用 Kasten 备份 kubernates etcd 数据库</a></li></ol><blockquote><p>本文转载自：「云端数据管理」，原文：<a href="https://url.hi-linux.com/YIzIq" target="_blank" rel="noopener">https://url.hi-linux.com/YIzIq</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;在日常对 Kubernetes 集群运行维护的过程中，您可能需要临时的关闭或者是重启 Kubernetes 集群对集群进行维护，本文将介绍如何去安全的关闭 K8s 集群以及如何重新启动集群。&lt;/p&gt;
&lt;h2 id=&quot;日常节点运维方式&quot;&gt;日常节点运维方式&lt;/h2&gt;
&lt;p&gt;关闭 K8s 集群是个危险的操作！在关闭集群之前，您必须完全了解这个操作所带来的后果。首先，我们要对集群内的应用、客户定义资源 CRD 和 Etcd 进行备份，然后再进行重启或关闭集群的操作。在通常运维的情况下，建议您驱逐维护节点，而非重启整个集群。在这里，我们也把驱逐维护节点命令放在下面供您参考。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>12 个超好用网站在线测速、路由追踪和 Ping 工具</title>
    <link href="https://www.hi-linux.com/posts/29415.html"/>
    <id>https://www.hi-linux.com/posts/29415.html</id>
    <published>2022-11-09T01:00:00.000Z</published>
    <updated>2022-11-16T03:38:20.964Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>我们在日常的建站中，经常要用到对网站加载速度测试服务。如遇到服务器自身的故障或是网络问题，可能还需要要对服务器的 IP 进行 Ping 测试或是进行路由追踪。</p><p>这篇文章我们就分享一些国内外比较好用的服务器和网站在线测速和 Ping 工具，主要是以国内的在线工具为主。国外的有一些在线测速工具提供了国内节点的也汇集在内，主要功能就是电信、联通和移动三网在线 Ping 响应、网页加载速度测试和服务器 IP 路由追踪。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_00-680x366.png-2022-10-31-5EwRzy.webp" alt></p><a id="more"></a><h2><span id="1-chinaz-站长工具">1. Chinaz 站长工具</span></h2><blockquote><p>网址：<a href="https://ping.chinaz.com" target="_blank" rel="noopener">https://ping.chinaz.com</a></p></blockquote><p>Chinaz 站长工具提供了 Ping 检测、国内测速、国际测速、网站速度对比，国内测速有电信、多线、联通、移动等。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_01.png-20221031160918137-2022-10-31-sDdYQe.webp" alt></p><h2><span id="2pingpe"></span></h2><blockquote><p>网址：<a href="https://ping.pe" target="_blank" rel="noopener">https://ping.pe</a></p></blockquote><p><a href="http://Ping.PE" target="_blank" rel="noopener">Ping.PE</a> 是国外一个专注于 Ping 响应监控的在线网页工具，国内与国外的节点都有，但是国内的节点比较少。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_02.png-20221031160810757-2022-10-31-ra5Mm0.webp" alt></p><h2><span id="3-17ce">3. 17CE</span></h2><blockquote><p>网址：<a href="https://www.17ce.com/" target="_blank" rel="noopener">https://www.17ce.com/</a></p></blockquote><p>17CE 是国内一个专业的测速在线工具，有 Get、Ping 和路由追踪测速，测速的结果还是比较靠谱的。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_03.png-20221031160924983-2022-10-31-fgbMp5.webp" alt></p><h2><span id="4-pagespeedinsights">4. PageSpeedInsights</span></h2><blockquote><p>网址：<a href="https://developers.google.com/speed/pagespeed/insights" target="_blank" rel="noopener">https://developers.google.com/speed/pagespeed/insights</a></p></blockquote><p>PageSpeedInsights 是谷歌开发的一个在线分析网页加载速度的工具，优势在于可以帮助你快速找到拖慢网页打开速度的文件，并且提出符合要求的优化建议，缺点就是国内打不开，适合国外的网站使用。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_04.png-20221031160825209-2022-10-31-jVsVdp.webp" alt></p><h2><span id="5-ipipnet">5. </span></h2><blockquote><p>网址：<a href="https://tools.ipip.net/ping.php" target="_blank" rel="noopener">https://tools.ipip.net/ping.php</a></p></blockquote><p>基于 <a href="http://IPIP.net" target="_blank" rel="noopener">IPIP.net</a> 的 IP 库的在线 ping 和路由追踪服务，特点是 IP 比较精准。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_05.png-20221031160829640-2022-10-31-NTCKqu.webp" alt></p><h2><span id="6-阿里云网站运维检测平台">6. 阿里云网站运维检测平台</span></h2><blockquote><p>网址：<a href="https://zijian.aliyun.com/detect/http/" target="_blank" rel="noopener">https://zijian.aliyun.com/detect/http/</a></p></blockquote><p>阿里云网站运维检测平台包括了 HTTP 检测、Ping 检测、DNS 检测、路由追踪检测。可以分地区，例如：东北、华南、华北、华东、华中、西南、西北，运营商分为电信、联通、移动等。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_06.png-20221031160835384-2022-10-31-NvsYvv.webp" alt></p><h2><span id="7-boce">7. BOCE</span></h2><blockquote><p>网址：<a href="https://www.boce.com" target="_blank" rel="noopener">https://www.boce.com</a></p></blockquote><p>BOCE 提供了网站测速、 PING 检测、 DNS 查询、 路由跟踪查询、 IPv6 检测等，可以指定运营商节点：电信 、移动 、联通 、教育网等，提供的节点还是挺多的。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_07.png-20221031160931578-2022-10-31-cyVjgc.webp" alt></p><h2><span id="8-webkaka">8. Webkaka</span></h2><blockquote><p>网址：<a href="http://www.webkaka.com/" target="_blank" rel="noopener">http://www.webkaka.com/</a></p></blockquote><p>Webkaka 是一个老牌的在线网站测试工具了，页面比较难看，而且广告也巨大，优点就是 Webkaka 提供了测速节点比较多，包括了国内网站测速、全球网站测速、本地网站测速、网站速度诊断、网站优化工具、Ping 测试、路由追踪、DNS 查询等等。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_8.png-20221031160848094-2022-10-31-yfyx6C.webp" alt></p><h2><span id="9-爱站网-ping">9. 爱站网 Ping</span></h2><blockquote><p>网址：<a href="https://ping.aizhan.com/" target="_blank" rel="noopener">https://ping.aizhan.com/</a></p></blockquote><p>爱站网提供的一个比较简单的在线 Ping 工具。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_9.png-20221031160858650-2022-10-31-yo1I0T.webp" alt></p><h2><span id="10-dotcom-tools">10. Dotcom-Tools</span></h2><blockquote><p>网址：<a href="https://www.dotcom-tools.com/website-speed-test" target="_blank" rel="noopener">https://www.dotcom-tools.com/website-speed-test</a></p></blockquote><p>Dotcom-Tools Website Speed Test 是一个国外的网站测速和在线 Ping 工具，虽然是一个国外的网站，但是测速的节点有国内的，在全球有三十多个测速节点。</p><p><img src="https://img.hi-linux.com/staticfile/cesu-gongju_10.png-2022-10-31-wZe3OW.webp" alt></p><h2><span id="11-it狗">11. IT狗</span></h2><blockquote><p>网址：<a href="https://www.itdog.cn/" target="_blank" rel="noopener">https://www.itdog.cn/</a></p></blockquote><p>IT 狗为用户提供在线 Ping、在线 tcping、在线路由追踪、域名被墙检测、域名被污染检测等实用工具。IT 狗 Ping 工具可持续的进行一段时间的 Ping 测试，并生成更为直观的网络质量柱状图，让用户更容易掌握服务器在各地区、各线路的网络状态。</p><p>路由追踪工具相比其他同类网站，通过多线程处理方式，可更快速，更准确的获取测试结果（平均 5秒 返回结果），返回的数据中，除了原生的路由记录，还包含节点的 PTR 记录、IP 地理位置、IP 所属 AS 号，IP 所属 AS 信息。</p><p><img src="https://img.hi-linux.com/staticfile/itdog.png-20221031160904827-2022-10-31-B6xeYD.webp" alt></p><h2><span id="12-pingsx">12、</span></h2><blockquote><p>网址：<a href="https://ping.sx/ping" target="_blank" rel="noopener">https://ping.sx/ping</a></p></blockquote><p>这是一家国外的 Ping 检测网站，有国内多个地方的节点，同时包含了大量的国外节点。</p><p><img src="https://img.hi-linux.com/staticfile/pingsx.png-20221031160909980-2022-10-31-vWXdLI.webp" alt></p><blockquote><p>本文转载自：「挖站否」，原文：<a href="https://url.hi-linux.com/LR6dX" target="_blank" rel="noopener">https://url.hi-linux.com/LR6dX</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在日常的建站中，经常要用到对网站加载速度测试服务。如遇到服务器自身的故障或是网络问题，可能还需要要对服务器的 IP 进行 Ping 测试或是进行路由追踪。&lt;/p&gt;
&lt;p&gt;这篇文章我们就分享一些国内外比较好用的服务器和网站在线测速和 Ping 工具，主要是以国内的在线工具为主。国外的有一些在线测速工具提供了国内节点的也汇集在内，主要功能就是电信、联通和移动三网在线 Ping 响应、网页加载速度测试和服务器 IP 路由追踪。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/cesu-gongju_00-680x366.png-2022-10-31-5EwRzy.webp&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="DNS" scheme="https://www.hi-linux.com/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>老板永远是对的？</title>
    <link href="https://www.hi-linux.com/posts/36229.html"/>
    <id>https://www.hi-linux.com/posts/36229.html</id>
    <published>2022-11-03T01:00:00.000Z</published>
    <updated>2022-11-03T02:15:10.715Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>曾经在企业工作的时候，我们经常有一句话：老板是不会有错的。老板是公司创始人，天马行空很多想法，时不时就会搞出一些想法，并且很快就要求下面的员工们执行，雷厉风行。</p><p>但对于一线的员工，经常会觉得这些想法根本就不现实，也就是无法执行，思想上不认可，导致行动上难以配合，甚至消极怠工。聪明的公司总裁在开会时，对员工们说：老板的指示，不理解也要先执行，在执行中理解。他从来都不会说老板的想法有问题。</p><a id="more"></a><p>更为有意思的事情。有一次内部培训上，有员工问高管们：</p><blockquote><p>老板说每个项目要开发一幢楼做大平层户型，但销售数据显示并不好，为什么老板强行这样要求呢？</p></blockquote><p>这位高管也确实了得，他如此回复我们：</p><blockquote><p>老板是说要开发大户型，但老板没有说让你马上配建啊！</p></blockquote><p>久而久之，我们都明白了，老板是不会有错的。公司都是他的，他的失败成本比我们这些流水的打工人大多了。要错的只能是打工人。何况老板站的高度那么高，格局那么宽，掌握的信息那么多，我们这些基层员工简直就是井底之蛙，错的只能是打工人。</p><p>现在回想起来，我倒对这种做法有了新的认识。商业老板们的想法固然会很多，他们不像学校里的教授那么有条有理，老板们更多的可能是一种感觉，就把想法提出来了。他们也不必每个想法都实现成功，只要有那么几个想法成功就会让老板们实现所有，一俊遮百丑。</p><p>因此，当老板们有了新想法后，他们要求员工立马落实，这样做还可以实现以下几个目的：</p><ol><li>狠抓公司高管和员工的执行力，没有执行力，一切等于零，再好的想法也没有用；</li><li>测试公司高管和员工的忠诚度，忠诚不绝对，就是绝对不忠诚，谁执行了老板的指示，就表明了对他的效忠。</li><li>通过高管和员工对指示的执行情况，可以测试出他们到底有多大的忍耐度，也就是对员工们的管理难易程度。</li></ol><p>这也就不奇怪总裁和高管们为老板的指示做出的表态和解释。只是我们这些低情商的员工们，还在苦苦思辨老板的想法是不是合理，从而错失一次又一次机会。</p><p>不过，老板他经常标榜他的开明之处，他说：</p><blockquote><p>只有真理可以在公司横着走。</p></blockquote><p>可能是大家都没有胆量吃螃蟹，所以一直没有见过有人横着走，而我想了很久才明白过来，也许“真理”就是老板，所以他怎么会有错呢？</p><p>对此，你怎么看呢？欢迎大家留言讨论！</p><blockquote><p>本文转载自：「 土木坛子 」，原文：<a href="https://url.hi-linux.com/gV4M5" target="_blank" rel="noopener">https://url.hi-linux.com/gV4M5</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;曾经在企业工作的时候，我们经常有一句话：老板是不会有错的。老板是公司创始人，天马行空很多想法，时不时就会搞出一些想法，并且很快就要求下面的员工们执行，雷厉风行。&lt;/p&gt;
&lt;p&gt;但对于一线的员工，经常会觉得这些想法根本就不现实，也就是无法执行，思想上不认可，导致行动上难以配合，甚至消极怠工。聪明的公司总裁在开会时，对员工们说：老板的指示，不理解也要先执行，在执行中理解。他从来都不会说老板的想法有问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="职场" scheme="https://www.hi-linux.com/tags/%E8%81%8C%E5%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 Headscale ( Tailscale 开源版 ) 快速搭建一个私有专属的 P2P 内网穿透网络</title>
    <link href="https://www.hi-linux.com/posts/33684.html"/>
    <id>https://www.hi-linux.com/posts/33684.html</id>
    <published>2022-10-26T01:00:00.000Z</published>
    <updated>2022-10-26T01:58:08.007Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="一-内网穿透简述">一、内网穿透简述</span></h2><p>由于国内网络环境问题, 普遍家庭用户宽带都没有分配到公网 IP(我有固定公网 IP, 嘿嘿); 这时候一般我们需要从外部访问家庭网络时就需要通过一些魔法手段, 比如 VPN、远程软件(向日葵…)等; 但是这些工具都有一个普遍存在的问题: 慢+卡!</p><h3><span id="11-传统星型拓扑">1.1、传统星型拓扑</span></h3><p>究其根本因素在于, 在传统架构中如果两个位于多层 NAT(简单理解为多个路由器)之后的设备, 只能通过一些中央(VPN/远程软件)中转服务器进行链接, 这时网络连接速度取决于中央服务器带宽和速度; 这种网络架构我这里简称为: 星型拓扑</p><p><img src="https://img.hi-linux.com/staticfile/MKn6bf-20221025104144038-2022-10-25-vuD5sk.png" alt></p><p>从这张图上可以看出, <strong>你的 “工作笔记本” 和 “家庭 NAS” 之间通讯的最大传输速度为 <code>Up/Down: 512K/s</code></strong>; 因为流量经过了中央服务器中转, 由于网络木桶效应存在, 即使你两侧的网络速度再高也没用, 整体的速度取决于这个链路中最低的一个设备网速而不是你两端的设备.</p><p><strong>在这种拓扑下, 想提高速度只有一个办法: 加钱!</strong> 在不使用 “钞能力” 的情况下, 普遍免费的软件提供商不可能给予过多的资源来让用户白嫖, 而自己弄大带宽的中央服务器成本又过高.</p><a id="more"></a><h3><span id="12-nat-穿透与网状拓扑">1.2、NAT 穿透与网状拓扑</span></h3><blockquote><p>本部分只做简述, 具体里面有大量细节和规则可能描述不准确, 细节部分推荐阅读 <a href="https://tailscale.com/blog/how-nat-traversal-works/" target="_blank" rel="noopener">How NAT traversal works</a>.</p></blockquote><p>既然传统的星型拓扑有这么多问题, 那么有没有其他骚操作可以解决呢? 答案是有的, 简单来说就是利用 NAT 穿透原理. NAT 穿透简单理解如下: <strong>在 A 设备主动向 B 设备发送流量后, 整个链路上的防火墙会短时间打开一个映射规则, 该规则允许 B 设备短暂的从这个路径上反向向 A 设备发送流量.</strong> 更通俗的讲大概就是所谓的: <strong>“顺着网线来打你”</strong></p><p><img src="https://img.hi-linux.com/staticfile/by4z9m-2022-10-25-VhDRc6.png" alt></p><p>搞清了这个规则以后, 我们就可以<strong>弄一台 “低配” 的中央服务器</strong>, 让中央服务器来<strong>帮助我们协商</strong>两边的设备谁先访问谁(或者说是访问规则); 两个设备一起无脑访问对方, 然后触发防火墙的 NAT 穿透规则(防火墙打开), 此后两个设备就可以不通过中央服务器源源不断的通讯了. 在这种架构下我们的设备其实就组成了一个非标准的网状拓扑:</p><p><img src="https://img.hi-linux.com/staticfile/MrF6yn-2022-10-25-sXBQjt.png" alt></p><p>在这种拓扑下, 两个设备之间的通讯速度已经不在取决于中央服务器, 而是直接取决于两端设备的带宽, 也就是说达到了设备网络带宽峰值. <strong>当然 NAT 穿透也不是百分百能够成功的, 在复杂网络情况下有些防火墙不会按照预期工作或者说有更严格的限制;</strong> 比如 IP、端口、协议限制等等, 所以为了保证可靠性可以让中央服务器中转做后备方案, 即尽量尝试 NAT 穿透, 如果不行走中央服务器中继.</p><h2><span id="二-tailscale-简介">二、Tailscale 简介</span></h2><blockquote><p>第一部分是为了方便读者理解一些新型内网穿透的大致基本原理, 现在回到本文重点: Tailscale</p></blockquote><p>Tailscale 就是一种利用 NAT 穿透(aka: P2P 穿透)技术的 VPN 工具. Tailscale 客户端等是开源的, 不过遗憾的是中央控制服务器目前并不开源; Tailscale 目前也提供免费的额度给用户使用, 在 NAT 穿透成功的情况下也能保证满速运行.</p><p>不过一旦无法 NAT 穿透需要做中转时, Tailscale 官方的服务器由于众所周知的原因在国内访问速度很拉胯; 不过万幸的是开源社区大佬们搓了一个开源版本的中央控制服务器(Headscale), 也就是说: <strong>我们可以自己搭建中央服务器啦, 完全 “自主可控” 啦.</strong></p><h2><span id="三-搭建-headscale-服务端">三、搭建 Headscale 服务端</span></h2><blockquote><p>以下命令假设安装系统为 Ubuntu 22.04, 其他系统请自行调整.</p></blockquote><h3><span id="31-宿主机安装">3.1、宿主机安装</span></h3><p>Headscale 是采用 Go 语言编写的, 所以只有一个二进制文件, 在 <a href="https://github.com/juanfont/headscale/releases" target="_blank" rel="noopener">Github Releases</a> 页面下载最新版本即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;juanfont&#x2F;headscale&#x2F;releases&#x2F;download&#x2F;v0.16.4&#x2F;headscale_0.16.4_linux_amd64 -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;headscale</span><br><span class="line"></span><br><span class="line"># 增加可执行权限</span><br><span class="line">chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;headscale</span><br></pre></td></tr></table></figure><p>下载完成后为了安全性我们需要创建单独的用户和目录用于 Headscale 运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 配置目录</span><br><span class="line">mkdir -p &#x2F;etc&#x2F;headscale</span><br><span class="line"></span><br><span class="line"># 创建用户</span><br><span class="line">useradd \</span><br><span class="line">--create-home \</span><br><span class="line">--home-dir &#x2F;var&#x2F;lib&#x2F;headscale&#x2F; \</span><br><span class="line">--system \</span><br><span class="line">--user-group \</span><br><span class="line">--shell &#x2F;usr&#x2F;sbin&#x2F;nologin \</span><br><span class="line">headscale</span><br></pre></td></tr></table></figure><p>为了保证 Headscale 能持久运行, 我们需要创建 SystemD 配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;headscale.service</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;headscale controller</span><br><span class="line">After&#x3D;syslog.target</span><br><span class="line">After&#x3D;network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;simple</span><br><span class="line">User&#x3D;headscale</span><br><span class="line">Group&#x3D;headscale</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;headscale serve</span><br><span class="line">Restart&#x3D;always</span><br><span class="line">RestartSec&#x3D;5</span><br><span class="line"></span><br><span class="line"># Optional security enhancements</span><br><span class="line">NoNewPrivileges&#x3D;yes</span><br><span class="line">PrivateTmp&#x3D;yes</span><br><span class="line">ProtectSystem&#x3D;strict</span><br><span class="line">ProtectHome&#x3D;yes</span><br><span class="line">ReadWritePaths&#x3D;&#x2F;var&#x2F;lib&#x2F;headscale &#x2F;var&#x2F;run&#x2F;headscale</span><br><span class="line">AmbientCapabilities&#x3D;CAP_NET_BIND_SERVICE</span><br><span class="line">RuntimeDirectory&#x3D;headscale</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><h3><span id="32-配置-headscale">3.2、配置 Headscale</span></h3><p>安装完成以后我们需要在 <code>/etc/headscale/config.yaml</code> 中配置 Headscale 的启动配置, 以下为配置样例以及解释(仅列出重要配置):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line"># Headscale 服务器的访问地址</span><br><span class="line"># </span><br><span class="line"># 这个地址是告诉客户端需要访问的地址, 即使你需要在跑在</span><br><span class="line"># 负载均衡器之后这个地址也必须写成负载均衡器的访问地址</span><br><span class="line">server_url: https:&#x2F;&#x2F;your.domain.com</span><br><span class="line"></span><br><span class="line"># Headscale 实际监听的地址</span><br><span class="line">listen_addr: 0.0.0.0:8080</span><br><span class="line"></span><br><span class="line"># 监控地址</span><br><span class="line">metrics_listen_addr: 127.0.0.1:9090</span><br><span class="line"></span><br><span class="line"># grpc 监听地址</span><br><span class="line">grpc_listen_addr: 0.0.0.0:50443</span><br><span class="line"></span><br><span class="line"># 是否允许不安全的 grpc 连接(非 TLS)</span><br><span class="line">grpc_allow_insecure: false</span><br><span class="line"></span><br><span class="line"># 客户端分配的内网网段</span><br><span class="line">ip_prefixes:</span><br><span class="line">  - fd7a:115c:a1e0::&#x2F;48</span><br><span class="line">  - 100.64.0.0&#x2F;10</span><br><span class="line"></span><br><span class="line"># 中继服务器相关配置</span><br><span class="line">derp:</span><br><span class="line">  server:</span><br><span class="line">    # 关闭内嵌的 derper 中继服务(可能不安全, 还没去看代码)</span><br><span class="line">    enabled: false</span><br><span class="line"></span><br><span class="line">  # 下发给客户端的中继服务器列表(默认走官方的中继节点)</span><br><span class="line">  urls:</span><br><span class="line">    - https:&#x2F;&#x2F;controlplane.tailscale.com&#x2F;derpmap&#x2F;default</span><br><span class="line"></span><br><span class="line">  # 可以在本地通过 yaml 配置定义自己的中继接待你</span><br><span class="line">  paths: []</span><br><span class="line"></span><br><span class="line"># SQLite config</span><br><span class="line">db_type: sqlite3</span><br><span class="line">db_path: &#x2F;var&#x2F;lib&#x2F;headscale&#x2F;db.sqlite</span><br><span class="line"></span><br><span class="line"># 使用自动签发证书是的域名</span><br><span class="line">tls_letsencrypt_hostname: &quot;&quot;</span><br><span class="line"></span><br><span class="line"># 使用自定义证书时的证书路径</span><br><span class="line">tls_cert_path: &quot;&quot;</span><br><span class="line">tls_key_path: &quot;&quot;</span><br><span class="line"></span><br><span class="line"># 是否让客户端使用随机端口, 默认使用 41641&#x2F;UDP</span><br><span class="line">randomize_client_port: false</span><br></pre></td></tr></table></figure><h3><span id="33-证书及反向代理">3.3、证书及反向代理</span></h3><p>可能很多人和我一样, 希望使用 ACME 自动证书, 又不想占用 80/443 端口, 又想通过负载均衡器负载, 配置又看的一头雾水; 所以这里详细说明一下 Headscale 证书相关配置和工作逻辑:</p><ul><li>1、Headscale 的 ACME 只支持 HTTP/TLS 挑战, 所以使用后必定占用 80/443</li><li>2、当配置了 <code>tls_letsencrypt_hostname</code> 时一定会进行 ACME 申请</li><li>3、在不配置 <code>tls_letsencrypt_hostname</code> 时如果配置了 <code>tls_cert_path</code> 则使用自定义证书</li><li>4、两者都不配置则不使用任何证书, 服务端监听 HTTP 请求</li><li>5、三种情况下(ACME 证书、自定义证书、无证书)主服务都只监听 <code>listen_addr</code> 地址, 与 <code>server_url</code> 没半毛钱关系</li><li>6、只有在有证书(ACME 证书或自定义证书)的情况下或者手动开启了 <code>grpc_allow_insecure</code> 才会监听 grpc 远程调用服务</li></ul><p>综上所述, 如果你想通过 Nginx、Caddy 反向代理 Headscale, 则你需要满足以下配置:</p><ul><li>1、删除掉 <code>tls_letsencrypt_hostname</code> 或留空, 防止 ACME 启动</li><li>2、删除掉 <code>tls_cert_path</code> 或留空, 防止加载自定义证书</li><li>3、<code>server_url</code> 填写 Nginx 或 Caddy 被访问的 HTTPS 地址</li><li>4、在你的 Nginx 或 Caddy 中反向代理填写 <code>listen_addr</code> 的 HTTP 地址</li></ul><p>Nginx 配置参考 <a href="https://github.com/juanfont/headscale/wiki/nginx-configuration" target="_blank" rel="noopener">官方 Wiki</a>, Caddy 只需要一行 <code>reverse_proxy headscale:8080</code> 即可(地址自行替换).</p><p>至于 ACME 证书你可以通过使用 <code>acme.sh</code> 自动配置 Nginx 或者使用 Caddy 自动申请等方式, 这些已经与 Headscale 无关了, 不在本文探讨范围内.</p><h3><span id="34-内网地址分配">3.4、内网地址分配</span></h3><p>请尽量不要将 <code>ip_prefixes</code> 配置为默认的 <code>100.64.0.0/10</code> 网段, 如果你有兴趣查询了该地址段, 那么你应该明白它叫 CGNAT; 很不幸的是例如 Aliyun 底层的 apt 源等都在这个范围内, 可能会有一些奇怪问题.</p><h3><span id="35-启动-headscale">3.5、启动 Headscale</span></h3><p>在处理完证书等配置后, 只需要愉快的启动一下即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 开机自启动 并 立即启动</span><br><span class="line">systemctl enable headscale --now</span><br></pre></td></tr></table></figure><p>再啰嗦一嘴, 如果你期望使用 Headscale ACME 自动申请证书, 你的关键配置应该像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server_url: https:&#x2F;&#x2F;your.domain.com</span><br><span class="line">listen_addr: 0.0.0.0:443</span><br><span class="line">tls_letsencrypt_hostname: &quot;your.domain.com&quot;</span><br><span class="line">tls_cert_path: &quot;&quot;</span><br><span class="line">tls_key_path: &quot;&quot;</span><br></pre></td></tr></table></figure><p>如果你期望使用自定义证书, 则你的关键配置应该像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server_url: https:&#x2F;&#x2F;your.domain.com</span><br><span class="line">listen_addr: 0.0.0.0:443</span><br><span class="line">tls_letsencrypt_hostname: &quot;&quot;</span><br><span class="line">tls_cert_path: &quot;&#x2F;path&#x2F;to&#x2F;cert&quot;</span><br><span class="line">tls_key_path: &quot;&#x2F;path&#x2F;to&#x2F;key&quot;</span><br></pre></td></tr></table></figure><p>如果你期望使用负载均衡器, 那么你的关键配置应该像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server_url: https:&#x2F;&#x2F;your.domain.com</span><br><span class="line">listen_addr: 0.0.0.0:8080</span><br><span class="line">tls_letsencrypt_hostname: &quot;&quot;</span><br><span class="line">tls_cert_path: &quot;&quot;</span><br><span class="line">tls_key_path: &quot;&quot;</span><br></pre></td></tr></table></figure><p>在使用负载均衡器配置时, 启动后会有一行警告日志, 忽略即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2022-09-18T07:57:36Z WRN Listening without TLS but ServerURL does not start with http:&#x2F;&#x2F;</span><br></pre></td></tr></table></figure><h3><span id="36-docker-compose-安装">3.6、Docker Compose 安装</span></h3><p>Compose 配置样例文件如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># docker-compose.yaml</span><br><span class="line">version: &quot;3.9&quot;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  headscale:</span><br><span class="line">    container_name: headscale</span><br><span class="line">    image: headscale&#x2F;headscale:0.16.4</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;8080:8080&quot;</span><br><span class="line">    cap_add:</span><br><span class="line">      - NET_ADMIN</span><br><span class="line">      - NET_RAW</span><br><span class="line">      - SYS_MODULE</span><br><span class="line">    sysctls:</span><br><span class="line">      - net.ipv4.ip_forward&#x3D;1</span><br><span class="line">      - net.ipv6.conf.all.forwarding&#x3D;1</span><br><span class="line">    restart: always</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;conf:&#x2F;etc&#x2F;headscale</span><br><span class="line">      - data:&#x2F;var&#x2F;lib&#x2F;headscale</span><br><span class="line">    command: [&quot;headscale&quot;, &quot;serve&quot;]</span><br><span class="line">volumes:</span><br><span class="line">  config:</span><br><span class="line">  data:</span><br></pre></td></tr></table></figure><p>你需要在与 <code>docker-compose.yaml</code> 同级目录下创建 <code>conf</code> 目录用于存储配置文件; 具体配置请参考上面的配置详解等部分, 最后不要忘记你的 Compose 文件端口映射需要和配置文件保持一致.</p><h2><span id="四-客户端安装">四、客户端安装</span></h2><p>对于客户端来说, Tailscale 提供了多个平台和发行版的预编译安装包, 并且部分客户端直接支持设置自定义的中央控制服务器.</p><h3><span id="41-linux-客户端">4.1、Linux 客户端</span></h3><p>Linux 用户目前只需要使用以下命令安装即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https:&#x2F;&#x2F;tailscale.com&#x2F;install.sh | sh</span><br></pre></td></tr></table></figure><p>默认该脚本会检测相关的 Linux 系统发行版并使用对应的包管理器安装 Tailscale, 安装完成后使用以下命令启动:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tailscale up --login-server https:&#x2F;&#x2F;your.domain.com --advertise-routes&#x3D;192.168.11.0&#x2F;24 --accept-routes&#x3D;true --accept-dns&#x3D;false</span><br></pre></td></tr></table></figure><p>关于选项设置:</p><ul><li><code>--login-server</code>: 指定使用的中央服务器地址(必填)</li><li><code>--advertise-routes</code>: 向中央服务器报告当前客户端处于哪个内网网段下, 便于中央服务器让同内网设备直接内网直连(可选的)或者将其他设备指定流量路由到当前内网(可选)</li><li><code>--accept-routes</code>: 是否接受中央服务器下发的用于路由到其他客户端内网的路由规则(可选)</li><li><code>--accept-dns</code>: 是否使用中央服务器下发的 DNS 相关配置(可选, 推荐关闭)</li></ul><p>启动完成后, <strong><code>tailscale</code> 将会卡住, 并打印一个你的服务器访问地址; 浏览器访问该地址后将会得到一条命令:</strong></p><p><img src="https://img.hi-linux.com/staticfile/l2zjmV-2022-10-25-U5QXXT.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/JU8BVZ-20221025104046371-2022-10-25-MKL0fj.png" alt></p><p><strong>注意: 浏览器上显示的命令需要在中央控制服务器执行(Headscale), <code>NAMESAPCE</code> 位置应该替换为一个具体的 Namespace, 可以使用以下命令创建 Namespace (名字随意)并让设备加入:</strong></p><p><img src="https://img.hi-linux.com/staticfile/x9tA4A-2022-10-25-QqSXMn.png" alt></p><p>在 Headscale 服务器上执行命令成功后客户端命令行在稍等片刻便会执行完成, 此时该客户端已经被加入 Headscale 网络并分配了特定的内网 IP; 多个客户端加入后在 NAT 穿透成功时就可以互相 ping 通, 如果出现问题请阅读后面的调试细节, 只要能注册成功就算是成功了一半, 暂时不要慌.</p><h3><span id="42-macos-客户端">4.2、MacOS 客户端</span></h3><p>MacOS 客户端安装目前有两种方式, 一种是使用标准的 AppStore 版本(好像还有一个可以直接下载的), 需要先设置服务器地址然后再启动 App:</p><p>首先访问你的 Headscale 地址 <code>https://your.domain.com/apple</code>:</p><p><img src="https://img.hi-linux.com/staticfile/Y1cXjS-20221025104153717-2022-10-25-krooqA.png" alt></p><p>复制倒数第二行命令到命令行执行(可能需要 sudo 执行), 然后去 AppStore 搜索 Hailscale 安装并启动; 启动后会自动打开浏览器页面, 与 Linux 安装类似, 复制命令到 Headscale 服务器执行即可(Namespace 创建一次就行).</p><p><strong>第二种方式也是比较推荐的方式, 直接编译客户端源码安装, 体验与 Linux 版本一致:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 安装 go</span><br><span class="line">brew install go</span><br><span class="line"></span><br><span class="line"># 编译命令行客户端</span><br><span class="line">go install tailscale.com&#x2F;cmd&#x2F;tailscale&#123;,d&#125;@main</span><br><span class="line"></span><br><span class="line"># 安装为系统服务</span><br><span class="line">sudo tailscaled install-system-daemon</span><br></pre></td></tr></table></figure><p>安装完成后同样通过 <code>tailscale up</code> 命令启动并注册即可, 具体请参考 Linux 客户端安装部分.</p><h3><span id="43-其他客户端">4.3、其他客户端</span></h3><p>关于 Windows 客户端大致流程就是创建一个注册表, 然后同样安装官方 App 启动, 接着浏览器复制命令注册即可. 至于移动端本人没有需求, 所以暂未研究. <strong>Windows 具体的安装流程请访问 <code>https://your.domain.com/windows</code> 地址查看(基本与 MacOS AppStore 版本安装类似).</strong></p><h2><span id="五-中继服务器搭建">五、中继服务器搭建</span></h2><p>在上面的 Headscale 搭建完成并添加客户端后, 某些客户端可能无法联通; 这是由于网络复杂情况下导致了 NAT 穿透失败; 为此我们可以搭建一个中继服务器来进行传统的星型拓扑通信.</p><h3><span id="51-搭建-derp-server">5.1、搭建 DERP Server</span></h3><p>首先需要注意的是, 在需要搭建 DERP Server 的服务器上, 请先安装一个 Tailscale 客户端并注册到 Headscale; <strong>这样做的目的是让搭建的 DERP Server 开启客户端认证, 否则你的 DERP Server 可以被任何人白嫖.</strong></p><p>目前 Tailscale 官方并未提供 DERP Server 的安装包, 所以需要我们自行编译安装; 在编译之前请确保安装了最新版本的 Go 语言及其编译环境.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 编译 DERP Server</span><br><span class="line">go install tailscale.com&#x2F;cmd&#x2F;derper@main</span><br><span class="line"></span><br><span class="line"># 复制到系统可执行目录</span><br><span class="line">mv $&#123;GOPATH&#125;&#x2F;bin&#x2F;derper &#x2F;usr&#x2F;local&#x2F;bin</span><br><span class="line"></span><br><span class="line"># 创建用户和运行目录</span><br><span class="line">useradd \</span><br><span class="line">        --create-home \</span><br><span class="line">        --home-dir &#x2F;var&#x2F;lib&#x2F;derper&#x2F; \</span><br><span class="line">        --system \</span><br><span class="line">        --user-group \</span><br><span class="line">        --shell &#x2F;usr&#x2F;sbin&#x2F;nologin \</span><br><span class="line">        derper</span><br></pre></td></tr></table></figure><p>接下来创建一个 SystemD 配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;derper.service</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;tailscale derper server</span><br><span class="line">After&#x3D;syslog.target</span><br><span class="line">After&#x3D;network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;simple</span><br><span class="line">User&#x3D;derper</span><br><span class="line">Group&#x3D;derper</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;derper -c&#x3D;&#x2F;var&#x2F;lib&#x2F;derper&#x2F;private.key -a&#x3D;:8989 -stun-port&#x3D;3456 -verify-clients</span><br><span class="line">Restart&#x3D;always</span><br><span class="line">RestartSec&#x3D;5</span><br><span class="line"></span><br><span class="line"># Optional security enhancements</span><br><span class="line">NoNewPrivileges&#x3D;yes</span><br><span class="line">PrivateTmp&#x3D;yes</span><br><span class="line">ProtectSystem&#x3D;strict</span><br><span class="line">ProtectHome&#x3D;yes</span><br><span class="line">ReadWritePaths&#x3D;&#x2F;var&#x2F;lib&#x2F;derper &#x2F;var&#x2F;run&#x2F;derper</span><br><span class="line">AmbientCapabilities&#x3D;CAP_NET_BIND_SERVICE</span><br><span class="line">RuntimeDirectory&#x3D;derper</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>最后使用以下命令启动 Derper Server 即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable derper --now</span><br></pre></td></tr></table></figure><p><strong>注意: 默认情况下 Derper Server 会监听在 <code>:443</code> 上, 同时会触发自动 ACME 申请证书. 关于证书逻辑如下:</strong></p><ul><li>1、如果不指定 <code>-a</code> 参数, 则默认监听 <code>:443</code></li><li>2、如果监听 <code>:443</code> 并且未指定 <code>--certmode=manual</code> 则会强制使用 <code>--hostname</code> 指定的域名进行 ACME 申请证书</li><li>3、如果指定了 <code>--certmode=manual</code> 则会使用 <code>--certmode</code> 指定目录下的证书开启 HTTPS</li><li>4、如果指定了 <code>-a</code> 为非 <code>:443</code> 端口, 且没有指定 <code>--certmode=manual</code> 则只监听 HTTP</li></ul><p><strong>如果期望使用 ACME 自动申请只需要不增加 <code>-a</code> 选项即可(占用 443 端口), 如果期望通过负载均衡器负载, 则需要将 <code>-a</code> 选项指定到非 443 端口, 然后配置 Nginx、Caddy 等 LB 软件即可. 最后一点 <code>stun</code> 监听的是 UDP 端口, 请确保防火墙打开此端口.</strong></p><h3><span id="52-配置-headscale">5.2、配置 Headscale</span></h3><p>在创建完 Derper 中继服务器后, 我们还需要配置 Headscale 来告诉所有客户端在必要时可以使用此中继节点进行通信; 为了达到这个目的, 我们需要在 Headscale 服务器上创建以下配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;etc&#x2F;headscale&#x2F;derper.yaml</span><br><span class="line"></span><br><span class="line">regions:</span><br><span class="line">  901:</span><br><span class="line">    regionid: 901</span><br><span class="line">    regioncode: private-derper</span><br><span class="line">    regionname: &quot;My Private Derper Server&quot;</span><br><span class="line">    nodes:</span><br><span class="line">      - name: private-derper</span><br><span class="line">        regionid: 901</span><br><span class="line">        # 自行更改为自己的域名</span><br><span class="line">        hostname: derper.xxxxx.com</span><br><span class="line">        # Derper 节点的 IP</span><br><span class="line">        ipv4: 123.123.123.123</span><br><span class="line">        # Derper 设置的 STUN 端口</span><br><span class="line">        stunport: 3456</span><br></pre></td></tr></table></figure><p>在创建好基本的 Derper Server 节点信息配置后, 我们需要调整主配置来让 Headscale 加载:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">derp:</span><br><span class="line">  server:</span><br><span class="line">    # 这里关闭 Headscale 默认的 Derper Server</span><br><span class="line">    enabled: false</span><br><span class="line">  # urls 留空, 保证不加载官方的默认 Derper</span><br><span class="line">  urls: []</span><br><span class="line">  # 这里填写 Derper 节点信息配置的绝对路径</span><br><span class="line">  paths:</span><br><span class="line">  - &#x2F;etc&#x2F;headscale&#x2F;derper.yaml</span><br><span class="line"></span><br><span class="line">  # If enabled, a worker will be set up to periodically</span><br><span class="line">  # refresh the given sources and update the derpmap</span><br><span class="line">  # will be set up.</span><br><span class="line">  auto_update_enabled: true</span><br><span class="line"></span><br><span class="line">  # How often should we check for DERP updates?</span><br><span class="line">  update_frequency: 24h</span><br></pre></td></tr></table></figure><p>接下来重启 Headscale 并重启 client 上的 tailscale 即可看到中继节点:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">~ ❯❯❯ tailscale netcheck</span><br><span class="line"></span><br><span class="line">Report:</span><br><span class="line">        * UDP: true</span><br><span class="line">        * IPv4: yes, 124.111.111.111:58630</span><br><span class="line">        * IPv6: no, but OS has support</span><br><span class="line">        * MappingVariesByDestIP: false</span><br><span class="line">        * HairPinning: false</span><br><span class="line">        * PortMapping: UPnP, NAT-PMP, PCP</span><br><span class="line">        * CaptivePortal: true</span><br><span class="line">        * Nearest DERP: XXXX Derper Server</span><br><span class="line">        * DERP latency:</span><br><span class="line">                - XXXX: 10.1ms  (XXXX Derper Server)</span><br></pre></td></tr></table></figure><p>到此中继节点搭建完成.</p><h3><span id="53-docker-compose-安装">5.3、Docker Compose 安装</span></h3><p>目前官方似乎也没有提供 Docker 镜像, 我自己通过 GitHub Action 编译了一个 Docker 镜像, 以下是使用此镜像的 Compose 文件样例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.9&#39;</span><br><span class="line">services:</span><br><span class="line">  derper:</span><br><span class="line">    image: mritd&#x2F;derper</span><br><span class="line">    container_name: derper</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;8080:8080&#x2F;tcp&quot;</span><br><span class="line">      - &quot;3456:3456&#x2F;udp&quot;</span><br><span class="line">    environment:</span><br><span class="line">      TZ: Asia&#x2F;Shanghai</span><br><span class="line">    volumes:</span><br><span class="line">      - &#x2F;etc&#x2F;timezone:&#x2F;etc&#x2F;timezone</span><br><span class="line">      - &#x2F;var&#x2F;run&#x2F;tailscale:&#x2F;var&#x2F;run&#x2F;tailscale</span><br><span class="line">      - data:&#x2F;var&#x2F;lib&#x2F;derper</span><br><span class="line">volumes:</span><br><span class="line">  data:</span><br></pre></td></tr></table></figure><p><strong>该镜像默认开启了客户端验证, 所以请确保 <code>/var/run/tailscale</code> 内存在已加入 Headscale 成功的 tailscaled 实例的 sock 文件. 其他具体环境变量等参数配置请参考 <a href="https://github.com/mritd/autobuild/blob/main/derper/Earthfile" target="_blank" rel="noopener">Earthfile</a>.</strong></p><h2><span id="六-客户端网络调试">六、客户端网络调试</span></h2><blockquote><p>在调试中继节点或者不确定网络情况时, 可以使用一些 Tailscale 内置的命令来调试网络.</p></blockquote><h3><span id="61-ping-命令">6.1、Ping 命令</span></h3><p><code>tailscale ping</code> 命令可以用于测试 IP 连通性, 同时可以看到时如何连接目标节点的. <strong>默认情况下 Ping 命令首先会使用 Derper 中继节点通信, 然后尝试 P2P 连接; 一旦 P2P 连接成功则自动停止 Ping:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">~ ❯❯❯ tailscale ping 10.24.0.5</span><br><span class="line">pong from k8s13 (10.24.0.5) via DERP(XXXXX) in 14ms</span><br><span class="line">pong from k8s13 (10.24.0.5) via DERP(XXXXX) in 13ms</span><br><span class="line">pong from k8s13 (10.24.0.5) via DERP(XXXXX) in 14ms</span><br><span class="line">pong from k8s13 (10.24.0.5) via DERP(XXXXX) in 12ms</span><br><span class="line">pong from k8s13 (10.24.0.5) via DERP(XXXXX) in 12ms</span><br><span class="line">pong from k8s13 (10.24.0.5) via 3.4.170.23:2495 in 9ms</span><br></pre></td></tr></table></figure><p>由于其先走 Derper 的特性也可以用来测试 Derper 连通性.</p><h3><span id="62-status-命令">6.2、Status 命令</span></h3><p>通过 <code>tailscale status</code> 命令可以查看当前节点与其他对等节点的连接方式, 通过此命令可以查看到当前节点可连接的节点以及是否走了 Derper 中继:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">~ ❯❯❯ tailscale status</span><br><span class="line">10.24.0.8       xmac                 kovacs       macOS   -</span><br><span class="line">                alivpn               kovacs       linux   active; direct 4.3.4.5:41644, tx 1264 rx 944</span><br><span class="line">                aliyun               kovacs       linux   -</span><br><span class="line">                bob                  kovacs       macOS   offline</span><br><span class="line">                bob-imac             kovacs       macOS   offline</span><br><span class="line">                company              kovacs       linux   active; direct 114.114.114.114:41642, tx 1296 rx 880</span><br></pre></td></tr></table></figure><h3><span id="63-netcheck-命令">6.3、NetCheck 命令</span></h3><p>有些情况下我们可以确认是当前主机的网络问题导致没法走 P2P 连接, 但是我们又想了解一下当前的网络环境; 此时可以使用 <code>tailscale netcheck</code> 命令来检测当前的网络环境, 此命令将会打印出详细的网络环境报告:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">~ ❯❯❯ tailscale netcheck</span><br><span class="line">2022&#x2F;10&#x2F;19 21:15:27 portmap: [v1] Got PMP response; IP: 123.123.123.123, epoch: 297671</span><br><span class="line">2022&#x2F;10&#x2F;19 21:15:27 portmap: [v1] Got PCP response: epoch: 297671</span><br><span class="line">2022&#x2F;10&#x2F;19 21:15:27 portmap: [v1] UPnP reply &#123;Location:http:&#x2F;&#x2F;192.168.11.1:39735&#x2F;rootDesc.xml Server:AsusWRT&#x2F;386 UPnP&#x2F;1.1 MiniUPnPd&#x2F;2.2.0 USN:uuid:23345-2380-45f5-34534-04421abwb7cf0::urn:schemas-upnp-org:device:InternetGatewayDevice:1&#125;, &quot;HTTP&#x2F;1.1 200 OK\r\nCACHE-CONTROL: max-age&#x3D;120\r\nST: urn:schemas-upnp-org:device:InternetGatewayDevice:1\r\nUSN: uuid:34564645-2380-45f5-b069-sdfdght3245.....&quot;</span><br><span class="line">2022&#x2F;10&#x2F;19 21:15:27 portmap: UPnP meta changed: &#123;Location:http:&#x2F;&#x2F;192.168.11.1:39735&#x2F;rootDesc.xml Server:AsusWRT&#x2F;386 UPnP&#x2F;1.1 MiniUPnPd&#x2F;2.2.0 USN:uuid:23345-2380-45f5-b069-04421abwb7cf0::urn:schemas-upnp-org:device:InternetGatewayDevice:1&#125;</span><br><span class="line"></span><br><span class="line">Report:</span><br><span class="line">        * UDP: true</span><br><span class="line">        * IPv4: yes, 123.123.123.123:5935</span><br><span class="line">        * IPv6: no, but OS has support</span><br><span class="line">        * MappingVariesByDestIP: false</span><br><span class="line">        * HairPinning: true</span><br><span class="line">        * PortMapping: UPnP, NAT-PMP, PCP</span><br><span class="line">        * CaptivePortal: true</span><br><span class="line">        * Nearest DERP: XXXXX Aliyun</span><br><span class="line">        * DERP latency:</span><br><span class="line">                - XXXXX: 9.5ms   (XXXXX Aliyun)</span><br><span class="line">                - XXXXX: 53.1ms  (XXXXX BandwagonHost)</span><br></pre></td></tr></table></figure><h2><span id="七-其他补充">七、其他补充</span></h2><h3><span id="71-某些代理工具兼容性">7.1、某些代理工具兼容性</span></h3><p>MacOS 下使用一些增强代理工具时, 如果安装 App Store 的官方图形化客户端, 则可能与这些软件冲突, 推荐使用纯命令行版本<strong>并添加进程规则匹配 <code>tailscale</code> 和 <code>tailscaled</code> 两个进程, 让它们始终走 <code>DIRECT</code> 规则即可.</strong></p><h3><span id="72-macos-下-cpu-占用突然起飞">7.2、MacOS 下 CPU 占用突然起飞</span></h3><p>在使用一些网络代理工具时, 网络工具会设置默认路由; 这可能导致 <code>tailscaled</code> 无法获取到默认路由接口, 然后进入死循环并把 CPU 吃满, 同时会与 Derper 服务器产生大量上传流量. <strong>截止本文发布此问题已修复, 请使用 <code>mian</code> 分支编译安装, 具体见 <a href="https://github.com/tailscale/tailscale/issues/5879" target="_blank" rel="noopener">ISSUE/5879</a>.</strong></p><h3><span id="73-阿里云安装客户端后无法更新软件">7.3、阿里云安装客户端后无法更新软件</span></h3><p>Tailscale 默认使用 CGNAT(<code>100.64.0.0/10</code>) 网段作为内部地址分配网段, <strong>目前 Tailscale 仅允许自己的接口使用此网段, 不巧的是阿里云的 DNS、Apt 源等也采用此网段.</strong> 这会导致阿里云服务器安装客户端后 DNS、Apt 等不可用, 解决方案目前只能修改源码删除掉这两个 DROP 规则并重新编译.</p><p><img src="https://img.hi-linux.com/staticfile/Nnv35j-20221025104030679-2022-10-25-rWqjrm.png" alt></p><h3><span id="74-开启路由转发">7.4、开启路由转发</span></h3><p>大多数时候我们可能并不会在每个服务器上都安装 Tailscale 客户端, 通常只安装 2、3 台, 然后想通过这两三台转发该内网的所有流量. <strong>此时你需要</strong></p><ul><li>启动 tailscale 时设置正确的路由提示 <code>--advertise-routes=192.168.1.0/24</code> 来告诉 Headscale 服务器 “我这个节点可以转发这些地址的路由”</li><li>其他节点启动时需要增加 <code>--accept-routes=true</code> 选项来声明 “我接受外部其他节点发布的路由”</li></ul><p><strong>以上两个选项配置后, 只需要 Headscale 服务器上使用 <code>headscale node route enable -a -i XX(ID)</code> 开启即可. 开启后目标节点(ID)的路由就会发布到接受外部路由的所有节点, 想要关闭的话去掉 <code>-a</code> 即可.</strong></p><h3><span id="75-其他问题">7.5、其他问题</span></h3><p>以上也只是我个人遇到的一些问题, 如果有其他问题推荐先搜索然后查看 ISSUE, 最后不行可以看看源码. 目前来说 Tailscale 很多选项很模糊, 可能需要阅读源码以后才能知道到底应该怎么做.</p><blockquote><p>本文转载自：「 bleem 」，原文：<a href="https://url.hi-linux.com/M3tzx" target="_blank" rel="noopener">https://url.hi-linux.com/M3tzx</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、内网穿透简述&quot;&gt;一、内网穿透简述&lt;/h2&gt;
&lt;p&gt;由于国内网络环境问题, 普遍家庭用户宽带都没有分配到公网 IP(我有固定公网 IP, 嘿嘿); 这时候一般我们需要从外部访问家庭网络时就需要通过一些魔法手段, 比如 VPN、远程软件(向日葵…)等; 但是这些工具都有一个普遍存在的问题: 慢+卡!&lt;/p&gt;
&lt;h3 id=&quot;1-1、传统星型拓扑&quot;&gt;1.1、传统星型拓扑&lt;/h3&gt;
&lt;p&gt;究其根本因素在于, 在传统架构中如果两个位于多层 NAT(简单理解为多个路由器)之后的设备, 只能通过一些中央(VPN/远程软件)中转服务器进行链接, 这时网络连接速度取决于中央服务器带宽和速度; 这种网络架构我这里简称为: 星型拓扑&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/MKn6bf-20221025104144038-2022-10-25-vuD5sk.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;从这张图上可以看出, &lt;strong&gt;你的 “工作笔记本” 和 “家庭 NAS” 之间通讯的最大传输速度为 &lt;code&gt;Up/Down: 512K/s&lt;/code&gt;&lt;/strong&gt;; 因为流量经过了中央服务器中转, 由于网络木桶效应存在, 即使你两侧的网络速度再高也没用, 整体的速度取决于这个链路中最低的一个设备网速而不是你两端的设备.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在这种拓扑下, 想提高速度只有一个办法: 加钱!&lt;/strong&gt; 在不使用 “钞能力” 的情况下, 普遍免费的软件提供商不可能给予过多的资源来让用户白嫖, 而自己弄大带宽的中央服务器成本又过高.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Tailscale" scheme="https://www.hi-linux.com/tags/Tailscale/"/>
    
      <category term="Headscale" scheme="https://www.hi-linux.com/tags/Headscale/"/>
    
      <category term="VPN" scheme="https://www.hi-linux.com/tags/VPN/"/>
    
  </entry>
  
  <entry>
    <title>保姆级零信任容器应用平台 Kasm 使用指南（全网最详细中文教程）</title>
    <link href="https://www.hi-linux.com/posts/19718.html"/>
    <id>https://www.hi-linux.com/posts/19718.html</id>
    <published>2022-10-14T01:00:00.000Z</published>
    <updated>2022-10-14T01:48:45.274Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="kasm-介绍">Kasm 介绍</span></h2><p><code>Kasm</code> 是一款基于 <code>Docker</code> 的容器应用平台，它提供企业级编排、数据丢失防护和 <code>Web</code> 流技术，以支持将容器化工作负载交付到你的浏览器。</p><p><code>Kasm</code> 可以在浏览器內运行各种应用，比如：<code>Linux</code> 桌面、浏览器、聊天工具、办公软件、多媒体工具等。</p><p><code>Kasm</code> 将这些应用隔离在独立的 <code>Docker</code> 容器内，在里面做的任何行为不会影响真实的主机，并且具备一次性特点、用完即删，保证了数据的安全性。</p><p><code>Kasm</code> 是个开源项目，你可以在个人及非营利条件下免费使用。</p><ul><li><code>Kasm</code> 官方网站: <a href="https://www.kasmweb.com/" target="_blank" rel="noopener">https://www.kasmweb.com/</a></li><li><code>Kasm Github</code>: <a href="https://github.com/kasmtech" target="_blank" rel="noopener">https://github.com/kasmtech</a></li></ul><p>简单来说 <code>Kasm</code> 可以让用户在浏览器（即开即用）使用各种（容器化）的软件和操作系统。</p><a id="more"></a><p><img src="https://img.hi-linux.com/staticfile/mobile01-d19f67c7496a3cb9062a1e9e43c0cdb3-2022-10-12-uKWaTN.gif" alt="在浏览器内运行 Chrome、Edge"></p><p><code>Kasm</code> 支持常用的主流浏览器：<code>Chrome</code>、<code>Edge</code>、<code>FireFox</code>、<code>Tor</code> 等。</p><p><img src="https://img.hi-linux.com/staticfile/mobile01-dd91659a413738e9545b76829c03a3b3-2022-10-12-iZyrRL.gif" alt="在浏览器内运行 Ubuntu 桌面"></p><p><code>Kasm</code> 支持常用的 <code>Linux</code> 桌面：<code>Ubuntu</code>、<code>CentOS</code>、<code>OPenSUSE</code>、<code>Kali Linux</code> 等。</p><h3><span id="kasm-优点"><code>Kasm</code> 优点:</span></h3><ul><li>支持受隔离保护的浏览器</li><li>支持受隔离保护的 <code>Linux</code> 桌面</li><li>支持受隔离保护的多种应用</li><li>在数秒间快速启动应用</li><li>使用完毕瞬间删除应用，不留痕迹</li><li>容器闲置超过指定时间自动删除应用，不留痕迹</li></ul><h3><span id="kasm-缺点"><code>Kasm</code> 缺点:</span></h3><ul><li>目前中文支持不友好，在部分应用内没有中文输入法。</li></ul><p>下表我们将比较下几种常用虚拟化服务 <code>VM</code>、<code>Docker</code>、<code>Kasm</code> 间的区别</p><table><thead><tr><th>VM</th><th>Docker</th><th>Kasm</th></tr></thead><tbody><tr><td>虚拟操作系统</td><td>虚拟容器</td><td>虚拟容器</td></tr><tr><td>硬件资源占用率高</td><td>👑硬件资源占用率最低</td><td>硬件资源占用率较低</td></tr><tr><td>需要安装专用应用程序</td><td>使用终端程序，图形操作不友好</td><td>👑使用网页浏览器，介面友好</td></tr><tr><td>安装操作系统耗时</td><td>部署容器快速</td><td>👑鼠标一键瞬间启动，支持多任务</td></tr><tr><td>虚拟机内的浏览器会储存 Cookie，无法达到完全的隐匿性</td><td>虽然可透过删除容器及重新部署来达到即开即用，但步骤较为繁琐</td><td>👑应用的启动或删除只需鼠标点击，真正实现即开即用。</td></tr><tr><td>👑中文支持度高</td><td>中文支持度低</td><td>中文支持度低</td></tr></tbody></table><h2><span id="部署-kasm">部署 Kasm</span></h2><ul><li>硬件要求</li></ul><table><thead><tr><th>硬件类型</th><th>配置规格</th></tr></thead><tbody><tr><td><strong>CPU</strong></td><td>2 cores</td></tr><tr><td><strong>Memory</strong></td><td>4GB</td></tr><tr><td><strong>Storage</strong></td><td>50GB (SSD)</td></tr></tbody></table><ul><li>操作系统要求</li></ul><table><thead><tr><th>支持的操作系统</th></tr></thead><tbody><tr><td>Ubuntu 18.04 / 20.04 / 22.04 (amd64/arm64)</td></tr><tr><td>Debian 9 / 10 / 11 (amd64/arm64)</td></tr><tr><td>CentOS 7 / 8 (amd64/arm64)</td></tr><tr><td>Oracle Linux 7 / 8 (amd64/arm64)</td></tr><tr><td>Raspberry Pi OS (Debian) 10 / 11 (arm64)</td></tr><tr><td><a href="https://www.kasmweb.com/docs/latest/how_to/other_operating_systems.html" target="_blank" rel="noopener">Other</a></td></tr></tbody></table><p><code>Kasm</code> 部署还是很容易的，基本只需执行以下几条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;tmp</span><br><span class="line">$ curl -O https:&#x2F;&#x2F;kasm-static-content.s3.amazonaws.com&#x2F;kasm_release_1.11.0.18142e.tar.gz</span><br><span class="line">$ tar -xvf kasm_release*.tar.gz</span><br><span class="line">$ sudo bash kasm_release&#x2F;install.sh</span><br></pre></td></tr></table></figure><p>执行完成后，安装脚本会询问『是否接受协议』和『是否启用交换分区』。你可以根据实际情况回答，当然协议是必须接受的。</p><p><img src="https://img.hi-linux.com/staticfile/WX20221012-153755-2022-10-12-TrB2Oe.png" alt></p><p>默认情况下，<code>Kasm</code> 安装脚本会去 <code>Github</code> 下载 <code>Docker-Compose V2</code> 的执行文件。如果你的网络环境不能正常访问 <code>Github</code>，安装脚本就无法正常执行。</p><p>这时你可以提前使用以下命令，先手动完成 <code>Docker-Compose V2</code> 的安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -L https:&#x2F;&#x2F;download.fastgit.org&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;v2.5.0&#x2F;docker-compose-linux-x86_64 -o &#x2F;usr&#x2F;local&#x2F;lib&#x2F;docker&#x2F;cli-plugins&#x2F;docker-compose</span><br><span class="line">$ chmod +x &#x2F;usr&#x2F;local&#x2F;lib&#x2F;docker&#x2F;cli-plugins&#x2F;docker-compose</span><br></pre></td></tr></table></figure><p>然后，等待脚本拉取完相应的 <code>Docker</code> 镜像。首次下载的镜像比较多，需要一定时间，请耐心等待。</p><p><img src="https://img.hi-linux.com/staticfile/WX20221012-160149-2022-10-12-ruVMVR.png" alt></p><p>最后，脚本安装完成后，会生成 <code>Kasm</code> 各组件默认的认证信息。（只显示一次，请注意保存。）</p><p><img src="https://img.hi-linux.com/staticfile/WX20221012-155525-2022-10-12-A4b779.png" alt></p><blockquote><p>注意：默认情况下，<code>Kasm Web</code> 应用程序是运行在 443 端口的，你需要在防火墙上对外开放此端口。如果你想在其他端口上运行 <code>Kasm Web</code> 应用程序，可在调用安装程序时通过 <code>-L</code> 参数指定。例如：<code>sudo bash kasm_release/install.sh -L 8443</code></p></blockquote><p>更详细官方安装教程可以查看：<a href="https://www.kasmweb.com/docs/latest/install/single_server_install.html" target="_blank" rel="noopener">Standard Installation</a>。</p><p>上面的方法是将所有 <code>Kasm</code> 服务组件部署到同一台机器上的。当然，你也可以将不同的 <code>Kasm</code> 服务角色分开安装到不同机器。具体可以参考: <a href="https://www.kasmweb.com/docs/latest/install/multi_server_install.html" target="_blank" rel="noopener">Multi Server Installation</a></p><h3><span id="访问-kasm">访问 Kasm</span></h3><p>默认情况下，你可以使用 <code>https://server_ip</code> 访问的 <code>Kasm</code> 的 Web 页面。</p><p>登陆信息就是上面安装过程中自动生成的默认凭据。</p><p><img src="https://img.hi-linux.com/staticfile/lFMyKV-2022-10-12-mb3ObR.png" alt></p><p><code>Kasm</code> 内置了很多常用的应用：</p><p><img src="https://img.hi-linux.com/staticfile/NlAxM0-2022-10-12-LNPZtO.png" alt></p><p>现在，我们来启动一个 <code>Chrome</code> 试试：</p><p><img src="https://img.hi-linux.com/staticfile/YWo2ol-2022-10-12-OvAv84.png" alt></p><p>点击一下图标后，就秒启动完成一个全新的 <code>Chrome</code> 环境。</p><p><img src="https://img.hi-linux.com/staticfile/Ycqfe7-2022-10-12-KZ0dut.png" alt></p><p>你还可以点击左面的键头图标，来使用一些辅助功能。比如：启用声音、剪贴板等。</p><p><img src="https://img.hi-linux.com/staticfile/myjMye-2022-10-12-8T0NdF.png" alt></p><p>简单体验了下，各种输入输出都很快，播放视频也是非常流畅的。接下来，再启动一个 <code>Ubuntu</code> 看看：</p><p><img src="https://img.hi-linux.com/staticfile/cZZ5O7-2022-10-12-R2qshk.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/fA7mpX-2022-10-12-n4XsEm.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/XhiYno-2022-10-12-TUEO7T.png" alt></p><p>太赞了，<code>Linux</code> 桌面应用，运行起来也是一样的丝般顺滑。</p><p><code>Kasm</code> 的强大功能远远不止这些，它还支持多用户、<code>LDAP</code>、<code>OpenID</code> 等三方认证、自定义容器应用等高级功能。有兴趣的同学可以到官网自行探索哟！</p><h2><span id="参考文档">参考文档</span></h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.mobile01.com/topicdetail.php?f=508&amp;t=6573952" target="_blank" rel="noopener">https://www.mobile01.com/topicdetail.php?f=508&amp;t=6573952</a></li><li><a href="https://www.kasmweb.com/docs/latest/index.html" target="_blank" rel="noopener">https://www.kasmweb.com/docs/latest/index.html</a></li><li><a href="https://www.kasmweb.com/docs/latest/install/single_server_install.html" target="_blank" rel="noopener">https://www.kasmweb.com/docs/latest/install/single_server_install.html</a></li><li><a href="https://www.kasmweb.com/docs/latest/install/multi_server_install.html" target="_blank" rel="noopener">https://www.kasmweb.com/docs/latest/install/multi_server_install.html</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Kasm-介绍&quot;&gt;Kasm 介绍&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Kasm&lt;/code&gt; 是一款基于 &lt;code&gt;Docker&lt;/code&gt; 的容器应用平台，它提供企业级编排、数据丢失防护和 &lt;code&gt;Web&lt;/code&gt; 流技术，以支持将容器化工作负载交付到你的浏览器。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Kasm&lt;/code&gt; 可以在浏览器內运行各种应用，比如：&lt;code&gt;Linux&lt;/code&gt; 桌面、浏览器、聊天工具、办公软件、多媒体工具等。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Kasm&lt;/code&gt; 将这些应用隔离在独立的 &lt;code&gt;Docker&lt;/code&gt; 容器内，在里面做的任何行为不会影响真实的主机，并且具备一次性特点、用完即删，保证了数据的安全性。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Kasm&lt;/code&gt; 是个开源项目，你可以在个人及非营利条件下免费使用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Kasm&lt;/code&gt; 官方网站: &lt;a href=&quot;https://www.kasmweb.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.kasmweb.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Kasm Github&lt;/code&gt;: &lt;a href=&quot;https://github.com/kasmtech&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/kasmtech&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简单来说 &lt;code&gt;Kasm&lt;/code&gt; 可以让用户在浏览器（即开即用）使用各种（容器化）的软件和操作系统。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="DNS" scheme="https://www.hi-linux.com/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>谷歌翻译停服？别慌，手把手教你一招修复 Chrome 浏览器无法翻译网页的问题</title>
    <link href="https://www.hi-linux.com/posts/43698.html"/>
    <id>https://www.hi-linux.com/posts/43698.html</id>
    <published>2022-10-09T01:00:00.000Z</published>
    <updated>2022-10-09T03:38:47.693Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近 Google 突然关停了「谷歌翻译中国版」以及「谷歌地图中国版」两大重磅产品，让无数人惊讶！官方称原因是用户使用率太低。这次关停不单是网页版，依靠其服务的相关功能也会受到影响。</p><p>比如谷歌浏览器「Google Chrome」目前是国内使用率最高的浏览器之一，此次停服则直接影响了浏览器内置的 「<strong>自动网页翻译</strong>」功能。由于很多用户访问英文或其他语言网页的时候，都常要用到谷歌浏览器网页翻译功能。</p><a id="more"></a><p>这里我们就介绍一下解决办法：通过修改 <code>hosts</code> 文件，将谷歌翻译 API 的域名解析到能正常访问的 IP 地址。</p><p><code>hosts</code> 是一个没有扩展名的系统文件，主要作用是定义 IP 地址和主机名的映射关系。</p><p>首先，找到 Hosts 文件所在路径：</p><ul><li>Windows 系统 Hosts 文件路径：<code>C:\Windows\System32\drivers\etc\hosts</code></li><li>Mac 或 Linux 系统 Hosts 文件路径：<code>/etc/hosts</code></li><li>Android 系统 Hosts 文件路径：<code>/system/etc/hosts</code></li></ul><p>然后，你可以用任何文本编辑器工具打开 hosts 文件进行修改。在 <code>macOS</code> 或 <code>Linux</code> 下可以使用 <code>sudo vi /etc/hosts</code> 命令进行编辑，在其末尾添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 谷歌翻译服务 IP</span><br><span class="line">113.108.239.162 translate.google.com</span><br><span class="line">113.108.239.162 translate.googleapis.com</span><br></pre></td></tr></table></figure><p>将以上内容加入 <code>hosts</code> 文件后，谷歌浏览器 <code>Chrome</code> 的翻译功能就可以正常使用了。</p><p>为防止不可用，下面再提供一些备选的 IP 地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 备选谷歌翻译服务 IP</span><br><span class="line">203.208.39.226</span><br><span class="line">120.253.253.34</span><br><span class="line">142.250.66.138</span><br><span class="line">142.250.0.90</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，这种修改只能恢复 <code>Chrome</code> 浏览器的内置翻译功能，并不能恢复 Web 版谷歌翻译 <code>translate.google.com</code> 的访问。</p></blockquote><p><strong>参考文档</strong></p><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.williamlong.info/archives/6947.html" target="_blank" rel="noopener">https://www.williamlong.info/archives/6947.html</a></li><li><a href="https://www.iplaysoft.com/fix-chrome-translate.html" target="_blank" rel="noopener">https://www.iplaysoft.com/fix-chrome-translate.html</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近 Google 突然关停了「谷歌翻译中国版」以及「谷歌地图中国版」两大重磅产品，让无数人惊讶！官方称原因是用户使用率太低。这次关停不单是网页版，依靠其服务的相关功能也会受到影响。&lt;/p&gt;
&lt;p&gt;比如谷歌浏览器「Google Chrome」目前是国内使用率最高的浏览器之一，此次停服则直接影响了浏览器内置的 「&lt;strong&gt;自动网页翻译&lt;/strong&gt;」功能。由于很多用户访问英文或其他语言网页的时候，都常要用到谷歌浏览器网页翻译功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Chrome" scheme="https://www.hi-linux.com/tags/Chrome/"/>
    
      <category term="Google" scheme="https://www.hi-linux.com/tags/Google/"/>
    
  </entry>
  
  <entry>
    <title>阿里开源，超强大的 Kubernetes 本地调试工具 Kt-Connect 使用指南</title>
    <link href="https://www.hi-linux.com/posts/39758.html"/>
    <id>https://www.hi-linux.com/posts/39758.html</id>
    <published>2022-09-27T01:00:00.000Z</published>
    <updated>2022-09-27T09:27:35.918Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="背景">背景</span></h2><blockquote><p>注：背景有点啰嗦，讲讲一路走来研发本地调试的变化，嫌烦的可以直接跳过，不影响阅读。</p></blockquote><h3><span id="2019年">2019年</span></h3><p>我在的公司当时是个什么情况，只有两个Java应用，还都跑在一个Tomcat Servlet容器。</p><p><img src="https://img.hi-linux.com/staticfile/1557258-20220819114243341-1314582490-2022-09-19-XCWjyz.png" alt></p><p>当时是如何本地调试？都是研发自己电脑装个 Mysql，装个 Tomcat，自己电脑运行调试，好处嘛就是后端研发互不干扰，想怎么改就怎么改，APP端研发就直连后端的笔记本调试。上线部署嘛就是一个研发手动编译个 Jar 包丢到云服务器上面，大体就是个草台班子，能干活，但是也就那样。</p><a id="more"></a><h3><span id="2020年">2020年</span></h3><p>到了 2020 年，公司买了一台服务器，Centos 的系统，给装上了 Mysql、Tomcat，用上了 Redis 缓存，RabbitMQ 消息队列，有了独立的测试环境，用上了 Jenkins 自动打包并部署应用，也算鸟枪换炮，起码不用自己打包了。</p><p><img src="https://img.hi-linux.com/staticfile/1557258-20220819134321534-273144804-2022-09-19-VC1hNI.png" alt></p><p>这个时候是如何本地调试呢？起码不用自己电脑装 Mysql 了，后面框架由 SpringMVC 和 Struts2 都改成 Spring Boot，外置的 Tomcat 也可以去掉了。后端研发本地运行 Spring Boot 时直连服务器的 Mysql 进行调试，APP 端再也不用连后端研发的笔记本了，有了相对稳定的调试环境。代价就是各个后端的数据库更新结构要保持兼容性，避免影响他人。</p><h3><span id="2021年">2021年</span></h3><p>随着业务增长，后端框架由 Spring Boot 进化为 Spring Cloud 全家桶，应用运行环境由 Linux 直接运行改为了 Docker 镜像部署，各类中间件同样也使用了 Docker 镜像。产品线增加，单一的开发分支已经不能满足需求，为此又开辟了另外一条后端代码分支，同样的开发测试环境也多了一份。</p><p><img src="https://img.hi-linux.com/staticfile/1557258-20220819135628647-203858289-20220919103031822-2022-09-19-26hYPm.png" alt></p><p>这个时候的本地调试，对于 APP 端来说变化不大，区别连接后端不同环境使用不同域名而已。对于后端的研发同学就不一样了，每次本地调试自己电脑要常驻一个 Eureka 和一个 Config Server，如果本地调试的微服务依赖比较多，没个大内存真是顶不住。</p><h3><span id="2022年">2022年</span></h3><p>业务量继续增加，产品同事数量增加了，那个需求量真是堆积如山，两个分支已经不能满足要求了，又开了第三个分支，还是不够。每次增加新的分支运行环境，后端研发同学也很痛苦，一堆环境和第三方平台回调需要配置。为了能动态扩容缩容，Spring Cloud 全家桶继续演进，抛弃了 Zuul 网关和 Eureka，改为使用 Spring Cloud Kubernetes，运行环境全面向 K8S 靠拢。在此期间公司又采购了一台服务器用于开发测试，内存 CPU 磁盘满上!</p><p><img src="https://img.hi-linux.com/staticfile/1557258-20220819153015204-416674218-20220919103037001-2022-09-19-BkYrUI.png" alt></p><p>进入 K8S 时代，后端研发本地的电脑没办法随意连接 Linux 服务器上面的各种中间件，每个新分支环境里面的每个 POD 都是一个新的 IP，也不可能像之前那样开放指定几个中间件的端口给后端连接，那么多环境每个都做设置的话，运维同学整天不用干别的事了。也由此引出了今天要说的 kt-connect 工具，通过这个工具，后端研发本地的电脑可以代理访问到各个分支环境，也就是 K8S 里面的命名空间的所有服务，并且只需要启动需要调试的服务，大大节省了电脑 CPU 内存占用。</p><h2><span id="选型">选型</span></h2><p>在选择代理访问 K8S 环境以便于本地调试的工具中，网上有几种。</p><h3><span id="1-端口转发">1. 端口转发</span></h3><p>使用 Ingress、NodePort、LoadBalancer 之类的将流量转发到指定端口，如上文所说，会让运维同学工作量比较大，也不便于分支环境的自动创建和回收，只适合需要暴露端口数量不多的场景。</p><h3><span id="2-vpn">2. VPN</span></h3><p>通过在 K8S 每个命名空间里面设置一个运行有 VPN 服务的 POD，后端研发笔记本通过 VPN 客户端连接代理进入到指定命名空间，可以正常访问和解析集群内各类服务，基本能满足日常的要求，缺点是每个命名空间都常驻了一个 VPN 服务的运行资源。</p><h3><span id="3-telepresence">3. Telepresence</span></h3><p>在搜索的过程中发现了这个代理工具，几乎可以说 9 成的中英文技术文章都推荐使用这个工具，功能非常强大，不但提供了 VPN 所具有的代理功能，可以访问到命名空间内所有服务，还能指定各种规则拦截指定服务的流量到本地机器，相当于本地机器也能作为一个普通的 POD 提供对外服务。大体设计原理如下：</p><p><img src="https://img.hi-linux.com/staticfile/1557258-20220825171140771-1117068712-2022-09-19-Gz6nqH.png" alt></p><p>在研发本地电脑执行如下命令</p><blockquote><p>telepresence helm install --kubeconfig .\kubeconfig<br>telepresence connect —kubeconfig .\kubeconfig</p></blockquote><p>就会自动在 K8S 集群创建一个命名空间 ambassador，并且部署一个 traffic-manager 的 Pod，用于流量管理，而在研发笔记本本地则会启动 2 个 Daemon 服务，其中一个叫 Root Daemon，用于建立一条双向代理通道，并管理本地电脑与 K8S 集群之间的流量，另外一个 User Daemon 则是负责与 Traffic Manager 通信，设置拦截规则，如果登录后还负责与 Ambassador Cloud 进行通信。</p><p>通过配置拦截规则，拦截的 Pod 里面会安装一个 traffic-agent，官方文档说明是类似 K8S 集群的 sidecar 模式，对注入 POD 进行流量劫持，所有流量出入通过 traffic-manager 进行重新路由。</p><blockquote><p>The Traffic Agent is a sidecar container that facilitates intercepts. When an intercept is first started, the Traffic Agent container is injected into the workload’s pod(s).</p></blockquote><p>虽然他的功能很强大，但是在目前 2.5 版本的使用过程中，为了使用他的拦截和 Preview Url 功能必须在他家的商业云平台 Ambassador Cloud 进行注册登陆(注：不知道为什么网上技术文章都没提到这点，测试的时候非得要登录他家云平台)，并且拦截规则的配置是通过云平台的网页进行操作的，联网的要求，包括可能存在的安全，泄露之类的隐患，我觉得是不可接受，也因此不得不放弃使用这个工具。</p><p>还有一个不得不说的缺点就是，老版本使用后可以清理掉自动创建的命名空间（namespace）和 Pod、拦截 Agent 的功能（telepresence uninstall）也没了，在 2.5 版本的命令参数里面完全消失了，这就导致每次使用后，如果想保持环境干净，还得麻烦运维同学去清理掉，非常麻烦，简直逼死洁癖患者。</p><h3><span id="4-kt-connect">4. kt-connect</span></h3><p>所幸开源社区又找到了另外一款类似 Telepresence 的工具，名为<a href="https://github.com/alibaba/kt-connect" target="_blank" rel="noopener">kt-connect</a>，使用版本为 v0.3.6（顺便说下我们使用的 K8S 版本是 1.24），并且它无需联网登陆什么账号，结束命令执行默认还会自动清理。阿里出品，不确定是不是又一个 KPI 开源项目，但是至少这一刻我对这个工具是非常满意的。</p><h2><span id="原理">原理</span></h2><p>同 Telepresence 类似，但不同的是，kt-connect 只会在指定连接的命名空间（namespace）里面新建一个自用的 Pod，然后部署一个 kt-connect-shadow 的镜像。相比 Telepresence，它在模式进行了细分扩展，分为四大模式：</p><h3><span id="1-connect模式">1. Connect模式</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ktctl.exe connect --kubeconfig .\kubeconfig --namespace feature-N --debug</span><br></pre></td></tr></table></figure><p>这个模式下，kt-connect 起到的是一个类似于VPN的作用，研发本地电脑可以访问到连接的命名空间(namespace)内的所有服务，但是并没有加到集群里面其他服务里面，其他服务的流量并不会转发到本地电脑。</p><blockquote><p>注1：与 telepresence 类似，kt-connect 所有命令都要带上 <code>--kubeconfig</code> ，确保有足够权限和能正确连接 K8S 集群的 API Server，很多文章都很少提到这点，假如K8S集群限制权限，或者与研发不在同一个网络，必须确保使用运维同学提供的有足够权限的授权文件 kubeconfig 来进行连接。</p></blockquote><blockquote><p>注2：</p><p>Failed to setup port forward local:28344 -&gt; pod kt-connect-shadow-gseak:53 error=“error upgrading connection: error sending request: Post “<a href="https://10.0.8.101:8443/api/v1/namespaces/feature-N/pods/kt-connect-shadow-gseak/portforward" target="_blank" rel="noopener">https://10.0.8.101:8443/api/v1/namespaces/feature-N/pods/kt-connect-shadow-gseak/portforward</a>”: dial tcp 10.0.8.101:8443: connectex: A socket operation was attempted to an unreachable host.”，</p></blockquote><p>如果出现以上报错的话，有可能是 kt-connect 路由 BUG，可能本地电脑的路由与新加的通往 API Server 的路由有冲突，增加参数 <code>--excludeIps 10.0.8.101/32</code> 即可，如果网段冲突比较多，可以扩大网段范围，例如<code>--excludeIps 10.0.8.0/24</code> 参考 <a href="https://github.com/alibaba/kt-connect/issues/302" target="_blank" rel="noopener">issue-302</a>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ktctl.exe connect --kubeconfig .\kubeconfig --namespace feature-N --excludeIps 10.0.8.101&#x2F;32 --debug</span><br></pre></td></tr></table></figure><h3><span id="2-exchange模式">2. Exchange模式</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ktctl.exe exchange serviceA --kubeconfig .\kubeconfig --namespace feature-N --expose 12001 --debug</span><br></pre></td></tr></table></figure><p>这个模式类似于 Telepresence 拦截模式，将指定服务的所有流量拦截下来转发到研发本地电脑的端口，使用这个模式能对环境里的访问请求直接进行调试。</p><p>具体原理就是将 service 里面的 Pod 替换成一个 <code>serviceA-kt-exchange</code> 的 Pod。</p><blockquote><p>注1：Exchange 模式的流量方向是单向的，并不会将本地电脑主动发起的请求代理过去，如果K8S集群跟研发本地电脑不在一个网段内，需要另外开一个命令行运行 Connect 模式，确保本地服务可以正常连接 K8S 集群的其他服务，参考<a href="https://github.com/alibaba/kt-connect/issues/216" target="_blank" rel="noopener">issue-216</a>。</p></blockquote><blockquote><p>注2：Exchange 模式是通过拦截 service 进行流量转发，假如集群的请求没有经过 service，例如直接解析到 Pod 类，可能就会出现拦截失败的情况（同理 Mesh 模式也是如此），所以出现问题记得跟运维同学确认K8S集群内的路由情况。</p></blockquote><h3><span id="3-mesh模式">3. Mesh模式</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kctl.exe mesh serviceA --kubeconfig .\kubeconfig --namespace feature-N --expose 12001 --debug</span><br></pre></td></tr></table></figure><p>执行命令后可以看到输出日志里面包含类似文字：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2:30PM INF Now you can access your service by header &#39;VERSION: xxxxx&#39;</span><br></pre></td></tr></table></figure><p>这个模式本地电脑的服务和 K8S 集群里面相同的服务同时对外响应请求，但是只有通过指定的 http 请求头 VERSION: xxxx 的请求才会转发到本地电脑，相比 Exchange 模式，保证了其他人服务正常使用，同时研发又能进行本地调试。每次生成的请求头 VERSION 的值都是动态生成的，如果要固定这个值，可以通过参数 <code>--versionMark</code> 写死，例如固定值为 test-version，命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kctl.exe mesh serviceA --kubeconfig .\kubeconfig --namespace feature-N --expose 12001 --debug --versionMark test-version</span><br></pre></td></tr></table></figure><p>具体原理就是将 serviceA 里面的 Pod 替换成一个 serviceA-kt-router 的路由镜像，负责根据请求头进行流量代理转发，另外生成一个 serviceA-kt-stuntman 服务，这个就是线上正常运行的 serviceA，还有一个serviceA-kt-mesh-xxxxx 服务，这个就负责将代理流量到本地电脑。</p><h3><span id="4-preview模式">4. Preview模式</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kctl.exe preview serviceB --kubeconfig .\kubeconfig --namespace feature-N --expose 12001</span><br></pre></td></tr></table></figure><p>不同于 Exchange 和 Mesh 模式要求 K8S 集群有一个在运行的服务，Preview 模式可以将本地电脑运行的程序部署到 K8S 集群中作为一个全新的 Service 对外提供服务，非常便于新建服务的开发调试、预览等作用。</p><blockquote><p>本文转载自：「 博客园 」，原文：<a href="https://url.hi-linux.com/9JmW5%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.hi-linux.com/9JmW5，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;注：背景有点啰嗦，讲讲一路走来研发本地调试的变化，嫌烦的可以直接跳过，不影响阅读。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;2019年&quot;&gt;2019年&lt;/h3&gt;
&lt;p&gt;我在的公司当时是个什么情况，只有两个Java应用，还都跑在一个Tomcat Servlet容器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/1557258-20220819114243341-1314582490-2022-09-19-XCWjyz.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;当时是如何本地调试？都是研发自己电脑装个 Mysql，装个 Tomcat，自己电脑运行调试，好处嘛就是后端研发互不干扰，想怎么改就怎么改，APP端研发就直连后端的笔记本调试。上线部署嘛就是一个研发手动编译个 Jar 包丢到云服务器上面，大体就是个草台班子，能干活，但是也就那样。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 KubeSeal 高效加密和管理 Kubernetes 集群的 Secret</title>
    <link href="https://www.hi-linux.com/posts/35875.html"/>
    <id>https://www.hi-linux.com/posts/35875.html</id>
    <published>2022-09-23T01:00:00.000Z</published>
    <updated>2022-09-23T01:21:21.530Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在 K8s 的管理过程中，像 Secret 这种资源并不好维护，KubeSeal 提供了一种相对简单的方式来对原始 Secret 资源进行加密，并通过控制器进行解密，以此来规避 Secret 泄露风险。</p><a id="more"></a><h2><span id="安装">安装</span></h2><h3><span id="安装-kubeseal">安装 <code>KubeSeal</code></span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.18.0/kubeseal-0.18.0-linux-amd64.tar.gz</span><br><span class="line">$ tar -xvf kubeseal-0.18.0-linux-amd64.tar.gz</span><br><span class="line">$ cp kubeseal /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">$ kubeseal --version</span><br></pre></td></tr></table></figure><h3><span id="安装controller">安装<code>controller</code></span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.18.0/controller.yaml</span><br></pre></td></tr></table></figure><p>执行上述命令之后会在 <code>kube-system</code> 命名空间下启动一个控制器 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ k get pod -n kube-system |grep seal</span><br><span class="line">sealed-secrets-controller-b9fb75d85-k4csm    1/1     Running   0          7h28m</span><br></pre></td></tr></table></figure><p>Pod 启动之后，使用端口转发映射到本地：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system port-forward svc/sealed-secrets-controller 8080:8080</span><br></pre></td></tr></table></figure><h2><span id="使用方式">使用方式</span></h2><h3><span id="生成加密文件">生成加密文件</span></h3><p>首先在本地创建一个名为 <code>secret-example.yaml</code> 的文件，编码前的 <code>secret</code> 字段为：<code>mysupersecret</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-example</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">secret:</span> <span class="string">bXlzdXBlcnNlY3JldAo=</span></span><br></pre></td></tr></table></figure><p>使用如下命令将 <code>secret-example.yaml</code>，转换为加密后的文件 <code>sealed-secret-example.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeseal --secret-file secret-example.yaml --sealed-secret-file sealed-secret-example.yaml</span><br></pre></td></tr></table></figure><p><code>sealed-secret-example.yaml</code> 的内容如下，<code>spec.encryptedData.secret</code> 就是加密后的内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">bitnami.com/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SealedSecret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-example</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">encryptedData:</span></span><br><span class="line">    <span class="attr">secret:</span> <span class="string">AgB1ZZg8+J+0HLymOQZdTfWVQZiNkhm5X6WULJuBAAEaQQNhM8i2TV2I1SgKT4sUOCRv90XA1oeFld3XoGPjvYE3leOD1cvK1dDVqno6mNLRziokISk/9fB3cVE2GVgyCud//M53xNpVemDufgsJS2q/KGIOeNEijk9ZM2FaKoLDwtPaVNL0NfmC2xne2XtWJp+/eMOREhbubQhnj5M/Se75axazviuDNf6Ss9fAuR38Msd5DXnKBtyrckEHSa8TDn8ErssOh0ogX14e0/ThN3EWJecSBtx7Xfd0m90+vjmvWevMag442349aquR/qLo0mg40mhcCqSBw/MjaIGZ2F5XRufG1WEP43OgLMTixN2lLSU3eYTrv5t075taI9WJgoOl0DD8UA74EMpX7RMKTiXD6C0XngKmMKg5fUK7JNLFfwHMRPi4zNTwJa9ViDyD0iAJrGGbmMso/nHEtwOtrLE5Rrf0kLQ5N6Lj57gOBdqu903/vDM4Jm695GvEWL2aR3ShOxasHCuZeXj8Q5+KYWeF9sySiJH8bwEtaw6x7j9AxBOwjxWYD0Jvj9KhtlqBa4okSDc3bcgRKGhsSXQx6jOumI5rj+V542hkB6Z8JOtJ17VmzR6XDQDmqSl1FqqwKD5n5yUy5Kf6pJYBnsgKn3TzesQ6JfQbyRLTh1Pn3odOYCnp+Ixbd0Tgn0n5m0KO3RX0hiwGoe0hObIZcsF36g==</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">data:</span> <span class="literal">null</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">secret-example</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure><p>可以将加密后的文件保存到 Gitlab。</p><p>创建加密文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ k create -f sealed-secret-example.yaml</span><br><span class="line">sealedsecret.bitnami.com/secret-example created</span><br><span class="line"></span><br><span class="line">$ k get sealedsecrets.bitnami.com</span><br><span class="line">NAME             AGE</span><br><span class="line">secret-example   6s</span><br></pre></td></tr></table></figure><p>在创建完加密文件之后，Controller 会解密并生成对应的 <code>secret</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ k get secrets |grep secret-example</span><br><span class="line">secret-example                                   Opaque                                1      2m15s</span><br></pre></td></tr></table></figure><p>查看由 Controller 生成的 <code>secret</code> 资源内容，可以看到 <code>data.secret</code> 与上面创建的 <code>secret-example.yaml</code> 文件内容一致：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">k</span> <span class="string">get</span> <span class="string">secret</span> <span class="string">secret-example</span> <span class="string">-oyaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">secret:</span> <span class="string">bXlzdXBlcnNlY3JldAo=</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">"2022-06-10T00:50:40Z"</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-example</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">ownerReferences:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">bitnami.com/v1alpha1</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">SealedSecret</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">secret-example</span></span><br><span class="line">    <span class="attr">uid:</span> <span class="string">57a5b691-9bb5-4dac-800a-1a1baa878299</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">"675560"</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">e0db31ad-082b-4596-9fd0-28cc810d86f4</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br></pre></td></tr></table></figure><blockquote><p>注：<code>SealedSecret</code> 和对应的 <code>secret</code> 资源必须位于相同的命名空间</p></blockquote><h3><span id="tips">TIPs</span></h3><ul><li><p><code>kubeseal</code> 支持如下<a href="https://github.com/bitnami-labs/sealed-secrets/blob/main/cmd/controller/server.go#L40" target="_blank" rel="noopener">API</a>：</p><table><thead><tr><th>Route</th><th>Description</th></tr></thead><tbody><tr><td>/healthz</td><td>Health check route useful for the readiness and liveness probes and for creating an external probe; for example with blackbox exporter.</td></tr><tr><td>/metrics</td><td>Endpoint for the Prometheus to retrieve the controller’s metrics.</td></tr><tr><td>/v1/verify</td><td>Validates a secret.</td></tr><tr><td>/v1/rotate</td><td>Rotates the secret.</td></tr><tr><td>/v1/cert.pem</td><td>Retrieves the public certificate.</td></tr></tbody></table></li><li><p>上例中 Controller 用的证书是自己生成的，还可以<a href="https://github.com/bitnami-labs/sealed-secrets/blob/main/docs/bring-your-own-certificates.md" target="_blank" rel="noopener">指定自己的证书</a>，更方便迁移和管理</p></li><li><p>使用 <code>KubeSeal</code> 可能会有一种困惑，如果用户直接挂载其他命名空间的 secret，那么这样可能会导致 secret 泄露。官方对此有作<a href="https://github.com/bitnami-labs/sealed-secrets#scopes" target="_blank" rel="noopener">解释</a>，如可以通过 RBAC 限制用户可以访问的命名空间以及资源类型。更多参见<a href="https://github.com/bitnami-labs/sealed-secrets#sealed-secrets-for-kubernetes" target="_blank" rel="noopener">README</a></p></li></ul><h3><span id="参考">参考</span></h3><ul><li><a href="https://carlosalca.medium.com/how-to-manage-all-my-k8s-secrets-in-git-securely-with-bitnami-sealed-secrets-43580b8fa0c7" target="_blank" rel="noopener">How to manage all my K8s secrets in git securely with Bitnami Sealed Secrets</a></li></ul><blockquote><p>本文转载自：「 博客园 」，原文：<a href="https://url.hi-linux.com/vakJR" target="_blank" rel="noopener">https://url.hi-linux.com/vakJR</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 K8s 的管理过程中，像 Secret 这种资源并不好维护，KubeSeal 提供了一种相对简单的方式来对原始 Secret 资源进行加密，并通过控制器进行解密，以此来规避 Secret 泄露风险。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>图解 Kubernetes 网络流量流转路径</title>
    <link href="https://www.hi-linux.com/posts/13487.html"/>
    <id>https://www.hi-linux.com/posts/13487.html</id>
    <published>2022-09-20T01:00:00.000Z</published>
    <updated>2022-09-20T06:07:22.929Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>本文翻译自 <a href="https://learnk8s.io/kubernetes-network-packets%EF%BC%8C%E5%B9%B6%E6%B2%A1%E6%9C%89%E9%80%90%E5%AD%97%E7%BF%BB%E8%AF%91%EF%BC%8C%E5%B8%A6%E5%85%A5%E4%BA%86%E4%BA%9B%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3%E3%80%82" target="_blank" rel="noopener">https://learnk8s.io/kubernetes-network-packets，并没有逐字翻译，带入了些自己的理解。</a></p></blockquote><p><img src="https://img.hi-linux.com/staticfile/k8s-network-1-2022-09-19-c7m4AB.svg" alt></p><p>阅读本文，你可以了解在 Kubernetes 内外，数据包是如何转发的，从原始的 Web 请求开始，到托管应用程序的容器。</p><h2><span id="kubernetes-网络要求">Kubernetes 网络要求</span></h2><p>在深入了解在 Kubernetes 集群中数据包如何流转的细节之前，先明确一下 Kubernetes 对网络的要求。</p><p>Kubernetes 网络模型定义了一组基本规则：</p><ul><li>在不使用网络地址转换 (NAT) 的情况下，集群中的 Pod 能够与任意其他 Pod 进行通信。</li><li>在不使用网络地址转换 (NAT) 的情况下，在集群节点上运行的程序能与同一节点上的任何 Pod 进行通信。</li><li>每个 Pod 都有自己的 IP 地址（IP-per-Pod），并且任意其他 Pod 都可以通过相同的这个地址访问它。</li></ul><p>这些要求，不会将具体实现限制在某种解决方案上。</p><a id="more"></a><p>相反，它们笼统地描述了集群网络的特性。</p><p>为了满足这些限制，你必须解决以下挑战:</p><ol><li>如何确保同一个 Pod 中的容器行为就像它们在同一个主机上一样？</li><li>集群中的 Pod 能否访问其他 Pod？</li><li>Pod 可以访问服务吗？服务是负载均衡的吗？</li><li>Pod 可以接收集群外部的流量吗？</li></ol><p>在本文中，将重点关注前三点，从 Pod 内的网络，容器到容器的通信说起。</p><h2><span id="linux-网络命名空间如何在-pod-中工作">Linux 网络命名空间如何在 Pod 中工作</span></h2><p>让我们来看一个运行应用的主容器和伴随一起的另一个容器。</p><p>在示例中，有一个带有 nginx 和 busybox 容器的 Pod:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: multi-container-Pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: container-1</span><br><span class="line">      image: busybox</span><br><span class="line">      command: [&#39;&#x2F;bin&#x2F;sh&#39;, &#39;-c&#39;, &#39;sleep 1d&#39;]</span><br><span class="line">    - name: container-2</span><br><span class="line">      image: nginx</span><br></pre></td></tr></table></figure><p>部署时，会发生以下事情：</p><ol><li>Pod 在节点上拥有独立的网络命名空间。</li><li>分配一个 IP 地址给 Pod ，两个容器之间共享端口。</li><li>两个容器共享相同的网络命名空间，并在本地彼此可见。</li></ol><p>网络配置在后台迅速完成。</p><p>但是，让我们退后一步，尝试理解为什么运行容器需要上述动作。</p><p><a href="https://iximiuz.com/en/posts/container-networking-is-simple/" target="_blank" rel="noopener">在 Linux 中，网络命名空间是独立的、隔离的逻辑空间。</a></p><p>你可以将网络命名空间视为，将物理网络接口分割小块之后的独立部分。</p><p>每个部分都可以单独配置，并拥有自己的网络规则和资源。</p><p>这些包括防火墙规则、接口（虚拟的或物理的）、路由以及与网络相关的所有内容。</p><ol><li>物理网络接口持有根网络命名空间。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-2-2022-09-19-2lGj37.svg" alt></p><ol start="2"><li>你可以使用 Linux 网络命名空间来创建独立的网络。每个网络都是独立的，除非你进行配置，默认不会与其他网络互通。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-3-2022-09-19-0Iv3p7.svg" alt></p><p>但最终，还是需要物理接口处理所有真实的数据包，所有虚拟接口都是基于物理接口创建的。</p><p>网络命名空间可以通过 <a href="https://man7.org/linux/man-pages/man8/ip-netns.8.html" target="_blank" rel="noopener">ip-netns</a> 进行管理，使用 <code>ip netns list</code> 可以列出主机上的命名空间。</p><blockquote><p>需要注意的是，创建的网络命名空间会出现在 <code>/var/run/netns</code> 下面，但 Docker 并没有遵循这一规则。</p></blockquote><p>例如，这是 Kubernetes 节点的一些命名空间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ip netns list</span><br><span class="line"></span><br><span class="line">cni-0f226515-e28b-df13-9f16-dd79456825ac (id: 3)</span><br><span class="line">cni-4e4dfaac-89a6-2034-6098-dd8b2ee51dcd (id: 4)</span><br><span class="line">cni-7e94f0cc-9ee8-6a46-178a-55c73ce58f2e (id: 2)</span><br><span class="line">cni-7619c818-5b66-5d45-91c1-1c516f559291 (id: 1)</span><br><span class="line">cni-3004ec2c-9ac2-2928-b556-82c7fb37a4d8 (id: 0)</span><br></pre></td></tr></table></figure><blockquote><p>注意 cni- 前缀；这意味着命名空间是由 CNI 插件创建的。</p></blockquote><p>当你创建一个 Pod，Pod 被分配给一个节点后，CNI 将：</p><ol><li>分配 IP 地址。</li><li>将容器连接到网络。</li></ol><p>如果 Pod 包含多个容器，那么这些容器都将被放在同一个命名空间中。</p><ol><li>当创建 Pod 时，容器运行时会给容器创建一个网络命名空间。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-4-20220919141522939-2022-09-19-nMCwoz.svg" alt></p><ol start="2"><li>然后 CNI 负责给 Pod 分配一个 IP 地址。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-5-2022-09-19-sBtEl3.svg" alt></p><ol start="3"><li>最后 CNI 将容器连接到网络的其余部分。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-6-2022-09-19-MiJzyw.svg" alt></p><p>那么，当你列出节点上的容器的命名空间会发生什么呢？</p><p>你可以通过 SSH 连接到 Kubernetes 节点并查看命名空间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ lsns -t net</span><br><span class="line"></span><br><span class="line">        NS TYPE NPROCS   PID USER     NETNSID NSFS                           COMMAND</span><br><span class="line">4026531992 net     171     1 root  unassigned &#x2F;run&#x2F;docker&#x2F;netns&#x2F;default      &#x2F;sbin&#x2F;init noembed norestore</span><br><span class="line">4026532286 net       2  4808 65535          0 &#x2F;run&#x2F;docker&#x2F;netns&#x2F;56c020051c3b &#x2F;pause</span><br><span class="line">4026532414 net       5  5489 65535          1 &#x2F;run&#x2F;docker&#x2F;netns&#x2F;7db647b9b187 &#x2F;pause</span><br></pre></td></tr></table></figure><p><code>lsns</code> 是一个用于列出主机上所有可用命名空间的命令。</p><blockquote><p>请记住，Linux 中有<a href="https://man7.org/linux/man-pages/man7/namespaces.7.html" target="_blank" rel="noopener">多种命名空间类型</a>。</p></blockquote><p>Nginx 容器在哪里？</p><p>那些 pause 容器是什么？</p><h2><span id="在-pod-中pause-容器创建了网络命名空间">在 Pod 中，pause 容器创建了网络命名空间</span></h2><p>先列出节点上的所有命名空间，看看能否找到 Nginx 容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ lsns</span><br><span class="line">        NS TYPE   NPROCS   PID USER            COMMAND</span><br><span class="line"># truncated output</span><br><span class="line">4026532414 net         5  5489 65535           &#x2F;pause</span><br><span class="line">4026532513 mnt         1  5599 root            sleep 1d</span><br><span class="line">4026532514 uts         1  5599 root            sleep 1d</span><br><span class="line">4026532515 pid         1  5599 root            sleep 1d</span><br><span class="line">4026532516 mnt         3  5777 root            nginx: master process nginx -g daemon off;</span><br><span class="line">4026532517 uts         3  5777 root            nginx: master process nginx -g daemon off;</span><br><span class="line">4026532518 pid         3  5777 root            nginx: master process nginx -g daemon off;</span><br></pre></td></tr></table></figure><p>Nginx 容器在挂载 (<code>mnt</code>)、Unix time-sharing (<code>uts</code>) 和 PID (<code>pid</code>) 命名空间中，但不在网络命名空间 (<code>net</code>) 中。</p><p>不幸的是，<code>lsns</code> 只显示每个进程最小的 PID，但你可以根据这个进程 ID 进一步过滤。</p><p>使用以下命令，在所有命名空间中检索 Nginx 容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lsns -p 5777</span><br><span class="line"></span><br><span class="line">       NS TYPE   NPROCS   PID USER  COMMAND</span><br><span class="line">4026531835 cgroup    178     1 root  &#x2F;sbin&#x2F;init noembed norestore</span><br><span class="line">4026531837 user      178     1 root  &#x2F;sbin&#x2F;init noembed norestore</span><br><span class="line">4026532411 ipc         5  5489 65535 &#x2F;pause</span><br><span class="line">4026532414 net         5  5489 65535 &#x2F;pause</span><br><span class="line">4026532516 mnt         3  5777 root  nginx: master process nginx -g daemon off;</span><br><span class="line">4026532517 uts         3  5777 root  nginx: master process nginx -g daemon off;</span><br><span class="line">4026532518 pid         3  5777 root  nginx: master process nginx -g daemon off;</span><br></pre></td></tr></table></figure><p><code>pause</code> 进程再次出现，它劫持了网络命名空间。</p><p>这是怎么回事？</p><p><em><strong>集群中的每个 Pod 都有一个额外的隐藏容器在后台运行，称为 pause 容器。</strong></em></p><p>列出在节点上运行的容器并获取 pause 容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps | grep pause</span><br><span class="line"></span><br><span class="line">fa9666c1d9c6   k8s.gcr.io&#x2F;pause:3.4.1  &quot;&#x2F;pause&quot;  k8s_POD_kube-dns-599484b884-sv2js…</span><br><span class="line">44218e010aeb   k8s.gcr.io&#x2F;pause:3.4.1  &quot;&#x2F;pause&quot;  k8s_POD_blackbox-exporter-55c457d…</span><br><span class="line">5fb4b5942c66   k8s.gcr.io&#x2F;pause:3.4.1  &quot;&#x2F;pause&quot;  k8s_POD_kube-dns-599484b884-cq99x…</span><br><span class="line">8007db79dcf2   k8s.gcr.io&#x2F;pause:3.4.1  &quot;&#x2F;pause&quot;  k8s_POD_konnectivity-agent-84f87c…</span><br></pre></td></tr></table></figure><p>可以看到，节点上的每一个 Pod 都会有一个对应的 pause 容器。</p><p>这个 <code>pause</code> 容器负责创建和维持网络命名空间。</p><p><a href="https://www.aquasec.com/cloud-native-academy/container-security/container-runtime/" target="_blank" rel="noopener">底层容器运行时</a>会完成网络命名空间的创建，通常是由 <code>containerd</code> 或 <code>CRI-O</code> 完成。</p><p>在部署 Pod 和创建容器之前，由运行时创建网络命名空间。</p><p>容器运行时会自动完成这些，不需要手工执行 <code>ip netns</code> 创建命名空间。</p><p>话题回到 pause 容器。</p><p>它包含非常少的代码，并且在部署后立即进入睡眠状态。</p><p>但是，<a href="https://www.ianlewis.org/en/almighty-pause-container" target="_blank" rel="noopener">它是必不可少的，并且在 Kubernetes 生态系统中起着至关重要的作用</a>。</p><ol><li>创建 Pod 时，容器运行时会创建一个带有睡眠容器的网络命名空间。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-7-20220919141528218-2022-09-19-7EsuRT.svg" alt></p><ol start="2"><li>Pod 中的其他容器都会加入由 pause 容器创建的网络名称空间。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-8-20220919141535160-2022-09-19-JOFs8C.svg" alt></p><ol start="3"><li>此时，CNI 分配 IP 地址并将容器连接到网络。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-9-2022-09-19-Wxey6q.svg" alt></p><p>一个进入睡眠状态的容器有什么用？</p><p>为了理解它的用途，让我们想象一个 Pod 有两个容器，就像前面的例子一样，但没有 pause 容器。</p><p>一旦容器启动，CNI 将会：</p><ol><li>使 busybox 容器加入之前的网络命名空间。</li><li>分配 IP 地址。</li><li>将容器连接到网络。</li></ol><p>如果 Nginx 崩溃了怎么办？</p><p>CNI 将不得不再次执行所有步骤，并且两个容器的网络都将中断。</p><p>由于睡眠容器不太可能有任何错误，因此创建网络命名空间通常是一种更安全、更健壮的选择。</p><blockquote><p>如果 Pod 中的一个容器崩溃了，剩下的仍然可以回复其他网络请求。</p></blockquote><h2><span id="分配一个-ip-地址给-pod">分配一个 IP 地址给 Pod</span></h2><p>前面我提到 Pod 和两个容器将具有同一个 IP 地址。</p><p>那是怎样配置的呢？</p><blockquote><p>在 Pod 网络命名空间内，创建了一个接口，并分配了一个 IP 地址。</p></blockquote><p>让我们验证一下。</p><p>首先，找到 Pod 的 IP 地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get Pod multi-container-Pod -o jsonpath&#x3D;&#123;.status.PodIP&#125;</span><br><span class="line"></span><br><span class="line">10.244.4.40</span><br></pre></td></tr></table></figure><p>接下来，找到相关的网络命名空间。</p><p>由于网络命名空间是从物理接口创建的，需要先访问集群节点。</p><blockquote><p>如果你运行的是 minikube，使用 <code>minikube ssh</code> 访问节点。如果在云厂中运行，那么应该有某种方法可以通过 SSH 访问节点。</p></blockquote><p>进入后，找到最新创建的命名网络命名空间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ ls -lt &#x2F;var&#x2F;run&#x2F;netns</span><br><span class="line"></span><br><span class="line">total 0</span><br><span class="line">-r--r--r-- 1 root root 0 Sep 25 13:34 cni-0f226515-e28b-df13-9f16-dd79456825ac</span><br><span class="line">-r--r--r-- 1 root root 0 Sep 24 09:39 cni-4e4dfaac-89a6-2034-6098-dd8b2ee51dcd</span><br><span class="line">-r--r--r-- 1 root root 0 Sep 24 09:39 cni-7e94f0cc-9ee8-6a46-178a-55c73ce58f2e</span><br><span class="line">-r--r--r-- 1 root root 0 Sep 24 09:39 cni-7619c818-5b66-5d45-91c1-1c516f559291</span><br><span class="line">-r--r--r-- 1 root root 0 Sep 24 09:39 cni-3004ec2c-9ac2-2928-b556-82c7fb37a4d8</span><br></pre></td></tr></table></figure><p>在示例中，就是 <code>cni-0f226515-e28b-df13-9f16-dd79456825ac</code>。然后，可以在该命名空间内运行 <code>exec</code> 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ip netns exec cni-0f226515-e28b-df13-9f16-dd79456825ac ip a</span><br><span class="line"></span><br><span class="line"># output truncated</span><br><span class="line">3: eth0@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default</span><br><span class="line">    link&#x2F;ether 16:a4:f8:4f:56:77 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.244.4.40&#x2F;32 brd 10.244.4.40 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::14a4:f8ff:fe4f:5677&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>这个 IP 就是 Pod 的 IP 地址！通过查找 @if12 中的 12 找到网络接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip link | grep -A1 ^12</span><br><span class="line"></span><br><span class="line">12: vethweplb3f36a0@if16: mtu 1376 qdisc noqueue master weave state UP mode DEFAULT group default</span><br><span class="line">    link&#x2F;ether 72:1c:73:d9:d9:f6 brd ff:ff:ff:ff:ff:ff link-netnsid 1</span><br></pre></td></tr></table></figure><p>你还可以验证 Nginx 容器是否监听了来自该命名空间内的 HTTP 流量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ip netns exec cni-0f226515-e28b-df13-9f16-dd79456825ac netstat -lnp</span><br><span class="line"></span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID&#x2F;Program name</span><br><span class="line">tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      692698&#x2F;nginx: master</span><br><span class="line">tcp6       0      0 :::80                   :::*                    LISTEN      692698&#x2F;nginx: master</span><br></pre></td></tr></table></figure><blockquote><p>如果你无法通过 SSH 访问集群中的工作节点，你可以使用 <code>kubectl exec</code> 获取到 busybox 容器的 shell 并直接在内部使用 <code>ip</code> 和 <code>netstat</code> 命令。</p></blockquote><p>刚刚我们介绍了容器之间的通信，再来看看如何建立 Pod 到 Pod 的通信吧。</p><h2><span id="查看集群中-pod-到-pod-的流量">查看集群中 Pod 到 Pod 的流量</span></h2><p>Pod 到 Pod 的通信有两种可能的情况：</p><ol><li>Pod 流量的目的地是同一节点上的 Pod。</li><li>Pod 流量的目的地是在不同节点上的 Pod。</li></ol><p>整个工作流依赖于虚拟接口对和网桥，下面先来了解一下这部分的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">为了让一个 Pod 与其他 Pod 通信，它必须先访问节点的根命名空间。</span><br></pre></td></tr></table></figure><p>通过虚拟以太网对来实现 Pod 和根命名空间的连接。</p><p>这些虚拟接口设备（veth 中的 v）连接并充当两个命名空间之间的隧道。</p><p>使用此 <code>veth</code> 设备，你将一端连接到 Pod 的命名空间，另一端连接到根命名空间。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-10-2022-09-19-zqzPW6.svg" alt></p><p>CNI 可以帮你执行这些操作，但你也可以手动执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip link add veth1 netns Pod-namespace type veth peer veth2 netns root</span><br></pre></td></tr></table></figure><p>现在 Pod 的命名空间有一个可以访问根命名空间的 <code>隧道</code>。</p><p>节点上，新建的每一个 Pod 都会设置这样的 <code>veth</code> 对。</p><p>一个是，创建接口对；另一个是为以太网设备分配地址并配置默认路由。</p><p>下面看看如何在 Pod 的命名空间中设置 <code>veth1</code> 接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ip netns exec cni-0f226515-e28b-df13-9f16-dd79456825ac ip addr add 10.244.4.40&#x2F;24 dev veth1</span><br><span class="line">$ ip netns exec cni-0f226515-e28b-df13-9f16-dd79456825ac ip link set veth1 up</span><br><span class="line">$ ip netns exec cni-0f226515-e28b-df13-9f16-dd79456825ac ip route add default via 10.244.4.40</span><br></pre></td></tr></table></figure><p>在节点上，让我们创建另一个 <code>veth2</code> 对：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ip addr add 169.254.132.141&#x2F;16 dev veth2</span><br><span class="line">$ ip link set veth2 up</span><br></pre></td></tr></table></figure><p>可以像前面一样检查现有的 <code>veth</code> 对。</p><p>在 Pod 的命名空间中，检索 <code>eth0</code> 接口的后缀。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip netns exec cni-0f226515-e28b-df13-9f16-dd79456825ac ip link show type veth</span><br><span class="line"></span><br><span class="line">3: eth0@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default</span><br><span class="line">    link&#x2F;ether 16:a4:f8:4f:56:77 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br></pre></td></tr></table></figure><p>在这种情况下，可以使用命令 <code>grep -A1 ^12</code> 查找（或滚动到目标所在处）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ip link show type veth</span><br><span class="line"></span><br><span class="line"># output truncated</span><br><span class="line">12: cali97e50e215bd@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default</span><br><span class="line">    link&#x2F;ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-0f226515-e28b-df13-9f16-dd79456825ac</span><br></pre></td></tr></table></figure><blockquote><p>也可以使用 <code>ip -n cni-0f226515-e28b-df13-9f16-dd79456825ac link show type veth</code>.命令</p></blockquote><p>注意 <code>3: eth0@if12和12: cali97e50e215bd@if3</code> 接口上的符号。</p><p>从 Pod 命名空间，该 <code>eth0</code> 接口连接到根命名空间的 12 号接口，因此是 <code>@if12</code>.</p><p>在 <code>veth</code> 对的另一端，根命名空间连接到 Pod 命名空间的 3 号接口。</p><p>接下来是连接 <code>veth</code> 对两端的桥接器。</p><h2><span id="pod-网络命名空间连接到以太网桥">Pod 网络命名空间连接到以太网桥</span></h2><p>网桥会汇聚位于根命名空间中的每一个虚拟接口。这个网桥允许虚拟 pair 之间的流量，也允许穿过公共根命名空间的流量。</p><p>补充一下相关原理。</p><p>以太网桥位于 <a href="https://en.wikipedia.org/wiki/OSI_model" target="_blank" rel="noopener">OSI 网络模型</a> 的第 2 层。</p><p>你可以将网桥视为接受来自不同命名空间和接口的连接的虚拟交换机。</p><p><a href="https://ops.tips/blog/using-network-namespaces-and-bridge-to-isolate-servers/" target="_blank" rel="noopener">以太网桥可以连接节点上的多个可用网络。</a></p><p>因此，可以使用网桥连接两个接口，即 Pod 命名空间的 <code>veth</code> 连接到同一节点上另一个 Pod 的 <code>veth</code>。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-11-20220919141543937-2022-09-19-lVtOgN.svg" alt></p><p>接下来，继续看网桥和 veth 对的用途。</p><h2><span id="跟踪在同一节点上-pod-到-pod-的流量">跟踪在同一节点上 Pod 到 Pod 的流量</span></h2><p>假设同一个节点上有两个 Pod，Pod-A 向 Pod-B 发送消息。</p><ol><li>由于访问目标不在同一个命名空间，Pod-A 将数据包发送到其默认接口 eth0。 这个接口与 veth 对的一端绑定，作为隧道。这样，数据包会被转发到节点上的根命名空间。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-12-20220919141632527-2022-09-19-NRPgWl.svg" alt></p><ol start="2"><li>以太网网桥作为一个虚拟交换机，需要目标 Pod-B 的 MAC 地址才能工作。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-13-2022-09-19-M7QRru.svg" alt></p><ol start="3"><li>ARP 协议会解决这个问题。当帧到达网桥时，会向所有连接的设备发送 ARP 广播。网桥广播询问持有 Pod-B 的 IP 地址</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-14-2022-09-19-Ibitey.svg" alt></p><ol start="4"><li>此时会收到一个带有 Pod-B IP 的 MAC 地址应答，这条消息会被存储在桥接 ARP 缓存(查找表)中。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-15-2022-09-19-y5ldCP.svg" alt></p><ol start="5"><li>IP 地址和 MAC 地址的映射关系存储之后，网桥就在表中查找，并将数据包转发到正确的端点。数据包到达根命名空间内 Pod-B 的 veth 之后，很快又到达 Pod-B 命名空间内的 eth0 接口。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-16-20220919141551029-2022-09-19-DusApt.svg" alt></p><p>至此，Pod-A 和 Pod-B 之间的通信就成功了。</p><h2><span id="跟踪不同节点上的-pod-到-pod-通信">跟踪不同节点上的 Pod 到 Pod 通信</span></h2><p>对于跨节点 Pod 之间的通信，会经过额外的通信跳跃。</p><ol><li>前几个步骤保持不变，直到数据包到达根命名空间并需要发送到 Pod-B。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-17-2022-09-19-xXNQzL.svg" alt></p><ol start="2"><li>当目的 IP 不在本地网络中时，报文被转发到节点的默认网关。节点的出口网关或默认网关，通常位于节点与网络相连的物理接口 eth0 上。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-18-2022-09-19-h2DI4L.svg" alt></p><p>此时 不会发生 ARP 解析，因为源 IP 和目标 IP 不在同一个网段中。</p><p>网段的检查是使用按位运算完成的。</p><p>当目的 IP 不在当前网络段时，数据包被转发到节点的默认网关。</p><h2><span id="按位运算的工作原理">按位运算的工作原理</span></h2><p>在确定数据包的转发位置时，源节点必须执行位运算</p><p><a href="https://en.wikipedia.org/wiki/Bitwise_operation#AND" target="_blank" rel="noopener">这也称为与操作。</a></p><p>复习一下，按位与运算的规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0 AND 0 &#x3D; 0</span><br><span class="line">0 AND 1 &#x3D; 0</span><br><span class="line">1 AND 0 &#x3D; 0</span><br><span class="line">1 AND 1 &#x3D; 1</span><br></pre></td></tr></table></figure><p>除了 1 与 1 以外的都是 false。</p><p>如果源节点的 IP 为 192.168.1.1，子网掩码为 /24，目标 IP 为 172.16.1.1/16，则按位与运算将得知它们位于不同的网段上。</p><p>这意味着目标 IP 与数据包的源不在同一个网络上，数据包将通过默认网关转发。</p><p>数学时间。</p><p>我们必须从二进制的 32 位地址开始进行 AND 操作。</p><p>先找出源 IP 网络和目标 IP 网段。</p><table><thead><tr><th style="text-align:left">Type</th><th style="text-align:left">Binary</th><th style="text-align:left">Converted</th></tr></thead><tbody><tr><td style="text-align:left">Src. IP Address</td><td style="text-align:left">11000000.10101000.00000001.00000001</td><td style="text-align:left">192.168.1.1</td></tr><tr><td style="text-align:left">Src. Subnet Mask</td><td style="text-align:left">11111111.11111111.11111111.00000000</td><td style="text-align:left">255.255.255.0(/24)</td></tr><tr><td style="text-align:left">Src. Network</td><td style="text-align:left">11000000.10101000.00000001.00000000</td><td style="text-align:left">192.168.1.0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left"></td></tr><tr><td style="text-align:left">Dst. IP Address</td><td style="text-align:left">10101100.00010000.00000001.00000001</td><td style="text-align:left">172.16.1.1</td></tr><tr><td style="text-align:left">Dst. Subnet Mask</td><td style="text-align:left">11111111.11111111.00000000.00000000</td><td style="text-align:left">255.255.0.0(/16)</td></tr><tr><td style="text-align:left">Dst. Network</td><td style="text-align:left">10101100.00010000.00000000.00000000</td><td style="text-align:left">172.16.0.0</td></tr></tbody></table><p>按位运算之后，需要将目标 IP 与数据包源节点的子网进行比较。</p><table><thead><tr><th style="text-align:left">Type</th><th style="text-align:left">Binary</th><th style="text-align:left">Converted</th></tr></thead><tbody><tr><td style="text-align:left">Dst. IP Address</td><td style="text-align:left">10101100.00010000.00000001.00000001</td><td style="text-align:left">172.16.1.1</td></tr><tr><td style="text-align:left">Src. Subnet Mask</td><td style="text-align:left">11111111.11111111.11111111.00000000</td><td style="text-align:left">255.255.255.0(/24)</td></tr><tr><td style="text-align:left">Network Result</td><td style="text-align:left">10101100.00010000.00000001.00000000</td><td style="text-align:left">172.16.1.0</td></tr></tbody></table><p>运算的结果是 172.16.1.0，不等于 192.168.1.0（源节点的网络）。说明源 IP 地址和目标 IP 地址不在同一个网络上。</p><p>如果目标 IP 是 192.168.1.2，即与发送 IP 在同一子网中，则 AND 操作将得到节点的本地网络。</p><table><thead><tr><th style="text-align:left">Type</th><th style="text-align:left">Binary</th><th style="text-align:left">Converted</th></tr></thead><tbody><tr><td style="text-align:left">Dst. IP Address</td><td style="text-align:left">11000000.10101000.00000001.00000010</td><td style="text-align:left">192.168.1.2</td></tr><tr><td style="text-align:left">Src. Subnet Mask</td><td style="text-align:left">11111111.11111111.11111111.00000000</td><td style="text-align:left">255.255.255.0(/24)</td></tr><tr><td style="text-align:left">Network</td><td style="text-align:left">11000000.10101000.00000001.00000000</td><td style="text-align:left">192.168.1.0</td></tr></tbody></table><p>进行逐位比较后，ARP 通过查找表查找默认网关的 MAC 地址。</p><p>如果有条目，将立即转发数据包。</p><p>否则，先进行广播以找到网关的 MAC 地址。</p><ol><li>现在，数据包路由到另一个节点的默认接口，我们称为 Node-B。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-19-2022-09-19-O2NAMf.svg" alt></p><ol start="2"><li>以相反的顺序。现在，数据包位于 Node-B 的根命名空间，并到达网桥，这里会进行 ARP 解析。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-20-2022-09-19-sncbQT.svg" alt></p><ol start="3"><li>路由系统将返回与 Pod-B 相连的接口的 MAC 地址。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-21-2022-09-19-l9iVbm.svg" alt></p><ol start="4"><li>网桥通过 Pod-B 的 <code>veth</code> 设备转发帧，并到达 Pod-B 的命名空间。</li></ol><p><img src="https://img.hi-linux.com/staticfile/k8s-network-22-20220919141556537-2022-09-19-8ckOcx.svg" alt></p><p>至此，你应该已经熟悉了 Pod 之间的流量是如何流转的。下面，让我们花点时间来看看 CNI 如何管理上诉内容。</p><h2><span id="容器网络接口-cni">容器网络接口 - CNI</span></h2><p><a href="https://github.com/containernetworking/cni/blob/main/SPEC.md" target="_blank" rel="noopener">容器网络接口（CNI）主要关注的是当前节点中的网络。</a></p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-23-2022-09-19-PBGpbi.svg" alt></p><p>可以将 CNI 看作为解决 Kubernetes 网络需求，而遵循的一组规则。</p><p>有这些 CNI 实现可供使用：</p><ul><li><a href="https://www.tigera.io/project-calico/" target="_blank" rel="noopener">Calico</a></li><li><a href="https://cilium.io/" target="_blank" rel="noopener">Cillium</a></li><li><a href="https://github.com/flannel-io/flannel" target="_blank" rel="noopener">Flannel</a></li><li><a href="https://www.weave.works/docs/net/latest/overview/" target="_blank" rel="noopener">Weave Net</a></li><li>其他网络插件</li></ul><p>他们都遵循相同的 CNI 标准。</p><p>如果没有 CNI，你需要人工完成如下操作：</p><ul><li>创建接口。</li><li>创建 veth 对。</li><li>设置网络命名空间。</li><li>设置静态路由。</li><li>配置以太网桥。</li><li>分配 IP 地址。</li><li>创建 NAT 规则。</li><li>还有其他大量事情。</li></ul><p>这还不包括，在删除或重启 Pod 时，需要进行类似的全部操作。</p><p>CNI 必须支持<a href="https://github.com/containernetworking/cni/blob/main/SPEC.md#cni-operations" target="_blank" rel="noopener">四种不同的操作</a>：</p><ul><li>ADD - 向网络添加一个容器。</li><li>DEL - 从网络中删除一个容器。</li><li>CHECK - 如果容器的网络出现问题，则返回错误。</li><li>VERSION - 显示插件的版本。</li></ul><p>我们一起看下，CNI 是如何工作的。</p><p>当 Pod 被分配到特定节点时，Kubelet 自身不会初始化网络。</p><p>相反，Kubelet 将这个任务交给 CNI。</p><p><em>但是，Kubelet 以 JSON 格式指定配置并发送至 CNI 插件。</em></p><p>你可以进入节点上的 <code>/etc/cni/net.d</code> 文件夹，使用以下命令查看当前的 CNI 配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ cat 10-calico.conflist</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;k8s-Pod-network&quot;,</span><br><span class="line">  &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span><br><span class="line">  &quot;plugins&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;type&quot;: &quot;calico&quot;,</span><br><span class="line">      &quot;datastore_type&quot;: &quot;kubernetes&quot;,</span><br><span class="line">      &quot;mtu&quot;: 0,</span><br><span class="line">      &quot;nodename_file_optional&quot;: false,</span><br><span class="line">      &quot;log_level&quot;: &quot;Info&quot;,</span><br><span class="line">      &quot;log_file_path&quot;: &quot;&#x2F;var&#x2F;log&#x2F;calico&#x2F;cni&#x2F;cni.log&quot;,</span><br><span class="line">      &quot;ipam&quot;: &#123; &quot;type&quot;: &quot;calico-ipam&quot;, &quot;assign_ipv4&quot; : &quot;true&quot;, &quot;assign_ipv6&quot; : &quot;false&quot;&#125;,</span><br><span class="line">      &quot;container_settings&quot;: &#123;</span><br><span class="line">          &quot;allow_ip_forwarding&quot;: false</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;policy&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;k8s&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">          &quot;k8s_api_root&quot;:&quot;https:&#x2F;&#x2F;10.96.0.1:443&quot;,</span><br><span class="line">          &quot;kubeconfig&quot;: &quot;&#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;calico-kubeconfig&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;type&quot;: &quot;bandwidth&quot;,</span><br><span class="line">      &quot;capabilities&quot;: &#123;&quot;bandwidth&quot;: true&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;&quot;type&quot;: &quot;portmap&quot;, &quot;snat&quot;: true, &quot;capabilities&quot;: &#123;&quot;portMappings&quot;: true&#125;&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个 CNI 插件都会使用不同类型的网络配置。</p><p>例如，Calico 使用基于 BGP 的三层网络连接 Pod</p><p>Cilium 从三层到七层使用的是基于 eBPF 的 overlay 网络</p><p>与 Calico 一样，Cilium 也支持通过配置网络策略来限制流量。</p><p>那么你应该使用哪一个呢？主要有两类 CNI。</p><p>在第一类中，使用基本网络设置（也称为平面网络），从集群的 IP 池为 Pod 分配 IP 地址的 CNI。</p><p>这种方式可能很快耗尽 IP 地址，而成为负担。</p><p>相反，另一类是使用 overlay 网络。</p><p>简单来说，overlay 网络是主（底层）网络之上的重建网络。</p><p>overlay 网络通过封装来自底层网络的数据包工作，这些数据包被发送到另一个节点上的 Pod。</p><p>overlay 网络的一种流行技术是 VXLAN，它可以在 L3 网络上建立 L2 域的隧道。</p><p>那么哪个更好呢？</p><p>没有单一的答案，这取决于你的需求。</p><p>你是否正在构建具有数万个节点的大型集群？</p><p>也许 overlay 网络更好。</p><p>你是否在意更简单的配置和审查网络流量，而不会愿意在复杂网络中丢失这种能力？</p><p>扁平网络更适合你。</p><p>现在我们讨论完了 CNI，接着让我们来看看 Pod 到服务的通信是如何连接的。</p><h2><span id="检查-pod-到-service-的流量">检查 Pod 到 Service 的流量</span></h2><p>由于 Pod 在 Kubernetes 中是动态的，分配给 Pod 的 IP 地址不是静态的。</p><p>Pod 的 IP 是短暂的，每次创建或删除 Pod 时都会发生变化。</p><p>Kubernetes 中的 Service 解决了这个问题，为连接一组 Pod 提供了可靠的机制。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-24-2022-09-19-8P1MI3.svg" alt></p><p>默认情况下，在 Kubernetes 中创建 Service 时，<a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies" target="_blank" rel="noopener">被分配一个虚拟 IP</a>。</p><p>在 Service 中，可以使用选择器将 Service 与目标 Pod 相关联。</p><p>当删除或添加一个 Pod 时会发生什么呢？</p><blockquote><p>Service 的虚拟 IP 保持静态不变。</p></blockquote><p>但流量可以再无需干预的情况下，到达新创建的 Pod。</p><p>换句话说，Kubernetes 中的 Service 类似于负载均衡器。</p><p>但它们是如何工作的？</p><h2><span id="使用-netfilter-和-iptables-拦截和重写流量">使用 Netfilter 和 Iptables 拦截和重写流量</span></h2><p>Kubernetes 中的 Service 是基于 Linux 内核中的两个组件构建的：</p><ol><li><a href="https://en.wikipedia.org/wiki/Netfilter" target="_blank" rel="noopener">网络过滤器</a></li><li><a href="https://en.wikipedia.org/wiki/Iptables" target="_blank" rel="noopener">iptables</a></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Netfilter 是一个可以配置数据包过滤、创建 NAT 、端口转发规则以及管理网络中流量的框架</span><br></pre></td></tr></table></figure><p>此外，它可以屏蔽和禁止未经同意的访问。</p><p>另一方面，iptables 是一个用户态程序，可以用来配置 Linux 内核防火墙的 IP 数据包过滤规则。</p><p>iptables 是作为不同的 Netfilter 模块实现的。</p><p>可以使用 iptables CLI 即时修改过滤规则，并将它们插入 netfilters 挂载点。</p><p>过滤器配置在不同的表中，其中包含用于处理网络流量数据包的链。</p><p>不同的协议使用不同的内核模块和程序。</p><blockquote><p>当提到 iptables 时，通常指的是 IPv4。对于 IPv6 ，终端工具是 ip6tables。</p></blockquote><p>iptables 有五种链，每一种链都直接映射到 Netfilter 的钩子上。</p><p>从 iptables 的角度来看，它们是：</p><ul><li><code>PRE_ROUTING</code></li><li><code>INPUT</code></li><li><code>FORWARD</code></li><li><code>OUTPUT</code></li><li><code>POST_ROUTING</code></li></ul><p>它们对应地映射到 Netfilter 钩子：</p><ul><li><code>NF_IP_PRE_ROUTING</code></li><li><code>NF_IP_LOCAL_IN</code></li><li><code>NF_IP_FORWARD</code></li><li><code>NF_IP_LOCAL_OUT</code></li><li><code>NF_IP_POST_ROUTING</code></li></ul><p>当一个数据包到达时，根据它所处的阶段，将 “触发” 一个 Netfilter 钩子。这个钩子会执行特定的 iptables 过滤规则。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-25-20220919141602921-2022-09-19-tsberQ.svg" alt></p><p>哎呀！看起来很复杂！</p><p>不过没什么好担心的。</p><p>这就是我们使用 Kubernetes 的原因，以上所有内容都是通过使用 Service 抽象出来的，并且一个简单的 YAML 定义可以自动设置这些规则。</p><p>如果你有兴趣查看 iptables 规则，可以连接到节点并运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables-save</span><br></pre></td></tr></table></figure><p>你还可以使用<a href="https://github.com/Nudin/iptable_vis" target="_blank" rel="noopener">这个工具来可视化</a>节点上的 iptables 链。</p><p>这是来自 GKE 节点上的可视化 iptables 链的示例图：</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-26-2022-09-19-GirLZG.svg" alt></p><p>注意，这里可能配置了几百条规则，想想一下自己动手怎么配置！</p><p>至此，我们已经了解了，相同节点上的 Pod 和不同节点上 Pod 之间是如何通信的。</p><p>在 Pod 与 Service 的通信中，链路的前半部分是一样的。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-27-2022-09-19-zcNnij.svg" alt></p><p>当请求从 Pod-A 走向 Pod-B 时，由于 Pod-B 在 Service 的 “后面”，在传输的过程中，会有一些不一样。</p><p>原始的请求，在 Pod-A 命名空间的 eth0 接口发出。</p><p>接着，请求通过 <code>veth</code>到达根名称空间的网桥。</p><p>一旦到达网桥，数据包就会立即通过默认网关转发。</p><p>与 Pod-to-Pod 部分一样，主机进行按位比较。由于服务的虚拟 IP 不是节点 CIDR 的一部分，因此数据包将立即通过默认网关转发。</p><p>如果默认网关的 MAC 地址尚未出现在查找表中，则会进行 ARP 解析找出默认网关的 MAC 地址。</p><p>现在神奇的事情发生了。</p><p>在数据包通过节点的路由之前，Netfilter 的 <code>NF_IP_PRE_ROUTING</code> 挂钩被触发，并执行 iptables 规则。这个规则会修改 Pod-A 数据包的目标 IP 地址 DNAT。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-28-2022-09-19-xAplcC.svg" alt></p><p>前面服务的虚拟 IP 地址被重写为 Pod-B 的 IP 地址。</p><p>接下来，数据包路由过程与 Pod 到 Pod 的通信一样。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-29-2022-09-19-7aqxsB.svg" alt></p><p>数据包重写后，通信是 Pod 到 Pod。</p><p>然而，在所有这些通信中，使用了一个第三方的功能。</p><p><a href="https://www.linuxtopia.org/Linux_Firewall_iptables/x1298.html" target="_blank" rel="noopener">此功能称为 conntrack</a> 或链路跟踪。</p><p>当 Pod-B 发回响应时，conntrack 会将数据包与链路相关联，并跟踪其来源。</p><p>NAT 严重依赖于 conntrack。</p><p>如果没有链路跟踪，将不知道将包含响应的数据包发回何处。</p><p>使用 conntrack 时，数据包的返回路径很容易设置为相同的源或目标 NAT 更改。</p><p>通信的另一部分与现在的链路相反。</p><p>Pod-B 接收并处理了请求，现在将数据发送回 Pod-A。</p><p>现在会发生什么呢？</p><h2><span id="检查来自服务的响应">检查来自服务的响应</span></h2><p>Pod-B 发送响应，将其 IP 地址设置为源地址，并将 Pod-A 的 IP 地址设置为目标地址。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-30-20220919141614676-2022-09-19-4nUE8X.svg" alt></p><p>当数据包到达 Pod-A 所在节点的接口时，会发生另一个 NAT。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-31-2022-09-19-PS5DQz.svg" alt></p><p>这时，conntrack 开始工作，修改源 IP 地址，iptables 规则执行 SNAT，并将 Pod-B 的源 IP 地址修改为原始服务的虚拟 IP。</p><p><img src="https://img.hi-linux.com/staticfile/k8s-network-32-2022-09-19-bQ6FAb.svg" alt></p><p>对于 Pod-A 来说，响应是来自于 Service 而不是 Pod-B。</p><p>其余的都是一样的。一旦 SNAT 完成，数据包就会到达根命名空间中的网桥，并通过 <code>veth</code> 对转发到 <code>Pod-A</code>。</p><h2><span id="总结一下">总结一下</span></h2><p>让我们一起回顾下本文相关要点</p><ul><li>容器如何在本地或 Pod 内通信。</li><li>在相同节点和不同节点上的 Pod 如何通信。</li><li>Pod-to-Service - Pod 如何将流量发送到 Kubernetes 中服务后面的 Pod 时。</li><li>什么是命名空间、veth、iptables、chains、conntrack、Netfilter、CNI、overlay 网络，以及 Kubernetes 网络工具箱中所需的一切。</li></ul><blockquote><p>本文转载自：「 陈少文的博客 」，原文：<a href="https://url.hi-linux.com/GQueR" target="_blank" rel="noopener">https://url.hi-linux.com/GQueR</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文翻译自 &lt;a href=&quot;https://learnk8s.io/kubernetes-network-packets%EF%BC%8C%E5%B9%B6%E6%B2%A1%E6%9C%89%E9%80%90%E5%AD%97%E7%BF%BB%E8%AF%91%EF%BC%8C%E5%B8%A6%E5%85%A5%E4%BA%86%E4%BA%9B%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3%E3%80%82&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://learnk8s.io/kubernetes-network-packets，并没有逐字翻译，带入了些自己的理解。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/k8s-network-1-2022-09-19-c7m4AB.svg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;阅读本文，你可以了解在 Kubernetes 内外，数据包是如何转发的，从原始的 Web 请求开始，到托管应用程序的容器。&lt;/p&gt;
&lt;h2 id=&quot;Kubernetes-网络要求&quot;&gt;Kubernetes 网络要求&lt;/h2&gt;
&lt;p&gt;在深入了解在 Kubernetes 集群中数据包如何流转的细节之前，先明确一下 Kubernetes 对网络的要求。&lt;/p&gt;
&lt;p&gt;Kubernetes 网络模型定义了一组基本规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在不使用网络地址转换 (NAT) 的情况下，集群中的 Pod 能够与任意其他 Pod 进行通信。&lt;/li&gt;
&lt;li&gt;在不使用网络地址转换 (NAT) 的情况下，在集群节点上运行的程序能与同一节点上的任何 Pod 进行通信。&lt;/li&gt;
&lt;li&gt;每个 Pod 都有自己的 IP 地址（IP-per-Pod），并且任意其他 Pod 都可以通过相同的这个地址访问它。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些要求，不会将具体实现限制在某种解决方案上。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 cri-docker 解决 Kubernetes 1.24 不支持 Docker 的问题</title>
    <link href="https://www.hi-linux.com/posts/20680.html"/>
    <id>https://www.hi-linux.com/posts/20680.html</id>
    <published>2022-09-13T01:00:00.000Z</published>
    <updated>2022-09-13T05:38:43.480Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>从 Kubernetes 1.24 开始，dockershim 已经从 kubelet 中移除，但因为历史问题 Docker 却不支持 Kubernetes 主推的 CRI（容器运行时接口）标准，所以 Docker 不能再作为 Kubernetes 的容器运行时了，即从Kubernetes v1.24 开始不再使用 Docker了。</p><p>但是如果想继续使用 Docker 的话，可以在 Kubelet 和 Docker 之间加上一个中间层 cri-docker。cri-docker 是一个支持 CRI 标准的 shim（垫片）。一头通过 CRI 跟 Kubelet 交互，另一头跟 Docker Api 交互，从而间接的实现了 Kubernetes 以 Docker 作为容器运行时。但是这种架构缺点也很明显，调用链更长，效率更低。</p><a id="more"></a><p>虽然本文演示了 cri-docker 的使用，但是更推荐使用 Containerd 作为 Kubernetes 的容器运行时。</p><h2><span id="实验环境">实验环境</span></h2><ul><li>两台机器，vms41 和 vms42</li><li>系统：centos7.4</li><li>vms41 为 master，vms42 是worker</li></ul><h3><span id="1-所有节点的基本设置">1. 所有节点的基本设置</span></h3><p>1.1 所有节点设置好 /etc/hosts ,使它们之间能互相解析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]# cat &#x2F;etc&#x2F;hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.26.41 vms41.rhce.cc vms41</span><br><span class="line">192.168.26.42 vms42.rhce.cc vms42</span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><p>1.2 在所有节点上关闭swap分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]# swapoff -a ; sed -i &#39;&#x2F;fstab&#x2F;d&#39; &#x2F;etc&#x2F;fstab </span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><p>1.3.在所有节点上更新yum源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]#  rm -rf &#x2F;etc&#x2F;yum.repos.d&#x2F;*  ; wget ftp:&#x2F;&#x2F;ftp.rhce.cc&#x2F;k8s&#x2F;* -P &#x2F;etc&#x2F;yum.repos.d&#x2F;</span><br><span class="line">[root@vms4X ~]# yum clean all</span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><p>1.4 在所有节点安装 Docker</p><ul><li>所有节点安装 docker-ce。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]#  yum install docker-ce -y</span><br></pre></td></tr></table></figure><ul><li>在所有节点启动 Docker 并设置开机自动启动</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]# systemctl enable docker --now</span><br></pre></td></tr></table></figure><ul><li>所有节点设置 Docker加速器</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">   &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;frz7i079.mirror.aliyuncs.com&quot;],</span><br><span class="line">    &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>所有节点重启 Docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]#  systemctl restart docker</span><br></pre></td></tr></table></figure><p>1.5 在所有节点安装 cri-docker</p><p>到下面的链接下载最新版 cri-docker</p><blockquote><p><a href="https://github.com/Mirantis/cri-dockerd/tags" target="_blank" rel="noopener">https://github.com/Mirantis/cri-dockerd/tags</a></p></blockquote><p>先在 vms41 上解压出 cri-docker，然后拷贝到 vms42 上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# tar zxf cri-dockerd-0.2.1.amd64.tgz </span><br><span class="line">[root@vms41 ~]# cp cri-dockerd&#x2F;cri-dockerd &#x2F;usr&#x2F;bin&#x2F;</span><br><span class="line">[root@vms41 ~]# scp &#x2F;usr&#x2F;bin&#x2F;cri-dockerd vms42:&#x2F;usr&#x2F;bin&#x2F;</span><br><span class="line">root@vms42&#39;s password: </span><br><span class="line">cri-dockerd         100%   50MB 117.2MB&#x2F;s   00:00    </span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><p>1.6 设置系统参数</p><p>在所有机器上执行下面的命令，目的是实现重启系统后，参数也能继续生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>让上述参数立即生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]# sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf</span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><p>1.7 创建 cri-docker 启动文件</p><ul><li>启动文件从下面链接找到:</li></ul><blockquote><p><a href="https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd" target="_blank" rel="noopener">https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd</a></p></blockquote><p>创建 cri-docker 启动文件:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# cat &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cri-docker.service</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;CRI Interface for Docker Application Container Engine</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;docs.mirantis.com</span><br><span class="line">After&#x3D;network-online.target firewalld.service docker.service</span><br><span class="line">Wants&#x3D;network-online.target</span><br><span class="line">Requires&#x3D;cri-docker.socket</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;notify</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;cri-dockerd --network-plugin&#x3D;cni --pod-infra-container-image&#x3D;registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.7</span><br><span class="line">ExecReload&#x3D;&#x2F;bin&#x2F;kill -s HUP $MAINPID</span><br><span class="line">TimeoutSec&#x3D;0</span><br><span class="line">RestartSec&#x3D;2</span><br><span class="line">Restart&#x3D;always</span><br><span class="line"></span><br><span class="line">StartLimitBurst&#x3D;3</span><br><span class="line"></span><br><span class="line">StartLimitInterval&#x3D;60s</span><br><span class="line"></span><br><span class="line">LimitNOFILE&#x3D;infinity</span><br><span class="line">LimitNPROC&#x3D;infinity</span><br><span class="line">LimitCORE&#x3D;infinity</span><br><span class="line"></span><br><span class="line">TasksMax&#x3D;infinity</span><br><span class="line">Delegate&#x3D;yes</span><br><span class="line">KillMode&#x3D;process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><p>这里 <code>/usr/bin/cri-dockerd</code> 一定要加上参数 <code>-–pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7</code>，用来指定所用的 pause 镜像是哪个，否则默认拉取 <a href="http://k8s.gcr.io/pause:3.6%EF%BC%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5%E3%80%82" target="_blank" rel="noopener">k8s.gcr.io/pause:3.6，会导致安装失败。</a></p><ul><li>创建启动文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# cat &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cri-docker.socket</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;CRI Docker Socket for the API</span><br><span class="line">PartOf&#x3D;cri-docker.service</span><br><span class="line"></span><br><span class="line">[Socket]</span><br><span class="line">ListenStream&#x3D;%t&#x2F;cri-dockerd.sock</span><br><span class="line">SocketMode&#x3D;0660</span><br><span class="line">SocketUser&#x3D;root</span><br><span class="line">SocketGroup&#x3D;docker</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;sockets.target</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><p>1.8 把启动脚本拷贝到 vms42 上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# scp &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cri-docker.socket &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cri-docker.service vms42:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;</span><br><span class="line">root@vms42&#39;s password: </span><br><span class="line">cri-docker.socket          100%  204   103.1KB&#x2F;s   00:00    </span><br><span class="line">cri-docker.service         100%  605   822.7KB&#x2F;s   00:00    </span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><p>启动 cri-docker 并设置开机自动启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# systemctl daemon-reload ; systemctl enable cri-docker --now</span><br><span class="line">Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;cri-docker.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cri-docker.service.</span><br><span class="line">[root@vms41 ~]#</span><br><span class="line"></span><br><span class="line">[root@vms4X ~]# systemctl is-active cri-docker</span><br><span class="line">active</span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><h2><span id="2-安装-kubernetes">2. 安装 Kubernetes</span></h2><p>2.1 查看当前源里有哪些版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]#yum list --showduplicates kubeadm --disableexcludes&#x3D;kubernetes</span><br></pre></td></tr></table></figure><p>在本试验时最新的版本是 v1.24.1，所以本次就安装 v1.24.1版本的。</p><p>2.2 所有节点上安装软件包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]#yum install -y kubelet-1.24.1-0 kubeadm-1.24.1-0 kubectl-1.24.1-0  --disableexcludes&#x3D;kubernetes</span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><p>2.3 所有节点上启动 Kubelet 并设置开机自动启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@vms4X ~]# systemctl enable kubelet --now</span><br><span class="line">Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;kubelet.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kubelet.service.</span><br><span class="line">[root@vms4X ~]#</span><br></pre></td></tr></table></figure><p>此时 Kubelet 状态是 activating 的，不是 active 的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# systemctl is-active kubelet</span><br><span class="line">activating</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><h2><span id="3初始化-kubernetes">3.初始化 Kubernetes</span></h2><p>3.1 在 master（vms41）上初始化集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# kubeadm init --image-repository registry.aliyuncs.com&#x2F;google_containers --kubernetes-version&#x3D;v1.24.1 --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --cri-socket &#x2F;var&#x2F;run&#x2F;cri-dockerd.sock</span><br></pre></td></tr></table></figure><blockquote><p>注意，这里需要添加选项 -–cri-socket /var/run/cri-dockerd.sock</p></blockquote><p><img src="https://img.hi-linux.com/staticfile/4969830fe751d18275b23b2d92929617-2022-09-06-TlqU5p.png" alt></p><p>按提示创建 kubeconfig 文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# mkdir -p $HOME&#x2F;.kube</span><br><span class="line">[root@vms41 ~]# sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">[root@vms41 ~]# sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><p>3.2 把 worker 加入集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vms42 ~]# kubeadm join 192.168.26.41:6443 --token l05cgf.kj5dvy5heki3jixt --discovery-token-ca-cert-hash sha256:07c1765ff4ac6eb2e54ed69fa57ca1afc728e825a6d4a11a83c96ff60ea545cd  --cri-socket &#x2F;var&#x2F;run&#x2F;cri-dockerd.sock</span><br><span class="line">[root@vms42 ~]#</span><br></pre></td></tr></table></figure><p>注意，这里也要加上选项 <code>-–cri-socket /var/run/cri-dockerd.sock</code></p><p>切换到 master，查看节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# kubectl get nodes</span><br><span class="line">NAME            STATUS     ROLES           AGE     VERSION</span><br><span class="line">vms41.rhce.cc   NotReady   control-plane   4m12s   v1.24.1</span><br><span class="line">vms42.rhce.cc   NotReady   &lt;none&gt;          13s     v1.24.1</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><h2><span id="4安装-calico">4.安装 Calico</span></h2><p>4.1 下载最新版的 Calico 部署文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vms71 ~]# wget https:&#x2F;&#x2F;docs.projectcalico.org&#x2F;manifests&#x2F;calico.yaml</span><br></pre></td></tr></table></figure><p>4.2 修改相应配置</p><p>修改 calico.yaml 找到 CALICO_IPV4POOL_CIDR 按下面修改。</p><p><img src="https://img.hi-linux.com/staticfile/839e789e218a3b6255911275b52ecc15-2022-09-06-j8alQ3.png" alt></p><p>改成</p><p><img src="https://img.hi-linux.com/staticfile/5b4040098c6ae58fa203d0fcc13ac56e-2022-09-06-il9eb3.png" alt></p><p>4.3 安装 Calico</p><p>在 vms41（master）上安装 calico，不需要在 vms42 上做什么。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# kubectl apply -f calico.yaml</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><h2><span id="5验证">5.验证</span></h2><p>5.1 在 vms41 上再次查看节点状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@vms41 ~]# kubectl get nodes</span><br><span class="line">NAME            STATUS   ROLES           AGE     VERSION</span><br><span class="line">vms41.rhce.cc   Ready    control-plane   11m     v1.24.1</span><br><span class="line">vms42.rhce.cc   Ready    &lt;none&gt;          7m20s   v1.24.1</span><br><span class="line">[root@vms41 ~]# </span><br><span class="line">[root@vms41 ~]# kubectl get nodes -o wide</span><br><span class="line">NAME            STATUS   ROLES           AGE     VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION          CONTAINER-RUNTIME</span><br><span class="line">vms41.rhce.cc   Ready    control-plane   11m     v1.24.1   192.168.26.41   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-693.el7.x86_64   docker:&#x2F;&#x2F;20.10.17</span><br><span class="line">vms42.rhce.cc   Ready    &lt;none&gt;          7m23s   v1.24.1   192.168.26.42   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-693.el7.x86_64   docker:&#x2F;&#x2F;20.10.17</span><br><span class="line">[root@vms41 ~]#</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 老段工作室 」，原文：<a href="https://url.hi-linux.com/moiru%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.hi-linux.com/moiru，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从 Kubernetes 1.24 开始，dockershim 已经从 kubelet 中移除，但因为历史问题 Docker 却不支持 Kubernetes 主推的 CRI（容器运行时接口）标准，所以 Docker 不能再作为 Kubernetes 的容器运行时了，即从Kubernetes v1.24 开始不再使用 Docker了。&lt;/p&gt;
&lt;p&gt;但是如果想继续使用 Docker 的话，可以在 Kubelet 和 Docker 之间加上一个中间层 cri-docker。cri-docker 是一个支持 CRI 标准的 shim（垫片）。一头通过 CRI 跟 Kubelet 交互，另一头跟 Docker Api 交互，从而间接的实现了 Kubernetes 以 Docker 作为容器运行时。但是这种架构缺点也很明显，调用链更长，效率更低。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何在 Linux 下限制端口仅对指定 IP 开放访问</title>
    <link href="https://www.hi-linux.com/posts/30329.html"/>
    <id>https://www.hi-linux.com/posts/30329.html</id>
    <published>2022-08-27T01:00:00.000Z</published>
    <updated>2022-08-27T07:58:58.005Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="1-主机服务端口">1. 主机服务端口</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -I INPUT -p tcp --dport 80 -j DROP</span><br><span class="line">$ iptables -I INPUT -p tcp -s 1.2.3.4 --dport 80 -j ACCEPT</span><br></pre></td></tr></table></figure><p>这里仅允许 <code>1.2.3.4</code> 访问本地主机的 80 端口。</p><a id="more"></a><h2><span id="2-docker-服务端口">2. Docker 服务端口</span></h2><p>对于类似 <code>docker run -d -p 80:80 shaowenchen/demo-whoami</code> 运行的服务，上面的方法无效，需要在 DOCKER-USER 链中添加规则。</p><p>Docker 会将 iptables 规则添加到 DOCKER 链中，如果需要在 Docker 之前添加规则需要添加到 DOCKER-USER 链中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -I DOCKER-USER -i ens192 ! -s 1.2.3.4 -p tcp --dport 80 -j DROP</span><br></pre></td></tr></table></figure><p>ens192 是本地的网卡，这里仅允许 <code>1.2.3.4</code> 访问本地主机的 80 端口。</p><h2><span id="3-清理环境">3. 清理环境</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y iptables-services</span><br><span class="line">$ systemctl restart iptables.service</span><br></pre></td></tr></table></figure><p>如果需要在主机重启之后 iptables 设置，依然有效，需要安装 <code>iptables-services</code> 并保存</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y iptables-services</span><br><span class="line">$ service iptables save</span><br></pre></td></tr></table></figure><h2><span id="4-参考">4. 参考</span></h2><ul><li><a href="https://docs.docker.com/network/iptables/" target="_blank" rel="noopener">https://docs.docker.com/network/iptables/</a></li></ul><blockquote><p>本文转载自：「 陈少文的博客 」，原文：<a href="https://url.hi-linux.com/SrAYO" target="_blank" rel="noopener">https://url.hi-linux.com/SrAYO</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-主机服务端口&quot;&gt;1. 主机服务端口&lt;/h2&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ iptables -I INPUT -p tcp --dport 80 -j DROP&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ iptables -I INPUT -p tcp -s 1.2.3.4 --dport 80 -j ACCEPT&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这里仅允许 &lt;code&gt;1.2.3.4&lt;/code&gt; 访问本地主机的 80 端口。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>五种常见 Linux 系统安装包管理工具中文使用指南</title>
    <link href="https://www.hi-linux.com/posts/24537.html"/>
    <id>https://www.hi-linux.com/posts/24537.html</id>
    <published>2022-08-10T01:00:00.000Z</published>
    <updated>2022-08-10T01:16:12.360Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>介绍常见 Linux 操作系统的安装包管理工具，主要介绍其使用命令！</strong></p></blockquote><p>包管理系统除了安装软件外，它还提供了工具来更新已经安装的包。包存储库有助于确保你的系统中使用的代码是经过审查的，并且软件的安装版本已经得到了开发人员和包维护人员的认可。</p><a id="more"></a><h2><span id="1-dpkg">1. dpkg</span></h2><blockquote><p><strong>Ubuntu、Debian</strong></p></blockquote><p><code>dpkg</code> 命令是 <code>Debian Linux</code> 系统用来安装、创建和管理软件包的实用工具。</p><ul><li><strong>命令行使用</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dpkg(选项)(参数)</span></span><br><span class="line">$ dpkg --<span class="built_in">help</span></span><br><span class="line">Usage: dpkg [&lt;option&gt; ...] &lt;<span class="built_in">command</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-i：安装软件包</span><br><span class="line">-r：删除软件包</span><br><span class="line">-P：删除软件包的同时删除其配置文件</span><br><span class="line">-L：显示于软件包关联的文件</span><br><span class="line">-l：显示已安装软件包列表</span><br><span class="line">--unpack：解开软件包</span><br><span class="line">-c：显示软件包内文件列表</span><br><span class="line">--confiugre：配置软件包</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">Deb软件包：指定要操作的.deb软件包</span><br></pre></td></tr></table></figure><ul><li><strong>示例演示说明</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装包</span></span><br><span class="line">$ dpkg -i package.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除包</span></span><br><span class="line">$ dpkg -r package</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除包（包括配置文件）</span></span><br><span class="line">$ dpkg -P package</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出与该包关联的文件</span></span><br><span class="line">$ dpkg -L package</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示该包的版本</span></span><br><span class="line">$ dpkg -l package</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解开deb包的内容</span></span><br><span class="line">$ dpkg --unpack package.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搜索所属的包内容</span></span><br><span class="line">$ dpkg -S keyword</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出当前已安装的包</span></span><br><span class="line">$ dpkg -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出deb包的内容</span></span><br><span class="line">$ dpkg -c package.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置包</span></span><br><span class="line">$ dpkg --configure package</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出已安装软件包</span></span><br><span class="line">$ sudo dpkg-query -l</span><br><span class="line">$ sudo dpkg-query -l | less</span><br><span class="line">$ sudo dpkg-query -l | grep tmux</span><br></pre></td></tr></table></figure><h2><span id="2-apt">2. apt</span></h2><blockquote><p><strong>Ubuntu、Debian</strong></p></blockquote><p><code>apt-get</code> 命令是 <code>Debian Linux</code> 发行版中的 APT 软件包管理工具。所有基于 <code>Debian</code> 的发行都使用这个包管理系统。<code>deb</code> 包可以把一个应用的文件包在一起，大体就如同 <code>Windows</code> 上的安装文件。</p><ul><li><strong>命令行使用</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apt-get(选项)(参数)</span></span><br><span class="line">$ apt --<span class="built_in">help</span></span><br><span class="line">Usage: apt [options] <span class="built_in">command</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-c：指定配置文件</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">管理指令：对APT软件包的管理操作</span><br><span class="line">软件包：指定要操纵的软件包</span><br></pre></td></tr></table></figure><ul><li><strong>示例演示说明</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新所有已安装的软件包</span></span><br><span class="line">$ apt-get upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将系统升级到新版本</span></span><br><span class="line">$ apt-get dist-upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新</span></span><br><span class="line">$ apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装一个新软件包</span></span><br><span class="line">$ apt-get install packagename</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载一个已安装的软件包（保留配置文件）</span></span><br><span class="line">$ apt-get remove packagename</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载一个已安装的软件包（删除配置文件）</span></span><br><span class="line">$ apt-get –purge remove packagename</span><br><span class="line"></span><br><span class="line"><span class="comment"># 来删除你已经删掉的软件</span></span><br><span class="line">$ apt-get autoclean apt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会把安装的软件的备份也删除</span></span><br><span class="line">$ apt-get clean</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出已安装软件包</span></span><br><span class="line">$ sudo apt list --installed</span><br><span class="line">$ sudo apt list --installed | less</span><br><span class="line">$ sudo apt list --installed | grep tmux</span><br></pre></td></tr></table></figure><h2><span id="3-rpm">3. rpm</span></h2><blockquote><p><strong>RHEL、CentOS</strong></p></blockquote><p><code>rpm</code> 命令是 <code>RPM</code> 软件包的管理工具。<code>rpm</code> 原本是 <code>Red Hat Linux</code> 发行版专门用来管理 <code>Linux</code> 各项套件的程序，由于它遵循 <code>GPL</code> 规则且功能强大方便，因而广受欢迎。逐渐受到其他发行版的采用。<code>RPM</code> 套件管理方式的出现，让 <code>Linux</code> 易于安装，升级，间接提升了 <code>Linux</code> 的适用度。</p><ul><li><strong>命令行使用</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm(选项)(参数)</span></span><br><span class="line">$ rpm --<span class="built_in">help</span></span><br><span class="line">Usage: rpm [OPTION...]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-a：查询所有套件</span><br><span class="line">-c：只列出组态配置文件，本参数需配合<span class="string">"-l"</span>参数使用</span><br><span class="line">-d：只列出文本文件，本参数需配合<span class="string">"-l"</span>参数使用</span><br><span class="line">-e&lt;套件档&gt;或--erase&lt;套件档&gt;：删除指定的套件</span><br><span class="line">-f&lt;文件&gt;+：查询拥有指定文件的套件</span><br><span class="line">-h或--<span class="built_in">hash</span>：套件安装时列出标记</span><br><span class="line">-i：显示套件的相关信息</span><br><span class="line">-i&lt;套件档&gt;或--install&lt;套件档&gt;：安装指定的套件档</span><br><span class="line">-l：显示套件的文件列表</span><br><span class="line">-p&lt;套件档&gt;+：查询指定的RPM套件档</span><br><span class="line">-q：使用询问模式，当遇到任何问题时，rpm指令会先询问用户</span><br><span class="line">-R：显示套件的关联性信息</span><br><span class="line">-s：显示文件状态，本参数需配合<span class="string">"-l"</span>参数使用</span><br><span class="line">-U&lt;套件档&gt;或--upgrade&lt;套件档&gt;：升级指定的套件档</span><br><span class="line">-v：显示指令执行过程</span><br><span class="line">-vv：详细显示指令执行过程，便于排错</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">软件包：指定要操纵的rpm软件包</span><br></pre></td></tr></table></figure><ul><li><strong>示例演示说明</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">$ rpm -ivh your-package.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制安装</span></span><br><span class="line">$ rpm --force -ivh your-package.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载</span></span><br><span class="line">$ rpm -e proftpd-1.2.8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有安装过的包</span></span><br><span class="line">$ rpm -qa</span><br><span class="line">$ rpm -qa | grep sql</span><br><span class="line"></span><br><span class="line"><span class="comment"># rpm包中的文件安装到那里</span></span><br><span class="line">$ rpm -ql ***.rpm</span><br><span class="line"><span class="comment"># 一个没有安装过的软件包</span></span><br><span class="line">$ rpm -qlp ***.rpm</span><br><span class="line"><span class="comment"># 一个已经安装过的软件包</span></span><br><span class="line">$ rpm -ql ***.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 某个程序是哪个软件包安装</span></span><br><span class="line">$ rpm -qf `<span class="built_in">which</span> 程序名`   <span class="comment"># 返回软件包的全名</span></span><br><span class="line">$ rpm -qif `<span class="built_in">which</span> 程序名`  <span class="comment"># 返回软件包的有关信息</span></span><br><span class="line">$ rpm -qlf `<span class="built_in">which</span> 程序名`  <span class="comment"># 返回软件包的文件列表</span></span><br></pre></td></tr></table></figure><h2><span id="4-yum">4. yum</span></h2><blockquote><p><strong>CentOS6、CentOS7</strong></p></blockquote><p><code>yum</code> 命令是在 <code>Fedora</code> 和 <code>RedHat</code> 以及 <code>SUSE</code> 中基于 <code>rpm</code> 的软件包管理器，它可以使系统管理人员交互和自动化地更新与管理 <code>RPM</code> 软件包，能够从指定的服务器自动下载 <code>RPM</code> 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。</p><ul><li><strong>命令行使用</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum(选项)(参数)</span></span><br><span class="line">$ yum --<span class="built_in">help</span></span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Usage: yum [options] COMMAND</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-h：显示帮助信息；</span><br><span class="line">-y：对所有的提问都回答“yes”；</span><br><span class="line">-c：指定配置文件；</span><br><span class="line">-q：安静模式；</span><br><span class="line">-v：详细模式；</span><br><span class="line">-d：设置调试等级（0-10）；</span><br><span class="line">-e：设置错误等级（0-10）；</span><br><span class="line">-R：设置yum处理一个命令的最大等待时间；</span><br><span class="line">-C：完全从缓存中运行，而不去下载或者更新任何头文件。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">install：安装rpm软件包；</span><br><span class="line">update：更新rpm软件包；</span><br><span class="line">check-update：检查是否有可用的更新rpm软件包；</span><br><span class="line">remove：删除指定的rpm软件包；</span><br><span class="line">list：显示软件包的信息；</span><br><span class="line">search：检查软件包的信息；</span><br><span class="line">info：显示指定的rpm软件包的描述信息和概要信息；</span><br><span class="line">clean：清理yum过期的缓存；</span><br><span class="line">shell：进入yum的shell提示符；</span><br><span class="line">resolvedep：显示rpm软件包的依赖关系；</span><br><span class="line">localinstall：安装本地的rpm软件包；</span><br><span class="line">localupdate：显示本地rpm软件包进行更新；</span><br><span class="line">deplist：显示rpm软件包的所有依赖关系。</span><br></pre></td></tr></table></figure><ul><li><strong>示例演示说明</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">$ yum install             <span class="comment"># 全部安装</span></span><br><span class="line">$ yum install package1    <span class="comment"># 安装指定的安装包package1</span></span><br><span class="line">$ yum groupinsall group1  <span class="comment"># 安装程序组group1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新和升级</span></span><br><span class="line">$ yum update              <span class="comment"># 全部更新</span></span><br><span class="line">$ yum update package1     <span class="comment"># 更新指定程序包package1</span></span><br><span class="line">$ yum check-update        <span class="comment"># 检查可更新的程序</span></span><br><span class="line">$ yum upgrade package1    <span class="comment"># 升级指定程序包package1</span></span><br><span class="line">$ yum groupupdate group1  <span class="comment"># 升级程序组group1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找显示</span></span><br><span class="line">$ yum list installed | grep mysql</span><br><span class="line">$ yum list installed mysql*</span><br><span class="line">$ yum info package1     <span class="comment"># 显示安装包信息package1</span></span><br><span class="line">$ yum list              <span class="comment"># 显示所有已经安装和可以安装的程序包</span></span><br><span class="line">$ yum list package1     <span class="comment"># 显示指定程序包安装情况package1</span></span><br><span class="line">$ yum groupinfo group1  <span class="comment"># 显示程序组group1信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除程序</span></span><br><span class="line">$ yum remove/erase package1  <span class="comment"># 删除程序包package1</span></span><br><span class="line">$ yum groupremove group1     <span class="comment"># 删除程序组group1</span></span><br><span class="line">$ yum deplist package1       <span class="comment"># 查看程序package1依赖情况</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清除缓存</span></span><br><span class="line">$ yum clean packages    <span class="comment"># 清除缓存目录下的软件包</span></span><br><span class="line">$ yum clean headers     <span class="comment"># 清除缓存目录下的 headers</span></span><br><span class="line">$ yum clean oldheaders  <span class="comment"># 清除缓存目录下旧的 headers</span></span><br></pre></td></tr></table></figure><h2><span id="5-dnf">5. dnf</span></h2><blockquote><p><strong>RHEL8、CentOS8</strong></p></blockquote><p><code>DNF</code> 使用 <code>libsolv</code> 进行依赖解析，由 <code>SUSE</code> 开发和维护，旨在提高性能。<code>Yum</code> 主要是用 <code>Python</code> 编写的，它有自己的应对依赖解析的方法。它的 <code>API</code> 没有完整的文档，它的扩展系统只允许 <code>Python</code> 插件。<code>Yum</code> 是 <code>RPM</code> 的前端工具，它管理依赖关系和资源库，然后使用 <code>RPM</code> 来安装、下载和删除包。</p><p>由于 <code>Yum</code> 中许多长期存在的问题仍未得到解决，因此 <code>Yum</code> 包管理器已被 <code>DNF</code> 包管理器取代。这些问题包括性能差、内存占用过多、依赖解析速度变慢等。两个管理包工具的更多区别可以查看，<a href="https://www.2daygeek.com/comparison-difference-between-dnf-vs-yum/" target="_blank" rel="noopener">What is the difference between DNF and YUM?</a> 进行阅读。</p><ul><li><strong>安装 DNF 包管理器</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 依赖</span></span><br><span class="line">$ yum install -y epel-release</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">$ yum install -y dnf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查</span></span><br><span class="line">$ dnf –version</span><br></pre></td></tr></table></figure><ul><li><strong>常用命令介绍</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装软件包</span></span><br><span class="line">$ dnf install nano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级软件包</span></span><br><span class="line">$ dnf update systemd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级所有系统软件包</span></span><br><span class="line">$ dnf update</span><br><span class="line">$ dnf upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查系统软件包的更新</span></span><br><span class="line">$ dnf check-update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除软件包</span></span><br><span class="line">$ dnf remove nano</span><br><span class="line">$ dnf erase nano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除无用孤立的软件包</span></span><br><span class="line">$ dnf autoremove</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除缓存的无用软件包</span></span><br><span class="line">$ dnf clean all</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统中可用的DNF软件库</span></span><br><span class="line">$ dnf repolist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统中可用和不可用的所有的DNF软件库</span></span><br><span class="line">$ dnf repolist all</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有RPM包</span></span><br><span class="line">$ dnf list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有安装了的RPM包</span></span><br><span class="line">$ dnf list installed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有可供安装的RPM包</span></span><br><span class="line">$ dnf list available</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搜索软件库中的RPM包</span></span><br><span class="line">$ dnf search nano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找某一文件的提供者</span></span><br><span class="line">$ dnf provides /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看软件包详情</span></span><br><span class="line">$ dnf info nano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有的软件包组</span></span><br><span class="line">$ dnf grouplist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装一个软件包组</span></span><br><span class="line">$ dnf groupinstall <span class="string">'Educational Software'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级一个软件包组中的软件包</span></span><br><span class="line">$ dnf groupupdate <span class="string">'Educational Software'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除一个软件包组</span></span><br><span class="line">$ dnf groupremove <span class="string">'Educational Software'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新安装特定软件包</span></span><br><span class="line">$ dnf reinstall nano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回滚某个特定软件的版本</span></span><br><span class="line">$ dnf downgrade acpid</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看DNF命令的执行历史</span></span><br><span class="line">$ dnf <span class="built_in">history</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有的DNF命令及其用途</span></span><br><span class="line">$ dnf <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取有关某条命令的使用帮助</span></span><br><span class="line">$ dnf <span class="built_in">help</span> clean</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://url.hi-linux.com/No9Xd" target="_blank" rel="noopener">https://url.hi-linux.com/No9Xd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;介绍常见 Linux 操作系统的安装包管理工具，主要介绍其使用命令！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;包管理系统除了安装软件外，它还提供了工具来更新已经安装的包。包存储库有助于确保你的系统中使用的代码是经过审查的，并且软件的安装版本已经得到了开发人员和包维护人员的认可。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>理解 Docker 容器退出码</title>
    <link href="https://www.hi-linux.com/posts/52091.html"/>
    <id>https://www.hi-linux.com/posts/52091.html</id>
    <published>2022-07-29T01:00:00.000Z</published>
    <updated>2022-07-29T01:24:38.372Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>为什么我的容器没有运行？</p><p>回答这个问题需要知道 Docker 容器为什么退出，退出码会提示容器停止运行的情况。本文列出了最常见的退出码，来回答两个重要问题：</p><ul><li>这些退出码是什么意思？</li><li>导致该退出码的动作是什么？</li></ul><p>exit code： 代表一个进程的返回码，通过系统调用 exit_group 来触发。在 POSIX 中，0 代表正常的返回码，而 1-255 代表异常返回码，不过一般错误码都是 1。这里有一张附表 <a href="http://tldp.org/LDP/abs/html/exitcodes.html" target="_blank" rel="noopener">Appendix E. Exit Codes With Special Meanings</a></p><a id="more"></a><h2><span id="如何查看退出码">如何查看退出码</span></h2><p>方法一：查看 pod 中的容器退出码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod xxx</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/3b8439b7-8a32-4e2f-9186-18773a333794-20220728150920792-2022-07-28-MAt1eU.jpg" alt></p><p>方法二：用 Docker 查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps --filter <span class="string">"status=exited"</span></span><br><span class="line">$ docker inspect &lt;container-id&gt; --format=<span class="string">'&#123;&#123;.State.ExitCode&#125;&#125;'</span></span><br></pre></td></tr></table></figure><p>方法三：手动输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker container run alpine sh -c <span class="string">"exit 1"</span></span><br><span class="line">$ docker container ls -a</span><br><span class="line"></span><br><span class="line">CONTAINER ID   IMAGE    COMMAND            CREATED              STATUS                       </span><br><span class="line">61c688005b3a   alpine   <span class="string">"sh -c 'exit 1'"</span>   About a minute ago   Exited (1) 3 seconds ago</span><br></pre></td></tr></table></figure><h2><span id="常见退出码">常见退出码</span></h2><h3><span id="exit-code-0">Exit Code 0</span></h3><ul><li>退出代码0表示特定容器没有附加前台进程。</li><li>该退出代码是所有其他后续退出代码的例外。</li><li>这不一定意味着发生了不好的事情。如果开发人员想要在容器完成其工作后自动停止其容器，则使用此退出代码。</li></ul><p>如果你执行 <code>docker run hello-world</code>, 你会得到“Hello from docker!”，但查看容器的时候<code>docker ps -a | grep hello-world</code>,会发现状态码为 0</p><p><img src="https://img.hi-linux.com/staticfile/99f9c7ed-fa66-4946-aaaf-d29bb0585bf8-2022-07-28-oFgCki.jpg" alt></p><h3><span id="exit-code-1">Exit Code 1</span></h3><ul><li>程序错误，或者 Dockerfile 中引用不存在的文件，如 entrypoint 中引用了错误的包</li><li>程序错误可以很简单，例如 “除以0”，也可以很复杂，比如空引用或者其他程序 crash</li></ul><h3><span id="exit-code-137">Exit Code 137</span></h3><ul><li>表明容器收到了 SIGKILL 信号，进程被杀掉，对应 kill -9</li><li>引发 SIGKILL 的是 Docker Kill。这可以由用户或由 Docker 守护程序来发起，手动执行：docker kill</li><li>137 比较常见，如果 pod 中的 limit 资源设置较小，会运行内存不足导致 OOMKilled，此时 state 中的 “OOMKilled” 值为 true，你可以在系统的 dmesg 中看到 oom 日志</li></ul><h3><span id="exit-code-139">Exit Code 139</span></h3><ul><li>表明容器收到了 SIGSEGV 信号，无效的内存引用，对应 kill -11</li><li>一般是代码有问题，或者 docker 的基础镜像有问题</li></ul><h3><span id="exit-code-143">Exit Code 143</span></h3><ul><li>表明容器收到了 SIGTERM 信号，终端关闭，对应 kill -15</li><li>一般对应 docker stop  命令</li><li>有时 docker stop 也会导致 Exit Code 137。发生在与代码无法处理 SIGTERM 的情况下，docker 进程等待十秒钟然后发出 SIGKILL 强制退出。</li></ul><h3><span id="不常用的一些-exit-code">不常用的一些 Exit Code</span></h3><ul><li>Exit Code 126: 权限问题或命令不可执行</li><li>Exit Code 127: Shell 脚本中可能出现错字且字符无法识别的情况</li><li>Exit Code 1 或 255：因为很多程序员写异常退出时习惯用 exit(1) 或 exit(-1)，-1 会根据转换规则转成 255。这个一般是自定义 code，要看具体逻辑。</li></ul><h3><span id="退出状态码的区间">退出状态码的区间</span></h3><ul><li>必须在 0-255 之间，0 表示正常退出</li><li>外界将程序中断退出，状态码在 129-255</li><li>程序自身异常退出，状态码一般在 1-128</li><li>假如写代码指定的退出状态码时不在 0-255 之间，例如: exit(-1)，这时会自动做一个转换，最终呈现的状态码还是会在 0-255 之间。我们把状态码记为 code，当指定的退出时状态码为负数，那么转换公式如下：<code>256 – (|code| % 256)</code></li></ul><h2><span id="参考">参考</span></h2><ul><li><a href="http://tldp.org/LDP/abs/html/exitcodes.html" target="_blank" rel="noopener">http://tldp.org/LDP/abs/html/exitcodes.html</a></li><li><a href="https://imroc.io/posts/kubernetes/analysis-exitcode/" target="_blank" rel="noopener">https://imroc.io/posts/kubernetes/analysis-exitcode/</a></li><li><a href="https://medium.com/better-programming/understanding-docker-container-exit-codes-5ee79a1d58f6" target="_blank" rel="noopener">https://medium.com/better-programming/understanding-docker-container-exit-codes-5ee79a1d58f6</a></li></ul><blockquote><p>本文转载自：「 Vermouth 的博客 」，原文：<a href="https://url.hi-linux.com/bfCGL" target="_blank" rel="noopener">https://url.hi-linux.com/bfCGL</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为什么我的容器没有运行？&lt;/p&gt;
&lt;p&gt;回答这个问题需要知道 Docker 容器为什么退出，退出码会提示容器停止运行的情况。本文列出了最常见的退出码，来回答两个重要问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这些退出码是什么意思？&lt;/li&gt;
&lt;li&gt;导致该退出码的动作是什么？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;exit code： 代表一个进程的返回码，通过系统调用 exit_group 来触发。在 POSIX 中，0 代表正常的返回码，而 1-255 代表异常返回码，不过一般错误码都是 1。这里有一张附表 &lt;a href=&quot;http://tldp.org/LDP/abs/html/exitcodes.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Appendix E. Exit Codes With Special Meanings&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>五分钟理解服务器 SMP、NUMA、MPP 三大体系结构</title>
    <link href="https://www.hi-linux.com/posts/12714.html"/>
    <id>https://www.hi-linux.com/posts/12714.html</id>
    <published>2022-07-02T01:00:00.000Z</published>
    <updated>2022-07-04T06:32:06.684Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>从系统架构来看，目前的商用服务器大体可以分为三类，即对称多处理器结构 (SMP ： Symmetric Multi-Processor) ，非一致存储访问结构 (NUMA ： Non-Uniform Memory Access) ，以及海量并行处理结构 (MPP ： Massive Parallel Processing) 。它们的特征分别描述如下：</p><h2><span id="1-smpsymmetric-multi-processor">1. SMP(Symmetric Multi-Processor)</span></h2><p>SMP (Symmetric Multi Processing),对称多处理系统内有许多紧耦合多处理器，在这样的系统中，所有的CPU共享全部资源，如总线，内存和I/O系统等，操作系统或管理数据库的复本只有一个，这种系统有一个最大的特点就是共享所有资源。多个CPU之间没有区别，平等地访问内存、外设、一个操作系统。操作系统管理着一个队列，每个处理器依次处理队列中的进程。如果两个处理器同时请求访问一个资源（例如同一段内存地址），由硬件、软件的锁机制去解决资源争用问题。Access to RAM is serialized; this and <a href="http://en.wikipedia.org/wiki/Cache_coherency" target="_blank" rel="noopener">cache coherency</a> issues causes performance to lag slightly behind the number of additional processors in the system.</p><p><img src="https://img.hi-linux.com/staticfile/clip_image001_d7728dc2-e525-4e5b-b84c-6f5a7f4de300-2022-06-29-09XWa8.gif" alt></p><p>所谓对称多处理器结构，是指服务器中多个 CPU 对称工作，无主次或从属关系。各 CPU 共享相同的物理内存，每个 CPU 访问内存中的任何地址所需时间是相同的，因此 SMP 也被称为一致存储器访问结构 (UMA ： Uniform Memory Access) 。对 SMP 服务器进行扩展的方式包括增加内存、使用更快的 CPU 、增加 CPU 、扩充 I/O( 槽口数与总线数 ) 以及添加更多的外部设备 ( 通常是磁盘存储 ) 。</p><a id="more"></a><p>SMP 服务器的主要特征是共享，系统中所有资源 (CPU 、内存、 I/O 等 ) 都是共享的。也正是由于这种特征，导致了 SMP 服务器的主要问题，那就是它的扩展能力非常有限。对于 SMP 服务器而言，每一个共享的环节都可能造成 SMP 服务器扩展时的瓶颈，而最受限制的则是内存。由于每个 CPU 必须通过相同的内存总线访问相同的内存资源，因此随着 CPU 数量的增加，内存访问冲突将迅速增加，最终会造成 CPU 资源的浪费，使 CPU 性能的有效性大大降低。实验证明， SMP 服务器 CPU 利用率最好的情况是 2 至 4 个 CPU 。</p><p><img src="https://img.hi-linux.com/staticfile/clip_image002_thumb-20220629133032132-2022-06-29-BqKbRu.gif" alt="图1. SMP 服务器 CPU 利用率状态"></p><p>8路服务器是服务器产业的分水岭。因为4路及以下服务器都采用SMP架构(Symmetric Multi-Processor，对称多处理结构)，实验证明，SMP服务器CPU利用率最好的情况是2至4个CPU。8是这种架构支持的处理器数量的极限，要支持8颗以上的处理器须采用另外的NUMA架构(Non-Uniform Memory Access，非一致性内存访问)。利用NUMA技术，可以较好地解决原来SMP系统的扩展问题，在一个物理服务器内可以支持上百个CPU。</p><h2><span id="2-numanon-uniform-memory-access">2. NUMA(Non-Uniform Memory Access)</span></h2><p>由于 SMP 在扩展能力上的限制，人们开始探究如何进行有效地扩展从而构建大型系统的技术， NUMA 就是这种努力下的结果之一。利用 NUMA 技术，可以把几十个 CPU( 甚至上百个 CPU) 组合在一个服务器内。其 CPU 模块结构如图 2 所示：</p><p><img src="https://img.hi-linux.com/staticfile/clip_image003_thumb-20220629133038040-2022-06-29-UEm1MW.gif" alt="图2. NUMA 服务器 CPU 模块结构"></p><p>NUMA 服务器的基本特征是具有多个 CPU 模块，每个 CPU 模块由多个 CPU( 如 4 个 ) 组成，并且具有独立的本地内存、 I/O 槽口等。由于其节点之间可以通过互联模块 ( 如称为 Crossbar Switch) 进行连接和信息交互，因此每个 CPU 可以访问整个系统的内存 ( 这是 NUMA 系统与 MPP 系统的重要差别 ) 。显然，访问本地内存的速度将远远高于访问远地内存 ( 系统内其它节点的内存 ) 的速度，这也是非一致存储访问 NUMA 的由来。由于这个特点，为了更好地发挥系统性能，开发应用程序时需要尽量减少不同 CPU 模块之间的信息交互。</p><p>利用 NUMA 技术，可以较好地解决原来 SMP 系统的扩展问题，在一个物理服务器内可以支持上百个 CPU 。比较典型的 NUMA 服务器的例子包括 HP 的 Superdome 、 SUN15K 、 IBMp690 等。</p><p>但 NUMA 技术同样有一定缺陷，由于访问远地内存的延时远远超过本地内存，因此当 CPU 数量增加时，系统性能无法线性增加。如 HP 公司发布 Superdome 服务器时，曾公布了它与 HP 其它 UNIX 服务器的相对性能值，结果发现， 64 路 CPU 的 Superdome (NUMA 结构 ) 的相对性能值是 20 ，而 8 路 N4000( 共享的 SMP 结构 ) 的相对性能值是 6.3 。从这个结果可以看到， 8 倍数量的 CPU 换来的只是 3 倍性能的提升。</p><p>2008年intel发布了Nehalem构架处理器，CPU内集成了内存控制器。当多CPU时任何一颗CPU都能访问全部内存。但CPU0访问本地内存(CPU0控制器直接控制的内存)消耗小，CPU0访问远地内存(CPU1内存控制器控制的内存)消耗大，NUMA功能的开启变成了必须了。</p><p>默认的NUMA功能是将计算和内存资源分配在一个NUMA内，有可能导致SWAP问题，即：NUMA0内存已经用完都开始用SWAP空间了，NUMA1还有很大的内存free。在数据库服务器上NUMA可能导致非常严重的性能问题，甚至有很多数据库死机的问题。就下图这个熊样。</p><p><img src="https://img.hi-linux.com/staticfile/1213536-20181228172000749-1913807104-2022-06-29-3ela76.png" alt></p><p>在虚拟化情况下，KVM虚机的CPU数量尽量不超过一个NUMA区域内的CPU数量，如果超过，则会出现一个KVM虚机使用了两个NUMA的情况，导致CPU等待内存时间过长，系统性能下降，此时需要手动调整KVM的配置才可以提高性能。</p><ul><li><p>Ubuntu 12.02自身带有Automatic NUMA balancing，可以支持NUMA自平衡，具体情况未测试。SUSE12也支持Automatic NUMA balancing</p></li><li><p>JUNO版的Openstack中，KVM的CPU的拓扑可以通过image或者flavor进行元数据传递来定义，如果没有特别的定义此类元数据，则模拟的CPU将是多Socket单Core单NUMA节点的CPU，这样的CPU与物理CPU完全不同。</p></li></ul><p>上面是KVM。Vmware ESX 5.0及之后的版本支持一种叫做vNUMA的特性，它将Host的NUMA特征暴露给了GuestOS，从而使得Guest OS可以根据NUMA特征进行更高性能的调度。</p><ul><li><p>CPU的热添加功能不支持vNUMA功能。</p></li><li><p>vmotion等功能一旦将vmware虚机迁移，则可能导致vNUMA失效，带来严重的性能降低。所以在ESXi中保持物理服务器的一致性是有必要的。</p></li></ul><p>中国第一台自主研发的，可支持32可处理器的高端服务器浪潮天梭K1，发布于2013年1月，系统可用性达到99.9994%，同时，我国也成为了时间上第三个掌握该技术的国家。</p><h2><span id="3-mppmassive-parallel-processing">3. MPP(Massive Parallel Processing)</span></h2><p>和 NUMA 不同， MPP 提供了另外一种进行系统扩展的方式，它由多个 SMP 服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。其基本特征是由多个 SMP 服务器 ( 每个 SMP 服务器称节点 ) 通过节点互联网络连接而成，每个节点只访问自己的本地资源 ( 内存、存储等 ) ，是一种完全无共享 (Share Nothing) 结构，因而扩展能力最好，理论上其扩展无限制，目前的技术可实现 512 个节点互联，数千个 CPU 。目前业界对节点互联网络暂无标准，如 NCR 的 Bynet ， IBM 的 SPSwitch ，它们都采用了不同的内部实现机制。但节点互联网仅供 MPP 服务器内部使用，对用户而言是透明的。</p><p>在 MPP 系统中，每个 SMP 节点也可以运行自己的操作系统、数据库等。但和 NUMA 不同的是，它不存在异地内存访问的问题。换言之，每个节点内的 CPU 不能访问另一个节点的内存。节点之间的信息交互是通过节点互联网络实现的，这个过程一般称为数据重分配 (Data Redistribution) 。</p><p>但是 MPP 服务器需要一种复杂的机制来调度和平衡各个节点的负载和并行处理过程。目前一些基于 MPP 技术的服务器往往通过系统级软件 ( 如数据库 ) 来屏蔽这种复杂性。举例来说， NCR 的 Teradata 就是基于 MPP 技术的一个关系数据库软件，基于此数据库来开发应用时，不管后台服务器由多少个节点组成，开发人员所面对的都是同一个数据库系统，而不需要考虑如何调度其中某几个节点的负载。</p><p>MPP (Massively Parallel Processing)，大规模并行处理系统，这样的系统是由许多松耦合的处理单元组成的，要注意的是这里指的是处理单元而不是处理器。每个单元内的CPU都有自己私有的资源，如总线，内存，硬盘等。在每个单元内都有操作系统和管理数据库的实例复本。这种结构最大的特点在于不共享资源。</p><p><img src="https://img.hi-linux.com/staticfile/clip_image004_a7d7609b-fc3c-4033-8181-5f4f4afaa572-20220629133045932-2022-06-29-XMfJa9.gif" alt></p><h2><span id="4-三种体系架构之间的差异">4. 三种体系架构之间的差异</span></h2><h3><span id="41-smp系统与mpp系统比较">4.1 </span></h3><p>既然有两种结构，那它们各有什么特点呢？采用什么结构比较合适呢？通常情况下，MPP系统因为要在不同处理单元之间传送信息（请注意上图），所以它的效率要比SMP要差一点，但是这也不是绝对的，因为MPP系统不共享资源，因此对它而言，资源比SMP要多，当需要处理的事务达到一定规模时，MPP的效率要比SMP好。这就是看通信时间占用计算时间的比例而定，如果通信时间比较多，那MPP系统就不占优势了，相反，如果通信时间比较少，那MPP系统可以充分发挥资源的优势，达到高效率。当前使用的OTLP程序中，用户访问一个中心数据库，如果采用SMP系统结构，它的效率要比采用MPP结构要快得多。而MPP系统在决策支持和数据挖掘方面显示了优势，可以这样说，如果操作相互之间没有什么关系，处理单元之间需要进行的通信比较少，那采用MPP系统就要好，相反就不合适了。</p><p>通过上面两个图我们可以看到，对于SMP来说，制约它速度的一个关键因素就是那个共享的总线，因此对于DSS程序来说，只能选择MPP，而不能选择SMP，当大型程序的处理要求大于共享总线时，总线就没有能力进行处理了，这时SMP系统就不行了。当然了，两个结构互有优缺点，如果能够将两种结合起来取长补短，当然最好了。</p><p><img src="https://img.hi-linux.com/staticfile/clip_image005_74c6d040-d7ed-476d-905a-91fb5d2a4255-20220629133052729-2022-06-29-Tfga9P.gif" alt></p><p><img src="https://img.hi-linux.com/staticfile/clip_image006_0219f756-4c51-408d-8646-83b91f6b158a-20220629133101304-2022-06-29-U6cJpB.gif" alt></p><h3><span id="42-numa-与-mpp-的区别">4.2 NUMA 与 MPP 的区别</span></h3><p>从架构来看， NUMA 与 MPP 具有许多相似之处：它们都由多个节点组成，每个节点都具有自己的 CPU 、内存、 I/O ，节点之间都可以通过节点互联机制进行信息交互。那么它们的区别在哪里？通过分析下面 NUMA 和 MPP 服务器的内部架构和工作原理不难发现其差异所在。</p><p>首先是节点互联机制不同， NUMA 的节点互联机制是在同一个物理服务器内部实现的，当某个 CPU 需要进行远地内存访问时，它必须等待，这也是 NUMA 服务器无法实现 CPU 增加时性能线性扩展的主要原因。而 MPP 的节点互联机制是在不同的 SMP 服务器外部通过 I/O 实现的，每个节点只访问本地内存和存储，节点之间的信息交互与节点本身的处理是并行进行的。因此 MPP 在增加节点时性能基本上可以实现线性扩展。</p><p>其次是内存访问机制不同。在 NUMA 服务器内部，任何一个 CPU 可以访问整个系统的内存，但远地访问的性能远远低于本地内存访问，因此在开发应用程序时应该尽量避免远地内存访问。在 MPP 服务器中，每个节点只访问本地内存，不存在远地内存访问的问题。</p><p><img src="https://img.hi-linux.com/staticfile/clip_image007_thumb-20220629133108009-2022-06-29-zu5Bnt.gif" alt="图3.MPP 服务器架构图"></p><p><strong>数据仓库的选择</strong></p><p>哪种服务器更加适应数据仓库环境？这需要从数据仓库环境本身的负载特征入手。众所周知，典型的数据仓库环境具有大量复杂的数据处理和综合分析，要求系统具有很高的 I/O 处理能力，并且存储系统需要提供足够的 I/O 带宽与之匹配。而一个典型的 OLTP 系统则以联机事务处理为主，每个交易所涉及的数据不多，要求系统具有很高的事务处理能力，能够在单位时间里处理尽量多的交易。显然这两种应用环境的负载特征完全不同。</p><p>从 NUMA 架构来看，它可以在一个物理服务器内集成许多 CPU ，使系统具有较高的事务处理能力，由于远地内存访问时延远长于本地内存访问，因此需要尽量减少不同 CPU 模块之间的数据交互。显然， NUMA 架构更适用于 OLTP 事务处理环境，当用于数据仓库环境时，由于大量复杂的数据处理必然导致大量的数据交互，将使 CPU 的利用率大大降低。</p><p>相对而言， MPP 服务器架构的并行处理能力更优越，更适合于复杂的数据综合分析与处理环境。当然，它需要借助于支持 MPP 技术的关系数据库系统来屏蔽节点之间负载平衡与调度的复杂性。另外，这种并行处理能力也与节点互联网络有很大的关系。显然，适应于数据仓库环境的 MPP 服务器，其节点互联网络的 I/O 性能应该非常突出，才能充分发挥整个系统的性能。</p><h3><span id="43-numa-mpp-smp-之间性能的区别">4.3 NUMA、MPP、SMP 之间性能的区别</span></h3><p>NUMA的节点互联机制是在同一个物理服务器内部实现的，当某个CPU需要进行远地内存访问时，它必须等待，这也是NUMA服务器无法实现CPU增加时性能线性扩展。</p><p>MPP的节点互联机制是在不同的SMP服务器外部通过I/O实现的，每个节点只访问本地内存和存储，节点之间的信息交互与节点本身的处理是并行进行的。因此MPP在增加节点时性能基本上可以实现线性扩展。</p><p>SMP所有的CPU资源是共享的，因此完全实现线性扩展。</p><h3><span id="44-numa-mpp-smp之间扩展的区别">4.4 NUMA、MPP、SMP之间扩展的区别</span></h3><p>NUMA理论上可以无限扩展，目前技术比较成熟的能够支持上百个CPU进行扩展。如HP的SUPERDOME。</p><p>MPP理论上也可以实现无限扩展，目前技术比较成熟的能够支持512个节点，数千个CPU进行扩展。</p><p>SMP扩展能力很差，目前2个到4个CPU的利用率最好，但是IBM的BOOK技术，能够将CPU扩展到8个。</p><p>MPP是由多个SMP构成，多个SMP服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务。</p><h3><span id="45-mpp-和-smp-numa-应用之间的区别">4.5 MPP 和 SMP、NUMA 应用之间的区别</span></h3><ul><li>MPP 的优势：</li></ul><p>MPP系统不共享资源，因此对它而言，资源比SMP要多，当需要处理的事务达到一定规模时，MPP的效率要比SMP好。由于MPP系统因为要在不同处理单元之间传送信息，在通讯时间少的时候，那MPP系统可以充分发挥资源的优势，达到高效率。也就是说：操作相互之间没有什么关系，处理单元之间需要进行的通信比较少，那采用MPP系统就要好。因此，MPP 系统在决策支持和数据挖掘方面显示了优势。</p><ul><li>SMP 的优势：</li></ul><p>MPP系统因为要在不同处理单元之间传送信息，所以它的效率要比SMP要差一点。在通讯时间多的时候，那MPP系统可以充分发挥资源的优势。因此当前使用的 OTLP程序中，用户访问一个中心数据库，如果采用 SMP 系统结构，它的效率要比采用MPP结构要快得多。</p><ul><li>NUMA 架构的优势：</li></ul><p>NUMA 架构来看，它可以在一个物理服务器内集成许多CPU，使系统具有较高的事务处理能力，由于远地内存访问时延远长于本地内存访问，因此需要尽量减少不同CPU模块之间的数据交互。显然，NUMA架构更适用于OLTP事务处理环境，当用于数据仓库环境时，由于大量复杂的数据处理必然导致大量的数据交互，将使CPU的利用率大大降低。</p><blockquote><p>本文转载自：「 博客园 」，原文：<a href="https://url.hi-linux.com/NWfZv%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.hi-linux.com/NWfZv，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从系统架构来看，目前的商用服务器大体可以分为三类，即对称多处理器结构 (SMP ： Symmetric Multi-Processor) ，非一致存储访问结构 (NUMA ： Non-Uniform Memory Access) ，以及海量并行处理结构 (MPP ： Massive Parallel Processing) 。它们的特征分别描述如下：&lt;/p&gt;
&lt;h2 id=&quot;1-SMP-Symmetric-Multi-Processor&quot;&gt;1. SMP(Symmetric Multi-Processor)&lt;/h2&gt;
&lt;p&gt;SMP (Symmetric Multi Processing),对称多处理系统内有许多紧耦合多处理器，在这样的系统中，所有的CPU共享全部资源，如总线，内存和I/O系统等，操作系统或管理数据库的复本只有一个，这种系统有一个最大的特点就是共享所有资源。多个CPU之间没有区别，平等地访问内存、外设、一个操作系统。操作系统管理着一个队列，每个处理器依次处理队列中的进程。如果两个处理器同时请求访问一个资源（例如同一段内存地址），由硬件、软件的锁机制去解决资源争用问题。Access to RAM is serialized; this and &lt;a href=&quot;http://en.wikipedia.org/wiki/Cache_coherency&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cache coherency&lt;/a&gt; issues causes performance to lag slightly behind the number of additional processors in the system.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/clip_image001_d7728dc2-e525-4e5b-b84c-6f5a7f4de300-2022-06-29-09XWa8.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;所谓对称多处理器结构，是指服务器中多个 CPU 对称工作，无主次或从属关系。各 CPU 共享相同的物理内存，每个 CPU 访问内存中的任何地址所需时间是相同的，因此 SMP 也被称为一致存储器访问结构 (UMA ： Uniform Memory Access) 。对 SMP 服务器进行扩展的方式包括增加内存、使用更快的 CPU 、增加 CPU 、扩充 I/O( 槽口数与总线数 ) 以及添加更多的外部设备 ( 通常是磁盘存储 ) 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="CPU" scheme="https://www.hi-linux.com/tags/CPU/"/>
    
  </entry>
  
  <entry>
    <title>pwru：一款基于 eBPF 的细粒度网络数据包排查工具</title>
    <link href="https://www.hi-linux.com/posts/6471.html"/>
    <id>https://www.hi-linux.com/posts/6471.html</id>
    <published>2022-06-27T01:00:00.000Z</published>
    <updated>2022-06-27T03:21:04.627Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>pwru</code> 是 Cilium 推出的基于 eBPF 开发的网络数据包排查工具，它提供了更细粒度的网络数据包排查方案。本文将介绍 <code>pwru</code> 的使用方法和经典场景，并介绍其实现原理。</p><a id="more"></a><h2><span id="安装部署">安装部署</span></h2><h3><span id="部署要求">部署要求</span></h3><p><code>pwru</code> 要求内核代码在 5.5 版本之上，<code>--output-skb</code> 要求内核版本在 5.9 之上，并且要求内核开启以下配置：</p><table><thead><tr><th style="text-align:left">Option</th><th style="text-align:left">Note</th></tr></thead><tbody><tr><td style="text-align:left">CONFIG_DEBUG_INFO_BTF=y</td><td style="text-align:left">Available since &gt;= 5.3</td></tr><tr><td style="text-align:left">CONFIG_KPROBES=y</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">CONFIG_PERF_EVENTS=y</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">CONFIG_BPF=y</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">CONFIG_BPF_SYSCALL=y</td><td style="text-align:left"></td></tr></tbody></table><h3><span id="使用方法">使用方法</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Usage of .&#x2F;pwru:</span><br><span class="line">      --filter-dst-ip string        filter destination IP addr</span><br><span class="line">      --filter-dst-port uint16      filter destination port</span><br><span class="line">      --filter-func string          filter kernel functions to be probed by name (exact match, supports RE2 regular expression)</span><br><span class="line">      --filter-mark uint32          filter skb mark</span><br><span class="line">      --filter-netns uint32         filter netns inode</span><br><span class="line">      --filter-proto string         filter L4 protocol (tcp, udp, icmp)</span><br><span class="line">      --filter-src-ip string        filter source IP addr</span><br><span class="line">      --filter-src-port uint16      filter source port</span><br><span class="line">      --output-limit-lines uint     exit the program after the number of events has been received&#x2F;printed</span><br><span class="line">      --output-meta                 print skb metadata</span><br><span class="line">      --output-relative-timestamp   print relative timestamp per skb</span><br><span class="line">      --output-skb                  print skb</span><br><span class="line">      --output-stack                print stack</span><br><span class="line">      --output-tuple                print L4 tuple</span><br></pre></td></tr></table></figure><h2><span id="案例演示">案例演示</span></h2><p>下图案例演示了 <code>pwru</code> 展现出快速定位出数据包被 iptables 规则 drop 掉的原因：</p><p><img src="https://img.hi-linux.com/staticfile/demo-2022-06-16-LarlDo.gif" alt></p><p>在不设置 iptables 规则之前：</p><p><img src="https://img.hi-linux.com/staticfile/20211102110051-2022-06-16-ATTuCp.png" alt></p><p>添加了 iptables 规则之后</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t filter -I OUTPUT 1 -m tcp --proto tcp --dst 1.1.1.1&#x2F;32 -j DROP</span><br></pre></td></tr></table></figure><p>可以看到在 <code>nf_hook_slow</code> 函数后发生了变化：</p><p><img src="https://img.hi-linux.com/staticfile/20211102110601-2022-06-16-pXKpVk.png" alt></p><p>我们可以看到数据包在 <code>nf_hook_slow</code> 判决为 <code>NF_DROP</code>，调用了 <code>kfree_skb</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">int nf_hook_slow(struct sk_buff *skb, struct nf_hook_state *state,</span><br><span class="line">     const struct nf_hook_entries *e, unsigned int s)</span><br><span class="line">&#123;</span><br><span class="line">  unsigned int verdict;</span><br><span class="line">  int ret;</span><br><span class="line"></span><br><span class="line">  for (; s &lt; e-&gt;num_hook_entries; s++) &#123;</span><br><span class="line">    verdict &#x3D; nf_hook_entry_hookfn(&amp;e-&gt;hooks[s], skb, state);</span><br><span class="line">    switch (verdict &amp; NF_VERDICT_MASK) &#123;</span><br><span class="line">    case NF_ACCEPT:</span><br><span class="line">      break;</span><br><span class="line">    case NF_DROP:</span><br><span class="line">      kfree_skb(skb);</span><br><span class="line">      ret &#x3D; NF_DROP_GETERR(verdict);</span><br><span class="line">      if (ret &#x3D;&#x3D; 0)</span><br><span class="line">        ret &#x3D; -EPERM;</span><br><span class="line">      return ret;</span><br><span class="line">    case NF_QUEUE:</span><br><span class="line">      ret &#x3D; nf_queue(skb, state, s, verdict);</span><br><span class="line">      if (ret &#x3D;&#x3D; 1)</span><br><span class="line">        continue;</span><br><span class="line">      return ret;</span><br><span class="line">    default:</span><br><span class="line">      &#x2F;* Implicit handling for NF_STOLEN, as well as any other</span><br><span class="line">       * non conventional verdicts.</span><br><span class="line">       *&#x2F;</span><br><span class="line">      return 0;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  return 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="原理实现">原理实现</span></h2><p><code>pwru</code> 本质上是向 kprobe 注册了一些 eBPF code，根据 <code>pwru</code> 传入的参数可以更新 <code>eBPF Map</code>，改变限制条件，从而更新输出。</p><p>比如在 <code>FilterCfg</code> 里面制定了过滤的 IP 地址和协议等条件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">type FilterCfg struct &#123;</span><br><span class="line">FilterMark uint32</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Filter l3</span><br><span class="line">FilterIPv6  uint8</span><br><span class="line">FilterSrcIP [16]byte</span><br><span class="line">FilterDstIP [16]byte</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Filter l4</span><br><span class="line">FilterProto   uint8</span><br><span class="line">FilterSrcPort uint16</span><br><span class="line">FilterDstPort uint16</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;TODO: if there are more options later, then you can consider using a bit map</span><br><span class="line">OutputRelativeTS uint8</span><br><span class="line">OutputMeta       uint8</span><br><span class="line">OutputTuple      uint8</span><br><span class="line">OutputSkb        uint8</span><br><span class="line">OutputStack      uint8</span><br><span class="line"></span><br><span class="line">Pad byte</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会根据 <code>pwru</code> 传入的参数更新这个 eBPF Map</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">func ConfigBPFMap(flags *Flags, cfgMap *ebpf.Map) &#123;</span><br><span class="line">cfg :&#x3D; FilterCfg&#123;</span><br><span class="line">FilterMark: flags.FilterMark,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if flags.FilterSrcPort &gt; 0 &#123;</span><br><span class="line">cfg.FilterSrcPort &#x3D; byteorder.HostToNetwork16(flags.FilterSrcPort)</span><br><span class="line">&#125;</span><br><span class="line">if flags.FilterDstPort &gt; 0 &#123;</span><br><span class="line">cfg.FilterDstPort &#x3D; byteorder.HostToNetwork16(flags.FilterDstPort)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">switch strings.ToLower(flags.FilterProto) &#123;</span><br><span class="line">case &quot;tcp&quot;:</span><br><span class="line">cfg.FilterProto &#x3D; syscall.IPPROTO_TCP</span><br><span class="line">case &quot;udp&quot;:</span><br><span class="line">cfg.FilterProto &#x3D; syscall.IPPROTO_UDP</span><br><span class="line">case &quot;icmp&quot;:</span><br><span class="line">cfg.FilterProto &#x3D; syscall.IPPROTO_ICMP</span><br><span class="line">case &quot;icmp6&quot;:</span><br><span class="line">cfg.FilterProto &#x3D; syscall.IPPROTO_ICMPV6</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; ... </span><br><span class="line">  </span><br><span class="line">if err :&#x3D; cfgMap.Update(uint32(0), cfg, 0); err !&#x3D; nil &#123;</span><br><span class="line">log.Fatalf(&quot;Failed to set filter map: %v&quot;, err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 eBPF code 中，可以看到会读取配置 <code>bpf_map_lookup_elem</code>，然后进而执行真正的 filter：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">struct config &#123;</span><br><span class="line">u32 mark;</span><br><span class="line">u8 ipv6;</span><br><span class="line">union addr saddr;</span><br><span class="line">union addr daddr;</span><br><span class="line">u8 l4_proto;</span><br><span class="line">u16 sport;</span><br><span class="line">u16 dport;</span><br><span class="line">u8 output_timestamp;</span><br><span class="line">u8 output_meta;</span><br><span class="line">u8 output_tuple;</span><br><span class="line">u8 output_skb;</span><br><span class="line">u8 output_stack;</span><br><span class="line">u8 pad;</span><br><span class="line">&#125; __attribute__((packed));</span><br><span class="line"></span><br><span class="line">static __always_inline int</span><br><span class="line">handle_everything(struct sk_buff *skb, struct pt_regs *ctx) &#123;</span><br><span class="line">struct event_t event &#x3D; &#123;&#125;;</span><br><span class="line"></span><br><span class="line">u32 index &#x3D; 0;</span><br><span class="line">struct config *cfg &#x3D; bpf_map_lookup_elem(&amp;cfg_map, &amp;index);</span><br><span class="line"></span><br><span class="line">if (cfg) &#123;</span><br><span class="line">if (!filter(skb, cfg))</span><br><span class="line">return 0;</span><br><span class="line"></span><br><span class="line">set_output(ctx, skb, &amp;event, cfg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">event.pid &#x3D; bpf_get_current_pid_tgid();</span><br><span class="line">event.addr &#x3D; PT_REGS_IP(ctx);</span><br><span class="line">event.skb_addr &#x3D; (u64) skb;</span><br><span class="line">event.ts &#x3D; bpf_ktime_get_ns();</span><br><span class="line">bpf_perf_event_output(ctx, &amp;events, BPF_F_CURRENT_CPU, &amp;event, sizeof(event));</span><br><span class="line"></span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这里通过 <code>bpf_perf_event_output</code> 将过滤结果以 Perf event 传递上来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">rd, err :&#x3D; perf.NewReader(events, os.Getpagesize())</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">log.Fatalf(&quot;Creating perf event reader: %s&quot;, err)</span><br><span class="line">&#125;</span><br><span class="line">defer rd.Close()</span><br><span class="line"></span><br><span class="line"> &#x2F;&#x2F; ...</span><br><span class="line"> var event pwru.Event</span><br><span class="line">for &#123;</span><br><span class="line">record, err :&#x3D; rd.Read()</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">if perf.IsClosed(err) &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(&quot;Reading from perf event reader: %s&quot;, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if record.LostSamples !&#x3D; 0 &#123;</span><br><span class="line">log.Printf(&quot;Perf event ring buffer full, dropped %d samples&quot;, record.LostSamples)</span><br><span class="line">continue</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if err :&#x3D; binary.Read(bytes.NewBuffer(record.RawSample), binary.LittleEndian, &amp;event); err !&#x3D; nil &#123;</span><br><span class="line">log.Printf(&quot;Parsing perf event: %s&quot;, err)</span><br><span class="line">continue</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output.Print(&amp;event)</span><br><span class="line"></span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-ctx.Done():</span><br><span class="line">break</span><br><span class="line">default:</span><br><span class="line">continue</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 Houmin 的博客 」，原文：<a href="https://url.hi-linux.com/et8wH" target="_blank" rel="noopener">https://url.hi-linux.com/et8wH</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;pwru&lt;/code&gt; 是 Cilium 推出的基于 eBPF 开发的网络数据包排查工具，它提供了更细粒度的网络数据包排查方案。本文将介绍 &lt;code&gt;pwru&lt;/code&gt; 的使用方法和经典场景，并介绍其实现原理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Cilium" scheme="https://www.hi-linux.com/tags/Cilium/"/>
    
      <category term="eBPF" scheme="https://www.hi-linux.com/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Pod 多网卡解决方案 Multus 入门指南</title>
    <link href="https://www.hi-linux.com/posts/5706.html"/>
    <id>https://www.hi-linux.com/posts/5706.html</id>
    <published>2022-06-21T01:00:00.000Z</published>
    <updated>2022-06-21T03:01:32.502Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在 Kubernetes中，网络是非常重要的一个领域。 Kubernetes 本身不提供网络解决方案，但是提供了 CN I规范。这些规范被许多 CNI 插件（例如 WeaveNet，Flannel，Calico 等）遵守。这些插件中任何一个都可以在集群上使用和部署以提供网络解决方案。该网络称为集群的默认网络。此默认网络使 Pods 不仅可以在同一节点上而且可以在群集中的各个节点之间相互通信。</p><p>随着发展，Kubernetes 缺乏支持 VNF 中多个网络接口的所需功能。传统上，网络功能使用多个网络接口分离控制，管理和控制用户/数据的网络平面。他们还用于支持不同的协议，满足不同的调整和配置要求。</p><p>为了解决这个需求，英特尔实现了 MULTUS 的 CNI 插件，其中提供了将多个接口添加到 Pod 的功能。这允许 POD 通过不同的接口连接到多个网络，并且每个接口都将使用其自己的 CNI 插件。</p><a id="more"></a><p>下面是 Multus CNI 提供的连接到 Pod 的网络接口的图示。该图显示了具有三个接口的容器：<code>eth0</code>，<code>net0</code>和<code>net1</code>。 <code>eth0</code>连接 Kubernetes 集群网络以连接kubernetes服务器/服务（例如 Kubernetes api-server，kubelet 等）。 <code>net0</code>和<code>net1</code>是其他网络附件，并通过使用其他 CNI 插件（例如vlan / vxlan / ptp）连接到其他网络。</p><p><img src="https://img.hi-linux.com/staticfile/1460000022848627-2022-06-16-tAgyzp.jpeg" alt></p><h2><span id="multus-工作原理">MULTUS 工作原理</span></h2><p>Kubernetes 当前没有提供为POD添加额外的接口选项的规定，或支持多个 CNI 插件同时工作的规定，但是它确实提供了一种由 API 服务器扩展受支持的API的机制。使用 “自定义资源定义” 可以做到这一点。 MULTUS依赖于 “自定义资源定义” 来存储其他接口和CNI插件所需的信息。</p><p><img src="https://img.hi-linux.com/staticfile/1460000022848626-20220616140455500-2022-06-16-l02xpE.jpeg" alt></p><p>我们首先需要确保将 MULTUS 二进制文件放置在 <code>/opt/cni/bin</code> 位置的所有节点上，并在<code>/etc/cni/net.d</code>位置创建一个新的配置文件。与 MULTUS 使用的 kubeconfig 文件一起使用。</p><p>在<code>/etc/cni/net.d</code>中创建的新配置文件基于集群中已经存在的默认网络配置。</p><p>在此之后，CRD 用于定义新的种类名称 “NetworkAttachmentDefinition”，以及服务帐户和 MULTUS 的集群角色以及相应的绑定。这个新的集群角色将提供对随 CRD 添加的新 API 组以及默认 API 组中 Pod 资源的访问权限。</p><p>然后创建类型为 “NetworkAttachmentDefinition” 的客户资源实例，该实例稍后将在创建具有多个接口的 Pod 时使用。</p><h2><span id="部署示例">部署示例</span></h2><p>在本文中，我们将多次提及两件事：</p><ul><li>“默认网络” - 这是您的Pod到Pod网络。这就是集群中 Pod 之间相互通信的方式，以及它们之间的连通性。一般而言，这被称为名为 eth0 的接口。此接口始终连接到您的 Pod，以便它们之间可以相互连接。除此之外，我们还将添加接口。</li><li>“ CRD”    - 自定义资源定义。自定义资源是扩展 Kubernetes API 的一种方式。我们在这里使用这些存储 Multus 可以读取的一些信息。首先，我们使用它们来存储附加到您的 Pod 的每个其他接口的配置。</li></ul><p>目前支持 Kubernetes 1.16+ 版本。</p><h2><span id="安装">安装</span></h2><p>我们建议的用于部署 Multus 的快速入门方法是使用 Daemonset（在群集中的每个节点上运行 Pod 的方法）进行部署，该 Pod 会安装 Multus 二进制文件并配置 Multus 以供使用。</p><p>首先，克隆此 GitHub 存储库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;multus-cni.git &amp;&amp; cd multus-cni</span><br></pre></td></tr></table></figure><p>我们将在此存储库中使用带有kubectl的YAML文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat .&#x2F;images&#x2F;multus-daemonset.yml | kubectl apply -f -</span><br></pre></td></tr></table></figure><h3><span id="multus-daemonset-完成了那些工作">Multus daemonset 完成了那些工作？</span></h3><ul><li>启动 Multus 守护程序集，这会在每个节点上运行一个pod，从而在<code>/opt/cni/bin</code>中的每个节点上放置一个 Multus 二进制文件</li><li>按照字母顺序读取<code>/etc/cni/net.d</code>中的第一个配置文件，并为 Multus 创建一个新的配置文件，即<code>/etc/cni/net.d/00-multus.conf</code>，此配置是自动生成并基于默认网络配置（假定是按字母顺序排列的第一个配置）</li><li>在每个节点上创建一个<code>/etc/cni/net.d/multus.d</code>目录，其中包含用于 Multus 访问 Kubernetes API 的身份验证信息。</li></ul><h2><span id="创建其他接口">创建其他接口</span></h2><p>我们要做的第一件事是为我们附加到Pod的每个其他接口创建配置。我们将通过创建自定义资源来做到这一点。快速入门安装的一部分会创建一个 “CRD” （自定义资源定义，它是我们保留这些自定义资源的位置），我们将在其中存储每个接口的配置。</p><h3><span id="cni-配置">CNI 配置</span></h3><p>我们将添加的每个配置都是CNI配置。如果您不熟悉它们，让我们快速分解它们。这是一个示例CNI配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;cniVersion&quot;: &quot;0.3.0&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;loopback&quot;,</span><br><span class="line">  &quot;additional&quot;: &quot;information&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CNI配置是 JSON，我们这里有一个结构，其中包含一些我们感兴趣的东西：</p><ul><li><code>cniVersion</code>：告诉每个 CNI 插件正在使用哪个版本，如果使用的版本太晚（或太早），则可以提供插件信息。</li><li><code>type</code>：告诉 CNI 在磁盘上调用哪个二进制文件。每个 CNI 插件都是一个二进制文件。通常，这些二进制文件存储在每个节点上的<code>/opt/cni/bin</code>中，并且 CNI 执行此二进制文件。在这种情况下，我们指定了<code>loopback</code>二进制文件（它将创建一个<code>loopback</code>类型的网络接口）。如果这是您首次安装 Multus，则可能需要验证 “type” 字段中的插件是否确实在<code>/opt/cni/bin</code>目录中。</li><li><code>additional</code>：此字段以此处为例，每个 CNI 插件都可以在JSON中指定所需的任何配置参数。这些特定于您在 “type” 字段中调用的二进制文件。</li></ul><p>当 CNI 配置更改时，您不需要重新加载或刷新 Kubelets。每次创建和删除 Pod 时都会读取这些内容。因此，如果您更改配置，它将在下一次创建 Pod 时应用。如果现有 Pod 需要新配置，则可能需要重新启动。</p><h3><span id="将配置存储为自定义资源">将配置存储为自定义资源</span></h3><p>因此，我们要创建一个附加接口。让我们创建一个 macvlan 接口供 Pod 使用。我们将创建一个自定义资源，该资源定义接口的 CNI 配置。</p><p>请注意，在以下命令中有一种：<code>NetworkAttachmentDefinition</code>。这是我们配置的名字-它是 Kubernetes 的自定义扩展，定义了我们如何将网络连接到 Pod。</p><p>其次，注意配置字段。您将看到这是一个 CNI 配置，就像我们前面解释的那样。</p><p>最后但非常重要的一点是，在元数据下注意 name 字段-在这里我们为该配置指定名称，这是我们告诉 pod 使用此配置的方式。这里的名称是<code>macvlan-conf</code>-我们正在为 macvlan 创建配置。</p><p>这是创建此示例配置的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: &quot;k8s.cni.cncf.io&#x2F;v1&quot;</span><br><span class="line">kind: NetworkAttachmentDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: macvlan-conf</span><br><span class="line">spec:</span><br><span class="line">  config: &#39;&#123;</span><br><span class="line">      &quot;cniVersion&quot;: &quot;0.3.0&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;macvlan&quot;,</span><br><span class="line">      &quot;master&quot;: &quot;eth0&quot;,</span><br><span class="line">      &quot;mode&quot;: &quot;bridge&quot;,</span><br><span class="line">      &quot;ipam&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;host-local&quot;,</span><br><span class="line">        &quot;subnet&quot;: &quot;192.168.1.0&#x2F;24&quot;,</span><br><span class="line">        &quot;rangeStart&quot;: &quot;192.168.1.200&quot;,</span><br><span class="line">        &quot;rangeEnd&quot;: &quot;192.168.1.216&quot;,</span><br><span class="line">        &quot;routes&quot;: [</span><br><span class="line">          &#123; &quot;dst&quot;: &quot;0.0.0.0&#x2F;0&quot; &#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;gateway&quot;: &quot;192.168.1.1&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;&#39;</span><br></pre></td></tr></table></figure><blockquote><p>本示例使用 eth0 作为主参数，此主参数应与集群中主机上的接口名称匹配。</p></blockquote><p>您可以查看使用 kubectl 创建的配置，方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get network-attachment-definitions</span><br></pre></td></tr></table></figure><p>您可以通过描述它们来获得更多详细信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe network-attachment-definitions macvlan-conf</span><br></pre></td></tr></table></figure><h3><span id="创建一个附加附加接口的pod">创建一个附加附加接口的Pod</span></h3><p>我们将创建一个 pod。就像您之前可能创建的任何pod一样，它看起来都很熟悉，但是，我们将有一个特殊的注释字段-在这种情况下，我们将有一个名为<code>k8s.v1.cni.cncf.io/networks</code>的注释。如上创建的，该字段以逗号分隔的列表列出了 NetworkAttachmentDefinitions 的名称。请注意，在下面的命令中，我们具有 <code>k8s.v1.cni.cncf.io/networks</code> 的注释：<code>macvlan-conf</code>其中<code>macvlan-conf</code>是我们在创建配置时使用的名称。</p><p>让我们继续使用以下命令创建一个 pod：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: samplepod</span><br><span class="line">  annotations:</span><br><span class="line">    k8s.v1.cni.cncf.io&#x2F;networks: macvlan-conf</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: samplepod</span><br><span class="line">    command: [&quot;&#x2F;bin&#x2F;ash&quot;, &quot;-c&quot;, &quot;trap : TERM INT; sleep infinity &amp; wait&quot;]</span><br><span class="line">    image: alpine</span><br></pre></td></tr></table></figure><p>您现在可以检查Pod并查看连接了哪些接口，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -it samplepod -- ip a</span><br></pre></td></tr></table></figure><p>您应该看到，有 3 个接口：</p><ul><li><code>lo</code>环回接口</li><li><code>eth0</code>我们的默认网络</li><li><code>net1</code>是我们使用macvlan配置创建的新接口</li></ul><h3><span id="网络状态-annotations">网络状态 Annotations</span></h3><p>为了确认，请使用<code>kubectl describe pod pod samplepod</code>，然后会有一个注释部分，类似于以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Annotations:        k8s.v1.cni.cncf.io&#x2F;networks: macvlan-conf</span><br><span class="line">                    k8s.v1.cni.cncf.io&#x2F;networks-status:</span><br><span class="line">                      [&#123;</span><br><span class="line">                          &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">                          &quot;ips&quot;: [</span><br><span class="line">                              &quot;10.244.1.73&quot;</span><br><span class="line">                          ],</span><br><span class="line">                          &quot;default&quot;: true,</span><br><span class="line">                          &quot;dns&quot;: &#123;&#125;</span><br><span class="line">                      &#125;,&#123;</span><br><span class="line">                          &quot;name&quot;: &quot;macvlan-conf&quot;,</span><br><span class="line">                          &quot;interface&quot;: &quot;net1&quot;,</span><br><span class="line">                          &quot;ips&quot;: [</span><br><span class="line">                              &quot;192.168.1.205&quot;</span><br><span class="line">                          ],</span><br><span class="line">                          &quot;mac&quot;: &quot;86:1d:96:ff:55:0d&quot;,</span><br><span class="line">                          &quot;dns&quot;: &#123;&#125;</span><br><span class="line">                      &#125;]</span><br></pre></td></tr></table></figure><p>该元数据告诉我们，我们有两个成功运行的 CNI 插件。</p><h3><span id="如果我想要更多接口怎么办">如果我想要更多接口怎么办？</span></h3><p>您可以通过创建更多的自定义资源，然后在pod的注释中引用它们，来向pod添加更多接口。您还可以重复使用配置，例如，要将两个 macvlan 接口附加到 Pod，可以创建如下 Pod：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: samplepod</span><br><span class="line">  annotations:</span><br><span class="line">    k8s.v1.cni.cncf.io&#x2F;networks: macvlan-conf,macvlan-conf</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: samplepod</span><br><span class="line">    command: [&quot;&#x2F;bin&#x2F;ash&quot;, &quot;-c&quot;, &quot;trap : TERM INT; sleep infinity &amp; wait&quot;]</span><br><span class="line">    image: alpine</span><br></pre></td></tr></table></figure><p>请注意，注释现在读取为<code>k8s.v1.cni.cncf.io/networks：macvlan-conf，macvlan-conf</code>。如果我们有两次使用相同的配置，并用逗号分隔。</p><h2><span id="参考资料">参考资料</span></h2><ul><li><a href="https://zhuanlan.zhihu.com/p/73863683" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73863683</a></li></ul><blockquote><p>本文转载自：「 Houmin 的博客 」，原文：<a href="https://url.hi-linux.com/uV1ne" target="_blank" rel="noopener">https://url.hi-linux.com/uV1ne</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 Kubernetes中，网络是非常重要的一个领域。 Kubernetes 本身不提供网络解决方案，但是提供了 CN I规范。这些规范被许多 CNI 插件（例如 WeaveNet，Flannel，Calico 等）遵守。这些插件中任何一个都可以在集群上使用和部署以提供网络解决方案。该网络称为集群的默认网络。此默认网络使 Pods 不仅可以在同一节点上而且可以在群集中的各个节点之间相互通信。&lt;/p&gt;
&lt;p&gt;随着发展，Kubernetes 缺乏支持 VNF 中多个网络接口的所需功能。传统上，网络功能使用多个网络接口分离控制，管理和控制用户/数据的网络平面。他们还用于支持不同的协议，满足不同的调整和配置要求。&lt;/p&gt;
&lt;p&gt;为了解决这个需求，英特尔实现了 MULTUS 的 CNI 插件，其中提供了将多个接口添加到 Pod 的功能。这允许 POD 通过不同的接口连接到多个网络，并且每个接口都将使用其自己的 CNI 插件。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Multus" scheme="https://www.hi-linux.com/tags/Multus/"/>
    
  </entry>
  
  <entry>
    <title>如何在 Mac 上愉快的使用 Docker</title>
    <link href="https://www.hi-linux.com/posts/8579.html"/>
    <id>https://www.hi-linux.com/posts/8579.html</id>
    <published>2022-06-10T01:00:00.000Z</published>
    <updated>2022-06-10T02:17:56.955Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="一-目标任务">一、目标任务</span></h2><p>首先要明确的是, 作为了一个每天在 Linux Server 上 <code>rm -rf</code> 的人来说, 如果想在 Mac 上使用 Docker, 最舒服的也是兼容所有 docker cli 命令行操作即可; 至于图形化的界面完全不需要, 我们并不指望图形化界面能比敲命令快到哪里去, 也不指望图形化界面变为主力; 所以本篇文章的核心目标:</p><ul><li>在 Mac 上使用完整的 docker cli 命令, 包括对基本的 <code>-v</code> 挂载支持</li><li>可以支持 x86 的模拟, 可以为 x86 build 或者运行相关镜像</li><li>在尽可能的情况下可以进行 CPU 架构切换, arm64 与 x86 最好都可以支持</li></ul><a id="more"></a><h2><span id="二-工具选型">二、工具选型</span></h2><p>首先是我们最熟悉的 Docker Desktop, 安装包奇大无比, UI 卡成翔, 启动速度更不用提而且还时不时的卡死, 所以 Docker Desktop 是完全不考虑的; 那么剩下几种方案类型如下:</p><ul><li>VM 虚拟机方案</li><li>Colima 方案</li><li>Lima 方案</li></ul><p><strong>先说结论: Lima YES! VM 虚拟机方案要花钱且难受, Colima 暂且不稳定. Lima 方案直接看第五节.</strong></p><h2><span id="三-虚拟机方案">三、虚拟机方案</span></h2><p>目前在 M1 上, 唯一可用或者说堪用的虚拟机当属 Parallels Desktop, 至于其他的 VBox、VMware 目前还不成熟; 如果纯 qemu 有点过于硬核(愿意自己封装脚本的当我没说); 对于 Parallels Desktop 来说, 我们需要购买开发版本的 License, 因为我们需要借助 <code>prlctl</code> 来实现一些自动化 , 一年好几百… 经过测试这种方案也有一定可行性:</p><ul><li>1、首先通过 PD 创建 Ubuntu 之类的虚拟机</li><li>2、在虚拟机里安装好 Docker</li><li>3、通过 cli 程序启动虚拟机, 并且将 <code>~</code> rw 挂载到虚拟机里</li></ul><p>基于这个方案我个人尝试过, 曾经写过一个 <a href="https://github.com/mritd/pd/blob/010101042308ecbad805cffebb93973b55db4ff2/helper/prlctl_wrapper.go#L332" target="_blank" rel="noopener">PD</a> 的小工具来辅助完成挂载动作. 但是这种工具有一些明显的缺点:</p><ul><li>目前不支持 x86 的模拟, 可通过 binfmt 缓解, 但是不完善</li><li>虚拟机要花钱且需要虚拟机 cli 支持完善</li></ul><h2><span id="四-colima-方案">四、Colima 方案</span></h2><p>Colima 号称是专门为了解决 Mac 平台容器化工具链的, 但是实际测试发现目前 Colima 还不算稳定, 有时可能会有一些小问题; 当然 Colima 最大的问题是: <strong>可自定义化程度不高, 底层基于 Lima.</strong> Colima 具体的使用方式啥的这里暂不详细描述, 目前还不稳定不太推荐.</p><h2><span id="五-lima-方案">五、Lima 方案</span></h2><p>Lima 目前是基于 QEMU 的自动化 VM 方案, 当前由于其出色设计, 借助 Cloud Init 可以在很多阶段帮助我们完成 hook; 所以不论是装个 Docker 还是 k8s, 亦或是弄个其他的东西都很方便; 而且很多方案比如 docker 官方都有相关样例, 我们可以直接照抄外加做点自定义.</p><h3><span id="51-lima-安装">5.1、Lima 安装</span></h3><p>Lima 在 Mac 下安装相对简单, 以下命令将安装 master 分支版本.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install lima --HEAD</span><br></pre></td></tr></table></figure><p>在正常情况下, 安装 Lima 会附带安装 QEMU, 如果本机已经安装 QEMU, 可能需要执行以下命令<strong>将 QEMU 升级到 7.0</strong>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew upgrade qemu</span><br></pre></td></tr></table></figure><p>为了使用 docker, 还需要通过 brew 安装一下 docker cli:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install docker</span><br></pre></td></tr></table></figure><h3><span id="52-lima-使用">5.2、Lima 使用</span></h3><p>默认情况下 Lima 安装完成后会生成一个 <code>lima</code> 的快捷命令, 目前不太推荐使用, 原因是看起来方便一点但是没法控制太多参数, <strong>所以仍然建议使用标准的 <code>limactl</code> 命令进行操作.</strong> limactl 使用方式如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Lima: Linux virtual machines</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  limactl [command]</span><br><span class="line"></span><br><span class="line">Examples:</span><br><span class="line">  Start the default instance:</span><br><span class="line">  $ limactl start</span><br><span class="line"></span><br><span class="line">  Open a shell:</span><br><span class="line">  $ lima</span><br><span class="line"></span><br><span class="line">  Run a container:</span><br><span class="line">  $ lima nerdctl run -d --name nginx -p 8080:80 nginx:alpine</span><br><span class="line"></span><br><span class="line">  Stop the default instance:</span><br><span class="line">  $ limactl stop</span><br><span class="line"></span><br><span class="line">  See also example YAMLs: &#x2F;opt&#x2F;homebrew&#x2F;share&#x2F;doc&#x2F;lima&#x2F;examples</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  completion    Generate the autocompletion script for the specified shell</span><br><span class="line">  copy          Copy files between host and guest</span><br><span class="line">  delete        Delete an instance of Lima.</span><br><span class="line">  edit          Edit an instance of Lima</span><br><span class="line">  factory-reset Factory reset an instance of Lima</span><br><span class="line">  help          Help about any command</span><br><span class="line">  info          Show diagnostic information</span><br><span class="line">  list          List instances of Lima.</span><br><span class="line">  prune         Prune garbage objects</span><br><span class="line">  shell         Execute shell in Lima</span><br><span class="line">  show-ssh      Show the ssh command line</span><br><span class="line">  start         Start an instance of Lima</span><br><span class="line">  stop          Stop an instance</span><br><span class="line">  sudoers       Generate &#x2F;etc&#x2F;sudoers.d&#x2F;lima file for enabling vmnet.framework support</span><br><span class="line">  validate      Validate YAML files</span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">      --debug     debug mode</span><br><span class="line">  -h, --help      help for limactl</span><br><span class="line">  -v, --version   version for limactl</span><br><span class="line"></span><br><span class="line">Use &quot;limactl [command] --help&quot; for more information about a command.</span><br></pre></td></tr></table></figure><h3><span id="53-lima-配置文件">5.3、Lima 配置文件</span></h3><p>Lima 通过读取一个 yaml 配置描述文件来决定如何创建一个虚拟机, 该文件基本结构如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"># 定义每个平台架构需要使用的启动镜像</span><br><span class="line">images:</span><br><span class="line">- location: &quot;https:&#x2F;&#x2F;cloud-images.ubuntu.com&#x2F;releases&#x2F;22.04&#x2F;release&#x2F;ubuntu-22.04-server-cloudimg-amd64.img&quot;</span><br><span class="line">  arch: &quot;x86_64&quot;</span><br><span class="line">- location: &quot;https:&#x2F;&#x2F;cloud-images.ubuntu.com&#x2F;releases&#x2F;22.04&#x2F;release&#x2F;ubuntu-22.04-server-cloudimg-arm64.img&quot;</span><br><span class="line">  arch: &quot;aarch64&quot;</span><br><span class="line"></span><br><span class="line"># 定义虚拟机需要使用哪个架构启动(对应上面的镜像)</span><br><span class="line">arch: &quot;x86_64&quot;</span><br><span class="line"></span><br><span class="line"># CPU 数量</span><br><span class="line">cpus: 4</span><br><span class="line"></span><br><span class="line"># 内存大小</span><br><span class="line">memory: &quot;16G&quot;</span><br><span class="line"></span><br><span class="line"># 磁盘大小</span><br><span class="line">disk: &quot;100G&quot;</span><br><span class="line"></span><br><span class="line"># 虚拟机与 macOS 宿主机挂载时使用的挂载技术</span><br><span class="line"># 目前推荐 9p, 可换成 sshfs, 但是 sshfs 会有权限问题</span><br><span class="line">mountType: 9p</span><br><span class="line"></span><br><span class="line"># 定义虚拟机和 macOS 宿主机有哪些目录可以共享</span><br><span class="line">mounts:</span><br><span class="line">- location: &quot;~&quot;</span><br><span class="line">  # 定义虚拟机对这个目录是否可写</span><br><span class="line">  writable: true</span><br><span class="line">  9p:</span><br><span class="line">    # 对于可写的共享目录, cache 推荐类型为 mmap, 不写好像默认 fscache</span><br><span class="line">    cache: &quot;mmap&quot;</span><br><span class="line">- location: &quot;&#x2F;tmp&#x2F;lima&quot;</span><br><span class="line">  writable: true</span><br><span class="line">  9p:</span><br><span class="line">    cache: &quot;mmap&quot;</span><br><span class="line"># containerd is managed by Docker, not by Lima, so the values are set to false here.</span><br><span class="line">containerd:</span><br><span class="line">  system: false</span><br><span class="line">  user: false</span><br><span class="line"></span><br><span class="line"># cloud-init hook 定义</span><br><span class="line">provision:</span><br><span class="line"># 定义以什么权限在虚拟机内执行脚本</span><br><span class="line">- mode: system</span><br><span class="line">  # This script defines the host.docker.internal hostname when hostResolver is disabled.</span><br><span class="line">  # It is also needed for lima 0.8.2 and earlier, which does not support hostResolver.hosts.</span><br><span class="line">  # Names defined in &#x2F;etc&#x2F;hosts inside the VM are not resolved inside containers when</span><br><span class="line">  # using the hostResolver; use hostResolver.hosts instead (requires lima 0.8.3 or later).</span><br><span class="line">  script: |</span><br><span class="line">    #!&#x2F;bin&#x2F;sh</span><br><span class="line">    sed -i &#39;s&#x2F;host.lima.internal.*&#x2F;host.lima.internal host.docker.internal&#x2F;&#39; &#x2F;etc&#x2F;hosts</span><br><span class="line">- mode: system</span><br><span class="line">  script: |</span><br><span class="line">    #!&#x2F;bin&#x2F;bash</span><br><span class="line">    set -eux -o pipefail</span><br><span class="line">    if command -v docker &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1; then</span><br><span class="line">      docker run --platform&#x3D;linux&#x2F;amd64 --privileged --rm tonistiigi&#x2F;binfmt --install all</span><br><span class="line">      exit 0</span><br><span class="line">    else</span><br><span class="line">      export DEBIAN_FRONTEND&#x3D;noninteractive</span><br><span class="line">      curl -fsSL https:&#x2F;&#x2F;get.docker.com | sh</span><br><span class="line">      docker run --platform&#x3D;linux&#x2F;amd64 --privileged --rm tonistiigi&#x2F;binfmt --install all</span><br><span class="line">      # NOTE: you may remove the lines below, if you prefer to use rootful docker, not rootless</span><br><span class="line">      systemctl disable --now docker</span><br><span class="line">      apt-get install -y uidmap dbus-user-session</span><br><span class="line">    fi</span><br><span class="line">- mode: user</span><br><span class="line">  script: |</span><br><span class="line">    #!&#x2F;bin&#x2F;bash</span><br><span class="line">    set -eux -o pipefail</span><br><span class="line">    systemctl --user start dbus</span><br><span class="line">    dockerd-rootless-setuptool.sh install</span><br><span class="line">    docker context use rootless</span><br><span class="line">probes:</span><br><span class="line">- script: |</span><br><span class="line">    #!&#x2F;bin&#x2F;bash</span><br><span class="line">    set -eux -o pipefail</span><br><span class="line">    if ! timeout 30s bash -c &quot;until command -v docker &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1; do sleep 3; done&quot;; then</span><br><span class="line">      echo &gt;&amp;2 &quot;docker is not installed yet&quot;</span><br><span class="line">      exit 1</span><br><span class="line">    fi</span><br><span class="line">    if ! timeout 30s bash -c &quot;until pgrep rootlesskit; do sleep 3; done&quot;; then</span><br><span class="line">      echo &gt;&amp;2 &quot;rootlesskit (used by rootless docker) is not running&quot;</span><br><span class="line">      exit 1</span><br><span class="line">    fi</span><br><span class="line">  hint: See &quot;&#x2F;var&#x2F;log&#x2F;cloud-init-output.log&quot;. in the guest</span><br><span class="line">hostResolver:</span><br><span class="line">  # hostResolver.hosts requires lima 0.8.3 or later. Names defined here will also</span><br><span class="line">  # resolve inside containers, and not just inside the VM itself.</span><br><span class="line">  hosts:</span><br><span class="line">    host.docker.internal: host.lima.internal</span><br><span class="line">portForwards:</span><br><span class="line">- guestSocket: &quot;&#x2F;run&#x2F;user&#x2F;&#123;&#123;.UID&#125;&#125;&#x2F;docker.sock&quot;</span><br><span class="line">  hostSocket: &quot;&#123;&#123;.Dir&#125;&#125;&#x2F;sock&#x2F;docker.sock&quot;</span><br><span class="line"># 自己定义的启动后消息输出</span><br><span class="line">message: |</span><br><span class="line">  To run &#96;docker&#96; on the host (assumes docker-cli is installed), run the following commands:</span><br><span class="line">  ------</span><br><span class="line">  docker context create amd64 --docker &quot;host&#x3D;unix:&#x2F;&#x2F;&#123;&#123;.Dir&#125;&#125;&#x2F;sock&#x2F;docker.sock&quot;</span><br><span class="line">  docker context use amd64</span><br><span class="line">  ------</span><br></pre></td></tr></table></figure><h3><span id="54-启动-vm">5.4、启动 VM</span></h3><p>limactl 命令提供了一个 <code>start</code> 子命令用于启动一个虚拟机, 子命令接受一个参数, 这个参数形式不同会产生不同的行为:</p><ul><li>如果参数为一个文件路径, 则假定文件为一个 lima 虚拟机的 yaml 配置, 读取并启动</li><li>如果参数是单纯字符串, 首先尝试从已存在的虚拟机中查找名字相同的, 找到则立即启动</li><li>如果参数是单纯字符串, 且未找到已存在同名的虚拟机, 则尝试通过内置模版来创建一个新的虚拟机</li></ul><p>以上面我自己定义的 docker 配置文件为例, 我们直接启动这个配置既可以创建一个 docker 虚拟机:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limactl start .&#x2F;docker-amd64.yaml</span><br></pre></td></tr></table></figure><p>启动后会提示是否编辑然后再启动, 这是为了使用同一个配置来启动多个 vm 使用的, 所以不编辑直接启动即可:</p><p><img src="https://img.hi-linux.com/staticfile/dJwuuJ-2022-06-09-OmbQn6.png" alt></p><p>稍等片刻后虚拟机将启动成功:</p><p><img src="https://img.hi-linux.com/staticfile/MhWILZ-2022-06-09-fazpql.png" alt></p><p>启动完成后, <strong>执行最下面打印出的两条命令, 即可在宿主机上完整的使用 <code>docker</code>.</strong> 其本质上利用 docker context 功能, 然后通过将虚拟机中的 sock 文件挂载到宿主机, 并配置 docker context 来实现无缝使用 docker 命令.</p><h3><span id="55-虚拟机调整">5.5、虚拟机调整</span></h3><p>某些情况下, 我们需要定制一些 VM 里的配置, 在定制时主要需要调整配置文件的 <code>provision</code> 部分; 在该部分中, 如果 <code>mode</code> 被定义为 <code>system</code> 则会以 root 用户执行相关命令, 否则以普通用户来执行命令. <strong>需要注意的是, 我们定义的脚本需要具有幂等性, 因为脚本在每次都会执行一次, 所以一般对于可能造成数据擦除动作的命令都要写好判断逻辑, 避免重复执行.</strong></p><p>关于文件挂载, 这里推荐使用 <code>9p</code> 类型, 未来 lima 将完全切换到该挂载方式; 同时经过测试<strong>目前仅有 <code>9p</code> 挂载模式下, 本地目录 rw 映射到虚拟机时不会出现权限问题, sshfs 方式挂载如果遇到 <code>chown</code> 之类的命令会造成权限错误, 可能导致容器启动失败(例如 mysql).</strong></p><p>在测试虚拟机配置过程中, 可以直接使用 <code>limactl delete -f xxxx</code> 来强制删除目标虚拟机, 然后重新启动即可; <strong>虚拟机名称默认与 yaml 文件名相同, 可使用 <code>limactl ls</code> 命令查看.</strong></p><h3><span id="56-多平台兼容">5.6、多平台兼容</span></h3><p>在上面我的 docker 配置样例中, 每次虚拟机启动完成后会自动安装 binfmt:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --platform&#x3D;linux&#x2F;amd64 --privileged --rm tonistiigi&#x2F;binfmt --install all</span><br></pre></td></tr></table></figure><p>这样能保证无论 Lima 虚拟机原始架构是什么, 都能运行其他平台的 docker 镜像; 典型的例如某些 openjdk8 镜像只有 amd64 的版本, 但是在 lima 虚拟机为 aarch64 的情况下仍然可以使用.</p><p>除了这种 “速度较快” 的跨架构运行方式, lima 还支持直接在 VM 中定义架构, 这样在 qemu 启动时则会直接从 VM 系统层模拟目标架构; <strong>这种方式的好处是对目标架构兼容性很好, 但是运行速度会更慢.</strong> 调整 VM 架构只需要修改 <code>arch</code> 配置即可(注意, 目标架构的镜像一定要配置好):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 定义每个平台架构需要使用的启动镜像</span><br><span class="line">images:</span><br><span class="line">- location: &quot;https:&#x2F;&#x2F;cloud-images.ubuntu.com&#x2F;releases&#x2F;22.04&#x2F;release&#x2F;ubuntu-22.04-server-cloudimg-amd64.img&quot;</span><br><span class="line">  arch: &quot;x86_64&quot;</span><br><span class="line">- location: &quot;https:&#x2F;&#x2F;cloud-images.ubuntu.com&#x2F;releases&#x2F;22.04&#x2F;release&#x2F;ubuntu-22.04-server-cloudimg-arm64.img&quot;</span><br><span class="line">  arch: &quot;aarch64&quot;</span><br><span class="line"></span><br><span class="line"># 定义本虚拟机需要使用哪个架构启动(对应会使用上面目标架构的镜像)</span><br><span class="line">arch: &quot;aarch64&quot;</span><br></pre></td></tr></table></figure><h2><span id="六-总结">六、总结</span></h2><p>目前整体来看, Docker Desktop 在 mac 上基本上是很难用的, Colima 现在还不太成熟, 适合轻度使用 docker 的用户; 而重度使用 docker 并且有定制化需求的用户还是推荐 Lima 虚拟机; 同时 Lima 也支持很多操作系统, 官方有大量的<a href="https://github.com/lima-vm/lima/tree/master/examples" target="_blank" rel="noopener">样例模版</a>(包括 k8s、k3s、podman 等), 非常适合重度容器使用者.</p><blockquote><p>本文转载自：「 bleem 的博客 」，原文：<a href="https://url.hi-linux.com/DZxIp/" target="_blank" rel="noopener">https://url.hi-linux.com/DZxIp/</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、目标任务&quot;&gt;一、目标任务&lt;/h2&gt;
&lt;p&gt;首先要明确的是, 作为了一个每天在 Linux Server 上 &lt;code&gt;rm -rf&lt;/code&gt; 的人来说, 如果想在 Mac 上使用 Docker, 最舒服的也是兼容所有 docker cli 命令行操作即可; 至于图形化的界面完全不需要, 我们并不指望图形化界面能比敲命令快到哪里去, 也不指望图形化界面变为主力; 所以本篇文章的核心目标:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 Mac 上使用完整的 docker cli 命令, 包括对基本的 &lt;code&gt;-v&lt;/code&gt; 挂载支持&lt;/li&gt;
&lt;li&gt;可以支持 x86 的模拟, 可以为 x86 build 或者运行相关镜像&lt;/li&gt;
&lt;li&gt;在尽可能的情况下可以进行 CPU 架构切换, arm64 与 x86 最好都可以支持&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 Kubectl 优雅的滚动更新应用</title>
    <link href="https://www.hi-linux.com/posts/28253.html"/>
    <id>https://www.hi-linux.com/posts/28253.html</id>
    <published>2022-06-02T01:00:00.000Z</published>
    <updated>2022-06-02T06:02:39.234Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Kubernetes 中的 Pod 通常应该是 “Running” 状态，然而有时候我们需要针对正在运行的 Pod 调度到其它的节点或是基于其它特殊的原因，将正常运行的 Pod 进行重启。Pod 的重启方式也有不少，比如常见删除正在运行的 Pod 让其创建新的 Pod 实例（单个 Pod 无法直接使用该方式）。以下罗列出几种常见的方式仅供备忘：</p><h2><span id="方法1滚动重启方法推荐">方法1：滚动重启方法[推荐]</span></h2><p>自 Kubernetes 1.15 版本就开始支持滚动重启部署。这是 Kubernetes 中最快的重启机制，因为它是新增的。下面给出的命令会一个一个地关闭并重新启动部署中的每个 Pod。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rollout restart deployment nginx-deploy</span><br></pre></td></tr></table></figure><blockquote><p>提示：由于大多数容器仍在运行，因此整个过程是纵享丝滑–无感知的。</p></blockquote><a id="more"></a><h2><span id="方法2环境变量方法">方法2：环境变量方法</span></h2><p>这种方式就是给运行的容器分配一个新的环境变量，来强制 Pod 重新启动。例如: 增加一个容器部署日期（实际可能未使用到该变量）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl set env deployment nginx-deploy DEPLOY_DATE&#x3D;&quot;$(date)&quot;</span><br></pre></td></tr></table></figure><blockquote><p>提示：在上面的场景中，使用了<code>set env</code> 修改了环境变量，deployment [deployment name] 选择了你的deployment，DEPLOY DATE=&quot;$(date)&quot; 修改了deployment date 并导致pod 更新。这种方式也是无感知的。</p></blockquote><h2><span id="方法3副本扩缩容">方法3：副本扩/缩容</span></h2><p>当副本数量设置为 0 时，Kubernetes 会消除它不再需要的副本。设置大于 0 后，Kubernetes 会生成新的副本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale --replicas&#x3D;0 deployment nginx-deploy</span><br><span class="line">$ kubectl scale --replicas&#x3D;N deployment nginx-deploy</span><br></pre></td></tr></table></figure><p>以上方式会中断业务，我们也可以使用不中断业务的方式来重启应用。比如记录当前的 Pod 副本数量，使用 <code>scale --replicas</code> 命令来分配一个大于当前的副本数值的值，使用 <code>kubectl delete pod</code> 方式删除旧 Pod，最后将使用<code>scale --replicas</code> 还原成正常的副本数量。</p><blockquote><p>提示：不建议使用这种方式来重启应用。</p></blockquote><h2><span id="结论">结论</span></h2><p>Kubernetes 是一个非常牛X的编排系统，然而只要是系统，就一定会出现问题。当出现问题时，可以利用上述 3 种方式快速安全地让您的应用程序恢复并运行，而不会影响用户体验。</p><h2><span id="参考引用">参考引用</span></h2><ul><li>[1] <a href="https://linuxhint.com/kubectl-rollout-restart/" target="_blank" rel="noopener">https://linuxhint.com/kubectl-rollout-restart/</a></li><li>[2] <a href="https://kubernetes.io/zh/docs/reference/kubectl/cheatsheet/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/kubectl/cheatsheet/</a></li></ul><blockquote><p>本文转载自：「 枯惠 」，原文：<a href="https://tinyurl.com/yse2usy9" target="_blank" rel="noopener">https://tinyurl.com/yse2usy9</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes 中的 Pod 通常应该是 “Running” 状态，然而有时候我们需要针对正在运行的 Pod 调度到其它的节点或是基于其它特殊的原因，将正常运行的 Pod 进行重启。Pod 的重启方式也有不少，比如常见删除正在运行的 Pod 让其创建新的 Pod 实例（单个 Pod 无法直接使用该方式）。以下罗列出几种常见的方式仅供备忘：&lt;/p&gt;
&lt;h2 id=&quot;方法1：滚动重启方法-推荐&quot;&gt;方法1：滚动重启方法[推荐]&lt;/h2&gt;
&lt;p&gt;自 Kubernetes 1.15 版本就开始支持滚动重启部署。这是 Kubernetes 中最快的重启机制，因为它是新增的。下面给出的命令会一个一个地关闭并重新启动部署中的每个 Pod。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl rollout restart deployment nginx-deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;提示：由于大多数容器仍在运行，因此整个过程是纵享丝滑–无感知的。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 Skopeo 做一个优雅的镜像搬运工</title>
    <link href="https://www.hi-linux.com/posts/55385.html"/>
    <id>https://www.hi-linux.com/posts/55385.html</id>
    <published>2022-06-01T01:00:00.000Z</published>
    <updated>2022-06-01T08:29:56.618Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="1-基础介绍">1. 基础介绍</span></h2><p>描述: 作为公司内部 PaaS toB 产品的打包发布人员，容器镜像对我们打工人而言就像是工地上的砖头 🧱，而我的一部分工作就是将这些砖头在各个仓库之间搬来搬去，最终将这些砖头打包放在产品的安装包中，形成一个完整的 PaaS 产品安装包。</p><ul><li>Q: 在 PaaS (平台即服务)中的大家常说的 ToB 与 ToC 到底是什么?</li></ul><blockquote><p>ToC 面向普通用户服务, 主要是让用户体验感好，解决用户使用方面的问题记录，并返回给前后端开发。<br>ToB 是面向企业用户服务, 产品可用、其中最关键是让Boss使用Happly!</p></blockquote><ul><li>Q: 假如有如下场景，我们从 dockerhub 公共仓库中下载一个 GB 以上的镜像，到本地的私有仓库中，我想通常你会这样做先 <code>docker pull</code> 到本地，然后使用 <code>docker tag</code> 更改为私有仓库地址加上镜像名称版本，最后再使用<code>docker push</code> 上传镜像到私有仓库中，以供其它内网机器拉取并使用。虽然该方法是可行，但是如果有多个大于 GB 以上的镜像需要上传到私有仓库，每次都要先解压 layer 到本地，然后再压缩 layer 上传到私有仓库中，你能想象此过程花费的时间有多久吗? 对于我们运维工程师来说时间就是金钱，所以需想尽一切方法来节约时间成本，那有没有一种办法可以直接将 registry 上的 blob 复制到另一个 registry，中间过程不涉及对镜像 layer 的解压缩，这岂不美哉。</li></ul><blockquote><p>解决方案当然是存在的，如果你不想使用docker进行images镜像拉取上传，我们完成可以使用skope工具来完全替代 docker-cli 来搬运镜像，skopeo是一个命令行实用程序，可对容器映像和映像存储库执行各种操作。</p></blockquote><a id="more"></a><p><strong>什么是 Skopeo ?</strong></p><p>skopeo 使用 API V2 Registry，例如 Docker Registry、Atomic Registry、私有Registry、本地目录和本地 OCI 镜像目录。skopeo 不需要运行守护进程，它可以执行的操作包括：</p><ul><li>通过各种存储机制复制镜像，例如，可以在不需要特权的情况下将镜像从一个 Registry 复制到另一个 Registry</li><li>检测远程镜像并查看其属性，包括其图层，无需将镜像拉到本地</li><li>从镜像库中删除镜像</li><li>当存储库需要时，skopeo 可以传递适当的凭据和证书进行身份验证</li></ul><p><strong>镜像存储特点</strong></p><p>根据 Robin 大佬在 《镜像仓库中镜像存储的原理解析》文章里得出的结论：</p><ul><li><p>通过 Registry API 获得的两个镜像仓库中相同镜像的 manifest 信息完全相同。</p></li><li><p>两个镜像仓库中相同镜像的 manifest 信息的存储路径和内容完全相同。</p></li><li><p>两个镜像仓库中相同镜像的 blob 信息的存储路径和内容完全相同</p></li></ul><p><strong>项目信息</strong></p><ul><li>Github 官方地址: <a href="https://github.com/containers/skopeo" target="_blank" rel="noopener">https://github.com/containers/skopeo</a></li><li>Gitee mirror: <a href="https://gitee.com/mirrors/skopeo" target="_blank" rel="noopener">https://gitee.com/mirrors/skopeo</a></li></ul><h2><span id="2-安装编译">2. 安装编译</span></h2><p>描述: Skopeo 官方安装&amp;编译方式参考文档: <a href="https://github.com/containers/skopeo/blob/main/install.md" target="_blank" rel="noopener">https://github.com/containers/skopeo/blob/main/install.md</a></p><p>本节安装实践环境将在 Ubuntu 20.04 LTS 以及 docker 20.10.12 中进行实践源码编译以及 apt 仓库源下载安装实践。</p><h3><span id="21-源码编译静态">2.1 源码编译（静态）</span></h3><p>描述: 要构建 skopeo 二进制文件您至少需要 Go 1.12 版本以上, 其次构建 skopeo 有两种方法，即<code>在容器中</code>或者在本地环境中构建(安装环境较为复杂), 此处为了方便演示将采用容器方式进行编译构建。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 1.拉取skopeo源码到本地</span><br><span class="line">$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;containers&#x2F;skopeo.git  # https:&#x2F;&#x2F;github.com&#x2F;containers&#x2F;skopeo.git</span><br><span class="line">$ cd skopeo</span><br><span class="line">$ sed -i &#39;s#proxy.golang.org#https:&#x2F;&#x2F;goproxy.cn#g&#39; skopeo&#x2F;Makefile</span><br><span class="line"></span><br><span class="line"># 2.下载镜像构建依赖</span><br><span class="line">$ sudo apt-get install go-md2man  # 构建手册依赖于 go-md2man。</span><br><span class="line">$ whereis go-md2man  # 获得本机中go-md2man路径。</span><br><span class="line"></span><br><span class="line"># 3.构建静态二进制文件</span><br><span class="line">$ BUILD_IMAGE&#x3D;&quot;golang:latest&quot;</span><br><span class="line">$ docker run --name skopeo-build -v $PWD:&#x2F;src -v &#x2F;usr&#x2F;bin&#x2F;go-md2man:&#x2F;go&#x2F;bin&#x2F;go-md2man -w &#x2F;src -e CGO_ENABLED&#x3D;0 -e GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn,direct $&#123;BUILD_IMAGE&#125; \</span><br><span class="line">sh -c &#39;make BUILDTAGS&#x3D;containers_image_openpgp GO_DYN_FLAGS&#x3D;&#39;</span><br><span class="line">  # CGO_CFLAGS&#x3D;&quot;&quot; CGO_LDFLAGS&#x3D;&quot;&quot; GO111MODULE&#x3D;on go build -mod&#x3D;vendor  -ldflags &#39;-X main.gitCommit&#x3D;df4d82b960572c19e9333381a203c0ac475766d7 &#39; -gcflags &quot;&quot; -tags  &quot;containers_image_openpgp&quot; -o bin&#x2F;skopeo .&#x2F;cmd&#x2F;skopeo</span><br><span class="line"></span><br><span class="line"># 4.运行编译生成的skopeo可执行文件</span><br><span class="line">$ cd .&#x2F;bin # &#x2F;opt&#x2F;software&#x2F;skopeo&#x2F;bin</span><br><span class="line">$ .&#x2F;skopeo --help</span><br><span class="line">  # Various operations with container images and container image registries</span><br><span class="line">  # .......</span><br><span class="line">  # Use &quot;skopeo [command] --help&quot; for more information about a command.</span><br></pre></td></tr></table></figure><p><strong>构建关键参数解析:</strong></p><ul><li>CGO_ENABLED=0 : 设置该环境变量, 禁用 CGO 会导致 Go 在可能的情况下更喜欢静态连接库，而不是动态链接到系统库 (解决可以在Ubuntu或者其它linux发行版中执行编译后二进制文件)。</li><li>GOPROXY=https://goproxy.cn,direct : Golong 依赖下载镜像站,加快go get依赖拉拉取。</li><li>BUILDTAGS=containers_image_openpgp : 设置该make参数消除了对libgpgme 及其配套库的依赖, Skopeo 的一些特性依赖于非 Go 库，例如 libgpgme 和 libdevmapper。</li><li>GO_DYN_FLAGS= : 清空该make参数 (否则会强制创建动态可执行文件)</li></ul><h3><span id="22-分发包安装">2.2 分发包安装</span></h3><p>描述: skopeo 可能已经打包在您的发行版中，此处以 ubuntu 20.04 为例进行安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 1.只支持 Ubuntu 20.10 and newer 发行版 </span><br><span class="line">$ sudo apt-get -y update</span><br><span class="line">$ sudo apt-get -y install skopeo</span><br><span class="line"></span><br><span class="line"># 2.但 Kubic 项目为 Ubuntu 20.04 提供了软件包，我们可以通过如下方式在我们及其上进行安装。</span><br><span class="line">$ . &#x2F;etc&#x2F;os-release</span><br><span class="line">$ echo &quot;deb https:&#x2F;&#x2F;download.opensuse.org&#x2F;repositories&#x2F;devel:&#x2F;kubic:&#x2F;libcontainers:&#x2F;stable&#x2F;xUbuntu_$&#123;VERSION_ID&#125;&#x2F; &#x2F;&quot; | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;devel:kubic:libcontainers:stable.list</span><br><span class="line">$ curl -L https:&#x2F;&#x2F;download.opensuse.org&#x2F;repositories&#x2F;devel:&#x2F;kubic:&#x2F;libcontainers:&#x2F;stable&#x2F;xUbuntu_$&#123;VERSION_ID&#125;&#x2F;Release.key | sudo apt-key add -</span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get -y upgrade</span><br><span class="line">$ sudo apt-get -y install skopeo</span><br></pre></td></tr></table></figure><h3><span id="23-容器安装运行">2.3 容器安装运行</span></h3><p>Skopeo 容器镜像可在 <a href="http://quay.io/skopeo/stable:latest" target="_blank" rel="noopener">quay.io/skopeo/stable:latest</a> 获得, 例如我们采用podman命令进行如下操作:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ podman run docker:&#x2F;&#x2F;quay.io&#x2F;skopeo&#x2F;stable:latest copy --help</span><br></pre></td></tr></table></figure><h2><span id="3-快速上手">3. 快速上手</span></h2><h3><span id="31-命令浅析">3.1 命令浅析</span></h3><p>描述: skopen 是操作各种容器映像和容器映像仓库的工具，其使用方法及其可用命令如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;skopeo --help    # 子命令可采用如下命令 skopeo [command] --help 命令</span><br><span class="line">Usage:</span><br><span class="line">  skopeo [flags]</span><br><span class="line">  skopeo [command]</span><br><span class="line">Available Commands: </span><br><span class="line">  copy          # 复制一个镜像从 A 到 B，这里的 A 和 B 可以为本地 docker 镜像或者 registry 上的镜像；</span><br><span class="line">  delete        # 删除一个镜像 tag，可以是本地 docker 镜像或者 registry 上的镜像；</span><br><span class="line">  help          # 帮助查看</span><br><span class="line">  inspect       # 查看一个镜像的 manifest 或者 image config 详细信息；</span><br><span class="line">  list-tags     # 列出存储库名称指定的镜像的tag</span><br><span class="line">  login           # 登陆某个镜像仓库,类似于 docker login 命令</span><br><span class="line">  logout          # 退出某个已认证的镜像仓库, 类似于 docker logout 命令</span><br><span class="line">  manifest-digest # 计算文件的清单摘要是一个sha256sum 值</span><br><span class="line">  standalone-sign   # 使用本地文件创建签名</span><br><span class="line">  standalone-verify # 验证本地文件的签名</span><br><span class="line">  sync              # 将一个或多个图像从一个位置同步到另一个位置 (该功能非常Nice)</span><br><span class="line">Flags:</span><br><span class="line">    --command-timeout duration   # 命令超时时间(单位秒)</span><br><span class="line">    --debug                      # 启用debug模式</span><br><span class="line">    --insecure-policy            # 在不进行任何策略检查的情况下运行该工具（如果没有配置 policy 的话需要加上该参数）</span><br><span class="line">    --override-arch ARCH         # 处理镜像时覆盖客户端 CPU 体系架构，如在 amd64 的机器上用 skopeo 处理 arm64 的镜像</span><br><span class="line">    --override-os OS             # 处理镜像时覆盖客户端 OS</span><br><span class="line">    --override-variant VARIANT   # 处理镜像时使用VARIANT而不是运行架构变量</span><br><span class="line">    --policy string              # 信任策略文件的路径 (为镜像配置安全策略情况下使用)</span><br><span class="line">    --registries.d DIR           # 在目录中使用Registry配置文件（例如，用于容器签名存储）</span><br><span class="line">    --tmpdir string              # 用于存储临时文件的目录</span><br><span class="line">-h, --help                       help for skopeo </span><br><span class="line">-v, --version                    Version for Skopeo</span><br></pre></td></tr></table></figure><h3><span id="32-skopeo-初体验">3.2 Skopeo 初体验</span></h3><p>描述: 在使用体验skopeo之前，我们需要了解一哈 Skopeo 可以在那些图像和存储库类型上执行镜像操作(官网文档走一波)：</p><table><thead><tr><th style="text-align:center">Repository types</th><th>Describe</th><th>Example</th></tr></thead><tbody><tr><td style="text-align:center"><code>containers-storage:docker-reference</code></td><td>适用于后端是 Podman, CRI-O, Buildah 的情况</td><td><code>containers-storage:</code></td></tr><tr><td style="text-align:center"><code>dir:path</code></td><td>适用于将manifest, layer tarballs 和 signatures 存储为单独文件的现有本地目录路径的情况</td><td><code>dir:/tmp/alpine:latest</code></td></tr><tr><td style="text-align:center"><code>docker://docker-reference</code></td><td>适用于Registry中实现&quot;Docker Registry HTTP API V2&quot;的镜像的情况</td><td><code>docker://harbor.weiyigeek.top/myblog:v2.8</code></td></tr><tr><td style="text-align:center"><code>docker-archive:path[:docker-reference]</code></td><td>适用于采用<code>docker save</code>命令导出镜像以tar格式存储的文件的情况</td><td><code>docker-archive:alpine.tar</code></td></tr><tr><td style="text-align:center"><code>docker-daemon:docker-reference</code></td><td>适用于存储在 docker 守护进程内部存储中的图像的情况</td><td><code>docker-daemon:alpine:latest</code></td></tr><tr><td style="text-align:center"><code>oci:path:tag</code></td><td>适用于符合&quot;Open Container Image Layout Specification&quot;的目录中的图像标记</td><td><code>oci:alpine:latest</code></td></tr></tbody></table><blockquote><p>温馨提示: 同一个镜像存在的方式有可能不同，不同类型方式存储对镜像的 layer 处理的方式也不一样,。</p></blockquote><p><strong>测试环境说明</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Docker 官方 hub 仓库 -&gt; docker.io             # 官网地址: https:&#x2F;&#x2F;hub.docker.com&#x2F;</span><br><span class="line">私有 Harbor 仓库     -&gt; harbor.weiyigeek.top</span><br><span class="line">临时创建的本地仓库    -&gt; 192.168.12.111:5000   # 一梭子解决: docker run -d -p 5000:5000 --name registry -v &#x2F;opt&#x2F;data&#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry registry:2</span><br></pre></td></tr></table></figure><blockquote><p>说明: 上述仓库都是在Registry中支持Docker Registry HTTP API V2版本的。</p></blockquote><h4><span id="321-skopeo-loginloout-远程仓库-auth">3.2.1 Skopeo login/loout - 远程仓库 Auth</span></h4><p>描述: 在使用 skopeo 前如果 src 或 dest 镜像是在 registry 仓库中的并且配置了非 public 的镜像需要相应的 auth 认证, 此时我们可以使用 <code>docker login</code> 或者 <code>skopeo login</code> 的方式登录到 registry 仓库，然后默认会在<code>~/.docker</code>目录下生成 registry 登录配置文件 config.json ,该文件里保存了登录需要的验证信息，skopeo 拿到该验证信息才有权限往 registry push 镜像。</p><ul><li><strong>登陆认证</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># (1) skopeo login 登陆示例 (两种方式)</span><br><span class="line">$ skopeo login -u WeiyiGeek -p testpassword harbor.weiyigeek.top</span><br><span class="line">  # Login Succeeded!</span><br><span class="line"></span><br><span class="line"># (2) docker login 登陆示例</span><br><span class="line">$ docker login -u WeiyiGeek docker.io</span><br><span class="line">$ docker login -u WeiyiGeek harbor.weiyigeek.top</span><br><span class="line">$ docker login -u anonymous -p anonymous 192.168.12.111:5000  # 实际上临时仓库没有配置认证, 账号密码随意即可。</span><br><span class="line">  # WARNING! Using --password via the CLI is insecure. Use --password-stdin.</span><br><span class="line">  # WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class="line">  # Configure a credential helper to remove this warning. See</span><br><span class="line">  # https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class="line">  # Login Succeeded</span><br><span class="line"></span><br><span class="line"># (3) docker login 生成的 registry 登录配置文件（base64编码安全性不多说）</span><br><span class="line">$ cat ~&#x2F;.docker&#x2F;config.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;auths&quot;: &#123;</span><br><span class="line">    &quot;192.168.12.111:5000&quot;: &#123;</span><br><span class="line">        &quot;auth&quot;: &quot;YW5v*******Q&#x3D;&#x3D;&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">    &quot;harbor.weiyigeek.top&quot;: &#123;</span><br><span class="line">        &quot;auth&quot;: &quot;YWR*******LkA&#x3D;&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">    &quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;: &#123;</span><br><span class="line">        &quot;auth&quot;: &quot;d2Vp**************kyZA&#x3D;&#x3D;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>注销认证</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo logout myregistrydomain.com:5000</span><br></pre></td></tr></table></figure><blockquote><p>温馨提示: 如果企业自建harbor仓库(一般都会设置自签证书)或者其它私有仓库配置证书,为了防止出错建议进行以下操作(正式环境请根据需要进行配置)。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># (1) 在 &#x2F;etc&#x2F;docker&#x2F;daemon.json 中配置 insecure-registries 字段,表示允许不安全的仓库。</span><br><span class="line">&quot;insecure-registries&quot;: [&quot;harbor.weiyigeek.top&quot;,&quot;192.168.12.111:5000&quot;]</span><br><span class="line"> </span><br><span class="line"># (2) 从官方文档可知客户端要使用tls与Harbor通信使用的还是&#96;自签证书&#96;，那么必须建立一个目录：&#96;&#x2F;etc&#x2F;docker&#x2F;certs.d&#96;</span><br><span class="line"># 如果配置可能会出现 x509: certificate signed by unknown authority 错误提示。</span><br><span class="line">$ mkdir -vp &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top</span><br><span class="line">$ cp -a &#x2F;deployapp&#x2F;harbor&#x2F;harbor.pem  &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top&#x2F;harbor.crt</span><br></pre></td></tr></table></figure><blockquote><p>温馨提示: 为了防止后续执行 skopeo 命令操作镜像时出错, 建议忽略 policy 策略和证书校验参数如下:</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--insecure-policy \</span><br><span class="line">--src-tls-verify&#x3D;false \ </span><br><span class="line">--dest-tls-verify&#x3D;false \</span><br></pre></td></tr></table></figure><h4><span id="322-skopeo-inspect-检查存储库中的镜像">3.2.2 Skopeo inspect - 检查存储库中的镜像</span></h4><p>描述: skopeo 能够检查容器 Registry 上的存储库并获取图像层。检查命令获取存储库的清单，它能够向您显示有关整个存储库或标签的类似 <code>docker inspect</code> 的 json 输出。与 docker inspect 相比,此工具可帮助您在拉取存储库或标签之前收集有用的信息(使用磁盘空间), 检查命令可以向您显示给定存储库可用的标签、映像具有的标签、映像的创建日期和操作系统等。</p><p>支持传输的类型 : <code>containers-storage, dir, docker, docker-archive, docker-daemon, oci, oci-archive, ostree, tarball</code></p><ul><li>步骤 01. 显示 busybox:latest 镜像的属性相关信息。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo inspect docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest</span><br><span class="line">&#123;</span><br><span class="line">  &quot;Name&quot;: &quot;docker.io&#x2F;library&#x2F;busybox&quot;,</span><br><span class="line">  &quot;Digest&quot;: &quot;sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678&quot;,</span><br><span class="line">  &quot;RepoTags&quot;: [</span><br><span class="line">      &quot;1&quot;,</span><br><span class="line">      &quot;1-glibc&quot;,</span><br><span class="line">      &quot;1-musl&quot;,</span><br><span class="line">      &quot;1-ubuntu&quot;,</span><br><span class="line">      &quot;1-uclibc&quot;,</span><br><span class="line">      &quot;1.21-ubuntu&quot;,</span><br><span class="line">      &quot;1.21.0-ubuntu&quot;,</span><br><span class="line">        .......          # 镜像历史tags</span><br><span class="line">      &quot;unstable-uclibc&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;Created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">  &quot;DockerVersion&quot;: &quot;20.10.7&quot;,</span><br><span class="line">  &quot;Labels&quot;: null,</span><br><span class="line">  &quot;Architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;Os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;Layers&quot;: [</span><br><span class="line">      &quot;sha256:5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>步骤 02. 显示 busybox:latest 镜像的容器配置相关信息。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo inspect --config docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest  | jq</span><br><span class="line">&#123;</span><br><span class="line">  &quot;created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">  &quot;architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;config&quot;: &#123;</span><br><span class="line">    &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Cmd&quot;: [</span><br><span class="line">      &quot;sh&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;rootfs&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;layers&quot;,</span><br><span class="line">    &quot;diff_ids&quot;: [</span><br><span class="line">      &quot;sha256:01fd6df81c8ec7dd24bbbd72342671f41813f992999a3471b9d9cbc44ad88374&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;history&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:40.833034683Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop) ADD file:6db446a57cbd2b7f4cfde1f280177b458390ed5a6d1b54c6169522bc2c4d838e in &#x2F; &quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop)  CMD [\&quot;sh\&quot;]&quot;,</span><br><span class="line">      &quot;empty_layer&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>步骤 03. 显示未经验证的图像 Digest（摘要）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo inspect --format &quot;Name: &#123;&#123;.Name&#125;&#125; Digest: &#123;&#123;.Digest&#125;&#125;&quot; docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest</span><br></pre></td></tr></table></figure><h4><span id="323-skopeo-copy-仓库镜像拷贝">3.2.3 Skopeo copy - 仓库镜像拷贝</span></h4><p>描述: skopeo 可以在各种存储机制之间复制容器镜像，支持包括容器仓库(<code>The Quay, Docker Hub, OpenShift, GCR, ，Artifactory ...</code>)以及容器存储后端 (<code>Podman, CRI-O, Docker</code>) 等、本地目录、本地 OCI-layout 目录。</p><p>例如，此处我从 hub 仓库复制 <code>busybox:latest</code> 镜像到私有 harbor 仓库中,在从私有 harbor 仓库中拷贝到本地指定目录中。</p><ul><li>步骤 01. 从 regsitry A 到 registry B 复制 busybox:latest 镜像。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo copy --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false --dest-authfile &#x2F;root&#x2F;.docker&#x2F;config.json docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa done</span><br><span class="line">  # Copying config beae173cca done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br></pre></td></tr></table></figure><blockquote><p>Tips: 由上述日志可以看到 skopeo 是直接从 registry 中 copy 镜像 layer 的 blob 文件，传输是镜像在 registry 中存储的原始格式。</p></blockquote><ul><li>步骤 02. 从 registry B 复制 busybox:latest 镜像到本地 busybox:latest 目录中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo copy --insecure-policy --src-tls-verify&#x3D;false docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest dir:busybox:latest</span><br><span class="line"># Getting image source signatures</span><br><span class="line"># Copying blob 5cc84ad355aa done</span><br><span class="line"># Copying config beae173cca done</span><br><span class="line"># Writing manifest to image destination</span><br><span class="line"># Storing signatures</span><br><span class="line"></span><br><span class="line">$ ls &amp;&amp; tree busybox\:latest&#x2F;</span><br><span class="line">busybox:latest&#x2F;</span><br><span class="line">├── 5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa   # blob 块文件 -&gt; vnd.docker.image.rootfs.diff.tar.gzip</span><br><span class="line">├── beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a   # 镜像配置信息文件 -&gt; vnd.docker.container.image.v1+json </span><br><span class="line">├── manifest.json</span><br><span class="line">└── version</span><br><span class="line">0 directories, 4 files</span><br><span class="line"></span><br><span class="line"># 查看镜像的 manifest 文件</span><br><span class="line">$ cat busybox\:latest&#x2F;manifest.json</span><br><span class="line">&#123;</span><br><span class="line">   &quot;schemaVersion&quot;: 2,</span><br><span class="line">   &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.distribution.manifest.v2+json&quot;,</span><br><span class="line">   &quot;config&quot;: &#123;</span><br><span class="line">      &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.container.image.v1+json&quot;,</span><br><span class="line">      &quot;size&quot;: 1456,</span><br><span class="line">      &quot;digest&quot;: &quot;sha256:beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;layers&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 772788,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa&quot;</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 根据 manifest 文件查看镜像的 image config 文件 (存放镜像Build指令与镜像相关配置信息)</span><br><span class="line">$ jq &#39;.&#39; busybox\:latest&#x2F;beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">&#123;</span><br><span class="line">  &quot;architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;config&quot;: &#123;</span><br><span class="line">    &quot;Hostname&quot;: &quot;&quot;,</span><br><span class="line">    &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">    &quot;User&quot;: &quot;&quot;,</span><br><span class="line">    &quot;AttachStdin&quot;: false,</span><br><span class="line">    &quot;AttachStdout&quot;: false,</span><br><span class="line">    &quot;AttachStderr&quot;: false,</span><br><span class="line">    &quot;Tty&quot;: false,</span><br><span class="line">    &quot;OpenStdin&quot;: false,</span><br><span class="line">    &quot;StdinOnce&quot;: false,</span><br><span class="line">    &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Cmd&quot;: [</span><br><span class="line">      &quot;sh&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Image&quot;: &quot;sha256:da658412c37aa24e561eb7e16c61bc82a9711340d8fb5cf1a8f39d8e96d7f723&quot;,</span><br><span class="line">    &quot;Volumes&quot;: null,</span><br><span class="line">    &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">    &quot;Entrypoint&quot;: null,</span><br><span class="line">    &quot;OnBuild&quot;: null,</span><br><span class="line">    &quot;Labels&quot;: null</span><br><span class="line">  &#125;,</span><br><span class="line">........</span><br><span class="line">  &quot;history&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:40.833034683Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop) ADD file:6db446a57cbd2b7f4cfde1f280177b458390ed5a6d1b54c6169522bc2c4d838e in &#x2F; &quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop)  CMD [\&quot;sh\&quot;]&quot;,</span><br><span class="line">      &quot;empty_layer&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;rootfs&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;layers&quot;,</span><br><span class="line">    &quot;diff_ids&quot;: [</span><br><span class="line">      &quot;sha256:01fd6df81c8ec7dd24bbbd72342671f41813f992999a3471b9d9cbc44ad88374&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>步骤 03. 将 busybox:latest 镜像从 registry B 复制到本地目录，并以 OCI 格式保存</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo copy --insecure-policy --src-tls-verify&#x3D;false docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest oci:busybox-latest</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa done</span><br><span class="line">  # Copying config 48edd9298a done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br><span class="line"></span><br><span class="line">$ tree -h busybox-latest&#x2F;</span><br><span class="line">  # busybox-latest&#x2F;</span><br><span class="line">  # ├── [4.0K]  blobs</span><br><span class="line">  # │   └── [4.0K]  sha256</span><br><span class="line">  # │       ├── [ 347]  1612e16ff3f6b0d09eefdc4e9d5c5c0624f63032743e016585b095b958778016</span><br><span class="line">  # │       ├── [ 575]  48edd9298a25de2c97cd574a5523026f87576c6b7202330a2b60ce7d304ec307</span><br><span class="line">  # │       └── [755K]  5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa  # Blob 块 -</span><br><span class="line">  # ├── [ 186]  index.json</span><br><span class="line">  # └── [  31]  oci-layout</span><br><span class="line">  # 2 directories, 5 files</span><br></pre></td></tr></table></figure><ul><li>步骤 04. 将 <code>alpine:3.13.1</code> 镜像从 docker 本地存储（ /var/lib/docker/image） push 到 registry B中(实际上替代 docker push 功能)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 在  &#x2F;var&#x2F;lib&#x2F;docker&#x2F; 目录中此处主要关心 image (主要存放镜像中layer层的元数据) 和 overlay2 (各层的具体信息)</span><br><span class="line">$ docker images alpine:3.13.1</span><br><span class="line">  # REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">  # alpine       3.13.1    e50c909a8df2   11 months ago   5.61MB</span><br><span class="line"></span><br><span class="line">$ skopeo copy --insecure-policy --dest-tls-verify&#x3D;false --dest-authfile &#x2F;root&#x2F;.docker&#x2F;config.json docker-daemon:alpine:3.13.1 docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;alpine:3.13.1</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 1119ff37d4a9 done</span><br><span class="line">  # Copying config e50c909a8d done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/640-20220520095506113-2022-05-20-jxlRy3.png" alt></p><h4><span id="324-skopeo-sync-镜像同步命令">3.2.4 Skopeo sync - 镜像同步命令</span></h4><p>描述: Skopeo sync可以在容器仓库和本地目录之间同步镜像，其功能类似于阿里云的 image-syncer (<a href="https://github.com/AliyunContainerService/image-syncer" target="_blank" rel="noopener">https://github.com/AliyunContainerService/image-syncer</a>) 工具, 实际上其比 image-syncer 更强大、灵活性更强一些，废话不多说实践为王。</p><p>skopeo sync 镜像同步文件示例:</p><ul><li>步骤 01. 将仓库中所有 busybox 镜像版本同步到本地目录。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo sync --insecure-policy --src-tls-verify&#x3D;false --src docker --dest dir harbor.weiyigeek.top&#x2F;devops&#x2F;busybox &#x2F;tmp</span><br><span class="line">  # INFO[0000] Tag presence check                            imagename&#x3D;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox tagged&#x3D;false</span><br><span class="line">  # INFO[0000] Getting tags                                  image&#x3D;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox</span><br><span class="line">  # INFO[0000] Copying image ref 1&#x2F;1                         from&#x3D;&quot;docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest&quot; to&#x3D;&quot;dir:&#x2F;tmp&#x2F;busybox:latest&quot;</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa done</span><br><span class="line">  # Copying config beae173cca done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br><span class="line">  # INFO[0000] Synced 1 images from 1 sources</span><br><span class="line"></span><br><span class="line">$ tree -h &#x2F;tmp&#x2F;busybox:latest</span><br><span class="line">&#x2F;tmp&#x2F;busybox:latest</span><br><span class="line">├── [755K]  5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa</span><br><span class="line">├── [1.4K]  beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">├── [ 527]  manifest.json</span><br><span class="line">└── [  33]  version</span><br><span class="line">0 directories, 4 files</span><br></pre></td></tr></table></figure><ul><li>步骤 02. 从本地目录 <code>/tmp/</code> 同步到 docker 的 hub 容器仓库中，此外我们可以通过浏览器看到 <code>weiyigeek</code> 用户下的 <code>busybox</code> 镜像 (<a href="https://hub.docker.com/u/weiyigeek" target="_blank" rel="noopener">https://hub.docker.com/u/weiyigeek</a>)。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo sync --insecure-policy --dest-tls-verify&#x3D;false --src dir --dest docker &#x2F;tmp weiyigeek</span><br><span class="line">  # INFO[0000] Copying image ref 1&#x2F;1                         from&#x3D;&quot;dir:&#x2F;tmp&#x2F;busybox:latest&quot; to&#x3D;&quot;docker:&#x2F;&#x2F;weiyigeek&#x2F;busybox:latest&quot;</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa skipped: already exists</span><br><span class="line">  # Copying config beae173cca done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br><span class="line">  # INFO[0021] Synced 1 images from 1 sources</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/640-20220520095506152-2022-05-20-wOfOkf.png" alt></p><ul><li>步骤 03. 从 hub 容器仓库中同步 alpine-jenkins-jnlp:v2.285 镜像到本地临时容器仓库中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo sync --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false --src docker --dest docker weiyigeek&#x2F;alpine-jenkins-jnlp:v2.285 192.168.12.111:5000&#x2F;</span><br><span class="line">  # INFO[0000] Tag presence check imagename&#x3D;&quot;weiyigeek&#x2F;alpine-jenkins-jnlp:v2.285&quot; tagged&#x3D;true</span><br><span class="line">  # INFO[0000] Copying image ref 1&#x2F;1 from&#x3D;&quot;docker:&#x2F;&#x2F;weiyigeek&#x2F;alpine-jenkins-jnlp:v2.285&quot; to&#x3D;&quot;docker:&#x2F;&#x2F;192.168.12.111:5000&#x2F;alpine-jenkins-jnlp:v2.285&quot;</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 68517a8c32d3 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;-------------------------------] 45.0MiB &#x2F; 255.7MiB</span><br><span class="line">  # Copying blob 4c0d98bf9879 done</span><br></pre></td></tr></table></figure><ul><li>步骤 04. 以配置文件方式进行同步, 首先我们需要准备一个需要同步的资源清单。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># YAML 文件内容（用于 **--src yaml** 的源）</span><br><span class="line">$ cat &lt;&lt;&#39;EOF&#39; &gt; skopeo-sync.yml</span><br><span class="line">registry.example.com:</span><br><span class="line">  images:</span><br><span class="line">    busybox: []</span><br><span class="line">    redis:</span><br><span class="line">      - &quot;1.0&quot;</span><br><span class="line">      - &quot;2.0&quot;</span><br><span class="line">      - &quot;sha256:111111&quot;</span><br><span class="line">  images-by-tag-regex:</span><br><span class="line">      nginx: ^1\.13\.[12]-alpine-perl$</span><br><span class="line">  credentials:</span><br><span class="line">      username: john</span><br><span class="line">      password: this is a secret</span><br><span class="line">  tls-verify: true</span><br><span class="line">  cert-dir: &#x2F;home&#x2F;john&#x2F;certs</span><br><span class="line">quay.io:</span><br><span class="line">  tls-verify: false</span><br><span class="line">  images:</span><br><span class="line">    coreos&#x2F;etcd:</span><br><span class="line">      - latest</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 以yaml文件方式进行同步镜像到 my-registry.local.lan&#x2F;repo&#x2F; 仓库中</span><br><span class="line">$ skopeo sync --src yaml --dest docker skopeo-sync.yml my-registry.local.lan&#x2F;repo&#x2F;</span><br></pre></td></tr></table></figure><p>skopeo-sync.yml 文件中镜像匹配复制镜像说明:</p><ul><li><a href="http://registry.example.com/busybox" target="_blank" rel="noopener">registry.example.com/busybox</a> : 所有版本的镜像.</li><li><a href="http://registry.example.com/redis" target="_blank" rel="noopener">registry.example.com/redis</a> : 标记为“1.0”和“2.0”的图像以及带有摘要的图像&quot;sha256:0000000000000000000000000000000011111111111111111111111111111111&quot;.</li><li><a href="http://registry.example.com/nginx" target="_blank" rel="noopener">registry.example.com/nginx</a> : 图片标记为“1.13.1-alpine-perl”和“1.13.2-alpine-perl”.</li><li><a href="http://quay.io/coreos/etcd" target="_blank" rel="noopener">quay.io/coreos/etcd</a> : 拉取最新版本的镜像。</li></ul><h4><span id="325-skopeo-list-tags-仓库中镜像-tag-查看">3.2.5 Skopeo list-tags - 仓库中镜像 Tag 查看</span></h4><p>描述: 利用该命令我们可以列出 registry 上的某个镜像的所有 tag ，它是使用标准的 registry API 来获取镜像 tag。</p><p>简单示例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo list-tags docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest</span><br></pre></td></tr></table></figure><h4><span id="326-skopeo-delete-删除仓库中镜像-tag">3.2.6 Skopeo delete - 删除仓库中镜像 Tag</span></h4><p>描述: 使用该命令我们可以删除镜像 Tag,注意此处仅仅只是通过 registry API 来删除镜像的 tag（即删除了 tag 对 manifests 文件的引用）并非真正将镜像删除掉，如果想要删除镜像的 layer 还是需要通过 registry GC 的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 方式1. 利用 skopeo delete</span><br><span class="line">$ skopeo delete docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest --debug</span><br><span class="line">  # DEBU[0000] Loading registries configuration &quot;&#x2F;etc&#x2F;containers&#x2F;registries.conf&quot;</span><br><span class="line">  # DEBU[0000] Found credentials for harbor.weiyigeek.top in credential helper containers-auth.json in file &#x2F;home&#x2F;weiyigeek&#x2F;.docker&#x2F;config.json</span><br><span class="line">  # DEBU[0000] Using registries.d directory &#x2F;etc&#x2F;containers&#x2F;registries.d for sigstore configuration</span><br><span class="line">  # DEBU[0000]  No signature storage configuration found for harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest, using built-in default file:&#x2F;&#x2F;&#x2F;home&#x2F;weiyigeek&#x2F;.local&#x2F;share&#x2F;containers&#x2F;sigstore</span><br><span class="line">  # DEBU[0000] Looking for TLS certificates and private keys in &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top</span><br><span class="line">  # DEBU[0000]  crt: &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top&#x2F;harbor.crt</span><br><span class="line">  # DEBU[0000] GET https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F;</span><br><span class="line">  # DEBU[0000] Ping https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F; status 401</span><br><span class="line">  # DEBU[0000] GET https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;service&#x2F;token?account&#x3D;WeiyiGeek&amp;scope&#x3D;repository%3Adevops%2Fbusybox%3A%2A&amp;service&#x3D;harbor-registry</span><br><span class="line">  # DEBU[0000] GET https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F;devops&#x2F;busybox&#x2F;manifests&#x2F;latest</span><br><span class="line">  # DEBU[0000] DELETE https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F;devops&#x2F;busybox&#x2F;manifests&#x2F;sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  # DEBU[0000] Deleting &#x2F;home&#x2F;weiyigeek&#x2F;.local&#x2F;share&#x2F;containers&#x2F;sigstore&#x2F;devops&#x2F;busybox@sha256&#x3D;62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee&#x2F;signature-1</span><br><span class="line"></span><br><span class="line"># 方式2.利用 curl 命令进行 registery 进行删除 Tag。</span><br><span class="line">$ curl --header &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -I -X GET http:&#x2F;&#x2F;192.168.12.111:5000&#x2F;v2&#x2F;busybox&#x2F;manifests&#x2F;latest</span><br><span class="line">  # HTTP&#x2F;1.1 200 OK</span><br><span class="line">  # Content-Length: 527</span><br><span class="line">  # Content-Type: application&#x2F;vnd.docker.distribution.manifest.v2+json</span><br><span class="line">  # Docker-Content-Digest: sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  # Docker-Distribution-Api-Version: registry&#x2F;2.0</span><br><span class="line">  # Etag: &quot;sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee&quot;</span><br><span class="line">  # X-Content-Type-Options: nosniff</span><br><span class="line">  # Date: Thu, 20 Jan 2022 13:18:28 GMT</span><br><span class="line"></span><br><span class="line"># 一把梭织搞定</span><br><span class="line">$ Docker-Content-Digest&#x3D;$(curl -s --header &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -I -X GET http:&#x2F;&#x2F;192.168.12.111:5000&#x2F;v2&#x2F;busybox&#x2F;manifests&#x2F;latest | grep &quot;Docker-Content-Digest&quot; | cut -d &#39; &#39; -f 2)</span><br><span class="line">$ curl -I -X DELETE http:&#x2F;&#x2F;192.168.12.111:5000&#x2F;v2&#x2F;busybox&#x2F;manifests&#x2F;$&#123;Docker-Content-Digest&#125;</span><br></pre></td></tr></table></figure><h2><span id="4-镜像同步最佳实践">4. 镜像同步最佳实践</span></h2><p>本节，主要参考我前同事木子.其博客地址(<a href="https://blog.k8s.li" target="_blank" rel="noopener">https://blog.k8s.li</a>)。</p><h3><span id="41-指定文本中镜像同步">4.1 指定文本中镜像同步</span></h3><p>假如,给你一个镜像列表 images-list.txt, 其格式如下, 我们可以直接采用 shell 脚本调用 skopeo 进行执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># images-list.txt</span><br><span class="line">cat &lt;&lt;&#39;EOF&#39; &gt; images-list.txt</span><br><span class="line">kubesphere&#x2F;kube-apiserver:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-scheduler:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-proxy:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-controller-manager:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-apiserver:v1.19.8</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><strong>同步的 shell 脚本 <a href="http://skopeo-copy.sh" target="_blank" rel="noopener">skopeo-copy.sh</a></strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">GREEN_COL&#x3D;&quot;\\033[32;1m&quot;</span><br><span class="line">RED_COL&#x3D;&quot;\\033[1;31m&quot;</span><br><span class="line">NORMAL_COL&#x3D;&quot;\\033[0;39m&quot;</span><br><span class="line"></span><br><span class="line">SOURCE_REGISTRY&#x3D;$1</span><br><span class="line">TARGET_REGISTRY&#x3D;$2</span><br><span class="line"></span><br><span class="line"># shell 变量赋值，当没有从命令行中传递值给SOURCE_REGISTRY和TARGET_REGISTRY变量时，便采用下述值进行覆盖。</span><br><span class="line">: $&#123;IMAGES_LIST_FILE:&#x3D;&quot;images-list.txt&quot;&#125;</span><br><span class="line">: $&#123;TARGET_REGISTRY:&#x3D;&quot;hub.k8s.li&quot;&#125;</span><br><span class="line">: $&#123;SOURCE_REGISTRY:&#x3D;&quot;docker.io&quot;&#125;</span><br><span class="line"></span><br><span class="line">BLOBS_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">REPO_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line"></span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">CURRENT_NUM&#x3D;0</span><br><span class="line">ALL_IMAGES&#x3D;&quot;$(sed -n &#39;&#x2F;#&#x2F;d;s&#x2F;:&#x2F;:&#x2F;p&#39; $&#123;IMAGES_LIST_FILE&#125; | sort -u)&quot;</span><br><span class="line">TOTAL_NUMS&#x3D;$(echo &quot;$&#123;ALL_IMAGES&#125;&quot; | wc -l)</span><br><span class="line"></span><br><span class="line"># shopeo 拷贝函数，注意其传递的参数，此处值得学习记录。</span><br><span class="line">skopeo_copy() &#123;</span><br><span class="line"> if skopeo copy --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false \</span><br><span class="line"> --override-arch amd64 --override-os linux -q docker:&#x2F;&#x2F;$1 docker:&#x2F;&#x2F;$2; then</span><br><span class="line">  echo -e &quot;$GREEN_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 successful $NORMAL_COL&quot;</span><br><span class="line"> else</span><br><span class="line">  echo -e &quot;$RED_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 failed $NORMAL_COL&quot;</span><br><span class="line">  exit 2</span><br><span class="line"> fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 调用拷贝函数并记录当前执行序号。</span><br><span class="line">for image in $&#123;ALL_IMAGES&#125;; do</span><br><span class="line"> let CURRENT_NUM&#x3D;$&#123;CURRENT_NUM&#125;+1</span><br><span class="line"> skopeo_copy $&#123;SOURCE_REGISTRY&#125;&#x2F;$&#123;image&#125; $&#123;TARGET_REGISTRY&#125;&#x2F;$&#123;image&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ul><li><strong>执行命令和结果:</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ bash sync.sh docker.io localhost:5000</span><br><span class="line">Progress: 1&#x2F;143 sync docker.io&#x2F;alpine:3.14 to localhost:5000&#x2F;alpine:3.14 successful</span><br><span class="line">Progress: 2&#x2F;143 sync docker.io&#x2F;busybox:1.31.1 to localhost:5000&#x2F;busybox:1.31.1 successful</span><br><span class="line">....</span><br><span class="line">Progress: 142&#x2F;143 sync docker.io&#x2F;weaveworks&#x2F;scope:1.13.0 to localhost:5000&#x2F;weaveworks&#x2F;scope:1.13.0 successful</span><br><span class="line">Progress: 143&#x2F;143 sync docker.io&#x2F;wordpress:4.8-apache to localhost:5000&#x2F;wordpress:4.8-apache successful</span><br></pre></td></tr></table></figure><h3><span id="42-使用-registry-存储特性同步">4.2 使用 registry 存储特性同步</span></h3><p>描述: 将镜像从 registry 中同步到本地目录，使用 registry 存储的特性，将本地目录中的镜像转换成 registry 存储的格式, 这样的好处就是可以去除一些 skopeo dir 中重复的 layers，减少镜像的总大小。</p><ul><li><a href="http://convert-images.sh" target="_blank" rel="noopener">convert-images.sh</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">GREEN_COL&#x3D;&quot;\\033[32;1m&quot;</span><br><span class="line">RED_COL&#x3D;&quot;\\033[1;31m&quot;</span><br><span class="line">NORMAL_COL&#x3D;&quot;\\033[0;39m&quot;</span><br><span class="line"></span><br><span class="line"># 命令行参数</span><br><span class="line">SOURCE_REGISTRY&#x3D;$1</span><br><span class="line">TARGET_REGISTRY&#x3D;$2</span><br><span class="line">IMAGES_DIR&#x3D;$2</span><br><span class="line"></span><br><span class="line">: $&#123;IMAGES_DIR:&#x3D;&quot;images&quot;&#125;</span><br><span class="line">: $&#123;IMAGES_LIST_FILE:&#x3D;&quot;images-list.txt&quot;&#125;</span><br><span class="line">: $&#123;SOURCE_REGISTRY:&#x3D;&quot;docker.io&quot;&#125;</span><br><span class="line">: $&#123;TARGET_REGISTRY:&#x3D;&quot;hub.k8s.li&quot;&#125;</span><br><span class="line"></span><br><span class="line"># hub.k8s.li 仓库服务器中的目录</span><br><span class="line">BLOBS_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">REPO_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line"></span><br><span class="line"># 记录当前数和总镜像数</span><br><span class="line">CURRENT_NUM&#x3D;0</span><br><span class="line">ALL_IMAGES&#x3D;&quot;$(sed -n &#39;&#x2F;#&#x2F;d;s&#x2F;:&#x2F;:&#x2F;p&#39; $&#123;IMAGES_LIST_FILE&#125; | sort -u)&quot;</span><br><span class="line">TOTAL_NUMS&#x3D;$(echo &quot;$&#123;ALL_IMAGES&#125;&quot; | wc -l)</span><br><span class="line"></span><br><span class="line"># 从远程仓库同步指定镜像到本地目录中。</span><br><span class="line">skopeo_sync() &#123;</span><br><span class="line"> if skopeo sync --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false \</span><br><span class="line"> --override-arch amd64 --override-os linux --src docker --dest dir $1 $2 &gt; &#x2F;dev&#x2F;null; then</span><br><span class="line">  echo -e &quot;$GREEN_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 successful $NORMAL_COL&quot;</span><br><span class="line"> else</span><br><span class="line">  echo -e &quot;$RED_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 failed $NORMAL_COL&quot;</span><br><span class="line">  exit 2</span><br><span class="line"> fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">convert_images() &#123;</span><br><span class="line"> rm -rf $&#123;IMAGES_DIR&#125;; mkdir -p $&#123;IMAGES_DIR&#125;</span><br><span class="line"> for image in $&#123;ALL_IMAGES&#125;; do</span><br><span class="line">  let CURRENT_NUM&#x3D;$&#123;CURRENT_NUM&#125;+1</span><br><span class="line">  </span><br><span class="line">  # 取 images-list.txt 文本中的每一行，并分隔存储。</span><br><span class="line">  image_name&#x3D;$&#123;image%%:*&#125;</span><br><span class="line">  image_tag&#x3D;$&#123;image##*:&#125;</span><br><span class="line">  image_repo&#x3D;$&#123;image%%&#x2F;*&#125;</span><br><span class="line"></span><br><span class="line">  # 函数调用 从仓库同步镜像到本地images目录</span><br><span class="line">  skopeo_sync $&#123;SOURCE_REGISTRY&#125;&#x2F;$&#123;image&#125; $&#123;IMAGES_DIR&#125;&#x2F;$&#123;image_repo&#125;</span><br><span class="line"></span><br><span class="line">  # 在本地images目录中，取得get image manifest sha256sum 信息</span><br><span class="line">  manifest&#x3D;&quot;$&#123;IMAGES_DIR&#125;&#x2F;$&#123;image&#125;&#x2F;manifest.json&quot;</span><br><span class="line">  manifest_sha256&#x3D;$(sha256sum $&#123;manifest&#125; | awk &#39;&#123;print $1&#125;&#39;)      # 62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  mkdir -p $&#123;BLOBS_PATH&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125; # docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&#x2F;62&#x2F;62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  ln -f $&#123;manifest&#125; $&#123;BLOBS_PATH&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;&#x2F;data  #  该 data 文件实际上是镜像的 manifest.json 文件。</span><br><span class="line"></span><br><span class="line">  # make image repositories dir</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;&#123;_uploads,_layers,_manifests&#125;</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;&#123;current,index&#x2F;sha256&#125;</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line"></span><br><span class="line">  # create image tag manifest link file</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link  # sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732deer</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;current&#x2F;link</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link</span><br><span class="line"></span><br><span class="line">  # link image layers file to registry blobs dir</span><br><span class="line">  for layer in $(sed &#39;&#x2F;v1Compatibility&#x2F;d&#39; $&#123;manifest&#125; | grep -Eo &quot;\b[a-f0-9]&#123;64&#125;\b&quot;); do  # 匹配 manifest.json 中&quot;digest&quot;两个不带sha256的值</span><br><span class="line">    mkdir -p $&#123;BLOBS_PATH&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;                 # 5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa 、 beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">    mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;  # 5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa 、 beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">    echo -n &quot;sha256:$&#123;layer&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;&#x2F;link  # sha256:5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa</span><br><span class="line">    ln -f $&#123;IMAGES_DIR&#125;&#x2F;$&#123;image&#125;&#x2F;$&#123;layer&#125; $&#123;BLOBS_PATH&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data     # 复制images目录中 &quot;application&#x2F;vnd.docker.container.image.v1+json&quot; 容器配置 config 与 多个 &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot; layer </span><br><span class="line">  done</span><br><span class="line"> done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">convert_images</span><br></pre></td></tr></table></figure><ul><li><a href="http://install.sh" target="_blank" rel="noopener">install.sh</a> : 使用这个脚本将 registry 存储中的镜像转换成 skopeo dir 的方式，然后再将镜像同步到 registry 中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">REGISTRY_DOMAIN&#x3D;&quot;harbor.k8s.li&quot;</span><br><span class="line">REGISTRY_PATH&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;registry&quot;</span><br><span class="line"></span><br><span class="line"># 切换到 registry 存储主目录下</span><br><span class="line">cd $&#123;REGISTRY_PATH&#125;</span><br><span class="line">gen_skopeo_dir() &#123;</span><br><span class="line">   # 定义 registry 存储的 blob 目录 和 repositories 目录，方便后面使用</span><br><span class="line">    BLOB_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">    REPO_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line">    # 定义生成 skopeo 目录</span><br><span class="line">    SKOPEO_DIR&#x3D;&quot;docker&#x2F;skopeo&quot;</span><br><span class="line">    # 通过 find 出 current 文件夹可以得到所有带 tag 的镜像，因为一个 tag 对应一个 current 目录</span><br><span class="line">    for image in $(find $&#123;REPO_DIR&#125; -type d -name &quot;current&quot;); do</span><br><span class="line">        # 根据镜像的 tag 提取镜像的名字</span><br><span class="line">        name&#x3D;$(echo $&#123;image&#125; | awk -F &#39;&#x2F;&#39; &#39;&#123;print $5&quot;&#x2F;&quot;$6&quot;:&quot;$9&#125;&#39;)</span><br><span class="line">        link&#x3D;$(cat $&#123;image&#125;&#x2F;link | sed &#39;s&#x2F;sha256:&#x2F;&#x2F;&#39;)</span><br><span class="line">        mfs&#x3D;&quot;$&#123;BLOB_DIR&#125;&#x2F;$&#123;link:0:2&#125;&#x2F;$&#123;link&#125;&#x2F;data&quot;</span><br><span class="line">        # 创建镜像的硬链接需要的目录</span><br><span class="line">        mkdir -p &quot;$&#123;SKOPEO_DIR&#125;&#x2F;$&#123;name&#125;&quot;</span><br><span class="line">        # 硬链接镜像的 manifests 文件到目录的 manifest 文件</span><br><span class="line">        ln $&#123;mfs&#125; $&#123;SKOPEO_DIR&#125;&#x2F;$&#123;name&#125;&#x2F;manifest.json</span><br><span class="line">        # 使用正则匹配出所有的 sha256 值，然后排序去重</span><br><span class="line">        layers&#x3D;$(grep -Eo &quot;\b[a-f0-9]&#123;64&#125;\b&quot; $&#123;mfs&#125; | sort -n | uniq)</span><br><span class="line">        for layer in $&#123;layers&#125;; do</span><br><span class="line">          # 硬链接 registry 存储目录里的镜像 layer 和 images config 到镜像的 dir 目录</span><br><span class="line">            ln $&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data $&#123;SKOPEO_DIR&#125;&#x2F;$&#123;name&#125;&#x2F;$&#123;layer&#125;</span><br><span class="line">        done</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line">sync_image() &#123;</span><br><span class="line">    # 使用 skopeo sync 将 dir 格式的镜像同步到 harbor</span><br><span class="line">    for project in $(ls $&#123;SKOPEO_DIR&#125;); do</span><br><span class="line">        skopeo sync --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false \</span><br><span class="line">        --src dir --dest docker $&#123;SKOPEO_DIR&#125;&#x2F;$&#123;project&#125; $&#123;REGISTRY_DOMAIN&#125;&#x2F;$&#123;project&#125;</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line">gen_skopeo_dir</span><br></pre></td></tr></table></figure><blockquote><p>温馨提示: 此种方式是有些复杂对于大镜像的复制是推荐的, 而对于一些小镜像且显得多余。</p></blockquote><h3><span id="43-从-registry-存储中-select-出镜像进行同步">4.3 从 registry 存储中 select 出镜像进行同步</span></h3><p>描述: 先将镜像同步到一个 registry 中，再将镜像从 registry 存储中捞出来，该 registry 可以当作一个镜像存储的池子，我们使用 Linux 中硬链接的特性将镜像&quot;复制&quot;一份出来，然后再打一个 tar 包, 这样做的好处就是每次打包镜像的时候都能复用历史的镜像数据，而且性能极快。</p><ul><li>步骤 01. 先将镜像同步到一个固定的 registry 中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bash skopeo-copy.sh docker.io localhost:5000</span><br></pre></td></tr></table></figure><ul><li>步骤 02. 使用该脚本将镜像从 registry 存储中捞出来</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eo pipefail</span><br><span class="line"># 命令行变量</span><br><span class="line">IMAGES_LIST&#x3D;&quot;$1&quot;</span><br><span class="line">REGISTRY_PATH&#x3D;&quot;$2&quot;</span><br><span class="line">OUTPUT_DIR&#x3D;&quot;$3&quot;</span><br><span class="line"></span><br><span class="line"># Registry 仓库数据目录</span><br><span class="line">BLOB_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">REPO_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line"></span><br><span class="line"># 判断输出目录是否存在如不存在则移除。</span><br><span class="line">if [ -d $&#123;OUTPUT_DIR&#125; ];then</span><br><span class="line">  rm -rf $&#123;OUTPUT_DIR&#125;;</span><br><span class="line">fi</span><br><span class="line">mkdir -p $&#123;OUTPUT_DIR&#125;</span><br><span class="line"></span><br><span class="line">for image in $(find $&#123;IMAGES_LIST&#125; -type f -name &quot;*.list&quot; | xargs grep -Ev &#39;^#|^&#x2F;&#39; | grep &#39;:&#39;); do</span><br><span class="line">  # 镜像名称和Tag</span><br><span class="line">  image_name&#x3D;$&#123;image%%:*&#125;</span><br><span class="line">  image_tag&#x3D;$&#123;image##*:&#125;</span><br><span class="line"></span><br><span class="line">  # link 路径获取</span><br><span class="line">  tag_link&#x3D;$&#123;REGISTRY_PATH&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;current&#x2F;link</span><br><span class="line">  manifest_sha256&#x3D;$(sed &#39;s&#x2F;sha256:&#x2F;&#x2F;&#39; $&#123;tag_link&#125;)</span><br><span class="line">  manifest&#x3D;$&#123;REGISTRY_PATH&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;&#x2F;data</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line"></span><br><span class="line">  # 强制硬链接到指定目录</span><br><span class="line">  ln -f $&#123;manifest&#125; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;&#x2F;data</span><br><span class="line"></span><br><span class="line">  # make image repositories dir</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;&#123;_uploads,_layers,_manifests&#125;</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;&#123;current,index&#x2F;sha256&#125;</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line"></span><br><span class="line">  # create image tag manifest link file  </span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;current&#x2F;link</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link</span><br><span class="line"></span><br><span class="line">  # 强制创建 &#x2F;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F; 各 layer data 文件到指定目录之中</span><br><span class="line">  for layer in $(sed &#39;&#x2F;v1Compatibility&#x2F;d&#39; $&#123;manifest&#125; | grep -Eo &#39;\b[a-f0-9]&#123;64&#125;\b&#39; | sort -u); do</span><br><span class="line">      mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;</span><br><span class="line">      mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;</span><br><span class="line">      ln -f $&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data</span><br><span class="line">      echo -n &quot;sha256:$&#123;layer&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;&#x2F;link</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>至此完毕！</p><blockquote><p>本文转载自：「 WeiyiGeek 」，原文：<a href="https://url.hi-linux.com/xCmXo/" target="_blank" rel="noopener">https://url.hi-linux.com/xCmXo/</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-基础介绍&quot;&gt;1. 基础介绍&lt;/h2&gt;
&lt;p&gt;描述: 作为公司内部 PaaS toB 产品的打包发布人员，容器镜像对我们打工人而言就像是工地上的砖头 🧱，而我的一部分工作就是将这些砖头在各个仓库之间搬来搬去，最终将这些砖头打包放在产品的安装包中，形成一个完整的 PaaS 产品安装包。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q: 在 PaaS (平台即服务)中的大家常说的 ToB 与 ToC 到底是什么?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;ToC 面向普通用户服务, 主要是让用户体验感好，解决用户使用方面的问题记录，并返回给前后端开发。&lt;br&gt;
ToB 是面向企业用户服务, 产品可用、其中最关键是让Boss使用Happly!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Q: 假如有如下场景，我们从 dockerhub 公共仓库中下载一个 GB 以上的镜像，到本地的私有仓库中，我想通常你会这样做先 &lt;code&gt;docker pull&lt;/code&gt; 到本地，然后使用 &lt;code&gt;docker tag&lt;/code&gt; 更改为私有仓库地址加上镜像名称版本，最后再使用&lt;code&gt;docker push&lt;/code&gt; 上传镜像到私有仓库中，以供其它内网机器拉取并使用。虽然该方法是可行，但是如果有多个大于 GB 以上的镜像需要上传到私有仓库，每次都要先解压 layer 到本地，然后再压缩 layer 上传到私有仓库中，你能想象此过程花费的时间有多久吗? 对于我们运维工程师来说时间就是金钱，所以需想尽一切方法来节约时间成本，那有没有一种办法可以直接将 registry 上的 blob 复制到另一个 registry，中间过程不涉及对镜像 layer 的解压缩，这岂不美哉。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;解决方案当然是存在的，如果你不想使用docker进行images镜像拉取上传，我们完成可以使用skope工具来完全替代 docker-cli 来搬运镜像，skopeo是一个命令行实用程序，可对容器映像和映像存储库执行各种操作。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Skopeo" scheme="https://www.hi-linux.com/tags/Skopeo/"/>
    
  </entry>
  
</feed>
