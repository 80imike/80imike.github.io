<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>奇妙的 Linux 世界</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2021-12-20T06:21:12.415Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>15 个实用的 Kubernetes 集群资源清理命令</title>
    <link href="https://www.hi-linux.com/posts/2396.html"/>
    <id>https://www.hi-linux.com/posts/2396.html</id>
    <published>2021-12-20T01:00:00.000Z</published>
    <updated>2021-12-20T06:21:12.415Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>长时间运行的集群，常会面临各种资源耗尽的问题，另外磁盘不足时 Kubelet 还会主动清理镜像增加不确定因素，本文提供了一些命令片段用于清理工作。</p></blockquote><h2><span id="kubernetes-基础对象清理">Kubernetes 基础对象清理</span></h2><ul><li>清理 Evicted 状态的 Pod</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide | grep Evicted | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pod -n</span><br></pre></td></tr></table></figure><ul><li>清理 Error 状态的 Pod</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide | grep Error | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pod -n</span><br></pre></td></tr></table></figure><ul><li>清理 Completed 状态的 Pod</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide | grep Completed | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pod -n</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>清理没有被使用的 PV</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe -A pvc | grep -E &quot;^Name:.*$|^Namespace:.*$|^Used By:.*$&quot; | grep -B 2 &quot;&lt;none&gt;&quot; | grep -E &quot;^Name:.*$|^Namespace:.*$&quot; | cut -f2 -d: | paste -d &quot; &quot; - - | xargs -n2 bash -c &#39;kubectl -n $&#123;1&#125; delete pvc $&#123;0&#125;&#39;</span><br></pre></td></tr></table></figure><ul><li>清理没有被绑定的 PVC</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pvc --all-namespaces | tail -n +2 | grep -v Bound | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pvc -n</span><br></pre></td></tr></table></figure><ul><li>清理没有被绑定的 PV</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pv | tail -n +2 | grep -v Bound | awk &#39;&#123;print $1&#125;&#39; | xargs -L1 kubectl delete pv</span><br></pre></td></tr></table></figure><h2><span id="linux-清理">Linux 清理</span></h2><ul><li>查看磁盘全部空间</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ df -hl &#x2F;</span><br><span class="line"></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">&#x2F;dev&#x2F;sda2       100G   47G   54G  47% &#x2F;</span><br></pre></td></tr></table></figure><ul><li>查看指定目录占用</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ du -sh .</span><br><span class="line"></span><br><span class="line">24G.</span><br></pre></td></tr></table></figure><ul><li>删除指定前缀的文件夹</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;nfsdata</span><br><span class="line">$ ls | grep archived- |xargs -L1 rm -r</span><br></pre></td></tr></table></figure><ul><li>清理僵尸进程</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps -A -ostat,ppid | grep -e &#39;^[Zz]&#39; | awk &#39;&#123;print &#125;&#39; | xargs kill -HUP &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h2><span id="docker-清理">Docker 清理</span></h2><ul><li>查看磁盘使用情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker system df</span><br><span class="line"></span><br><span class="line">TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE</span><br><span class="line">Images              361                 23                  178.5GB             173.8GB (97%)</span><br><span class="line">Containers          29                  9                   6.682GB             6.212GB (92%)</span><br><span class="line">Local Volumes       4                   0                   3.139MB             3.139MB (100%)</span><br><span class="line">Build Cache         0                   0                   0B                  0B</span><br></pre></td></tr></table></figure><ul><li>清理 none 镜像</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker images | grep none | awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi</span><br></pre></td></tr></table></figure><ul><li>清理不再使用的数据卷</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume rm $(docker volume ls -q)</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume prune</span><br></pre></td></tr></table></figure><ul><li>清理缓存</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker builder prune</span><br></pre></td></tr></table></figure><ul><li>全面清理</li></ul><p>删除关闭的容器、无用的存储卷、无用的网络、dangling 镜像（无 tag 镜像）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker system prune -f</span><br></pre></td></tr></table></figure><ul><li>清理正则匹配上的镜像</li></ul><p>这里清理的是 <code>master-8bcf8d7-20211206-111155163</code> 格式的镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker images |grep -E &quot;([0-9a-z]*[-])&#123;3,&#125;[0-9]&#123;9&#125;&quot; |awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi</span><br></pre></td></tr></table></figure><h2><span id="设置定时">设置定时</span></h2><ul><li>查看定时任务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -l</span><br></pre></td></tr></table></figure><ul><li>设置定时任务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br></pre></td></tr></table></figure><p>文本新增定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*&#x2F;35 *&#x2F;6 * * *  docker images | grep none | awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi</span><br><span class="line">45 1 * * * docker system prune -f</span><br></pre></td></tr></table></figure><p>这里第一个任务是每隔六个小时的第 35 分钟执行，第二个任务每天的 1 时 45 分执行。</p><ul><li>定时任务的格式</li></ul><p>设置定时格式: <code>* * * * * shell</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">第一个星号，minute，分钟，值为 0-59</span><br><span class="line">第二个星号，hour，小时，值从 0-23</span><br><span class="line">第三个星号，day，天，值为从 1-31</span><br><span class="line">第四个星号，month，月，值为从 1-12 月，或者简写的英文，比如 Nov、Feb 等</span><br><span class="line">第五个星号，week 周，值为从 0-6 或者简写的英文，Wen、Tur 等，代表周几，其中 0 代表周末</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 陈少文的网站 」，原文：<a href="https://tinyurl.com/yckjyedn" target="_blank" rel="noopener">https://tinyurl.com/yckjyedn</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;长时间运行的集群，常会面临各种资源耗尽的问题，另外磁盘不足时 Kubelet 还会主动清理镜像增加不确定因素，本文提供了一些命令片段用于清理工作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Kubernetes-基础对象清理&quot;&gt;Kubernetes 基础对象清理&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;清理 Evicted 状态的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get pods --all-namespaces -o wide | grep Evicted | awk &amp;#39;&amp;#123;print $1,$2&amp;#125;&amp;#39; | xargs -L1 kubectl delete pod -n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;清理 Error 状态的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get pods --all-namespaces -o wide | grep Error | awk &amp;#39;&amp;#123;print $1,$2&amp;#125;&amp;#39; | xargs -L1 kubectl delete pod -n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;清理 Completed 状态的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get pods --all-namespaces -o wide | grep Completed | awk &amp;#39;&amp;#123;print $1,$2&amp;#125;&amp;#39; | xargs -L1 kubectl delete pod -n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>云原生分布式文件存储 MinIO 保姆级中文教程</title>
    <link href="https://www.hi-linux.com/posts/43710.html"/>
    <id>https://www.hi-linux.com/posts/43710.html</id>
    <published>2021-12-07T01:00:00.000Z</published>
    <updated>2021-12-08T03:11:30.366Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>MinIO - 构建高性能的云原生数据的多云对象存储</strong></p></blockquote><p><code>MinIO</code> 提供开源、高性能、兼容 <code>s3</code> 的对象存储，为每个公共云、每个 <code>Kubernetes</code> 发行版、私有云和边缘云中无缝运行，使其成为混合云和多云对象存储的领导者。</p><ul><li><a href="https://min.io/" target="_blank" rel="noopener">MinIO 英文官网地址</a></li><li><a href="http://www.minio.org.cn/" target="_blank" rel="noopener">MinIO 中文官网地址</a></li></ul><h2><span id="1-minio-的应用场景">1. MinIO 的应用场景</span></h2><blockquote><p><strong>MinIO 是一个非常轻量的服务，可以很简单的和其他应用的结合。</strong></p></blockquote><p><code>MinIO</code> 是一个基于 <code>Apache License v2.0</code> 开源协议的对象存储服务。它兼容亚马逊 <code>S3</code> 云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从 <code>KB</code> 到最大 <code>TB</code> 不等。</p><ul><li>网盘 : 海量文件</li><li>社交网站：海量图片</li><li>电商网站：海量商品图片</li><li>视频网站：海量视频文件</li></ul><p>对于中小型企业，如果不选择存储上云，那么 <code>MinIO</code> 是个不错的选择，麻雀虽小，五脏俱全。当然 <code>MinIO</code> 除了直接作为对象存储使用，还可以作为云上对象存储服务的网关层，无缝对接到 <code>Amazon S3</code> 等。</p><a id="more"></a><h2><span id="2-minio-的系统特点">2. MinIO 的系统特点</span></h2><blockquote><p><strong>介绍 MinIO 服务的主要特点和特性</strong></p></blockquote><ul><li>[1] 高性能<ul><li><code>MinIO</code> 是全球领先的对象存储先锋，在标准硬件上，读/写速度上高达 <code>183GB/s</code> 和<code> 171GB/s</code>，已经成为 <code>Hadoop HDFS</code> 的替代品。</li><li><code>MinIO</code> 用作云原生应用程序的主要存储，与传统对象存储相比，云原生应用程序需要更高的吞吐量和更低的延迟。而这些都是 <code>MinIO</code> 能够达成的性能指标。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-01-2021-12-06-g5KIqw.png" alt="MinIO分布式文件存储 - 高性能"></p><ul><li>[2] 可扩展性<ul><li><code>MinIO</code> 一直秉承着 “简单可扩展” 的理念，为对象存储带来了一个简单的缩放模型。借助在此基础之上，可以实现 <code>MinIO</code> 从单个群集到其他 <code>MinIO</code> 群集联合使用的情况，并且在需要时可以跨越多个不同的数据中心。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-02-2021-12-06-SDx7Q3.png" alt="MinIO分布式文件存储 - 可扩展性"></p><ul><li>[3] 开放全部源代码 + 企业级支持<ul><li><code>MinIO</code> 基于 <code>Apache V2 license</code> 的 <code>100%</code> 开放源代码的产品。</li><li>客户能够自动的、无限制、自由免费使用和集成 MinIO、自由的创新和创造、 自由的去修改、自由的再次发行新的版本和软件。其部署的多样性使软件变得更加坚固，这是专有软件无法提供的。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-03-20211206173811532-2021-12-06-kKFztU.png" alt="MinIO分布式文件存储 - 开放全部源代码+企业级支持"></p><ul><li>[4] 混合云和多云<ul><li>亚马逊云的 <code>S3 API</code> 是在全球范围内达到共识的对象存储的协议。</li><li>当添加到数以百万计的私有云实例和广泛的边缘部署时，MinIO 是混合云的领导者。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-04-2021-12-06-Z6G0QE.png" alt="MinIO分布式文件存储 - 混合云和多云"></p><p><strong>MinIO分布式文件存储 - 混合云和多云</strong></p><ul><li>[5] 简单而强大<ul><li>极简主义是 <code>MinIO</code> 的指导性设计原则。简单性减少了出错的机会，提高了正常运行时间，提供了可靠性，同时简单性又是性能的基础。</li><li>只需下载一个二进制文件然后执行，即可在几分钟内安装和配置 <code>MinIO</code>。<code>MinIO</code> 升级是通过一个简单命令完成的，这个命令可以无中断的完成 <code>MinIO</code> 的升级，并且不需要停机即可完成升级操作。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-05-20211206173756926-2021-12-06-dKfVuA.gif" alt="MinIO分布式文件存储 - 简单而强大"></p><h2><span id="3-minio-的基础概念">3. MinIO 的基础概念</span></h2><blockquote><p><strong>了解如下基础概念，可以方便的理解其使用方式。</strong></p></blockquote><ul><li>存储相关的概念<ul><li>一个对象存储在一个 <code>Set</code></li><li>一个集群划分为多个 <code>Set</code></li><li>一个 <code>Set</code> 中的 <code>Drive</code> 尽可能分布在不同的节点上</li><li>一个 <code>Set</code> 包含的 <code>Drive</code> 数量是固定的，默认由系统根据集群规模自动计算</li></ul></li></ul><table><thead><tr><th style="text-align:left">概念名称</th><th style="text-align:left">对应含义解释</th></tr></thead><tbody><tr><td style="text-align:left"><code>Object</code></td><td style="text-align:left">存储的基本对象；比如文件、图片等等</td></tr><tr><td style="text-align:left"><code>Bucket</code></td><td style="text-align:left">用于存储 <code>Object</code> 的逻辑空间；相互之间互相隔离；类似于系统中的顶层文件夹</td></tr><tr><td style="text-align:left"><code>Drive</code></td><td style="text-align:left">即存储数据的磁盘；所有的对象数据都会存储在 <code>Drive</code> 里面</td></tr><tr><td style="text-align:left"><code>Set</code></td><td style="text-align:left">即一组 <code>Drive</code> 的集合；分布式部署根据集群规模自动划分一个或多个 <code>Set</code></td></tr></tbody></table><ul><li><strong>纠删码 - EC - Erasure Code</strong></li></ul><p><code>MinIO</code> 使用 <strong>纠删码和校验和</strong> 机制来保证高可靠性，即便丢失一半数量(<code>N/2</code>)的硬盘，仍然可以恢复数据。纠删码是一种恢复丢失和损坏数据的数学算法，<code>MinIO</code> 采用 <code>Reed-Solomon code</code> 将对象拆分成 <code>N/2</code> 数据和 <code>N/2</code> 奇偶校验块。这就意味着如果是 <code>12</code> 块盘，一个对象会被分成 <code>6</code> 个数据块、<code>6</code> 个奇偶校验块，你可以丢失任意 <code>6</code> 块盘，仍可以从剩下的盘中的数据进行恢复。</p><p>纠删码的工作原理和 <code>RAID</code> 或者复制不同，像 <code>RAID6</code> 可以在损失两块盘的情况下不丢数据，而 <code>MinIO</code> 纠删码可以在丢失一半的盘的情况下，仍可以保证数据安全。而且 <code>MinIO</code> 纠删码是作用在对象级别，可以一次恢复一个对象，而 <code>RAID</code> 是作用在卷级别，数据恢复时间很长。<code>MinIO</code> 对每个对象单独编码，存储服务一经部署，通常情况下是不需要更换硬盘或者修复。<code>MinIO</code> 纠删码的设计目标是为了性能和尽可能的使用硬件加速。</p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-06-2021-12-06-ytxrnO.jpg" alt="MinIO分布式文件存储 - 对象的存储形式"></p><ul><li><strong>对象的存储形式</strong></li></ul><p>文件对象上传到 <code>MinIO</code> 上面，会在对应的磁盘当中，以 <code>Bucket</code> 名称为目录，文件名称为下一级目录，文件名下是 <code>part.1</code> 和 <code>xl.meta</code>，前者是编码数据块及检验块，后者是元数据文件。</p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-07-20211206173827530-2021-12-06-p2Otij.png" alt="MinIO分布式文件存储 - 对象的存储形式(网络采集的图片)"></p><ul><li><strong>常见的使用方案</strong></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-08-2021-12-06-QGpa3P.png" alt="MinIO分布式文件存储 - 常见的使用方案(网络采集的图片)"></p><h2><span id="4-minio-的安装部署-单机">4. MinIO 的安装部署 - 单机</span></h2><blockquote><p><strong>建议使用容器化安装和部署方式 - 简单和好用</strong></p></blockquote><p>需要注意的是，单机版本无法使用，版本控制、对象锁定和存储桶复制等功能。如果需要使用，是需要部署 <strong>带有纠删码的分布式 MinIO</strong>。</p><ul><li>单机版 - 容器安装 - 没有纠错码版本<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 内嵌了一个MinIO的对象服务</span><br><span class="line"># http:&#x2F;&#x2F;127.0.0.1:9000 (minioadmin:minioadmin)</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">    -p 9000:9000 -p 9001:9001 \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data --console-address &quot;:9001&quot;</span><br><span class="line"></span><br><span class="line"># 启动时自定义用户和密码</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">    -p 9000:9000 -p 9001:9001 \</span><br><span class="line">    -e &quot;MINIO_ROOT_USER&#x3D;admin&quot; \</span><br><span class="line">    -e &quot;MINIO_ROOT_PASSWORD&#x3D;123456&quot; \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data --console-address &quot;:9001&quot;</span><br><span class="line"></span><br><span class="line"># Windows系统启动</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">    -p 9000:9000 -p 9001:9001 \</span><br><span class="line">    -v D:\data:&#x2F;data \</span><br><span class="line">    -e &quot;MINIO_ROOT_USER&#x3D;admin&quot; \</span><br><span class="line">    -e &quot;MINIO_ROOT_PASSWORD&#x3D;123456&quot; \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data --console-address &quot;:9001&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 设置安全秘钥启动</span><br><span class="line">$ echo &quot;admin&quot; | docker secret create access_key -</span><br><span class="line">$ echo &quot;123456&quot; | docker secret create secret_key -</span><br><span class="line"></span><br><span class="line"># 使用docker-service的安全秘钥启动</span><br><span class="line">$ docker service create --name&#x3D;&quot;minio-service&quot; \</span><br><span class="line">    --secret&#x3D;&quot;access_key&quot; --secret&#x3D;&quot;secret_key&quot; \</span><br><span class="line">    --env&#x3D;&quot;MINIO_ROOT_USER_FILE&#x3D;my_access_key&quot; \</span><br><span class="line">    --env&#x3D;&quot;MINIO_ROOT_PASSWORD_FILE&#x3D;my_secret_key&quot; \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data</span><br></pre></td></tr></table></figure><ul><li>单机版 - 容器安装 - 带有纠错码版本<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 命令行启动</span><br><span class="line">$ minio server \</span><br><span class="line">    &#x2F;data1 &#x2F;data2 &#x2F;data3 &#x2F;data4 \</span><br><span class="line">    &#x2F;data5 &#x2F;data6 &#x2F;data7 &#x2F;data8</span><br><span class="line"></span><br><span class="line"># 容器启动</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">  -p 9000:9000 -p 9001:9001 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data1:&#x2F;data1 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data2:&#x2F;data2 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data3:&#x2F;data3 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data4:&#x2F;data4 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data5:&#x2F;data5 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data6:&#x2F;data6 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data7:&#x2F;data7 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data8:&#x2F;data8 \</span><br><span class="line">  quay.io&#x2F;minio&#x2F;minio server &#x2F;data&#123;1...8&#125; --console-address &quot;:9001&quot;</span><br></pre></td></tr></table></figure><ul><li>单机版 - 命令安装<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># MacOS</span><br><span class="line">$ brew install minio&#x2F;stable&#x2F;minio</span><br><span class="line">$ minio server &#x2F;data</span><br><span class="line"></span><br><span class="line"># linux</span><br><span class="line">$ apt install minio</span><br><span class="line">$ minio server &#x2F;data</span><br></pre></td></tr></table></figure><ul><li>单机版 - 二进制安装<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># MacOS</span><br><span class="line">$ wget https:&#x2F;&#x2F;dl.min.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;darwin-amd64&#x2F;minio</span><br><span class="line">$ chmod +x minio</span><br><span class="line">$ .&#x2F;minio server &#x2F;data</span><br><span class="line"></span><br><span class="line"># Windows</span><br><span class="line">$ wget https:&#x2F;&#x2F;dl.min.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;windows-amd64&#x2F;minio.exe</span><br><span class="line">$ minio.exe server D:\</span><br><span class="line"></span><br><span class="line"># Linux</span><br><span class="line">$ wget https:&#x2F;&#x2F;dl.min.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;linux-amd64&#x2F;minio</span><br><span class="line">$ chmod +x minio</span><br><span class="line">$ .&#x2F;minio server &#x2F;data</span><br><span class="line"></span><br><span class="line">$ ufw allow 9000:9010&#x2F;tcp</span><br><span class="line">$ firewall-cmd --get-active-zones</span><br><span class="line">$ firewall-cmd --zone&#x3D;public --add-port&#x3D;9000&#x2F;tcp --permanent</span><br><span class="line">$ firewall-cmd --reload</span><br></pre></td></tr></table></figure><h2><span id="5-minio-的安装部署-分布式">5. MinIO 的安装部署 - 分布式</span></h2><blockquote><p><strong>建议使用容器化安装和部署方式 - 简单和好用</strong></p></blockquote><p>在大数据领域，通常的设计理念都是无中心和分布式。<code>MinIO</code> 也提供了分布式部署的方式，其好处在于，可以提供一个高可用的对象存储服务，确保数据不会丢失和一致。<code>MinIO</code> 在分布式和单机模式下，所有读写操作都严格遵守 <code>read-after-write</code> 一致性模型。</p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-09-2021-12-06-WIfj1H.png" alt="MinIO分布式文件存储 - 分布式架构图"></p><ul><li><strong>命令行方式启动 - client</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 设置变量</span><br><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;SECRET_KEY&gt;</span><br><span class="line"></span><br><span class="line"># 命令行启动方式格式</span><br><span class="line">$ minio server http:&#x2F;&#x2F;host&#123;1...n&#125;&#x2F;export&#123;1...m&#125;</span><br><span class="line">$ minio server http:&#x2F;&#x2F;host&#123;1...n&#125;&#x2F;export&#123;1...m&#125; http:&#x2F;&#x2F;host&#123;o...z&#125;&#x2F;export&#123;1...m&#125;</span><br><span class="line"></span><br><span class="line"># 命令行启动方式示例</span><br><span class="line">minio server http:&#x2F;&#x2F;192.168.1.11&#x2F;export1 http:&#x2F;&#x2F;192.168.1.12&#x2F;export2 \</span><br><span class="line">             http:&#x2F;&#x2F;192.168.1.13&#x2F;export3 http:&#x2F;&#x2F;192.168.1.14&#x2F;export4 \</span><br><span class="line">             http:&#x2F;&#x2F;192.168.1.15&#x2F;export5 http:&#x2F;&#x2F;192.168.1.16&#x2F;export6 \</span><br><span class="line">             http:&#x2F;&#x2F;192.168.1.17&#x2F;export7 http:&#x2F;&#x2F;192.168.1.18&#x2F;export8</span><br></pre></td></tr></table></figure><ul><li><strong>容器方式启动 - docker</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.7&#39;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  minio:</span><br><span class="line">    restart: on-failure</span><br><span class="line">    container_name: app_minio</span><br><span class="line">    image: quay.io&#x2F;minio&#x2F;minio:RELEASE.2021-11-09T03-21-45Z</span><br><span class="line">    command: server &#x2F;data --console-address &quot;:9001&quot;</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;80:9000&quot;</span><br><span class="line">      - &quot;81:9001&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - &quot;&#x2F;app_minio&#x2F;data:&#x2F;data&quot;</span><br><span class="line">    environment:</span><br><span class="line">      MINIO_ROOT_USER: admin</span><br><span class="line">      MINIO_ROOT_PASSWORD: 123456</span><br><span class="line">    healthcheck:</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http:&#x2F;&#x2F;localhost:9000&#x2F;minio&#x2F;health&#x2F;live&quot;]</span><br><span class="line">      interval: 30s</span><br><span class="line">      timeout: 20s</span><br><span class="line">      retries: 3</span><br><span class="line">    networks:</span><br><span class="line">      - app_minio_network</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  app_minio_network:</span><br></pre></td></tr></table></figure><ul><li>容器方式启动 - kubernetes<ul><li><a href="https://github.com/minio/charts" target="_blank" rel="noopener">helm minio charts</a></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 安装MinIO的chart</span><br><span class="line">$ helm install stable&#x2F;minio</span><br><span class="line"></span><br><span class="line"># 容器平台上面启动服务 - 单机</span><br><span class="line">$ helm install --name minio-release \</span><br><span class="line">    --namespace minio</span><br><span class="line">    --set rootUser&#x3D;rootuser,rootPassword&#x3D;rootpass123</span><br><span class="line">    --set persistence.size&#x3D;100Gi \</span><br><span class="line">    stable&#x2F;minio</span><br><span class="line"></span><br><span class="line">#  容器平台上面启动服务 - 分布式</span><br><span class="line">$ helm install --set mode&#x3D;distributed stable&#x2F;minio</span><br><span class="line">$ helm install --set mode&#x3D;distributed,numberOfNodes&#x3D;8 stable&#x2F;minio</span><br><span class="line">$ helm install --set mode&#x3D;shared,numberOfNodes&#x3D;8 stable&#x2F;minio</span><br><span class="line">$ helm install --set persistence.enabled&#x3D;false stable&#x2F;minio</span><br></pre></td></tr></table></figure><h2><span id="6-minio-的安装部署-多租户">6. MinIO 的安装部署 - 多租户</span></h2><blockquote><p><strong>建议使用容器化安装和部署方式 - 简单和好用</strong></p></blockquote><ul><li><strong>[1] 单主机 + 单磁盘</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ minio server --address :9001 &#x2F;data&#x2F;tenant1</span><br><span class="line">$ minio server --address :9002 &#x2F;data&#x2F;tenant2</span><br><span class="line">$ minio server --address :9003 &#x2F;data&#x2F;tenant3</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-10-2021-12-06-qGORMY.jpg" alt="MinIO分布式文件存储 - 多租户"></p><ul><li><strong>[2] 单主机 + 块磁盘 (有纠错码)</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ minio server --address :9001 &#x2F;disk&#123;1...4&#125;&#x2F;data&#x2F;tenant1</span><br><span class="line">$ minio server --address :9002 &#x2F;disk&#123;1...4&#125;&#x2F;data&#x2F;tenant2</span><br><span class="line">$ minio server --address :9003 &#x2F;disk&#123;1...4&#125;&#x2F;data&#x2F;tenant3</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-11-2021-12-06-j2cFg2.jpg" alt="MinIO分布式文件存储 - 多租户"></p><ul><li><strong>[3] 多主机 + 多块磁盘 (分布式+纠错码)</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;TENANT1_ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;TENANT1_SECRET_KEY&gt;</span><br><span class="line">$ minio server --address :9001 http:&#x2F;&#x2F;192.168.10.1&#123;1...4&#125;&#x2F;data&#x2F;tenant1</span><br><span class="line"></span><br><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;TENANT2_ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;TENANT2_SECRET_KEY&gt;</span><br><span class="line">$ minio server --address :9002 http:&#x2F;&#x2F;192.168.10.1&#123;1...4&#125;&#x2F;data&#x2F;tenant2</span><br><span class="line"></span><br><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;TENANT3_ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;TENANT3_SECRET_KEY&gt;</span><br><span class="line">$ minio server --address :9003 http:&#x2F;&#x2F;192.168.10.1&#123;1...4&#125;&#x2F;data&#x2F;tenant3</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-12-20211206174412358-2021-12-06-0zVHNj.jpg" alt="MinIO分布式文件存储 - 多租户"></p><h2><span id="7-minio-的网页使用">7. MinIO 的网页使用</span></h2><blockquote><p><strong>安装部署完成之后，建议使用界面操作，简单好用！</strong></p></blockquote><ul><li>[1] 运行服务 - docker-compose<ul><li><a href="https://raw.githubusercontent.com/minio/minio/master/docs/orchestration/docker-compose/docker-compose.yaml" target="_blank" rel="noopener"><code>docker-compose.yaml</code></a></li><li><a href="https://raw.githubusercontent.com/minio/minio/master/docs/orchestration/docker-compose/nginx.conf" target="_blank" rel="noopener"><code>nginx.conf</code></a></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">version: &quot;3.7&quot;</span><br><span class="line"></span><br><span class="line">x-minio-common: &amp;minio-common</span><br><span class="line">  image: quay.io&#x2F;minio&#x2F;minio:RELEASE.2021-11-24T23-19-33Z</span><br><span class="line">  command: server --console-address &quot;:9001&quot; http:&#x2F;&#x2F;minio&#123;1...4&#125;&#x2F;data&#123;1...2&#125;</span><br><span class="line">  expose:</span><br><span class="line">    - &quot;9000&quot;</span><br><span class="line">    - &quot;9001&quot;</span><br><span class="line">  environment:</span><br><span class="line">    MINIO_ROOT_USER: minio</span><br><span class="line">    MINIO_ROOT_PASSWORD: minio123</span><br><span class="line">  healthcheck:</span><br><span class="line">    test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http:&#x2F;&#x2F;localhost:9000&#x2F;minio&#x2F;health&#x2F;live&quot;]</span><br><span class="line">    interval: 30s</span><br><span class="line">    timeout: 20s</span><br><span class="line">    retries: 3</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  minio1:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio1</span><br><span class="line">    volumes:</span><br><span class="line">      - data1-1:&#x2F;data1</span><br><span class="line">      - data1-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  minio2:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio2</span><br><span class="line">    volumes:</span><br><span class="line">      - data2-1:&#x2F;data1</span><br><span class="line">      - data2-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  minio3:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio3</span><br><span class="line">    volumes:</span><br><span class="line">      - data3-1:&#x2F;data1</span><br><span class="line">      - data3-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  minio4:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio4</span><br><span class="line">    volumes:</span><br><span class="line">      - data4-1:&#x2F;data1</span><br><span class="line">      - data4-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  nginx:</span><br><span class="line">    image: nginx:1.19.2-alpine</span><br><span class="line">    hostname: nginx</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9000:9000&quot;</span><br><span class="line">      - &quot;9001:9001&quot;</span><br><span class="line">    depends_on:</span><br><span class="line">      - minio1</span><br><span class="line">      - minio2</span><br><span class="line">      - minio3</span><br><span class="line">      - minio4</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  data1-1:</span><br><span class="line">  data1-2:</span><br><span class="line">  data2-1:</span><br><span class="line">  data2-2:</span><br><span class="line">  data3-1:</span><br><span class="line">  data3-2:</span><br><span class="line">  data4-1:</span><br><span class="line">  data4-2:</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 启动服务</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># docker-compose</span><br><span class="line">$ docker stack deploy --compose-file docker-compose.yaml minio</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 界面登录</strong></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-13-20211206174432974-2021-12-06-k00IiE.png" alt="MinIO分布式文件存储 - 网页地址"></p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-14-2021-12-06-2dPHBS.png" alt="MinIO分布式文件存储 - 网页地址"></p><h2><span id="8-minio-客户端使用">8. MinIO 客户端使用</span></h2><blockquote><p><strong>MinIO Client (mc) provides a modern alternative to UNIX commands</strong></p></blockquote><ul><li><strong>[1] MC 命令行工具安装</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 容器安装</span><br><span class="line">$ docker pull minio&#x2F;mc</span><br><span class="line">$ docker run minio&#x2F;mc ls play</span><br><span class="line">$ docker run -it --entrypoint&#x3D;&#x2F;bin&#x2F;sh minio&#x2F;mc</span><br><span class="line"></span><br><span class="line"># MacOS</span><br><span class="line">brew install minio&#x2F;stable&#x2F;mc</span><br><span class="line"></span><br><span class="line"># Linux</span><br><span class="line">$ wget http:&#x2F;&#x2F;dl.minio.org.cn&#x2F;client&#x2F;mc&#x2F;release&#x2F;linux-amd64&#x2F;mc</span><br><span class="line">chmod +x mc</span><br><span class="line"></span><br><span class="line"># 自动补全</span><br><span class="line">mc --autocompletion</span><br></pre></td></tr></table></figure><ul><li>[2] MC 命令行参数介绍<ul><li><code>mc xxx</code></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">alias        设置&#x2F;移除&#x2F;列出自定义的别名</span><br><span class="line">ls           列出文件和文件夹</span><br><span class="line">mb           创建一个存储桶或一个文件夹</span><br><span class="line">rb           移除一个桶</span><br><span class="line">cp           拷贝文件和对象</span><br><span class="line">mirror       给存储桶和文件夹做镜像</span><br><span class="line">cat          显示文件和对象内容</span><br><span class="line">head         显示对象的第n行</span><br><span class="line">pipe         将一个STDIN重定向到一个对象或者文件或者STDOUT</span><br><span class="line">share        生成用于共享的URL</span><br><span class="line">find         基于参数查找文件</span><br><span class="line">sql          在对象上运行SQL查询</span><br><span class="line">stat         显示对象元信息</span><br><span class="line">mv           移动文件和对象</span><br><span class="line">tree         以树的格式列出桶和对象</span><br><span class="line">du           统计磁盘使用情况</span><br><span class="line">retention    设置对象和桶的保留</span><br><span class="line">legalhold    设置对象的合法持有</span><br><span class="line">diff         对两个文件夹或者存储桶比较差异</span><br><span class="line">rm           删除文件和对象</span><br><span class="line">encrypt      管理桶加密配置</span><br><span class="line">events       管理对象通知</span><br><span class="line">watch        监听文件和对象的事件</span><br><span class="line">undo         取消PUT&#x2F;DELETE操作</span><br><span class="line">policy       管理访问策略</span><br><span class="line">tag          管理桶和对象的标签</span><br><span class="line">ilm          管理桶的生命周期</span><br><span class="line">version      输出版本信息</span><br><span class="line">replicate    配置服务器端桶复制</span><br><span class="line">admin        管理Minio服务器</span><br><span class="line">update       检查软件更新</span><br></pre></td></tr></table></figure><ul><li>[3] MC 服务端命令参数<ul><li><code>mc admin xxx</code></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">service     服务重启并停止所有MinIO服务器</span><br><span class="line">update      更新更新所有MinIO服务器</span><br><span class="line">info        信息显示MinIO服务器信息</span><br><span class="line">user        管理用户</span><br><span class="line">group       管理小组</span><br><span class="line">policy      MinIO服务器中定义的策略管理策略</span><br><span class="line">config      配置管理MinIO服务器配置</span><br><span class="line">heal        修复MinIO服务器上的磁盘，存储桶和对象</span><br><span class="line">profile     概要文件生成概要文件数据以进行调试</span><br><span class="line">top         顶部提供MinIO的顶部统计信息</span><br><span class="line">trace       跟踪显示MinIO服务器的http跟踪</span><br><span class="line">console     控制台显示MinIO服务器的控制台日志</span><br><span class="line">prometheus  Prometheus管理Prometheus配置</span><br><span class="line">kms         kms执行KMS管理操作</span><br><span class="line">bucket      管理MinIO服务器中定义的存储桶</span><br></pre></td></tr></table></figure><ul><li><strong>[4] 示例演示</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># MinIO云存储配置</span><br><span class="line">mc alias set minio http:&#x2F;&#x2F;192.168.1.51 admin 123456</span><br><span class="line">mc alias set s3 https:&#x2F;&#x2F;s3.amazonaws.com admin 123456</span><br><span class="line">mc alias set gcs  https:&#x2F;&#x2F;storage.googleapis.com admin 123456</span><br><span class="line"></span><br><span class="line"># 开始操作云存储 - 列出所有存储桶</span><br><span class="line">mc ls play</span><br><span class="line"></span><br><span class="line"># 创建一个桶</span><br><span class="line">mc mb play&#x2F;mybucket</span><br><span class="line"></span><br><span class="line"># 上传东西</span><br><span class="line">mc cp myobject.txt play&#x2F;mybucket</span><br></pre></td></tr></table></figure><h2><span id="9-minio-python-sdk">9. MinIO Python SDK</span></h2><blockquote><p><strong>Python 代码操作 MinIO 服务</strong></p></blockquote><ul><li><a href="https://docs.min.io/docs/python-client-quickstart-guide.html" target="_blank" rel="noopener">MinIO Python SDK for Amazon S3 Compatible Cloud Storage Slack</a></li><li><a href="https://docs.min.io/docs/python-client-api-reference" target="_blank" rel="noopener">Python Client API Reference</a></li><li><a href="https://github.com/minio/minio-py/tree/release/examples" target="_blank" rel="noopener">MinIO Python SDK Examples</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 安装pip包</span><br><span class="line">pip3 install minio</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># file_uploader.py</span><br><span class="line">from minio import Minio</span><br><span class="line">from minio.error import S3Error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # Create a client with the MinIO server playground, its access key</span><br><span class="line">    # and secret key.</span><br><span class="line">    client &#x3D; Minio(</span><br><span class="line">        &quot;play.min.io&quot;,</span><br><span class="line">        access_key&#x3D;&quot;Q3AM3UQ867SPQQA43P2F&quot;,</span><br><span class="line">        secret_key&#x3D;&quot;zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # Make &#39;asiatrip&#39; bucket if not exist.</span><br><span class="line">    found &#x3D; client.bucket_exists(&quot;asiatrip&quot;)</span><br><span class="line">    if not found:</span><br><span class="line">        client.make_bucket(&quot;asiatrip&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;Bucket &#39;asiatrip&#39; already exists&quot;)</span><br><span class="line">    </span><br><span class="line">    # Upload &#39;&#x2F;home&#x2F;user&#x2F;Photos&#x2F;asiaphotos.zip&#39; as object name</span><br><span class="line">    # &#39;asiaphotos-2015.zip&#39; to bucket &#39;asiatrip&#39;.</span><br><span class="line">    client.fput_object(</span><br><span class="line">        &quot;asiatrip&quot;, &quot;asiaphotos-2015.zip&quot;, &quot;&#x2F;home&#x2F;user&#x2F;Photos&#x2F;asiaphotos.zip&quot;,</span><br><span class="line">    )</span><br><span class="line">    print(</span><br><span class="line">        &quot;&#39;&#x2F;home&#x2F;user&#x2F;Photos&#x2F;asiaphotos.zip&#39; is successfully uploaded as &quot;</span><br><span class="line">        &quot;object &#39;asiaphotos-2015.zip&#39; to bucket &#39;asiatrip&#39;.&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    try:</span><br><span class="line">        main()</span><br><span class="line">    except S3Error as exc:</span><br><span class="line">        print(&quot;error occurred.&quot;, exc)</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 Escape 」，原文：<a href="https://tinyurl.com/yc3edfec" target="_blank" rel="noopener">https://tinyurl.com/yc3edfec</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;MinIO - 构建高性能的云原生数据的多云对象存储&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;MinIO&lt;/code&gt; 提供开源、高性能、兼容 &lt;code&gt;s3&lt;/code&gt; 的对象存储，为每个公共云、每个 &lt;code&gt;Kubernetes&lt;/code&gt; 发行版、私有云和边缘云中无缝运行，使其成为混合云和多云对象存储的领导者。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://min.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MinIO 英文官网地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.minio.org.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MinIO 中文官网地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1-MinIO-的应用场景&quot;&gt;1. MinIO 的应用场景&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;MinIO 是一个非常轻量的服务，可以很简单的和其他应用的结合。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;MinIO&lt;/code&gt; 是一个基于 &lt;code&gt;Apache License v2.0&lt;/code&gt; 开源协议的对象存储服务。它兼容亚马逊 &lt;code&gt;S3&lt;/code&gt; 云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从 &lt;code&gt;KB&lt;/code&gt; 到最大 &lt;code&gt;TB&lt;/code&gt; 不等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网盘 : 海量文件&lt;/li&gt;
&lt;li&gt;社交网站：海量图片&lt;/li&gt;
&lt;li&gt;电商网站：海量商品图片&lt;/li&gt;
&lt;li&gt;视频网站：海量视频文件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于中小型企业，如果不选择存储上云，那么 &lt;code&gt;MinIO&lt;/code&gt; 是个不错的选择，麻雀虽小，五脏俱全。当然 &lt;code&gt;MinIO&lt;/code&gt; 除了直接作为对象存储使用，还可以作为云上对象存储服务的网关层，无缝对接到 &lt;code&gt;Amazon S3&lt;/code&gt; 等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="MinIO" scheme="https://www.hi-linux.com/tags/MinIO/"/>
    
  </entry>
  
  <entry>
    <title>关于 Kubernetes 的 Secret 并不安全这件事</title>
    <link href="https://www.hi-linux.com/posts/45918.html"/>
    <id>https://www.hi-linux.com/posts/45918.html</id>
    <published>2021-11-25T01:00:00.000Z</published>
    <updated>2021-12-18T08:41:42.651Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>K8s 提供了 Secret 资源供我们来保存、设置一些敏感信息，比如 API endpoint 地址，各种用户密码或 token 之类的信息。在没有使用 K8s 的时候，这些信息可能是通过配置文件或者环境变量在部署的时候设置的。</p><p>不过，Secret 其实并不安全，稍微用 kubectl 查看过 Secret 的人都知道，我们可以非常方便的看到 Secret 的原文，只要有相关的权限即可，尽管它的内容是 base64 编码的，这基本上等同于明文。</p><p>所以说，K8s 原生的 Secret 是非常简单的，不是特别适合在大型公司里直接使用，对 RBAC 的挑战也比较大，很多不该看到明文信息的人可能都能看到。</p><p>尤其是现在很多公司采用了所谓的 GitOps 理念，很多东西都需要放到 VCS，比如 git 中，这一问题就更日益突出，因为 VCS 也得需要设置必要的权限。</p><a id="more"></a><h2><span id="问题">问题</span></h2><p>简单来说，大概有几个地方都可以让不应该看到 Secret 内容的人获得 Secret 内容：</p><ul><li>etcd 存储</li><li>通过 API server</li><li>在 node 上直接查看文件</li></ul><p>这里我们以这个例子来看一下 Secret 在 K8s 中的使用情况。</p><p>Secret 定义， 用户名和密码分别为 <code>admin</code> 和 <code>hello-secret</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: mysecret</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  username: YWRtaW4&#x3D;</span><br><span class="line">  password: aGVsbG8tc2VjcmV0Cg&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>Pod 定义，这里我们将 Secret 作为 volume mount 到容器中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: mypod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: mypod</span><br><span class="line">    image: docker.io&#x2F;containerstack&#x2F;alpine-stress</span><br><span class="line">    command:</span><br><span class="line">      - top</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: foo</span><br><span class="line">      mountPath: &quot;&#x2F;etc&#x2F;foo&quot;</span><br><span class="line">      readOnly: true</span><br><span class="line">  volumes:</span><br><span class="line">  - name: foo</span><br><span class="line">    secret:</span><br><span class="line">      secretName: mysecret</span><br></pre></td></tr></table></figure><p>Pod 启动后，我们可以到容器中来查看 Secret 作为 volume mount 到容器后的文件内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -it mypod sh</span><br><span class="line">&#x2F; # cd &#x2F;etc&#x2F;foo&#x2F;</span><br><span class="line">&#x2F;etc&#x2F;foo # ls -tal</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x    1 root     root          4096 Apr 14 08:55 ..</span><br><span class="line">drwxrwxrwt    3 root     root           120 Apr 14 08:55 .</span><br><span class="line">drwxr-xr-x    2 root     root            80 Apr 14 08:55 ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx    1 root     root            31 Apr 14 08:55 ..data -&gt; ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx    1 root     root            15 Apr 14 08:55 password -&gt; ..data&#x2F;password</span><br><span class="line">lrwxrwxrwx    1 root     root            15 Apr 14 08:55 username -&gt; ..data&#x2F;username</span><br><span class="line">&#x2F;etc&#x2F;foo # ls -tal ..2021_04_14_08_55_54.401661151</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x    2 root     root            80 Apr 14 08:55 .</span><br><span class="line">drwxrwxrwt    3 root     root           120 Apr 14 08:55 ..</span><br><span class="line">-rw-r--r--    1 root     root            13 Apr 14 08:55 password</span><br><span class="line">-rw-r--r--    1 root     root             5 Apr 14 08:55 username</span><br><span class="line">&#x2F;etc&#x2F;foo # cat password</span><br><span class="line">hello-secret</span><br><span class="line">&#x2F;etc&#x2F;foo #</span><br></pre></td></tr></table></figure><h3><span id="etcd-存储">etcd 存储</span></h3><p>API server 中的资源都保存在 etcd 中，我们可以直接从文件看到相关内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># hexdump -C &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;member&#x2F;snap&#x2F;db | grep -A 5 -B 5 hello</span><br><span class="line">00043640  12 00 1a 07 64 65 66 61  75 6c 74 22 00 2a 24 32  |....default&quot;.*$2|</span><br><span class="line">00043650  35 66 37 35 38 30 38 2d  37 33 31 33 2d 34 38 64  |5f75808-7313-48d|</span><br><span class="line">00043660  39 2d 39 61 38 65 2d 38  61 35 66 66 32 32 63 64  |9-9a8e-8a5ff22cd|</span><br><span class="line">00043670  64 35 39 32 00 38 00 42  08 08 98 dc da 83 06 10  |d592.8.B........|</span><br><span class="line">00043680  00 7a 00 12 19 0a 08 70  61 73 73 77 6f 72 64 12  |.z.....password.|</span><br><span class="line">00043690  0d 68 65 6c 6c 6f 2d 73  65 63 72 65 74 0a 12 11  |.hello-secret...|</span><br><span class="line">000436a0  0a 08 75 73 65 72 6e 61  6d 65 12 05 61 64 6d 69  |..username..admi|</span><br><span class="line">000436b0  6e 1a 06 4f 70 61 71 75  65 1a 00 22 00 00 00 00  |n..Opaque..&quot;....|</span><br><span class="line">000436c0  00 00 00 08 95 5f 00 00  00 00 00 00 00 00 0a 37  |....._.........7|</span><br><span class="line">000436d0  2f 72 65 67 69 73 74 72  79 2f 73 65 72 76 69 63  |&#x2F;registry&#x2F;servic|</span><br><span class="line">000436e0  65 73 2f 65 6e 64 70 6f  69 6e 74 73 2f 6b 75 62  |es&#x2F;endpoints&#x2F;kub|</span><br></pre></td></tr></table></figure><p>可以看到，基本 yaml 中的内容都是明文存放的，而且是进行 base64 解码之后的内容。</p><p>使用下面的命令也可以获得类似的结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ETCDCTL_API&#x3D;3 etcdctl get --prefix &#x2F;registry&#x2F;secrets&#x2F;default&#x2F;mysecret | hexdump -C</span><br></pre></td></tr></table></figure><p>etcd 本来存储的是明文数据，这个好像已经从 1.7 开始支持 <a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/" target="_blank" rel="noopener">加密存储</a> 了，而且直接访问 etcd 从物理上来说也不是那么容易。</p><h3><span id="api-server">API server</span></h3><p>通过 API server 则简单的多，只要有权限就可以从任何节点上通过访问 API server 来得到 secret 的明文内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get secret mysecret -o yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  password: aGVsbG8tc2VjcmV0Cg&#x3D;&#x3D;</span><br><span class="line">  username: YWRtaW4&#x3D;</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: &quot;2021-04-14T08:55:52Z&quot;</span><br><span class="line">  name: mysecret</span><br><span class="line">  namespace: default</span><br><span class="line">  resourceVersion: &quot;2196&quot;</span><br><span class="line">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;secrets&#x2F;mysecret</span><br><span class="line">  uid: 25f75808-7313-48d9-9a8e-8a5ff22cdd59</span><br><span class="line">type: Opaque</span><br></pre></td></tr></table></figure><h3><span id="节点上">节点上</span></h3><p>在节点上也可以看到 Secret 文件的内容。</p><p>查找 foo volume 的挂载点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># mount | grep foo </span><br><span class="line">tmpfs on &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;280451e8-512b-489c-b5dd-df2b1a3c9b29&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;foo type tmpfs (rw,relatime)</span><br></pre></td></tr></table></figure><p>查看这个 volume 下面的文件内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># ls -tal &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;280451e8-512b-489c-b5dd-df2b1a3c9b29&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;foo</span><br><span class="line">total 4</span><br><span class="line">drwxrwxrwt 3 root root  120 4月  14 16:55 .</span><br><span class="line">drwxr-xr-x 2 root root   80 4月  14 16:55 ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx 1 root root   31 4月  14 16:55 ..data -&gt; ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx 1 root root   15 4月  14 16:55 password -&gt; ..data&#x2F;password</span><br><span class="line">lrwxrwxrwx 1 root root   15 4月  14 16:55 username -&gt; ..data&#x2F;username</span><br><span class="line">drwxr-xr-x 4 root root 4096 4月  14 16:55 ..</span><br><span class="line"></span><br><span class="line"># cat &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;280451e8-512b-489c-b5dd-df2b1a3c9b29&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;foo&#x2F;password</span><br><span class="line">hello-secret</span><br></pre></td></tr></table></figure><h2><span id="第三方方案">第三方方案</span></h2><p>针对上面提到的可能泄露 Secret 的几点，大概解决方案不难想到如下几种：</p><ul><li>etcd 加密</li><li>API server 严格进行权限设计</li><li>强化 node 节点用户权限管理和系统安全</li></ul><p>不过，要相关确保 Secret 的绝对安全，上面这几种方案都是必须，缺一不可，缺少了那一个都相当于在墙上留了一个洞。</p><p>社区和公有云提供商都有一些产品和方案，我们可以参考一下。</p><ul><li><a href="https://github.com/shyiko/kubesec" target="_blank" rel="noopener">shyiko/kubesec</a>: Secure Secret management for Kubernetes (with gpg, Google Cloud KMS and AWS KMS backends)</li><li><a href="https://github.com/bitnami-labs/sealed-secrets" target="_blank" rel="noopener">bitnami-labs/sealed-secrets</a>: A Kubernetes controller and tool for one-way encrypted Secrets</li><li><a href="https://www.vaultproject.io/docs/platform/k8s" target="_blank" rel="noopener">Vault by HashiCorp</a></li><li><a href="https://github.com/mozilla/sops" target="_blank" rel="noopener">mozilla/sops</a></li><li><a href="https://github.com/external-secrets/kubernetes-external-secrets" target="_blank" rel="noopener">Kubernetes External Secrets</a></li><li><a href="https://github.com/Soluto/kamus" target="_blank" rel="noopener">Kamus</a></li></ul><h3><span id="shyikokubesec">shyiko/kubesec</span></h3><p>kubesec 只对 Secret 中数据进行加密/解密，支持如下 key 管理服务或软件：</p><ul><li>AWS Key Management Service</li><li>Google Cloud KMS</li><li>GnuPG</li></ul><h3><span id="bitnami-labssealed-secrets">bitnami-labs/sealed-secrets</span></h3><p>Bitnami 在 K8s 领域也是一家人人知晓的公司，输出了很多技术和最佳实践。</p><p><img src="https://img.hi-linux.com/staticfile/sealed-secrets-20210520174450379-2021-05-20-foc4mT.png" alt></p><p><em>本图来自 <a href="https://engineering.bitnami.com/articles/sealed-secrets.html" target="_blank" rel="noopener">Sealed Secrets: Protecting your passwords before they reach Kubernetes</a></em></p><p>SealeSecret 将 secret 资源整个加密保存为 <code>SealedSecret</code> 资源，而解密只能由该集群中的 controller 进行。</p><p>SealeSecret 提供了一个 kubeseal 工具来对 secret 资源进行加密，这个过程需要一个公开 key（公钥），这个公开 key 就是从 SealeSecret controller 拿到的。</p><p>不过，只从从说明文档来看， SealeSecret controller 加密解密所依赖的 key，也是通过普通的 Secret 来保存的，这难道不是一个问题？同时也增加了 SealeSecret controller 的运维成本。</p><h3><span id="mozillasops">mozilla/sops</span></h3><p>严格来说， sops 跟 K8s 并没有什么必然关系，它只是一个支持 YAML/JSON/ENV/INI 等文件格式的加密文件编辑器，它支持 AWS KMS, GCP KMS, Azure Key Vault, age, 和 PGP 等服务与应用。</p><p>如果有有兴趣可以看它的<a href="https://github.com/mozilla/sops" target="_blank" rel="noopener">主页</a>。</p><h3><span id="kubernetes-external-secrets">Kubernetes External Secrets</span></h3><p>Kubernetes External Secrets 是知名域名服务提供商 godaddy 开发的开源软件，它可以直接将保存在外部 KMS 中的机密信息传给 K8s 。目前支持的 KSM 包括：</p><ul><li>AWS Secrets Manager</li><li>AWS System Manager</li><li>Hashicorp Vault</li><li>Azure Key Vault</li><li>GCP Secret Manager</li><li>Alibaba Cloud KMS Secret Manager</li></ul><p>它通过自定义 controller 和 CRD 来实现，具体架构图如下：</p><p><img src="https://img.hi-linux.com/staticfile/kubernetes-external-secrets-architecture-2021-05-20-iCQv1L.png" alt="img"></p><p>具体来说用户需要创建一个 ExternalSecret 类型的资源，来将外部 KMS 的数据映射到 K8s 的 Secret 上。</p><p>不过，这种方式大概只有两点好处：</p><ul><li>统一 key 的管理，或者沿用既有 key 资产</li><li>key 信息不想放到 VCS 等</li></ul><p>对于防止 Sercet 信息泄露，作用不大，因为其明文资源还是可以在 API server/etcd 上看到。</p><p>或者说，External Secrets 真正做的事情，也就是从外部 KMS 中的 key ，映射成 K8s 中的 Secret 资源而已，对保证在 K8s 集群中数据的安全性用处不大。</p><h3><span id="kamus">Kamus</span></h3><p>Kamus 同样提供了加密 key 的方法（一个命令行工具），同时只有通过 K8s 中的 controller 才能对这个 key 进行解密。不过它 保存在 K8s 中的 Secret 是加密的状态，用户不能像 External Secrets 那样直接获得 Secret 的明文内容。</p><p>Kamus 由 3 个组件组成，分别是：</p><ul><li>Encrypt API</li><li>Decrypt API</li><li>Key Management System (KMS)</li></ul><p>KMS 是一个外部加密服务的封装，目前支持如下服务： - AES - AWS KMS - Azure KeyVault - Google Cloud KMS</p><p>Kamus 以 service account 为单位对 secret 进行加密，之后 Pod 会通过 service account 来请求 Kamus 的解密服务来对该 secret 进行解密。</p><p>对 K8s 来说，解密 secret 可以通过 init container 来实现：定义一个 基于内存的 emptyDir ，业务容器和 init 容器使用同一个 volume， init 容器解密后，将数据存放到该 volume 下，之后业务容器就可以使用解密后的 secret 数据了。</p><p><img src="https://img.hi-linux.com/staticfile/kamus-pod-2021-05-20-5Z6xjw.png" alt="img"></p><h3><span id="vault-by-hashicorp">Vault by HashiCorp</span></h3><p>HashiCorp 公司就不多说，在云计算/DevOps领域也算是数一数二的公司了。</p><p>Vault 本身就是一个 KMS 类似的服务，用于管理机密数据。对于 K8s 的原生 secret ，大概提供了如下两种方式的支持：</p><ul><li><a href="https://www.vaultproject.io/docs/platform/k8s/injector" target="_blank" rel="noopener">Agent Sidecar Injector/vault-k8s</a></li><li><a href="https://www.vaultproject.io/docs/platform/k8s/csi" target="_blank" rel="noopener">Vault CSI Provider</a></li></ul><h4><span id="agent-sidecar-injector">Agent Sidecar Injector</span></h4><p>这种方式和上面的 Kamus 类似，也是需要两个组件：</p><ul><li>Mutation webhook：负责修改 pod 定义，注入init/sidecar</li><li>agent-sidecar：负责获取和解密数据，将数据保存到指定的 volume/路径下</li></ul><p>Vault agent sidecar injector 不仅提供了 init container 来初始化 secret ，还通过 sidecar 来定期更新 secret ，这样就非常接近原生 secret 的实现了。</p><p>应用程序则只需要在文件系统上读取指定的文件就可以了，而不必关系如何从外部获取加密信息。</p><p>这是官方 blog 中的一个示例：</p><p>Pod 信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        vault.hashicorp.com&#x2F;agent-inject: &quot;true&quot;</span><br><span class="line">        vault.hashicorp.com&#x2F;agent-inject-secret-helloworld: &quot;secrets&#x2F;helloworld&quot;</span><br><span class="line">        vault.hashicorp.com&#x2F;role: &quot;myapp&quot;</span><br></pre></td></tr></table></figure><p>这个定义中，<code>vault-k8s</code> 会对该 pod 注入 <code>vault agent</code>，并使用 <code>secrets/helloworld</code> 来初始化。Pod 运行后，可以在 <code>/vault/secrets</code> 下找到一个名为 <code>helloworld</code> 的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -ti app-XXXXXXXXX -c app -- cat &#x2F;vault&#x2F;secrets&#x2F;helloworld</span><br><span class="line">data: map[password:foobarbazpass username:foobaruser]</span><br><span class="line">metadata: map[created_time:2019-12-16T01:01:58.869828167Z deletion_time: destroyed:false version:1]</span><br></pre></td></tr></table></figure><p>当然这个数据是raw data，没有经过格式化。如果想指定输出到文件中的格式，可以使用 vault 的模板功能。</p><h4><span id="vault-csi-provider">Vault CSI Provider</span></h4><p>这部分可以参考下面的社区方案部分。</p><h2><span id="社区方案">社区方案</span></h2><p>当然，社区没有理由意识不到原生 secret 的问题，因此社区也有 <a href="https://github.com/kubernetes-sigs/secrets-store-csi-driver" target="_blank" rel="noopener">Kubernetes Secrets Store CSI Driver</a> ，一种通过 CSI 接口将 Secret 集成到 K8s 的方案。</p><p>Secrets Store CSI driver（<code>secrets-store.csi.k8s.io</code>）可以让 K8s mount 多个 secret 以 volume 的形式，从外部 KMS mount 到 Pod 里。</p><p>要想使用 Secrets Store CSI Driver ，大致过程如下:</p><ul><li>定义 SecretProviderClass</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: secrets-store.csi.x-k8s.io&#x2F;v1alpha1</span><br><span class="line">kind: SecretProviderClass</span><br><span class="line">metadata:</span><br><span class="line">  name: my-provider</span><br><span class="line">spec:</span><br><span class="line">  provider: vault   # accepted provider options: azure or vault or gcp</span><br><span class="line">  parameters:       # provider-specific parameters</span><br></pre></td></tr></table></figure><ul><li>为 Pod 配置 Volume</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: secrets-store-inline</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: k8s.gcr.io&#x2F;e2e-test-images&#x2F;busybox:1.29</span><br><span class="line">    name: busybox</span><br><span class="line">    command:</span><br><span class="line">    - &quot;&#x2F;bin&#x2F;sleep&quot;</span><br><span class="line">    - &quot;10000&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: secrets-store-inline</span><br><span class="line">      mountPath: &quot;&#x2F;mnt&#x2F;secrets-store&quot;</span><br><span class="line">      readOnly: true</span><br><span class="line">  volumes:</span><br><span class="line">    - name: secrets-store-inline</span><br><span class="line">      csi:</span><br><span class="line">        driver: secrets-store.csi.k8s.io</span><br><span class="line">        readOnly: true</span><br><span class="line">        volumeAttributes:</span><br><span class="line">          secretProviderClass: &quot;my-provider&quot;</span><br></pre></td></tr></table></figure><p>Pod 启动之后，就可以确认解密后的数据了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec secrets-store-inline -- ls &#x2F;mnt&#x2F;secrets-store&#x2F;</span><br><span class="line">foo</span><br></pre></td></tr></table></figure><h2><span id="总结">总结</span></h2><p>上面的总结都是基于互联网公开的资料而来，并没有经过亲身体验，因此有些地方可能理解有误，要想深入了解还需要自己亲手确认最好。</p><p>不过总体来说，社区这种方案可能最简单，部署也不是很麻烦，只是这就和原生的 secret 基本没什么关系了。。。</p><p>Vault 方案也很成熟，值得关注。</p><blockquote><p>本文转载自：「 人间指南 」，原文：<a href="https://tinyurl.com/y9warvpa" target="_blank" rel="noopener">https://tinyurl.com/y9warvpa</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;K8s 提供了 Secret 资源供我们来保存、设置一些敏感信息，比如 API endpoint 地址，各种用户密码或 token 之类的信息。在没有使用 K8s 的时候，这些信息可能是通过配置文件或者环境变量在部署的时候设置的。&lt;/p&gt;
&lt;p&gt;不过，Secret 其实并不安全，稍微用 kubectl 查看过 Secret 的人都知道，我们可以非常方便的看到 Secret 的原文，只要有相关的权限即可，尽管它的内容是 base64 编码的，这基本上等同于明文。&lt;/p&gt;
&lt;p&gt;所以说，K8s 原生的 Secret 是非常简单的，不是特别适合在大型公司里直接使用，对 RBAC 的挑战也比较大，很多不该看到明文信息的人可能都能看到。&lt;/p&gt;
&lt;p&gt;尤其是现在很多公司采用了所谓的 GitOps 理念，很多东西都需要放到 VCS，比如 git 中，这一问题就更日益突出，因为 VCS 也得需要设置必要的权限。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Linux 运维工程师必须知道的 6 类好习惯和 23 个教训</title>
    <link href="https://www.hi-linux.com/posts/17487.html"/>
    <id>https://www.hi-linux.com/posts/17487.html</id>
    <published>2021-11-19T01:00:00.000Z</published>
    <updated>2021-12-18T08:41:42.656Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>从事运维三年半，遇到过各式各样的问题，数据丢失，网站挂马，误删数据库文件，黑客攻击等各类问题。</p><p>今天简单整理一下，分享给各位小伙伴。</p><h2><span id="线上操作规范">线上操作规范</span></h2><p><strong>1、测试使用</strong></p><p>当初学习 Linux 的使用，从基础到服务到集群，都是在虚拟机做的，虽然老师告诉我们跟真机没有什么差别，可是对真实环境的渴望日渐上升，不过虚拟机的各种快照却让我们养成了各种手贱的习惯，以致于拿到服务器操作权限时候，就迫不及待的想去试试，记得上班第一天，老大把 root 密码交给我，由于只能使用 putty，我就想使用 xshell，于是悄悄登录服务器尝试改为 Xshell+密钥登录，因为没有测试，也没有留一个 SSH 连接，所有重启 SSHD 服务器之后，自己就被挡在服务器之外了，幸好当时我备份了 sshd_config 文件，后来让机房人员 cp 过去就可以了，幸亏这是一家小公司，不然直接就被干了……庆幸当年运气比较好。</p><p>第二个例子是关于文件同步的，大家都知道 sync 同步很快，可是他删除文件的速度大大超过了 rm -rf，在 rsync 中有一个命令是，以某目录为准同步某文件（如果第一个目录是空的，那么结果可想而知），源目录（有数据的）就会被删除，当初我就是因为误操作，以及缺乏测试，就目录写反了，关键是没有备份……生产环境数据被删了。</p><p>没备份，大家自己想后果吧，其重要性不言而喻。</p><a id="more"></a><p><strong>2、Enter 前再三确认</strong></p><p>关于 <code>rm -rf / var</code> 这种错误，我相信手快的人，或者网速比较慢的时候，出现的几率相当大，当你发现执行完之后，你的心至少是凉了半截。</p><p>大家可能会说，我按了这么多次都没出过错，不用怕，我只想说当出现一次你就明白了，不要以为那些运维事故都是在别人身上，如果你不注意，下一个就是你。</p><p><strong>3、切忌多人操作</strong></p><p>我在的上一家公司，运维管理相当混乱，举一个最典型的例子吧，离职好几任的运维都有服务器 root 密码。</p><p>通常我们运维接到任务，都会进行简单查看如果无法解决，就请求他人帮忙，可是当问题焦头烂额的时候，客服主管（懂点 Linux），网管，你上司一起调试一个服务器，当你各种百度,各种对照，完了发现，你的服务器配置文件，跟上次你修改不一样了，然后再改回来，然后再谷歌，兴冲冲发现问题，解决了，别人却告诉你，他也解决了，修改的是不同的参数……这个，我就真不知道哪个是问题真正的原因了，当然这还是好的，问题解决了，皆大欢喜，可是你遇到过你刚修改的文件，测试无效，再去修改发现文件又被修改的时候呢？真的很恼火，切忌多人操作。</p><p><strong>4、先备份后操作</strong></p><p>养成一个习惯，要修改数据时，先备份，比如 <code>.conf</code> 的配置文件。另外，修改配置文件时，建议注释原选项，然后再复制，修改。</p><p>再者说，如果第一个例子中，有数据库备份，那 rsync 的误操作不久没事了吧。所以说丢数据库非一朝一夕，随便备份一个就不用那么惨。</p><h2><span id="涉及数据">涉及数据</span></h2><p><strong>5、慎用rm -rf</strong></p><p>网上的例子很多，各种 <code>rm -rf /</code>，各种删除主数据库，各种运维事故……</p><p>一点小失误就会造成很大的损失。如果真需要删除，一定要谨慎。</p><p><strong>6、备份大于一切</strong></p><p>本来上面都有各种关于备份，但是我想把它划分在数据类再次强调，备份非常之重要哇。</p><p>我记得我的老师说过一句话，涉及到数据何种的谨慎都不为过。我就职的公司有做第三方支付网站和网贷平台的，第三方支付是每两个小时完全备份一次，网贷平台是每 20 分钟备份一次。</p><p>我不多说了，大家自己斟酌吧。</p><p><strong>7、稳定大于一切</strong></p><p>其实不止是数据，在整个服务器环境，都是稳定大于一切，不求最快，但求最稳定，求可用性，所以未经测试，不要在服务器使用新的软件，比如 Nginx+PHP-FPM，生产环境中 PHP 各种挂啊。</p><p>重启下就好了，或者换 apache 就好了。</p><p><strong>8、保密大于一切</strong></p><p>现在各种艳照门漫天飞，各种路由器后门，所以说，涉及到数据，不保密是不行的。</p><h2><span id="涉及安全">涉及安全</span></h2><p><strong>9、SSH</strong></p><ul><li>更改默认端口（当然如果专业要黑你，扫描下就出来了）</li><li>禁止 root 登录</li><li>使用普通用户+key认证+sudo规则+IP地址+用户限制</li><li>使用 hostdeny 类似的防爆里破解软件（超过几次尝试直接拉黑）</li></ul><p>筛选 <code>/etc/passwd</code> 中 login 的用户。</p><p><strong>10、防火墙</strong></p><p>防火墙生产环境一定要开，并且要遵循最小原则，drop所有，然后放行需要的服务端口。</p><p><strong>11、精细权限和控制粒度</strong></p><p>能使用普通用户启动的服务坚决不使用root，把各种服务权限控制到最低，控制粒度要精细。</p><p><strong>12、入侵检测和日志监控</strong></p><p>使用第三方软件，时刻检测系统关键文件以及各种服务配置文件的改动，比如：<code>/etc/passwd</code>，<code>/etc/my.cnf</code>，<code>/etc/httpd/con/httpd.conf</code>等。</p><p>使用集中化的日志监控体系，监控 <code>/var/log/secure</code>，<code>/etc/log/message</code>，ftp 上传下载文件等报警错误日志。</p><p>另外针对端口扫描，也可以使用一些第三方软件，发现被扫描就直接拉入 host.deny。这些信息对于系统被入侵后排错很有帮助。</p><p>有人说过，一个公司在安全投入的成本跟他被安全攻击损失的成本成正比，安全是一个很大的话题，也是一个很基础的工作，把基础做好了，就能相当的提高系统安全性，其他的就是安全高手做的了。</p><h2><span id="日常监控">日常监控</span></h2><p><strong>13、系统运行监控</strong></p><p>好多人踏入运维都是从监控做起，大的公司一般都有专业 24 小时监控运维。系统运行监控一般包括硬件占用率，常见的有，内存，硬盘，CPU，网卡，OS包括登录监控，系统关键文件监控。</p><p>定期的监控可以预测出硬件损坏的概率，并且给调优带来很实用的功能。</p><p><strong>14、服务运行监控</strong></p><p>服务监控一般就是各种应用，Web，DB，LVS等，这一般都是监控一些指标。</p><p>在系统出现性能瓶颈的时候就能很快发现并解决。</p><p><strong>15、日志监控</strong></p><p>这里的日志监控跟安全的日志监控类似，但这里一般都是硬件，OS，应用程序的报错和警报信息。</p><p>监控在系统稳定运行的时候确实没啥用，但是一旦出现问题，你又没做监控，就会很被动了。</p><h2><span id="性能调优">性能调优</span></h2><p><strong>16、深入了解运行机制</strong></p><p>其实按一年多的运维经验来说，谈调优根本就是纸上谈兵，但是我只是想简单总结下，如果有更深入的了解，我会更新。在对软件进行优化之前，比如要深入了解一个软件的运行机制，比如 Nginx 和 Apache，大家都说 Nginx 快，那就必须知道 Nginx 为什么快，利用什么原理，处理请求比 Apache，并且要能跟别人用浅显易懂的话说出来，必要的时候还要能看懂源代码，否则一切以参数为调优对象的文档都是瞎谈。</p><p><strong>17、调优框架以及先后</strong></p><p>熟悉了底层运行机制，就要有调优的框架和先后顺序，比如数据库出现瓶颈，好多人直接就去更改数据库的配置文件，我的建议是，先根据瓶颈去分析，查看日志，写出来调优方向，然后再入手，并且数据库服务器调优应该是最后一步，最先的应该是硬件和操作系统，现在的数据库服务器都是在各种测试之后才会发布的</p><p>适用于所有操作系统，不应该先从他入手。</p><p><strong>18、每次只调一个参数</strong></p><p>每次只调一个参数，这个相比大家都了解，调的多了，你就自己就迷糊了。</p><p><strong>19、基准测试</strong></p><p>判断调优是否有用，和测试一个新版本软件的稳定性和性能等方面，就必须要基准测试了，测试要涉及很多因素。</p><p>测试是否接近业务真实需求这要看测试人的经验了，相关资料大家可以参考《高性能MySQL》第三版相当的好。</p><p>我的老师曾说过，没有放之四海皆准的参数，任何参数更改任何调优都必须符合业务场景，所以不要再谷歌什么什么调优了，对你的提升和业务环境的改善没有长久作用。</p><h2><span id="运维心态">运维心态</span></h2><p><strong>20、控制心态</strong></p><p>很多 <code>rm -rf /data</code> 都在下班的前几分钟，都在烦躁的高峰，那么你还不打算控制下你的心态么？</p><p>有人说了，烦躁也要上班，可是你可以在烦躁的时候尽量避免处理关键数据环境，越是有压力，越要冷静，不然会损失更多。</p><p>大多人都有 <code>rm -rf /data/mysql</code> 的经历，发现删除之后，那种心情你可以想象一下，可是如果没有备份，你急又有什么用，一般这种情况下，你就要冷静想下最坏打算了，对于 MySQL 来说，删除了物理文件，一部分表还会存在内存中，所以断开业务，但是不要关闭MySQL数据库，这对恢复很有帮助，并使用dd复制硬盘，然后你再进行恢复。</p><p>当然了大多时候你就只能找数据恢复公司了。</p><p>试想一下，数据被删了，你各种操作，关闭数据库，然后修复，不但有可能覆盖文件，还找不到内存中的表了。</p><p><strong>21、对数据负责</strong></p><p>生产环境不是儿戏，数据库也不是儿戏，一定要对数据负责。不备份的后果是非常严重的。</p><p><strong>22、追根究底</strong></p><p>很多运维人员比较忙，遇到问题解决就不会再管了，记得去年一个客户的网站老是打不开，经过 PHP 代码报错，发现是 session 和 whos_online 损坏，前任运维是通过 repair 修复的，我就也这样修复了，但是过了几个小时，又出现了。反复三四次之后，我就去谷歌数据库表莫名损坏原因：一是 myisam 的 bug，二是 mysqlbug，三是 MySQL 在写入过程中被 kill，最后发现是内存不够用，导致 OOM kill 了 mysqld 进程，并且没有 swap 分区，后台监控内存是够用的，最后升级物理内存解决。</p><p><strong>23、测试和生产环境</strong></p><p>在重要操作之前一定要看自己所在的机器，尽量避免多开窗口。</p><blockquote><p>本文转载自：「 博客园 」，原文：<a href="https://tinyurl.com/jrh7nr2x" target="_blank" rel="noopener">https://tinyurl.com/jrh7nr2x</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从事运维三年半，遇到过各式各样的问题，数据丢失，网站挂马，误删数据库文件，黑客攻击等各类问题。&lt;/p&gt;
&lt;p&gt;今天简单整理一下，分享给各位小伙伴。&lt;/p&gt;
&lt;h2 id=&quot;线上操作规范&quot;&gt;线上操作规范&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1、测试使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当初学习 Linux 的使用，从基础到服务到集群，都是在虚拟机做的，虽然老师告诉我们跟真机没有什么差别，可是对真实环境的渴望日渐上升，不过虚拟机的各种快照却让我们养成了各种手贱的习惯，以致于拿到服务器操作权限时候，就迫不及待的想去试试，记得上班第一天，老大把 root 密码交给我，由于只能使用 putty，我就想使用 xshell，于是悄悄登录服务器尝试改为 Xshell+密钥登录，因为没有测试，也没有留一个 SSH 连接，所有重启 SSHD 服务器之后，自己就被挡在服务器之外了，幸好当时我备份了 sshd_config 文件，后来让机房人员 cp 过去就可以了，幸亏这是一家小公司，不然直接就被干了……庆幸当年运气比较好。&lt;/p&gt;
&lt;p&gt;第二个例子是关于文件同步的，大家都知道 sync 同步很快，可是他删除文件的速度大大超过了 rm -rf，在 rsync 中有一个命令是，以某目录为准同步某文件（如果第一个目录是空的，那么结果可想而知），源目录（有数据的）就会被删除，当初我就是因为误操作，以及缺乏测试，就目录写反了，关键是没有备份……生产环境数据被删了。&lt;/p&gt;
&lt;p&gt;没备份，大家自己想后果吧，其重要性不言而喻。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>阿里云发布全新开源操作系统『龙蜥』，支持 X86 64 和 ARM 64 架构及飞腾、海光、兆芯、鲲鹏等芯片</title>
    <link href="https://www.hi-linux.com/posts/20754.html"/>
    <id>https://www.hi-linux.com/posts/20754.html</id>
    <published>2021-10-19T01:00:00.000Z</published>
    <updated>2021-12-18T08:41:42.654Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>近日，2021 云栖大会上，阿里云发布了全新操作系统 <strong>“龙蜥”(Anolis OS)</strong>，并宣布开源。</p><p>据了解，龙蜥操作系统 <strong>定位于服务器市场</strong>，支持 x86、ARM 等多种硬件架构和计算场景。</p><p><strong>它特别针对云原生应用开发做了多重优化，云上典型场景的综合性能可提升 40％，同时故障率可降低 50％，还兼容 CentOS 生态，支持一键迁移，并提供全栈国密能力。</strong></p><p>龙蜥操作系统 <strong>完全开源</strong>，通过开源社区和操作系统厂商等形式提供服务，<strong>技术支持至少 10 年。</strong></p><a id="more"></a><p>未来，<strong>阿里云计划为龙蜥系统投入 20 亿元的专项资金</strong>，并联合 100 家生态合作伙伴推动生态建设。</p><p>事实上，龙蜥操作系统并非新鲜事物，只是首次对外公布而已，<strong>它已经在阿里巴巴内部打磨了 10 年之久，特别是有效支撑了历年来的天猫双 11 活动</strong>，性能和稳定性都经受住了严苛的考验。</p><p>另外，<strong>阿里达摩院操作系统实验室</strong> 同步宣告成立，未来将专注于操作系统的研发、推广。</p><blockquote><p>龙蜥操作系统(Anolis OS) 8.4 版本依然秉承与国际主流 Linux 厂商发行版 100% 兼容的原则，且提供配套的迁移工具，助力用户完美平滑地迁移至龙蜥操作系统(Anolis OS)，满足 CentOS 停服后的各领域、各行业用户的使用习惯和需求。在硬件生态方面通过和 Intel 及国内芯片厂商的合作，支持 Intel、海光、兆芯、飞腾、鲲鹏等一系列芯片平台，进行软、硬一体的优化，充分发挥硬件平台的性能。</p></blockquote><p>在基本库、应用生态上融入了适合云场景新组件，各组件经过云计算场景超大规模部署的打磨和完善，可满足各个行业领域对于不同生产环境下不同方案的实际需求。</p><h2><span id="亮点">亮点</span></h2><ul><li>100% 兼容<strong>国际主流 Linux</strong> 厂商发行版；</li><li>支持 x86_64 和 aarch64 架构及飞腾、海光、兆芯、鲲鹏等芯片，适配 x86 及 arm64 <strong>主流服务器</strong>硬件；</li><li>支持 Linux Kernel <strong>4.19 LTS</strong> 版本并同步上游社区<strong>最新成果</strong>，帮助用户及时获得开源社区创新红利；</li><li>支持开源分布式关系数据库<strong>OceanBase</strong>；</li><li>支持安全容器<strong>Kata Containers</strong>；</li><li>支持开源云原生关系型数据库<strong>PolarDB for PostgreSQL</strong>；</li><li><strong>基础应用组件</strong>升级；<br>Python 3.9/SWIG 4.0/Subversion 1.14/Redis 6/PostgreSQL 13/MariaDB 10.5；</li><li><strong>工具链</strong>升级；<br>GCC Toolset 10/LLVM Toolset 11.0.0/Rust Toolset 1.49.0/Go Toolset 1.15.7；</li><li>提供 CentOS 系统到 Anolis OS 迁移工具，帮助系统及应用的<strong>顺滑迁移</strong>；</li></ul><h2><span id="硬件支撑">硬件支撑</span></h2><h3><span id="支持架构">支持架构</span></h3><p>x86_64 和 aarch64</p><h3><span id="cloud-kernel-平台兼容性">Cloud Kernel 平台兼容性</span></h3><p>Cloud Kernel 内核 <strong>已验证支持的服务器</strong> 如下，后续将逐步增加对其他服务器的支持，也欢迎广大合作伙伴/开发者参与贡献和验证。</p><table><thead><tr><th>名称</th><th>架构</th><th>CPU</th></tr></thead><tbody><tr><td>飞腾</td><td>aarch64</td><td>Phytium FT-2000+/64,Phytium S2500/64</td></tr><tr><td>海光</td><td>x86_64</td><td>Hygon C86 7185 32-core Process</td></tr><tr><td>兆芯</td><td>x86_64</td><td>Zhaoxin KH-37800D</td></tr><tr><td>鲲鹏</td><td>aarch64</td><td>Kunpeng-920</td></tr></tbody></table><h2><span id="发布内容">发布内容</span></h2><p>目前龙蜥最新的稳定版是 7 月份发布的 Anolis OS 8.4，发布内容包括 <strong>ISO、虚拟机镜像和 REPO 源</strong>。</p><h3><span id="iso-列表">ISO 列表</span></h3><table><thead><tr><th><strong>名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>AnolisOS-8.4-x86_64-dvd.iso</td><td>x86_64架构的安装 ISO</td></tr><tr><td>AnolisOS-8.4-aarch64-dvd.iso</td><td>aarch64架构的安装 ISO</td></tr><tr><td>AnolisOS-8.4-src-dvd.iso</td><td>source 包ISO</td></tr></tbody></table><h3><span id="虚拟机镜像列表">虚拟机镜像列表</span></h3><table><thead><tr><th><strong>名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>AnolisOS-8.4-GA-x86_64-ANCK.qcow2</td><td>x86_64架构虚拟机镜像搭配ANCK内核</td></tr><tr><td>AnolisOS-8.4-GA-x86_64-RHCK.qcow2</td><td>x86_64架构虚拟机镜像搭配RHCK内核[注1]</td></tr><tr><td>AnolisOS-8.4-GA-aarch64-ANCK.qcow2</td><td>aarch64架构虚拟机镜像搭配ANCK内核</td></tr><tr><td>AnolisOS-8.4-GA-aarch64-RHCK.qcow2</td><td>aarch64架构虚拟机镜像搭配RHCK内核</td></tr></tbody></table><blockquote><p>注1：RHCK 内核兼容 CentOS 8.4 的内核，当前版本是 kernel-4.18.0-305.an8</p><p>注2：镜像缺省 sudo 用户 anuser，对应登录密码是 anolisos。</p></blockquote><h3><span id="repo-源列表">REPO 源列表</span></h3><table><thead><tr><th><strong>名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>BaseOS</td><td>BaseOS 软件包源，该源目的是提供安装基础的所有核心包。</td></tr><tr><td>AppStream</td><td>AppStream 软件包源，该源提供额外的多场景，多用途的用户态程序，数据库等。该部分引入了额外的 RPM Module 形态。</td></tr><tr><td>PowerTools</td><td>PowerTools 软件包源， 该源提供开发者需要的额外包。</td></tr><tr><td>Plus</td><td>Plus 软件包源，该源提供 OpenAnolis SIG 组专门研发包，如 ANCK 内核，Dragonwell8 JDK等。</td></tr><tr><td>DDE</td><td>DDE 桌面主包以及依赖包</td></tr></tbody></table><h3><span id="下载地址">下载地址</span></h3><ul><li>社区网站</li></ul><p><a href="https://mirrors.openanolis.cn/anolis/8.4/isos/" target="_blank" rel="noopener">https://mirrors.openanolis.cn/anolis/8.4/isos/</a></p><ul><li>阿里云镜像</li></ul><p><a href="https://mirrors.aliyun.com/anolis/8.4/" target="_blank" rel="noopener">https://mirrors.aliyun.com/anolis/8.4/</a></p><h2><span id="参考文档">参考文档</span></h2><ol><li><a href="https://news.mydrivers.com/1/790/790382.htm" target="_blank" rel="noopener">https://news.mydrivers.com/1/790/790382.htm</a></li><li><a href="https://segmentfault.com/a/1190000040419582" target="_blank" rel="noopener">https://segmentfault.com/a/1190000040419582</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日，2021 云栖大会上，阿里云发布了全新操作系统 &lt;strong&gt;“龙蜥”(Anolis OS)&lt;/strong&gt;，并宣布开源。&lt;/p&gt;
&lt;p&gt;据了解，龙蜥操作系统 &lt;strong&gt;定位于服务器市场&lt;/strong&gt;，支持 x86、ARM 等多种硬件架构和计算场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;它特别针对云原生应用开发做了多重优化，云上典型场景的综合性能可提升 40％，同时故障率可降低 50％，还兼容 CentOS 生态，支持一键迁移，并提供全栈国密能力。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;龙蜥操作系统 &lt;strong&gt;完全开源&lt;/strong&gt;，通过开源社区和操作系统厂商等形式提供服务，&lt;strong&gt;技术支持至少 10 年。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
      <category term="阿里云" scheme="https://www.hi-linux.com/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 应用包管理器 Helm 保姆级中文简明教程</title>
    <link href="https://www.hi-linux.com/posts/23277.html"/>
    <id>https://www.hi-linux.com/posts/23277.html</id>
    <published>2021-09-30T01:00:00.000Z</published>
    <updated>2021-09-30T05:02:30.282Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>Helm 是查找、分享和使用软件构建 Kubernetes 的最优方式！</strong></p></blockquote><p><code>Helm</code> 帮助您管理 <code>Kubernetes</code> 应用 —— <code>Helm</code> 图表，即使是最复杂的 <code>Kubernetes</code> 应用程序，都可以帮助您定义，安装和升级。图表 <code>Chart</code> 易于创建、发版、分享和发布，所以停止复制粘贴，开始使用 <code>Helm</code> 吧。</p><ul><li><code>Helm</code> 是什么?</li><li><code>Kubernetes</code> 包管理器，可以简单理解为 <code>apt</code> 或 <code>yml</code> 工具。</li></ul><h2><span id="工具特性">工具特性</span></h2><blockquote><p><strong>Helm 是 CNCF 的毕业项目，由 Helm 社区维护。</strong></p></blockquote><ul><li><strong>复杂性管理</strong></li></ul><p>即使是最复杂的应用，图表 <code>Charts</code> 依然可以描述， 提供使用单点授权的可重复安装应用程序。</p><ul><li><strong>易于升级</strong></li></ul><p>随时随地升级和自定义的钩子消除您升级的痛苦。</p><ul><li><strong>分发简单</strong></li></ul><p>图表 <code>Charts</code> 很容易在公共或私有化服务器上发版，分发和部署站点。</p><ul><li><strong>回滚</strong></li></ul><p>使用 <code>helm rollback</code> 可以轻松回滚到之前的发布版本。</p><a id="more"></a><h2><span id="安装使用">安装使用</span></h2><blockquote><p><strong>工具安装提供多种安装方式</strong></p></blockquote><p><a href="https://helm.sh/zh/docs/topics/plugins/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/plugins/</a></p><ul><li>[1] 获取 Helm 工具 - 包管理器安装<ul><li>安装完成后，解压二进制包并添加到 <code>PATH</code>，就可以使用了！</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># homebrew(macOS)</span></span><br><span class="line">$ brew install helm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chocolatey(Windows)</span></span><br><span class="line">$ choco install kubernetes-helm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apt(Debian/Ubuntu)</span></span><br><span class="line">$ curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -</span><br><span class="line">$ sudo apt-get install apt-transport-https --yes</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"deb https://baltocdn.com/helm/stable/debian/ all main"</span> | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list</span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install helm</span><br></pre></td></tr></table></figure><ul><li>[2] 获取 Helm 工具 - 使用脚本安装<ul><li><code>Helm</code> 现在有个安装脚本可以自动拉取最新的 <code>Helm</code> 版本并在本地安装！</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接执行安装</span></span><br><span class="line">$ curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash</span><br></pre></td></tr></table></figure><ul><li>[3] 获取 Helm 工具 - 二进制版本安装<ul><li>每个 <code>Helm</code> 版本都提供了各种操作系统的二进制版本！</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载需要的版本</span></span><br><span class="line">$ https://github.com/helm/helm/releases</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压压缩包</span></span><br><span class="line">$ tar -zxvf helm-v3.0.0-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移动到需要的目录中</span></span><br><span class="line">$ mv linux-amd64/helm /usr/<span class="built_in">local</span>/bin/helm</span><br></pre></td></tr></table></figure><ul><li>[4] 获取 Charts 图表<ul><li>访问 <a href="https://artifacthub.io/" target="_blank" rel="noopener">Helm 应用中心</a> 浏览公共库大量的图表！</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/kubernetes-new-helm-tool-01-2021-09-28-Tr63vR.jpg" alt="Artifacthub"></p><ul><li>[5] 简单上手使用<ul><li>安装好了 <code>Helm</code> 之后，可以添加一个 <code>chart</code> 仓库！</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加:有效的Helm-chart仓库</span></span><br><span class="line"><span class="comment"># 更新:确定可以拿到最新的charts列表</span></span><br><span class="line">$ helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line">$ helm repo add brigade https://brigadecore.github.io/charts</span><br><span class="line">$ helm repo update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 之后就可以查找相关的charts列表</span></span><br><span class="line">$ $ helm search repo bitnami</span><br><span class="line">NAME                      CHART VERSION      APP VERSION      DESCRIPTION</span><br><span class="line">bitnami/bitnami-common    0.0.9              0.0.9            ...</span><br><span class="line">bitnami/airflow           8.0.2              2.0.0            ...</span><br><span class="line">bitnami/apache            8.2.3              2.4.46        ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 了解到这个chart的基本信息</span></span><br><span class="line">$ helm show chart bitnami/mysql</span><br><span class="line"><span class="comment"># 获取关于该chart的所有信息</span></span><br><span class="line">$ helm show all bitnami/mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装对应版本服务</span></span><br><span class="line">$ helm install bitnami/mysql --generate-name</span><br><span class="line">NAME: mysql-1612624192</span><br><span class="line">LAST DEPLOYED: Sat Feb  6 16:09:56 2021</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES: ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有可被部署的版本</span></span><br><span class="line">$ helm list</span><br><span class="line">NAME                NAMESPACE    REVISION    STATUS      CHART          APP VERSION</span><br><span class="line">mysql-1612624192    default      1           deployed    mysql-8.3.0    8.0.23</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载一个版本</span></span><br><span class="line">$ helm uninstall mysql-1612624192</span><br><span class="line">release <span class="string">"mysql-1612624192"</span> uninstalled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看帮助信息</span></span><br><span class="line">$ helm get -h</span><br></pre></td></tr></table></figure><h2><span id="三大概念">三大概念</span></h2><p><code>Helm</code> 安装 <code>charts</code> 到 <code>Kubernetes</code> 集群中，每次安装都会创建一个新的 <code>release</code>。</p><ul><li>Chart<ul><li><code>Chart</code> 代表着 <code>Helm</code> 包。</li><li>你可以把它看作是 <code>Apt</code> 或 <code>Yum</code> 在 <code>Kubernetes</code> 中的等价物。</li><li>它包含在 <code>Kubernetes</code> 集群内部运行应用程序，工具或服务所需的所有资源定义。</li></ul></li><li>Repository<ul><li><code>Repository</code>(仓库)是用来存放和共享 <code>charts</code> 的地方。</li><li>它就像 <code>Fedora</code> 的软件包仓库，只不过它是供 <code>Kubernetes</code> 包所使用的。</li></ul></li><li>Release<ul><li><code>Release</code> 是运行在 <code>Kubernetes</code> 集群中的 <code>chart</code> 的实例。</li><li>一个 <code>chart</code> 通常可以在同一个集群中安装多次，每一次安装都会创建一个新的 <code>release</code>。</li></ul></li></ul><p><code>Helm</code> 按照以下顺序安装资源(这里列出主要的一些)：</p><ul><li>Namespace</li><li>NetworkPolicy</li><li>ResourceQuota</li><li>LimitRange</li><li>ServiceAccount</li><li>Secret</li><li>SecretList</li><li>ConfigMap</li><li>StorageClass</li><li>PersistentVolume</li><li>PersistentVolumeClaim</li><li>Role</li><li>RoleList</li><li>RoleBinding</li><li>RoleBindingList</li><li>Service</li><li>DaemonSet</li><li>Pod</li><li>ReplicationController</li><li>ReplicaSet</li><li>Deployment</li><li>HorizontalPodAutoscaler</li><li>StatefulSet</li><li>Job</li><li>CronJob</li><li>Ingress</li><li>APIService</li></ul><h2><span id="组织架构">组织架构</span></h2><blockquote><ol><li><a href="https://helm.sh/zh/docs/topics/architecture/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/architecture/</a></li></ol></blockquote><h2><span id="常用操作">常用操作</span></h2><blockquote><ol><li><a href="https://helm.sh/zh/docs/helm/helm/" target="_blank" rel="noopener">https://helm.sh/zh/docs/helm/helm/</a></li></ol></blockquote><table><thead><tr><th style="text-align:left">命令实例</th><th style="text-align:left">对应功能介绍</th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>helm repo add bitnami https://charts.bitnami.com/bitnami</code></strong></td><td style="text-align:left">添加有效的 Helm-chart 仓库</td></tr><tr><td style="text-align:left"><strong><code>helm repo list</code></strong></td><td style="text-align:left">查看配置的 chart 仓库</td></tr><tr><td style="text-align:left"><strong><code>helm search repo wordpress</code></strong></td><td style="text-align:left">从添加的仓库中查找 chart 的名字</td></tr><tr><td style="text-align:left"><strong><code>helm install happy-panda bitnami/wordpress</code></strong></td><td style="text-align:left">安装一个新的 helm 包</td></tr><tr><td style="text-align:left"><strong><code>helm status happy-panda</code></strong></td><td style="text-align:left">来追踪展示 release 的当前状态</td></tr><tr><td style="text-align:left"><strong><code>helm show values bitnami/wordpress</code></strong></td><td style="text-align:left">查看 chart 中的可配置选项</td></tr><tr><td style="text-align:left"><strong><code>helm uninstall happy-panda</code></strong></td><td style="text-align:left">从集群中卸载一个 release</td></tr><tr><td style="text-align:left"><strong><code>helm list</code></strong></td><td style="text-align:left">看到当前部署的所有 release</td></tr><tr><td style="text-align:left"><strong><code>helm pull bitnami/wordpress</code></strong></td><td style="text-align:left">下载和查看一个发布的 chart</td></tr><tr><td style="text-align:left"><strong><code>helm upgrade</code></strong></td><td style="text-align:left">升级 release 版本</td></tr><tr><td style="text-align:left"><strong><code>helm rollback</code></strong></td><td style="text-align:left">恢复 release 版本</td></tr></tbody></table><h2><span id="值传递方式">值传递方式</span></h2><h3><span id="安装前自定义-chart">安装前自定义 chart</span></h3><blockquote><ol><li><p><a href="https://helm.sh/zh/docs/chart_best_practices/conventions/" target="_blank" rel="noopener">https://helm.sh/zh/docs/chart_best_practices/conventions/</a></p></li><li><p><a href="https://helm.sh/zh/docs/chart_best_practices/values/" target="_blank" rel="noopener">https://helm.sh/zh/docs/chart_best_practices/values/</a></p></li></ol></blockquote><p>上述安装方式只会使用 chart 的默认配置选项。很多时候，我们需要自定义 chart 来指定我们想要的配置。</p><p>使用 <code>helm show values</code> 可以查看 chart 中的可配置选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ helm show values bitnami/wordpress</span><br><span class="line"></span><br><span class="line">image:</span><br><span class="line">  registry: docker.io</span><br><span class="line">  repository: bitnami/wordpress</span><br><span class="line">  tag: 5.6.0-debian-10-r35</span><br><span class="line">  [..]</span><br></pre></td></tr></table></figure><p>然后，你可以使用 YAML 格式的文件覆盖上述任意配置项，并在安装过程中使用该文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">'&#123;mariadb.auth.database: user0db, mariadb.auth.username: user0&#125;'</span> &gt; values.yaml</span><br><span class="line">$ helm install -f values.yaml bitnami/wordpress --generate-name</span><br></pre></td></tr></table></figure><p>上述命令将为 MariaDB 创建一个名称为  <code>user0</code> 的默认用户，并且授予该用户访问新建的  <code>user0db</code> 数据库的权限。chart 中的其他默认配置保持不变。</p><p>安装过程中有两种方式传递配置数据：</p><ul><li><code>--values</code> (或  <code>-f</code>)：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件。</li><li><code>--set</code>：通过命令行的方式对指定项进行覆盖。</li></ul><p>如果同时使用两种方式，则  <code>--set</code> 中的值会被合并到  <code>--values</code> 中，但是  <code>--set</code> 中的值优先级更高。在<code>--set</code> 中覆盖的内容会被被保存在 ConfigMap 中。可以通过  <code>helm get values &lt;release-name&gt;</code> 来查看指定 release 中  <code>--set</code> 设置的值。也可以通过运行  <code>helm upgrade</code> 并指定  <code>--reset-values</code> 字段来清除  <code>--set</code> 中设置的值。</p><h3><span id="-set-的格式和限制"><code>--set</code> 的格式和限制</span></h3><p><code>--set</code> 选项使用 0 或多个 name/value 对。最简单的用法类似于：<code>--set name=value</code>，等价于如下 YAML 格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name: value</span><br></pre></td></tr></table></figure><p>多个值使用逗号分割，因此  <code>--set a=b,c=d</code> 的 YAML 表示是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a: b</span><br><span class="line">c: d</span><br></pre></td></tr></table></figure><p>支持更复杂的表达式。例如，<code>--set outer.inner=value</code>被转换成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outer:</span><br><span class="line">  inner: value</span><br></pre></td></tr></table></figure><p>列表使用花括号（<code>{}</code>）来表示。例如，<code>--set name={a, b, c}</code> 被转换成了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">a</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">b</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">c</span></span><br></pre></td></tr></table></figure><p>从 2.5.0 版本开始，可以使用数组下标的语法来访问列表中的元素。例如  <code>--set servers[0].port=80</code> 就变成了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>多个值也可以通过这种方式来设置。<code>--set servers[0].port=80,servers[0].host=example</code> 变成了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">example</span></span><br></pre></td></tr></table></figure><p>如果需要在  <code>--set</code> 中使用特殊字符，你可以使用反斜线来进行转义；<code>--set name=value1\,value2</code> 就变成了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">"value1,value2"</span></span><br></pre></td></tr></table></figure><p>类似的，你也可以转义点  序列（英文句号）。这可能会在 chart 使用  <code>toYaml</code> 函数来解析 annotations，labels，和 node selectors 时派上用场。<code>--set nodeSelector.&quot;kubernetes\.io/role&quot;=master</code> 语法就变成了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodeSelector:</span></span><br><span class="line">  <span class="attr">kubernetes.io/role:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure><p>深层嵌套的数据结构可能会很难用  <code>--set</code> 表达。我们希望 Chart 的设计者们在设计  <code>values.yaml</code> 文件的格式时，考虑到  <code>--set</code> 的使用。（更多内容请查看  <a href="https://helm.sh/docs/chart_template_guide/values_files/" target="_blank" rel="noopener">Values 文件</a>）</p><h2><span id="模板的使用">模板的使用</span></h2><blockquote><ol><li><p><a href="https://helm.sh/zh/docs/howto/charts_tips_and_tricks/" target="_blank" rel="noopener">https://helm.sh/zh/docs/howto/charts_tips_and_tricks/</a></p></li><li><p><a href="https://helm.sh/zh/docs/chart_best_practices/templates/" target="_blank" rel="noopener">https://helm.sh/zh/docs/chart_best_practices/templates/</a></p></li></ol></blockquote><h2><span id="自定义开发">自定义开发</span></h2><blockquote><ol><li><p><a href="https://helm.sh/zh/docs/topics/charts/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/charts/</a></p></li><li><p><a href="https://helm.sh/zh/docs/chart_best_practices/pods/" target="_blank" rel="noopener">https://helm.sh/zh/docs/chart_best_practices/pods/</a></p></li><li><p><a href="https://helm.sh/zh/docs/chart_template_guide/getting_started/" target="_blank" rel="noopener">https://helm.sh/zh/docs/chart_template_guide/getting_started/</a></p></li></ol></blockquote><p><a href="https://helm.sh/zh/docs/topics/charts" target="_blank" rel="noopener">chart 开发指南</a> 介绍了如何开发你自己的 chart。 但是你也可以通过使用  <code>helm create</code> 命令来快速开始：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ helm create deis-workflow</span><br><span class="line">Creating deis-workflow</span><br></pre></td></tr></table></figure><p>现在，<code>./deis-workflow</code> 目录下已经有一个 chart 了。你可以编辑它并创建你自己的模版。</p><p>在编辑 chart 时，可以通过  <code>helm lint</code> 验证格式是否正确。</p><p>当准备将 chart 打包分发时，你可以运行  <code>helm package</code> 命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ helm package deis-workflow</span><br><span class="line">deis-workflow-0.1.0.tgz</span><br></pre></td></tr></table></figure><p>然后这个 chart 就可以很轻松的通过  <code>helm install</code> 命令安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ helm install deis-workflow ./deis-workflow-0.1.0.tgz</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>打包好的 chart 可以上传到 chart 仓库中。查看  <a href="https://helm.sh/zh/docs/topics/chart_repository" target="_blank" rel="noopener">Helm chart 仓库</a>获取更多信息。</p><h2><span id="钩子的使用">钩子的使用</span></h2><blockquote><ol><li><a href="https://helm.sh/zh/docs/topics/charts_hooks/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/charts_hooks/</a></li></ol></blockquote><h2><span id="仓库的创建">仓库的创建</span></h2><blockquote><ol><li><a href="https://helm.sh/zh/docs/topics/chart_repository/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/chart_repository/</a></li><li><a href="https://helm.sh/zh/docs/topics/registries/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/registries/</a></li></ol></blockquote><h2><span id="自动化发布">自动化发布</span></h2><blockquote><p>Chart 发布操作用以自动化 GitHub 的页面 Chart</p></blockquote><h2><span id="新版本变化">新版本变化</span></h2><blockquote><ol><li><a href="https://helm.sh/zh/docs/topics/v2_v3_migration/" target="_blank" rel="noopener">https://helm.sh/zh/docs/topics/v2_v3_migration/</a></li></ol></blockquote><h2><span id="参考链接">参考链接</span></h2><ul><li><a href="https://helm.sh/zh/" target="_blank" rel="noopener">Helm 官方中文文档</a></li></ul><blockquote><p>本文转载自：「 Escapelife 的博客 」，原文：<a href="https://tinyurl.com/53hjshe2" target="_blank" rel="noopener">https://tinyurl.com/53hjshe2</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Helm 是查找、分享和使用软件构建 Kubernetes 的最优方式！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Helm&lt;/code&gt; 帮助您管理 &lt;code&gt;Kubernetes&lt;/code&gt; 应用 —— &lt;code&gt;Helm&lt;/code&gt; 图表，即使是最复杂的 &lt;code&gt;Kubernetes&lt;/code&gt; 应用程序，都可以帮助您定义，安装和升级。图表 &lt;code&gt;Chart&lt;/code&gt; 易于创建、发版、分享和发布，所以停止复制粘贴，开始使用 &lt;code&gt;Helm&lt;/code&gt; 吧。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Helm&lt;/code&gt; 是什么?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Kubernetes&lt;/code&gt; 包管理器，可以简单理解为 &lt;code&gt;apt&lt;/code&gt; 或 &lt;code&gt;yml&lt;/code&gt; 工具。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;工具特性&quot;&gt;工具特性&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Helm 是 CNCF 的毕业项目，由 Helm 社区维护。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;复杂性管理&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;即使是最复杂的应用，图表 &lt;code&gt;Charts&lt;/code&gt; 依然可以描述， 提供使用单点授权的可重复安装应用程序。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;易于升级&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随时随地升级和自定义的钩子消除您升级的痛苦。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分发简单&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;图表 &lt;code&gt;Charts&lt;/code&gt; 很容易在公共或私有化服务器上发版，分发和部署站点。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;回滚&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用 &lt;code&gt;helm rollback&lt;/code&gt; 可以轻松回滚到之前的发布版本。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Helm" scheme="https://www.hi-linux.com/tags/Helm/"/>
    
  </entry>
  
  <entry>
    <title>如何优雅的使用 Nginx 缓存机制将网站访问速度提高 10 倍</title>
    <link href="https://www.hi-linux.com/posts/64107.html"/>
    <id>https://www.hi-linux.com/posts/64107.html</id>
    <published>2021-09-28T01:00:00.000Z</published>
    <updated>2021-09-28T01:23:29.122Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Nginx</code> 缓存作为性能优化的一个重要手段，可以极大减轻后端服务器的负载。下面我们将介绍 <code>Nginx</code> 缓存配置的相关指令以及 <code>http</code> 缓存机制，以及 <code>Nginx</code> 缓存实践案例分析。</p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-90-2021-09-14-CeSSM9.jpg" alt="Nginx缓存机制详解 - 缓存示意图"></p><h2><span id="nginx-缓存示例">Nginx 缓存示例</span></h2><blockquote><p><strong>实例演示，缓存是怎么出现的，怎么查看！</strong></p></blockquote><p>当我们代开某个网站，如 <code>baidu.com</code>，我们可以看到 <code>size</code> 这一列有一些 <code>js</code> 标识为 <code>disk cache</code>，这里就是应用到了缓存。</p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-91-2021-09-14-yYaa6H.png" alt="Nginx缓存机制详解 - 缓存截图"></p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-92-2021-09-14-N6MxNz.png" alt="Nginx缓存机制详解 - 缓存截图"></p><a id="more"></a><h2><span id="http-缓存机制">HTTP 缓存机制</span></h2><blockquote><p><strong>HTTP 的缓存流程如下图所示</strong></p></blockquote><ul><li>缓存，可以分为强制缓存和对比缓存。</li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-93-2021-09-14-p0P9RY.png" alt="Nginx缓存机制详解 - 浏览器缓存处理流程图"></p><h2><span id="nginx-强制缓存">Nginx 强制缓存</span></h2><blockquote><p><strong>介绍强制缓存是什么？以及可能造成这个原因的配置参数！</strong></p></blockquote><p>浏览器不会向服务器发送任何请求，直接从本地缓存中读取缓存数据并返回 <code>200</code> 状态码，如下图所示。如果缓存过期再找服务器，其过程如下：</p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-94-2021-09-14-wF4Kp5.png" alt="Nginx缓存机制详解 - 强制缓存示意图"></p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-95-2021-09-14-QAm42h.png" alt="Nginx缓存机制详解 - 缓存截图"></p><p>可以造成强制缓存的字段，有如下几个：</p><ul><li>Expires<ul><li>位置: <code>HTTP Response Header</code></li><li>说明: <code>Expires</code> 是服务端返回的到期时间。如果下一次请求如果小于服务端返回的过期时间，则直接使用缓存数据。<code>Expires</code> 是 <code>HTTP1.0</code> 的东西，现在浏览器默认都是使用 <code>HTTP1.1</code>。而且由于该值是有服务端生成，而客户端的时间和服务端的时间有可能不一致，导致存在一定误差。所以 <code>HTTP1.1</code> 使用 <code>Cache-Control</code> 替代。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line">Expires: Mon, 22 Jul 2019 11:08:59 GMT</span><br></pre></td></tr></table></figure><ul><li>Cache-Control<ul><li>位置: <code>HTTP Response Header</code></li><li>说明: 缓存策略定义</li><li><code>max-age</code>: 标识资源能够被缓存的最大时间</li><li><code>public</code>: 表示该响应任何中间人，包括客户端和代理服务器都可以缓存</li><li><code>private</code>: 表示该响应只能用于浏览器私有缓存中，中间人（代理服务器）不能缓存此响应</li><li><code>no-cache</code>: 需要使用对比缓存（<code>Last-Modified/If-Modified-Since/Etag/If-None-Match</code>）来验证缓存数据</li><li><code>no-store</code>: 所有内容都不会缓存，强制缓存和对比缓存都不会触发</li></ul></li></ul><h2><span id="nginx-对比缓存">Nginx 对比缓存</span></h2><blockquote><p><strong>介绍使用缓存和不使用缓存的区别和对比！</strong></p></blockquote><p>浏览器在第一次请求数据时，服务器会将缓存的标识与数据一起返回给浏览器，浏览器将这两个缓存到本地缓存数据库中。</p><p>再次请求数据时，就会在请求 <code>header</code> 中带上缓存的标识发送给服务器，服务器根据缓存标识对比，如果发生变化，则返回 <code>200</code> 状态码，返回完整的响应数据给浏览器，如果未发生更新，则返回 <code>304</code> 状态码告诉浏览器继续使用缓存数据。</p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-96-2021-09-14-xaQuoZ.png" alt="Nginx缓存机制详解 - 对比缓存示意图"></p><p>如下图比较所示，在第一次请求时，没有使用缓存。而在第二次使用缓存时，可以明显看到两者请求的时间不一样，后者时间少很多。这是因为服务端如果进行缓存比较后发现未更新，只返回 <code>header</code> 部分，并返回 <code>304</code> 状态码通知客户端使用本地缓存，没有将报文的 <code>body</code> 部分返回给浏览器，所以请求时间和报文大小才明显优化。别小看这几十毫秒，当访问量很大时，这里就优化了很多时间、减少了很多服务器压力。</p><ul><li>第一次访问，未使用缓存：</li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-97-2021-09-14-5rMVz9.png" alt="Nginx缓存机制详解 - 使用缓存前时间和大小"></p><ul><li>第二次访问，使用缓存：</li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-98-2021-09-14-LTXTz4.png" alt="Nginx缓存机制详解 - 使用缓存后示意图"></p><ul><li>HTTP 请求和响应报文结构如下图所示：</li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-99-2021-09-14-USdFeo.png" alt="Nginx缓存机制详解 - http请求和响应报文结构"></p><p>会造成对比缓存的字段如下：</p><ul><li>Last-Modified<ul><li>位置: <code>HTTP Response Header</code></li><li>说明: 第一次请求时，服务器会在响应头里设置该参数，告诉浏览器该资源的最后修改时间。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line">Last-Modified: Tue, 12 Jan 2010 13:48:00 GMT</span><br></pre></td></tr></table></figure><ul><li>If-Modified-Since<ul><li>位置: <code>HTTP Request Header</code></li><li>说明: 再次（注意不是第一次）请求服务器时，客户端浏览器通过此字段通知服务器上次请求时，服务器返回的资源最后修改时间。服务器收到请求后，发现 <code>header</code> 中有 <code>If-Modified-Since</code> 字段，则与被请求资源的最后修改时间进行对比。若资源的最后修改时间大于 <code>If-Modified-Since</code>，则说明资源被修改过，则响应返回完整的内容，返回状态码 <code>200</code>。 若资源的最后修改时间小于或等于 <code>If-Modified-Since</code>，则说明资源未修改，则返回 <code>304</code> 状态码，告诉浏览器继续使用所保存的缓存数据。</li></ul></li><li>Etag<ul><li>位置: HTTP Response Header</li><li>说明: 服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识（由服务端生成）。</li><li>优先级: 高于 Last-Modified 与 If-Modified-Since</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-100-2021-09-14-tVc0UC.png" alt="Nginx缓存机制详解 - Etag"></p><ul><li>If-None-Match<ul><li>位置: <code>HTTP Request Header</code></li><li>说明: 再次请求服务器时，通过此字段通知服务器客户端缓存的资源的唯一标识。服务器收到请求 <code>header</code> 周发现有 <code>If-None-Match</code> 字段，则与被请求资源的唯一标识进行对比。 如果不一样，说明资源被修改过，则返回完整的响应，状态码 <code>200</code>。 如果一样，说明资源未被修改过，则返回 <code>304</code> 状态码，告诉浏览器继续使用缓存的数据。</li></ul></li></ul><h2><span id="nginx-缓存实践">Nginx 缓存实践</span></h2><blockquote><p><strong>实际配置和演示一下，使用缓存的效果！</strong></p></blockquote><ul><li><strong>配置文件的内容，如下所示：</strong></li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">user</span>  nginx;</span><br><span class="line"><span class="attribute">pid</span> /run/nginx.pid;</span><br><span class="line"><span class="attribute">worker_processes</span>  auto;</span><br><span class="line"><span class="attribute">worker_rlimit_nofile</span> <span class="number">100000</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span>  <span class="number">2048</span>;</span><br><span class="line">    <span class="attribute">multi_accept</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">access_log</span> <span class="literal">off</span>;</span><br><span class="line">    <span class="attribute">error_log</span>  /data/log/nginx-<span class="number">1</span>.<span class="number">0</span>/error.log  <span class="literal">error</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">proxy_cache_path</span> /data/nginx-<span class="number">1</span>.<span class="number">0</span>/cache levels=<span class="number">1</span>:<span class="number">2</span> keys_zone=cache_zone:<span class="number">10m</span> inactive=<span class="number">60m</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">        <span class="attribute">server_name</span> localhost;</span><br><span class="line">        <span class="attribute">root</span> /usr/local/services/nginx-<span class="number">1</span>.<span class="number">0</span>/html/;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">location</span> / &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">location</span> ~.*\.(gif|jpg|png|css|js)(.*) &#123;</span><br><span class="line">            <span class="attribute">proxy_cache</span> cache_zone;</span><br><span class="line">            <span class="attribute">proxy_cache_valid</span> <span class="number">200</span> <span class="number">302</span> <span class="number">24h</span>;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">1d</span>;</span><br><span class="line">            <span class="attribute">add_header</span> X-Proxy-Cache <span class="variable">$upstream_cache_status</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>实际的测试情况，如下所示：</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_16_4_centos conf]<span class="comment"># curl -I http://localhost/test.js</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.14.0</span><br><span class="line">Date: Sun, 21 Jul 2019 12:35:06 GMT</span><br><span class="line">Content-Type: text/plain</span><br><span class="line">Content-Length: 12</span><br><span class="line">Last-Modified: Sun, 21 Jul 2019 12:33:32 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: <span class="string">"5d345b9c-c"</span></span><br><span class="line">Expires: Mon, 22 Jul 2019 12:35:06 GMT</span><br><span class="line">Cache-Control: max-age=86400</span><br><span class="line">Accept-Ranges: bytes</span><br></pre></td></tr></table></figure><ul><li>我们再以图片为例，当我们第一次请求 <code>http://localhost/google_logo.jpg</code>，服务端返回了该资源的唯一标识 <code>Etag</code> 给我们。</li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-101-20210914125805020-2021-09-14-aMfHFo.png" alt="Nginx缓存机制详解"></p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-102-2021-09-14-lMBLXI.png" alt="Nginx缓存机制详解"></p><ul><li>我们第二次请求时，可以发现 http 报文的体积和响应实践大大缩减，说明我们的缓存发回了作用。</li></ul><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-103-2021-09-14-ZYgfzM.png" alt="Nginx缓存机制详解"></p><p><img src="https://img.hi-linux.com/staticfile/linux-nginx-server-104-2021-09-14-oM8eQF.png" alt="Nginx缓存机制详解"></p><h2><span id="相关的参考链接">相关的参考链接</span></h2><blockquote><p><strong>送人玫瑰，手有余香！</strong></p></blockquote><ul><li><a href="https://shuwoom.com/?p=4311#comment-3660" target="_blank" rel="noopener">NGINX 缓存机制详解</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/erzmh7uv" target="_blank" rel="noopener">https://tinyurl.com/erzmh7uv</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Nginx&lt;/code&gt; 缓存作为性能优化的一个重要手段，可以极大减轻后端服务器的负载。下面我们将介绍 &lt;code&gt;Nginx&lt;/code&gt; 缓存配置的相关指令以及 &lt;code&gt;http&lt;/code&gt; 缓存机制，以及 &lt;code&gt;Nginx&lt;/code&gt; 缓存实践案例分析。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/linux-nginx-server-90-2021-09-14-CeSSM9.jpg&quot; alt=&quot;Nginx缓存机制详解 - 缓存示意图&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Nginx-缓存示例&quot;&gt;Nginx 缓存示例&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;实例演示，缓存是怎么出现的，怎么查看！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当我们代开某个网站，如 &lt;code&gt;baidu.com&lt;/code&gt;，我们可以看到 &lt;code&gt;size&lt;/code&gt; 这一列有一些 &lt;code&gt;js&lt;/code&gt; 标识为 &lt;code&gt;disk cache&lt;/code&gt;，这里就是应用到了缓存。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/linux-nginx-server-91-2021-09-14-yYaa6H.png&quot; alt=&quot;Nginx缓存机制详解 - 缓存截图&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/linux-nginx-server-92-2021-09-14-N6MxNz.png&quot; alt=&quot;Nginx缓存机制详解 - 缓存截图&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="https://www.hi-linux.com/categories/nginx/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Nginx" scheme="https://www.hi-linux.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>如何优雅的通过 ApiServer 远程访问 Kubernetes 集群</title>
    <link href="https://www.hi-linux.com/posts/60537.html"/>
    <id>https://www.hi-linux.com/posts/60537.html</id>
    <published>2021-09-27T01:00:00.000Z</published>
    <updated>2021-09-27T01:51:42.085Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在研发时，需要直接连接远端 Kubernetes 集群。通常的做法是，将 <code>/etc/kubernetes/admin.conf</code> 拷贝到本地 <code>~/.kube/kubeconfig</code>。</p><p>但是 kubeconfig 的 server 地址是 <code>kubernetes.default.svc</code>。因此，我们需要配置一个 hosts:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.1.1.1 kubernetes.default.svc</span><br></pre></td></tr></table></figure><p>如果需要在不同集群之间切换，不仅需要更换 kubeconfig，还需要修改 hosts。下面介绍一种方法，可以直接将远程访问地址，添加到集群的证书中，节省修改 hosts 的步骤，同时还能让人更容易的区分不同集群。</p><h2><span id="查看-apiserver-证书包含哪些地址">查看 Apiserver 证书包含哪些地址</span></h2><ol><li>进入证书目录</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;etc&#x2F;kubernetes&#x2F;pki</span><br></pre></td></tr></table></figure><a id="more"></a><ol start="2"><li>查看证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ openssl x509 -in apiserver.crt -noout -text|grep -A  2 &#39;Alternative&#39;</span><br><span class="line"></span><br><span class="line">X509v3 Subject Alternative Name:</span><br><span class="line">                DNS:1-1-1-1, DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, DNS:lb-apiserver.kubernetes.local, DNS:localhost, IP Address:1.1.1.1</span><br></pre></td></tr></table></figure><p>这里如果只允许通过 1.1.1.1 访问集群的 Apiserver。如果需要使用域名，<code>kubernetes、kubernetes.default、kubernetes.default.svc</code> 等，则需要配置 hosts 将其指向 1.1.1.1 。</p><h2><span id="添加新的域名或-ip-到证书">添加新的域名或 IP 到证书</span></h2><ol><li>备份证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;etc&#x2F;kubernetes&#x2F;pki</span><br><span class="line">$ mv apiserver.crt apiserver.crt.bak</span><br><span class="line">$ mv apiserver.key apiserver.key.bak</span><br></pre></td></tr></table></figure><ol start="2"><li>修改 <code>/etc/kubernetes/kubeadm-config.yaml</code></li></ol><p>在 ClusterConfiguration 的 apiServer 字段下，找到 certSANs。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io&#x2F;v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">...</span><br><span class="line">  certSANs:</span><br><span class="line">    - kubernetes</span><br><span class="line">    - kubernetes.default</span><br><span class="line">    - kubernetes.default.svc</span><br><span class="line">    - kubernetes.default.svc.cluster.local</span><br><span class="line">    - 10.233.0.1</span><br></pre></td></tr></table></figure><p>在 certSANs 中添加远程访问的域名或 IP 地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">certSANs:</span><br><span class="line">  - remote.doamin.com</span><br><span class="line">  - 1.2.3.4</span><br><span class="line">  - kubernetes</span><br><span class="line">  - kubernetes.default</span><br><span class="line">  - kubernetes.default.svc</span><br><span class="line">  - kubernetes.default.svc.cluster.local</span><br><span class="line">  - 10.233.0.1</span><br></pre></td></tr></table></figure><p>如果你在 <code>/etc/kubernetes/</code> 目录中没有找到 kubeadm-config.yaml 文件，不要紧张，你可以使用下面的方式生成一个当前集群的配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get cm kubeadm-config  -n kube-system -o yaml &gt; &#x2F;etc&#x2F;kubernetes&#x2F;kubeadm-config.yaml</span><br><span class="line">或者</span><br><span class="line">$ kubeadm config view | tee &#x2F;etc&#x2F;kubernetes&#x2F;kubeadm-config.yaml</span><br></pre></td></tr></table></figure><p>当然你的集群的配置文件中可能没有 <code>certSANs</code> 配置段，你可以直接加在类似下面的位置处：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiServer:</span><br><span class="line">  certSANs:</span><br><span class="line">    - remote.doamin.com</span><br><span class="line">    - 1.2.3.4</span><br><span class="line">    - kubernetes</span><br><span class="line">    - kubernetes.default</span><br><span class="line">    - kubernetes.default.svc</span><br><span class="line">    - kubernetes.default.svc.cluster.local</span><br><span class="line">    - 10.233.0.1</span><br><span class="line">  extraArgs:</span><br><span class="line">    authorization-mode: Node,RBAC</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io&#x2F;v1beta2</span><br><span class="line">....</span><br></pre></td></tr></table></figure><ol start="3"><li>重新生成证书</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm init phase certs apiserver --config &#x2F;etc&#x2F;kubernetes&#x2F;kubeadm-config.yaml</span><br></pre></td></tr></table></figure><ol start="4"><li>再次查看证书</li></ol><p>检查输出的结果中，是否包含前面增加的公网 IP，如有则证明操作成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ openssl x509 -in pki&#x2F;apiserver.crt -noout -text | grep 1.2.3.4</span><br><span class="line">                IP Address:192.168.0.8, IP Address: 1.2.3.4</span><br></pre></td></tr></table></figure><ol start="5"><li>重启 kube-apiserver</li></ol><ul><li>如果是高可用集群</li></ul><p>直接杀死当前节点的 kube-apiserver 进程，等待 kubelet 拉起 kube-apiserver 即可。需要在三个节点执行步骤 1 到步骤 4，逐一更新。</p><ul><li>如果是非高可用集群</li></ul><p>杀死 kube-apiserver 可能会导致服务有中断，需要在业务低峰的时候操作。</p><p>进入 <code>/etc/kubernetes/manifests</code> 目录下，移动 kube-apiserver.yaml 文件至其它位置，然后又移回来即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-apiserver.yaml &#x2F;root&#x2F;</span><br><span class="line">$ mv &#x2F;root&#x2F;kube-apiserver.yaml &#x2F;etc&#x2F;kubernetes&#x2F;manifests</span><br></pre></td></tr></table></figure><ol start="6"><li>修改 kubeconfig 中的 server ip</li></ol><p>最后，你只需要将 <code>kubeconfig</code> 文件中 <code>server</code> 地址修改为 <code>1.2.3.4</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">...</span><br><span class="line">    server: https:&#x2F;&#x2F;1.2.3.4:6443</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>保存之后，就可以直接通过公网 IP 访问 Kubernetes 集群。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node</span><br></pre></td></tr></table></figure><h2><span id="参考">参考</span></h2><ol><li><a href="https://www.chenshaowen.com/blog/how-to-add-entrance-to-kubernetes-apiserver.html" target="_blank" rel="noopener">https://www.chenshaowen.com/blog/how-to-add-entrance-to-kubernetes-apiserver.html</a></li><li><a href="https://kubesphereio.com/post/add-public-ip-to-kubernetes-apiserver-operation-guide/" target="_blank" rel="noopener">https://kubesphereio.com/post/add-public-ip-to-kubernetes-apiserver-operation-guide/</a></li><li><a href="https://stackoverflow.com/questions/61023319/where-i-can-find-kubeadm-config-yaml-on-my-kubernetes-cluster" target="_blank" rel="noopener">https://stackoverflow.com/questions/61023319/where-i-can-find-kubeadm-config-yaml-on-my-kubernetes-cluster</a></li><li><a href="https://help.hcltechsw.com/connections/v6/admin/install/cp_prereqs_upgrade_latest_implementation.html" target="_blank" rel="noopener">https://help.hcltechsw.com/connections/v6/admin/install/cp_prereqs_upgrade_latest_implementation.html</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在研发时，需要直接连接远端 Kubernetes 集群。通常的做法是，将 &lt;code&gt;/etc/kubernetes/admin.conf&lt;/code&gt; 拷贝到本地 &lt;code&gt;~/.kube/kubeconfig&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;但是 kubeconfig 的 server 地址是 &lt;code&gt;kubernetes.default.svc&lt;/code&gt;。因此，我们需要配置一个 hosts:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1.1.1.1 kubernetes.default.svc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如果需要在不同集群之间切换，不仅需要更换 kubeconfig，还需要修改 hosts。下面介绍一种方法，可以直接将远程访问地址，添加到集群的证书中，节省修改 hosts 的步骤，同时还能让人更容易的区分不同集群。&lt;/p&gt;
&lt;h2 id=&quot;查看-Apiserver-证书包含哪些地址&quot;&gt;查看 Apiserver 证书包含哪些地址&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;进入证书目录&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cd &amp;#x2F;etc&amp;#x2F;kubernetes&amp;#x2F;pki&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款超实用的查看容器系统资源真实使用情况的工具 topic</title>
    <link href="https://www.hi-linux.com/posts/36129.html"/>
    <id>https://www.hi-linux.com/posts/36129.html</id>
    <published>2021-09-23T01:00:00.000Z</published>
    <updated>2021-09-23T01:22:23.907Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>容器通过 cgroups 和 namespace 实现了资源的轻量级隔离和限制，但容器中的 /proc 文件实际上是宿主机的，因此在执行 top 命令查看容器运行信息时，部分指标显示不正确，例如启动时间、用户数、平均负载、cpu 使用率、内存使用率。</p><p>目前比较通用的解决方案是通过 lxcfs，将容器中相应的文件通过 fuse 劫持 read 调用，在打开时显示为容器信息，从而统一解决各种系统状态诊断工具的问题。</p><a id="more"></a><p>考虑到部署 lxcfs 有一定的成本，topic(top in container) 的思路则是改造 top 命令，去适配容器，读取容器中反映真实运行情况的系统文件，从而展示正确的容器运行信息，对于用户而言成本更低。</p><p>如下，在一个 1C 和 1Gi 的容器中运行 <code>stress --cpu 2</code>，通过 topic 和 top 查看容器的运行状态：</p><p><img src="https://img.hi-linux.com/staticfile/topic-2021-09-16-xCY4pd.png" alt="topic"></p><p><img src="https://img.hi-linux.com/staticfile/top-2021-09-16-5XrCD7.png" alt="top"></p><p>可以看到，topic 比较好的解决了容器运行信息的问题：</p><ul><li>topic 查看到的 CPU 使用率，其 us 为 99.8%，而 top 查看到的是 13.2%（实为宿主机的 us 信息）</li><li>topic 查看到的 Mem 是 1Gi，而 top 查看到的是 16Gi（实为宿主机的内存信息）</li><li>topic 查看到的 user 数是 11，而 top 查看到的 user 数是 1（实为宿主机的当前登录用户数）</li><li>topic 查看到的容器运行时间为 2days 10:35，而 top 查看到的是 20days 1:57（实为宿主机的运行时间）</li><li>topic 和 top 的进程相关信息显示基本一致。</li></ul><p>如果你需要使用，可以通过下面地址下载 topic 到容器中运行（记得加上执行权限）。</p><ol><li><p>下载地址：<a href="https://silenceshell-1255345740.cos.ap-shanghai.myqcloud.com/topic/topic" target="_blank" rel="noopener">https://silenceshell-1255345740.cos.ap-shanghai.myqcloud.com/topic/topic</a></p></li><li><p>项目地址：<a href="https://github.com/silenceshell/topic" target="_blank" rel="noopener">https://github.com/silenceshell/topic</a></p></li></ol><blockquote><p>本文转载自：「 Zlatan Eevee 」，原文：<a href="https://tinyurl.com/rxdb5n72" target="_blank" rel="noopener">https://tinyurl.com/rxdb5n72</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器通过 cgroups 和 namespace 实现了资源的轻量级隔离和限制，但容器中的 /proc 文件实际上是宿主机的，因此在执行 top 命令查看容器运行信息时，部分指标显示不正确，例如启动时间、用户数、平均负载、cpu 使用率、内存使用率。&lt;/p&gt;
&lt;p&gt;目前比较通用的解决方案是通过 lxcfs，将容器中相应的文件通过 fuse 劫持 read 调用，在打开时显示为容器信息，从而统一解决各种系统状态诊断工具的问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>5 个冷门但非常实用的 Kubectl 使用技巧，99% 的人都不知道</title>
    <link href="https://www.hi-linux.com/posts/11484.html"/>
    <id>https://www.hi-linux.com/posts/11484.html</id>
    <published>2021-09-13T01:00:00.000Z</published>
    <updated>2021-09-13T01:39:57.930Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>kubectl 是 K8s 官方附带的命令行工具, 可以方便的操作 K8s 集群. 这篇文章主要介绍一些 kubectl 的别样用法, 希望读者有一定基础的 K8s 使用经验.</p><p>有一篇文章也介绍了一些技巧, 写博客的时候正好搜到了, 正好也分享出来吧.</p><ul><li><a href="https://blog.flant.com/ready-to-use-commands-and-tips-for-kubectl/" target="_blank" rel="noopener">Ready-to-use commands and tips for kubectl</a></li></ul><h2><span id="打印当前使用的api">打印当前使用的API</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># kubectl 的主要作用就是与 ApiServer 进行交互, 而交互的过程, 我们可以通过下面的方式来打印, </span><br><span class="line"># 这个命令尤其适合调试自己的api接口时使用.</span><br><span class="line">$ kubectl get ns -v&#x3D;9</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/20210816195205-2021-08-23-FOJY7v.png" alt></p><a id="more"></a><h2><span id="按状态筛选容器以及删除">按状态筛选容器以及删除</span></h2><p>这是我在这里学到的命令: <a href="https://computingforgeeks.com/force-delete-evicted-terminated-pods-in-kubernetes/" target="_blank" rel="noopener">Force Delete Evicted / Terminated Pods in Kubernetes</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces --field-selector status.phase&#x3D;Pending -o json | \</span><br><span class="line">  jq &#39;.items[] | &quot;kubectl delete pods \(.metadata.name) -n \(.metadata.namespace)&quot;&#39; | \</span><br><span class="line">  xargs -n 1 bash -c</span><br><span class="line"></span><br><span class="line"># 这个命令要拆开来看</span><br><span class="line"># 首先, 获取所有 ns 中状态为 Pending 的 pods, 并以 json 形式输出</span><br><span class="line"># 这个语句其实由很多变体, 比如,我想查找 Failed 的状态, 或是某个 deployment</span><br><span class="line"></span><br><span class="line">kubectl get pods --all-namespaces --field-selector status.phase&#x3D;Pending -o json </span><br><span class="line"></span><br><span class="line"># 针对 json 变量进行处理, 生成可用的脚本</span><br><span class="line"># 这里是我想介绍的重点, 利用jq以及kubectl的输出, 构建出可用的命令</span><br><span class="line">jq &#39;.items[] | &quot;kubectl delete pods \(.metadata.name) -n \(.metadata.namespace)&quot;&#39;</span><br><span class="line"></span><br><span class="line"># 执行每一条命令</span><br><span class="line"># 注意, 这种命令一定要好好调试, 删掉预期之外的pod就不好了.</span><br><span class="line">xargs -n 1 bash -c</span><br><span class="line"></span><br><span class="line"># 例如, 下面的语句可以找到所有的Pods并打印可以执行的语句</span><br><span class="line">$ kubectl get pods --all-namespaces --field-selector status.phase&#x3D;Running -o json | \</span><br><span class="line">  jq &#39;.items[] | &quot;kubectl get pods \(.metadata.name) -o wide -n \(.metadata.namespace)&quot;&#39;</span><br><span class="line"></span><br><span class="line">&quot;kubectl get pods metrics-server-6d684c7b5-gtd6q -o wide -n kube-system&quot;</span><br><span class="line">&quot;kubectl get pods local-path-provisioner-58fb86bdfd-98frc -o wide -n kube-system&quot;</span><br><span class="line">&quot;kubectl get pods nginx-deployment-574b87c764-xppmx -o wide -n default&quot;</span><br><span class="line"></span><br><span class="line"># 当然, 如果只是删除单个NS下面的一些pods, 我会选择下面的方法, 但是它操作多个NS就很不方便了.</span><br><span class="line">$ kubectl -n default get pods  | grep Completed | awk &#39;&#123;print $1&#125;&#39; | xargs kubectl -n default delete pods</span><br></pre></td></tr></table></figure><h2><span id="统计具体某台机器上运行的所有pod">统计具体某台机器上运行的所有pod</span></h2><blockquote><p>kubectl 可以使用两种选择器, 一种是 label, 一种是 field, 可以看官网的介绍:</p><ul><li><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">Labels and Selectors</a></li><li><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/" target="_blank" rel="noopener">Field Selectors</a></li></ul></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 它是一种选择器, 可以与上面的 awk 或者 xargs 配合使用.</span><br><span class="line"># 我个人平时都不喜欢用这个, 直接 get 全部 pods, 然后 grep 查找感觉更快</span><br><span class="line">$ kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName&#x3D;pve-node1</span><br></pre></td></tr></table></figure><h2><span id="统计-pod-在不同机器的具体数量分布">统计 Pod 在不同机器的具体数量分布</span></h2><p>不知道有读者看过我的这篇文章: <a href="https://corvo.myseu.cn/2021/04/30/2021-04-30-%E5%9F%BA%E4%BA%8Ekubernetes%E7%9A%84PaaS%E5%B9%B3%E5%8F%B0%E4%B8%AD%E7%BB%86%E5%8A%9B%E5%BA%A6%E6%8E%A7%E5%88%B6pod/" target="_blank" rel="noopener">基于 Kubernetes 的 PaaS 平台中细力度控制 pods 方案的实现</a>. 均衡分布的工作前提是得知pod在各个机器的分布情况. 最好的办法就是我们得到pod信息之后进行简单的统计, 这个工作可以使用<code>awk</code>实现.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n default get pods -o wide -l app&#x3D;&quot;nginx&quot; | awk &#39;&#123;print $7&#125;&#39;|\</span><br><span class="line"> awk &#39;&#123; count[$0]++  &#125; </span><br><span class="line"> END &#123; </span><br><span class="line">   printf(&quot;%-35s: %s\n&quot;,&quot;Word&quot;,&quot;Count&quot;);</span><br><span class="line">   for(ind in count)&#123;</span><br><span class="line">    printf(&quot;%-35s: %d\n&quot;,ind,count[ind]);</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;&#39;</span><br><span class="line"></span><br><span class="line"># 执行结果如下</span><br><span class="line">Word                               : Count</span><br><span class="line">NODE                               : 1</span><br><span class="line">pve-node1                          : 1</span><br><span class="line">pve-node2                          : 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># awk 的语法我没深入了解, 有兴趣的读者可以研究看看, 这里我就不求甚解了.</span><br></pre></td></tr></table></figure><h2><span id="kubectl-proxy-的使用">kubectl Proxy 的使用</span></h2><p>你可以理解为这个命令为 K8s 的 ApiServer 做了一层代理, 使用该代理, 你可以直接调用 API 而不需要经过鉴权. 启动之后, 甚至可以实现 <code>kubectl</code> 套娃, 下面是一个例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 当你没有设置 kubeconfig 而直接调用 kubectl 时</span><br><span class="line">$ kubectl get ns -v&#x3D;9</span><br><span class="line"># 可以打印出下面类似的错误</span><br><span class="line">$ curl -k -v -XGET  -H &quot;Accept: application&#x2F;json, *&#x2F;*&quot; -H &quot;User-Agent: kubectl&#x2F;v1.21.3 (linux&#x2F;amd64) kubernetes&#x2F;ca643a4&quot; &#39;http:&#x2F;&#x2F;localhost:8080&#x2F;api?timeout&#x3D;32s&#39;</span><br><span class="line">skipped caching discovery info due to Get &quot;http:&#x2F;&#x2F;localhost:8080&#x2F;api?timeout&#x3D;32s&quot;: dial tcp 127.0.0.1:8080: connect: connection refused                     </span><br><span class="line"># 也就是说当你不指定kubeconfig文件时, kubectl会默认访问本机的8080端口</span><br><span class="line"># 那么我们先启动一个kubectl proxy, 然后指定监听8080, 再使用kubectl直接访问, 是不是就可行了呢, </span><br><span class="line"># 事实证明, 安全与预想一致.</span><br><span class="line">$ KUBECONFIG&#x3D;~&#x2F;.kube&#x2F;config-symv3 kubectl proxy  -p 8080</span><br><span class="line">$ kubectl get ns</span><br><span class="line">NAME                           STATUS   AGE</span><br><span class="line">default                        Active   127d</span><br></pre></td></tr></table></figure><blockquote><p>默认启动的 Proxy 是屏蔽了某些 API  的, 并且有一些限制, 例如无法使用 exec 进入 pod 之中 可以使用 <code>kubectl proxy --help</code> 来看, 例如</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 仅允许本机访问</span><br><span class="line">--accept-hosts&#x3D;&#39;^localhost$,^127\.0\.0\.1$,^\[::1\]$&#39;: Regular expression for hosts that the proxy should accept.</span><br><span class="line"># 不允许访问下面的api, 也就是说默认没法exec进入容器</span><br><span class="line">--reject-paths&#x3D;&#39;^&#x2F;api&#x2F;.*&#x2F;pods&#x2F;.*&#x2F;exec,^&#x2F;api&#x2F;.*&#x2F;pods&#x2F;.*&#x2F;attach&#39;: Regular expression for paths that the proxy should reject. Paths specified here will be rejected even accepted by --accept-paths.</span><br><span class="line"></span><br><span class="line"># 想跳过 exec 的限制也很简单, 把 reject-paths 去掉就可以了</span><br><span class="line">$ kubectl proxy -p 8080 --keepalive 3600s --reject-paths&#x3D;&#39;&#39; -v&#x3D;9</span><br></pre></td></tr></table></figure><p>有人说这个 <code>kubectl proxy</code> 可能没什么作用, 那可能仅仅是你还没有实际的应用场景. 例如当我想要调试 <code>K8s Dashboard</code> 代码的时候. 如果直接使用 kubeconfig 文件, 我没法看到具体的请求过程, 如果你加上一层 Proxy 转发, 并且设置 <code>-v=9</code> 的时候, 你就自动获得了一个日志记录工具, 在调试时相当有用.</p><h2><span id="总结">总结</span></h2><p>kubectl 是一个强大的命令行工具, 上面我只是介绍了我工作中对其用法的一点探索, 也并不鼓励大家非要记住这些命令, 只是希望当读者需要的时候, 能够想起来 kubectl 可以有类似的功能, 就不需要针对几个临时需求去研读client-api 了.</p><blockquote><p>本文转载自：「 我的小米粥分你一半 」，原文：<a href="https://tinyurl.com/364wh2rk" target="_blank" rel="noopener">https://tinyurl.com/364wh2rk</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kubectl 是 K8s 官方附带的命令行工具, 可以方便的操作 K8s 集群. 这篇文章主要介绍一些 kubectl 的别样用法, 希望读者有一定基础的 K8s 使用经验.&lt;/p&gt;
&lt;p&gt;有一篇文章也介绍了一些技巧, 写博客的时候正好搜到了, 正好也分享出来吧.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.flant.com/ready-to-use-commands-and-tips-for-kubectl/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Ready-to-use commands and tips for kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;打印当前使用的API&quot;&gt;打印当前使用的API&lt;/h2&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# kubectl 的主要作用就是与 ApiServer 进行交互, 而交互的过程, 我们可以通过下面的方式来打印, &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 这个命令尤其适合调试自己的api接口时使用.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get ns -v&amp;#x3D;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/20210816195205-2021-08-23-FOJY7v.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款 GitHub 星标 11.5K 的命令行文件传输神器 transfer.sh（开源免费，支持 10GB 大文件）</title>
    <link href="https://www.hi-linux.com/posts/62383.html"/>
    <id>https://www.hi-linux.com/posts/62383.html</id>
    <published>2021-09-10T01:00:00.000Z</published>
    <updated>2021-09-11T11:02:08.100Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>互联网行业跳槽指南公布，你认可这个顺序吗？</strong></p></blockquote><p>在工作和生活中，我们经常需要在不同设备之间传输文件，但往往会遇到需要安装第三方软件、文件大小限制、传输速度慢等问题。安装第三方软件还好，但是限制传输速度和文件大小就非常恶心了，用着用着就得逼得你充值付费了。不然紧急需要传输一个东西，就非常花费时间和精力了。</p><h2><span id="软件介绍">软件介绍</span></h2><blockquote><p><strong>Easy and fast file sharing from the command-line.</strong></p></blockquote><p>当然，我们可以也使用，老牌的 <strong>百度云盘</strong>(非会员限速)、<strong>Dropbox</strong>(速度非常之慢)和 <strong>Google Drive</strong>(需要科学上网)，新进的 <strong>阿里云盘</strong>(虽然不限速但上传不能加速)、<strong>奶牛快传</strong>(有文件大小总量限制)。但是这里我们要介绍的是一个基于命令行的文件传输工具 —— <a href="https://github.com/dutchcoders/transfer.sh" target="_blank" rel="noopener"><strong><code>transfer.sh</code></strong></a>。</p><ul><li>Made for use with shell</li><li>Share files with a URL</li><li>For free</li><li>Upload up to 10 GB</li><li>Files stored for 14 days</li><li>Encrypt your files</li><li>Maximize amount of downloads</li></ul><h2><span id="使用方式">使用方式</span></h2><blockquote><p><strong>Sample use cases</strong></p></blockquote><ul><li><strong>[1] 命令行使用</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 将shell函数添加到.bashrc或.zshrc文件中</span><br><span class="line">transfer() &#123;</span><br><span class="line">  if [ $# -eq 0 ]; then</span><br><span class="line">    echo &quot;No arguments specified.&quot;</span><br><span class="line">    echo &quot;Usage: &quot;</span><br><span class="line">    echo &quot;  transfer &lt;file|directory&gt; ... | transfer &lt;file_name&gt;&quot;</span><br><span class="line">    return 1</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  if tty -s; then</span><br><span class="line">    file&#x3D;&quot;$1&quot;</span><br><span class="line">    file_name&#x3D;$(basename &quot;$file&quot;)</span><br><span class="line"></span><br><span class="line">    if [ ! -e &quot;$file&quot; ]; then</span><br><span class="line">      echo &quot;$file: No such file or directory&quot;</span><br><span class="line">      return 1</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    if [ -d &quot;$file&quot; ]; then</span><br><span class="line">      file_name&#x3D;&quot;$file_name.zip&quot;</span><br><span class="line">      (cd &quot;$file&quot; &amp;&amp; zip -r -q - .) | curl --progress-bar --upload-file &quot;-&quot; &quot;https:&#x2F;&#x2F;transfer.sh&#x2F;$file_name&quot; | tee &#x2F;dev&#x2F;null</span><br><span class="line">    else</span><br><span class="line">      cat &quot;$file&quot; | curl --progress-bar --upload-file &quot;-&quot; &quot;https:&#x2F;&#x2F;transfer.sh&#x2F;$file_name&quot; | tee &#x2F;dev&#x2F;null</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">  else</span><br><span class="line">    file_name&#x3D;&quot;$1&quot;</span><br><span class="line">    curl --progress-bar --upload-file &quot;-&quot; &quot;https:&#x2F;&#x2F;transfer.sh&#x2F;$file_name&quot;|tee &#x2F;dev&#x2F;null</span><br><span class="line">  fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 现在可以使用函数来上传文件</span><br><span class="line">$ transfer hello.txt</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 简单上传文件</strong> - <a href="https://transfer.sh/#" target="_blank" rel="noopener">官方支持界面上传</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 使用curl命令上传文件</span><br><span class="line">$ curl --upload-file .&#x2F;hello.txt https:&#x2F;&#x2F;transfer.sh&#x2F;hello.txt</span><br><span class="line">https:&#x2F;&#x2F;transfer.sh&#x2F;66nb8&#x2F;hello.txt</span><br><span class="line"></span><br><span class="line"># 上传文件设定最大下载次数和过期时间</span><br><span class="line">$ curl -H &quot;Max-Downloads: 1&quot; -H &quot;Max-Days: 5&quot; --upload-file .&#x2F;hello.txt https:&#x2F;&#x2F;transfer.sh&#x2F;hello.txt</span><br><span class="line">https:&#x2F;&#x2F;transfer.sh&#x2F;66nb8&#x2F;hello.txt</span><br><span class="line"></span><br><span class="line"># 下载文件</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;66nb8&#x2F;hello.txt -o hello.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 还支持wget上传文件</span><br><span class="line">$ wget --method PUT --body-file&#x3D;&#x2F;tmp&#x2F;file.tar https:&#x2F;&#x2F;transfer.sh&#x2F;file.tar -O - -nv</span><br><span class="line"></span><br><span class="line"># 还支持HTTPie上传文件</span><br><span class="line">$ http https:&#x2F;&#x2F;transfer.sh&#x2F; -vv &lt; &#x2F;tmp&#x2F;test.log</span><br><span class="line"></span><br><span class="line"># 还支持PowerShell上传文件</span><br><span class="line">PS H:\&gt; invoke-webrequest -method put -infile .\file.txt https:&#x2F;&#x2F;transfer.sh&#x2F;file.txt</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 一次上传多个文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 使用filedata执行文件地址</span><br><span class="line">$ curl -i -F filedata&#x3D;@&#x2F;tmp&#x2F;hello.txt -F filedata&#x3D;@&#x2F;tmp&#x2F;hello2.txt https:&#x2F;&#x2F;transfer.sh&#x2F;</span><br><span class="line"></span><br><span class="line"># 将下载合并为zip或tar存档</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;(15HKz&#x2F;hello.txt,15HKz&#x2F;hello.txt).tar.gz</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;(15HKz&#x2F;hello.txt,15HKz&#x2F;hello.txt).zip</span><br></pre></td></tr></table></figure><ul><li><strong>[4] 传输前使用加密您的文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用gpg加密文件</span><br><span class="line">$ cat &#x2F;tmp&#x2F;hello.txt | gpg -ac -o- | curl -X PUT --upload-file &quot;-&quot; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br><span class="line"></span><br><span class="line"># 下载并解密</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;1lDau&#x2F;test.txt | gpg -o- &gt; &#x2F;tmp&#x2F;hello.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用openssl加密文件</span><br><span class="line">$ cat &#x2F;tmp&#x2F;hello.txt | openssl aes-256-cbc -pbkdf2 -e | curl -X PUT --upload-file &quot;-&quot; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br><span class="line"></span><br><span class="line"># 下载并解密</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;1lDau&#x2F;test.txt | openssl aes-256-cbc -pbkdf2 -d &gt; &#x2F;tmp&#x2F;hello.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 从keybase导入key</span><br><span class="line">$ keybase track [them]</span><br><span class="line"></span><br><span class="line"># 加密文件</span><br><span class="line">$ cat somebackupfile.tar.gz | keybase encrypt [them] | curl --upload-file &#39;-&#39; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br><span class="line"></span><br><span class="line"># 解密下载</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;sqUFi&#x2F;test.md | keybase decrypt</span><br></pre></td></tr></table></figure><ul><li><strong>[5] 扫描恶意软件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 使用Clamav扫描恶意软件或病毒</span><br><span class="line">$ wget http:&#x2F;&#x2F;www.eicar.org&#x2F;download&#x2F;eicar.com</span><br><span class="line">$ curl -X PUT --upload-file .&#x2F;eicar.com https:&#x2F;&#x2F;transfer.sh&#x2F;eicar.com&#x2F;scan</span><br><span class="line"></span><br><span class="line"># 上传恶意软件到VirusTotal并获得永久链接</span><br><span class="line">$ curl -X PUT --upload-file nhgbhhj https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt&#x2F;virustotal</span><br></pre></td></tr></table></figure><ul><li><strong>[6] 加密传输备份 mysql 数据库</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 备份+加密+传输</span><br><span class="line">$ mysqldump --all-databases | gzip | gpg -ac -o- | curl -X PUT --upload-file &quot;-&quot; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br></pre></td></tr></table></figure><ul><li><strong>[7] 发送带有传输链接的电子邮件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 传输和发送带有链接的电子邮件</span><br><span class="line">$ transfer &#x2F;tmp&#x2F;hello.txt | mail -s &quot;Hello World&quot; user@yourmaildomain.com</span><br></pre></td></tr></table></figure><ul><li><strong>[8] 传输日志文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># grep syslog for pound and transfer</span><br><span class="line">$ cat &#x2F;var&#x2F;log&#x2F;syslog | grep pound | curl --upload-file - https:&#x2F;&#x2F;transfer.sh&#x2F;pound.log</span><br></pre></td></tr></table></figure><h2><span id="参考链接">参考链接</span></h2><ul><li><a href="https://transfer.sh/#" target="_blank" rel="noopener">transfer.sh 官方网站</a></li><li><a href="https://github.com/dutchcoders/transfer.sh" target="_blank" rel="noopener">transfer.sh 的 Github 仓库地址</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/5chzpk9w" target="_blank" rel="noopener">https://tinyurl.com/5chzpk9w</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="终端" scheme="https://www.hi-linux.com/tags/%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>Docker Desktop 突然宣告收费，是时候弃用了？</title>
    <link href="https://www.hi-linux.com/posts/20003.html"/>
    <id>https://www.hi-linux.com/posts/20003.html</id>
    <published>2021-09-09T01:00:00.000Z</published>
    <updated>2021-09-30T04:54:17.581Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在容器引擎 Docker 诞生的 8 年间，其与开源的容器编排 Kubernetes 共同推动容器技术在云计算领域的应用，也让自身在全球范围内受到了广泛的关注。可以说，做过云计算开发的程序员，十有八有学过 Docker 技术。</p><p>不过，近日 Docker 宣布对其产品的订阅方案进行了更新，更新内容包括使用 “Docker Personal” 订阅来代替此前的 “Docker Free” 订阅，以及增加新的订阅方案——“Docker Business”。</p><p>因此，Docker 目前总共有 4 种订阅方案，分别是：<strong>Personal, Pro, Team 和 Business</strong>。虽然新增的 “Docker Business” 订阅方案收费比较昂贵，不过 Docker 表示，这对于大多数人来说并没有影响，他们仍然可以继续免费使用。</p><a id="more"></a><p>之所以推出收费更高的订阅方案，是为了探索出一种可持续的商业模式。Docker CEO Scott Johnston 表示，Docker 已成为企业标准，他们希望解决软件供应链存在的安全挑战，于是有了更昂贵且提供更安全服务的 Docker Business 订阅方案。</p><p><img src="https://img.hi-linux.com/staticfile/640-2021-09-07-Ytdr8l.jpg" alt></p><p><em>本次调整对 Docker Engine 以及上游 Docker 和 Moby 开源项目没有进行任何改动。</em></p><p>事实上，此次订阅方案的调整主要是对 Docker Desktop 的使用条款进行了更改：</p><ul><li><p>对于小型企业（少于 250 名员工且年收入少于 1000 万美元）、个人、教育和非商业开源项目，Docker Desktop 仍然会免费提供</p></li><li><p>中大型企业使用 Docker Desktop 需要付费订阅，可选择 Pro, Team 和 Business 三种方案的任意一种，收费是每位用户每月 5 美元起。这几种方案的主要区别是提供了不同的功能。例如 Docker Business 提供了集中管理和单点登录等增强安全性的功能</p></li></ul><p>Docker Desktop 是一个 GUI 工具，用于管理各种 Docker 组件和功能，包括容器、镜像、卷（附加到容器的存储）、本地 Kubernetes、容器内的开发环境等。虽然大多数 Docker 组件都可用于 Windows、Mac 和 Linux，但 Docker Desktop 不支持在 Linux 上运行，仅适用于 Windows 和 Mac。</p><p>据悉，这些条款的生效日期是 2021 年 8 月 31 日，不过，对于需要付费订阅才能使用 Docker Desktop 的用户，Docker 官方也提供了一个宽限期，供用户过渡，具体时间是截止到 2022 年 1 月 31 日。那么这对用户的影响究竟有多大？</p><p>据 Docker 官方报道，全球有 55% 的专业开发者正在使用 Docker 技术，其中个人开发者及小型企业占据其中的一半，这也意味着大多数 Docker 用户仍然可以以免费的方式使用它。不过，Scott Johnston 也透露此前订阅用户仍然不到 Docker 总体使用量的 10%。</p><p>因此时下的这一调整，也会对不少企业带来一定的影响。对于这样的改变，不少网友也纷纷有种被劝退之感：</p><ul><li><p>我非常期待有开源替代品出现，并将 Docker 取而代之；</p></li><li><p>这极有可能会杀死 Docker；</p></li><li><p>再见 Docker Desktop，我认为接下来会有很多超过 250 名员工的企业会做出同样的事情；</p></li><li><p>…</p></li></ul><p>最后给大家推荐一个 Docker for Mac 下的替代品 <code>Lima+Containerd+nerdctl</code>。</p><blockquote><p><strong>什么是 Lima？</strong></p><p>Lima（Linux MAchines）可以启动具有自动文件共享、端口转发和使用 containerd 的 Linux 虚拟机。</p><p><strong>什么是 Containerd？</strong></p><p>Containerd 是一个开源的容器运行时，被很多项目所使用，包括 Docker，和很多云厂商默认配置的 Kubernetes 集群，例如 AKS， EKS 和 GKE。</p><p><strong>什么是 nerdctl？</strong></p><p>nerdctl 是一个与 Docker Cli 风格兼容的 Containerd 客户端工具，而且直接兼容 Docker Compose 的语法的，这就大大提高了直接将 containerd 作为本地开发、测试或者单机容器部署使用的效率。</p></blockquote><p>更多详细使用方法可参考：『<a href="https://mp.weixin.qq.com/s/TreV41cxXL5RXuFiLpg6Mw" target="_blank" rel="noopener">Lima：Docker Desktop for Mac 的免费开源且自由的替代品</a>』一文</p><p><strong>参考文档</strong></p><ol><li><a href="https://mp.weixin.qq.com/s/rbNSX03rbIb5-gTrEkdRrw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/rbNSX03rbIb5-gTrEkdRrw</a></li><li><a href="https://mp.weixin.qq.com/s/TreV41cxXL5RXuFiLpg6Mw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TreV41cxXL5RXuFiLpg6Mw</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在容器引擎 Docker 诞生的 8 年间，其与开源的容器编排 Kubernetes 共同推动容器技术在云计算领域的应用，也让自身在全球范围内受到了广泛的关注。可以说，做过云计算开发的程序员，十有八有学过 Docker 技术。&lt;/p&gt;
&lt;p&gt;不过，近日 Docker 宣布对其产品的订阅方案进行了更新，更新内容包括使用 “Docker Personal” 订阅来代替此前的 “Docker Free” 订阅，以及增加新的订阅方案——“Docker Business”。&lt;/p&gt;
&lt;p&gt;因此，Docker 目前总共有 4 种订阅方案，分别是：&lt;strong&gt;Personal, Pro, Team 和 Business&lt;/strong&gt;。虽然新增的 “Docker Business” 订阅方案收费比较昂贵，不过 Docker 表示，这对于大多数人来说并没有影响，他们仍然可以继续免费使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>如何快速的在 Kubernetes 上部署云原生微服务网关 APISIX</title>
    <link href="https://www.hi-linux.com/posts/16167.html"/>
    <id>https://www.hi-linux.com/posts/16167.html</id>
    <published>2021-09-08T01:00:00.000Z</published>
    <updated>2021-09-08T09:42:27.518Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="几种常见网关的比较">几种常见网关的比较</span></h2><ul><li>Nginx, 模块化设计的反向代理软件，C 语言开发</li><li>OpenResty, 以 Nginx 为核心的 Web 开发平台，可以解析执行 Lua 脚本</li><li>Kong, OpenResty 的一个应用，是一个 API 网关，具有 API 管理和请求代理的功能，使用 PostgreSQL 存储</li><li>APISIX, 替换了 Kong 的 PostgreSQL 为 Etcd，基于 Nginx 的核心库实现</li></ul><p>APISIX 的优势在于提供了 API 的管理和扩展能力，让网关不再仅仅转发服务，而是可以被配置、定制化。相较于 Nginx，APISIX 使用的是动态路由，避免了配置之后 reload 产生的风险。同时，APISIX 支持 HTTP(S)、HTTP2、Dubbo、QUIC、MQTT、TCP/UDP 等更多的协议，具有更好的使用生态。</p><p><img src="https://img.hi-linux.com/staticfile/apisix-infras-20210906170155554-2021-09-06-eR1jIQ.webp" alt></p><p>上面是 APISIX 的架构图，数据面处理客户端请求，控制面管理路由。</p><a id="more"></a><h2><span id="apisix-能解决什么问题">APISIX 能解决什么问题</span></h2><ul><li>边缘路由</li></ul><p>机房对外暴露的访问入口 IP 数量，通常是极少的，但是却支撑了很多个服务。比如，访问的 IP 是 1.2.3.4，但却同时提供了 <a href="http://a.domain.com" target="_blank" rel="noopener">a.domain.com</a>、<a href="http://b.domain.com" target="_blank" rel="noopener">b.domain.com</a> 的访问服务。这就需要用到边缘路由，边缘路由会将不同域名的访问，转发到不同的内网地址。</p><p>APISIX 中三种方式可以注册边缘路由，dashboard、ingress-controller、admin api。</p><ul><li>基础网关能力</li></ul><p>网关的功能不限于转发流量，更重要的是限流、熔断等。</p><p>APISIX 内置了很多插件，提供 APM、日志、熔断、鉴权、证书管理、故障注入等功能。同时，也支持拖拽组合新的插件、开发新插件以满足业务需求。</p><ul><li>Serverless</li></ul><p>APISIX 通过插件的方式提供 Serverless，目前仅支持 Lua。但 APIGateway + Serverless 的组合，极具想象力。</p><p>利用 Serverless 可以快速对外提供无服务的 API，粘合各种服务，也可以对外直接提供功能服务。</p><ul><li>灰度发布</li></ul><p>由于对网关层进行了控制，APISIX 允许用户通过配置权重控制流量的转发行为，可以用来做灰度发布使用。</p><h2><span id="kubernetes-上安装-apisix">Kubernetes 上安装 APISIX</span></h2><h3><span id="1-添加-helm-源">1 添加 Helm 源</span></h3><ul><li>添加 Helm 源</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add apisix https:&#x2F;&#x2F;charts.apiseven.com</span><br><span class="line">$ helm repo update</span><br></pre></td></tr></table></figure><ul><li>查找 Chart 包</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ helm search repo apisix</span><br><span class="line"></span><br><span class="line">NAME                            CHART VERSIONAPP VERSIONDESCRIPTION</span><br><span class="line">apisix&#x2F;apisix                   0.3.5        2.7.0      A Helm chart for Apache APISIX</span><br><span class="line">apisix&#x2F;apisix-dashboard         0.1.5        2.7.0      A Helm chart for Apache APISIX Dashboard</span><br><span class="line">apisix&#x2F;apisix-ingress-controller0.5.0        1.0.0      Apache APISIX Ingress Controller for Kubernetes</span><br></pre></td></tr></table></figure><h3><span id="2-安装-apisix">2 安装 APISIX</span></h3><ul><li>安装 APISIX</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install apisix apisix&#x2F;apisix  --set gateway.type&#x3D;NodePort --set admin.allow.ipList&#x3D;&quot;&#123;0.0.0.0&#x2F;0&#125;&quot;  -n apisix --create-namespace</span><br></pre></td></tr></table></figure><ul><li>查看入口地址</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ export NODE_PORT&#x3D;$(kubectl get --namespace apisix -o jsonpath&#x3D;&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services apisix-gateway)</span><br><span class="line">$ export NODE_IP&#x3D;$(kubectl get nodes --namespace apisix -o jsonpath&#x3D;&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">$ echo http:&#x2F;&#x2F;$NODE_IP:$NODE_PORT</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;1.1.1.1:32462</span><br></pre></td></tr></table></figure><p>这里的入口地址是后端服务的入口地址，如果是生成环境，应该使用 LoadBalancer 提供的地址。</p><ul><li>查看 apisix-admin 接口 key</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ export POD_NAME&#x3D;$(kubectl get pods --namespace apisix -l &quot;app.kubernetes.io&#x2F;instance&#x3D;apisix,app.kubernetes.io&#x2F;name&#x3D;apisix&quot; -o jsonpath&#x3D;&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line"></span><br><span class="line">$ kubectl -n apisix exec -it $POD_NAME cat conf&#x2F;config.yaml |grep key </span><br><span class="line"></span><br><span class="line">  admin_key:</span><br><span class="line">      key: edd1c9f034335f136f87ad84b625c8f1</span><br><span class="line">      key: 4054f7cf07e344346cd3f287985e76a2</span><br></pre></td></tr></table></figure><p>第一个 key 是 admin，第二个 key 是 viewer。这里的 key 可以用来通过 admin api 来配置 APISIX，给其他系统集成 APISIX 提供了入口。</p><h3><span id="3-安装-dashboard">3 安装 Dashboard</span></h3><ul><li>安装 Dashboard</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install apisix-dashboard apisix&#x2F;apisix-dashboard -n apisix --create-namespace</span><br></pre></td></tr></table></figure><p>默认账户是：admin<br>默认密码是：admin</p><ul><li>查看 Dashboard 访问入口</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ export NODE_PORT&#x3D;$(kubectl get --namespace apisix -o jsonpath&#x3D;&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services apisix-gateway)</span><br><span class="line">$ export NODE_IP&#x3D;$(kubectl get nodes --namespace apisix -o jsonpath&#x3D;&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">$ echo http:&#x2F;&#x2F;$NODE_IP:$NODE_PORT</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;1.1.1.1:31501</span><br></pre></td></tr></table></figure><h3><span id="4-安装-ingress-controller">4 安装 ingress-controller</span></h3><ul><li>安装 ingress-controller</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install apisix-ingress-controller apisix&#x2F;apisix-ingress-controller   --set config.apisix.baseURL&#x3D;http:&#x2F;&#x2F;apisix-admin:9180&#x2F;apisix&#x2F;admin  --set config.apisix.adminKey&#x3D;edd1c9f034335f136f87ad84b625c8f1  -n apisix</span><br></pre></td></tr></table></figure><p>这里就会需要设置上面获取到的 admin key, 实际上 ingress-controller 也是通过调用 admin api 来配置路由的。</p><h2><span id="创建服务测试">创建服务测试</span></h2><p>前面提到 APISIX 通过 admin api 配置路由，有三种方式可以操作。这里主要验证使用 Dashboard 和 Ingress 两种方式：</p><ul><li>创建一个服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create deployment web --image&#x3D;gcr.io&#x2F;google-samples&#x2F;hello-app:1.0</span><br></pre></td></tr></table></figure><ul><li>暴露服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl expose deployment web --type&#x3D;NodePort --port&#x3D;8080</span><br></pre></td></tr></table></figure><ul><li>查看服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get service web</span><br><span class="line"></span><br><span class="line">NAME   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">web    NodePort   10.233.58.113   &lt;none&gt;        8080:30572&#x2F;TCP   28d</span><br></pre></td></tr></table></figure><h3><span id="1-dashboard-配置路由">1 Dashboard 配置路由</span></h3><ul><li>新建一个上游服务</li></ul><p>这里需要填入上面创建的集群访问地址：<code>web.default.svc.cluster.local</code></p><p><img src="https://www.chenshaowen.com/blog/images/2021/09/dashboard-apisix-1.png" alt></p><ul><li>新建一个路由</li></ul><p><img src="https://www.chenshaowen.com/blog/images/2021/09/dashboard-apisix-2.png" alt></p><p>点击下一步之后，选择上面创建的服务 web，相关的参数就会自动填充。</p><p><img src="https://www.chenshaowen.com/blog/images/2021/09/dashboard-apisix-3.png" alt></p><ul><li>访问测试</li></ul><p><img src="https://www.chenshaowen.com/blog/images/2021/09/ip-apisix.png" alt></p><h3><span id="2-ingress-配置路由">2 Ingress 配置路由</span></h3><ul><li>创建一个 ApisixRoute 路由</li></ul><p>虽然这里部署的是 ingress-controller 组件，但是使用时创建的是 ApisixRoute 对象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apisix.apache.org&#x2F;v1 </span><br><span class="line">kind: ApisixRoute </span><br><span class="line">metadata: </span><br><span class="line">  name: web-route </span><br><span class="line">spec:</span><br><span class="line">  http:</span><br><span class="line">  - name: web</span><br><span class="line">    match:</span><br><span class="line">      hosts:</span><br><span class="line">      - dev4.chenshaowen.com</span><br><span class="line">      paths:</span><br><span class="line">      - &quot;&#x2F;router-web&#x2F;*&quot;</span><br><span class="line">    backend:</span><br><span class="line">     serviceName: web</span><br><span class="line">     servicePort: 8080</span><br></pre></td></tr></table></figure><ul><li>访问测试</li></ul><p><img src="https://img.hi-linux.com/staticfile/domain-apisix-20210906170156087-2021-09-06-DNDSce.png" alt></p><ul><li>查看创建的路由</li></ul><p><img src="https://img.hi-linux.com/staticfile/ingress-apisix-router-20210906170156197-2021-09-06-OIIY5x.png" alt></p><p>可以发现路由是被 ingress-controller 接管的，人工不要编辑。</p><ul><li>查看服务</li></ul><p><img src="https://img.hi-linux.com/staticfile/ingress-apisix-svc-20210906170156309-2021-09-06-kxONs3.png" alt></p><p>可以看到服务主要是由四个后端提供。</p><ul><li>查看服务 Pod 的 IP</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod  -o wide</span><br><span class="line"></span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE   IP              NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">web-79d88c97d6-2sdlj   1&#x2F;1     Running   0          27d   10.233.105.34   node4   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web-79d88c97d6-7bfbb   1&#x2F;1     Running   0          27d   10.233.105.32   node4   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web-79d88c97d6-hccqk   1&#x2F;1     Running   0          27d   10.233.105.33   node4   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web-79d88c97d6-mh9gz   1&#x2F;1     Running   0          28d   10.233.105.22   node4   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>APISIX 会将 Pod 的 IP 地址直接作为流量后端，而不需要经过 Service 的转发，这有别于 Kubernetes 的服务转发、负载均衡机制。</p><h2><span id="总结">总结</span></h2><p>本文主要简述了几种网关的区别，思考了 APISIX 主要能帮助我们解决什么问题，最后在 Kubernetes 上进行了实践。内容如下：</p><ul><li>APISIX 是基于 Nginx 网络库实现的 API 网关应用，使用 Etcd 作为存储后端</li><li>APISIX 能作为边缘路由使用，其动态特性，避免了 Nginx reload 带来的抖动</li><li>APISIX 提供了 admin api 管理路由，有三种方式可以进行配置</li><li>Kubernetes 下的 APISIX 跳过了 Kubernetes Service 直接将流量转发到 Pod IP</li></ul><h2><span id="参考">参考</span></h2><ul><li><a href="https://github.com/apache/apisix" target="_blank" rel="noopener">https://github.com/apache/apisix</a></li><li><a href="https://bbs.huaweicloud.com/blogs/125686" target="_blank" rel="noopener">https://bbs.huaweicloud.com/blogs/125686</a></li><li><a href="https://github.com/apache/apisix-ingress-controller/blob/master/docs/en/latest/concepts/apisix_route.md" target="_blank" rel="noopener">https://github.com/apache/apisix-ingress-controller/blob/master/docs/en/latest/concepts/apisix_route.md</a></li></ul><blockquote><p>本文转载自：「 陈少文的网站 」，原文：<a href="https://tinyurl.com/yf9476mj" target="_blank" rel="noopener">https://tinyurl.com/yf9476mj</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;几种常见网关的比较&quot;&gt;几种常见网关的比较&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Nginx, 模块化设计的反向代理软件，C 语言开发&lt;/li&gt;
&lt;li&gt;OpenResty, 以 Nginx 为核心的 Web 开发平台，可以解析执行 Lua 脚本&lt;/li&gt;
&lt;li&gt;Kong, OpenResty 的一个应用，是一个 API 网关，具有 API 管理和请求代理的功能，使用 PostgreSQL 存储&lt;/li&gt;
&lt;li&gt;APISIX, 替换了 Kong 的 PostgreSQL 为 Etcd，基于 Nginx 的核心库实现&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;APISIX 的优势在于提供了 API 的管理和扩展能力，让网关不再仅仅转发服务，而是可以被配置、定制化。相较于 Nginx，APISIX 使用的是动态路由，避免了配置之后 reload 产生的风险。同时，APISIX 支持 HTTP(S)、HTTP2、Dubbo、QUIC、MQTT、TCP/UDP 等更多的协议，具有更好的使用生态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/apisix-infras-20210906170155554-2021-09-06-eR1jIQ.webp&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面是 APISIX 的架构图，数据面处理客户端请求，控制面管理路由。&lt;/p&gt;
    
    </summary>
    
    
      <category term="APISIX" scheme="https://www.hi-linux.com/categories/APISIX/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="APISIX" scheme="https://www.hi-linux.com/tags/APISIX/"/>
    
  </entry>
  
  <entry>
    <title>万字长文详解 PaaS toB 场景下 Kubernetes 离线部署方案</title>
    <link href="https://www.hi-linux.com/posts/27427.html"/>
    <id>https://www.hi-linux.com/posts/27427.html</id>
    <published>2021-09-01T01:00:00.000Z</published>
    <updated>2021-09-01T01:27:55.874Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在企业私有云环境当中，出于对数据安全的考虑以及满足 <a href="http://www.djbh.net/" target="_blank" rel="noopener">网络安全等级保护</a> 的要求，往往会对内部环境中的服务器做出严格的访问限制。一般来讲生产环境都会禁止访问外部网络，开发人员要访问生产环境也必须通过堡垒机或者其他方式进行安全审计登录。在这种无网（无法访问公网）的环境中，想要部署好一个 K8s 集群并不是一件轻松的事儿。市面上 K8s 部署工具也多不胜数，对于离线部署的支持情况也各不相同：</p><table><thead><tr><th style="text-align:left">Item</th><th style="text-align:left">Language</th><th style="text-align:left">Star</th><th style="text-align:left">Fork</th><th style="text-align:left">离线部署支持情况</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://github.com/kubernetes/kops" target="_blank" rel="noopener">kops</a></td><td style="text-align:left">Golang</td><td style="text-align:left">13.2k</td><td style="text-align:left">4.1k</td><td style="text-align:left">不支持</td></tr><tr><td style="text-align:left"><a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">Ansible</td><td style="text-align:left">11.1k</td><td style="text-align:left">4.7k</td><td style="text-align:left">支持，需自行构建安装包</td></tr><tr><td style="text-align:left"><a href="https://github.com/easzlab/kubeasz" target="_blank" rel="noopener">kubeasz</a></td><td style="text-align:left">Ansible</td><td style="text-align:left">7.2k</td><td style="text-align:left">2.7k</td><td style="text-align:left">支持，需自行构建安装包</td></tr><tr><td style="text-align:left"><a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a></td><td style="text-align:left">Golang</td><td style="text-align:left">4.1k</td><td style="text-align:left">790</td><td style="text-align:left">支持，需付费充值会员</td></tr><tr><td style="text-align:left"><a href="https://github.com/rancher/rke" target="_blank" rel="noopener">RKE</a></td><td style="text-align:left">Golang</td><td style="text-align:left">2.5k</td><td style="text-align:left">480</td><td style="text-align:left">不支持，需自行安装 docker</td></tr><tr><td style="text-align:left"><a href="https://github.com/alibaba/sealer" target="_blank" rel="noopener">sealer</a></td><td style="text-align:left">Golang</td><td style="text-align:left">503</td><td style="text-align:left">112</td><td style="text-align:left">支持，源自 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a></td></tr><tr><td style="text-align:left"><a href="https://github.com/kubesphere/kubekey" target="_blank" rel="noopener">kubekey</a></td><td style="text-align:left">Golang</td><td style="text-align:left">471</td><td style="text-align:left">155</td><td style="text-align:left">部分支持，仅镜像可离线</td></tr></tbody></table><p>无网环境离线部署 K8s 往往是作为一个商业服务或者商业付费产品来出售（如 <a href="https://www.sealyun.com/" target="_blank" rel="noopener">sealos</a> ），很少有开源免费的解决方案；或者虽然提供了离线部署方案，但想要操作起来十分繁琐，很难顺畅地做到一键部署；又或者只支持部分离线部署，还有一部分资源需要在部署的时候通过公网获取。</p><p>针对上述问题，本文调研主流的 K8s 部署工具，并基于这些工具设计并实现一种从构建离线安装包到一键部署 K8s 集群全流程的解决方案，以满足在无网的环境中一键部署 K8s 集群的需求，比较适合基于 K8s 的 PaaS toB 产品使用。</p><a id="more"></a><h2><span id="离线资源">离线资源</span></h2><p>总体来讲部署一个 K8s 集群大致需要依赖如下三种资源：</p><ul><li>系统 OS 的 rpm/deb 包：如 docker-ce、containerd、ipvsadm、conntrack 等；</li><li>二进制文件：如 kubelet、kubectl、kubeadm、crictl 等；</li><li>组件容器镜像：如 kube-apiserver、kube-proxy、coredns、calico、flannel 等；</li></ul><h3><span id="os-packages">OS packages</span></h3><p>这类属于 OS 系统层面的依赖，根据不同系统或者支持的功能需要使用相应的包管理器安装相应的依赖包，大致分为如下几种：</p><ul><li>kubernetes 组件依赖</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- conntrack           # kube-proxy 依赖</span><br><span class="line">- ipset               # kube-proxy 使用 ipvs 模式需要</span><br><span class="line">- ipvsadm             # kube-proxy 使用 ipvs 模式需要</span><br><span class="line">- socat               # 用于 port forwarding</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/" target="_blank" rel="noopener">Implementation details</a>:</p><p>[Error] if conntrack, ip, iptables, mount, nsenter commands are not present in the command path<br>[warning] if ebtables, ethtool, socat, tc, touch, crictl commands are not present in the command path</p></blockquote><ul><li>部署依赖</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- ebtables            # kubeadm 依赖工具</span><br><span class="line">- ethtool             # kubeadm 依赖工具</span><br><span class="line">- chrony              # 时钟同步工具，部署前节点的时候必须一致，不然证书或者 CNI 插件会出现问题</span><br></pre></td></tr></table></figure><ul><li>CRI 容器运行运行时</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- containerd.io       # 可单独安装&#x2F;docker-ce 依赖</span><br><span class="line">- docker-ce           # docker-ce</span><br><span class="line">- libseccomp          # 安装 containerd 需要</span><br><span class="line">- nvidia-container-runtime # 支持 GPU 时需要依赖</span><br></pre></td></tr></table></figure><ul><li>存储客户端依赖</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- nfs-utils&#x2F;nfs-common # 创建基于 nfs 的 PV 需要</span><br><span class="line">- ceph-common          # ceph 客户端安装包，创建基于 ceph 的 pv 需要</span><br><span class="line">- lvm2                 # 创建基于 ceph 的 pv 需要</span><br><span class="line">- glusterfs-client     # 创建基于 glusterfs 的 pv 需要</span><br><span class="line">- glusterfs-common     # 创建基于 glusterfs 的 pv 需要</span><br><span class="line">- cifs-utils           # 创建基于 cifs 的 pv 需要</span><br><span class="line">- fuse                 # ceph 或者其他存储客户端依赖</span><br></pre></td></tr></table></figure><p>想要解决上面这些依赖项十分棘手，也是离线部署场景下最难的一部分，至今并没有一个成熟的方案实现这些依赖的离线部署，基本上所有的 k8s 部署工具都没有提供这些包的离线安装方式。对于这些包的依赖，目前主要有避免安装这些依赖和制作离线源这两种解决方案。</p><h4><span id="sealos">sealos</span></h4><p>在 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 中就极力避免使用包管理器来安装依赖，比如安装 containerd 时的依赖 libseccomp 使用的是编译好的 .so 文件的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ tar -tf kube1.20.0.tar.gz</span><br><span class="line">kube&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;README.md</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2.3.1</span><br></pre></td></tr></table></figure><p>安装 docker 使用的二进制的方式，但 docker 官方文档中也明确说明<strong>不建议使用二进制的方式来安装 docker</strong>，应该使用发行版自带的包管理器来安装。</p><blockquote><p>If you want to try Docker or use it in a testing environment, but you’re not on a supported platform, you can try installing from static binaries. <strong>If possible, you should use packages built for your operating system</strong>, and use your operating system’s package management system to manage Docker installation and upgrades.</p><p><a href="https://docs.docker.com/engine/install/binaries/" target="_blank" rel="noopener">Install Docker Engine from binaries</a></p></blockquote><p>实际上任何部署工具都会对系统 rpm/deb 包都会有不同程度上的依赖，有一部分依赖可以像 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 这样通过某种方式去规避掉。但并不是所有的依赖都能规避的，比如提供挂载 PV 需要依赖的存储客户端（nfs-common/nfs-utils，lvm2，gluster-client）这些包，基本上是没有任何规避的途径，必须通过包管理器来安装才行。</p><p>当然如果这些前置的依赖项在部署工具之外手动解决或者让用户自行去解决，那么使用 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 这种轻量级的工具来部署 K8s 是比较合适的。但对于一些 PaaS toB 的产品而言，让用户自己去手动解决这些依赖恐怕不太好。站在客户的角度来考虑既然平台提供了这部分功能，就应该在部署的时候解决所有的依赖问题，而不是让我自己手动临时来解决。</p><h4><span id="kubekey">kubekey</span></h4><p>在 kubekey 中一些依赖项目则是要求用户自行安装，并没有提供离线安装的方式：</p><blockquote><ul><li>建议您使用干净的操作系统（不安装任何其他软件），否则可能会有冲突。</li><li>请确保每个节点的硬盘至少有 <strong>100G</strong>。</li><li>所有节点必须都能通过 <code>SSH</code> 访问。</li><li>所有节点时间同步。</li><li>所有节点都应使用 <code>sudo</code>/<code>curl</code>/<code>openssl</code>。</li></ul><p>KubeKey 能够同时安装 Kubernetes 和 KubeSphere。根据要安装的 Kubernetes 版本，需要安装的依赖项可能会不同。您可以参考下方列表，查看是否需要提前在您的节点上安装相关依赖项。</p><table><thead><tr><th style="text-align:left">依赖项</th><th style="text-align:left">Kubernetes 版本 ≥ 1.18</th><th style="text-align:left">Kubernetes 版本 &lt; 1.18</th></tr></thead><tbody><tr><td style="text-align:left"><code>socat</code></td><td style="text-align:left">必须</td><td style="text-align:left">可选但建议</td></tr><tr><td style="text-align:left"><code>conntrack</code></td><td style="text-align:left">必须</td><td style="text-align:left">可选但建议</td></tr><tr><td style="text-align:left"><code>ebtables</code></td><td style="text-align:left">可选但建议</td><td style="text-align:left">可选但建议</td></tr><tr><td style="text-align:left"><code>ipset</code></td><td style="text-align:left">可选但建议</td><td style="text-align:left">可选但建议</td></tr></tbody></table><p>备注</p><ul><li>在离线环境中，您可以使用私有包、RPM 包（适用于 CentOS）或者 Deb 包（适用于 Debian）来安装这些依赖项。</li><li>建议您事先创建一个操作系统镜像文件，并且安装好所有相关依赖项。这样，您便可以直接使用该镜像文件在每台机器上安装操作系统，提高部署效率，也不用担心任何依赖项问题。</li></ul><p>您的集群必须有一个可用的容器运行时。在离线环境中创建集群之前，您必须手动安装 Docker 或其他容器运行时。</p><p><a href="https://github.com/kubesphere/kubekey#requirements-and-recommendations" target="_blank" rel="noopener">Requirements and Recommendations</a></p></blockquote><h4><span id="构建离线源">构建离线源</span></h4><p>对于系统 rpm/deb 包的依赖，我们还是踏踏实实地使用包管理器来安装这些包较为妥当，因此我们有必要为这些依赖的 rpm/deb 包构建成离线源，部署的时候使用这个离线源来安装这些依赖。在 《<a href="https://blog.k8s.li/make-offline-mirrors.html" target="_blank" rel="noopener">使用 docker build 制作 yum/apt 离线源</a>》一文中曾分析过制作和使用离线源这么难的原因：</p><blockquote><p>作为平台部署工具的开发者，始终被离线部署这个难题困扰着。在线的容器镜像和二进制文件比较好解决，因为这些资源是与 OS 无关的，只要下载下来放到安装包里，部署的时候启动一个 HTTP 服务器和镜像仓库服务提供这些资源的下载即可。</p><p>但是对于 yum/apt 之类的软件来讲并不那么简单：</p><ul><li>首先由于各个包之间的依赖关系比较复杂，并不能将它们直接下载下来；</li><li>其次即便下载下来之后也无法直接通过 yum/apt 的方式安装指定的软件包，虽然也可以使用 scp 的方式将这些包复制到部署节点，通过 rpm 或 dpkg 的方式来安装上，但这样并不是很优雅，而且通用性能也不是很好；</li><li>最后需要适配的 Linux 发行版和包管理器种类也有多种，而且有些包的包名或者版本号在不同的包管理之间也相差甚大，无法做到统一管理。</li><li>离线源同时适配适配 ARM64 和 AMD64 有一定的难度</li></ul></blockquote><p>好在文中也给出了一个比较通用的解决方案，即通过 Dockerfile 来构建离线源，具体的实现细节可以翻看《<a href="https://blog.k8s.li/make-offline-mirrors.html" target="_blank" rel="noopener">使用 docker build 制作 yum/apt 离线源</a>》一文。使用这个方案可以解决 PaaS 或者 IaaS 层面的离线源制作的难题，同样也适用于我们部署 K8s 集群的场景，而且采用 Dockerfile 的方式来构建离线源可以完美地解决同时适配 arm64 和 amd64 的难题。</p><h3><span id="files">files</span></h3><p>一些部署过程中需要的二进制文件，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- kubelet</span><br><span class="line">- kubeadm</span><br><span class="line">- kubectl</span><br><span class="line">- etcd            # systemd 方式部署 etcd 时需要的安装包</span><br><span class="line">- crictl          # k8s 官方的 CRI CLI 工具</span><br><span class="line">- calicoctl       # calico 的 CLI 工具</span><br><span class="line">- helm            # 安装 helm 需要的二进制安装包</span><br><span class="line">- nerdctl         # containerd 的 CLI 工具</span><br><span class="line">- cni-plugins     # CNI 插件</span><br><span class="line">- cuda            # GPU 依赖</span><br><span class="line">- nvidia_driver   # GPU 驱动</span><br></pre></td></tr></table></figure><h4><span id="sealos">sealos</span></h4><p>sealos 对二进制文件的处理比较好，全部打包在离线安装包里，部署的时候会分发到集群节点上，整个部署过程都无需访问公网。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tar -tf kube1.20.0.tar.gz</span><br><span class="line">kube&#x2F;bin&#x2F;kubelet</span><br><span class="line">kube&#x2F;bin&#x2F;kubectl</span><br><span class="line">kube&#x2F;bin&#x2F;conntrack</span><br><span class="line">kube&#x2F;bin&#x2F;kubeadm</span><br></pre></td></tr></table></figure><h4><span id="kubekey">kubekey</span></h4><p>在 kubekey 的源码当中，是将所有二进制文件的 URL 硬编码在代码当中的。如果在部署的时候需要根据部署环境来修改二进制文件的下载地址，比如从内网 nginx 服务器上下载，就需要修改这部分源码把 <code>https://kubernetes-release.pek3b.qingstor.com</code> 修改成内网地址，比如 <code>http://172.20.0.25:8080/files</code> ，然而在部署的时候重新编译 kubekey 的代码又必须能访问公网才行，这就很僵硬。所以以目前开源的 kubekey 来看，是没有办法做到无网环境中愉快地部署 k8s 的，可能商业版会支持（猜测）。</p><ul><li><a href="https://github.com/kubesphere/kubekey/blob/master/pkg/kubernetes/preinstall/preinstall.go" target="_blank" rel="noopener">kubekey/blob/master/pkg/kubernetes/preinstall/preinstall.go</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; FilesDownloadHTTP defines the kubernetes&#39; binaries that need to be downloaded in advance and downloads them.</span><br><span class="line">func FilesDownloadHTTP(mgr *manager.Manager, filepath, version, arch string) error &#123;</span><br><span class="line">kkzone :&#x3D; os.Getenv(&quot;KKZONE&quot;)</span><br><span class="line">etcd :&#x3D; files.KubeBinary&#123;Name: &quot;etcd&quot;, Arch: arch, Version: kubekeyapiv1alpha1.DefaultEtcdVersion&#125;</span><br><span class="line">kubeadm :&#x3D; files.KubeBinary&#123;Name: &quot;kubeadm&quot;, Arch: arch, Version: version&#125;</span><br><span class="line">kubelet :&#x3D; files.KubeBinary&#123;Name: &quot;kubelet&quot;, Arch: arch, Version: version&#125;</span><br><span class="line">kubectl :&#x3D; files.KubeBinary&#123;Name: &quot;kubectl&quot;, Arch: arch, Version: version&#125;</span><br><span class="line">kubecni :&#x3D; files.KubeBinary&#123;Name: &quot;kubecni&quot;, Arch: arch, Version: kubekeyapiv1alpha1.DefaultCniVersion&#125;</span><br><span class="line">helm :&#x3D; files.KubeBinary&#123;Name: &quot;helm&quot;, Arch: arch, Version: kubekeyapiv1alpha1.DefaultHelmVersion&#125;</span><br><span class="line"></span><br><span class="line">etcd.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;etcd-%s-linux-%s.tar.gz&quot;, filepath, kubekeyapiv1alpha1.DefaultEtcdVersion, arch)</span><br><span class="line">kubeadm.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;kubeadm&quot;, filepath)</span><br><span class="line">kubelet.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;kubelet&quot;, filepath)</span><br><span class="line">kubectl.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;kubectl&quot;, filepath)</span><br><span class="line">kubecni.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;cni-plugins-linux-%s-%s.tgz&quot;, filepath, arch, kubekeyapiv1alpha1.DefaultCniVersion)</span><br><span class="line">helm.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;helm&quot;, filepath)</span><br><span class="line"></span><br><span class="line">if kkzone &#x3D;&#x3D; &quot;cn&quot; &#123;</span><br><span class="line">etcd.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;etcd&#x2F;release&#x2F;download&#x2F;%s&#x2F;etcd-%s-linux-%s.tar.gz&quot;, etcd.Version, etcd.Version, etcd.Arch)</span><br><span class="line">kubeadm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubeadm&quot;, kubeadm.Version, kubeadm.Arch)</span><br><span class="line">kubelet.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubelet&quot;, kubelet.Version, kubelet.Arch)</span><br><span class="line">kubectl.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubectl&quot;, kubectl.Version, kubectl.Arch)</span><br><span class="line">kubecni.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;containernetworking.pek3b.qingstor.com&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;%s&#x2F;cni-plugins-linux-%s-%s.tgz&quot;, kubecni.Version, kubecni.Arch, kubecni.Version)</span><br><span class="line">helm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-helm.pek3b.qingstor.com&#x2F;linux-%s&#x2F;%s&#x2F;helm&quot;, helm.Arch, helm.Version)</span><br><span class="line">helm.GetCmd &#x3D; mgr.DownloadCommand(helm.Path, helm.Url)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">etcd.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;%s&#x2F;etcd-%s-linux-%s.tar.gz&quot;, etcd.Version, etcd.Version, etcd.Arch)</span><br><span class="line">kubeadm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubeadm&quot;, kubeadm.Version, kubeadm.Arch)</span><br><span class="line">kubelet.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubelet&quot;, kubelet.Version, kubelet.Arch)</span><br><span class="line">kubectl.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubectl&quot;, kubectl.Version, kubectl.Arch)</span><br><span class="line">kubecni.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;github.com&#x2F;containernetworking&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;%s&#x2F;cni-plugins-linux-%s-%s.tgz&quot;, kubecni.Version, kubecni.Arch, kubecni.Version)</span><br><span class="line">helm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;get.helm.sh&#x2F;helm-%s-linux-%s.tar.gz&quot;, helm.Version, helm.Arch)</span><br><span class="line">getCmd :&#x3D; mgr.DownloadCommand(fmt.Sprintf(&quot;%s&#x2F;helm-%s-linux-%s.tar.gz&quot;, filepath, helm.Version, helm.Arch), helm.Url)</span><br><span class="line">helm.GetCmd &#x3D; fmt.Sprintf(&quot;%s &amp;&amp; cd %s &amp;&amp; tar -zxf helm-%s-linux-%s.tar.gz &amp;&amp; mv linux-%s&#x2F;helm . &amp;&amp; rm -rf *linux-%s*&quot;, getCmd, filepath, helm.Version, helm.Arch, helm.Arch, helm.Arch)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外 kubekey 在安装 docker 时，是直接调用的 <a href="https://get.docker.com/" target="_blank" rel="noopener">docker 官方的脚本</a> 来安装，安装过程也必须访问公网才行。</p><ul><li><a href="https://github.com/kubesphere/kubekey/blob/master/pkg/container-engine/docker/docker.go" target="_blank" rel="noopener">kubekey/blob/master/pkg/container-engine/docker/docker.go</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func installDockerOnNode(mgr *manager.Manager, _ *kubekeyapiv1alpha1.HostCfg) error &#123;</span><br><span class="line">dockerConfig, err :&#x3D; GenerateDockerConfig(mgr)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return err</span><br><span class="line">&#125;</span><br><span class="line">dockerConfigBase64 :&#x3D; base64.StdEncoding.EncodeToString([]byte(dockerConfig))</span><br><span class="line">output, err1 :&#x3D; mgr.Runner.ExecuteCmd(fmt.Sprintf(&quot;sudo -E &#x2F;bin&#x2F;sh -c \&quot;if [ -z $(which docker) ] || [ ! -e &#x2F;var&#x2F;run&#x2F;docker.sock ]; then curl https:&#x2F;&#x2F;kubernetes.pek3b.qingstor.com&#x2F;tools&#x2F;kubekey&#x2F;docker-install.sh | sh &amp;&amp; systemctl enable docker; if [ ! -f &#x2F;etc&#x2F;docker&#x2F;daemon.json ]; then mkdir -p &#x2F;etc&#x2F;docker &amp;&amp; echo %s | base64 -d &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json; fi; systemctl daemon-reload &amp;&amp; systemctl restart docker; fi\&quot;&quot;, dockerConfigBase64), 0, false)</span><br><span class="line">if err1 !&#x3D; nil &#123;</span><br><span class="line">return errors.Wrap(errors.WithStack(err1), fmt.Sprintf(&quot;Failed to install docker:\n%s&quot;, output))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 docker 官方的安装脚本来安装 docker 是有一个明显的问题就是：没有版本控制，不能指定 docker 的版本，每次安装的 docker 版本都是最新的 stable 版本。没有版本控制就会导致不同时间部署的集群或者加入的节点，docker 版本可能就不一样，在这里可能会埋下一些坑，可能会带来一定的维护成本或者将来升级时遇到问题。</p><p>编译过 kubernetes 组件的可能都知道 k8s 源码当中存在一个 <a href="https://github.com/kubernetes/kubernetes/blob/master/build/dependencies.yaml" target="_blank" rel="noopener">build/dependencies.yaml</a> 的文件，里面记录的是 k8s 组件与其他组件 (如 docker, etcd, coredns, cni, pause) 所匹配的最佳版本。</p><blockquote><p>On each of your nodes, install the Docker for your Linux distribution as per <a href="https://docs.docker.com/engine/install/#server" target="_blank" rel="noopener">Install Docker Engine</a>. You can find the latest validated version of Docker in this <a href="https://git.k8s.io/kubernetes/build/dependencies.yaml" target="_blank" rel="noopener">dependencies</a> file.</p></blockquote><ul><li><a href="https://github.com/kubernetes/kubernetes/blob/release-1.20/build/dependencies.yaml" target="_blank" rel="noopener">kubernetes/blob/release-1.20/build/dependencies.yaml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">dependencies:</span><br><span class="line">  # zeitgeist (https:&#x2F;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;zeitgeist) was inspired by</span><br><span class="line">  # (and now replaces) the cmd&#x2F;verifydependencies tool to verify external</span><br><span class="line">  # dependencies across the repo.</span><br><span class="line">  #</span><br><span class="line">  # The zeitgeist dependencies.yaml file format is intended to be</span><br><span class="line">  # backwards-compatible with the original tooling.</span><br><span class="line">  #</span><br><span class="line">  # In instances where the file format may change across versions, this meta</span><br><span class="line">  # dependency check exists to ensure we&#39;re pinned to a known good version.</span><br><span class="line">  #</span><br><span class="line">  # ref: https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;pull&#x2F;98845</span><br><span class="line"></span><br><span class="line">  # Docker</span><br><span class="line">  - name: &quot;docker&quot;</span><br><span class="line">    version: 19.03</span><br><span class="line">    refPaths:</span><br><span class="line">    - path: vendor&#x2F;k8s.io&#x2F;system-validators&#x2F;validators&#x2F;docker_validator.go</span><br><span class="line">      match: latestValidatedDockerVersion</span><br></pre></td></tr></table></figure><p>以 1.20.x 版本的 k8s 为例，它所依赖的 docker 版本为 19.03，而现在最新的 docker 版本如 20.10.8，并不是 K8s 官方所建议的最佳版本。总之，我们在部署 K8s 时，可以参考 <a href="https://github.com/kubernetes/kubernetes/blob/master/build/dependencies.yaml" target="_blank" rel="noopener">build/dependencies.yaml</a> 来确定与 K8s 相关的组件应该选择哪一个最佳的版本，而不是随便装一个最新的版本就完事儿了。</p><h4><span id="kubespray">kubespray</span></h4><p>在 kubespray 中，所有二进制文件的 URL 都是通过变量的方式定义的，想要做到离线部署十分简单，只需要通过 ansible 变量优先级的特性，将它们在 group_vars 通过 overrides 的方式覆盖即可。比如这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Download URLs</span><br><span class="line">kubelet_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubelet&quot;</span><br><span class="line">kubectl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubectl&quot;</span><br><span class="line">kubeadm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubeadm&quot;</span><br></pre></td></tr></table></figure><h3><span id="images">images</span></h3><p>一些如 kube-proxy、kube-apiserver、coredns、calico 组件镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">k8s.gcr.io&#x2F;kube-apiserver:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;kube-controller-manager:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;kube-proxy:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;kube-registry-proxy:0.4</span><br><span class="line">k8s.gcr.io&#x2F;kube-scheduler:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;pause:3.3</span><br><span class="line">k8s.gcr.io&#x2F;coredns:1.7.0</span><br><span class="line">k8s.gcr.io&#x2F;cpa&#x2F;cluster-proportional-autoscaler-amd64:1.8.3</span><br><span class="line">k8s.gcr.io&#x2F;dns&#x2F;k8s-dns-node-cache:1.17.1</span><br></pre></td></tr></table></figure><h4><span id="sealos">sealos</span></h4><p>sealos 将这些镜像使用 docker save 的方式打包成一个 tar 包，在部署的时候使用 docker/ctr load 的方式将镜像导入到容器运行时的存储目录当中，源码如下：</p><ul><li><a href="https://github.com/fanux/sealos/blob/develop/install/send.go" target="_blank" rel="noopener">fanux/sealos/blob/develop/install/send.go</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; SendPackage is send new pkg to all nodes.</span><br><span class="line">func (u *SealosUpgrade) SendPackage() &#123;</span><br><span class="line">all :&#x3D; append(u.Masters, u.Nodes...)</span><br><span class="line">pkg :&#x3D; path.Base(u.NewPkgUrl)</span><br><span class="line">&#x2F;&#x2F; rm old sealos in package avoid old version problem. if sealos not exist in package then skip rm</span><br><span class="line">var kubeHook string</span><br><span class="line">if For120(Version) &#123;</span><br><span class="line">&#x2F;&#x2F; TODO update need load modprobe -- br_netfilter modprobe -- bridge.</span><br><span class="line">&#x2F;&#x2F; https:&#x2F;&#x2F;github.com&#x2F;fanux&#x2F;cloud-kernel&#x2F;issues&#x2F;23</span><br><span class="line">kubeHook &#x3D; fmt.Sprintf(&quot;cd &#x2F;root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf %s  &amp;&amp; cd &#x2F;root&#x2F;kube&#x2F;shell &amp;&amp; rm -f ..&#x2F;bin&#x2F;sealos &amp;&amp; (ctr -n&#x3D;k8s.io image import ..&#x2F;images&#x2F;images.tar || true) &amp;&amp; cp -f ..&#x2F;bin&#x2F;* &#x2F;usr&#x2F;bin&#x2F; &quot;, pkg)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">kubeHook &#x3D; fmt.Sprintf(&quot;cd &#x2F;root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf %s  &amp;&amp; cd &#x2F;root&#x2F;kube&#x2F;shell &amp;&amp; rm -f ..&#x2F;bin&#x2F;sealos &amp;&amp; (docker load -i ..&#x2F;images&#x2F;images.tar || true) &amp;&amp; cp -f ..&#x2F;bin&#x2F;* &#x2F;usr&#x2F;bin&#x2F; &quot;, pkg)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PkgUrl &#x3D; SendPackage(pkg, all, &quot;&#x2F;root&quot;, nil, &amp;kubeHook)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用这种方式加载镜像有一个比较明显的限制就是 kube-apiserver 的 admission 准入控制中不能加入 <code>AlwaysPullImages</code> 参数。不然与这些镜像相关的 pod 重新调度或者重启之后会重新从源镜像仓库拉取镜像，在无网或者网络限制的环境中可能无法拉取镜像导致这些 Pod 启动失败，从而导致集群异常。</p><p>而在多租户场景下，出于安全的考虑 <code>AlwaysPullImages</code> 准入控制往往是要开启的。因此 sealos 可能并不适用于多租户或者对此有要求的环境中（最常见的就是 PaaS 平台）。</p><blockquote><p>该准入控制器会修改每一个新创建的 Pod 的镜像拉取策略为 Always 。 这在多租户集群中是有用的，这样用户就可以放心，他们的私有镜像只能被那些有凭证的人使用。 如果没有这个准入控制器，一旦镜像被拉取到节点上，任何用户的 Pod 都可以通过已了解到的镜像的名称（假设 Pod 被调度到正确的节点上）来使用它，而不需要对镜像进行任何授权检查。 当启用这个准入控制器时，总是在启动容器之前拉取镜像，这意味着需要有效的凭证。</p></blockquote><h4><span id="kubekey">kubekey</span></h4><p><a href="https://kubesphere.io/docs/installing-on-linux/introduction/air-gapped-installation/" target="_blank" rel="noopener">kubekey 官方的文档</a> 中有提到组件镜像离线部署的方式，不过十分繁琐(劝退😂)，在 <a href="https://github.com/kubesphere/kubekey/issues/597" target="_blank" rel="noopener">Offline installation is too troublesome #597</a> 中也有人吐槽这个问题。不过目前 kubekey 开发团队已经在重构这部分内容了，至于结果如何，只能等了。</p><h4><span id="镜像仓库">镜像仓库</span></h4><p>在私有云环境中，企业一般都会有自己的镜像仓库（比如 harbor ）用于存放业务组件镜像或者一些其他平台依赖的镜像。再加上 Docker Hub 自从去年开始就加入了 pull 镜像次数的限制，如果直接使用 Docker Hub 上面的镜像来部署集群，很有可能会因为 <a href="https://www.docker.com/increase-rate-limit" target="_blank" rel="noopener">429 toomanyrequests</a> 或者一些网络原因导致拉取镜像失败。因此对于 k8s 集群部署而言，建议使用内部自己的镜像仓库，而非公网上镜像仓库。如果没有的话可以使用 harbor 或者 docker registry 在本地部署一个镜像仓库。我们将部署依赖的镜像导入到已经存在的镜像仓库中，部署的时候从该镜像仓库拉取即可。</p><h2><span id="部署工具选择">部署工具选择</span></h2><p>上面简单梳理了一下部署 k8s 集群过程中所依赖的的在线资源，以及如何将它们制作成离线资源的一些分析。上面提及的部署工具各有各的优缺点，针对以下两种不同的场景可以选择不同的部署工具。</p><h3><span id="sealos">sealos</span></h3><p>如果仅仅是部署一个简单的 k8s 集群，对集群没有太多定制化的需求，那么使用 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 可能是最佳的选择，只不过它是收费的，<a href="https://www.sealyun.com/" target="_blank" rel="noopener">需要充值会员</a> 😂。</p><blockquote><h3><span id="现在开始-99-69年">现在开始 <s>￥99</s> ￥69/年</span></h3><p>欢迎成为年费会员，任意下载所有版本软件包!</p><blockquote><p>@F-liuhui 离线包居然要收费？那还是开源项目吗？</p></blockquote><p>开源与付费不冲突，100%开源 100%付费</p><p><a href="https://www.sealyun.com/" target="_blank" rel="noopener">sealyun.com</a></p></blockquote><p>如果动手能力强的话，可以根据 selaos 离线安装包的目录结构使用 GitHub Actions 来构建，实现起来也不是很难。只不过砸别人饭碗的事儿还是不做为好，因此我们应该选择另一种方案来实现，这样也能避免一些商业纠纷问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ tar -tf kube1.20.0.tar.gz</span><br><span class="line">kube&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;README.md</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2.3.1</span><br><span class="line">kube&#x2F;shell&#x2F;</span><br><span class="line">kube&#x2F;shell&#x2F;containerd.sh</span><br><span class="line">kube&#x2F;shell&#x2F;init.sh</span><br><span class="line">kube&#x2F;shell&#x2F;master.sh</span><br><span class="line">kube&#x2F;README.md</span><br><span class="line">kube&#x2F;bin&#x2F;</span><br><span class="line">kube&#x2F;bin&#x2F;kubelet</span><br><span class="line">kube&#x2F;bin&#x2F;kubectl</span><br><span class="line">kube&#x2F;bin&#x2F;conntrack</span><br><span class="line">kube&#x2F;bin&#x2F;kubeadm</span><br><span class="line">kube&#x2F;bin&#x2F;kubelet-pre-start.sh</span><br><span class="line">kube&#x2F;conf&#x2F;</span><br><span class="line">kube&#x2F;conf&#x2F;kubeadm.yaml</span><br><span class="line">kube&#x2F;conf&#x2F;kubelet.service</span><br><span class="line">kube&#x2F;conf&#x2F;calico.yaml</span><br><span class="line">kube&#x2F;conf&#x2F;10-kubeadm.conf</span><br><span class="line">kube&#x2F;conf&#x2F;net&#x2F;</span><br><span class="line">kube&#x2F;conf&#x2F;net&#x2F;calico.yaml</span><br><span class="line">kube&#x2F;containerd&#x2F;</span><br><span class="line">kube&#x2F;containerd&#x2F;README.md</span><br><span class="line">kube&#x2F;containerd&#x2F;cri-containerd-cni-linux-amd64.tar.gz</span><br><span class="line">kube&#x2F;images&#x2F;</span><br><span class="line">kube&#x2F;images&#x2F;images.tar</span><br><span class="line">kube&#x2F;images&#x2F;README.md</span><br></pre></td></tr></table></figure><h3><span id="kubekey">kubekey</span></h3><p>由于 kubekey 部署时二进制文件需要公网获取，docker 无法离线部署以及需要手动安装一些前置依赖，没有办法做到完整的离线部署，因此离线部署的方案也就直接放弃掉了，抽空他们提个 Issue 或 PR 看看能否支持这部分 😅。</p><h3><span id="kubespray">kubespray</span></h3><p>如果想找一个即开源又免费的离线部署方案，或者对集群部署有特殊的要求，比如基于 K8s 的 PaaS toB 产品，需要在部署时安装平台本身需要的一些依赖（如存储客户端、GPU 驱动等）。那么不妨先看一下 kubernetes-sig 社区的 <a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">kubespray</a> 如何 🤔，主要的特性如下：</p><ul><li>支持的 10 种 CNI 插件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- cni-plugins v0.9.1</span><br><span class="line">- calico v3.17.4</span><br><span class="line">- canal (given calico&#x2F;flannel versions)</span><br><span class="line">- cilium v1.9.9</span><br><span class="line">- flanneld v0.14.0</span><br><span class="line">- kube-ovn v1.7.1</span><br><span class="line">- kube-router v1.3.0</span><br><span class="line">- multus v3.7.2</span><br><span class="line">- ovn4nfv v1.1.0</span><br><span class="line">- weave v2.8.1</span><br></pre></td></tr></table></figure><ul><li>支持 3 种容器运行时以及 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/docs/kata-containers.md" target="_blank" rel="noopener">Kata Containers</a> 还有 nvidia-gpu-device-plugin 等</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- docker v20.10</span><br><span class="line">- containerd v1.4.6</span><br><span class="line">- cri-o v1.21</span><br></pre></td></tr></table></figure><ul><li>适配了 10 种 Linux 发行版，覆盖了绝大多数私有云场景</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- Flatcar Container Linux by Kinvolk</span><br><span class="line">- Debian Buster, Jessie, Stretch, Wheezy</span><br><span class="line">- Ubuntu 16.04, 18.04, 20.04</span><br><span class="line">- CentOS&#x2F;RHEL 7, 8</span><br><span class="line">- Fedora 33, 34</span><br><span class="line">- Fedora CoreOS (see fcos Note)</span><br><span class="line">- openSUSE Leap 15.x&#x2F;Tumbleweed</span><br><span class="line">- Oracle Linux 7, 8</span><br><span class="line">- Alma Linux 8</span><br><span class="line">- Amazon Linux 2</span><br></pre></td></tr></table></figure><ul><li>丰富的插件和扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">## 工具类</span><br><span class="line">- helm</span><br><span class="line">- krew</span><br><span class="line">- nerdctl</span><br><span class="line"></span><br><span class="line">## 一些 controller 和 provisioner</span><br><span class="line">- ambassador: v1.5</span><br><span class="line">- cephfs-provisioner v2.1.0-k8s1.11</span><br><span class="line">- rbd-provisioner v2.1.1-k8s1.11</span><br><span class="line">- cert-manager v0.16.1</span><br><span class="line">- coredns v1.8.0</span><br><span class="line">- ingress-nginx v0.43.0</span><br></pre></td></tr></table></figure><ul><li>依赖的文件和镜像支持离线部署 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/docs/offline-environment.md" target="_blank" rel="noopener">Offline environment</a></li></ul><p>kubespray 对所有的依赖资源都做到了离线下载的支持：比如所有依赖文件的 URL 都通过变量的方式来定义，而非 kubekey 那样硬编码在代码中；所有镜像的 repo 和 tag 都是通过变量的方式来定义。这样的好处就是在部署的时候可以根据客户环境的的镜像仓库地址和文件服务器的 URL 地址来填写相应的参数，无需通过公网来获取。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Registry overrides</span><br><span class="line">kube_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line">gcr_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line">docker_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line">quay_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line">kubeadm_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;kubeadm&quot;</span><br><span class="line">kubectl_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;kubectl&quot;</span><br><span class="line">kubelet_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;kubelet&quot;</span><br><span class="line"># etcd is optional if you **DON&#39;T** use etcd_deployment&#x3D;host</span><br><span class="line">etcd_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;etcd&#x2F;etcd-&#123;&#123; etcd_version &#125;&#125;-linux-amd64.tar.gz&quot;</span><br><span class="line">cni_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;cni&#x2F;cni-plugins-linux-&#123;&#123; image_arch &#125;&#125;-&#123;&#123; cni_version &#125;&#125;.tgz&quot;</span><br><span class="line">crictl_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;cri-tools&#x2F;crictl-&#123;&#123; crictl_version &#125;&#125;-&#123;&#123; ansible_system | lower &#125;&#125;-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line"># If using Calico</span><br><span class="line">calicoctl_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;calico&#x2F;&#123;&#123; calico_ctl_version &#125;&#125;&#x2F;calicoctl-linux-&#123;&#123; image_arch &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><p>和上述几种部署工具对比不难发现，kubespray 灵活性和可扩展性要领先其他工具（支持 10 种 CNI、10种 Linux 发行版、3 种 CRI、以及多种插件和扩展）并在参数层面上做到了离线部署的支持。因此我们首先选用 kubespray 作为集群部署的底层工具。</p><p>还有一个问题就是 kubespray 虽然在参数配置上支持离线部署，但是从制作离线安装包到一键部署，目前为止还未有一个完整的实现方案。因此需要为 kubespray 设计一套从离线安装包的构建到集群一键部署的流程和方案，为此我们新建一个名为 <a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">kubeplay</a> 的 repo 来完成这部分内容。</p><p>另外值得一提的是 kubesphere 早期的版本 v2.x 使用也是 kubespray 部署的 k8s，至今 ks-installer 代码中仍残留着 <a href="https://github.com/kubesphere/ks-installer/commits/master/roles/download/tasks" target="_blank" rel="noopener">部分 kubespray 的代码</a> ，到了 3.0 的时候开始使用自研的 kubekey 来部署 K8s 了。</p><blockquote><p>基于 Ansible 的安装程序具有大量软件依赖性，例如 Python。KubeKey 是使用 Go 语言开发的，可以消除在各种环境中出现的问题，从而提高安装成功率。</p><p><a href="https://github.com/kubesphere/kubekey/blob/master/README_zh-CN.md" target="_blank" rel="noopener">README_zh-CN.md</a></p></blockquote><p>不过 ansible 的依赖问题当时为什么没有考虑采用容器化的方式运行 kubespray 🤔，至于 ansible 的性能问题也不是没有优化的余地。</p><h2><span id="kubeplay"></span></h2><p>kubeplay 这个项目主要是实现 K8s 离线安装包的构建和一键部署功能，目前只适配了 kubespray，等到后面会适配一些其他部署工具如 kubekey。</p><h3><span id="打包方式">打包方式</span></h3><p>由于部署依赖的二进制文件和组件镜像大都存放在 GitHub 、Docker Hub、<a href="http://gcr.io" target="_blank" rel="noopener">gcr.io</a>（Google Container Registry）、<a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 这些国外的平台上，在国内环境获取这些资源是有一定的网络限制。而 GitHub 托管的 runner 运行在国外的机房当中，可以很顺畅地获取这些资源。因此我们选择使用 GitHub Actions 来进行离线安装包的构建。</p><p>像 selos 那样将安装包存放在阿里云 OSS 上，在国内能十分顺畅地高速下载，收费也是理所当然。但我们的方案是 100% 开源 100% 免费，每个人都可以 fork 代码到自己的 repo，根据自己的需求进行构建。因此选择 GitHub 来构建和存放我们的安装包是最合适的选择，这样也不用去额外考虑安装包下载的问题。至于从 GitHub 上下载安装包慢的问题，那应该由使用者自行去解决，而非本方案所关心的问题。</p><blockquote><p>Q：如何摆脱网络的依赖来创建个 Docker 的 image 呢，我觉得这个是 Docker 用户自己的基本权利？</p><p>A：这个基本权利我觉得还是要问 GFW ，国外的开发人员是非常难理解有些他们认为跟水电一样普及的基础设施在某些地方还是很困难的。</p><p>此处引用 <a href="http://dockone.io/article/722" target="_blank" rel="noopener">DockOne技术分享（二十四）：容器和IaaS：谁动了谁的奶酪</a></p></blockquote><p>选择好的构建场所为 GitHub Actions 之后我们再将这些离线资源进行拆分，目的是为了实现各个离线资源之间的解耦，这样做灵活性更好一些，比如能够适配多种 OS、支持多个 k8s 版本等。主要拆分成如下几个模块。</p><table><thead><tr><th style="text-align:left">模块</th><th style="text-align:left">Repo</th><th style="text-align:left">用途</th><th style="text-align:left">运行/使用方式</th></tr></thead><tbody><tr><td style="text-align:left">compose</td><td style="text-align:left"><a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">kubeplay</a></td><td style="text-align:left">用于部署 nginx 和 registry 服务</td><td style="text-align:left">nerdctl compose</td></tr><tr><td style="text-align:left">os-tools</td><td style="text-align:left"><a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">kubeplay</a></td><td style="text-align:left">部署 compose 时的一些依赖工具</td><td style="text-align:left">二进制安装</td></tr><tr><td style="text-align:left">os-packages</td><td style="text-align:left"><a href="https://github.com/k8sli/os-packages" target="_blank" rel="noopener">os-packages</a></td><td style="text-align:left">提供 rpm/deb 离线源</td><td style="text-align:left">nginx 提供 http 方式下载</td></tr><tr><td style="text-align:left">kubespray</td><td style="text-align:left"><a href="https://github.com/k8sli/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">用于部署/扩缩容 k8s 集群</td><td style="text-align:left">容器或者 pod</td></tr><tr><td style="text-align:left">kubespray-files</td><td style="text-align:left"><a href="https://github.com/k8sli/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">提供二进制文件依赖</td><td style="text-align:left">nginx 提供 http 方式下载</td></tr><tr><td style="text-align:left">kubespray-images</td><td style="text-align:left"><a href="https://github.com/k8sli/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">提供组件镜像</td><td style="text-align:left">registry 提供镜像下载</td></tr></tbody></table><p>拆分完成之后，我们最终还是需要将它们组合成一个完成的离线安装包。为了减少维护成本，我们将每个模块的构建操作都放在 Dockerfile 中，即 <code>All in Dockerfile</code> 🤣。这样每个模块的 GitHub Actions 流水线最终交付的都是一个镜像，然后镜像都推送到 <code>ghcr.io</code> 上，这样就解决了模块间产物传递以及镜像缓存的问题。最终通过一个最终的 <a href="https://github.com/k8sli/kubeplay/blob/main/Dockerfile" target="_blank" rel="noopener">Dockerfile</a> 将这些模块的镜像全部 COPY 到一个镜像当中，只要打包这个最终的镜像为离线安装包即可；另一个好处就使用 buildx 构建这些离线资源就原生支持多 CPU 体系架构，能够同时适配 amd64 和 arm64 体系架构，这样 arm64 也能愉快地玩耍了，真是一举两得。</p><p>下面就详细讲解每个模块的功能以及是如何打包的：</p><h3><span id="compose">compose</span></h3><p>compose 模块里面主要运两个服务： 用于提供文件下载的 nginx 和组件镜像拉取的 registry。这两个我们依旧是容器化以类似 docker-compose 的方式来部署，而所依赖的也只有两个镜像和一些配置文件而已。</p><ul><li><a href="https://github.com/k8sli/kubeplay/blob/main/compose.yaml" target="_blank" rel="noopener">kubeplay/blob/main/compose.yaml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.1&#39;</span><br><span class="line">services:</span><br><span class="line">  nginx:</span><br><span class="line">    container_name: nginx</span><br><span class="line">    image: nginx:1.20-alpine</span><br><span class="line">    restart: always</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;resources&#x2F;nginx:&#x2F;usr&#x2F;share&#x2F;nginx</span><br><span class="line">      - .&#x2F;config&#x2F;compose&#x2F;certs&#x2F;domain.crt:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;domain.crt</span><br><span class="line">      - .&#x2F;config&#x2F;compose&#x2F;certs&#x2F;domain.key:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;domain.key</span><br><span class="line">      - .&#x2F;config&#x2F;compose&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf</span><br><span class="line">    ports:</span><br><span class="line">      # 443 端口反向代理 registr 的 5000 端口，仅用于 pull 镜像</span><br><span class="line">      - 443:443</span><br><span class="line">      - 8080:8080</span><br><span class="line"></span><br><span class="line">  registry:</span><br><span class="line">    image: registry:2.7.1</span><br><span class="line">    container_name: registry</span><br><span class="line">    restart: always</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;resources&#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry</span><br><span class="line">    ports:</span><br><span class="line">      # 只允许本地 5000 端口 push 镜像</span><br><span class="line">      - 127.0.0.1:5000:5000</span><br></pre></td></tr></table></figure><p>这两个镜像我们使用 skopeo copy 的方式保存为 tar 包，部署的时候 load 到容器运行时的存储中。</p><blockquote><p>Q：为什么要用 skopeo 而不是 docker？</p><p>A：因为 Dockerfile 构建过程中不支持运行 docker 命令 save 镜像</p></blockquote><ul><li>Dockerfile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest as downloader</span><br><span class="line">ARG SKOPEO_VERSION&#x3D;v1.4.0</span><br><span class="line">ARG NGINX_VERSION&#x3D;1.20-alpine</span><br><span class="line">ARG RERGISRRY_VERSION&#x3D;2.7.1</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;tools</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; apk --no-cache add wget ca-certificates \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;skopeo&#x2F;releases&#x2F;download&#x2F;v1.4.0&#x2F;skopeo-linux-$&#123;ARCH&#125; -O &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; \</span><br><span class="line">    &amp;&amp; chmod a+x &#x2F;tools&#x2F;* \</span><br><span class="line">    &amp;&amp; ln -s &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; &#x2F;usr&#x2F;bin&#x2F;skopeo</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;images</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag nginx:$&#123;NGINX_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;nginx:$&#123;NGINX_VERSION&#125; docker-archive:nginx-$&#123;NGINX_VERSION&#125;.tar \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag registry:$&#123;RERGISRRY_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;registry:$&#123;RERGISRRY_VERSION&#125; docker-archive:registry-$&#123;RERGISRRY_VERSION&#125;.tar</span><br></pre></td></tr></table></figure><p>在部署的时候我们使用 nerdctl compose 的方式启动即可，使用方式有点类似于 docker-compose。</p><blockquote><p>Q: 为什么不用 docker 和 docker-compose</p><p>A：K8s 去 docker 是大势所趋，选择 containerd 更符合主流发展方向</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 将镜像 load 进 containerd 存储</span><br><span class="line">$ find $&#123;IMAGES_DIR&#125; -type f -name &#39;*.tar&#39; | xargs -L1 nerdctl load -i</span><br><span class="line"># nerdctl compose 启动 nginx 和 registry</span><br><span class="line">$ nerdctl compose -f compose.yaml up</span><br></pre></td></tr></table></figure><h3><span id="os-packages">os-packages</span></h3><p>这部分是 rpm/deb 离线源的构建，其详细的过程和原理可以参考我之前写的博客 《<a href="https://blog.k8s.li/make-offline-mirrors.html" target="_blank" rel="noopener">使用 docker build 制作 yum/apt 离线源</a>》，下面只列举一下 CentOS7 离线源的构建配置：</p><ul><li><a href="https://github.com/k8sli/os-packages/blob/main/build/Dockerfile.os.centos7" target="_blank" rel="noopener">Dockerfile</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7.9.2009 as os-centos7</span><br><span class="line">ARG OS_VERSION&#x3D;7</span><br><span class="line">ARG DOCKER_MIRROR_URL&#x3D;&quot;https:&#x2F;&#x2F;download.docker.com&quot;</span><br><span class="line">ARG BUILD_TOOLS&#x3D;&quot;yum-utils createrepo epel-release wget&quot;</span><br><span class="line"></span><br><span class="line"># 安装构建工具，配置 docker 官方 yum 源</span><br><span class="line">RUN yum install -q -y $&#123;BUILD_TOOLS&#125; \</span><br><span class="line">    &amp;&amp; yum-config-manager --add-repo $&#123;DOCKER_MIRROR_URL&#125;&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo \</span><br><span class="line">    &amp;&amp; yum makecache</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;centos&#x2F;$OS_VERSION&#x2F;os</span><br><span class="line">COPY packages.yaml .</span><br><span class="line">COPY --from&#x3D;mikefarah&#x2F;yq:4.11.1 &#x2F;usr&#x2F;bin&#x2F;yq &#x2F;usr&#x2F;bin&#x2F;yq</span><br><span class="line"></span><br><span class="line"># 根据配置文件解析该 OS 需要构建的包，并获取这些包的下载 url</span><br><span class="line">RUN yq eval &#39;.common[],.yum[],.centos7[],.kubespray.common[],.kubespray.yum[]&#39; packages.yaml &gt; packages.list \</span><br><span class="line">    &amp;&amp; sort -u packages.list | xargs repotrack --urls | sort -u &gt; packages.urls</span><br><span class="line"></span><br><span class="line"># 通过 wget 的方式下载 rpm 包，使用 createrepo 创建 repo 索引文件</span><br><span class="line">RUN ARCH&#x3D;$(uname -m) \</span><br><span class="line">    &amp;&amp; wget -q -x -P $&#123;ARCH&#125; -i packages.urls \</span><br><span class="line">    &amp;&amp; createrepo -d $&#123;ARCH&#125;</span><br><span class="line"></span><br><span class="line"># 将构建的内容 COPY 成单独的一层</span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;os-centos7 &#x2F;centos &#x2F;centos</span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com/k8sli/os-packages/blob/main/packages.yaml" target="_blank" rel="noopener">packages.yaml</a> 配置文件</li></ul><p>这个是需要安装包的配置文件，可以根据平台或者客户的一些要求配置上不同的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">kubespray:</span><br><span class="line">  common:</span><br><span class="line">    - curl</span><br><span class="line">    - rsync</span><br><span class="line">    - socat</span><br><span class="line">    - unzip</span><br><span class="line">    - e2fsprogs</span><br><span class="line">    - xfsprogs</span><br><span class="line">    - ebtables</span><br><span class="line">    - bash-completion</span><br><span class="line">    - ipvsadm</span><br><span class="line">    - ipset</span><br><span class="line">    - conntrack</span><br><span class="line"></span><br><span class="line">  yum:</span><br><span class="line">    - nss</span><br><span class="line">    - libselinux-python</span><br><span class="line">    - device-mapper-libs</span><br><span class="line">  apt:</span><br><span class="line">    - python-apt</span><br><span class="line">    - python3-apt</span><br><span class="line">    - aufs-tools</span><br><span class="line">    - apt-transport-https</span><br><span class="line">    - software-properties-common</span><br><span class="line"></span><br><span class="line">common:</span><br><span class="line">  - cifs-utils</span><br><span class="line">  - lsof</span><br><span class="line">  - lvm2</span><br><span class="line">  - openssl</span><br><span class="line">  - sshpass</span><br><span class="line">  - vim</span><br><span class="line">  - wget</span><br><span class="line">  - ethtool</span><br><span class="line">  - net-tools</span><br><span class="line">  - rsync</span><br><span class="line">  - chrony</span><br><span class="line"></span><br><span class="line">yum:</span><br><span class="line">  - nfs-utils</span><br><span class="line">  - yum-utils</span><br><span class="line">  - createrepo</span><br><span class="line">  - epel-release</span><br><span class="line">  - nc</span><br><span class="line">  - httpd-tools</span><br><span class="line"></span><br><span class="line">apt:</span><br><span class="line">  - nfs-common</span><br><span class="line">  - apt-transport-https</span><br><span class="line">  - ca-certificates</span><br><span class="line">  - gnupg</span><br><span class="line">  - lsb-release</span><br><span class="line">  - aptitude</span><br><span class="line">  - dpkg-dev</span><br><span class="line">  - gnupg2</span><br><span class="line">  - netcat</span><br><span class="line">  - apache2-utils</span><br><span class="line"></span><br><span class="line">centos7:</span><br><span class="line">  - containerd.io-1.4.6</span><br><span class="line"></span><br><span class="line">ubuntu:</span><br><span class="line">  - containerd.io&#x3D;1.4.6-1</span><br><span class="line"></span><br><span class="line">debian10:</span><br><span class="line">  - containerd.io&#x3D;1.4.6-1</span><br></pre></td></tr></table></figure><blockquote><p>对于 toB 产品，建议将下面这些常见的运维调试工具（如 tcpdump, strace, lsof, net-tools 等）也构建在离线源中。这样也不至于在客户的环境中排查问题的时候机器上连个 tcpdump 都没有，尤其是在无网的环境中，如果没有这些常用的运维工具，排查问题将会十分棘手。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">tools:</span><br><span class="line">  - bash-completion</span><br><span class="line">  - chrony</span><br><span class="line">  - cifs-utils</span><br><span class="line">  - curl</span><br><span class="line">  - dstat</span><br><span class="line">  - e2fsprogs</span><br><span class="line">  - ebtables</span><br><span class="line">  - expect</span><br><span class="line">  - gdb</span><br><span class="line">  - htop</span><br><span class="line">  - iftop</span><br><span class="line">  - iotop</span><br><span class="line">  - ipset</span><br><span class="line">  - ipvsadm</span><br><span class="line">  - jq</span><br><span class="line">  - lsof</span><br><span class="line">  - lvm2</span><br><span class="line">  - ncdu</span><br><span class="line">  - net-tools</span><br><span class="line">  - nethogs</span><br><span class="line">  - nload</span><br><span class="line">  - ntpdate</span><br><span class="line">  - openssl</span><br><span class="line">  - pciutils</span><br><span class="line">  - psmisc</span><br><span class="line">  - rsync</span><br><span class="line">  - smartmontools</span><br><span class="line">  - socat</span><br><span class="line">  - sshpass</span><br><span class="line">  - strace</span><br><span class="line">  - sysstat</span><br><span class="line">  - tcpdump</span><br><span class="line">  - telnet</span><br><span class="line">  - tmux</span><br></pre></td></tr></table></figure><h3><span id="kubespray">kubespray</span></h3><p>kubespray 是部署 K8s 集群、增加节点、删除节点、移除集群等涉及对集群操作的主要工具。我们依旧采用容器化的方式运行 kubespray，主要有以下场景会用到 kubespray：</p><ul><li>在部署工具运行节点，使用 nerdctl 来运行 kubespray 容器部署 K8s 集群</li><li>K8s 集群部署完毕后，以 Job pod 的方式运行部署另一个 K8s 集群，实现多集群部署的基本能力</li><li>K8s 集群部署完毕后，以 Job pod 的方式运行 kubespray 对该集群集群节点进行扩缩容</li></ul><p>Job pod 方式对集群进行扩缩容的设计的是为了从一定程度上解决部署大规模集群时 ansible 性能问题。即我们一开始不必就部署一个上千节点的集群，而是先把一个规模较小的集群部署起来，然后通过创建批量的 Job 的方式运行 kubespray 再将集群慢慢扩容起来，比如扩容到上千台节点。</p><p>kubespray 官方的 Dockerfile 构建出来的镜像有 1.4GB，实在是太大了，因此我们需要优化一下，减少镜像大小</p><ul><li>kubespray BASE 镜像</li></ul><p>首先构建一个 base 镜像，对于不经常变动的内容我们把它封装在一个 base 镜像里，只有当相关依赖更新了才需要重新构建这个 base 镜像，<code>Dockerfile.base</code> 如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">FROM python:3 as builder</span><br><span class="line">ARG KUBE_VERSION&#x3D;v1.21.3</span><br><span class="line">COPY requirements.txt requirements.txt</span><br><span class="line">COPY tests&#x2F;requirements.txt tests&#x2F;requirements.txt</span><br><span class="line">RUN echo &#39;shellcheck-py&#x3D;&#x3D;0.7.2.1&#39; &gt;&gt; requirements.txt \</span><br><span class="line">    &amp;&amp; grep -E &#39;^yamllint|^ansible-lint&#39; tests&#x2F;requirements.txt &gt;&gt; requirements.txt \</span><br><span class="line">    &amp;&amp; pip3 install --user -r requirements.txt</span><br><span class="line"></span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; wget -O &#x2F;root&#x2F;.local&#x2F;bin&#x2F;kubectl -q https:&#x2F;&#x2F;dl.k8s.io&#x2F;$&#123;KUBE_VERSION&#125;&#x2F;bin&#x2F;linux&#x2F;$&#123;ARCH&#125;&#x2F;kubectl \</span><br><span class="line">&amp;&amp; chmod a+x &#x2F;root&#x2F;.local&#x2F;bin&#x2F;kubectl</span><br><span class="line"></span><br><span class="line">FROM python:3-slim</span><br><span class="line">RUN DEBIAN_FRONTEND&#x3D;noninteractive apt-get update -y -qq \</span><br><span class="line">    &amp;&amp; apt-get install -y -qq --no-install-recommends \</span><br><span class="line">        ca-certificates libssl-dev openssh-client sshpass curl gnupg2 rsync \</span><br><span class="line">        jq moreutils vim iputils-ping wget tcpdump xz-utils \</span><br><span class="line">    &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</span><br><span class="line"></span><br><span class="line">COPY --from&#x3D;builder &#x2F;root&#x2F;.local &#x2F;usr&#x2F;local</span><br><span class="line">WORKDIR &#x2F;kubespray</span><br></pre></td></tr></table></figure><ul><li><a href="https://blog.k8s.li/pass-tob-k8s-offline-deploy.html?utm_source=pocket_mylist" target="_blank" rel="noopener">kubespray 镜像</a></li></ul><p>FROM 的 base 镜像就使用我们刚刚构建好的镜像，相关依赖已经在 base 镜像中安装好了，这里构建的时候只需要把 repo 源码复制到 /kubespray 目录下即可，内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ARG BASE_IMAGE&#x3D;ghcr.io&#x2F;k8sli&#x2F;kubespray-base</span><br><span class="line">ARG BASE_IMAGE_VERSION&#x3D;latest</span><br><span class="line">FROM $BASE_IMAGE:$BASE_IMAGE_VERSION</span><br><span class="line">WORKDIR &#x2F;kubespray</span><br><span class="line">COPY . .</span><br></pre></td></tr></table></figure><ul><li>kubespray 集群部署入口 <code>run.sh</code></li></ul><p>将集群部署、增加节点、删除节点、删除集群等操作封装成一个入口的脚本，提供外部工具调用该脚本，不然外部调用的时候直接运行 <code>ansible-playbook</code> 命令实在是不太方便。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">TYPE&#x3D;$1</span><br><span class="line">NODES&#x3D;$2</span><br><span class="line"></span><br><span class="line">KUBE_ROOT&#x3D;&quot;$(cd &quot;$(dirname &quot;$0&quot;)&quot; &amp;&amp; pwd)&quot;</span><br><span class="line"></span><br><span class="line">: $&#123;TYPE:&#x3D;deploy-cluster&#125;</span><br><span class="line">: $&#123;ANSIBLE_FORKS:&#x3D;10&#125;</span><br><span class="line">: $&#123;BECOME_USER:&#x3D;root&#125;</span><br><span class="line">: $&#123;ANSIBLE_LOG_FORMAT:&#x3D;yaml&#125;</span><br><span class="line">: $&#123;INVENTORY:&#x3D;$&#123;KUBE_ROOT&#125;&#x2F;config&#x2F;inventory&#125;</span><br><span class="line">: $&#123;ENV_FILE:&#x3D;$&#123;KUBE_ROOT&#125;&#x2F;config&#x2F;env.yml&#125;</span><br><span class="line">: $&#123;INSTALL_STEPS_FILE:&#x3D;$&#123;KUBE_ROOT&#125;&#x2F;config&#x2F;.install_steps&#125;</span><br><span class="line"></span><br><span class="line">export ANSIBLE_STDOUT_CALLBACK&#x3D;$&#123;ANSIBLE_LOG_FORMAT&#125;</span><br><span class="line">export ANSIBLE_ARGS&#x3D;&quot;-f $&#123;ANSIBLE_FORKS&#125; --become --become-user&#x3D;$&#123;BECOME_USER&#125; -i $&#123;INVENTORY&#125; -e @$&#123;ENV_FILE&#125;&quot;</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Set logging colors</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">NORMAL_COL&#x3D;$(tput sgr0)</span><br><span class="line">RED_COL&#x3D;$(tput setaf 1)</span><br><span class="line">WHITE_COL&#x3D;$(tput setaf 7)</span><br><span class="line">GREEN_COL&#x3D;$(tput setaf 76)</span><br><span class="line">YELLOW_COL&#x3D;$(tput setaf 202)</span><br><span class="line"></span><br><span class="line">debuglog()&#123; printf &quot;$&#123;WHITE_COL&#125;%s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line">infolog()&#123; printf &quot;$&#123;GREEN_COL&#125;✔ %s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line">warnlog()&#123; printf &quot;$&#123;YELLOW_COL&#125;➜ %s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line">errorlog()&#123; printf &quot;$&#123;RED_COL&#125;✖ %s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line"></span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">if [[ ! -f $&#123;INVENTORY&#125; ]]; then</span><br><span class="line">  errorlog &quot;$&#123;INVENTORY&#125; file is missing, please check the inventory file is exists&quot;</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">deploy_cluster()&#123;</span><br><span class="line">:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">  case $TYPE in</span><br><span class="line">    deploy-cluster)</span><br><span class="line">      infolog &quot;######  start deploy kubernetes cluster  ######&quot;</span><br><span class="line">      deploy_cluster</span><br><span class="line">      infolog &quot;######  kubernetes cluster successfully installed  ######&quot;</span><br><span class="line">      ;;</span><br><span class="line">    remove-cluster)</span><br><span class="line">      infolog &quot;######  start remove kubernetes cluster  ######&quot;</span><br><span class="line">      if ansible-playbook $&#123;ANSIBLE_ARGS&#125; $&#123;KUBE_ROOT&#125;&#x2F;reset.yml &gt;&#x2F;dev&#x2F;stdout 2&gt;&#x2F;dev&#x2F;stderr; then</span><br><span class="line">        rm -f $&#123;INSTALL_STEP_FILE&#125;</span><br><span class="line">        infolog &quot;######  kubernetes cluster successfully removed ######&quot;</span><br><span class="line">      fi</span><br><span class="line">      ;;</span><br><span class="line">    add-node)</span><br><span class="line">      check_nodename</span><br><span class="line">      infolog &quot;######  start add worker to kubernetes cluster  ######&quot;</span><br><span class="line">      ansible-playbook $&#123;ANSIBLE_ARGS&#125; --limit&#x3D;&quot;$&#123;NODES&#125;&quot; $&#123;KUBE_ROOT&#125;&#x2F;playbooks&#x2F;10-scale-nodes.yml &gt;&#x2F;dev&#x2F;stdout 2&gt;&#x2F;dev&#x2F;stderr</span><br><span class="line">      ;;</span><br><span class="line">    remove-node)</span><br><span class="line">      check_nodename</span><br><span class="line">      infolog &quot;######  start remove worker from kubernetes cluster  ######&quot;</span><br><span class="line">      ansible-playbook $&#123;ANSIBLE_ARGS&#125; -e node&#x3D;&quot;$&#123;NODES&#125;&quot; -e reset_nodes&#x3D;true $&#123;KUBE_ROOT&#125;&#x2F;remove-node.yml &gt;&#x2F;dev&#x2F;stdout 2&gt;&#x2F;dev&#x2F;stderr</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      errorlog &quot;unknow [TYPE] parameter: $&#123;TYPE&#125;&quot;</span><br><span class="line">      ;;</span><br><span class="line">  esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main &quot;$@&quot;</span><br></pre></td></tr></table></figure><ul><li>分层部署 <a href="https://github.com/k8sli/kubespray/tree/main/playbooks" target="_blank" rel="noopener">playbooks</a></li></ul><p>不同于 kubespray 官方使用一个完整的 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/cluster.yml" target="_blank" rel="noopener">cluster.yaml</a> 来完成整个 K8s 集群的部署，我们在这里引入了分层部署的特性。即将集群部署分成若干个相互独立的 playbook，然后在各个 playbook 里引入我们增加的 roles 以及二开内容。这样的好处就是能和 kubespray 上游的代码保持相互独立，在 rebase 或者 cherry-pick 上游最新的代码能够避免出现冲突的现象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">playbooks</span><br><span class="line">├── 00-default-ssh-config.yml    # 配置 ssh 连接</span><br><span class="line">├── 01-cluster-bootstrap-os.yml  # 初始化集群节点</span><br><span class="line">├── 02-cluster-etcd.yml          # 部署 etcd 集群</span><br><span class="line">├── 03-cluster-kubernetes.yml    # 部署 k8s master 和 node</span><br><span class="line">├── 04-cluster-network.yml       # 部署 CNI 插件</span><br><span class="line">├── 05-cluster-apps.yml          # 部署一些 addon 组件如 coredns</span><br><span class="line">└── 10-scale-nodes.yml           # 增删节点</span><br></pre></td></tr></table></figure><p>分层部署的时候通过一个文件来记录已经部署成功的步骤，这样如果本次因为一些原因导致部署失败（如网络中断），那么下次重新部署的时候会跳过已经部署好的步骤，从失败的地方继续部署，以提升整体的部署效率。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">deploy_cluster()&#123;</span><br><span class="line">  touch $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">  STEPS&#x3D;&quot;00-default-ssh-config 01-cluster-bootstrap-os 02-cluster-etcd 03-cluster-kubernetes 04-cluster-network 05-cluster-apps&quot;</span><br><span class="line">  for step in $&#123;STEPS&#125;; do</span><br><span class="line">    if ! grep -q &quot;$&#123;step&#125;&quot; $&#123;INSTALL_STEPS_FILE&#125;; then</span><br><span class="line">      infolog &quot;start deploy $&#123;step&#125;&quot;</span><br><span class="line">      if ansible-playbook $&#123;ANSIBLE_ARGS&#125; $&#123;KUBE_ROOT&#125;&#x2F;playbooks&#x2F;$&#123;step&#125;.yml; then</span><br><span class="line">        echo $&#123;step&#125; &gt;&gt; $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">        infolog &quot;$&#123;step&#125; successfully installed&quot;</span><br><span class="line">      else</span><br><span class="line">        errorlog &quot;$&#123;step&#125; installation failed&quot;</span><br><span class="line">        exit 1</span><br><span class="line">      fi</span><br><span class="line">    else</span><br><span class="line">      warnlog &quot;$&#123;step&#125; is already installed, so skipped...&quot;</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="文件和镜像">文件和镜像</span></h3><p>我们需要提取出 kubespray 部署的时候依赖的文件和镜像，生成一个文件列表和镜像列表，然后根据这些列表下载并构建到一个镜像里。</p><ul><li>文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Download URLs</span><br><span class="line">kubelet_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubelet&quot;</span><br><span class="line">kubectl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubectl&quot;</span><br><span class="line">kubeadm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubeadm&quot;</span><br><span class="line">etcd_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;&#123;&#123; etcd_version &#125;&#125;&#x2F;etcd-&#123;&#123; etcd_version &#125;&#125;-linux-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">cni_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;containernetworking&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;&#123;&#123; cni_version &#125;&#125;&#x2F;cni-plugins-linux-&#123;&#123; image_arch &#125;&#125;-&#123;&#123; cni_version &#125;&#125;.tgz&quot;</span><br><span class="line">calicoctl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;projectcalico&#x2F;calicoctl&#x2F;releases&#x2F;download&#x2F;&#123;&#123; calico_ctl_version &#125;&#125;&#x2F;calicoctl-linux-&#123;&#123; image_arch &#125;&#125;&quot;</span><br><span class="line">calico_crds_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;projectcalico&#x2F;calico&#x2F;archive&#x2F;&#123;&#123; calico_version &#125;&#125;.tar.gz&quot;</span><br><span class="line">crictl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;cri-tools&#x2F;releases&#x2F;download&#x2F;&#123;&#123; crictl_version &#125;&#125;&#x2F;crictl-&#123;&#123; crictl_version &#125;&#125;-&#123;&#123; ansible_system | lower &#125;&#125;-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">helm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;get.helm.sh&#x2F;helm-&#123;&#123; helm_version &#125;&#125;-linux-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">nerdctl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;containerd&#x2F;nerdctl&#x2F;releases&#x2F;download&#x2F;v&#123;&#123; nerdctl_version &#125;&#125;&#x2F;nerdctl-&#123;&#123; nerdctl_version &#125;&#125;-&#123;&#123; ansible_system | lower &#125;&#125;-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">patched_kubeadm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;k8sli&#x2F;kubernetes&#x2F;releases&#x2F;download&#x2F;&#123;&#123; kubeadm_patch_version &#125;&#125;&#x2F;kubeadm-linux-&#123;&#123; image_arch &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><p>在构建安装包的时候，将 download_url 变量设置为 <code>https://</code> ，在部署的时候将 <code>download_url</code> 设置为内网 文件服务器服务器的 URL，比如 <code>https://172.20.0.25:8080/files</code>，这样就可以实现文件构建和部署使用的统一，节省维护成本。</p><ul><li>镜像</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># Define image repo and tag overwrite role&#x2F;download&#x2F;default&#x2F;main.yml</span><br><span class="line">pod_infra_image_tag: &quot;&#123;&#123; pod_infra_version &#125;&#125;&quot;</span><br><span class="line">pod_infra_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;pause&quot;</span><br><span class="line"></span><br><span class="line">kube_proxy_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-proxy&quot;</span><br><span class="line">kube_apiserver_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-apiserver&quot;</span><br><span class="line">kube_scheduler_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-scheduler&quot;</span><br><span class="line">kube_controller_manager_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-controller-manager&quot;</span><br><span class="line"></span><br><span class="line">coredns_image_tag: &quot;&#123;&#123; coredns_version &#125;&#125;&quot;</span><br><span class="line">dnsautoscaler_image_tag: &quot;&#123;&#123; dnsautoscaler_version &#125;&#125;&quot;</span><br><span class="line">coredns_image_repo: &quot;&#123;&#123; docker_image_repo &#125;&#125;&#x2F;coredns&quot;</span><br><span class="line">dnsautoscaler_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;cluster-proportional-autoscaler-&#123;&#123; image_arch &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line"># Full image name for generate images list</span><br><span class="line">kube_proxy_image_name: &quot;&#123;&#123; kube_proxy_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">kube_apiserver_image_name: &quot;&#123;&#123; kube_apiserver_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">kube_scheduler_image_name: &quot;&#123;&#123; kube_scheduler_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">kube_controller_manager_image_name: &quot;&#123;&#123; kube_controller_manager_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">coredns_image_name: &quot;&#123;&#123; coredns_image_repo &#125;&#125;:&#123;&#123; coredns_image_tag &#125;&#125;&quot;</span><br><span class="line">dnsautoscaler_image_name: &quot;&#123;&#123; dnsautoscaler_image_repo &#125;&#125;:&#123;&#123; dnsautoscaler_image_tag &#125;&#125;&quot;</span><br><span class="line">nginx_image_name: &quot;&#123;&#123; nginx_image_repo &#125;&#125;:&#123;&#123; nginx_image_tag &#125;&#125;&quot;</span><br><span class="line">pod_infra_image_name: &quot;&#123;&#123; pod_infra_image_repo &#125;&#125;:&#123;&#123; pod_infra_image_tag &#125;&#125;&quot;</span><br><span class="line">calico_policy_image_name: &quot;&#123;&#123; calico_policy_image_repo &#125;&#125;:&#123;&#123; calico_policy_image_tag &#125;&#125;&quot;</span><br><span class="line">calico_cni_image_name: &quot;&#123;&#123; calico_cni_image_repo &#125;&#125;:&#123;&#123; calico_cni_image_tag &#125;&#125;&quot;</span><br><span class="line">calico_node_image_name: &quot;&#123;&#123; calico_node_image_repo &#125;&#125;:&#123;&#123; calico_node_image_tag &#125;&#125;&quot;</span><br><span class="line">flannel_image_name: &quot;&#123;&#123; flannel_image_repo &#125;&#125;:&#123;&#123; flannel_image_tag &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><ul><li><code>generate.sh</code> 列表生成脚本</li></ul><p>我们根据上面 group_vars 中定义的版本号和一些参数，使用脚本的方式自动生成一个文件列表和镜像列表，构建的时候根据这些列表来下载所需要的文件和镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">SCRIPT_PATH&#x3D;$(cd $(dirname $0); pwd)</span><br><span class="line">REPO_PATH&#x3D;&quot;$&#123;SCRIPT_PATH%&#x2F;build&#125;&quot;</span><br><span class="line"></span><br><span class="line">: $&#123;IMAGE_ARCH:&#x3D;&quot;amd64&quot;&#125;</span><br><span class="line">: $&#123;ANSIBLE_ARCHITECTURE:&#x3D;&quot;x86_64&quot;&#125;</span><br><span class="line">: $&#123;DOWNLOAD_YML:&#x3D;&quot;config&#x2F;group_vars&#x2F;all&#x2F;download.yml&quot;&#125;</span><br><span class="line"></span><br><span class="line"># ARCH used in convert &#123;%- if image_arch !&#x3D; &#39;amd64&#39; -%&#125;-&#123;&#123; image_arch &#125;&#125;&#123;%- endif -%&#125; to &#123;&#123;arch&#125;&#125;</span><br><span class="line">if [[ &quot;$&#123;IMAGE_ARCH&#125;&quot; !&#x3D; &quot;amd64&quot; ]]; then ARCH&#x3D;&quot;-$&#123;IMAGE_ARCH&#125;&quot;; fi</span><br><span class="line"></span><br><span class="line">cat &gt; &#x2F;tmp&#x2F;generate.sh &lt;&lt; EOF</span><br><span class="line">arch&#x3D;$&#123;ARCH&#125;</span><br><span class="line">download_url&#x3D;https:&#x2F;</span><br><span class="line">image_arch&#x3D;$&#123;IMAGE_ARCH&#125;</span><br><span class="line">ansible_system&#x3D;linux</span><br><span class="line">ansible_architecture&#x3D;$&#123;ANSIBLE_ARCHITECTURE&#125;</span><br><span class="line">registry_project&#x3D;library</span><br><span class="line">registry_domain&#x3D;localhost</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># generate all component version by $DOWNLOAD_YML</span><br><span class="line">grep &#39;_version:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| sed &#39;s&#x2F;: &#x2F;&#x3D;&#x2F;g;s&#x2F;&#123;&#123;&#x2F;$&#123;&#x2F;g;s&#x2F;&#125;&#125;&#x2F;&#125;&#x2F;g&#39; | tr -d &#39; &#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br><span class="line"></span><br><span class="line"># generate download files url list</span><br><span class="line">grep &#39;_download_url:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| sed &#39;s&#x2F;: &#x2F;&#x3D;&#x2F;g;s&#x2F; &#x2F;&#x2F;g;s&#x2F;&#123;&#123;&#x2F;$&#123;&#x2F;g;s&#x2F;&#125;&#125;&#x2F;&#125;&#x2F;g;s&#x2F;|lower&#x2F;&#x2F;g;s&#x2F;^.*_url&#x3D;&#x2F;echo &#x2F;g&#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br><span class="line"></span><br><span class="line"># generate download images list</span><br><span class="line">grep -E &#39;_image_tag:|_image_repo:|_image_name:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| sed &quot;s#&#123;%- if image_arch !&#x3D; &#39;amd64&#39; -%&#125;-&#123;&#123; image_arch &#125;&#125;&#123;%- endif -%&#125;#&#123;&#123;arch&#125;&#125;#g&quot; \</span><br><span class="line">| sed &#39;s&#x2F;: &#x2F;&#x3D;&#x2F;g;s&#x2F;&#123;&#123;&#x2F;$&#123;&#x2F;g;s&#x2F;&#125;&#125;&#x2F;&#125;&#x2F;g&#39; | tr -d &#39; &#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br><span class="line"></span><br><span class="line">grep &#39;_image_name:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| cut -d &#39;:&#39; -f1 | sed &#39;s&#x2F;^&#x2F;echo $&#x2F;g&#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br></pre></td></tr></table></figure><p>为了同时支持 amd64 和 arm64 的 CPU 架构，需要为两种架构各自生成列表，需要特殊处理一下。在这里踩的一个坑就是不同的组件镜像的命名方法千差万别，大致可以分为如下四种情况：</p><ul><li>像 kube-apiserver 这些 k8s 组件的镜像，镜像名称和镜像 tag 是不需要加上 CPU 体系架构的；</li><li>cluster-proportional-autoscaler 的镜像则是在镜像的名称后面加上了 CPU 体系架构的名称如 cluster-proportional-autoscaler-amd64，cluster-proportional-autoscaler-arm64；</li><li>flannel 则是将 CPU 体系架构名称定义在镜像 tag 后面比如 <code>flannel:v0.14.0-amd64</code>；</li><li>还有 calico 更奇葩，amd64 架构的镜像不需要加体系架构的名称如 <code>calico/cni:v3.18.4</code>，而 arm64 的则必须要在镜像 tag 后面带上 CPU 体系架构比如 <code>calico/cni:v3.18.4-arm64</code>；</li></ul><p>在这里需要强调一下，文件列表和镜像列表一定要使用自动化的方式来管理，切勿手动更新，这样能节省大量的维护成本，不然的话每次都手动去更新这些列表成本实在是太高了，而且特别容易出出错或者遗漏某个组件。</p><h3><span id="kubespray-files">kubespray-files</span></h3><p>我们将 kubespray 部署所依赖的二进制文件构建在一个名为 kubespray-files 的镜像当中：</p><ul><li>生成的文件列表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;get.helm.sh&#x2F;helm-v3.6.3-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;containerd&#x2F;nerdctl&#x2F;releases&#x2F;download&#x2F;v0.8.1&#x2F;nerdctl-0.8.1-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;containernetworking&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;v0.9.1&#x2F;cni-plugins-linux-amd64-v0.9.1.tgz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;v3.4.13&#x2F;etcd-v3.4.13-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;kubernetes&#x2F;releases&#x2F;download&#x2F;v1.21.3-patch-1.0&#x2F;kubeadm-linux-amd64</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;cri-tools&#x2F;releases&#x2F;download&#x2F;v1.21.0&#x2F;crictl-v1.21.0-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;projectcalico&#x2F;calico&#x2F;archive&#x2F;v3.18.4.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;projectcalico&#x2F;calicoctl&#x2F;releases&#x2F;download&#x2F;v3.18.4&#x2F;calicoctl-linux-amd64</span><br><span class="line">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;v1.21.3&#x2F;bin&#x2F;linux&#x2F;amd64&#x2F;kubeadm</span><br><span class="line">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;v1.21.3&#x2F;bin&#x2F;linux&#x2F;amd64&#x2F;kubectl</span><br><span class="line">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;v1.21.3&#x2F;bin&#x2F;linux&#x2F;amd64&#x2F;kubelet</span><br></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest as files</span><br><span class="line">RUN apk --no-cache add wget ca-certificates</span><br><span class="line">WORKDIR &#x2F;build</span><br><span class="line">COPY build&#x2F;kubespray-files&#x2F;files_*.list &#x2F;build&#x2F;</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; sed &#39;&#x2F;#&#x2F;d&#39; *$&#123;ARCH&#125;.list &gt; all_files.list \</span><br><span class="line">    &amp;&amp; wget -q -x -P &#x2F;files -i all_files.list</span><br><span class="line"></span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;files &#x2F;files &#x2F;files</span><br></pre></td></tr></table></figure><ul><li>构建后的目录结构，通过目录层级的方式保留原有的 URL 地址，维护和使用起来比较方便</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">files&#x2F;</span><br><span class="line">├── get.helm.sh</span><br><span class="line">│   └── helm-v3.6.3-linux-amd64.tar.gz</span><br><span class="line">├── github.com</span><br><span class="line">│   ├── containerd</span><br><span class="line">│   │   └── nerdctl</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v0.8.1</span><br><span class="line">│   │                   └── nerdctl-0.8.1-linux-amd64.tar.gz</span><br><span class="line">│   ├── containernetworking</span><br><span class="line">│   │   └── plugins</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v0.9.1</span><br><span class="line">│   │                   └── cni-plugins-linux-amd64-v0.9.1.tgz</span><br><span class="line">│   ├── coreos</span><br><span class="line">│   │   └── etcd</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v3.4.13</span><br><span class="line">│   │                   └── etcd-v3.4.13-linux-amd64.tar.gz</span><br><span class="line">│   ├── k8sli</span><br><span class="line">│   │   └── kubernetes</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v1.21.3-patch-1.0</span><br><span class="line">│   │                   └── kubeadm-linux-amd64</span><br><span class="line">│   ├── kubernetes-sigs</span><br><span class="line">│   │   └── cri-tools</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v1.21.0</span><br><span class="line">│   │                   └── crictl-v1.21.0-linux-amd64.tar.gz</span><br><span class="line">│   └── projectcalico</span><br><span class="line">│       ├── calico</span><br><span class="line">│       │   └── archive</span><br><span class="line">│       │       └── v3.18.4.tar.gz</span><br><span class="line">│       └── calicoctl</span><br><span class="line">│           └── releases</span><br><span class="line">│               └── download</span><br><span class="line">│                   └── v3.18.4</span><br><span class="line">│                       └── calicoctl-linux-amd64</span><br><span class="line">└── storage.googleapis.com</span><br><span class="line">    └── kubernetes-release</span><br><span class="line">        └── release</span><br><span class="line">            └── v1.21.3</span><br><span class="line">                └── bin</span><br><span class="line">                    └── linux</span><br><span class="line">                        └── amd64</span><br><span class="line">                            ├── kubeadm</span><br><span class="line">                            ├── kubectl</span><br><span class="line">                            └── kubelet</span><br></pre></td></tr></table></figure><h3><span id="kubespray-images">kubespray-images</span></h3><p>我们同样将 kubespray 部署所需要的组件镜像构建在一个名为 kubespray-images 的镜像当中：</p><ul><li>镜像列表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">library&#x2F;calico-cni:v3.18.4</span><br><span class="line">library&#x2F;calico-kube-controllers:v3.18.4</span><br><span class="line">library&#x2F;calico-node:v3.18.4</span><br><span class="line">library&#x2F;calico-pod2daemon-flexvol:v3.18.4</span><br><span class="line">library&#x2F;cluster-proportional-autoscaler-amd64:1.8.3</span><br><span class="line">library&#x2F;coredns:v1.8.0</span><br><span class="line">library&#x2F;flannel:v0.14.0-amd64</span><br><span class="line">library&#x2F;kube-apiserver:v1.21.3</span><br><span class="line">library&#x2F;kube-controller-manager:v1.21.3</span><br><span class="line">library&#x2F;kube-proxy:v1.21.3</span><br><span class="line">library&#x2F;kube-scheduler:v1.21.3</span><br><span class="line">library&#x2F;nginx:1.19</span><br><span class="line">library&#x2F;pause:3.3</span><br></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><p>在 Dockerfile 里完成所有镜像的下载，并使用 《<a href="https://blog.k8s.li/skopeo-to-registry.html" target="_blank" rel="noopener">如何使用 registry 存储的特性</a>》文中提到的骚操作，利用 registry 存储复用相同 layer 的特性，将 skopeo sync 下载的镜像转换成 registry 存储的结构。这样在部署的时候直接把这个 registry 存储目录挂载进 registry 容器的 <code>/var/lib/registry</code> 即可。特点是性能方面无论是构建和部署，都比常规使用 docker save 和 docker load 的方式要快至少 5 到 10 倍。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:3.12 as images</span><br><span class="line">ARG SKOPEO_VERSION&#x3D;v1.4.0</span><br><span class="line">ARG YQ_VERSION&#x3D;v4.11.2</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; apk --no-cache add bash wget ca-certificates \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;mikefarah&#x2F;yq&#x2F;releases&#x2F;download&#x2F;$&#123;YQ_VERSION&#125;&#x2F;yq_linux_$&#123;ARCH&#125; -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;yq \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;skopeo&#x2F;releases&#x2F;download&#x2F;$&#123;SKOPEO_VERSION&#125;&#x2F;skopeo-linux-$&#123;ARCH&#125; -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;skopeo \</span><br><span class="line">    &amp;&amp; chmod a+x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;*</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;build</span><br><span class="line">COPY build&#x2F;kubespray-images&#x2F;*  &#x2F;build&#x2F;</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; IMAGE_ARCH&#x3D;$&#123;ARCH&#125; bash build.sh</span><br><span class="line"></span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;images &#x2F;build&#x2F;docker &#x2F;docker</span><br></pre></td></tr></table></figure><ul><li>images_origin.yaml 镜像配置文件</li></ul><p>考虑到有将镜像导入到已经存在的镜像仓库中的场景，这里我们需要修改一下镜像仓库的 repo。因为 <code>library</code> 这个 repo 在 harbor 中是默认自带的，在导入到 harbor 的过程中也不需要创建一些额外的 project ，所以将所有镜像的 repo 全部统一为 <code>library</code> 更通用一些。</p><p>这里用一个 yaml 配置文件来记录原镜像地址和 library 镜像的地址的对应关系。比如上游的 <code>k8s.gcr.io/kube-apiserver</code> 映射为 <code>library/kube-apiserver</code>， <code>quay.io/calico/node</code> 映射为 <code>library/calico-node</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line"># kubeadm core images</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-apiserver</span><br><span class="line">  dest: library&#x2F;kube-apiserver</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-controller-manager</span><br><span class="line">  dest: library&#x2F;kube-controller-manager</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-proxy</span><br><span class="line">  dest: library&#x2F;kube-proxy</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-scheduler</span><br><span class="line">  dest: library&#x2F;kube-scheduler</span><br><span class="line">- src: k8s.gcr.io&#x2F;coredns&#x2F;coredns</span><br><span class="line">  dest: library&#x2F;coredns</span><br><span class="line">- src: k8s.gcr.io&#x2F;pause</span><br><span class="line">  dest: library&#x2F;pause</span><br><span class="line"></span><br><span class="line"># kubernetes addons</span><br><span class="line">- src: k8s.gcr.io&#x2F;dns&#x2F;k8s-dns-node-cache</span><br><span class="line">  dest: library&#x2F;k8s-dns-node-cache</span><br><span class="line">- src: k8s.gcr.io&#x2F;cpa&#x2F;cluster-proportional-autoscaler-amd64</span><br><span class="line">  dest: library&#x2F;cluster-proportional-autoscaler-amd64</span><br><span class="line">- src: k8s.gcr.io&#x2F;cpa&#x2F;cluster-proportional-autoscaler-arm64</span><br><span class="line">  dest: library&#x2F;cluster-proportional-autoscaler-arm64</span><br><span class="line"></span><br><span class="line"># network plugin</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;cni</span><br><span class="line">  dest: library&#x2F;calico-cni</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;node</span><br><span class="line">  dest: library&#x2F;calico-node</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;kube-controllers</span><br><span class="line">  dest: library&#x2F;calico-kube-controllers</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;pod2daemon-flexvol</span><br><span class="line">  dest: library&#x2F;calico-pod2daemon-flexvol</span><br><span class="line"></span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;typha</span><br><span class="line">  dest: library&#x2F;calico-typha</span><br><span class="line">- src: quay.io&#x2F;coreos&#x2F;flannel</span><br><span class="line">  dest: library&#x2F;flannel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># nginx for daemonset and offline</span><br><span class="line">- src: docker.io&#x2F;library&#x2F;nginx</span><br><span class="line">  dest: library&#x2F;nginx</span><br></pre></td></tr></table></figure><h3><span id="kubeplay">kubeplay</span></h3><p>kubeplay 部署的代码主要是由一些 shell 脚本和配置文件构成，用于完成 nginx 服务和 registry 服务的部署，以及最后调用 kubespray 来完成集群部署。</p><blockquote><p>kubeplay 项目地址：<a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">https://github.com/k8sli/kubeplay</a></p></blockquote><ul><li>代码结构</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kubeplay&#x2F;</span><br><span class="line">├── Dockerfile          # 构建完整安装包的 Dockerfile</span><br><span class="line">├── compose.yaml        # compose 启动配置 yaml 文件</span><br><span class="line">├── config</span><br><span class="line">│   ├── compose</span><br><span class="line">│   │   └── nginx.conf  # nginx 配置文件</span><br><span class="line">│   └── rootCA.cnf      # 生成镜像仓库证书用到的 openssl 配置文件</span><br><span class="line">├── config-sample.yaml  # 主配置文件</span><br><span class="line">├── install.sh          # 安装操作然后</span><br><span class="line">└── library             # 一些 shell 函数库</span><br></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest as downloader</span><br><span class="line">ARG SKOPEO_VERSION&#x3D;v1.4.0</span><br><span class="line">ARG YQ_VERSION&#x3D;v4.11.2</span><br><span class="line">ARG NERDCTL_VERSION&#x3D;0.11.0</span><br><span class="line">ARG NGINX_VERSION&#x3D;1.20-alpine</span><br><span class="line">ARG RERGISRRY_VERSION&#x3D;2.7.1</span><br><span class="line">ARG KUBESPRAY_VERSION&#x3D;latest</span><br><span class="line">ARG KUBESPRAY_IMAGE&#x3D;ghcr.io&#x2F;k8sli&#x2F;kubespray</span><br><span class="line"></span><br><span class="line"># 下载部署时需要的工具，如 yq、skopeo、nerdctl-fullsss</span><br><span class="line">WORKDIR &#x2F;tools</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; apk --no-cache add wget ca-certificates \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;mikefarah&#x2F;yq&#x2F;releases&#x2F;download&#x2F;$&#123;YQ_VERSION&#125;&#x2F;yq_linux_$&#123;ARCH&#125;  -O &#x2F;tools&#x2F;yq-linux-$&#123;ARCH&#125; \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;skopeo&#x2F;releases&#x2F;download&#x2F;v1.4.0&#x2F;skopeo-linux-$&#123;ARCH&#125; -O &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;containerd&#x2F;nerdctl&#x2F;releases&#x2F;download&#x2F;v$&#123;NERDCTL_VERSION&#125;&#x2F;nerdctl-full-$&#123;NERDCTL_VERSION&#125;-linux-$&#123;ARCH&#125;.tar.gz \</span><br><span class="line">    &amp;&amp; chmod a+x &#x2F;tools&#x2F;* \</span><br><span class="line">    &amp;&amp; ln -s &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; &#x2F;usr&#x2F;bin&#x2F;skopeo</span><br><span class="line"></span><br><span class="line"># 下载一些镜像，如 nginx、registry、kubespray</span><br><span class="line">WORKDIR &#x2F;images</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag nginx:$&#123;NGINX_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;nginx:$&#123;NGINX_VERSION&#125; docker-archive:nginx-$&#123;NGINX_VERSION&#125;.tar \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag registry:$&#123;RERGISRRY_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;registry:$&#123;RERGISRRY_VERSION&#125; docker-archive:registry-$&#123;RERGISRRY_VERSION&#125;.tar \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag kubespray:$&#123;KUBESPRAY_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;$&#123;KUBESPRAY_IMAGE&#125;:$&#123;KUBESPRAY_VERSION&#125; docker-archive:kubespray-$&#123;KUBESPRAY_VERSION&#125;.tar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FROM scratch</span><br><span class="line">COPY . .</span><br><span class="line"> # 将其它模块中的内容复制到 scratch 镜像中，构建的时候导出为 local 方式</span><br><span class="line">COPY --from&#x3D;downloader &#x2F;tools &#x2F;resources&#x2F;nginx&#x2F;tools</span><br><span class="line">COPY --from&#x3D;downloader &#x2F;images &#x2F;resources&#x2F;images</span><br><span class="line">COPY --from&#x3D;$&#123;OS_PACKAGES_IMAGE&#125;:$&#123;OS_PACKAGE_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;nginx</span><br><span class="line">COPY --from&#x3D;$&#123;KUBESPRAY_FILES_IMAGE&#125;:$&#123;KUBESPRAY_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;nginx</span><br><span class="line">COPY --from&#x3D;$&#123;KUBESPRAY_IMAGES_IMAGE&#125;:$&#123;KUBESPRAY_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;registry</span><br></pre></td></tr></table></figure><h3><span id="构建">构建</span></h3><p>由于最终的构建涉及多个模块和 repo，其流程比较复杂，详细的代码可参考源码 <a href="https://github.com/k8sli/kubeplay/blob/main/.github/workflows/build.yaml" target="_blank" rel="noopener">build.yaml</a> ，在这里只讲几个关键的部分</p><ul><li>checkout repo，将 kubespray 和 os-packages repo clone 到工作目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  build-package:</span><br><span class="line">    # 以 tag 的事件触发构建流水线</span><br><span class="line">    if: startsWith(github.ref, &#39;refs&#x2F;tags&#x2F;&#39;)</span><br><span class="line">    runs-on: ubuntu-20.04</span><br><span class="line">    steps:</span><br><span class="line">      - name: Checkout</span><br><span class="line">        uses: actions&#x2F;checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          # fetch all git repo tag for define image tag</span><br><span class="line">          fetch-depth: 0</span><br><span class="line"></span><br><span class="line">      - name: Checkout kubespray repo</span><br><span class="line">        uses: actions&#x2F;checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          ref: main</span><br><span class="line">          fetch-depth: 0</span><br><span class="line">          path: kubespray</span><br><span class="line">          repository: $&#123;&#123; github.repository_owner &#125;&#125;&#x2F;kubespray</span><br><span class="line"></span><br><span class="line">      - name: Checkout os-packages repo</span><br><span class="line">        uses: actions&#x2F;checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          ref: main</span><br><span class="line">          fetch-depth: 0</span><br><span class="line">          path: os-packages</span><br><span class="line">          repository: $&#123;&#123; github.repository_owner &#125;&#125;&#x2F;os-packages</span><br></pre></td></tr></table></figure><ul><li>获取 kubespray 和 os-packages 的 repo tag，根据它来确定 os-packages, kubespray-files, kubespray-images 这个三个镜像的 tag，并生成一个 All in One 的 Dockerfile 用于完成后续安装包的构建。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 获取一些组件的版本和变量传递给 Dockerfile</span><br><span class="line">- name: Prepare for build images</span><br><span class="line">  shell: bash</span><br><span class="line">  run: |</span><br><span class="line">    git describe --tags --always | sed &#39;s&#x2F;^&#x2F;IMAGE_TAG&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line"></span><br><span class="line">    cd kubespray &amp;&amp; git describe --tags --always | sed &#39;s&#x2F;^&#x2F;KUBESPRAY_VERSION&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV &amp;&amp; cd ..</span><br><span class="line">    cd os-packages &amp;&amp; git describe --tags --always | sed &#39;s&#x2F;^&#x2F;OS_PACKAGE_REPO_TAG&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV &amp;&amp; cd ..</span><br><span class="line">    cp -rf kubespray&#x2F;config config&#x2F;kubespray &amp;&amp; rm -rf kubespray os-packages</span><br><span class="line"></span><br><span class="line">    source $GITHUB_ENV</span><br><span class="line">    echo &quot;&quot; &gt;&gt; Dockerfile</span><br><span class="line">    echo &quot;COPY --from&#x3D;$&#123;OS_PACKAGES_IMAGE&#125;:$&#123;OS_PACKAGE_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;nginx&quot; &gt;&gt; Dockerfile</span><br><span class="line">    echo &quot;COPY --from&#x3D;$&#123;KUBESPRAY_FILES_IMAGE&#125;:$&#123;KUBESPRAY_VERSION&#125; &#x2F; &#x2F;resources&#x2F;nginx&quot; &gt;&gt; Dockerfile</span><br><span class="line">    echo &quot;COPY --from&#x3D;$&#123;KUBESPRAY_IMAGES_IMAGE&#125;:$&#123;KUBESPRAY_VERSION&#125; &#x2F; &#x2F;resources&#x2F;registry&quot; &gt;&gt; Dockerfile</span><br><span class="line"></span><br><span class="line">    sed -n &#39;s|image: nginx:|NGINX_VERSION&#x3D;|p&#39; compose.yaml | tr -d &#39; &#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    sed -n &#39;s|image: registry:|RERGISRRY_VERSION&#x3D;|p&#39; compose.yaml | tr -d &#39; &#39; &gt;&gt; $GITHUB_ENV</span><br></pre></td></tr></table></figure><ul><li>使用 <code>outputs: type=local,dest=./</code> 构建镜像到本地目录而非 push 到 registry</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- name: Build kubeplay image to local</span><br><span class="line">  uses: docker&#x2F;build-push-action@v2</span><br><span class="line">  with:</span><br><span class="line">    context: .</span><br><span class="line">    file: Dockerfile</span><br><span class="line">    platforms: linux&#x2F;amd64,linux&#x2F;arm64</span><br><span class="line">    build-args: |</span><br><span class="line">      NGINX_VERSION&#x3D;$&#123;&#123; env.NGINX_VERSION &#125;&#125;</span><br><span class="line">      RERGISRRY_VERSION&#x3D;$&#123;&#123; env.RERGISRRY_VERSION &#125;&#125;</span><br><span class="line">      KUBESPRAY_IMAGE&#x3D;$&#123;&#123; env.KUBESPRAY_IMAGE &#125;&#125;</span><br><span class="line">      KUBESPRAY_VERSION&#x3D;$&#123;&#123; env.KUBESPRAY_VERSION &#125;&#125;</span><br><span class="line">    outputs: type&#x3D;local,dest&#x3D;.&#x2F;</span><br></pre></td></tr></table></figure><ul><li>打包并上传安装包到 GitHub release 存储</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">- name: Prepare for upload package</span><br><span class="line">  shell: bash</span><br><span class="line">  run: |</span><br><span class="line">    rm -rf linux_&#123;amd64,arm64&#125;&#x2F;&#123;Dockerfile,LICENSE&#125;</span><br><span class="line">    mv linux_amd64 kubeplay</span><br><span class="line">    tar -I pigz -cf kubeplay-$&#123;IMAGE_TAG&#125;-linux-amd64.tar.gz kubeplay --remove-files</span><br><span class="line">    mv linux_arm64 kubeplay</span><br><span class="line">    tar -I pigz -cf kubeplay-$&#123;IMAGE_TAG&#125;-linux-arm64.tar.gz kubeplay --remove-files</span><br><span class="line">    sha256sum kubeplay-$&#123;IMAGE_TAG&#125;-linux-&#123;amd64,arm64&#125;.tar.gz &gt; sha256sum.txt</span><br><span class="line"></span><br><span class="line">- name: Release and upload packages</span><br><span class="line">  uses: softprops&#x2F;action-gh-release@v1</span><br><span class="line">  env:</span><br><span class="line">    GITHUB_TOKEN: $&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125;</span><br><span class="line">  with:</span><br><span class="line">    files: |</span><br><span class="line">      sha256sum.txt</span><br><span class="line">      kubeplay-$&#123;&#123; env.IMAGE_TAG &#125;&#125;-linux-amd64.tar.gz</span><br><span class="line">      kubeplay-$&#123;&#123; env.IMAGE_TAG &#125;&#125;-linux-arm64.tar.gz</span><br></pre></td></tr></table></figure><p>由此一个完整的离线安装包就构建完成了，接下来再讲一下安装流程</p><h2><span id="安装流程">安装流程</span></h2><p>在 <a href="https://github.com/k8sli/kubeplay/releases" target="_blank" rel="noopener">GitHub release 页面</a> 将我们的离线安装包下载到本地，需要根据 CPU 架构的类型选择相应的安装包。</p><p><img src="https://p.k8s.li/2021-08-24-offline-deploy-k8s-1.png" alt></p><p>下载完成之后再将安装包通过 scp 或者其他方式上传到内网的部署节点上，部署的文档可参考 <a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">README</a> 。过程十分简单：只需要填写好 <code>config.yaml</code> 配置文件然后执行 <code>bash install.sh</code> 即可完成 K8s 集群的一键部署。</p><p>下面从源码而非 README 文档的角度来讲一下部署流程的实现细节</p><h3><span id="安装包结构">安装包结构</span></h3><ul><li>配置文件 <code>config.yaml</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"># nginx 端口和 registry 域名配置参数</span><br><span class="line">compose:</span><br><span class="line">  # Compose bootstrap node ip, default is local internal ip</span><br><span class="line">  internal_ip: 172.20.0.25</span><br><span class="line">  # Nginx http server bind port for download files and packages</span><br><span class="line">  nginx_http_port: 8080</span><br><span class="line">  # Registry domain for CRI runtime download images</span><br><span class="line">  registry_domain: kube.registry.local</span><br><span class="line"></span><br><span class="line"># kubespray 参数</span><br><span class="line">kubespray:</span><br><span class="line">  # Kubernetes version by default, only support v1.20.6</span><br><span class="line">  kube_version: v1.21.3</span><br><span class="line">  # For deploy HA cluster you must configure a external apiserver access ip</span><br><span class="line">  external_apiserver_access_ip: 127.0.0.1</span><br><span class="line">  # Set network plugin to calico with vxlan mode by default</span><br><span class="line">  kube_network_plugin: calico</span><br><span class="line">  #Container runtime, only support containerd if offline deploy</span><br><span class="line">  container_manager: containerd</span><br><span class="line">  # Now only support host if use containerd as CRI runtime</span><br><span class="line">  etcd_deployment_type: host</span><br><span class="line">  # Settings for etcd event server</span><br><span class="line">  etcd_events_cluster_setup: true</span><br><span class="line">  etcd_events_cluster_enabled: true</span><br><span class="line"></span><br><span class="line"># 集群节点 ssh 登录 inventory 配置</span><br><span class="line"># Cluster nodes inventory info</span><br><span class="line">inventory:</span><br><span class="line">  all:</span><br><span class="line">    vars:</span><br><span class="line">      ansible_port: 22</span><br><span class="line">      ansible_user: root</span><br><span class="line">      ansible_ssh_pass: Password</span><br><span class="line">      # ansible_ssh_private_key_file: &#x2F;kubespray&#x2F;config&#x2F;id_rsa</span><br><span class="line">    hosts:</span><br><span class="line">      node1:</span><br><span class="line">        ansible_host: 172.20.0.21</span><br><span class="line">      node2:</span><br><span class="line">        ansible_host: 172.20.0.22</span><br><span class="line">      node3:</span><br><span class="line">        ansible_host: 172.20.0.23</span><br><span class="line">      node4:</span><br><span class="line">        ansible_host: 172.20.0.24</span><br><span class="line">    children:</span><br><span class="line">      kube_control_plane:</span><br><span class="line">        hosts:</span><br><span class="line">          node1:</span><br><span class="line">          node2:</span><br><span class="line">          node3:</span><br><span class="line">      kube_node:</span><br><span class="line">        hosts:</span><br><span class="line">          node1:</span><br><span class="line">          node2:</span><br><span class="line">          node3:</span><br><span class="line">          node4:</span><br><span class="line">      etcd:</span><br><span class="line">        hosts:</span><br><span class="line">          node1:</span><br><span class="line">          node2:</span><br><span class="line">          node3:</span><br><span class="line">      k8s_cluster:</span><br><span class="line">        children:</span><br><span class="line">          kube_control_plane:</span><br><span class="line">          kube_node:</span><br><span class="line">      gpu:</span><br><span class="line">        hosts: &#123;&#125;</span><br><span class="line">      calico_rr:</span><br><span class="line">        hosts: &#123;&#125;</span><br><span class="line"></span><br><span class="line"># 一些默认的配置，一般情况下无需修改</span><br><span class="line">### Default parameters ###</span><br><span class="line">## This filed not need config, will auto update,</span><br><span class="line">## if no special requirement, do not modify these parameters.</span><br><span class="line">default:</span><br><span class="line">  # NTP server ip address or domain, default is internal_ip</span><br><span class="line">  ntp_server:</span><br><span class="line">    - internal_ip</span><br><span class="line">  # Registry ip address, default is internal_ip</span><br><span class="line">  registry_ip: internal_ip</span><br><span class="line">  # Offline resource url for download files, default is internal_ip:nginx_http_port</span><br><span class="line">  offline_resources_url: internal_ip:nginx_http_port</span><br><span class="line">  # Use nginx and registry provide all offline resources</span><br><span class="line">  offline_resources_enabled: true</span><br><span class="line">  # Image repo in registry</span><br><span class="line">  image_repository: library</span><br><span class="line">  # Kubespray container image for deploy user cluster or scale</span><br><span class="line">  kubespray_image: &quot;kubespray&quot;</span><br><span class="line">  # Auto generate self-signed certificate for registry domain</span><br><span class="line">  generate_domain_crt: true</span><br><span class="line">  # For nodes pull image, use 443 as default</span><br><span class="line">  registry_https_port: 443</span><br><span class="line">  # For push image to this registry, use 5000 as default, and only bind at 127.0.0.1</span><br><span class="line">  registry_push_port: 5000</span><br><span class="line">  # Set false to disable download all container images on all nodes</span><br><span class="line">  download_container: false</span><br></pre></td></tr></table></figure><ul><li>安装包目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">kubeplay&#x2F;</span><br><span class="line">.</span><br><span class="line">├── compose.yaml                 # compose 配置文件</span><br><span class="line">├── config</span><br><span class="line">│   ├── compose</span><br><span class="line">│   │   └── nginx.conf           # nginx 配置文件</span><br><span class="line">│   ├── kubespray</span><br><span class="line">│   │   ├── env.yml</span><br><span class="line">│   │   ├── group_vars           # kubespray group_vars  配置文件</span><br><span class="line">│   │   └── inventory.ini</span><br><span class="line">│   └── rootCA.cnf               # openssl 配置文件</span><br><span class="line">├── config-sample.yaml           # 主配置文件</span><br><span class="line">├── install.sh                   # 安装包入口脚本</span><br><span class="line">├── library</span><br><span class="line">└── resources                    # 所有离线资源</span><br><span class="line">    ├── images</span><br><span class="line">    │   ├── kubespray-v2.16.tar  # kubespray 镜像</span><br><span class="line">    │   ├── nginx-1.20-alpine.tar# nginx 镜像</span><br><span class="line">    │   └── registry-2.7.1.tar   # registry 镜像</span><br><span class="line">    ├── nginx                    # rpm&#x2F;deb 包以及一些二进制文件</span><br><span class="line">    │   ├── centos               # centos rpm 包</span><br><span class="line">    │   ├── debian               # debian deb 包</span><br><span class="line">    │   ├── files                # 一些二进制文件</span><br><span class="line">    │   ├── repos                # yum&#x2F;apt 配置文件</span><br><span class="line">    │   ├── tools                # 一些部署时依赖的工具</span><br><span class="line">    │   └── ubuntu               # ubuntu deb 包</span><br><span class="line">    └── registry</span><br><span class="line">        └── docker               # 组件镜像 registry 存储目录</span><br></pre></td></tr></table></figure><h3><span id="compose-节点">compose 节点</span></h3><p>需要单独划分出一个节点用户部署 nginx 和镜像仓库服务，并在该节点上运行 kubespray 来部署 K8s 集群。大致流程的代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">deploy_compose()&#123;</span><br><span class="line">  case $&#123;ID&#125; in</span><br><span class="line">    Debian|debian)</span><br><span class="line">      system::debian::config_repo</span><br><span class="line">      ;;</span><br><span class="line">    CentOS|centos)</span><br><span class="line">      system::centos::disable_selinux</span><br><span class="line">      system::centos::config_repo</span><br><span class="line">      ;;</span><br><span class="line">    Ubuntu|ubuntu)</span><br><span class="line">      system::ubuntu::config_repo</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      errorlog &quot;Not support system: $&#123;ID&#125;&quot;</span><br><span class="line">      exit 1</span><br><span class="line">      ;;</span><br><span class="line">  esac</span><br><span class="line">  system::disable_firewalld</span><br><span class="line">  system::install_pkgs</span><br><span class="line">  common::install_tools</span><br><span class="line">  common::rudder_config</span><br><span class="line">  common::update_hosts</span><br><span class="line">  common::generate_domain_certs</span><br><span class="line">  common::load_images</span><br><span class="line">  common::compose_up</span><br><span class="line">  common::health_check</span><br><span class="line">  system::install_chrony</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">  case $&#123;INSTALL_TYPE&#125; in</span><br><span class="line">    all)</span><br><span class="line">      deploy_compose</span><br><span class="line">      common::push_kubespray_image</span><br><span class="line">      common::run_kubespray &quot;bash &#x2F;kubespray&#x2F;run.sh deploy-cluster&quot;</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      echowarn &quot;unknow [TYPE] parameter: $&#123;INSTALL_TYPE&#125;&quot;</span><br><span class="line">      common::usage</span><br><span class="line">      ;;</span><br><span class="line">  esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main &quot;$@&quot;</span><br></pre></td></tr></table></figure><ul><li>首先初始化节点，关闭防火墙和 <code>SELinux</code></li><li>配置部署节点 yum/apt 离线源</li><li>安装一些部署依赖包，如 chrony、 libseccomp 等</li><li>安装一些工具如 yq, skopeo, kubectl 等</li><li>安装 nerdctl-full (containerd)</li><li>使用 nerdctl load -i 的方式导入nginx, registry, kubespray 镜像</li><li>使用 yq 渲染配置文件，生成 kubespray 需要的 env 文件和 inventory 文件</li><li>生成镜像仓库域名证书并将自签证书添加到主机的 CA trust 信任当中</li><li>在 <code>/etc/hosts</code> 中添加镜像仓库域名 hosts 映射</li><li>使用 nerdctl compose 启动 nginx 和 registry 服务</li><li>部署时钟同步服务 chrony</li><li>检查各个服务的状态</li><li>最后使用 nerdctl run 启动 kubespray 容器来部署 k8s 集群</li></ul><h3><span id="kubespray">kubespray</span></h3><p>部署的流程上基本上和 kubespray 官方大体一致，只不过我们引入里分层部署的特性</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">deploy_cluster()&#123;</span><br><span class="line">  touch $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">  STEPS&#x3D;&quot;00-default-ssh-config 01-cluster-bootstrap-os 02-cluster-etcd 03-cluster-kubernetes 04-cluster-network 05-cluster-apps&quot;</span><br><span class="line">  for step in $&#123;STEPS&#125;; do</span><br><span class="line">    if ! grep -q &quot;$&#123;step&#125;&quot; $&#123;INSTALL_STEPS_FILE&#125;; then</span><br><span class="line">      infolog &quot;start deploy $&#123;step&#125;&quot;</span><br><span class="line">      if ansible-playbook $&#123;ANSIBLE_ARGS&#125; $&#123;KUBE_ROOT&#125;&#x2F;playbooks&#x2F;$&#123;step&#125;.yml; then</span><br><span class="line">        echo $&#123;step&#125; &gt;&gt; $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">        infolog &quot;$&#123;step&#125; successfully installed&quot;</span><br><span class="line">      else</span><br><span class="line">        errorlog &quot;$&#123;step&#125; installation failed&quot;</span><br><span class="line">        exit 1</span><br><span class="line">      fi</span><br><span class="line">    else</span><br><span class="line">      warnlog &quot;$&#123;step&#125; is already installed, so skipped...&quot;</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>配置堡垒机 ssh 登录（可选）</li><li>配置节点 yum/apt 源为 nginx 服务提供的源</li><li>将自签的域名证书添加到主机的 CA trust 信任当中</li><li>在 <code>/etc/hosts</code> 中添加镜像仓库域名 hosts 映射</li><li>关闭防火墙，安装时钟同步服务，进行同步时钟</li><li>初始化集群节点，安装部署依赖</li><li>安装容器运行时，下载文件和组件镜像</li><li>部署 etcd 集群</li><li>部署 K8s 集群</li><li>部署 CNI 插件</li><li>安装一些额外的 addon 组件如 (coredns)</li></ul><p>至此整个打包和部署流程就完毕了，下面再讲几个打包/部署常见的问题</p><h2><span id="其他">其他</span></h2><h3><span id="kubeadm-证书">kubeadm 证书</span></h3><p>通过修改 kubeadm 源码的方式将证书续命到 10 年，开启 <code>kubeadm_patch_enabled</code> 参数部署时就将 kubeadm 替换为修改后的 kubeadm。关于 kubeadm 的修改和构建和参考我之前写过的《<a href="https://blog.k8s.li/build-k8s-binary-by-github-actions.html" target="_blank" rel="noopener">使用 GitHub Actions 编译 kubernetes 组件</a>》。</p><ul><li><a href="https://github.com/k8sli/kubespray/blob/main/roles/cluster/download/tasks/main.yml" target="_blank" rel="noopener">roles/cluster/download/tasks/main.yml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">- name: Relpace kubeadm binary file as patched version</span><br><span class="line">  get_url:</span><br><span class="line">    url: &quot;&#123;&#123; patched_kubeadm_download_url &#125;&#125;&quot;</span><br><span class="line">    dest: &quot;&#123;&#123; bin_dir &#125;&#125;&#x2F;kubeadm&quot;</span><br><span class="line">    mode: 0755</span><br><span class="line">    owner: root</span><br><span class="line">    group: root</span><br><span class="line">  tags:</span><br><span class="line">    - kubeadm</span><br><span class="line">  when: kubeadm_patch_enabled | default(true) | bool</span><br></pre></td></tr></table></figure><h3><span id="镜像缓存">镜像缓存</span></h3><p>os-packages, kubespray-base, kubespray-files, kubespray-images 这四个镜像在构建的时候都会采用 md5 值的方式校验是否需要重新构建镜像，这样能够大大提升 CI 的执行效率，下面以 kubespray-base 这个镜像为例介绍其原理和实现：</p><ul><li>在构建镜像前会有一个 md5 计算和校验的步骤，将与该镜像紧密相关的文件内容进行汇总并生成 md5 值，并将这个值得以 label 的方式保存在镜像的元数据信息当中。如果该值与上个最新的镜像中的 md5 值相等，那么就不需要重新构建该镜像，只需要进行 retag 即可。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- name: Prepare for build images</span><br><span class="line">  shell: bash</span><br><span class="line">  run: |</span><br><span class="line">    git describe --tags --always | sed &#39;s&#x2F;^&#x2F;IMAGE_TAG&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    git branch --show-current | sed &#39;s&#x2F;^&#x2F;BRANCH_NAME&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    git branch --show-current | sed &#39;s&#x2F;master&#x2F;latest&#x2F;;s&#x2F;main&#x2F;latest&#x2F;;s&#x2F;^&#x2F;IMAGE_TAG_BY_BRANCH&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    sed -n &#39;s&#x2F;^kube_version: &#x2F;KUBE_VERSION&#x3D;&#x2F;p&#39; roles&#x2F;kubespray-defaults&#x2F;defaults&#x2F;main.yaml &gt;&gt; $GITHUB_ENV</span><br><span class="line">    cat build&#x2F;kubespray-base&#x2F;Dockerfile requirements.txt tests&#x2F;requirements.txt .github&#x2F;workflows&#x2F;build.yaml \</span><br><span class="line">    | md5sum | tr -d &#39;\ -&#39; | sed &#39;s&#x2F;^&#x2F;BASE_MD5&#x3D;md5-&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line"></span><br><span class="line">    source $GITHUB_ENV</span><br><span class="line">    if skopeo inspect docker:&#x2F;&#x2F;$&#123;BASE_IMAGE_REPO&#125;:$&#123;BRANCH_NAME&#125; &gt; mainfest.json; then</span><br><span class="line">      jq -r &#39;.Labels.BASE_MD5&#39; mainfest.json | sed &#39;s&#x2F;^&#x2F;LATEST_BASE_MD5&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    else</span><br><span class="line">      echo &#39;LATEST_BASE_MD5&#x3D;null&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    fi</span><br></pre></td></tr></table></figure><ul><li>如果当前md5 的值与最新的 md5 值相等，就重新生成一个新的 Dockerfile 来进行镜像 retag 的操作。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- name: Replace Dockerfile if MD5 not update</span><br><span class="line">  if: $&#123;&#123; env.BASE_MD5 &#x3D;&#x3D; env.LATEST_BASE_MD5 &#125;&#125;</span><br><span class="line">  run: |</span><br><span class="line">    echo &quot;FROM $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.BASE_MD5 &#125;&#125;&quot; &gt; build&#x2F;kubespray-base&#x2F;Dockerfile</span><br></pre></td></tr></table></figure><ul><li>构建镜像并将 md5 值作为 labels 填充到镜像的元数据信息当中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- name: Build and push kubespray-base images</span><br><span class="line">  uses: docker&#x2F;build-push-action@v2</span><br><span class="line">  with:</span><br><span class="line">    context: .</span><br><span class="line">    push: $&#123;&#123; github.event_name !&#x3D; &#39;pull_request&#39; &#125;&#125;</span><br><span class="line">    file: build&#x2F;kubespray-base&#x2F;Dockerfile</span><br><span class="line">    platforms: linux&#x2F;amd64,linux&#x2F;arm64</span><br><span class="line">    cache-from: type&#x3D;local,src&#x3D;&#x2F;tmp&#x2F;.buildx-cache</span><br><span class="line">    cache-to: type&#x3D;local,dest&#x3D;&#x2F;tmp&#x2F;.buildx-cache-new</span><br><span class="line">    build-args: KUBE_VERSION&#x3D;$&#123;&#123; env.KUBE_VERSION &#125;&#125;</span><br><span class="line">    labels: BASE_MD5&#x3D;$&#123;&#123; env.BASE_MD5 &#125;&#125;</span><br><span class="line">    tags: |</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.IMAGE_TAG &#125;&#125;</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.BASE_MD5 &#125;&#125;</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.BRANCH_NAME &#125;&#125;</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.IMAGE_TAG_BY_BRANCH &#125;&#125;</span><br></pre></td></tr></table></figure><p>使用这种方式的好处就在于在不需要构建镜像的时候能大幅度提升 CI 的运行效率。</p><blockquote><p>本文转载自：「 木子的博客 」，原文：<a href="https://tinyurl.com/y9bekf67" target="_blank" rel="noopener">https://tinyurl.com/y9bekf67</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在企业私有云环境当中，出于对数据安全的考虑以及满足 &lt;a href=&quot;http://www.djbh.net/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;网络安全等级保护&lt;/a&gt; 的要求，往往会对内部环境中的服务器做出严格的访问限制。一般来讲生产环境都会禁止访问外部网络，开发人员要访问生产环境也必须通过堡垒机或者其他方式进行安全审计登录。在这种无网（无法访问公网）的环境中，想要部署好一个 K8s 集群并不是一件轻松的事儿。市面上 K8s 部署工具也多不胜数，对于离线部署的支持情况也各不相同：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Item&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Language&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Star&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Fork&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;离线部署支持情况&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/kubernetes/kops&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kops&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;13.2k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;4.1k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;不支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/kubespray&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kubespray&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Ansible&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;11.1k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;4.7k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，需自行构建安装包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/easzlab/kubeasz&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kubeasz&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Ansible&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;7.2k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;2.7k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，需自行构建安装包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/fanux/sealos&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealos&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;4.1k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;790&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，需付费充值会员&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/rancher/rke&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RKE&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;2.5k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;480&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;不支持，需自行安装 docker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/alibaba/sealer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealer&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;503&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;112&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，源自 &lt;a href=&quot;https://github.com/fanux/sealos&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealos&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/kubesphere/kubekey&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kubekey&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;471&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;155&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;部分支持，仅镜像可离线&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;无网环境离线部署 K8s 往往是作为一个商业服务或者商业付费产品来出售（如 &lt;a href=&quot;https://www.sealyun.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealos&lt;/a&gt; ），很少有开源免费的解决方案；或者虽然提供了离线部署方案，但想要操作起来十分繁琐，很难顺畅地做到一键部署；又或者只支持部分离线部署，还有一部分资源需要在部署的时候通过公网获取。&lt;/p&gt;
&lt;p&gt;针对上述问题，本文调研主流的 K8s 部署工具，并基于这些工具设计并实现一种从构建离线安装包到一键部署 K8s 集群全流程的解决方案，以满足在无网的环境中一键部署 K8s 集群的需求，比较适合基于 K8s 的 PaaS toB 产品使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>两个 99% 的人都遇到过的 Kubernetes 故障处理技巧</title>
    <link href="https://www.hi-linux.com/posts/19507.html"/>
    <id>https://www.hi-linux.com/posts/19507.html</id>
    <published>2021-08-30T01:00:00.000Z</published>
    <updated>2021-08-31T01:58:11.448Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>随着微服务的不断推进，使用 k8s 集群越来越多，越来越深入，随之而来会遇到一系列的问题，本文向大家介绍实际使用 k8s 遇到的一些问题以及解决方法。</p><h2><span id="问题一修复-k8s-内存泄露问题">问题一：修复 K8S 内存泄露问题</span></h2><h3><span id="问题描述">问题描述</span></h3><ol><li>当 k8s 集群运行日久以后，有的 node 无法再新建 pod，并且出现如下错误，当重启服务器之后，才可以恢复正常使用。查看 pod 状态的时候会出现以下报错。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">applying cgroup … caused: mkdir …no space left on device</span><br></pre></td></tr></table></figure><p>或者在 describe pod 的时候出现 cannot allocate memory。</p><p>这时候你的 k8s 集群可能就存在内存泄露的问题了，当创建的 pod 越多的时候内存会泄露的越多，越快。</p><ol start="2"><li>具体查看是否存在内存泄露</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;memory.kmem.slabinfo</span><br></pre></td></tr></table></figure><p>当出现 cat: /sys/fs/cgroup/memory/kubepods/memory.kmem.slabinfo: Input/output error 则说明不存在内存泄露的情况 如果存在内存泄露会出现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slabinfo - version: 2.1</span><br><span class="line"># name            &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt;</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="解决方案">解决方案</span></h3><ol><li><p>解决方法思路：关闭 runc 和 kubelet 的 kmem，因为升级内核的方案改动较大，此处不采用。</p></li><li><p>kmem 导致内存泄露的原因：</p></li></ol><p>内核对于每个 cgroup 子系统的的条目数是有限制的，限制的大小定义在 kernel/cgroup.c #L139，当正常在 cgroup 创建一个 group 的目录时，条目数就加 1。我们遇到的情况就是因为开启了 kmem accounting 功能，虽然 cgroup 的目录删除了，但是条目没有回收。这样后面就无法创建 65535 个 cgroup 了。也就是说，在当前内核版本下，开启了 kmem accounting 功能，会导致 memory cgroup 的条目泄漏无法回收。</p><h4><span id="21-编译-runc">2.1 编译 runc</span></h4><ul><li>配置 go 语言环境</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;dl.google.com&#x2F;go&#x2F;go1.12.9.linux-amd64.tar.gz</span><br><span class="line">$ tar xf go1.12.9.linux-amd64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line"></span><br><span class="line"># 写入bashrc</span><br><span class="line">$ vim ~&#x2F;.bashrc</span><br><span class="line">$ export GOPATH&#x3D;&quot;&#x2F;data&#x2F;Documents&quot;</span><br><span class="line">$ export GOROOT&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;go&quot;</span><br><span class="line">$ export PATH&#x3D;&quot;$GOROOT&#x2F;bin:$GOPATH&#x2F;bin:$PATH&quot;</span><br><span class="line">$ export GO111MODULE&#x3D;off</span><br><span class="line"></span><br><span class="line"># 验证</span><br><span class="line">$ source ~&#x2F;.bashrc</span><br><span class="line">$ go env</span><br></pre></td></tr></table></figure><ul><li>下载 runc 源码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p &#x2F;data&#x2F;Documents&#x2F;src&#x2F;github.com&#x2F;opencontainers&#x2F;</span><br><span class="line">$ cd &#x2F;data&#x2F;Documents&#x2F;src&#x2F;github.com&#x2F;opencontainers&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;opencontainers&#x2F;runc</span><br><span class="line">$ cd runc&#x2F;</span><br><span class="line">$ git checkout v1.0.0-rc9  # 切到v1.0.0-rc9 tag</span><br></pre></td></tr></table></figure><ul><li>编译</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装编译组件</span><br><span class="line">$ sudo yum install libseccomp-devel</span><br><span class="line">$ make BUILDTAGS&#x3D;&#39;seccomp nokmem&#39;</span><br><span class="line"># 编译完成之后会在当前目录下看到一个runc的可执行文件,等kubelet编译完成之后会将其替换</span><br></pre></td></tr></table></figure><h4><span id="22-编译-kubelet">2.2 编译 kubelet</span></h4><ul><li>下载 kubernetes 源码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p &#x2F;root&#x2F;k8s&#x2F;</span><br><span class="line">$ cd &#x2F;root&#x2F;k8s&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line">$ cd kubernetes&#x2F;</span><br><span class="line">$ git checkout v1.15.3</span><br></pre></td></tr></table></figure><ul><li>制作编译环境的镜像(Dockerfile 如下)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:centos7.3.1611</span><br><span class="line"></span><br><span class="line">ENV GOROOT &#x2F;usr&#x2F;local&#x2F;go</span><br><span class="line">ENV GOPATH &#x2F;usr&#x2F;local&#x2F;gopath</span><br><span class="line">ENV PATH &#x2F;usr&#x2F;local&#x2F;go&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line">RUN yum install rpm-build which where rsync gcc gcc-c++ automake autoconf libtool make -y \</span><br><span class="line">    &amp;&amp; curl -L https:&#x2F;&#x2F;studygolang.com&#x2F;dl&#x2F;golang&#x2F;go1.12.9.linux-amd64.tar.gz | tar zxvf - -C &#x2F;usr&#x2F;local</span><br></pre></td></tr></table></figure><ul><li>在制作好的 go 环境镜像中来进行编译 kubelet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker run  -it --rm   -v &#x2F;root&#x2F;k8s&#x2F;kubernetes:&#x2F;usr&#x2F;local&#x2F;gopath&#x2F;src&#x2F;k8s.io&#x2F;kubernetes   build-k8s:centos-7.3-go-1.12.9-k8s-1.15.3   bash</span><br><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;gopath&#x2F;src&#x2F;k8s.io&#x2F;kubernetes</span><br><span class="line">#编译</span><br><span class="line">$ GO111MODULE&#x3D;off KUBE_GIT_TREE_STATE&#x3D;clean KUBE_GIT_VERSION&#x3D;v1.15.3 make kubelet GOFLAGS&#x3D;&quot;-tags&#x3D;nokmem&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li>替换原有的 runc 和 kubelet</li></ol><ul><li>将原有 runc 和 kubelet 备份</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;kubelet &#x2F;home&#x2F;kubelet</span><br><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;docker-runc &#x2F;home&#x2F;docker-runc</span><br></pre></td></tr></table></figure><ul><li>停止 docker 和 kubelet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop docker</span><br><span class="line">$ systemctl stop kubelet</span><br></pre></td></tr></table></figure><ul><li>将编译好的 runc 和 kubelet 进行替换</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cp kubelet &#x2F;usr&#x2F;bin&#x2F;kubelet</span><br><span class="line">$ cp kubelet &#x2F;usr&#x2F;local&#x2F;bin&#x2F;kubelet</span><br><span class="line">$ cp runc &#x2F;usr&#x2F;bin&#x2F;docker-runc</span><br></pre></td></tr></table></figure><ul><li>检查 kmem 是否关闭前需要将此节点的 pod 杀掉重启或者重启服务器,当结果为 0 时成功</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;burstable&#x2F;memory.kmem.usage_in_bytes</span><br></pre></td></tr></table></figure><ul><li>检查是否还存在内存泄露的情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;memory.kmem.slabinfo</span><br></pre></td></tr></table></figure><h2><span id="问题二k8s-证书过期问题的两种处理方法">问题二：k8s 证书过期问题的两种处理方法</span></h2><h3><span id="前情提要">前情提要</span></h3><p>公司测试环境的 k8s 集群使用已经很长时间了,突然有一天开发联系我说 k8s 集群无法访问，开始以为是测试环境的机器磁盘空间不够了，导致组件异常或者把开发使用的镜像自动清理掉了，但是当登上机器去查验的时候发现不是这个原因。当时觉得也很疑惑。因为开发环境使用人数较少，不应该会出问题，所以就去查验 log 的相关报错信息。</p><h3><span id="问题现象">问题现象</span></h3><p>出现 k8s api 无法调取的现象，使用 kubectl 命令获取资源均返回如下报错:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Unable to connect to the server: x509: certificate has expired or is not yet valid</span><br></pre></td></tr></table></figure><p>经网上搜索之后发现应该是 k8s 集群的证书过期了，使用命令排查证书的过期时间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm alpha certs check-expiration</span><br></pre></td></tr></table></figure><p>发现确实是证书过期了</p><h3><span id="相关介绍以及问题解决">相关介绍以及问题解决</span></h3><p>因为我们是使用 kubeadm 部署的 k8s 集群，所以更新起证书也是比较方便的，默认的证书时间有效期是一年，我们集群的 k8s 版本是 1.15.3 版本是可以使用以下命令来更新证书的，但是一年之后还是会到期，这样就很麻烦，所以我们需要了解一下 k8s 的证书，然后我们来生成一个时间很长的证书，这样我们就可以不用去总更新证书了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm alpha certs renew all --config&#x3D;kubeadm.yaml</span><br><span class="line">$ systemctl restart kubelet</span><br><span class="line">$ kubeadm init phase kubeconfig all --config kubeadm.yaml</span><br><span class="line"># 然后将生成的配置文件替换,重启 kube-apiserver、kube-controller、kube-scheduler、etcd 这4个容器即可</span><br></pre></td></tr></table></figure><p>另外 kubeadm 会在控制面板升级的时候自动更新所有证书，所以使用 kubeadm 搭建的集群最佳的做法是经常升级集群，这样可以确保你的集群保持最新状态并保持合理的安全性。但是对于实际的生产环境我们可能并不会去频繁的升级集群，所以这个时候我们就需要去手动更新证书。</p><p>下面我们通过调用 k8s 的 api 来实现更新一个 10 年的证书</p><p>首先在 <code>/etc/kubernetes/manifests/kube-controller-manager.yaml</code> 文件加入配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    # 设置证书有效期为 10年</span><br><span class="line">    - --experimental-cluster-signing-duration&#x3D;87600h</span><br><span class="line">    - --client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br></pre></td></tr></table></figure><p>修改完成后 kube-controller-manager 会自动重启生效。然后我们需要使用下面的命令为 Kubernetes 证书 API 创建一个证书签名请求。如果您设置例如 cert-manager 等外部签名者，则会自动批准证书签名请求（CSRs）。否者，您必须使用 kubectl certificate 命令手动批准证书。以下 kubeadm 命令输出要批准的证书名称，然后等待批准发生：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 需要将全部 pending 的证书全部批准</span><br><span class="line">$ kubeadm alpha certs renew all --use-api --config kubeadm.yaml &amp;</span><br></pre></td></tr></table></figure><p>我们还不能直接重启控制面板的几个组件，这是因为使用 kubeadm 安装的集群对应的 etcd 默认是使用的 /etc/kubernetes/pki/etcd/ca.crt 这个证书进行前面的，而上面我们用命令 kubectl certificate approve 批准过后的证书是使用的默认的 /etc/kubernetes/pki/ca.crt 证书进行签发的，所以我们需要替换 etcd 中的 ca 机构证书:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 先拷贝静态 Pod 资源清单</span><br><span class="line">$ cp -r &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F; &#x2F;etc&#x2F;kubernetes&#x2F;manifests.bak</span><br><span class="line">$ vi &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;etcd.yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    # 修改为 CA 文件</span><br><span class="line">    - --peer-trusted-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">    - --trusted-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">......</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: &#x2F;var&#x2F;lib&#x2F;etcd</span><br><span class="line">      name: etcd-data</span><br><span class="line">    - mountPath: &#x2F;etc&#x2F;kubernetes&#x2F;pki  # 更改证书目录</span><br><span class="line">      name: etcd-certs</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: &#x2F;etc&#x2F;kubernetes&#x2F;pki  # 将 pki 目录挂载到 etcd 中去</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: &#x2F;var&#x2F;lib&#x2F;etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-data</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>由于 kube-apiserver 要连接 etcd 集群，所以也需要重新修改对应的 etcd ca 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vi &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-apiserver.yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    # 将etcd ca文件修改为默认的ca.crt文件</span><br><span class="line">    - --etcd-cafile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>除此之外还需要替换 requestheader-client-ca-file 文件，默认是 /etc/kubernetes/pki/front-proxy-ca.crt 文件，现在也需要替换成默认的 CA 文件，否则使用聚合 API，比如安装了 metrics-server 后执行 kubectl top 命令就会报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.crt</span><br><span class="line">$ cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.key</span><br></pre></td></tr></table></figure><p>这样我们就得到了一个 10 年证书的 k8s 集群，还可以通过重新编译 kubeadm 来实现一个 10 年证书的，这个我没有尝试，不过在初始化集群的时候也是一个方法。</p><blockquote><p>本文转载自：「 知乎 」，原文：<a href="https://tinyurl.com/h9yet6sd" target="_blank" rel="noopener">https://tinyurl.com/h9yet6sd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着微服务的不断推进，使用 k8s 集群越来越多，越来越深入，随之而来会遇到一系列的问题，本文向大家介绍实际使用 k8s 遇到的一些问题以及解决方法。&lt;/p&gt;
&lt;h2 id=&quot;问题一：修复-K8S-内存泄露问题&quot;&gt;问题一：修复 K8S 内存泄露问题&lt;/h2&gt;
&lt;h3 id=&quot;问题描述&quot;&gt;问题描述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;当 k8s 集群运行日久以后，有的 node 无法再新建 pod，并且出现如下错误，当重启服务器之后，才可以恢复正常使用。查看 pod 状态的时候会出现以下报错。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;applying cgroup … caused: mkdir …no space left on device&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;或者在 describe pod 的时候出现 cannot allocate memory。&lt;/p&gt;
&lt;p&gt;这时候你的 k8s 集群可能就存在内存泄露的问题了，当创建的 pod 越多的时候内存会泄露的越多，越快。&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;具体查看是否存在内存泄露&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ cat &amp;#x2F;sys&amp;#x2F;fs&amp;#x2F;cgroup&amp;#x2F;memory&amp;#x2F;kubepods&amp;#x2F;memory.kmem.slabinfo&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当出现 cat: /sys/fs/cgroup/memory/kubepods/memory.kmem.slabinfo: Input/output error 则说明不存在内存泄露的情况 如果存在内存泄露会出现&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;slabinfo - version: 2.1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# name            &amp;lt;active_objs&amp;gt; &amp;lt;num_objs&amp;gt; &amp;lt;objsize&amp;gt; &amp;lt;objperslab&amp;gt; &amp;lt;pagesperslab&amp;gt; : tunables &amp;lt;limit&amp;gt; &amp;lt;batchcount&amp;gt; &amp;lt;sharedfactor&amp;gt; : slabdata &amp;lt;active_slabs&amp;gt; &amp;lt;num_slabs&amp;gt; &amp;lt;sharedavail&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>服务网格除了 Istio，其实你还可以有其它 8 种选择</title>
    <link href="https://www.hi-linux.com/posts/1629.html"/>
    <id>https://www.hi-linux.com/posts/1629.html</id>
    <published>2021-08-26T01:00:00.000Z</published>
    <updated>2021-08-26T01:32:52.275Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>哪种服务网格最适合你的企业？近年来，Kubernetes 服务网格框架数量增加迅速，使得这成为一个棘手的问题。</p><p>下面将介绍 9 种较受欢迎的用以支撑微服务开发的服务网格框架，每种方案都给出了其适用场景。</p><h2><span id="什么是服务网格">什么是服务网格</span></h2><p>服务网格近年来有很高的话题度，背后的原因是什么？</p><p>微服务已经成为一种灵活快速的开发方式。然而，随着微服务数量成倍数地增长，开发团队开始遇到了部署和扩展性上的问题。</p><p>容器和 Kubernetes 这样的容器编排系统 ，将运行时和服务一起打包进镜像，调度容器到合适的节点，运行容器。这个方案可以解决开发团队遇到的不少问题[1]。然而，在这个操作流程中仍存在短板：如何管理服务间的通信。</p><p>在采用服务网格的场景下，以一种和应用代码解耦的方式，增强了应用间统一的网络通信能力。服务网格扩展了集群的管理能力，增强可观测性、服务发现、负载均衡、IT 运维监控及应用故障恢复等功能。</p><a id="more"></a><h2><span id="服务网格概览">服务网格概览</span></h2><p>服务网格一直有很高的热度。正如 Linkerd 的作者 William Morgan 所提到[2]的：“服务网格本质上无非就是和应用捆绑在一起的用户空间代理。” 此说法相当简洁，他还补充道，“如果你能透过噪音看清本质，服务网格能给你带来实实在在的重要价值。”</p><p>Envoy 是许多服务网格框架的核心组件，是一个通用的开源代理，常被用于 Pod 内的 sidecar 以拦截流量。也有服务网格使用另外的代理方案。</p><p>若论具体服务网格方案的普及程度，Istio 和 Linkerd 获得了更多的认可。也有其它可选项，包括 Consul Connect，Kuma，AWS App Mesh和OpenShift。下文会阐述9种服务网格提供的关键特性。</p><p><strong>Istio</strong></p><p>Istio 是基于 Envoy 构建的一个可扩展的开源服务网格。开发团队可以通过它连接、加密、管控和观察应用服务。Istio 于 2017 年开源，目前 IBM、Google、Lyft 仍在对其进行持续维护升级。Lyft 在 2017 年把 Envoy 捐赠给了 CNCF。</p><p>Istio 花了不少时间去完善增强它的功能特性。Istio 的关键特性包括负载均衡、流量路由、策略创建、可度量性及服务间认证。</p><p>Istio 有两个部分组成：数据平面和控制平面。数据平面负责处理流量管理，通过 Envoy 的 sidecar 代理来实现流量路由和服务间调用。控制平面是主要由开发者用来配置路由规则和观测指标。</p><p>Istio 观测指标是细粒度的属性，其中包含和服务行为相关的特定数据值。下面是个样例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">request.path: xyz&#x2F;abc </span><br><span class="line">request.size: 234 </span><br><span class="line">request.time: 12:34:56.789 04&#x2F;17&#x2F;2017 </span><br><span class="line">source.ip: [192 168 0 1] </span><br><span class="line">destination.service.name: example</span><br></pre></td></tr></table></figure><p>与其他服务网格相比，Istio 胜在其平台成熟度以及通过其 Dashbaord</p><p>着重突出的服务行为观测和业务管理功能，然而也因为这些高级特性和复杂的配置流程，Istio 可能并不如其它一些替代方案那样容易上手。</p><p><strong>Linkerd</strong></p><p>按照官网的说法，Linkerd 是一个轻量级、安全优先的 Kubernetes 服务网格。它的创建流程快到让人难以置信（据称在 Kubernetes 安装只需要 60 秒），这是大多数开发者喜闻乐见的。Linkerd 并没有采用基于 Envoy 的构建方案。而是使用了一个基于 Rust 的高性能代理 linkerd2-proxy，这个代理是专门为 Linkerd 服务网格编写的。</p><p>Linkerd 由社区驱动，是 100% 的 Apache 许可开源项目。它还是 CNCF 孵化项目。Linkerd 始于 2016 年，维护者也花了不少时间去解决其中的缺陷。</p><p>使用 Linkerd 服务网格，应用服务可以增强其可靠性、可观测性及其在 Kubernetes 上部署的安全性。举个例子，可观测性的增强可以帮助用户解决服务间的延迟问题。使用 Linkerd 不要求用户做很多代码调整或是花费大量时间写 YAML 配置文件。可靠的产品特性和正向的开发者使用回馈，使得 Linkerd 成为服务网格中一个强有力的竞争者。</p><p><strong>Consul Connect</strong></p><p>Consul Connect 是来自 HashiCorp 的服务网格，专注于路由和分段，通过应用级的 sidecar 代理来提供服务间的网络特性。Consult Connect 侧重于应用安全，提供应用间的双向 TLS 连接以实现授权和加密。</p><p>Consult Connect 独特的一点是提供了两种代理模式。一种是它内建的代理，同时它还支持 Envoy 方案。Connect 强调可观测性，集成了例如 Prometheus 这样的工具来监控来自 sidecar 代理的数据。Consul Connect 可以灵活地满足开发者使用需求。比如，它提供了多种方式注册服务：可以从编排系统注册，可以通过配置文件，通过 API 调用，或是命令行工具。</p><p><strong>Kuma</strong></p><p>Kuma 来源于 Kong，自称是一个非常好用的服务网格替代方案。Kuma 是一个基于 Envoy 的平台无关的控制平面。Kuma 提供了安全、观测、路由等网络特性，同时增强了服务间的连通性。Kuma 同时支持 Kubernetes 和虚拟机。</p><p>Kuma 让人感兴趣的一点是，它的企业版可以通过一个统一控制面板来运维管理多个互相隔离独立的服务网格。这项能力可以满足安全要求高的使用场景。既符合隔离的要求，又实现集中控制。</p><p>Kuma 也是相对容易安装的一个方案。因为它预先内置了不少策略。这些策略覆盖了常见需求，例如路由，双向 TLS，故障注入，流量控制，加密等场景。</p><p>Kuma 原生兼容 Kong，对于那些已经采用 Kong API 管理的企业组织，Kuma 是个非常自然而然的候选方案。</p><p><strong>Maesh</strong></p><p>Maesh 是来自 Containous 的容器原生的服务网格，标榜自己是比市场其它服务网格更轻量级更易用的方案。和很多基于 Envoy 构建的服务网格不同，Maesh 采用了 Traefik， 一个开源的反向代理和负载均衡器。</p><p>Maesh 并没有采用 sidecar 的方式进行代理，而是在每个节点部署一个代理终端。这样做的好处是不需要去编辑 Kubernetes 对象，同时可以让用户有选择性地修改流量，Maesh 相比其他服务网格侵入性更低。Maesh 支持的配置方式：在用户服务对象上添加注解或是在服务网格对象上添加注解来实现配置。</p><p>实际上，SMI 是一种新的服务网格规范格式，对 SMI 的支持 Maesh 独有的一大亮点。随着 SMI 在业界逐渐被采用，可以提高可扩展性和减缓供应商绑定的担忧。</p><p>Maesh 要求 Kubernetes 1.11 以上的版本，同时集群里安装了 CoreDNS/KubeDNS。这篇安装指南[3]演示了如何通过 Helm v3 快速安装 Maesh。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add maesh https:&#x2F;&#x2F;containous.github.io&#x2F;maesh&#x2F;charts </span><br><span class="line">$ helm repo update </span><br><span class="line">$ helm install maesh maesh&#x2F;maesh</span><br></pre></td></tr></table></figure><p><strong>ServiceComb-mesher</strong></p><p>Apache 软件基金会形容旗下的 ServiceComb-mesher “是一款用 Go 语言实现的高性能服务网格”。Mesher 基于一个非常受欢迎的 Go 语言微服务开发框架 Go Chassis[4] 来设计实现。因此，它沿袭了 Go Chassis 的一些特性如服务发现、负载均衡、错误容忍、路由管理和分布式追踪等特性。</p><p>Mesher 采用了 sidecar 方式；每个服务有一个 Mesher sidecar 代理。开发人员通过 Admin API 和 Mesher 交互，查看运行时信息。Mesher 同时支持 HTTP 和 gRPC，可快速移植到不同的基础设施环境，包括 Docker、Kubernetes、虚拟机和裸金属机环境。</p><p><strong>Network Service Mesh（NSM）</strong></p><p>Network Service Mesh（NSM）是一款专门为 telcos 和 ISPs 设计的服务网格。它提供了一层级用以增强服务在 Kubernetes 的低层级网络能力。NSM 目前是 CNCF 的沙箱项目。</p><p>根据 NSM 的文档说明，“经常接触 L2/L3 层的网络运维人员抱怨说，适合他们的下一代架构的容器网络解决方案几乎没有”。</p><p>因此，NSM 在设计时就考虑到一些不同使用场景，尤其是网络协议不同和网络配置混杂的场景。这使得 NSM 对某些特殊场景具备相当吸引力，例如边缘计算、5G 网络和 IOT 设备等场景。NSM 使用简单直接的 API 接口去实现容器和外部端点的之间的通信。</p><p>和其他服务网格相比，NSM 工作在另一个不同的网络层。VMware 形容 NSM“专注于连接”。GitHub 的文档[5]演示了 NSM 是如何与 Envoy协同工作的。</p><p><strong>AWS App Mesh</strong></p><p>AWS APP Mesh 为开发者提供了“适用于不同服务的应用层的网络”。它接管了服务的所有网络流量，使用开源的 Envoy 代理去控制容器的流量出入。AWS App Mesh 支持 HTTP/2 gRPC。</p><p>AWS App Mesh 对于那些已经将容器平台深度绑定 AWS 的公司而言，会是相当不错的服务网格方案。AWS 平台包括 AWS Fargate，Amazon Elastic Container Service，Amazon Elastic Kubernetes Service（EKS），Amazon Elastic Compute Cloud（EC2），Kubernetes on EC2，包括 AWS App Mesh 不需要付额外费用。</p><p>AWS App Mesh 和 AWS 生态内的监控工具无缝兼容。这些工具包括 CloudWatch 和 AWS X-Ray，以及一些来自第三方供应商的工具。因为 AWS 计算服务支持 AWS Outposts，AWS App Mesh 可以和混合云和已经部署的应用良好兼容。</p><p>AWS App Mesh 的缺点可能是使得开发者深度绑定了单一供应商方案，相对闭源，可扩展性缺失。</p><p><strong>OpenShift Service Mesh by Red Hat</strong></p><p>OpenShift 是来自红帽的一款帮助用户“连接、管理、观测微服务应用”的容器管理平台。OpenShift 预装了不少提升企业能力的组件，也被形容为企业级的混合云 Kubernetes 平台。</p><p>OpenShift Service Mesh 基于开源的 Istio 构建，具备 Isito 的控制平面和数据平面等特性。OpenShift 利用两款开源工具来增强 Isito 的追踪能力和可观测性。OpenShift 使用 Jaeger 实现分布式追踪，更好地跟踪请求是如何在服务间调用处理的。</p><p>另一方面，OpenShift 使用了 Kiali 来增强微服务配置、流量监控、跟踪分析等方面的可观测性。</p><h2><span id="如何选择">如何选择</span></h2><p>正如文中所提到的，可供选择的服务网格方案[6]有很多，同时还有新的方案在涌现。当然，每一种方案在技术实现上都略有不同。选择一款合适的服务网格，主要考虑的因素包括，你能接受它带来多大的侵入性，它的安全性如何，以及平台成熟度等。</p><p>以下几点可以帮助 DevOps 团队选择一款适合他们场景的服务网格：</p><ul><li>是否依赖Envoy。Envoy 有一个活跃的社区生态。开源，同时是许多服务网格的底座。Envoy 具备的丰富特性使得其成为一个很难绕过的因素。</li><li>具体使用场景。服务网格为微服务而生。如果你的应用是一个单体的庞然大物，那你在服务网格上的投入可能达不到预期的收益。如果不是所有应用都部署在 Kubernetes，则应该优先考虑平台无关的方案。</li><li>现有容器管理平台。有些企业已经使用了特定供应商的生态来解决容器编排问题，例如 AWS 的 EKS，红帽的 OpenShift，Consul。沿袭原有的生态，可以继承并拓展原有的特性。而这些可能是开源方案所不能提供的。</li><li>所在行业。许多服务网格不是为特定行业专门设计的。Kuma 统一管理多个隔离服务网格的能力可能更适用于收到高度管制的金融行业。底层网络 telcos 和 ISPs 则更应该考虑 Network Service Mesh。</li><li>对可视化的要求。可观测性是服务网格的核心能力之一。考虑进一步定制和更深度能力的团队应该优先考虑 Istio 或 Consul。</li><li>是否遵循开发标准。遵循开发标准使得你的平台更具备前瞻性和可扩展性。这使得企业会倾向于采用支持 SMI 的方案，Maesh 或其他基金会孵化的项目如 Linkerd。</li><li>是否重视用户体验。考虑运维人员的易用性是评判新工具的关键指标。这方 Linkerd 似乎在开发者中间口碑不错。</li><li>团队准备。评估你的团队所具备的资源和技术储备，在技术选型时决定你们适合用基于 Envoy 的 Istio，或是供应商抽象封装的方案，例如 OpenShift。</li></ul><p>这些考虑因素没有覆盖到全部场景。此处仅是抛砖引玉，引起读者的思考。希望读完上面所列的服务网格清单，和相关的决策因素之后，你们的团队能找到新的方法去改善微服务应用的网络特性。</p><p>相关链接：</p><ol><li><a href="https://techbeacon.com/app-dev-testing/3-reasons-why-you-should-always-run-microservices-apps-containers" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/3-reasons-why-you-should-always-run-microservices-apps-containers</a></li><li><a href="https://buoyant.io/service-mesh-manifesto/" target="_blank" rel="noopener">https://buoyant.io/service-mesh-manifesto/</a></li><li><a href="https://docs.mae.sh/quickstart/" target="_blank" rel="noopener">https://docs.mae.sh/quickstart/</a></li><li><a href="https://github.com/go-chassis/go-chassis" target="_blank" rel="noopener">https://github.com/go-chassis/go-chassis</a></li><li><a href="https://github.com/networkservicemesh/examples/tree/master/examples/envoy_interceptor" target="_blank" rel="noopener">https://github.com/networkservicemesh/examples/tree/master/examples/envoy_interceptor</a></li><li><a href="https://techbeacon.com/app-dev-testing/make-your-app-architecture-cloud-native-service-mesh" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/make-your-app-architecture-cloud-native-service-mesh</a></li></ol><p>原文链接：<a href="https://techbeacon.com/app-dev-testing/9-open-source-service-meshes-compared" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/9-open-source-service-meshes-compared</a></p><blockquote><p>本文转载自：「  分布式实验室 」，原文：<a href="https://tinyurl.com/4xsy53bd" target="_blank" rel="noopener">https://tinyurl.com/4xsy53bd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;哪种服务网格最适合你的企业？近年来，Kubernetes 服务网格框架数量增加迅速，使得这成为一个棘手的问题。&lt;/p&gt;
&lt;p&gt;下面将介绍 9 种较受欢迎的用以支撑微服务开发的服务网格框架，每种方案都给出了其适用场景。&lt;/p&gt;
&lt;h2 id=&quot;什么是服务网格&quot;&gt;什么是服务网格&lt;/h2&gt;
&lt;p&gt;服务网格近年来有很高的话题度，背后的原因是什么？&lt;/p&gt;
&lt;p&gt;微服务已经成为一种灵活快速的开发方式。然而，随着微服务数量成倍数地增长，开发团队开始遇到了部署和扩展性上的问题。&lt;/p&gt;
&lt;p&gt;容器和 Kubernetes 这样的容器编排系统 ，将运行时和服务一起打包进镜像，调度容器到合适的节点，运行容器。这个方案可以解决开发团队遇到的不少问题[1]。然而，在这个操作流程中仍存在短板：如何管理服务间的通信。&lt;/p&gt;
&lt;p&gt;在采用服务网格的场景下，以一种和应用代码解耦的方式，增强了应用间统一的网络通信能力。服务网格扩展了集群的管理能力，增强可观测性、服务发现、负载均衡、IT 运维监控及应用故障恢复等功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Istio" scheme="https://www.hi-linux.com/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>超给力，一款简单又实用的免费 GitHub 加速神器</title>
    <link href="https://www.hi-linux.com/posts/8698.html"/>
    <id>https://www.hi-linux.com/posts/8698.html</id>
    <published>2021-08-25T01:00:00.000Z</published>
    <updated>2021-08-25T02:41:30.820Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天给大家推荐一个堪称 GitHub 加速神器的开源项目。</p><p>这个开源项目就是：<strong>FastGitHub</strong>，它主要解决 GitHub 打不开、用户头像无法加载、releases 无法上传下载、git-clone、git-pull、git-push 失败等问题。</p><p>该项目的好处就是专门针对 GitHub 访问速度慢的问题，具有合法性，可靠性，稳定性。最重要的是它是免费的，而且不需要外网服务器资源。</p><h2><span id="fastgithub-加速原理">FastGitHub 加速原理</span></h2><ul><li>修改本机的 <code>DNS</code> 服务指向 FastGithub 自身</li><li>解析匹配的域名为 <code>FastGithub</code> 自身的 IP</li><li>请求安全 <code>DNS</code> 服务 (<code>dnscrypt-proxy</code>) 获取相应域名的 <code>IP</code></li><li>选择最优的 <code>IP</code> 进行 <code>SSH</code> 或 <code>HTTPS</code> 反向代理</li></ul><blockquote><ul><li><p>开源项目地址：<a href="https://github.com/dotnetcore/FastGithub" target="_blank" rel="noopener">https://github.com/dotnetcore/FastGithub</a></p></li><li><p>开源项目作者：.NET Core Community</p></li></ul></blockquote><h2><span id="使用方法">使用方法</span></h2><h3><span id="1-安装-fastgithub">1. 安装 FastGithub</span></h3><h4><span id="本地环境安装">本地环境安装</span></h4><p>运行 <code>FastGithub</code> 程序，本机的网络适配器的 <code>DNS</code> 会自动变成 127.0.0.1。</p><p>如果网络适配器的 <code>DNS</code> 没有变成 <code>127.0.0.1</code>，请手工修改网络适配器的 <code>DNS</code>。</p><blockquote><p>注： Linux 和 macOS 系统需要手动修改。</p></blockquote><h4><span id="局域网服务器安装推荐">局域网服务器安装(推荐)</span></h4><ul><li>在 Linux 服务器上运行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ yum install libicu # 安装依赖包</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;dotnetcore&#x2F;FastGithub&#x2F;releases&#x2F;download&#x2F;1.1.8&#x2F;FastGithub_linux-x64.zip</span><br><span class="line">$ unzip FastGithub_linux-x64.zip</span><br><span class="line">$ cd  FastGithub_linux-x64</span><br><span class="line">$ .&#x2F;FastGithub</span><br></pre></td></tr></table></figure><ul><li>在 Windows 服务器上运行</li></ul><p>以管理员身份运行 <code>cmd</code>，键入如下命令，其中 <code>D:\Softs</code> 为软件实际目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\Softs\FastGithub.exe start &#x2F;&#x2F; 以 Windows 服务安装并启动</span><br><span class="line">D:\Softs\FastGithub.exe stop &#x2F;&#x2F; 卸载并删除 Windows 服务</span><br></pre></td></tr></table></figure><h3><span id="2-使用-fastgithub">2. 使用 FastGithub</span></h3><p>FastGithub 安装完成后， 通过浏览器访问 <code>http://127.0.0.1</code> 或 <code>https://127.0.0.1</code> 以及所在机器的其它 IP 进入 FastGithub 的 Dashboard。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210824134508736-2021-08-24-HDI4u9.png" alt></p><p>接下来，根据实际情况按 <code>Dashboard</code> 页面的提示进行简单设置后，便可高速访问 Github。</p><ol><li>手工修改你电脑的 <code>DNS</code> 服务器的 IP 为 <code>127.0.0.1</code> 或局域网服务器的 <code>IP</code>。</li><li>手工下载和安装 <code>FastGithub.cer</code> 到受信任的根证书颁发机构</li></ol><p><img src="https://img.hi-linux.com/staticfile/image-20210824135233117-2021-08-24-0EnZhv.png" alt></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;p&gt;今天给大家推荐一个堪称 GitHub 加速神器的开源项目。&lt;/p&gt;
&lt;p&gt;这个开源项目就是：&lt;strong&gt;FastGitHub&lt;/strong&gt;，它主要解决 GitHub 打不开、用户头像无法加载、releases
        
      
    
    </summary>
    
    
      <category term="GitHub" scheme="https://www.hi-linux.com/categories/GitHub/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>6 张图带你搞懂 CI/CD 流水线</title>
    <link href="https://www.hi-linux.com/posts/22785.html"/>
    <id>https://www.hi-linux.com/posts/22785.html</id>
    <published>2021-08-20T01:00:00.000Z</published>
    <updated>2021-08-20T08:11:43.614Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>在CI/CD和DevOps领域中，持续交付和持续部署是一个老生常谈的话题。持续集成这个术语最早是在1994年由Grady Booch提出。微服务提出者Martin Flower在2014年发表的论文《Microservice》中也对软件开发持续集成提供了可参考原则。持续集成是借助工具对软件项目进行持续的自动化的编译打包构建测试发布，来检查软件交付质量的一种行为。而持续部署是基于持续交付的优势自动将经过测试的代码推入生产环境的过程。下文从细节描述了持续集成和持续部署各阶段的关键步骤，以下是原文。</p></blockquote><p>本文将探讨CI（持续集成）/CD（持续部署）流程中的各个阶段；以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。</p><p>CI/CD流水线工作流包括CI/CD流程开始时所有阶段等一系列步骤，负责创建自动、连贯的软件交付模型。</p><p>通过CI/CD流水线，软件研发可以实现从代码签入、测试、构建和部署直至生产阶段都在流水线中向前推进。此概念之所以高大上，是因为一旦实施了流水线，就可以将其部分或全部自动化，从而加快开发流程并减少错误。换句话说，CI/CD流水线使企业可以更轻松地应对软件的自动、快速、持续交付。</p><p>DevOps工程师经常会将CI/CD各阶段的和其CI/CD流水线混淆。尽管不同的工具可以将每个复杂阶段自动化完成分阶段的CI/CD，但是整体CI/CD软件链仍然可能由于不可避免的人工干预而中断。因此我们首先需要了解CI/CD流程中的各个阶段，以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。</p><a id="more"></a><h2><span id="cicd-阶段理解参与者-流程-技术">CI/CD 阶段：理解参与者、流程、技术</span></h2><p>企业应用程序开发参与者通常由开发人员，测试人员/QA工程师，运维工程师以及SRE（站点可靠性工程师）或IT运营团队组成。他们紧密合作，目标是高质量软件交付。CI/CD是两个独立过程的组合：持续集成和持续部署。下面列出了每个步骤中的主要步骤：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210616154923127-2021-06-16-Fyhe7J.png" alt></p><h2><span id="持续集成">持续集成</span></h2><p>持续集成（CI）是构建软件和完成初始测试的过程。持续部署（CD）是将代码与基础设施相结合的过程，确保完成所有测试并遵循策略，然后将代码部署到预期环境中。当然，许多公司也有自己特有流程，但主要步骤如下。</p><p><strong>CI：代码提交阶段</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616154929212-2021-06-16-5XICGL.png" alt></p><ul><li><p>参与者：开发工程师，数据库管理员（DBA），基础架构团队</p></li><li><p>技术：GitHub，GitLab，SVM，BitBucket</p></li><li><p>流程：代码提交阶段也称为版本控制。提交是将开发人员编写的最新代码变更发送到代码存储库的操作。开发人员编写的代码的每个版本都被无限期地存储。在与合作者讨论和审查变更之后，开发人员将编写代码，并在软件需求、特性增强、bug修复或变更请求完成后提交。管理编辑和提交变更的存储库称为源代码管理工具（配置管理工具）。在开发人员提交代码（代码推送请求）后，代码更改被合并到主线代码分支中，这些主线代码分支存储在GitHub这样的中央存储库中。</p></li></ul><p><strong>CI：静态代码检查阶段</strong></p><ul><li><p>参与者：开发工程师，数据库管理员（DBA），基础架构团队</p></li><li><p>技术：GitHub，GitLab，SVM，BitBucket</p></li><li><p>流程：开发人员编写代码并将其推送到存储库后，系统将自动触发以启动下一个代码分析过程。开发过程中存在这种情况：提交的代码可以构建成功，但在部署期间构建失败。无论从机器还是人力资源的利用率而言，这都是一个缓慢而昂贵的过程。因此必须检查代码中的静态策略。SAST（静态应用程序安全性测试）：SAST是一种白盒测试方法，可以使用SonarQube，Veracode，Appscan等SAST工具从内部检查代码，以发现软件缺陷，漏洞和弱点（例如SQL注入等）。这是一个快速检查过程，其中检查代码是否存在语法错误。尽管此阶段缺少检查运行时错误的功能，但该功能将在以后的阶段中执行。</p></li></ul><p>将额外的策略检查加入自动化流水线中可以显著减少流程中稍后发现的错误数量。</p><p><strong>CI：构建</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412585-2021-06-16-Ji7Bgv.png" alt></p><ul><li><p>参与者：开发工程师</p></li><li><p>技术：Jenkins，Bamboo CI，Circle CI，Travis CI，Maven，Azure DevOps</p></li><li><p>流程：持续集成过程的目标是提交的代码持续构建为二进制文件或构建产物。通过持续集成来检查添加的新模块是否与现有模块兼容，不仅有助于更快地发现bug，还有助于减少验证新代码更改的时间。构建工具可以根据几乎所有编程语言的源代码创建可执行文件或包（.exe，.dll，.jar等）。在构建过程中，还可以生成SQL脚本，配合基础设施配置文件一起进行测试。简而言之，构建阶段就是编译应用程序的阶段。Artifactory存储、构建验证测试和单元测试也可以作为构建过程的一部分。</p></li></ul><p>构建验证测试（BVT）/冒烟测试/单元测试：</p><p>创建构建后立即执行冒烟测试。BVT将检查所有模块是否正确集成，以及程序的关键功能是否正常运行。这样做的目的是拒绝严重损坏的应用程序，以使QA团队不会在安装和测试软件应用程序步骤浪费时间。</p><p>在完成这些检查后，将向流水线中执行UT（单元测试），以进一步减少生产中的故障。单元测试可验证开发人员编写的单个单元或组件是否按预期执行。</p><p>构建产物存储：</p><p>一旦构建就绪，程序包就会存储在称为Artifactory或Repository工具的中央数据库。随着每天构建量的增加，跟踪所有构建产物也会变得愈加困难。因此，一旦生成并验证了构建产物，就将其发送到存储库进行存储管理。诸如Jfrog Artifactory之类的存储库工具可用于存储诸如.rar，.war，.exe，Msi等之类的二进制文件。测试人员可以从此处手动进行选择，并在测试环境中部署构建产物以进行测试。</p><p><strong>CI：测试阶段</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412605-2021-06-16-52oF9C.png" alt></p><ul><li><p>参与者：测试人员、QA</p></li><li><p>技术：Selenium，Appium，Jmeter，SOAP UI，Tarantula</p></li><li><p>过程：发布构建过程后的一系列自动测试将验证代码的准确性。此阶段可帮助避免生产中的错误。根据构建的大小，此检查可能持续数秒至数小时。对于由多个团队提交和构建代码的大型组织，这些检查在并行环境中运行，以节省宝贵的时间并尽早将错误通知开发人员。</p></li></ul><p>测试人员（或称为QA工程师）基于用户描述的测试用例和场景设置自动化测试用例。他们执行回归分析、压力测试来检查与预期输出的偏差。测试中涉及的活动有完整性测试、集成测试、压力测试。这是一个高层次测试方法。在这个阶段，可以发现开发人员忽视的某些代码问题。</p><p>集成测试：</p><p>集成测试是使用Cucumber、Selenium等工具执行的，在这些工具中，单个应用程序模块被组合起来并作为一组进行测试，同时评估其是否符合指定的功能需求。在集成测试之后，需要有人批准该组中的更新集应该移到下一个阶段，这通常是性能测试。这个验证过程可能很麻烦，但它是整个过程的一个重要部分。验证这个过程业界有很多优秀的方案。</p><p>性能和压力测试：</p><p>Selenium、JMeter等自动化测试工具也可执行性能和压力测试，以检查应用程序在面对高负载时是否稳定和性能良好。该测试流程通常不会在每个更新提交上运行，因为完整的压力测试是长期运行的。当发布主要的新功能时，将对多个更新进行分组，并完成完整的性能测试。在单个更新被转移到下一阶段的情况下，流水线可能将金丝雀测试加入作为可选。</p><h2><span id="持续部署bake和部署">持续部署：Bake和部署</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412635-2021-06-16-lr0ZjG.png" alt></p><ul><li><p>参与者：基础架构工程师，SRE，运维工程师</p></li><li><p>技术：Spinnaker，Argo CD，Tekton CD</p></li><li><p>过程：在测试阶段完成之后，可以部署到服务器的标准代码准备就绪。在部署到生产中之前，它们将被部署到产品团队内部使用的测试环境或beta环境。在将构建移至这些环境之前，构建必须经过Bake和Deploy的子阶段。这两个阶段都是Spinnaker所支持存在的。</p></li></ul><p><strong>CD：Bake</strong></p><p>Baking是指在生产时使用当前配置从源代码创建不可变的镜像实例。这些配置可能是数据库更改和其他基础结构更新之类的事情。Spinnaker可以触发Jenkins执行此任务，并且某些组织更喜欢使用Packer。</p><p><strong>CD：部署</strong></p><p>Spinnaker自动将已bake的镜像发送到部署阶段。这是将服务器组设置为部署到集群的位置。与上述测试过程类似，在部署阶段将执行功能相同的过程。首先将部署移至测试阶段，然后最终移至生产环境，以进行批准和检查。这个处理过程可以由Spinnaker等工具支持。</p><p><strong>CD：验证</strong></p><p>这也是团队优化整个CI/CD流程的关键位置。因为现在已经进行了如此多的测试，所以失败很少见。但是，此时必须尽快解决所有故障，以最大程度地减少对最终客户的影响。团队也应该考虑使流程的这一部分自动化。</p><p>使用蓝绿部署、金丝雀分析、滚动更新等策略部署到产品。在部署阶段，将监视正在运行的应用程序以验证当前部署是否正确或是否需要回滚。</p><p><strong>CD：监控</strong></p><ul><li><p>参与者：站点可靠性工程师（SRE）、运营团队</p></li><li><p>技术：Zabbix、Nagios、Prometheus、Elastic Search、Splunk、Appdynamics、Tivoli</p></li><li><p>过程：为了使软件发行版具有故障安全性和健壮性，在生产环境中跟踪发行版的运行状况至关重要。应用程序监视工具将跟踪性能指标，例如CPU利用率和发行版延迟。日志分析器将扫描由底层中间件和操作系统产生的大量日志，以识别行为并跟踪问题的根源。如果生产中出现任何问题，将通知利益相关者以确保生产环境的安全性和可靠性。此外，监视阶段可帮助组织收集有关其新软件更改如何为收入贡献的情报，帮助基础设施团队跟踪系统行为趋势并进行容量规划。</p></li></ul><h2><span id="持续交付cd反馈和协作工具">持续交付（CD）：反馈和协作工具</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210616154942237-2021-06-16-o4hfIX.png" alt></p><ul><li><p>参与者：站点可靠性工程师（SRE）、运营和维护团队。</p></li><li><p>技术：JIRA、ServiceNow、Slack、电子邮件、Hipchat。</p></li><li><p>过程：DevOps团队的目标是更快地持续发布，然后不断减少错误和性能问题。这是通过不时地通过发送电子邮件向开发人员、项目经理提供有关新版本的质量和性能的反馈。通常情况下，反馈系统是整个软件交付过程的一部分。因此，交付中的任何更改都会频繁地录入系统，以便交付团队可以对它采取行动。</p></li></ul><h2><span id="总结">总结</span></h2><p>企业必须评估一个整体的持续交付解决方案，该解决方案可以自动化或促进上述这些阶段的自动化。</p><p>原文链接：<a href="https://www.opsmx.com/blog/what-is-a-ci-cd-pipeline/" target="_blank" rel="noopener">https://www.opsmx.com/blog/what-is-a-ci-cd-pipeline/</a></p><blockquote><p>本文转载自：「 分布式实验室 」，原文：<a href="https://tinyurl.com/5dtbbk3x" target="_blank" rel="noopener">https://tinyurl.com/5dtbbk3x</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在CI/CD和DevOps领域中，持续交付和持续部署是一个老生常谈的话题。持续集成这个术语最早是在1994年由Grady Booch提出。微服务提出者Martin Flower在2014年发表的论文《Microservice》中也对软件开发持续集成提供了可参考原则。持续集成是借助工具对软件项目进行持续的自动化的编译打包构建测试发布，来检查软件交付质量的一种行为。而持续部署是基于持续交付的优势自动将经过测试的代码推入生产环境的过程。下文从细节描述了持续集成和持续部署各阶段的关键步骤，以下是原文。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文将探讨CI（持续集成）/CD（持续部署）流程中的各个阶段；以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。&lt;/p&gt;
&lt;p&gt;CI/CD流水线工作流包括CI/CD流程开始时所有阶段等一系列步骤，负责创建自动、连贯的软件交付模型。&lt;/p&gt;
&lt;p&gt;通过CI/CD流水线，软件研发可以实现从代码签入、测试、构建和部署直至生产阶段都在流水线中向前推进。此概念之所以高大上，是因为一旦实施了流水线，就可以将其部分或全部自动化，从而加快开发流程并减少错误。换句话说，CI/CD流水线使企业可以更轻松地应对软件的自动、快速、持续交付。&lt;/p&gt;
&lt;p&gt;DevOps工程师经常会将CI/CD各阶段的和其CI/CD流水线混淆。尽管不同的工具可以将每个复杂阶段自动化完成分阶段的CI/CD，但是整体CI/CD软件链仍然可能由于不可避免的人工干预而中断。因此我们首先需要了解CI/CD流程中的各个阶段，以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevOps" scheme="https://www.hi-linux.com/categories/DevOps/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="DevOps" scheme="https://www.hi-linux.com/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>如何有效的在 60 秒内进行 Linux 服务器性能故障分析</title>
    <link href="https://www.hi-linux.com/posts/21098.html"/>
    <id>https://www.hi-linux.com/posts/21098.html</id>
    <published>2021-08-18T01:00:00.000Z</published>
    <updated>2021-08-18T02:23:32.294Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>感谢前辈，光荣属于前辈。</p></blockquote><p>掌握一些性能优化工具和方法，这就需要在工作中不断地积累；计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。</p><p>虽然监控工具可以帮助我们解决大多数问题，但我们有时需要登录实例并运行一些标准的 Linux 性能工具。</p><blockquote><p>来看 Netflix 性能工程团队的这篇博文：<a href="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55" target="_blank" rel="noopener">https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55</a></p></blockquote><p>看他们通过十条命令在一分钟内对机器性能问题进行诊断。在 60 秒内，您可以通过运行以下十个命令，对系统资源使用情况和正在运行的进程有一个高层次的了解。寻找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。饱和是指资源的负载超出其处理能力的情况，可以作为请求队列的长度或等待时间来公开。</p><a id="more"></a><p>当我们把 Linux 操作系统所有的关键一级计数器找完之后，就会得到这样一张图：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210722112925483-2021-07-22-hI8hui.jpg" alt></p><p>这些命令的输出，有助于快速定位性能瓶颈。主要检查出图中标红的计数器，所有资源（CPU、内存、磁盘 IO 等）的利用率（utilization）、饱和度（saturation）和错误（error）度量，也就是 Brendan Gregg 提出的 USE 方法。</p><blockquote><p>The USE Method: <a href="https://www.brendangregg.com/usemethod.html" target="_blank" rel="noopener">https://www.brendangregg.com/usemethod.html</a></p></blockquote><p><img src="https://img.hi-linux.com/staticfile/640-20210722112925497-2021-07-22-I7bgnm.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">uptime</span><br><span class="line">dmesg | tail</span><br><span class="line">vmstat 1</span><br><span class="line">mpstat -P ALL 1</span><br><span class="line">pidstat 1</span><br><span class="line">iostat -xz 1</span><br><span class="line">free -m</span><br><span class="line">sar -n DEV 1</span><br><span class="line">sar -n TCP,ETCP 1</span><br><span class="line">top</span><br></pre></td></tr></table></figure><p>下面我们来逐一介绍下这些命令，有关这些命令更多的参数和说明，请参照命令的手册。</p><h2><span id="uptime">uptime</span></h2><p>这个命令可以快速查看机器的负载情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ uptime</span><br><span class="line">23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02</span><br></pre></td></tr></table></figure><ul><li><p>在 Linux 系统中，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的。这些数据可以让我们对系统资源使用有一个宏观的了解。</p></li><li><p>命令的输出分别表示 1 分钟、5 分钟、15 分钟的平均负载情况。通过这三个数据，可以了解服务器负载是在趋于紧张还是区域缓解。如果 1 分钟平均负载很高，而 15 分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查 CPU 资源都消耗在了哪里。反之，如果 15 分钟平均负载很高，1 分钟平均负载较低，则有可能是 CPU 资源紧张时刻已经过去。</p></li><li><p>上面例子中的输出，可以看见最近 1 分钟的平均负载非常高，且远高于最近 15 分钟负载，因此我们需要继续排查当前系统中有什么进程消耗了大量的资源。可以通过下文将会介绍的 vmstat、mpstat 等命令进一步排查。</p></li></ul><h2><span id="dmesg-tail">dmesg | tail</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg | tail</span><br><span class="line">[1880957.563150] perl invoked oom-killer: gfp_mask&#x3D;0x280da, order&#x3D;0, oom_score_adj&#x3D;0</span><br><span class="line">[...]</span><br><span class="line">[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child</span><br><span class="line">[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB</span><br><span class="line">[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.</span><br></pre></td></tr></table></figure><p>这将查看最近 10 条系统消息（如果有）。查找可能导致性能问题的错误。上面的示例包括 oom-killer 和 TCP 丢弃请求。不要错过这一步！dmesg 总是值得检查。这些日志可以帮助排查性能问题。</p><h2><span id="vmstat">vmstat</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vmstat 1</span><br><span class="line">procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line">r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line">34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0</span><br><span class="line">32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0</span><br><span class="line">32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0</span><br><span class="line">32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0</span><br><span class="line">32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。后面跟的参数 1，表示每秒输出一次统计信息，表头提示了每一列的含义，这里介绍一些和性能调优相关的列：</p><ul><li>r：等待在 CPU 资源的进程数量。这个数据比平均负载更加能够体现 CPU 负载情况，数据中不包含等待 IO 的进程。如果这个数值大于机器 CPU 核数，那么机器的 CPU 资源已经饱和。</li><li>free：系统可用内存数（以千字节为单位），如果剩余内存不足，也会导致系统性能问题。下文介绍到的 free 命令，可以更详细的了解系统内存的使用情况。</li><li>si, so：交换区写入和读取的数量。如果这个数据不为 0，说明系统已经在使用交换区（swap），机器物理内存已经不足。</li><li>us, sy, id, wa, st：这些都代表了 CPU 时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）、IO 等待时间（wait）和被偷走的时间（stolen，一般被其他虚拟机消耗）。</li></ul><p>上述这些 CPU 时间，可以让我们很快了解 CPU 是否处于繁忙状态。一般情况下，如果用户时间和系统时间相加非常大，CPU 处于忙于执行指令。如果 IO 等待时间很长，那么系统的瓶颈可能在磁盘 IO。示例命令的输出可以看见，大量 CPU 时间消耗在用户态，也就是用户应用程序消耗了 CPU 时间。这不一定是性能问题，需要结合 r 队列，一起分析。</p><h2><span id="mpstat-p-all-1">mpstat -P ALL 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ mpstat -P ALL 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015  _x86_64_ (32 CPU)</span><br><span class="line">07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle</span><br><span class="line">07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78</span><br><span class="line">07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99</span><br><span class="line">07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00</span><br><span class="line">07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00</span><br><span class="line">07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><p>该命令可以显示每个 CPU 的占用情况，如果有一个 CPU 占用率特别高，那么有可能是一个单线程应用程序引起的。</p><h2><span id="pidstat-1">pidstat 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ pidstat 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015    _x86_64_    (32 CPU)</span><br><span class="line"></span><br><span class="line">07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos&#x2F;0</span><br><span class="line">07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave</span><br><span class="line">07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java</span><br><span class="line">07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java</span><br><span class="line">07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java</span><br><span class="line">07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat</span><br><span class="line"></span><br><span class="line">07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave</span><br><span class="line">07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java</span><br><span class="line">07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java</span><br><span class="line">07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass</span><br><span class="line">07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>pidstat 命令输出进程的 CPU 占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个 JAVA 进程占用了将近 1600% 的 CPU 时间，既消耗了大约 16 个 CPU 核心的运算资源。</p><h2><span id="iostat-xz-1">iostat -xz 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ iostat -xz 1</span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.13    0.00    0.10    0.01    0.00   99.76</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.62    0.03    0.89     0.57     7.97    18.52     0.00    0.68    1.96    0.64   0.60   0.06</span><br><span class="line">vdb               0.00     0.02    0.00    0.38     0.05     2.64    14.12     0.00    0.84    0.46    0.84   0.54   0.02</span><br><span class="line">dm-0              0.00     0.00    0.00    0.40     0.01     2.75    13.62     0.00    0.98    0.37    0.98   0.35   0.01</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.25    0.00    0.00    0.00    0.00   99.75</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.00    0.00    1.00     0.00     4.00     8.00     0.00    0.00    0.00    0.00   1.00   0.10</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.00    0.00    0.00    0.00    0.00  100.00</span><br></pre></td></tr></table></figure><p>iostat 命令主要用于查看机器磁盘 IO 情况。该命令输出的列，主要含义是：</p><ul><li>r/s, w/s, rkB/s, wkB/s：分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。</li><li>await：IO 操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括 IO 等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。</li><li>avgqu-sz：向设备发出的请求平均数量。如果这个数值大于 1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。</li><li>%util：设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过 60，可能会影响 IO 性能（可以参照 IO 操作平均等待时间）。如果到达 100%，说明硬件设备已经饱和。</li></ul><p>如果显示的是逻辑设备的数据，那么设备利用率不代表后端实际的硬件设备已经饱和。值得注意的是，即使 IO 性能不理想，也不一定意味应用程序会出现性能问题，可以利用诸如预读取、写缓存等策略提升应用性能。</p><h2><span id="free-m">free –m</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ free -m</span><br><span class="line">            total       used       free     shared    buffers     cached</span><br><span class="line">Mem:        245998      24545     221453         83         59        541</span><br><span class="line">-&#x2F;+ buffers&#x2F;cache:      23944     222053</span><br><span class="line">Swap:            0          0          0</span><br></pre></td></tr></table></figure><p>free 命令可以查看系统内存的使用情况，-m 参数表示按照兆字节展示。最后两列分别表示用于 IO 缓存的内存数，和用于文件系统页缓存的内存数。需要注意的是，第二行 -/+ buffers/cache，看上去缓存占用了大量内存空间。这是 Linux 系统的内存使用策略，尽可能的利用内存，如果应用程序需要内存，这部分内存会立即被回收并分配给应用程序。因此，这部分内存一般也被当成是可用内存。如果可用内存非常少，系统可能会动用交换区（如果配置了的话），这样会增加 IO 开销（可以在 iostat 命令中体现），降低系统性能。</p><h2><span id="sar-n-dev-1">sar -n DEV 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n DEV 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015     _x86_64_    (32 CPU)</span><br><span class="line">12:16:48 AM     IFACE   rxpck&#x2F;s   txpck&#x2F;s    rxkB&#x2F;s    txkB&#x2F;s   rxcmp&#x2F;s   txcmp&#x2F;s  rxmcst&#x2F;s   %ifutil</span><br><span class="line">12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM     IFACE   rxpck&#x2F;s   txpck&#x2F;s    rxkB&#x2F;s    txkB&#x2F;s   rxcmp&#x2F;s   txcmp&#x2F;s  rxmcst&#x2F;s   %ifutil</span><br><span class="line">12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>sar 命令在这里可以查看网络设备的吞吐率。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。如示例输出中，eth0 网卡设备，吞吐率大概在 22 Mbytes/s，既 176 Mbits/sec，没有达到 1Gbit/sec 的硬件上限。</p><h2><span id="sar-n-tcpetcp-1">sar -n TCP,ETCP 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n TCP,ETCP 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015    _x86_64_    (32 CPU)</span><br><span class="line">12:17:19 AM  active&#x2F;s passive&#x2F;s    iseg&#x2F;s    oseg&#x2F;s</span><br><span class="line">12:17:20 AM      1.00      0.00  10233.00  18846.00</span><br><span class="line">12:17:19 AM  atmptf&#x2F;s  estres&#x2F;s retrans&#x2F;s isegerr&#x2F;s   orsts&#x2F;s</span><br><span class="line">12:17:20 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:17:20 AM  active&#x2F;s passive&#x2F;s    iseg&#x2F;s    oseg&#x2F;s</span><br><span class="line">12:17:21 AM      1.00      0.00   8359.00   6039.00</span><br><span class="line">12:17:20 AM  atmptf&#x2F;s  estres&#x2F;s retrans&#x2F;s isegerr&#x2F;s   orsts&#x2F;s</span><br><span class="line">12:17:21 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>sar 命令在这里用于查看 TCP 连接状态，其中包括：</p><ul><li>active/s：每秒本地发起的 TCP 连接数，既通过 connect 调用创建的 TCP 连接；</li><li>passive/s：每秒远程发起的 TCP 连接数，即通过 accept 调用创建的 TCP 连接；</li><li>retrans/s：每秒 TCP 重传数量；</li></ul><p>TCP 连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP 重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。重传会严重影响tcp的效率，可以使用Brendan Gregg开发的一个轻量级tcp重传抓取工具: tcpretrans。</p><h2><span id="top">top</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92</span><br><span class="line">Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie</span><br><span class="line">%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers</span><br><span class="line">KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java</span><br><span class="line"> 4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave</span><br><span class="line">66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top</span><br><span class="line"> 5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java</span><br><span class="line"> 4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java</span><br><span class="line">    1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init</span><br><span class="line">    2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd</span><br><span class="line">    3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd&#x2F;0</span><br><span class="line">    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker&#x2F;0:0H</span><br><span class="line">    6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker&#x2F;u256:0</span><br><span class="line">    8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched</span><br></pre></td></tr></table></figure><p>top 命令包含了前面好几个命令的检查的内容。比如系统负载情况（uptime）、系统内存使用情况（free）、系统 CPU 使用情况（vmstat）等。因此通过这个命令，可以相对全面的查看系统负载的来源。同时，top 命令支持排序，可以按照不同的列排序，方便查找出诸如内存占用最多的进程、CPU 占用率最高的进程等。但是，top 命令相对于前面一些命令，输出是一个瞬间值，如果不持续盯着，可能会错过一些线索。这时可能需要暂停 top 命令刷新，来记录和比对数据。</p><h2><span id="总结">总结</span></h2><p>排查 Linux 服务器性能问题还有很多工具，上面介绍的一些命令，可以帮助我们快速的定位问题。例如前面的示例输出，多个证据证明有 JAVA 进程占用了大量 CPU 资源，之后的性能调优就可以针对应用程序进行。</p><blockquote><p>本文转载自：「 运维开发故事 」，原文：<a href="https://tinyurl.com/rsyjhzhw" target="_blank" rel="noopener">https://tinyurl.com/rsyjhzhw</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;感谢前辈，光荣属于前辈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;掌握一些性能优化工具和方法，这就需要在工作中不断地积累；计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。&lt;/p&gt;
&lt;p&gt;虽然监控工具可以帮助我们解决大多数问题，但我们有时需要登录实例并运行一些标准的 Linux 性能工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;来看 Netflix 性能工程团队的这篇博文：&lt;a href=&quot;https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看他们通过十条命令在一分钟内对机器性能问题进行诊断。在 60 秒内，您可以通过运行以下十个命令，对系统资源使用情况和正在运行的进程有一个高层次的了解。寻找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。饱和是指资源的负载超出其处理能力的情况，可以作为请求队列的长度或等待时间来公开。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="性能分析" scheme="https://www.hi-linux.com/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Ventoy - 免格式化！超简单的『多合一』系统启动盘制作神器 (开源免费，多平台支持)</title>
    <link href="https://www.hi-linux.com/posts/50557.html"/>
    <id>https://www.hi-linux.com/posts/50557.html</id>
    <published>2021-08-11T01:00:00.000Z</published>
    <updated>2021-09-30T04:54:17.582Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>Ventoy：操作系统多合一的启动盘制作神器！</strong></p></blockquote><p>简单来说，<code>Ventoy</code> 是一个制作可启动 <code>U</code> 盘的开源工具。有了 <code>Ventoy</code> 你就无需反复地格式化 <code>U</code> 盘，你只需要把 <code>ISO</code>/<code>WIM</code>/<code>IMG</code>/<code>VHD(x)</code>/<code>EFI</code> 等类型的文件拷贝到 <code>U</code> 盘里面就可以启动了，无需其他操作。<br>你可以一次性拷贝很多个不同类型的镜像文件，<code>Ventoy</code> 会在启动时显示一个菜单来供你进行选择。</p><p><img src="https://img.hi-linux.com/staticfile/tools-ventoy-install-system-2021-08-04-8BhAbr.png" alt="好用的U盘装机神器"></p><h2><span id="工具介绍">工具介绍</span></h2><blockquote><p><strong>简单理解：分区一(PE) + 分区二(Images) = 不影响正常使用</strong></p></blockquote><p>目前已经测试了各类超过 <code>720+</code> 个镜像文件，可以在 <code>distrowatch.com</code> 网站上查看收录的的操作系统列表。</p><ul><li><code>100%</code> 开源且使用方便简单快速</li><li>可以安装在 <code>U</code> 盘/本地硬盘/<code>SSD</code>/<code>NVMe</code>/<code>SD</code> 卡等设备上</li><li>直接从 <code>ISO</code>/<code>WIM</code>/<code>IMG</code>/<code>VHD(x)</code>/<code>EFI</code> 文件启动且无需解开</li><li>支持 <code>MBR</code> 和 <code>GPT</code> 分区格式</li><li>支持数据持久化</li><li>支持 <code>Windows</code> 系统的自动安装部署</li><li>支持 <code>RHEL</code>/<code>CentOS</code>/<code>Ubuntu Server</code> 等 <code>Linux</code> 系统的自动安装部署</li><li>镜像分区支持 FAT32/exFAT/NTFS/UDF/XFS/Ext2(3)(4) 文件系统</li><li>支持超过 <code>4GB</code> 的 <code>ISO</code> 文件</li><li>支持插件扩展</li><li>支持向运行环境中插入文件</li><li>动态替换 <code>ISO</code> 文件中的原始启动配置文件</li><li>高度可定制化的主题风格和菜单</li><li>启动过程中支持 <code>U</code> 盘设置写保护</li><li>不影响 <code>U</code> 盘日常普通使用</li></ul><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">文件                         SHA-256                 发布日期      大小</span><br><span class="line">ventoy-1.0.48-windows.zip    6f0200b68xxx3f06d6b05    2021-08-01    12 MB</span><br><span class="line">ventoy-1.0.48-linux.tar.gz    7ca5ef89fxxx691c180b1    2021-08-01    14 MB</span><br><span class="line">ventoy-1.0.48-livecd.iso    a682ef252xxx2b474cda4    2021-08-01    46 MB</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/image-20210804123904706-2021-08-04-M4KwZv.png" alt></p><h2><span id="使用方式-windows">使用方式 - Windows</span></h2><blockquote><p><strong>简单介绍下，在 Windows 操作系统上面的使用方式！</strong></p></blockquote><ul><li><strong>[1] 下载工具并解压开</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 官方</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ventoy&#x2F;Ventoy&#x2F;releases</span><br><span class="line"></span><br><span class="line"># 天翼云</span><br><span class="line">https:&#x2F;&#x2F;cloud.189.cn&#x2F;t&#x2F;b2eMBrrmay2y</span><br></pre></td></tr></table></figure><ul><li>[2] 直接执行 <code>Ventoy2Disk.exe</code> 这个可执行文件<ul><li>注意在这里可以选择 <code>MBR</code>/<code>GPT</code> 的分区格式</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/tools-ventoy-install-system-01-2021-08-04-XR1bJe.png" alt="好用的U盘装机神器"></p><h2><span id="使用方式-linux">使用方式 - Linux</span></h2><blockquote><p><strong>简单介绍下，在 Linux 操作系统上面的使用方式！</strong></p></blockquote><ul><li><strong>[1] 下载工具并解压开</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 官方</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ventoy&#x2F;Ventoy&#x2F;releases</span><br><span class="line"></span><br><span class="line"># 天翼云</span><br><span class="line">https:&#x2F;&#x2F;cloud.189.cn&#x2F;t&#x2F;b2eMBrrmay2y</span><br></pre></td></tr></table></figure><ul><li>[2] 图形化安装方式<ul><li>注意在这里可以选择 <code>MBR</code>/<code>GPT</code> 的分区格式</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 打开终端执行</span><br><span class="line">$ sudo sh VentoyWeb.sh -H 192.168.0.100 -P 8080</span><br><span class="line"></span><br><span class="line"># 打开浏览器直接访问</span><br><span class="line">http:&#x2F;&#x2F;192.168.0.100:8080</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/tools-ventoy-install-system-02-2021-08-04-oPXtw6.png" alt="好用的U盘装机神器"></p><ul><li>[3] 命令行安装方式<ul><li>注意在这里可以选择 <code>MBR</code>/<code>GPT</code> 的分区格式</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 对应的U盘设备名称</span><br><span class="line">$ sudo sh Ventoy2Disk.sh -i &#x2F;dev&#x2F;XXX</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 命令使用帮助</span><br><span class="line">Ventoy2Disk.sh  命令  [选项]  &#x2F;dev&#x2F;XXX</span><br><span class="line">  命令含义:</span><br><span class="line">    -i   安装ventoy到磁盘中 (如果对应磁盘已经安装了ventoy则会返回失败)</span><br><span class="line">    -I   强制安装ventoy到磁盘中，(不管原来有没有安装过)</span><br><span class="line">    -u   升级磁盘中的ventoy版本</span><br><span class="line">    -l   显示磁盘中的ventoy相关信息</span><br><span class="line"></span><br><span class="line">  选项含义: (可选)</span><br><span class="line">    -r SIZE_MB  在磁盘最后保留部分空间，单位 MB (只在安装时有效)</span><br><span class="line">    -s          启用安全启动支持 (默认是关闭的)</span><br><span class="line">    -g          使用GPT分区格式，默认是MBR格式 (只在安装时有效)</span><br><span class="line">    -L          主分区（镜像分区）的卷标 (默认是 Ventoy)</span><br></pre></td></tr></table></figure><ul><li>[4] 拷贝镜像文件<ul><li>安装完成之后，<code>U</code> 盘会被分成两个分区</li><li>第 <code>1</code> 个分区为镜像分区，只需要把 <code>ISO</code>/<code>WIM</code> 等文件拷贝到这里面即可</li><li>第 <code>2</code> 个分区为 <code>EFI</code> 系统分区，用来保存 <code>UEFI</code> 模式下的启动文件以及 <code>Ventoy</code> 的其他文件</li></ul></li></ul><h2><span id="插件扩展">插件扩展</span></h2><blockquote><p><strong><code>Ventoy</code> 会为每一个插件定义一个 <code>json</code> 配置项用来设置与此插件功能相关的属性！</strong></p></blockquote><p>比如 <code>Ventoy</code> 的启动菜单你可能不太喜欢，如何自己定制主题吗？再比如 <code>Ventoy</code> 的界面字体你有可能不喜欢，那如何自定义启动菜单中显示的文字呢？又比如，我想在 <code>Ventoy</code> 中增加一些功能，比如自动安装系统，等等。这时，我们就可以使用自己写的，或者他人写的第三方插件来补全我们需要定制化的地方，上述所有问题都可以通过插件来解决。</p><p>所有的插件配置规则都放在 <code>ventoy.json</code> 文件中，此文件位于 <code>/ventoy</code> 目录下。插件其他相关的文件也都必须位于 <code>/ventoy</code> 目录下。这里的 <code>/ventoy</code> 目录是放在第 <code>1</code> 个分区，也就是放镜像文件的分区中（不是 <code>32MB</code> 的 <code>VTOYEFI</code> 分区）。这个分区在刚安装完 <code>Ventoy</code> 的时候是空的，什么都没有。<code>/ventoy</code> 目录和 <code>ventoy.json</code> 文件都是需要用户自己创建的。</p><table><thead><tr><th style="text-align:left">编号</th><th style="text-align:left">插件名称</th><th style="text-align:left">对应地址</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong>全局控制插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_control.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_control.html</a></td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong>文件列表插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_imagelist.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_imagelist.html</a></td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong>主题插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_theme.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_theme.html</a></td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong>菜单类型插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_menuclass.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_menuclass.html</a></td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong>菜单别名插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_menualias.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_menualias.html</a></td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><strong>自定义菜单插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_grubmenu.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_grubmenu.html</a></td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><strong>自动安装插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_autoinstall.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_autoinstall.html</a></td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><strong>文件注入插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_injection.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_injection.html</a></td></tr><tr><td style="text-align:left">9</td><td style="text-align:left"><strong>数据持久化插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_persistence.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_persistence.html</a></td></tr><tr><td style="text-align:left">10</td><td style="text-align:left"><strong>Wim 文件启动插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_wimboot.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_wimboot.html</a></td></tr><tr><td style="text-align:left">11</td><td style="text-align:left"><strong>Linux vDisk 启动插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_vtoyboot.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_vtoyboot.html</a></td></tr><tr><td style="text-align:left">12</td><td style="text-align:left"><strong>启动配置替换插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_bootconf_replace.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_bootconf_replace.html</a></td></tr><tr><td style="text-align:left">13</td><td style="text-align:left"><strong>密码插件</strong></td><td style="text-align:left"><a href="https://www.ventoy.net/cn/plugin_password.html" target="_blank" rel="noopener">https://www.ventoy.net/cn/plugin_password.html</a></td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 示例配置 - ventoy.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;control&quot;: [&#123; &quot;VTOY_DEFAULT_MENU_MODE&quot;: &quot;1&quot; &#125;, &#123; &quot;VTOY_FILT_DOT_UNDERSCORE_FILE&quot;: &quot;1&quot; &#125;],</span><br><span class="line"></span><br><span class="line">  &quot;theme&quot;: &#123;</span><br><span class="line">    &quot;file&quot;: &quot;&#x2F;ventoy&#x2F;theme&#x2F;blur&#x2F;theme.txt&quot;,</span><br><span class="line">    &quot;gfxmode&quot;: &quot;1920x1080&quot;</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  &quot;auto_install&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;image&quot;: &quot;&#x2F;ISO&#x2F;cn_windows_server_2012_r2_vl_x64_dvd_2979220.iso&quot;,</span><br><span class="line">      &quot;template&quot;: &quot;&#x2F;ventoy&#x2F;script&#x2F;windows_unattended.xml&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;image&quot;: &quot;&#x2F;000&#x2F;centos.iso&quot;,</span><br><span class="line">      &quot;template&quot;: &quot;&#x2F;ventoy&#x2F;script&#x2F;centos_kickstart.cfg&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="相关链接">相关链接</span></h2><ul><li><a href="https://www.ventoy.net/cn/index.html" target="_blank" rel="noopener">Ventoy 官方网站</a></li><li><a href="https://github.com/ventoy/Ventoy" target="_blank" rel="noopener">Ventoy 的 Github 地址</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/tvwdh62a" target="_blank" rel="noopener">https://tinyurl.com/tvwdh62a</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Ventoy：操作系统多合一的启动盘制作神器！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说，&lt;code&gt;Ventoy&lt;/code&gt; 是一个制作可启动 &lt;code&gt;U&lt;/code&gt; 盘的开源工具。有了 &lt;code&gt;Ventoy&lt;/code&gt; 你就无需反复地格式化 &lt;code&gt;U&lt;/code&gt; 盘，你只需要把 &lt;code&gt;ISO&lt;/code&gt;/&lt;code&gt;WIM&lt;/code&gt;/&lt;code&gt;IMG&lt;/code&gt;/&lt;code&gt;VHD(x)&lt;/code&gt;/&lt;code&gt;EFI&lt;/code&gt; 等类型的文件拷贝到 &lt;code&gt;U&lt;/code&gt; 盘里面就可以启动了，无需其他操作。&lt;br&gt;
你可以一次性拷贝很多个不同类型的镜像文件，&lt;code&gt;Ventoy&lt;/code&gt; 会在启动时显示一个菜单来供你进行选择。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/tools-ventoy-install-system-2021-08-04-8BhAbr.png&quot; alt=&quot;好用的U盘装机神器&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;工具介绍&quot;&gt;工具介绍&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;简单理解：分区一(PE) + 分区二(Images) = 不影响正常使用&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;目前已经测试了各类超过 &lt;code&gt;720+&lt;/code&gt; 个镜像文件，可以在 &lt;code&gt;distrowatch.com&lt;/code&gt; 网站上查看收录的的操作系统列表。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;100%&lt;/code&gt; 开源且使用方便简单快速&lt;/li&gt;
&lt;li&gt;可以安装在 &lt;code&gt;U&lt;/code&gt; 盘/本地硬盘/&lt;code&gt;SSD&lt;/code&gt;/&lt;code&gt;NVMe&lt;/code&gt;/&lt;code&gt;SD&lt;/code&gt; 卡等设备上&lt;/li&gt;
&lt;li&gt;直接从 &lt;code&gt;ISO&lt;/code&gt;/&lt;code&gt;WIM&lt;/code&gt;/&lt;code&gt;IMG&lt;/code&gt;/&lt;code&gt;VHD(x)&lt;/code&gt;/&lt;code&gt;EFI&lt;/code&gt; 文件启动且无需解开&lt;/li&gt;
&lt;li&gt;支持 &lt;code&gt;MBR&lt;/code&gt; 和 &lt;code&gt;GPT&lt;/code&gt; 分区格式&lt;/li&gt;
&lt;li&gt;支持数据持久化&lt;/li&gt;
&lt;li&gt;支持 &lt;code&gt;Windows&lt;/code&gt; 系统的自动安装部署&lt;/li&gt;
&lt;li&gt;支持 &lt;code&gt;RHEL&lt;/code&gt;/&lt;code&gt;CentOS&lt;/code&gt;/&lt;code&gt;Ubuntu Server&lt;/code&gt; 等 &lt;code&gt;Linux&lt;/code&gt; 系统的自动安装部署&lt;/li&gt;
&lt;li&gt;镜像分区支持 FAT32/exFAT/NTFS/UDF/XFS/Ext2(3)(4) 文件系统&lt;/li&gt;
&lt;li&gt;支持超过 &lt;code&gt;4GB&lt;/code&gt; 的 &lt;code&gt;ISO&lt;/code&gt; 文件&lt;/li&gt;
&lt;li&gt;支持插件扩展&lt;/li&gt;
&lt;li&gt;支持向运行环境中插入文件&lt;/li&gt;
&lt;li&gt;动态替换 &lt;code&gt;ISO&lt;/code&gt; 文件中的原始启动配置文件&lt;/li&gt;
&lt;li&gt;高度可定制化的主题风格和菜单&lt;/li&gt;
&lt;li&gt;启动过程中支持 &lt;code&gt;U&lt;/code&gt; 盘设置写保护&lt;/li&gt;
&lt;li&gt;不影响 &lt;code&gt;U&lt;/code&gt; 盘日常普通使用&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Ventoy" scheme="https://www.hi-linux.com/tags/Ventoy/"/>
    
  </entry>
  
</feed>
