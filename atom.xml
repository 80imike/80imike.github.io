<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>奇妙的 Linux 世界</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2021-09-23T01:21:22.698Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推荐一款超实用的查看容器系统资源真实使用情况的工具 topic</title>
    <link href="https://www.hi-linux.com/posts/36129.html"/>
    <id>https://www.hi-linux.com/posts/36129.html</id>
    <published>2021-09-23T01:00:00.000Z</published>
    <updated>2021-09-23T01:21:22.698Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>容器通过 cgroups 和 namespace 实现了资源的轻量级隔离和限制，但容器中的 /proc 文件实际上是宿主机的，因此在执行 top 命令查看容器运行信息时，部分指标显示不正确，例如启动时间、用户数、平均负载、cpu 使用率、内存使用率。</p><p>目前比较通用的解决方案是通过 lxcfs，将容器中相应的文件通过 fuse 劫持 read 调用，在打开时显示为容器信息，从而统一解决各种系统状态诊断工具的问题。</p><a id="more"></a><p>考虑到部署 lxcfs 有一定的成本，topic(top in container) 的思路则是改造 top 命令，去适配容器，读取容器中反映真实运行情况的系统文件，从而展示正确的容器运行信息，对于用户而言成本更低。</p><p>如下，在一个 1C 和 1Gi 的容器中运行 <code>stress --cpu 2</code>，通过 topic 和 top 查看容器的运行状态：</p><p><img src="https://img.hi-linux.com/staticfile/topic-2021-09-16-xCY4pd.png" alt="topic"></p><p><img src="https://img.hi-linux.com/staticfile/top-2021-09-16-5XrCD7.png" alt="top"></p><p>可以看到，topic 比较好的解决了容器运行信息的问题：</p><ul><li>topic 查看到的 CPU 使用率，其 us 为 99.8%，而 top 查看到的是 13.2%（实为宿主机的 us 信息）</li><li>topic 查看到的 Mem 是 1Gi，而 top 查看到的是 16Gi（实为宿主机的内存信息）</li><li>topic 查看到的 user 数是 11，而 top 查看到的 user 数是 1（实为宿主机的当前登录用户数）</li><li>topic 查看到的容器运行时间为 2days 10:35，而 top 查看到的是 20days 1:57（实为宿主机的运行时间）</li><li>topic 和 top 的进程相关信息显示基本一致。</li></ul><p>如果你需要使用，可以通过下面地址下载 topic 到容器中运行（记得加上执行权限）。</p><ol><li><p>下载地址：<a href="https://silenceshell-1255345740.cos.ap-shanghai.myqcloud.com/topic/topic" target="_blank" rel="noopener">https://silenceshell-1255345740.cos.ap-shanghai.myqcloud.com/topic/topic</a></p></li><li><p>项目地址：<a href="https://github.com/silenceshell/topic" target="_blank" rel="noopener">https://github.com/silenceshell/topic</a></p></li></ol><blockquote><p>本文转载自：「 Zlatan Eevee 」，原文：<a href="https://tinyurl.com/rxdb5n72" target="_blank" rel="noopener">https://tinyurl.com/rxdb5n72</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器通过 cgroups 和 namespace 实现了资源的轻量级隔离和限制，但容器中的 /proc 文件实际上是宿主机的，因此在执行 top 命令查看容器运行信息时，部分指标显示不正确，例如启动时间、用户数、平均负载、cpu 使用率、内存使用率。&lt;/p&gt;
&lt;p&gt;目前比较通用的解决方案是通过 lxcfs，将容器中相应的文件通过 fuse 劫持 read 调用，在打开时显示为容器信息，从而统一解决各种系统状态诊断工具的问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>5 个冷门但非常实用的 Kubectl 使用技巧，99% 的人都不知道</title>
    <link href="https://www.hi-linux.com/posts/11484.html"/>
    <id>https://www.hi-linux.com/posts/11484.html</id>
    <published>2021-09-13T01:00:00.000Z</published>
    <updated>2021-09-13T01:39:57.930Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>kubectl 是 K8s 官方附带的命令行工具, 可以方便的操作 K8s 集群. 这篇文章主要介绍一些 kubectl 的别样用法, 希望读者有一定基础的 K8s 使用经验.</p><p>有一篇文章也介绍了一些技巧, 写博客的时候正好搜到了, 正好也分享出来吧.</p><ul><li><a href="https://blog.flant.com/ready-to-use-commands-and-tips-for-kubectl/" target="_blank" rel="noopener">Ready-to-use commands and tips for kubectl</a></li></ul><h2><span id="打印当前使用的api">打印当前使用的API</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># kubectl 的主要作用就是与 ApiServer 进行交互, 而交互的过程, 我们可以通过下面的方式来打印, </span><br><span class="line"># 这个命令尤其适合调试自己的api接口时使用.</span><br><span class="line">$ kubectl get ns -v&#x3D;9</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/20210816195205-2021-08-23-FOJY7v.png" alt></p><a id="more"></a><h2><span id="按状态筛选容器以及删除">按状态筛选容器以及删除</span></h2><p>这是我在这里学到的命令: <a href="https://computingforgeeks.com/force-delete-evicted-terminated-pods-in-kubernetes/" target="_blank" rel="noopener">Force Delete Evicted / Terminated Pods in Kubernetes</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces --field-selector status.phase&#x3D;Pending -o json | \</span><br><span class="line">  jq &#39;.items[] | &quot;kubectl delete pods \(.metadata.name) -n \(.metadata.namespace)&quot;&#39; | \</span><br><span class="line">  xargs -n 1 bash -c</span><br><span class="line"></span><br><span class="line"># 这个命令要拆开来看</span><br><span class="line"># 首先, 获取所有 ns 中状态为 Pending 的 pods, 并以 json 形式输出</span><br><span class="line"># 这个语句其实由很多变体, 比如,我想查找 Failed 的状态, 或是某个 deployment</span><br><span class="line"></span><br><span class="line">kubectl get pods --all-namespaces --field-selector status.phase&#x3D;Pending -o json </span><br><span class="line"></span><br><span class="line"># 针对 json 变量进行处理, 生成可用的脚本</span><br><span class="line"># 这里是我想介绍的重点, 利用jq以及kubectl的输出, 构建出可用的命令</span><br><span class="line">jq &#39;.items[] | &quot;kubectl delete pods \(.metadata.name) -n \(.metadata.namespace)&quot;&#39;</span><br><span class="line"></span><br><span class="line"># 执行每一条命令</span><br><span class="line"># 注意, 这种命令一定要好好调试, 删掉预期之外的pod就不好了.</span><br><span class="line">xargs -n 1 bash -c</span><br><span class="line"></span><br><span class="line"># 例如, 下面的语句可以找到所有的Pods并打印可以执行的语句</span><br><span class="line">$ kubectl get pods --all-namespaces --field-selector status.phase&#x3D;Running -o json | \</span><br><span class="line">  jq &#39;.items[] | &quot;kubectl get pods \(.metadata.name) -o wide -n \(.metadata.namespace)&quot;&#39;</span><br><span class="line"></span><br><span class="line">&quot;kubectl get pods metrics-server-6d684c7b5-gtd6q -o wide -n kube-system&quot;</span><br><span class="line">&quot;kubectl get pods local-path-provisioner-58fb86bdfd-98frc -o wide -n kube-system&quot;</span><br><span class="line">&quot;kubectl get pods nginx-deployment-574b87c764-xppmx -o wide -n default&quot;</span><br><span class="line"></span><br><span class="line"># 当然, 如果只是删除单个NS下面的一些pods, 我会选择下面的方法, 但是它操作多个NS就很不方便了.</span><br><span class="line">$ kubectl -n default get pods  | grep Completed | awk &#39;&#123;print $1&#125;&#39; | xargs kubectl -n default delete pods</span><br></pre></td></tr></table></figure><h2><span id="统计具体某台机器上运行的所有pod">统计具体某台机器上运行的所有pod</span></h2><blockquote><p>kubectl 可以使用两种选择器, 一种是 label, 一种是 field, 可以看官网的介绍:</p><ul><li><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">Labels and Selectors</a></li><li><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/" target="_blank" rel="noopener">Field Selectors</a></li></ul></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 它是一种选择器, 可以与上面的 awk 或者 xargs 配合使用.</span><br><span class="line"># 我个人平时都不喜欢用这个, 直接 get 全部 pods, 然后 grep 查找感觉更快</span><br><span class="line">$ kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName&#x3D;pve-node1</span><br></pre></td></tr></table></figure><h2><span id="统计-pod-在不同机器的具体数量分布">统计 Pod 在不同机器的具体数量分布</span></h2><p>不知道有读者看过我的这篇文章: <a href="https://corvo.myseu.cn/2021/04/30/2021-04-30-%E5%9F%BA%E4%BA%8Ekubernetes%E7%9A%84PaaS%E5%B9%B3%E5%8F%B0%E4%B8%AD%E7%BB%86%E5%8A%9B%E5%BA%A6%E6%8E%A7%E5%88%B6pod/" target="_blank" rel="noopener">基于 Kubernetes 的 PaaS 平台中细力度控制 pods 方案的实现</a>. 均衡分布的工作前提是得知pod在各个机器的分布情况. 最好的办法就是我们得到pod信息之后进行简单的统计, 这个工作可以使用<code>awk</code>实现.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n default get pods -o wide -l app&#x3D;&quot;nginx&quot; | awk &#39;&#123;print $7&#125;&#39;|\</span><br><span class="line"> awk &#39;&#123; count[$0]++  &#125; </span><br><span class="line"> END &#123; </span><br><span class="line">   printf(&quot;%-35s: %s\n&quot;,&quot;Word&quot;,&quot;Count&quot;);</span><br><span class="line">   for(ind in count)&#123;</span><br><span class="line">    printf(&quot;%-35s: %d\n&quot;,ind,count[ind]);</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;&#39;</span><br><span class="line"></span><br><span class="line"># 执行结果如下</span><br><span class="line">Word                               : Count</span><br><span class="line">NODE                               : 1</span><br><span class="line">pve-node1                          : 1</span><br><span class="line">pve-node2                          : 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># awk 的语法我没深入了解, 有兴趣的读者可以研究看看, 这里我就不求甚解了.</span><br></pre></td></tr></table></figure><h2><span id="kubectl-proxy-的使用">kubectl Proxy 的使用</span></h2><p>你可以理解为这个命令为 K8s 的 ApiServer 做了一层代理, 使用该代理, 你可以直接调用 API 而不需要经过鉴权. 启动之后, 甚至可以实现 <code>kubectl</code> 套娃, 下面是一个例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 当你没有设置 kubeconfig 而直接调用 kubectl 时</span><br><span class="line">$ kubectl get ns -v&#x3D;9</span><br><span class="line"># 可以打印出下面类似的错误</span><br><span class="line">$ curl -k -v -XGET  -H &quot;Accept: application&#x2F;json, *&#x2F;*&quot; -H &quot;User-Agent: kubectl&#x2F;v1.21.3 (linux&#x2F;amd64) kubernetes&#x2F;ca643a4&quot; &#39;http:&#x2F;&#x2F;localhost:8080&#x2F;api?timeout&#x3D;32s&#39;</span><br><span class="line">skipped caching discovery info due to Get &quot;http:&#x2F;&#x2F;localhost:8080&#x2F;api?timeout&#x3D;32s&quot;: dial tcp 127.0.0.1:8080: connect: connection refused                     </span><br><span class="line"># 也就是说当你不指定kubeconfig文件时, kubectl会默认访问本机的8080端口</span><br><span class="line"># 那么我们先启动一个kubectl proxy, 然后指定监听8080, 再使用kubectl直接访问, 是不是就可行了呢, </span><br><span class="line"># 事实证明, 安全与预想一致.</span><br><span class="line">$ KUBECONFIG&#x3D;~&#x2F;.kube&#x2F;config-symv3 kubectl proxy  -p 8080</span><br><span class="line">$ kubectl get ns</span><br><span class="line">NAME                           STATUS   AGE</span><br><span class="line">default                        Active   127d</span><br></pre></td></tr></table></figure><blockquote><p>默认启动的 Proxy 是屏蔽了某些 API  的, 并且有一些限制, 例如无法使用 exec 进入 pod 之中 可以使用 <code>kubectl proxy --help</code> 来看, 例如</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 仅允许本机访问</span><br><span class="line">--accept-hosts&#x3D;&#39;^localhost$,^127\.0\.0\.1$,^\[::1\]$&#39;: Regular expression for hosts that the proxy should accept.</span><br><span class="line"># 不允许访问下面的api, 也就是说默认没法exec进入容器</span><br><span class="line">--reject-paths&#x3D;&#39;^&#x2F;api&#x2F;.*&#x2F;pods&#x2F;.*&#x2F;exec,^&#x2F;api&#x2F;.*&#x2F;pods&#x2F;.*&#x2F;attach&#39;: Regular expression for paths that the proxy should reject. Paths specified here will be rejected even accepted by --accept-paths.</span><br><span class="line"></span><br><span class="line"># 想跳过 exec 的限制也很简单, 把 reject-paths 去掉就可以了</span><br><span class="line">$ kubectl proxy -p 8080 --keepalive 3600s --reject-paths&#x3D;&#39;&#39; -v&#x3D;9</span><br></pre></td></tr></table></figure><p>有人说这个 <code>kubectl proxy</code> 可能没什么作用, 那可能仅仅是你还没有实际的应用场景. 例如当我想要调试 <code>K8s Dashboard</code> 代码的时候. 如果直接使用 kubeconfig 文件, 我没法看到具体的请求过程, 如果你加上一层 Proxy 转发, 并且设置 <code>-v=9</code> 的时候, 你就自动获得了一个日志记录工具, 在调试时相当有用.</p><h2><span id="总结">总结</span></h2><p>kubectl 是一个强大的命令行工具, 上面我只是介绍了我工作中对其用法的一点探索, 也并不鼓励大家非要记住这些命令, 只是希望当读者需要的时候, 能够想起来 kubectl 可以有类似的功能, 就不需要针对几个临时需求去研读client-api 了.</p><blockquote><p>本文转载自：「 我的小米粥分你一半 」，原文：<a href="https://tinyurl.com/364wh2rk" target="_blank" rel="noopener">https://tinyurl.com/364wh2rk</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kubectl 是 K8s 官方附带的命令行工具, 可以方便的操作 K8s 集群. 这篇文章主要介绍一些 kubectl 的别样用法, 希望读者有一定基础的 K8s 使用经验.&lt;/p&gt;
&lt;p&gt;有一篇文章也介绍了一些技巧, 写博客的时候正好搜到了, 正好也分享出来吧.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.flant.com/ready-to-use-commands-and-tips-for-kubectl/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Ready-to-use commands and tips for kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;打印当前使用的API&quot;&gt;打印当前使用的API&lt;/h2&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# kubectl 的主要作用就是与 ApiServer 进行交互, 而交互的过程, 我们可以通过下面的方式来打印, &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 这个命令尤其适合调试自己的api接口时使用.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get ns -v&amp;#x3D;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/20210816195205-2021-08-23-FOJY7v.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款 GitHub 星标 11.5K 的命令行文件传输神器 transfer.sh（开源免费，支持 10GB 大文件）</title>
    <link href="https://www.hi-linux.com/posts/62383.html"/>
    <id>https://www.hi-linux.com/posts/62383.html</id>
    <published>2021-09-10T01:00:00.000Z</published>
    <updated>2021-09-11T11:02:08.100Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>互联网行业跳槽指南公布，你认可这个顺序吗？</strong></p></blockquote><p>在工作和生活中，我们经常需要在不同设备之间传输文件，但往往会遇到需要安装第三方软件、文件大小限制、传输速度慢等问题。安装第三方软件还好，但是限制传输速度和文件大小就非常恶心了，用着用着就得逼得你充值付费了。不然紧急需要传输一个东西，就非常花费时间和精力了。</p><h2><span id="软件介绍">软件介绍</span></h2><blockquote><p><strong>Easy and fast file sharing from the command-line.</strong></p></blockquote><p>当然，我们可以也使用，老牌的 <strong>百度云盘</strong>(非会员限速)、<strong>Dropbox</strong>(速度非常之慢)和 <strong>Google Drive</strong>(需要科学上网)，新进的 <strong>阿里云盘</strong>(虽然不限速但上传不能加速)、<strong>奶牛快传</strong>(有文件大小总量限制)。但是这里我们要介绍的是一个基于命令行的文件传输工具 —— <a href="https://github.com/dutchcoders/transfer.sh" target="_blank" rel="noopener"><strong><code>transfer.sh</code></strong></a>。</p><ul><li>Made for use with shell</li><li>Share files with a URL</li><li>For free</li><li>Upload up to 10 GB</li><li>Files stored for 14 days</li><li>Encrypt your files</li><li>Maximize amount of downloads</li></ul><h2><span id="使用方式">使用方式</span></h2><blockquote><p><strong>Sample use cases</strong></p></blockquote><ul><li><strong>[1] 命令行使用</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 将shell函数添加到.bashrc或.zshrc文件中</span><br><span class="line">transfer() &#123;</span><br><span class="line">  if [ $# -eq 0 ]; then</span><br><span class="line">    echo &quot;No arguments specified.&quot;</span><br><span class="line">    echo &quot;Usage: &quot;</span><br><span class="line">    echo &quot;  transfer &lt;file|directory&gt; ... | transfer &lt;file_name&gt;&quot;</span><br><span class="line">    return 1</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  if tty -s; then</span><br><span class="line">    file&#x3D;&quot;$1&quot;</span><br><span class="line">    file_name&#x3D;$(basename &quot;$file&quot;)</span><br><span class="line"></span><br><span class="line">    if [ ! -e &quot;$file&quot; ]; then</span><br><span class="line">      echo &quot;$file: No such file or directory&quot;</span><br><span class="line">      return 1</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    if [ -d &quot;$file&quot; ]; then</span><br><span class="line">      file_name&#x3D;&quot;$file_name.zip&quot;</span><br><span class="line">      (cd &quot;$file&quot; &amp;&amp; zip -r -q - .) | curl --progress-bar --upload-file &quot;-&quot; &quot;https:&#x2F;&#x2F;transfer.sh&#x2F;$file_name&quot; | tee &#x2F;dev&#x2F;null</span><br><span class="line">    else</span><br><span class="line">      cat &quot;$file&quot; | curl --progress-bar --upload-file &quot;-&quot; &quot;https:&#x2F;&#x2F;transfer.sh&#x2F;$file_name&quot; | tee &#x2F;dev&#x2F;null</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">  else</span><br><span class="line">    file_name&#x3D;&quot;$1&quot;</span><br><span class="line">    curl --progress-bar --upload-file &quot;-&quot; &quot;https:&#x2F;&#x2F;transfer.sh&#x2F;$file_name&quot;|tee &#x2F;dev&#x2F;null</span><br><span class="line">  fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 现在可以使用函数来上传文件</span><br><span class="line">$ transfer hello.txt</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 简单上传文件</strong> - <a href="https://transfer.sh/#" target="_blank" rel="noopener">官方支持界面上传</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 使用curl命令上传文件</span><br><span class="line">$ curl --upload-file .&#x2F;hello.txt https:&#x2F;&#x2F;transfer.sh&#x2F;hello.txt</span><br><span class="line">https:&#x2F;&#x2F;transfer.sh&#x2F;66nb8&#x2F;hello.txt</span><br><span class="line"></span><br><span class="line"># 上传文件设定最大下载次数和过期时间</span><br><span class="line">$ curl -H &quot;Max-Downloads: 1&quot; -H &quot;Max-Days: 5&quot; --upload-file .&#x2F;hello.txt https:&#x2F;&#x2F;transfer.sh&#x2F;hello.txt</span><br><span class="line">https:&#x2F;&#x2F;transfer.sh&#x2F;66nb8&#x2F;hello.txt</span><br><span class="line"></span><br><span class="line"># 下载文件</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;66nb8&#x2F;hello.txt -o hello.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 还支持wget上传文件</span><br><span class="line">$ wget --method PUT --body-file&#x3D;&#x2F;tmp&#x2F;file.tar https:&#x2F;&#x2F;transfer.sh&#x2F;file.tar -O - -nv</span><br><span class="line"></span><br><span class="line"># 还支持HTTPie上传文件</span><br><span class="line">$ http https:&#x2F;&#x2F;transfer.sh&#x2F; -vv &lt; &#x2F;tmp&#x2F;test.log</span><br><span class="line"></span><br><span class="line"># 还支持PowerShell上传文件</span><br><span class="line">PS H:\&gt; invoke-webrequest -method put -infile .\file.txt https:&#x2F;&#x2F;transfer.sh&#x2F;file.txt</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 一次上传多个文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 使用filedata执行文件地址</span><br><span class="line">$ curl -i -F filedata&#x3D;@&#x2F;tmp&#x2F;hello.txt -F filedata&#x3D;@&#x2F;tmp&#x2F;hello2.txt https:&#x2F;&#x2F;transfer.sh&#x2F;</span><br><span class="line"></span><br><span class="line"># 将下载合并为zip或tar存档</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;(15HKz&#x2F;hello.txt,15HKz&#x2F;hello.txt).tar.gz</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;(15HKz&#x2F;hello.txt,15HKz&#x2F;hello.txt).zip</span><br></pre></td></tr></table></figure><ul><li><strong>[4] 传输前使用加密您的文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用gpg加密文件</span><br><span class="line">$ cat &#x2F;tmp&#x2F;hello.txt | gpg -ac -o- | curl -X PUT --upload-file &quot;-&quot; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br><span class="line"></span><br><span class="line"># 下载并解密</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;1lDau&#x2F;test.txt | gpg -o- &gt; &#x2F;tmp&#x2F;hello.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用openssl加密文件</span><br><span class="line">$ cat &#x2F;tmp&#x2F;hello.txt | openssl aes-256-cbc -pbkdf2 -e | curl -X PUT --upload-file &quot;-&quot; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br><span class="line"></span><br><span class="line"># 下载并解密</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;1lDau&#x2F;test.txt | openssl aes-256-cbc -pbkdf2 -d &gt; &#x2F;tmp&#x2F;hello.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 从keybase导入key</span><br><span class="line">$ keybase track [them]</span><br><span class="line"></span><br><span class="line"># 加密文件</span><br><span class="line">$ cat somebackupfile.tar.gz | keybase encrypt [them] | curl --upload-file &#39;-&#39; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br><span class="line"></span><br><span class="line"># 解密下载</span><br><span class="line">$ curl https:&#x2F;&#x2F;transfer.sh&#x2F;sqUFi&#x2F;test.md | keybase decrypt</span><br></pre></td></tr></table></figure><ul><li><strong>[5] 扫描恶意软件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 使用Clamav扫描恶意软件或病毒</span><br><span class="line">$ wget http:&#x2F;&#x2F;www.eicar.org&#x2F;download&#x2F;eicar.com</span><br><span class="line">$ curl -X PUT --upload-file .&#x2F;eicar.com https:&#x2F;&#x2F;transfer.sh&#x2F;eicar.com&#x2F;scan</span><br><span class="line"></span><br><span class="line"># 上传恶意软件到VirusTotal并获得永久链接</span><br><span class="line">$ curl -X PUT --upload-file nhgbhhj https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt&#x2F;virustotal</span><br></pre></td></tr></table></figure><ul><li><strong>[6] 加密传输备份 mysql 数据库</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 备份+加密+传输</span><br><span class="line">$ mysqldump --all-databases | gzip | gpg -ac -o- | curl -X PUT --upload-file &quot;-&quot; https:&#x2F;&#x2F;transfer.sh&#x2F;test.txt</span><br></pre></td></tr></table></figure><ul><li><strong>[7] 发送带有传输链接的电子邮件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 传输和发送带有链接的电子邮件</span><br><span class="line">$ transfer &#x2F;tmp&#x2F;hello.txt | mail -s &quot;Hello World&quot; user@yourmaildomain.com</span><br></pre></td></tr></table></figure><ul><li><strong>[8] 传输日志文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># grep syslog for pound and transfer</span><br><span class="line">$ cat &#x2F;var&#x2F;log&#x2F;syslog | grep pound | curl --upload-file - https:&#x2F;&#x2F;transfer.sh&#x2F;pound.log</span><br></pre></td></tr></table></figure><h2><span id="参考链接">参考链接</span></h2><ul><li><a href="https://transfer.sh/#" target="_blank" rel="noopener">transfer.sh 官方网站</a></li><li><a href="https://github.com/dutchcoders/transfer.sh" target="_blank" rel="noopener">transfer.sh 的 Github 仓库地址</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/5chzpk9w" target="_blank" rel="noopener">https://tinyurl.com/5chzpk9w</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="终端" scheme="https://www.hi-linux.com/tags/%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>如何快速的在 Kubernetes 上部署云原生微服务网关 APISIX</title>
    <link href="https://www.hi-linux.com/posts/16167.html"/>
    <id>https://www.hi-linux.com/posts/16167.html</id>
    <published>2021-09-08T01:00:00.000Z</published>
    <updated>2021-09-08T09:42:27.518Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="几种常见网关的比较">几种常见网关的比较</span></h2><ul><li>Nginx, 模块化设计的反向代理软件，C 语言开发</li><li>OpenResty, 以 Nginx 为核心的 Web 开发平台，可以解析执行 Lua 脚本</li><li>Kong, OpenResty 的一个应用，是一个 API 网关，具有 API 管理和请求代理的功能，使用 PostgreSQL 存储</li><li>APISIX, 替换了 Kong 的 PostgreSQL 为 Etcd，基于 Nginx 的核心库实现</li></ul><p>APISIX 的优势在于提供了 API 的管理和扩展能力，让网关不再仅仅转发服务，而是可以被配置、定制化。相较于 Nginx，APISIX 使用的是动态路由，避免了配置之后 reload 产生的风险。同时，APISIX 支持 HTTP(S)、HTTP2、Dubbo、QUIC、MQTT、TCP/UDP 等更多的协议，具有更好的使用生态。</p><p><img src="https://img.hi-linux.com/staticfile/apisix-infras-20210906170155554-2021-09-06-eR1jIQ.webp" alt></p><p>上面是 APISIX 的架构图，数据面处理客户端请求，控制面管理路由。</p><a id="more"></a><h2><span id="apisix-能解决什么问题">APISIX 能解决什么问题</span></h2><ul><li>边缘路由</li></ul><p>机房对外暴露的访问入口 IP 数量，通常是极少的，但是却支撑了很多个服务。比如，访问的 IP 是 1.2.3.4，但却同时提供了 <a href="http://a.domain.com" target="_blank" rel="noopener">a.domain.com</a>、<a href="http://b.domain.com" target="_blank" rel="noopener">b.domain.com</a> 的访问服务。这就需要用到边缘路由，边缘路由会将不同域名的访问，转发到不同的内网地址。</p><p>APISIX 中三种方式可以注册边缘路由，dashboard、ingress-controller、admin api。</p><ul><li>基础网关能力</li></ul><p>网关的功能不限于转发流量，更重要的是限流、熔断等。</p><p>APISIX 内置了很多插件，提供 APM、日志、熔断、鉴权、证书管理、故障注入等功能。同时，也支持拖拽组合新的插件、开发新插件以满足业务需求。</p><ul><li>Serverless</li></ul><p>APISIX 通过插件的方式提供 Serverless，目前仅支持 Lua。但 APIGateway + Serverless 的组合，极具想象力。</p><p>利用 Serverless 可以快速对外提供无服务的 API，粘合各种服务，也可以对外直接提供功能服务。</p><ul><li>灰度发布</li></ul><p>由于对网关层进行了控制，APISIX 允许用户通过配置权重控制流量的转发行为，可以用来做灰度发布使用。</p><h2><span id="kubernetes-上安装-apisix">Kubernetes 上安装 APISIX</span></h2><h3><span id="1-添加-helm-源">1 添加 Helm 源</span></h3><ul><li>添加 Helm 源</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add apisix https:&#x2F;&#x2F;charts.apiseven.com</span><br><span class="line">$ helm repo update</span><br></pre></td></tr></table></figure><ul><li>查找 Chart 包</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ helm search repo apisix</span><br><span class="line"></span><br><span class="line">NAME                            CHART VERSIONAPP VERSIONDESCRIPTION</span><br><span class="line">apisix&#x2F;apisix                   0.3.5        2.7.0      A Helm chart for Apache APISIX</span><br><span class="line">apisix&#x2F;apisix-dashboard         0.1.5        2.7.0      A Helm chart for Apache APISIX Dashboard</span><br><span class="line">apisix&#x2F;apisix-ingress-controller0.5.0        1.0.0      Apache APISIX Ingress Controller for Kubernetes</span><br></pre></td></tr></table></figure><h3><span id="2-安装-apisix">2 安装 APISIX</span></h3><ul><li>安装 APISIX</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install apisix apisix&#x2F;apisix  --set gateway.type&#x3D;NodePort --set admin.allow.ipList&#x3D;&quot;&#123;0.0.0.0&#x2F;0&#125;&quot;  -n apisix --create-namespace</span><br></pre></td></tr></table></figure><ul><li>查看入口地址</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ export NODE_PORT&#x3D;$(kubectl get --namespace apisix -o jsonpath&#x3D;&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services apisix-gateway)</span><br><span class="line">$ export NODE_IP&#x3D;$(kubectl get nodes --namespace apisix -o jsonpath&#x3D;&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">$ echo http:&#x2F;&#x2F;$NODE_IP:$NODE_PORT</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;1.1.1.1:32462</span><br></pre></td></tr></table></figure><p>这里的入口地址是后端服务的入口地址，如果是生成环境，应该使用 LoadBalancer 提供的地址。</p><ul><li>查看 apisix-admin 接口 key</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ export POD_NAME&#x3D;$(kubectl get pods --namespace apisix -l &quot;app.kubernetes.io&#x2F;instance&#x3D;apisix,app.kubernetes.io&#x2F;name&#x3D;apisix&quot; -o jsonpath&#x3D;&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line"></span><br><span class="line">$ kubectl -n apisix exec -it $POD_NAME cat conf&#x2F;config.yaml |grep key </span><br><span class="line"></span><br><span class="line">  admin_key:</span><br><span class="line">      key: edd1c9f034335f136f87ad84b625c8f1</span><br><span class="line">      key: 4054f7cf07e344346cd3f287985e76a2</span><br></pre></td></tr></table></figure><p>第一个 key 是 admin，第二个 key 是 viewer。这里的 key 可以用来通过 admin api 来配置 APISIX，给其他系统集成 APISIX 提供了入口。</p><h3><span id="3-安装-dashboard">3 安装 Dashboard</span></h3><ul><li>安装 Dashboard</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install apisix-dashboard apisix&#x2F;apisix-dashboard -n apisix --create-namespace</span><br></pre></td></tr></table></figure><p>默认账户是：admin<br>默认密码是：admin</p><ul><li>查看 Dashboard 访问入口</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ export NODE_PORT&#x3D;$(kubectl get --namespace apisix -o jsonpath&#x3D;&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services apisix-gateway)</span><br><span class="line">$ export NODE_IP&#x3D;$(kubectl get nodes --namespace apisix -o jsonpath&#x3D;&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">$ echo http:&#x2F;&#x2F;$NODE_IP:$NODE_PORT</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;1.1.1.1:31501</span><br></pre></td></tr></table></figure><h3><span id="4-安装-ingress-controller">4 安装 ingress-controller</span></h3><ul><li>安装 ingress-controller</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install apisix-ingress-controller apisix&#x2F;apisix-ingress-controller   --set config.apisix.baseURL&#x3D;http:&#x2F;&#x2F;apisix-admin:9180&#x2F;apisix&#x2F;admin  --set config.apisix.adminKey&#x3D;edd1c9f034335f136f87ad84b625c8f1  -n apisix</span><br></pre></td></tr></table></figure><p>这里就会需要设置上面获取到的 admin key, 实际上 ingress-controller 也是通过调用 admin api 来配置路由的。</p><h2><span id="创建服务测试">创建服务测试</span></h2><p>前面提到 APISIX 通过 admin api 配置路由，有三种方式可以操作。这里主要验证使用 Dashboard 和 Ingress 两种方式：</p><ul><li>创建一个服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create deployment web --image&#x3D;gcr.io&#x2F;google-samples&#x2F;hello-app:1.0</span><br></pre></td></tr></table></figure><ul><li>暴露服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl expose deployment web --type&#x3D;NodePort --port&#x3D;8080</span><br></pre></td></tr></table></figure><ul><li>查看服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get service web</span><br><span class="line"></span><br><span class="line">NAME   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">web    NodePort   10.233.58.113   &lt;none&gt;        8080:30572&#x2F;TCP   28d</span><br></pre></td></tr></table></figure><h3><span id="1-dashboard-配置路由">1 Dashboard 配置路由</span></h3><ul><li>新建一个上游服务</li></ul><p>这里需要填入上面创建的集群访问地址：<code>web.default.svc.cluster.local</code></p><p><img src="https://www.chenshaowen.com/blog/images/2021/09/dashboard-apisix-1.png" alt></p><ul><li>新建一个路由</li></ul><p><img src="https://www.chenshaowen.com/blog/images/2021/09/dashboard-apisix-2.png" alt></p><p>点击下一步之后，选择上面创建的服务 web，相关的参数就会自动填充。</p><p><img src="https://www.chenshaowen.com/blog/images/2021/09/dashboard-apisix-3.png" alt></p><ul><li>访问测试</li></ul><p><img src="https://www.chenshaowen.com/blog/images/2021/09/ip-apisix.png" alt></p><h3><span id="2-ingress-配置路由">2 Ingress 配置路由</span></h3><ul><li>创建一个 ApisixRoute 路由</li></ul><p>虽然这里部署的是 ingress-controller 组件，但是使用时创建的是 ApisixRoute 对象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apisix.apache.org&#x2F;v1 </span><br><span class="line">kind: ApisixRoute </span><br><span class="line">metadata: </span><br><span class="line">  name: web-route </span><br><span class="line">spec:</span><br><span class="line">  http:</span><br><span class="line">  - name: web</span><br><span class="line">    match:</span><br><span class="line">      hosts:</span><br><span class="line">      - dev4.chenshaowen.com</span><br><span class="line">      paths:</span><br><span class="line">      - &quot;&#x2F;router-web&#x2F;*&quot;</span><br><span class="line">    backend:</span><br><span class="line">     serviceName: web</span><br><span class="line">     servicePort: 8080</span><br></pre></td></tr></table></figure><ul><li>访问测试</li></ul><p><img src="https://img.hi-linux.com/staticfile/domain-apisix-20210906170156087-2021-09-06-DNDSce.png" alt></p><ul><li>查看创建的路由</li></ul><p><img src="https://img.hi-linux.com/staticfile/ingress-apisix-router-20210906170156197-2021-09-06-OIIY5x.png" alt></p><p>可以发现路由是被 ingress-controller 接管的，人工不要编辑。</p><ul><li>查看服务</li></ul><p><img src="https://img.hi-linux.com/staticfile/ingress-apisix-svc-20210906170156309-2021-09-06-kxONs3.png" alt></p><p>可以看到服务主要是由四个后端提供。</p><ul><li>查看服务 Pod 的 IP</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod  -o wide</span><br><span class="line"></span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE   IP              NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">web-79d88c97d6-2sdlj   1&#x2F;1     Running   0          27d   10.233.105.34   node4   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web-79d88c97d6-7bfbb   1&#x2F;1     Running   0          27d   10.233.105.32   node4   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web-79d88c97d6-hccqk   1&#x2F;1     Running   0          27d   10.233.105.33   node4   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web-79d88c97d6-mh9gz   1&#x2F;1     Running   0          28d   10.233.105.22   node4   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>APISIX 会将 Pod 的 IP 地址直接作为流量后端，而不需要经过 Service 的转发，这有别于 Kubernetes 的服务转发、负载均衡机制。</p><h2><span id="总结">总结</span></h2><p>本文主要简述了几种网关的区别，思考了 APISIX 主要能帮助我们解决什么问题，最后在 Kubernetes 上进行了实践。内容如下：</p><ul><li>APISIX 是基于 Nginx 网络库实现的 API 网关应用，使用 Etcd 作为存储后端</li><li>APISIX 能作为边缘路由使用，其动态特性，避免了 Nginx reload 带来的抖动</li><li>APISIX 提供了 admin api 管理路由，有三种方式可以进行配置</li><li>Kubernetes 下的 APISIX 跳过了 Kubernetes Service 直接将流量转发到 Pod IP</li></ul><h2><span id="参考">参考</span></h2><ul><li><a href="https://github.com/apache/apisix" target="_blank" rel="noopener">https://github.com/apache/apisix</a></li><li><a href="https://bbs.huaweicloud.com/blogs/125686" target="_blank" rel="noopener">https://bbs.huaweicloud.com/blogs/125686</a></li><li><a href="https://github.com/apache/apisix-ingress-controller/blob/master/docs/en/latest/concepts/apisix_route.md" target="_blank" rel="noopener">https://github.com/apache/apisix-ingress-controller/blob/master/docs/en/latest/concepts/apisix_route.md</a></li></ul><blockquote><p>本文转载自：「 陈少文的网站 」，原文：<a href="https://tinyurl.com/yf9476mj" target="_blank" rel="noopener">https://tinyurl.com/yf9476mj</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;几种常见网关的比较&quot;&gt;几种常见网关的比较&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Nginx, 模块化设计的反向代理软件，C 语言开发&lt;/li&gt;
&lt;li&gt;OpenResty, 以 Nginx 为核心的 Web 开发平台，可以解析执行 Lua 脚本&lt;/li&gt;
&lt;li&gt;Kong, OpenResty 的一个应用，是一个 API 网关，具有 API 管理和请求代理的功能，使用 PostgreSQL 存储&lt;/li&gt;
&lt;li&gt;APISIX, 替换了 Kong 的 PostgreSQL 为 Etcd，基于 Nginx 的核心库实现&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;APISIX 的优势在于提供了 API 的管理和扩展能力，让网关不再仅仅转发服务，而是可以被配置、定制化。相较于 Nginx，APISIX 使用的是动态路由，避免了配置之后 reload 产生的风险。同时，APISIX 支持 HTTP(S)、HTTP2、Dubbo、QUIC、MQTT、TCP/UDP 等更多的协议，具有更好的使用生态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/apisix-infras-20210906170155554-2021-09-06-eR1jIQ.webp&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面是 APISIX 的架构图，数据面处理客户端请求，控制面管理路由。&lt;/p&gt;
    
    </summary>
    
    
      <category term="APISIX" scheme="https://www.hi-linux.com/categories/APISIX/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="APISIX" scheme="https://www.hi-linux.com/tags/APISIX/"/>
    
  </entry>
  
  <entry>
    <title>万字长文详解 PaaS toB 场景下 Kubernetes 离线部署方案</title>
    <link href="https://www.hi-linux.com/posts/27427.html"/>
    <id>https://www.hi-linux.com/posts/27427.html</id>
    <published>2021-09-01T01:00:00.000Z</published>
    <updated>2021-09-01T01:27:55.874Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在企业私有云环境当中，出于对数据安全的考虑以及满足 <a href="http://www.djbh.net/" target="_blank" rel="noopener">网络安全等级保护</a> 的要求，往往会对内部环境中的服务器做出严格的访问限制。一般来讲生产环境都会禁止访问外部网络，开发人员要访问生产环境也必须通过堡垒机或者其他方式进行安全审计登录。在这种无网（无法访问公网）的环境中，想要部署好一个 K8s 集群并不是一件轻松的事儿。市面上 K8s 部署工具也多不胜数，对于离线部署的支持情况也各不相同：</p><table><thead><tr><th style="text-align:left">Item</th><th style="text-align:left">Language</th><th style="text-align:left">Star</th><th style="text-align:left">Fork</th><th style="text-align:left">离线部署支持情况</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://github.com/kubernetes/kops" target="_blank" rel="noopener">kops</a></td><td style="text-align:left">Golang</td><td style="text-align:left">13.2k</td><td style="text-align:left">4.1k</td><td style="text-align:left">不支持</td></tr><tr><td style="text-align:left"><a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">Ansible</td><td style="text-align:left">11.1k</td><td style="text-align:left">4.7k</td><td style="text-align:left">支持，需自行构建安装包</td></tr><tr><td style="text-align:left"><a href="https://github.com/easzlab/kubeasz" target="_blank" rel="noopener">kubeasz</a></td><td style="text-align:left">Ansible</td><td style="text-align:left">7.2k</td><td style="text-align:left">2.7k</td><td style="text-align:left">支持，需自行构建安装包</td></tr><tr><td style="text-align:left"><a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a></td><td style="text-align:left">Golang</td><td style="text-align:left">4.1k</td><td style="text-align:left">790</td><td style="text-align:left">支持，需付费充值会员</td></tr><tr><td style="text-align:left"><a href="https://github.com/rancher/rke" target="_blank" rel="noopener">RKE</a></td><td style="text-align:left">Golang</td><td style="text-align:left">2.5k</td><td style="text-align:left">480</td><td style="text-align:left">不支持，需自行安装 docker</td></tr><tr><td style="text-align:left"><a href="https://github.com/alibaba/sealer" target="_blank" rel="noopener">sealer</a></td><td style="text-align:left">Golang</td><td style="text-align:left">503</td><td style="text-align:left">112</td><td style="text-align:left">支持，源自 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a></td></tr><tr><td style="text-align:left"><a href="https://github.com/kubesphere/kubekey" target="_blank" rel="noopener">kubekey</a></td><td style="text-align:left">Golang</td><td style="text-align:left">471</td><td style="text-align:left">155</td><td style="text-align:left">部分支持，仅镜像可离线</td></tr></tbody></table><p>无网环境离线部署 K8s 往往是作为一个商业服务或者商业付费产品来出售（如 <a href="https://www.sealyun.com/" target="_blank" rel="noopener">sealos</a> ），很少有开源免费的解决方案；或者虽然提供了离线部署方案，但想要操作起来十分繁琐，很难顺畅地做到一键部署；又或者只支持部分离线部署，还有一部分资源需要在部署的时候通过公网获取。</p><p>针对上述问题，本文调研主流的 K8s 部署工具，并基于这些工具设计并实现一种从构建离线安装包到一键部署 K8s 集群全流程的解决方案，以满足在无网的环境中一键部署 K8s 集群的需求，比较适合基于 K8s 的 PaaS toB 产品使用。</p><a id="more"></a><h2><span id="离线资源">离线资源</span></h2><p>总体来讲部署一个 K8s 集群大致需要依赖如下三种资源：</p><ul><li>系统 OS 的 rpm/deb 包：如 docker-ce、containerd、ipvsadm、conntrack 等；</li><li>二进制文件：如 kubelet、kubectl、kubeadm、crictl 等；</li><li>组件容器镜像：如 kube-apiserver、kube-proxy、coredns、calico、flannel 等；</li></ul><h3><span id="os-packages">OS packages</span></h3><p>这类属于 OS 系统层面的依赖，根据不同系统或者支持的功能需要使用相应的包管理器安装相应的依赖包，大致分为如下几种：</p><ul><li>kubernetes 组件依赖</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- conntrack           # kube-proxy 依赖</span><br><span class="line">- ipset               # kube-proxy 使用 ipvs 模式需要</span><br><span class="line">- ipvsadm             # kube-proxy 使用 ipvs 模式需要</span><br><span class="line">- socat               # 用于 port forwarding</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/" target="_blank" rel="noopener">Implementation details</a>:</p><p>[Error] if conntrack, ip, iptables, mount, nsenter commands are not present in the command path<br>[warning] if ebtables, ethtool, socat, tc, touch, crictl commands are not present in the command path</p></blockquote><ul><li>部署依赖</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- ebtables            # kubeadm 依赖工具</span><br><span class="line">- ethtool             # kubeadm 依赖工具</span><br><span class="line">- chrony              # 时钟同步工具，部署前节点的时候必须一致，不然证书或者 CNI 插件会出现问题</span><br></pre></td></tr></table></figure><ul><li>CRI 容器运行运行时</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- containerd.io       # 可单独安装&#x2F;docker-ce 依赖</span><br><span class="line">- docker-ce           # docker-ce</span><br><span class="line">- libseccomp          # 安装 containerd 需要</span><br><span class="line">- nvidia-container-runtime # 支持 GPU 时需要依赖</span><br></pre></td></tr></table></figure><ul><li>存储客户端依赖</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- nfs-utils&#x2F;nfs-common # 创建基于 nfs 的 PV 需要</span><br><span class="line">- ceph-common          # ceph 客户端安装包，创建基于 ceph 的 pv 需要</span><br><span class="line">- lvm2                 # 创建基于 ceph 的 pv 需要</span><br><span class="line">- glusterfs-client     # 创建基于 glusterfs 的 pv 需要</span><br><span class="line">- glusterfs-common     # 创建基于 glusterfs 的 pv 需要</span><br><span class="line">- cifs-utils           # 创建基于 cifs 的 pv 需要</span><br><span class="line">- fuse                 # ceph 或者其他存储客户端依赖</span><br></pre></td></tr></table></figure><p>想要解决上面这些依赖项十分棘手，也是离线部署场景下最难的一部分，至今并没有一个成熟的方案实现这些依赖的离线部署，基本上所有的 k8s 部署工具都没有提供这些包的离线安装方式。对于这些包的依赖，目前主要有避免安装这些依赖和制作离线源这两种解决方案。</p><h4><span id="sealos">sealos</span></h4><p>在 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 中就极力避免使用包管理器来安装依赖，比如安装 containerd 时的依赖 libseccomp 使用的是编译好的 .so 文件的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ tar -tf kube1.20.0.tar.gz</span><br><span class="line">kube&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;README.md</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2.3.1</span><br></pre></td></tr></table></figure><p>安装 docker 使用的二进制的方式，但 docker 官方文档中也明确说明<strong>不建议使用二进制的方式来安装 docker</strong>，应该使用发行版自带的包管理器来安装。</p><blockquote><p>If you want to try Docker or use it in a testing environment, but you’re not on a supported platform, you can try installing from static binaries. <strong>If possible, you should use packages built for your operating system</strong>, and use your operating system’s package management system to manage Docker installation and upgrades.</p><p><a href="https://docs.docker.com/engine/install/binaries/" target="_blank" rel="noopener">Install Docker Engine from binaries</a></p></blockquote><p>实际上任何部署工具都会对系统 rpm/deb 包都会有不同程度上的依赖，有一部分依赖可以像 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 这样通过某种方式去规避掉。但并不是所有的依赖都能规避的，比如提供挂载 PV 需要依赖的存储客户端（nfs-common/nfs-utils，lvm2，gluster-client）这些包，基本上是没有任何规避的途径，必须通过包管理器来安装才行。</p><p>当然如果这些前置的依赖项在部署工具之外手动解决或者让用户自行去解决，那么使用 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 这种轻量级的工具来部署 K8s 是比较合适的。但对于一些 PaaS toB 的产品而言，让用户自己去手动解决这些依赖恐怕不太好。站在客户的角度来考虑既然平台提供了这部分功能，就应该在部署的时候解决所有的依赖问题，而不是让我自己手动临时来解决。</p><h4><span id="kubekey">kubekey</span></h4><p>在 kubekey 中一些依赖项目则是要求用户自行安装，并没有提供离线安装的方式：</p><blockquote><ul><li>建议您使用干净的操作系统（不安装任何其他软件），否则可能会有冲突。</li><li>请确保每个节点的硬盘至少有 <strong>100G</strong>。</li><li>所有节点必须都能通过 <code>SSH</code> 访问。</li><li>所有节点时间同步。</li><li>所有节点都应使用 <code>sudo</code>/<code>curl</code>/<code>openssl</code>。</li></ul><p>KubeKey 能够同时安装 Kubernetes 和 KubeSphere。根据要安装的 Kubernetes 版本，需要安装的依赖项可能会不同。您可以参考下方列表，查看是否需要提前在您的节点上安装相关依赖项。</p><table><thead><tr><th style="text-align:left">依赖项</th><th style="text-align:left">Kubernetes 版本 ≥ 1.18</th><th style="text-align:left">Kubernetes 版本 &lt; 1.18</th></tr></thead><tbody><tr><td style="text-align:left"><code>socat</code></td><td style="text-align:left">必须</td><td style="text-align:left">可选但建议</td></tr><tr><td style="text-align:left"><code>conntrack</code></td><td style="text-align:left">必须</td><td style="text-align:left">可选但建议</td></tr><tr><td style="text-align:left"><code>ebtables</code></td><td style="text-align:left">可选但建议</td><td style="text-align:left">可选但建议</td></tr><tr><td style="text-align:left"><code>ipset</code></td><td style="text-align:left">可选但建议</td><td style="text-align:left">可选但建议</td></tr></tbody></table><p>备注</p><ul><li>在离线环境中，您可以使用私有包、RPM 包（适用于 CentOS）或者 Deb 包（适用于 Debian）来安装这些依赖项。</li><li>建议您事先创建一个操作系统镜像文件，并且安装好所有相关依赖项。这样，您便可以直接使用该镜像文件在每台机器上安装操作系统，提高部署效率，也不用担心任何依赖项问题。</li></ul><p>您的集群必须有一个可用的容器运行时。在离线环境中创建集群之前，您必须手动安装 Docker 或其他容器运行时。</p><p><a href="https://github.com/kubesphere/kubekey#requirements-and-recommendations" target="_blank" rel="noopener">Requirements and Recommendations</a></p></blockquote><h4><span id="构建离线源">构建离线源</span></h4><p>对于系统 rpm/deb 包的依赖，我们还是踏踏实实地使用包管理器来安装这些包较为妥当，因此我们有必要为这些依赖的 rpm/deb 包构建成离线源，部署的时候使用这个离线源来安装这些依赖。在 《<a href="https://blog.k8s.li/make-offline-mirrors.html" target="_blank" rel="noopener">使用 docker build 制作 yum/apt 离线源</a>》一文中曾分析过制作和使用离线源这么难的原因：</p><blockquote><p>作为平台部署工具的开发者，始终被离线部署这个难题困扰着。在线的容器镜像和二进制文件比较好解决，因为这些资源是与 OS 无关的，只要下载下来放到安装包里，部署的时候启动一个 HTTP 服务器和镜像仓库服务提供这些资源的下载即可。</p><p>但是对于 yum/apt 之类的软件来讲并不那么简单：</p><ul><li>首先由于各个包之间的依赖关系比较复杂，并不能将它们直接下载下来；</li><li>其次即便下载下来之后也无法直接通过 yum/apt 的方式安装指定的软件包，虽然也可以使用 scp 的方式将这些包复制到部署节点，通过 rpm 或 dpkg 的方式来安装上，但这样并不是很优雅，而且通用性能也不是很好；</li><li>最后需要适配的 Linux 发行版和包管理器种类也有多种，而且有些包的包名或者版本号在不同的包管理之间也相差甚大，无法做到统一管理。</li><li>离线源同时适配适配 ARM64 和 AMD64 有一定的难度</li></ul></blockquote><p>好在文中也给出了一个比较通用的解决方案，即通过 Dockerfile 来构建离线源，具体的实现细节可以翻看《<a href="https://blog.k8s.li/make-offline-mirrors.html" target="_blank" rel="noopener">使用 docker build 制作 yum/apt 离线源</a>》一文。使用这个方案可以解决 PaaS 或者 IaaS 层面的离线源制作的难题，同样也适用于我们部署 K8s 集群的场景，而且采用 Dockerfile 的方式来构建离线源可以完美地解决同时适配 arm64 和 amd64 的难题。</p><h3><span id="files">files</span></h3><p>一些部署过程中需要的二进制文件，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- kubelet</span><br><span class="line">- kubeadm</span><br><span class="line">- kubectl</span><br><span class="line">- etcd            # systemd 方式部署 etcd 时需要的安装包</span><br><span class="line">- crictl          # k8s 官方的 CRI CLI 工具</span><br><span class="line">- calicoctl       # calico 的 CLI 工具</span><br><span class="line">- helm            # 安装 helm 需要的二进制安装包</span><br><span class="line">- nerdctl         # containerd 的 CLI 工具</span><br><span class="line">- cni-plugins     # CNI 插件</span><br><span class="line">- cuda            # GPU 依赖</span><br><span class="line">- nvidia_driver   # GPU 驱动</span><br></pre></td></tr></table></figure><h4><span id="sealos">sealos</span></h4><p>sealos 对二进制文件的处理比较好，全部打包在离线安装包里，部署的时候会分发到集群节点上，整个部署过程都无需访问公网。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tar -tf kube1.20.0.tar.gz</span><br><span class="line">kube&#x2F;bin&#x2F;kubelet</span><br><span class="line">kube&#x2F;bin&#x2F;kubectl</span><br><span class="line">kube&#x2F;bin&#x2F;conntrack</span><br><span class="line">kube&#x2F;bin&#x2F;kubeadm</span><br></pre></td></tr></table></figure><h4><span id="kubekey">kubekey</span></h4><p>在 kubekey 的源码当中，是将所有二进制文件的 URL 硬编码在代码当中的。如果在部署的时候需要根据部署环境来修改二进制文件的下载地址，比如从内网 nginx 服务器上下载，就需要修改这部分源码把 <code>https://kubernetes-release.pek3b.qingstor.com</code> 修改成内网地址，比如 <code>http://172.20.0.25:8080/files</code> ，然而在部署的时候重新编译 kubekey 的代码又必须能访问公网才行，这就很僵硬。所以以目前开源的 kubekey 来看，是没有办法做到无网环境中愉快地部署 k8s 的，可能商业版会支持（猜测）。</p><ul><li><a href="https://github.com/kubesphere/kubekey/blob/master/pkg/kubernetes/preinstall/preinstall.go" target="_blank" rel="noopener">kubekey/blob/master/pkg/kubernetes/preinstall/preinstall.go</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; FilesDownloadHTTP defines the kubernetes&#39; binaries that need to be downloaded in advance and downloads them.</span><br><span class="line">func FilesDownloadHTTP(mgr *manager.Manager, filepath, version, arch string) error &#123;</span><br><span class="line">kkzone :&#x3D; os.Getenv(&quot;KKZONE&quot;)</span><br><span class="line">etcd :&#x3D; files.KubeBinary&#123;Name: &quot;etcd&quot;, Arch: arch, Version: kubekeyapiv1alpha1.DefaultEtcdVersion&#125;</span><br><span class="line">kubeadm :&#x3D; files.KubeBinary&#123;Name: &quot;kubeadm&quot;, Arch: arch, Version: version&#125;</span><br><span class="line">kubelet :&#x3D; files.KubeBinary&#123;Name: &quot;kubelet&quot;, Arch: arch, Version: version&#125;</span><br><span class="line">kubectl :&#x3D; files.KubeBinary&#123;Name: &quot;kubectl&quot;, Arch: arch, Version: version&#125;</span><br><span class="line">kubecni :&#x3D; files.KubeBinary&#123;Name: &quot;kubecni&quot;, Arch: arch, Version: kubekeyapiv1alpha1.DefaultCniVersion&#125;</span><br><span class="line">helm :&#x3D; files.KubeBinary&#123;Name: &quot;helm&quot;, Arch: arch, Version: kubekeyapiv1alpha1.DefaultHelmVersion&#125;</span><br><span class="line"></span><br><span class="line">etcd.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;etcd-%s-linux-%s.tar.gz&quot;, filepath, kubekeyapiv1alpha1.DefaultEtcdVersion, arch)</span><br><span class="line">kubeadm.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;kubeadm&quot;, filepath)</span><br><span class="line">kubelet.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;kubelet&quot;, filepath)</span><br><span class="line">kubectl.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;kubectl&quot;, filepath)</span><br><span class="line">kubecni.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;cni-plugins-linux-%s-%s.tgz&quot;, filepath, arch, kubekeyapiv1alpha1.DefaultCniVersion)</span><br><span class="line">helm.Path &#x3D; fmt.Sprintf(&quot;%s&#x2F;helm&quot;, filepath)</span><br><span class="line"></span><br><span class="line">if kkzone &#x3D;&#x3D; &quot;cn&quot; &#123;</span><br><span class="line">etcd.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;etcd&#x2F;release&#x2F;download&#x2F;%s&#x2F;etcd-%s-linux-%s.tar.gz&quot;, etcd.Version, etcd.Version, etcd.Arch)</span><br><span class="line">kubeadm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubeadm&quot;, kubeadm.Version, kubeadm.Arch)</span><br><span class="line">kubelet.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubelet&quot;, kubelet.Version, kubelet.Arch)</span><br><span class="line">kubectl.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-release.pek3b.qingstor.com&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubectl&quot;, kubectl.Version, kubectl.Arch)</span><br><span class="line">kubecni.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;containernetworking.pek3b.qingstor.com&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;%s&#x2F;cni-plugins-linux-%s-%s.tgz&quot;, kubecni.Version, kubecni.Arch, kubecni.Version)</span><br><span class="line">helm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;kubernetes-helm.pek3b.qingstor.com&#x2F;linux-%s&#x2F;%s&#x2F;helm&quot;, helm.Arch, helm.Version)</span><br><span class="line">helm.GetCmd &#x3D; mgr.DownloadCommand(helm.Path, helm.Url)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">etcd.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;%s&#x2F;etcd-%s-linux-%s.tar.gz&quot;, etcd.Version, etcd.Version, etcd.Arch)</span><br><span class="line">kubeadm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubeadm&quot;, kubeadm.Version, kubeadm.Arch)</span><br><span class="line">kubelet.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubelet&quot;, kubelet.Version, kubelet.Arch)</span><br><span class="line">kubectl.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;%s&#x2F;bin&#x2F;linux&#x2F;%s&#x2F;kubectl&quot;, kubectl.Version, kubectl.Arch)</span><br><span class="line">kubecni.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;github.com&#x2F;containernetworking&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;%s&#x2F;cni-plugins-linux-%s-%s.tgz&quot;, kubecni.Version, kubecni.Arch, kubecni.Version)</span><br><span class="line">helm.Url &#x3D; fmt.Sprintf(&quot;https:&#x2F;&#x2F;get.helm.sh&#x2F;helm-%s-linux-%s.tar.gz&quot;, helm.Version, helm.Arch)</span><br><span class="line">getCmd :&#x3D; mgr.DownloadCommand(fmt.Sprintf(&quot;%s&#x2F;helm-%s-linux-%s.tar.gz&quot;, filepath, helm.Version, helm.Arch), helm.Url)</span><br><span class="line">helm.GetCmd &#x3D; fmt.Sprintf(&quot;%s &amp;&amp; cd %s &amp;&amp; tar -zxf helm-%s-linux-%s.tar.gz &amp;&amp; mv linux-%s&#x2F;helm . &amp;&amp; rm -rf *linux-%s*&quot;, getCmd, filepath, helm.Version, helm.Arch, helm.Arch, helm.Arch)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外 kubekey 在安装 docker 时，是直接调用的 <a href="https://get.docker.com/" target="_blank" rel="noopener">docker 官方的脚本</a> 来安装，安装过程也必须访问公网才行。</p><ul><li><a href="https://github.com/kubesphere/kubekey/blob/master/pkg/container-engine/docker/docker.go" target="_blank" rel="noopener">kubekey/blob/master/pkg/container-engine/docker/docker.go</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func installDockerOnNode(mgr *manager.Manager, _ *kubekeyapiv1alpha1.HostCfg) error &#123;</span><br><span class="line">dockerConfig, err :&#x3D; GenerateDockerConfig(mgr)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return err</span><br><span class="line">&#125;</span><br><span class="line">dockerConfigBase64 :&#x3D; base64.StdEncoding.EncodeToString([]byte(dockerConfig))</span><br><span class="line">output, err1 :&#x3D; mgr.Runner.ExecuteCmd(fmt.Sprintf(&quot;sudo -E &#x2F;bin&#x2F;sh -c \&quot;if [ -z $(which docker) ] || [ ! -e &#x2F;var&#x2F;run&#x2F;docker.sock ]; then curl https:&#x2F;&#x2F;kubernetes.pek3b.qingstor.com&#x2F;tools&#x2F;kubekey&#x2F;docker-install.sh | sh &amp;&amp; systemctl enable docker; if [ ! -f &#x2F;etc&#x2F;docker&#x2F;daemon.json ]; then mkdir -p &#x2F;etc&#x2F;docker &amp;&amp; echo %s | base64 -d &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json; fi; systemctl daemon-reload &amp;&amp; systemctl restart docker; fi\&quot;&quot;, dockerConfigBase64), 0, false)</span><br><span class="line">if err1 !&#x3D; nil &#123;</span><br><span class="line">return errors.Wrap(errors.WithStack(err1), fmt.Sprintf(&quot;Failed to install docker:\n%s&quot;, output))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 docker 官方的安装脚本来安装 docker 是有一个明显的问题就是：没有版本控制，不能指定 docker 的版本，每次安装的 docker 版本都是最新的 stable 版本。没有版本控制就会导致不同时间部署的集群或者加入的节点，docker 版本可能就不一样，在这里可能会埋下一些坑，可能会带来一定的维护成本或者将来升级时遇到问题。</p><p>编译过 kubernetes 组件的可能都知道 k8s 源码当中存在一个 <a href="https://github.com/kubernetes/kubernetes/blob/master/build/dependencies.yaml" target="_blank" rel="noopener">build/dependencies.yaml</a> 的文件，里面记录的是 k8s 组件与其他组件 (如 docker, etcd, coredns, cni, pause) 所匹配的最佳版本。</p><blockquote><p>On each of your nodes, install the Docker for your Linux distribution as per <a href="https://docs.docker.com/engine/install/#server" target="_blank" rel="noopener">Install Docker Engine</a>. You can find the latest validated version of Docker in this <a href="https://git.k8s.io/kubernetes/build/dependencies.yaml" target="_blank" rel="noopener">dependencies</a> file.</p></blockquote><ul><li><a href="https://github.com/kubernetes/kubernetes/blob/release-1.20/build/dependencies.yaml" target="_blank" rel="noopener">kubernetes/blob/release-1.20/build/dependencies.yaml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">dependencies:</span><br><span class="line">  # zeitgeist (https:&#x2F;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;zeitgeist) was inspired by</span><br><span class="line">  # (and now replaces) the cmd&#x2F;verifydependencies tool to verify external</span><br><span class="line">  # dependencies across the repo.</span><br><span class="line">  #</span><br><span class="line">  # The zeitgeist dependencies.yaml file format is intended to be</span><br><span class="line">  # backwards-compatible with the original tooling.</span><br><span class="line">  #</span><br><span class="line">  # In instances where the file format may change across versions, this meta</span><br><span class="line">  # dependency check exists to ensure we&#39;re pinned to a known good version.</span><br><span class="line">  #</span><br><span class="line">  # ref: https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;pull&#x2F;98845</span><br><span class="line"></span><br><span class="line">  # Docker</span><br><span class="line">  - name: &quot;docker&quot;</span><br><span class="line">    version: 19.03</span><br><span class="line">    refPaths:</span><br><span class="line">    - path: vendor&#x2F;k8s.io&#x2F;system-validators&#x2F;validators&#x2F;docker_validator.go</span><br><span class="line">      match: latestValidatedDockerVersion</span><br></pre></td></tr></table></figure><p>以 1.20.x 版本的 k8s 为例，它所依赖的 docker 版本为 19.03，而现在最新的 docker 版本如 20.10.8，并不是 K8s 官方所建议的最佳版本。总之，我们在部署 K8s 时，可以参考 <a href="https://github.com/kubernetes/kubernetes/blob/master/build/dependencies.yaml" target="_blank" rel="noopener">build/dependencies.yaml</a> 来确定与 K8s 相关的组件应该选择哪一个最佳的版本，而不是随便装一个最新的版本就完事儿了。</p><h4><span id="kubespray">kubespray</span></h4><p>在 kubespray 中，所有二进制文件的 URL 都是通过变量的方式定义的，想要做到离线部署十分简单，只需要通过 ansible 变量优先级的特性，将它们在 group_vars 通过 overrides 的方式覆盖即可。比如这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Download URLs</span><br><span class="line">kubelet_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubelet&quot;</span><br><span class="line">kubectl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubectl&quot;</span><br><span class="line">kubeadm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubeadm&quot;</span><br></pre></td></tr></table></figure><h3><span id="images">images</span></h3><p>一些如 kube-proxy、kube-apiserver、coredns、calico 组件镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">k8s.gcr.io&#x2F;kube-apiserver:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;kube-controller-manager:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;kube-proxy:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;kube-registry-proxy:0.4</span><br><span class="line">k8s.gcr.io&#x2F;kube-scheduler:v1.20.7</span><br><span class="line">k8s.gcr.io&#x2F;pause:3.3</span><br><span class="line">k8s.gcr.io&#x2F;coredns:1.7.0</span><br><span class="line">k8s.gcr.io&#x2F;cpa&#x2F;cluster-proportional-autoscaler-amd64:1.8.3</span><br><span class="line">k8s.gcr.io&#x2F;dns&#x2F;k8s-dns-node-cache:1.17.1</span><br></pre></td></tr></table></figure><h4><span id="sealos">sealos</span></h4><p>sealos 将这些镜像使用 docker save 的方式打包成一个 tar 包，在部署的时候使用 docker/ctr load 的方式将镜像导入到容器运行时的存储目录当中，源码如下：</p><ul><li><a href="https://github.com/fanux/sealos/blob/develop/install/send.go" target="_blank" rel="noopener">fanux/sealos/blob/develop/install/send.go</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; SendPackage is send new pkg to all nodes.</span><br><span class="line">func (u *SealosUpgrade) SendPackage() &#123;</span><br><span class="line">all :&#x3D; append(u.Masters, u.Nodes...)</span><br><span class="line">pkg :&#x3D; path.Base(u.NewPkgUrl)</span><br><span class="line">&#x2F;&#x2F; rm old sealos in package avoid old version problem. if sealos not exist in package then skip rm</span><br><span class="line">var kubeHook string</span><br><span class="line">if For120(Version) &#123;</span><br><span class="line">&#x2F;&#x2F; TODO update need load modprobe -- br_netfilter modprobe -- bridge.</span><br><span class="line">&#x2F;&#x2F; https:&#x2F;&#x2F;github.com&#x2F;fanux&#x2F;cloud-kernel&#x2F;issues&#x2F;23</span><br><span class="line">kubeHook &#x3D; fmt.Sprintf(&quot;cd &#x2F;root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf %s  &amp;&amp; cd &#x2F;root&#x2F;kube&#x2F;shell &amp;&amp; rm -f ..&#x2F;bin&#x2F;sealos &amp;&amp; (ctr -n&#x3D;k8s.io image import ..&#x2F;images&#x2F;images.tar || true) &amp;&amp; cp -f ..&#x2F;bin&#x2F;* &#x2F;usr&#x2F;bin&#x2F; &quot;, pkg)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">kubeHook &#x3D; fmt.Sprintf(&quot;cd &#x2F;root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf %s  &amp;&amp; cd &#x2F;root&#x2F;kube&#x2F;shell &amp;&amp; rm -f ..&#x2F;bin&#x2F;sealos &amp;&amp; (docker load -i ..&#x2F;images&#x2F;images.tar || true) &amp;&amp; cp -f ..&#x2F;bin&#x2F;* &#x2F;usr&#x2F;bin&#x2F; &quot;, pkg)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PkgUrl &#x3D; SendPackage(pkg, all, &quot;&#x2F;root&quot;, nil, &amp;kubeHook)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用这种方式加载镜像有一个比较明显的限制就是 kube-apiserver 的 admission 准入控制中不能加入 <code>AlwaysPullImages</code> 参数。不然与这些镜像相关的 pod 重新调度或者重启之后会重新从源镜像仓库拉取镜像，在无网或者网络限制的环境中可能无法拉取镜像导致这些 Pod 启动失败，从而导致集群异常。</p><p>而在多租户场景下，出于安全的考虑 <code>AlwaysPullImages</code> 准入控制往往是要开启的。因此 sealos 可能并不适用于多租户或者对此有要求的环境中（最常见的就是 PaaS 平台）。</p><blockquote><p>该准入控制器会修改每一个新创建的 Pod 的镜像拉取策略为 Always 。 这在多租户集群中是有用的，这样用户就可以放心，他们的私有镜像只能被那些有凭证的人使用。 如果没有这个准入控制器，一旦镜像被拉取到节点上，任何用户的 Pod 都可以通过已了解到的镜像的名称（假设 Pod 被调度到正确的节点上）来使用它，而不需要对镜像进行任何授权检查。 当启用这个准入控制器时，总是在启动容器之前拉取镜像，这意味着需要有效的凭证。</p></blockquote><h4><span id="kubekey">kubekey</span></h4><p><a href="https://kubesphere.io/docs/installing-on-linux/introduction/air-gapped-installation/" target="_blank" rel="noopener">kubekey 官方的文档</a> 中有提到组件镜像离线部署的方式，不过十分繁琐(劝退😂)，在 <a href="https://github.com/kubesphere/kubekey/issues/597" target="_blank" rel="noopener">Offline installation is too troublesome #597</a> 中也有人吐槽这个问题。不过目前 kubekey 开发团队已经在重构这部分内容了，至于结果如何，只能等了。</p><h4><span id="镜像仓库">镜像仓库</span></h4><p>在私有云环境中，企业一般都会有自己的镜像仓库（比如 harbor ）用于存放业务组件镜像或者一些其他平台依赖的镜像。再加上 Docker Hub 自从去年开始就加入了 pull 镜像次数的限制，如果直接使用 Docker Hub 上面的镜像来部署集群，很有可能会因为 <a href="https://www.docker.com/increase-rate-limit" target="_blank" rel="noopener">429 toomanyrequests</a> 或者一些网络原因导致拉取镜像失败。因此对于 k8s 集群部署而言，建议使用内部自己的镜像仓库，而非公网上镜像仓库。如果没有的话可以使用 harbor 或者 docker registry 在本地部署一个镜像仓库。我们将部署依赖的镜像导入到已经存在的镜像仓库中，部署的时候从该镜像仓库拉取即可。</p><h2><span id="部署工具选择">部署工具选择</span></h2><p>上面简单梳理了一下部署 k8s 集群过程中所依赖的的在线资源，以及如何将它们制作成离线资源的一些分析。上面提及的部署工具各有各的优缺点，针对以下两种不同的场景可以选择不同的部署工具。</p><h3><span id="sealos">sealos</span></h3><p>如果仅仅是部署一个简单的 k8s 集群，对集群没有太多定制化的需求，那么使用 <a href="https://github.com/fanux/sealos" target="_blank" rel="noopener">sealos</a> 可能是最佳的选择，只不过它是收费的，<a href="https://www.sealyun.com/" target="_blank" rel="noopener">需要充值会员</a> 😂。</p><blockquote><h3><span id="现在开始-99-69年">现在开始 <s>￥99</s> ￥69/年</span></h3><p>欢迎成为年费会员，任意下载所有版本软件包!</p><blockquote><p>@F-liuhui 离线包居然要收费？那还是开源项目吗？</p></blockquote><p>开源与付费不冲突，100%开源 100%付费</p><p><a href="https://www.sealyun.com/" target="_blank" rel="noopener">sealyun.com</a></p></blockquote><p>如果动手能力强的话，可以根据 selaos 离线安装包的目录结构使用 GitHub Actions 来构建，实现起来也不是很难。只不过砸别人饭碗的事儿还是不做为好，因此我们应该选择另一种方案来实现，这样也能避免一些商业纠纷问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ tar -tf kube1.20.0.tar.gz</span><br><span class="line">kube&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;</span><br><span class="line">kube&#x2F;lib64&#x2F;README.md</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2</span><br><span class="line">kube&#x2F;lib64&#x2F;libseccomp.so.2.3.1</span><br><span class="line">kube&#x2F;shell&#x2F;</span><br><span class="line">kube&#x2F;shell&#x2F;containerd.sh</span><br><span class="line">kube&#x2F;shell&#x2F;init.sh</span><br><span class="line">kube&#x2F;shell&#x2F;master.sh</span><br><span class="line">kube&#x2F;README.md</span><br><span class="line">kube&#x2F;bin&#x2F;</span><br><span class="line">kube&#x2F;bin&#x2F;kubelet</span><br><span class="line">kube&#x2F;bin&#x2F;kubectl</span><br><span class="line">kube&#x2F;bin&#x2F;conntrack</span><br><span class="line">kube&#x2F;bin&#x2F;kubeadm</span><br><span class="line">kube&#x2F;bin&#x2F;kubelet-pre-start.sh</span><br><span class="line">kube&#x2F;conf&#x2F;</span><br><span class="line">kube&#x2F;conf&#x2F;kubeadm.yaml</span><br><span class="line">kube&#x2F;conf&#x2F;kubelet.service</span><br><span class="line">kube&#x2F;conf&#x2F;calico.yaml</span><br><span class="line">kube&#x2F;conf&#x2F;10-kubeadm.conf</span><br><span class="line">kube&#x2F;conf&#x2F;net&#x2F;</span><br><span class="line">kube&#x2F;conf&#x2F;net&#x2F;calico.yaml</span><br><span class="line">kube&#x2F;containerd&#x2F;</span><br><span class="line">kube&#x2F;containerd&#x2F;README.md</span><br><span class="line">kube&#x2F;containerd&#x2F;cri-containerd-cni-linux-amd64.tar.gz</span><br><span class="line">kube&#x2F;images&#x2F;</span><br><span class="line">kube&#x2F;images&#x2F;images.tar</span><br><span class="line">kube&#x2F;images&#x2F;README.md</span><br></pre></td></tr></table></figure><h3><span id="kubekey">kubekey</span></h3><p>由于 kubekey 部署时二进制文件需要公网获取，docker 无法离线部署以及需要手动安装一些前置依赖，没有办法做到完整的离线部署，因此离线部署的方案也就直接放弃掉了，抽空他们提个 Issue 或 PR 看看能否支持这部分 😅。</p><h3><span id="kubespray">kubespray</span></h3><p>如果想找一个即开源又免费的离线部署方案，或者对集群部署有特殊的要求，比如基于 K8s 的 PaaS toB 产品，需要在部署时安装平台本身需要的一些依赖（如存储客户端、GPU 驱动等）。那么不妨先看一下 kubernetes-sig 社区的 <a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">kubespray</a> 如何 🤔，主要的特性如下：</p><ul><li>支持的 10 种 CNI 插件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- cni-plugins v0.9.1</span><br><span class="line">- calico v3.17.4</span><br><span class="line">- canal (given calico&#x2F;flannel versions)</span><br><span class="line">- cilium v1.9.9</span><br><span class="line">- flanneld v0.14.0</span><br><span class="line">- kube-ovn v1.7.1</span><br><span class="line">- kube-router v1.3.0</span><br><span class="line">- multus v3.7.2</span><br><span class="line">- ovn4nfv v1.1.0</span><br><span class="line">- weave v2.8.1</span><br></pre></td></tr></table></figure><ul><li>支持 3 种容器运行时以及 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/docs/kata-containers.md" target="_blank" rel="noopener">Kata Containers</a> 还有 nvidia-gpu-device-plugin 等</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- docker v20.10</span><br><span class="line">- containerd v1.4.6</span><br><span class="line">- cri-o v1.21</span><br></pre></td></tr></table></figure><ul><li>适配了 10 种 Linux 发行版，覆盖了绝大多数私有云场景</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- Flatcar Container Linux by Kinvolk</span><br><span class="line">- Debian Buster, Jessie, Stretch, Wheezy</span><br><span class="line">- Ubuntu 16.04, 18.04, 20.04</span><br><span class="line">- CentOS&#x2F;RHEL 7, 8</span><br><span class="line">- Fedora 33, 34</span><br><span class="line">- Fedora CoreOS (see fcos Note)</span><br><span class="line">- openSUSE Leap 15.x&#x2F;Tumbleweed</span><br><span class="line">- Oracle Linux 7, 8</span><br><span class="line">- Alma Linux 8</span><br><span class="line">- Amazon Linux 2</span><br></pre></td></tr></table></figure><ul><li>丰富的插件和扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">## 工具类</span><br><span class="line">- helm</span><br><span class="line">- krew</span><br><span class="line">- nerdctl</span><br><span class="line"></span><br><span class="line">## 一些 controller 和 provisioner</span><br><span class="line">- ambassador: v1.5</span><br><span class="line">- cephfs-provisioner v2.1.0-k8s1.11</span><br><span class="line">- rbd-provisioner v2.1.1-k8s1.11</span><br><span class="line">- cert-manager v0.16.1</span><br><span class="line">- coredns v1.8.0</span><br><span class="line">- ingress-nginx v0.43.0</span><br></pre></td></tr></table></figure><ul><li>依赖的文件和镜像支持离线部署 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/docs/offline-environment.md" target="_blank" rel="noopener">Offline environment</a></li></ul><p>kubespray 对所有的依赖资源都做到了离线下载的支持：比如所有依赖文件的 URL 都通过变量的方式来定义，而非 kubekey 那样硬编码在代码中；所有镜像的 repo 和 tag 都是通过变量的方式来定义。这样的好处就是在部署的时候可以根据客户环境的的镜像仓库地址和文件服务器的 URL 地址来填写相应的参数，无需通过公网来获取。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Registry overrides</span><br><span class="line">kube_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line">gcr_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line">docker_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line">quay_image_repo: &quot;&#123;&#123; registry_host &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line">kubeadm_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;kubeadm&quot;</span><br><span class="line">kubectl_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;kubectl&quot;</span><br><span class="line">kubelet_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;kubelet&quot;</span><br><span class="line"># etcd is optional if you **DON&#39;T** use etcd_deployment&#x3D;host</span><br><span class="line">etcd_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;etcd&#x2F;etcd-&#123;&#123; etcd_version &#125;&#125;-linux-amd64.tar.gz&quot;</span><br><span class="line">cni_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;cni&#x2F;cni-plugins-linux-&#123;&#123; image_arch &#125;&#125;-&#123;&#123; cni_version &#125;&#125;.tgz&quot;</span><br><span class="line">crictl_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;cri-tools&#x2F;crictl-&#123;&#123; crictl_version &#125;&#125;-&#123;&#123; ansible_system | lower &#125;&#125;-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line"># If using Calico</span><br><span class="line">calicoctl_download_url: &quot;&#123;&#123; files_repo &#125;&#125;&#x2F;kubernetes&#x2F;calico&#x2F;&#123;&#123; calico_ctl_version &#125;&#125;&#x2F;calicoctl-linux-&#123;&#123; image_arch &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><p>和上述几种部署工具对比不难发现，kubespray 灵活性和可扩展性要领先其他工具（支持 10 种 CNI、10种 Linux 发行版、3 种 CRI、以及多种插件和扩展）并在参数层面上做到了离线部署的支持。因此我们首先选用 kubespray 作为集群部署的底层工具。</p><p>还有一个问题就是 kubespray 虽然在参数配置上支持离线部署，但是从制作离线安装包到一键部署，目前为止还未有一个完整的实现方案。因此需要为 kubespray 设计一套从离线安装包的构建到集群一键部署的流程和方案，为此我们新建一个名为 <a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">kubeplay</a> 的 repo 来完成这部分内容。</p><p>另外值得一提的是 kubesphere 早期的版本 v2.x 使用也是 kubespray 部署的 k8s，至今 ks-installer 代码中仍残留着 <a href="https://github.com/kubesphere/ks-installer/commits/master/roles/download/tasks" target="_blank" rel="noopener">部分 kubespray 的代码</a> ，到了 3.0 的时候开始使用自研的 kubekey 来部署 K8s 了。</p><blockquote><p>基于 Ansible 的安装程序具有大量软件依赖性，例如 Python。KubeKey 是使用 Go 语言开发的，可以消除在各种环境中出现的问题，从而提高安装成功率。</p><p><a href="https://github.com/kubesphere/kubekey/blob/master/README_zh-CN.md" target="_blank" rel="noopener">README_zh-CN.md</a></p></blockquote><p>不过 ansible 的依赖问题当时为什么没有考虑采用容器化的方式运行 kubespray 🤔，至于 ansible 的性能问题也不是没有优化的余地。</p><h2><span id="kubeplay"></span></h2><p>kubeplay 这个项目主要是实现 K8s 离线安装包的构建和一键部署功能，目前只适配了 kubespray，等到后面会适配一些其他部署工具如 kubekey。</p><h3><span id="打包方式">打包方式</span></h3><p>由于部署依赖的二进制文件和组件镜像大都存放在 GitHub 、Docker Hub、<a href="http://gcr.io" target="_blank" rel="noopener">gcr.io</a>（Google Container Registry）、<a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 这些国外的平台上，在国内环境获取这些资源是有一定的网络限制。而 GitHub 托管的 runner 运行在国外的机房当中，可以很顺畅地获取这些资源。因此我们选择使用 GitHub Actions 来进行离线安装包的构建。</p><p>像 selos 那样将安装包存放在阿里云 OSS 上，在国内能十分顺畅地高速下载，收费也是理所当然。但我们的方案是 100% 开源 100% 免费，每个人都可以 fork 代码到自己的 repo，根据自己的需求进行构建。因此选择 GitHub 来构建和存放我们的安装包是最合适的选择，这样也不用去额外考虑安装包下载的问题。至于从 GitHub 上下载安装包慢的问题，那应该由使用者自行去解决，而非本方案所关心的问题。</p><blockquote><p>Q：如何摆脱网络的依赖来创建个 Docker 的 image 呢，我觉得这个是 Docker 用户自己的基本权利？</p><p>A：这个基本权利我觉得还是要问 GFW ，国外的开发人员是非常难理解有些他们认为跟水电一样普及的基础设施在某些地方还是很困难的。</p><p>此处引用 <a href="http://dockone.io/article/722" target="_blank" rel="noopener">DockOne技术分享（二十四）：容器和IaaS：谁动了谁的奶酪</a></p></blockquote><p>选择好的构建场所为 GitHub Actions 之后我们再将这些离线资源进行拆分，目的是为了实现各个离线资源之间的解耦，这样做灵活性更好一些，比如能够适配多种 OS、支持多个 k8s 版本等。主要拆分成如下几个模块。</p><table><thead><tr><th style="text-align:left">模块</th><th style="text-align:left">Repo</th><th style="text-align:left">用途</th><th style="text-align:left">运行/使用方式</th></tr></thead><tbody><tr><td style="text-align:left">compose</td><td style="text-align:left"><a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">kubeplay</a></td><td style="text-align:left">用于部署 nginx 和 registry 服务</td><td style="text-align:left">nerdctl compose</td></tr><tr><td style="text-align:left">os-tools</td><td style="text-align:left"><a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">kubeplay</a></td><td style="text-align:left">部署 compose 时的一些依赖工具</td><td style="text-align:left">二进制安装</td></tr><tr><td style="text-align:left">os-packages</td><td style="text-align:left"><a href="https://github.com/k8sli/os-packages" target="_blank" rel="noopener">os-packages</a></td><td style="text-align:left">提供 rpm/deb 离线源</td><td style="text-align:left">nginx 提供 http 方式下载</td></tr><tr><td style="text-align:left">kubespray</td><td style="text-align:left"><a href="https://github.com/k8sli/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">用于部署/扩缩容 k8s 集群</td><td style="text-align:left">容器或者 pod</td></tr><tr><td style="text-align:left">kubespray-files</td><td style="text-align:left"><a href="https://github.com/k8sli/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">提供二进制文件依赖</td><td style="text-align:left">nginx 提供 http 方式下载</td></tr><tr><td style="text-align:left">kubespray-images</td><td style="text-align:left"><a href="https://github.com/k8sli/kubespray" target="_blank" rel="noopener">kubespray</a></td><td style="text-align:left">提供组件镜像</td><td style="text-align:left">registry 提供镜像下载</td></tr></tbody></table><p>拆分完成之后，我们最终还是需要将它们组合成一个完成的离线安装包。为了减少维护成本，我们将每个模块的构建操作都放在 Dockerfile 中，即 <code>All in Dockerfile</code> 🤣。这样每个模块的 GitHub Actions 流水线最终交付的都是一个镜像，然后镜像都推送到 <code>ghcr.io</code> 上，这样就解决了模块间产物传递以及镜像缓存的问题。最终通过一个最终的 <a href="https://github.com/k8sli/kubeplay/blob/main/Dockerfile" target="_blank" rel="noopener">Dockerfile</a> 将这些模块的镜像全部 COPY 到一个镜像当中，只要打包这个最终的镜像为离线安装包即可；另一个好处就使用 buildx 构建这些离线资源就原生支持多 CPU 体系架构，能够同时适配 amd64 和 arm64 体系架构，这样 arm64 也能愉快地玩耍了，真是一举两得。</p><p>下面就详细讲解每个模块的功能以及是如何打包的：</p><h3><span id="compose">compose</span></h3><p>compose 模块里面主要运两个服务： 用于提供文件下载的 nginx 和组件镜像拉取的 registry。这两个我们依旧是容器化以类似 docker-compose 的方式来部署，而所依赖的也只有两个镜像和一些配置文件而已。</p><ul><li><a href="https://github.com/k8sli/kubeplay/blob/main/compose.yaml" target="_blank" rel="noopener">kubeplay/blob/main/compose.yaml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.1&#39;</span><br><span class="line">services:</span><br><span class="line">  nginx:</span><br><span class="line">    container_name: nginx</span><br><span class="line">    image: nginx:1.20-alpine</span><br><span class="line">    restart: always</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;resources&#x2F;nginx:&#x2F;usr&#x2F;share&#x2F;nginx</span><br><span class="line">      - .&#x2F;config&#x2F;compose&#x2F;certs&#x2F;domain.crt:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;domain.crt</span><br><span class="line">      - .&#x2F;config&#x2F;compose&#x2F;certs&#x2F;domain.key:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;domain.key</span><br><span class="line">      - .&#x2F;config&#x2F;compose&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf</span><br><span class="line">    ports:</span><br><span class="line">      # 443 端口反向代理 registr 的 5000 端口，仅用于 pull 镜像</span><br><span class="line">      - 443:443</span><br><span class="line">      - 8080:8080</span><br><span class="line"></span><br><span class="line">  registry:</span><br><span class="line">    image: registry:2.7.1</span><br><span class="line">    container_name: registry</span><br><span class="line">    restart: always</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;resources&#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry</span><br><span class="line">    ports:</span><br><span class="line">      # 只允许本地 5000 端口 push 镜像</span><br><span class="line">      - 127.0.0.1:5000:5000</span><br></pre></td></tr></table></figure><p>这两个镜像我们使用 skopeo copy 的方式保存为 tar 包，部署的时候 load 到容器运行时的存储中。</p><blockquote><p>Q：为什么要用 skopeo 而不是 docker？</p><p>A：因为 Dockerfile 构建过程中不支持运行 docker 命令 save 镜像</p></blockquote><ul><li>Dockerfile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest as downloader</span><br><span class="line">ARG SKOPEO_VERSION&#x3D;v1.4.0</span><br><span class="line">ARG NGINX_VERSION&#x3D;1.20-alpine</span><br><span class="line">ARG RERGISRRY_VERSION&#x3D;2.7.1</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;tools</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; apk --no-cache add wget ca-certificates \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;skopeo&#x2F;releases&#x2F;download&#x2F;v1.4.0&#x2F;skopeo-linux-$&#123;ARCH&#125; -O &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; \</span><br><span class="line">    &amp;&amp; chmod a+x &#x2F;tools&#x2F;* \</span><br><span class="line">    &amp;&amp; ln -s &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; &#x2F;usr&#x2F;bin&#x2F;skopeo</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;images</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag nginx:$&#123;NGINX_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;nginx:$&#123;NGINX_VERSION&#125; docker-archive:nginx-$&#123;NGINX_VERSION&#125;.tar \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag registry:$&#123;RERGISRRY_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;registry:$&#123;RERGISRRY_VERSION&#125; docker-archive:registry-$&#123;RERGISRRY_VERSION&#125;.tar</span><br></pre></td></tr></table></figure><p>在部署的时候我们使用 nerdctl compose 的方式启动即可，使用方式有点类似于 docker-compose。</p><blockquote><p>Q: 为什么不用 docker 和 docker-compose</p><p>A：K8s 去 docker 是大势所趋，选择 containerd 更符合主流发展方向</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 将镜像 load 进 containerd 存储</span><br><span class="line">$ find $&#123;IMAGES_DIR&#125; -type f -name &#39;*.tar&#39; | xargs -L1 nerdctl load -i</span><br><span class="line"># nerdctl compose 启动 nginx 和 registry</span><br><span class="line">$ nerdctl compose -f compose.yaml up</span><br></pre></td></tr></table></figure><h3><span id="os-packages">os-packages</span></h3><p>这部分是 rpm/deb 离线源的构建，其详细的过程和原理可以参考我之前写的博客 《<a href="https://blog.k8s.li/make-offline-mirrors.html" target="_blank" rel="noopener">使用 docker build 制作 yum/apt 离线源</a>》，下面只列举一下 CentOS7 离线源的构建配置：</p><ul><li><a href="https://github.com/k8sli/os-packages/blob/main/build/Dockerfile.os.centos7" target="_blank" rel="noopener">Dockerfile</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7.9.2009 as os-centos7</span><br><span class="line">ARG OS_VERSION&#x3D;7</span><br><span class="line">ARG DOCKER_MIRROR_URL&#x3D;&quot;https:&#x2F;&#x2F;download.docker.com&quot;</span><br><span class="line">ARG BUILD_TOOLS&#x3D;&quot;yum-utils createrepo epel-release wget&quot;</span><br><span class="line"></span><br><span class="line"># 安装构建工具，配置 docker 官方 yum 源</span><br><span class="line">RUN yum install -q -y $&#123;BUILD_TOOLS&#125; \</span><br><span class="line">    &amp;&amp; yum-config-manager --add-repo $&#123;DOCKER_MIRROR_URL&#125;&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo \</span><br><span class="line">    &amp;&amp; yum makecache</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;centos&#x2F;$OS_VERSION&#x2F;os</span><br><span class="line">COPY packages.yaml .</span><br><span class="line">COPY --from&#x3D;mikefarah&#x2F;yq:4.11.1 &#x2F;usr&#x2F;bin&#x2F;yq &#x2F;usr&#x2F;bin&#x2F;yq</span><br><span class="line"></span><br><span class="line"># 根据配置文件解析该 OS 需要构建的包，并获取这些包的下载 url</span><br><span class="line">RUN yq eval &#39;.common[],.yum[],.centos7[],.kubespray.common[],.kubespray.yum[]&#39; packages.yaml &gt; packages.list \</span><br><span class="line">    &amp;&amp; sort -u packages.list | xargs repotrack --urls | sort -u &gt; packages.urls</span><br><span class="line"></span><br><span class="line"># 通过 wget 的方式下载 rpm 包，使用 createrepo 创建 repo 索引文件</span><br><span class="line">RUN ARCH&#x3D;$(uname -m) \</span><br><span class="line">    &amp;&amp; wget -q -x -P $&#123;ARCH&#125; -i packages.urls \</span><br><span class="line">    &amp;&amp; createrepo -d $&#123;ARCH&#125;</span><br><span class="line"></span><br><span class="line"># 将构建的内容 COPY 成单独的一层</span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;os-centos7 &#x2F;centos &#x2F;centos</span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com/k8sli/os-packages/blob/main/packages.yaml" target="_blank" rel="noopener">packages.yaml</a> 配置文件</li></ul><p>这个是需要安装包的配置文件，可以根据平台或者客户的一些要求配置上不同的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">kubespray:</span><br><span class="line">  common:</span><br><span class="line">    - curl</span><br><span class="line">    - rsync</span><br><span class="line">    - socat</span><br><span class="line">    - unzip</span><br><span class="line">    - e2fsprogs</span><br><span class="line">    - xfsprogs</span><br><span class="line">    - ebtables</span><br><span class="line">    - bash-completion</span><br><span class="line">    - ipvsadm</span><br><span class="line">    - ipset</span><br><span class="line">    - conntrack</span><br><span class="line"></span><br><span class="line">  yum:</span><br><span class="line">    - nss</span><br><span class="line">    - libselinux-python</span><br><span class="line">    - device-mapper-libs</span><br><span class="line">  apt:</span><br><span class="line">    - python-apt</span><br><span class="line">    - python3-apt</span><br><span class="line">    - aufs-tools</span><br><span class="line">    - apt-transport-https</span><br><span class="line">    - software-properties-common</span><br><span class="line"></span><br><span class="line">common:</span><br><span class="line">  - cifs-utils</span><br><span class="line">  - lsof</span><br><span class="line">  - lvm2</span><br><span class="line">  - openssl</span><br><span class="line">  - sshpass</span><br><span class="line">  - vim</span><br><span class="line">  - wget</span><br><span class="line">  - ethtool</span><br><span class="line">  - net-tools</span><br><span class="line">  - rsync</span><br><span class="line">  - chrony</span><br><span class="line"></span><br><span class="line">yum:</span><br><span class="line">  - nfs-utils</span><br><span class="line">  - yum-utils</span><br><span class="line">  - createrepo</span><br><span class="line">  - epel-release</span><br><span class="line">  - nc</span><br><span class="line">  - httpd-tools</span><br><span class="line"></span><br><span class="line">apt:</span><br><span class="line">  - nfs-common</span><br><span class="line">  - apt-transport-https</span><br><span class="line">  - ca-certificates</span><br><span class="line">  - gnupg</span><br><span class="line">  - lsb-release</span><br><span class="line">  - aptitude</span><br><span class="line">  - dpkg-dev</span><br><span class="line">  - gnupg2</span><br><span class="line">  - netcat</span><br><span class="line">  - apache2-utils</span><br><span class="line"></span><br><span class="line">centos7:</span><br><span class="line">  - containerd.io-1.4.6</span><br><span class="line"></span><br><span class="line">ubuntu:</span><br><span class="line">  - containerd.io&#x3D;1.4.6-1</span><br><span class="line"></span><br><span class="line">debian10:</span><br><span class="line">  - containerd.io&#x3D;1.4.6-1</span><br></pre></td></tr></table></figure><blockquote><p>对于 toB 产品，建议将下面这些常见的运维调试工具（如 tcpdump, strace, lsof, net-tools 等）也构建在离线源中。这样也不至于在客户的环境中排查问题的时候机器上连个 tcpdump 都没有，尤其是在无网的环境中，如果没有这些常用的运维工具，排查问题将会十分棘手。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">tools:</span><br><span class="line">  - bash-completion</span><br><span class="line">  - chrony</span><br><span class="line">  - cifs-utils</span><br><span class="line">  - curl</span><br><span class="line">  - dstat</span><br><span class="line">  - e2fsprogs</span><br><span class="line">  - ebtables</span><br><span class="line">  - expect</span><br><span class="line">  - gdb</span><br><span class="line">  - htop</span><br><span class="line">  - iftop</span><br><span class="line">  - iotop</span><br><span class="line">  - ipset</span><br><span class="line">  - ipvsadm</span><br><span class="line">  - jq</span><br><span class="line">  - lsof</span><br><span class="line">  - lvm2</span><br><span class="line">  - ncdu</span><br><span class="line">  - net-tools</span><br><span class="line">  - nethogs</span><br><span class="line">  - nload</span><br><span class="line">  - ntpdate</span><br><span class="line">  - openssl</span><br><span class="line">  - pciutils</span><br><span class="line">  - psmisc</span><br><span class="line">  - rsync</span><br><span class="line">  - smartmontools</span><br><span class="line">  - socat</span><br><span class="line">  - sshpass</span><br><span class="line">  - strace</span><br><span class="line">  - sysstat</span><br><span class="line">  - tcpdump</span><br><span class="line">  - telnet</span><br><span class="line">  - tmux</span><br></pre></td></tr></table></figure><h3><span id="kubespray">kubespray</span></h3><p>kubespray 是部署 K8s 集群、增加节点、删除节点、移除集群等涉及对集群操作的主要工具。我们依旧采用容器化的方式运行 kubespray，主要有以下场景会用到 kubespray：</p><ul><li>在部署工具运行节点，使用 nerdctl 来运行 kubespray 容器部署 K8s 集群</li><li>K8s 集群部署完毕后，以 Job pod 的方式运行部署另一个 K8s 集群，实现多集群部署的基本能力</li><li>K8s 集群部署完毕后，以 Job pod 的方式运行 kubespray 对该集群集群节点进行扩缩容</li></ul><p>Job pod 方式对集群进行扩缩容的设计的是为了从一定程度上解决部署大规模集群时 ansible 性能问题。即我们一开始不必就部署一个上千节点的集群，而是先把一个规模较小的集群部署起来，然后通过创建批量的 Job 的方式运行 kubespray 再将集群慢慢扩容起来，比如扩容到上千台节点。</p><p>kubespray 官方的 Dockerfile 构建出来的镜像有 1.4GB，实在是太大了，因此我们需要优化一下，减少镜像大小</p><ul><li>kubespray BASE 镜像</li></ul><p>首先构建一个 base 镜像，对于不经常变动的内容我们把它封装在一个 base 镜像里，只有当相关依赖更新了才需要重新构建这个 base 镜像，<code>Dockerfile.base</code> 如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">FROM python:3 as builder</span><br><span class="line">ARG KUBE_VERSION&#x3D;v1.21.3</span><br><span class="line">COPY requirements.txt requirements.txt</span><br><span class="line">COPY tests&#x2F;requirements.txt tests&#x2F;requirements.txt</span><br><span class="line">RUN echo &#39;shellcheck-py&#x3D;&#x3D;0.7.2.1&#39; &gt;&gt; requirements.txt \</span><br><span class="line">    &amp;&amp; grep -E &#39;^yamllint|^ansible-lint&#39; tests&#x2F;requirements.txt &gt;&gt; requirements.txt \</span><br><span class="line">    &amp;&amp; pip3 install --user -r requirements.txt</span><br><span class="line"></span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; wget -O &#x2F;root&#x2F;.local&#x2F;bin&#x2F;kubectl -q https:&#x2F;&#x2F;dl.k8s.io&#x2F;$&#123;KUBE_VERSION&#125;&#x2F;bin&#x2F;linux&#x2F;$&#123;ARCH&#125;&#x2F;kubectl \</span><br><span class="line">&amp;&amp; chmod a+x &#x2F;root&#x2F;.local&#x2F;bin&#x2F;kubectl</span><br><span class="line"></span><br><span class="line">FROM python:3-slim</span><br><span class="line">RUN DEBIAN_FRONTEND&#x3D;noninteractive apt-get update -y -qq \</span><br><span class="line">    &amp;&amp; apt-get install -y -qq --no-install-recommends \</span><br><span class="line">        ca-certificates libssl-dev openssh-client sshpass curl gnupg2 rsync \</span><br><span class="line">        jq moreutils vim iputils-ping wget tcpdump xz-utils \</span><br><span class="line">    &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</span><br><span class="line"></span><br><span class="line">COPY --from&#x3D;builder &#x2F;root&#x2F;.local &#x2F;usr&#x2F;local</span><br><span class="line">WORKDIR &#x2F;kubespray</span><br></pre></td></tr></table></figure><ul><li><a href="https://blog.k8s.li/pass-tob-k8s-offline-deploy.html?utm_source=pocket_mylist" target="_blank" rel="noopener">kubespray 镜像</a></li></ul><p>FROM 的 base 镜像就使用我们刚刚构建好的镜像，相关依赖已经在 base 镜像中安装好了，这里构建的时候只需要把 repo 源码复制到 /kubespray 目录下即可，内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ARG BASE_IMAGE&#x3D;ghcr.io&#x2F;k8sli&#x2F;kubespray-base</span><br><span class="line">ARG BASE_IMAGE_VERSION&#x3D;latest</span><br><span class="line">FROM $BASE_IMAGE:$BASE_IMAGE_VERSION</span><br><span class="line">WORKDIR &#x2F;kubespray</span><br><span class="line">COPY . .</span><br></pre></td></tr></table></figure><ul><li>kubespray 集群部署入口 <code>run.sh</code></li></ul><p>将集群部署、增加节点、删除节点、删除集群等操作封装成一个入口的脚本，提供外部工具调用该脚本，不然外部调用的时候直接运行 <code>ansible-playbook</code> 命令实在是不太方便。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">TYPE&#x3D;$1</span><br><span class="line">NODES&#x3D;$2</span><br><span class="line"></span><br><span class="line">KUBE_ROOT&#x3D;&quot;$(cd &quot;$(dirname &quot;$0&quot;)&quot; &amp;&amp; pwd)&quot;</span><br><span class="line"></span><br><span class="line">: $&#123;TYPE:&#x3D;deploy-cluster&#125;</span><br><span class="line">: $&#123;ANSIBLE_FORKS:&#x3D;10&#125;</span><br><span class="line">: $&#123;BECOME_USER:&#x3D;root&#125;</span><br><span class="line">: $&#123;ANSIBLE_LOG_FORMAT:&#x3D;yaml&#125;</span><br><span class="line">: $&#123;INVENTORY:&#x3D;$&#123;KUBE_ROOT&#125;&#x2F;config&#x2F;inventory&#125;</span><br><span class="line">: $&#123;ENV_FILE:&#x3D;$&#123;KUBE_ROOT&#125;&#x2F;config&#x2F;env.yml&#125;</span><br><span class="line">: $&#123;INSTALL_STEPS_FILE:&#x3D;$&#123;KUBE_ROOT&#125;&#x2F;config&#x2F;.install_steps&#125;</span><br><span class="line"></span><br><span class="line">export ANSIBLE_STDOUT_CALLBACK&#x3D;$&#123;ANSIBLE_LOG_FORMAT&#125;</span><br><span class="line">export ANSIBLE_ARGS&#x3D;&quot;-f $&#123;ANSIBLE_FORKS&#125; --become --become-user&#x3D;$&#123;BECOME_USER&#125; -i $&#123;INVENTORY&#125; -e @$&#123;ENV_FILE&#125;&quot;</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Set logging colors</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">NORMAL_COL&#x3D;$(tput sgr0)</span><br><span class="line">RED_COL&#x3D;$(tput setaf 1)</span><br><span class="line">WHITE_COL&#x3D;$(tput setaf 7)</span><br><span class="line">GREEN_COL&#x3D;$(tput setaf 76)</span><br><span class="line">YELLOW_COL&#x3D;$(tput setaf 202)</span><br><span class="line"></span><br><span class="line">debuglog()&#123; printf &quot;$&#123;WHITE_COL&#125;%s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line">infolog()&#123; printf &quot;$&#123;GREEN_COL&#125;✔ %s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line">warnlog()&#123; printf &quot;$&#123;YELLOW_COL&#125;➜ %s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line">errorlog()&#123; printf &quot;$&#123;RED_COL&#125;✖ %s$&#123;NORMAL_COL&#125;\n&quot; &quot;$@&quot;; &#125;</span><br><span class="line"></span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">if [[ ! -f $&#123;INVENTORY&#125; ]]; then</span><br><span class="line">  errorlog &quot;$&#123;INVENTORY&#125; file is missing, please check the inventory file is exists&quot;</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">deploy_cluster()&#123;</span><br><span class="line">:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">  case $TYPE in</span><br><span class="line">    deploy-cluster)</span><br><span class="line">      infolog &quot;######  start deploy kubernetes cluster  ######&quot;</span><br><span class="line">      deploy_cluster</span><br><span class="line">      infolog &quot;######  kubernetes cluster successfully installed  ######&quot;</span><br><span class="line">      ;;</span><br><span class="line">    remove-cluster)</span><br><span class="line">      infolog &quot;######  start remove kubernetes cluster  ######&quot;</span><br><span class="line">      if ansible-playbook $&#123;ANSIBLE_ARGS&#125; $&#123;KUBE_ROOT&#125;&#x2F;reset.yml &gt;&#x2F;dev&#x2F;stdout 2&gt;&#x2F;dev&#x2F;stderr; then</span><br><span class="line">        rm -f $&#123;INSTALL_STEP_FILE&#125;</span><br><span class="line">        infolog &quot;######  kubernetes cluster successfully removed ######&quot;</span><br><span class="line">      fi</span><br><span class="line">      ;;</span><br><span class="line">    add-node)</span><br><span class="line">      check_nodename</span><br><span class="line">      infolog &quot;######  start add worker to kubernetes cluster  ######&quot;</span><br><span class="line">      ansible-playbook $&#123;ANSIBLE_ARGS&#125; --limit&#x3D;&quot;$&#123;NODES&#125;&quot; $&#123;KUBE_ROOT&#125;&#x2F;playbooks&#x2F;10-scale-nodes.yml &gt;&#x2F;dev&#x2F;stdout 2&gt;&#x2F;dev&#x2F;stderr</span><br><span class="line">      ;;</span><br><span class="line">    remove-node)</span><br><span class="line">      check_nodename</span><br><span class="line">      infolog &quot;######  start remove worker from kubernetes cluster  ######&quot;</span><br><span class="line">      ansible-playbook $&#123;ANSIBLE_ARGS&#125; -e node&#x3D;&quot;$&#123;NODES&#125;&quot; -e reset_nodes&#x3D;true $&#123;KUBE_ROOT&#125;&#x2F;remove-node.yml &gt;&#x2F;dev&#x2F;stdout 2&gt;&#x2F;dev&#x2F;stderr</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      errorlog &quot;unknow [TYPE] parameter: $&#123;TYPE&#125;&quot;</span><br><span class="line">      ;;</span><br><span class="line">  esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main &quot;$@&quot;</span><br></pre></td></tr></table></figure><ul><li>分层部署 <a href="https://github.com/k8sli/kubespray/tree/main/playbooks" target="_blank" rel="noopener">playbooks</a></li></ul><p>不同于 kubespray 官方使用一个完整的 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/cluster.yml" target="_blank" rel="noopener">cluster.yaml</a> 来完成整个 K8s 集群的部署，我们在这里引入了分层部署的特性。即将集群部署分成若干个相互独立的 playbook，然后在各个 playbook 里引入我们增加的 roles 以及二开内容。这样的好处就是能和 kubespray 上游的代码保持相互独立，在 rebase 或者 cherry-pick 上游最新的代码能够避免出现冲突的现象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">playbooks</span><br><span class="line">├── 00-default-ssh-config.yml    # 配置 ssh 连接</span><br><span class="line">├── 01-cluster-bootstrap-os.yml  # 初始化集群节点</span><br><span class="line">├── 02-cluster-etcd.yml          # 部署 etcd 集群</span><br><span class="line">├── 03-cluster-kubernetes.yml    # 部署 k8s master 和 node</span><br><span class="line">├── 04-cluster-network.yml       # 部署 CNI 插件</span><br><span class="line">├── 05-cluster-apps.yml          # 部署一些 addon 组件如 coredns</span><br><span class="line">└── 10-scale-nodes.yml           # 增删节点</span><br></pre></td></tr></table></figure><p>分层部署的时候通过一个文件来记录已经部署成功的步骤，这样如果本次因为一些原因导致部署失败（如网络中断），那么下次重新部署的时候会跳过已经部署好的步骤，从失败的地方继续部署，以提升整体的部署效率。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">deploy_cluster()&#123;</span><br><span class="line">  touch $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">  STEPS&#x3D;&quot;00-default-ssh-config 01-cluster-bootstrap-os 02-cluster-etcd 03-cluster-kubernetes 04-cluster-network 05-cluster-apps&quot;</span><br><span class="line">  for step in $&#123;STEPS&#125;; do</span><br><span class="line">    if ! grep -q &quot;$&#123;step&#125;&quot; $&#123;INSTALL_STEPS_FILE&#125;; then</span><br><span class="line">      infolog &quot;start deploy $&#123;step&#125;&quot;</span><br><span class="line">      if ansible-playbook $&#123;ANSIBLE_ARGS&#125; $&#123;KUBE_ROOT&#125;&#x2F;playbooks&#x2F;$&#123;step&#125;.yml; then</span><br><span class="line">        echo $&#123;step&#125; &gt;&gt; $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">        infolog &quot;$&#123;step&#125; successfully installed&quot;</span><br><span class="line">      else</span><br><span class="line">        errorlog &quot;$&#123;step&#125; installation failed&quot;</span><br><span class="line">        exit 1</span><br><span class="line">      fi</span><br><span class="line">    else</span><br><span class="line">      warnlog &quot;$&#123;step&#125; is already installed, so skipped...&quot;</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="文件和镜像">文件和镜像</span></h3><p>我们需要提取出 kubespray 部署的时候依赖的文件和镜像，生成一个文件列表和镜像列表，然后根据这些列表下载并构建到一个镜像里。</p><ul><li>文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Download URLs</span><br><span class="line">kubelet_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubelet&quot;</span><br><span class="line">kubectl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubectl&quot;</span><br><span class="line">kubeadm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;&#123;&#123; kube_version &#125;&#125;&#x2F;bin&#x2F;linux&#x2F;&#123;&#123; image_arch &#125;&#125;&#x2F;kubeadm&quot;</span><br><span class="line">etcd_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;&#123;&#123; etcd_version &#125;&#125;&#x2F;etcd-&#123;&#123; etcd_version &#125;&#125;-linux-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">cni_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;containernetworking&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;&#123;&#123; cni_version &#125;&#125;&#x2F;cni-plugins-linux-&#123;&#123; image_arch &#125;&#125;-&#123;&#123; cni_version &#125;&#125;.tgz&quot;</span><br><span class="line">calicoctl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;projectcalico&#x2F;calicoctl&#x2F;releases&#x2F;download&#x2F;&#123;&#123; calico_ctl_version &#125;&#125;&#x2F;calicoctl-linux-&#123;&#123; image_arch &#125;&#125;&quot;</span><br><span class="line">calico_crds_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;projectcalico&#x2F;calico&#x2F;archive&#x2F;&#123;&#123; calico_version &#125;&#125;.tar.gz&quot;</span><br><span class="line">crictl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;cri-tools&#x2F;releases&#x2F;download&#x2F;&#123;&#123; crictl_version &#125;&#125;&#x2F;crictl-&#123;&#123; crictl_version &#125;&#125;-&#123;&#123; ansible_system | lower &#125;&#125;-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">helm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;get.helm.sh&#x2F;helm-&#123;&#123; helm_version &#125;&#125;-linux-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">nerdctl_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;containerd&#x2F;nerdctl&#x2F;releases&#x2F;download&#x2F;v&#123;&#123; nerdctl_version &#125;&#125;&#x2F;nerdctl-&#123;&#123; nerdctl_version &#125;&#125;-&#123;&#123; ansible_system | lower &#125;&#125;-&#123;&#123; image_arch &#125;&#125;.tar.gz&quot;</span><br><span class="line">patched_kubeadm_download_url: &quot;&#123;&#123; download_url &#125;&#125;&#x2F;github.com&#x2F;k8sli&#x2F;kubernetes&#x2F;releases&#x2F;download&#x2F;&#123;&#123; kubeadm_patch_version &#125;&#125;&#x2F;kubeadm-linux-&#123;&#123; image_arch &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><p>在构建安装包的时候，将 download_url 变量设置为 <code>https://</code> ，在部署的时候将 <code>download_url</code> 设置为内网 文件服务器服务器的 URL，比如 <code>https://172.20.0.25:8080/files</code>，这样就可以实现文件构建和部署使用的统一，节省维护成本。</p><ul><li>镜像</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># Define image repo and tag overwrite role&#x2F;download&#x2F;default&#x2F;main.yml</span><br><span class="line">pod_infra_image_tag: &quot;&#123;&#123; pod_infra_version &#125;&#125;&quot;</span><br><span class="line">pod_infra_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;pause&quot;</span><br><span class="line"></span><br><span class="line">kube_proxy_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-proxy&quot;</span><br><span class="line">kube_apiserver_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-apiserver&quot;</span><br><span class="line">kube_scheduler_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-scheduler&quot;</span><br><span class="line">kube_controller_manager_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;kube-controller-manager&quot;</span><br><span class="line"></span><br><span class="line">coredns_image_tag: &quot;&#123;&#123; coredns_version &#125;&#125;&quot;</span><br><span class="line">dnsautoscaler_image_tag: &quot;&#123;&#123; dnsautoscaler_version &#125;&#125;&quot;</span><br><span class="line">coredns_image_repo: &quot;&#123;&#123; docker_image_repo &#125;&#125;&#x2F;coredns&quot;</span><br><span class="line">dnsautoscaler_image_repo: &quot;&#123;&#123; kube_image_repo &#125;&#125;&#x2F;cluster-proportional-autoscaler-&#123;&#123; image_arch &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line"># Full image name for generate images list</span><br><span class="line">kube_proxy_image_name: &quot;&#123;&#123; kube_proxy_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">kube_apiserver_image_name: &quot;&#123;&#123; kube_apiserver_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">kube_scheduler_image_name: &quot;&#123;&#123; kube_scheduler_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">kube_controller_manager_image_name: &quot;&#123;&#123; kube_controller_manager_image_repo &#125;&#125;:&#123;&#123; kube_version &#125;&#125;&quot;</span><br><span class="line">coredns_image_name: &quot;&#123;&#123; coredns_image_repo &#125;&#125;:&#123;&#123; coredns_image_tag &#125;&#125;&quot;</span><br><span class="line">dnsautoscaler_image_name: &quot;&#123;&#123; dnsautoscaler_image_repo &#125;&#125;:&#123;&#123; dnsautoscaler_image_tag &#125;&#125;&quot;</span><br><span class="line">nginx_image_name: &quot;&#123;&#123; nginx_image_repo &#125;&#125;:&#123;&#123; nginx_image_tag &#125;&#125;&quot;</span><br><span class="line">pod_infra_image_name: &quot;&#123;&#123; pod_infra_image_repo &#125;&#125;:&#123;&#123; pod_infra_image_tag &#125;&#125;&quot;</span><br><span class="line">calico_policy_image_name: &quot;&#123;&#123; calico_policy_image_repo &#125;&#125;:&#123;&#123; calico_policy_image_tag &#125;&#125;&quot;</span><br><span class="line">calico_cni_image_name: &quot;&#123;&#123; calico_cni_image_repo &#125;&#125;:&#123;&#123; calico_cni_image_tag &#125;&#125;&quot;</span><br><span class="line">calico_node_image_name: &quot;&#123;&#123; calico_node_image_repo &#125;&#125;:&#123;&#123; calico_node_image_tag &#125;&#125;&quot;</span><br><span class="line">flannel_image_name: &quot;&#123;&#123; flannel_image_repo &#125;&#125;:&#123;&#123; flannel_image_tag &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><ul><li><code>generate.sh</code> 列表生成脚本</li></ul><p>我们根据上面 group_vars 中定义的版本号和一些参数，使用脚本的方式自动生成一个文件列表和镜像列表，构建的时候根据这些列表来下载所需要的文件和镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">SCRIPT_PATH&#x3D;$(cd $(dirname $0); pwd)</span><br><span class="line">REPO_PATH&#x3D;&quot;$&#123;SCRIPT_PATH%&#x2F;build&#125;&quot;</span><br><span class="line"></span><br><span class="line">: $&#123;IMAGE_ARCH:&#x3D;&quot;amd64&quot;&#125;</span><br><span class="line">: $&#123;ANSIBLE_ARCHITECTURE:&#x3D;&quot;x86_64&quot;&#125;</span><br><span class="line">: $&#123;DOWNLOAD_YML:&#x3D;&quot;config&#x2F;group_vars&#x2F;all&#x2F;download.yml&quot;&#125;</span><br><span class="line"></span><br><span class="line"># ARCH used in convert &#123;%- if image_arch !&#x3D; &#39;amd64&#39; -%&#125;-&#123;&#123; image_arch &#125;&#125;&#123;%- endif -%&#125; to &#123;&#123;arch&#125;&#125;</span><br><span class="line">if [[ &quot;$&#123;IMAGE_ARCH&#125;&quot; !&#x3D; &quot;amd64&quot; ]]; then ARCH&#x3D;&quot;-$&#123;IMAGE_ARCH&#125;&quot;; fi</span><br><span class="line"></span><br><span class="line">cat &gt; &#x2F;tmp&#x2F;generate.sh &lt;&lt; EOF</span><br><span class="line">arch&#x3D;$&#123;ARCH&#125;</span><br><span class="line">download_url&#x3D;https:&#x2F;</span><br><span class="line">image_arch&#x3D;$&#123;IMAGE_ARCH&#125;</span><br><span class="line">ansible_system&#x3D;linux</span><br><span class="line">ansible_architecture&#x3D;$&#123;ANSIBLE_ARCHITECTURE&#125;</span><br><span class="line">registry_project&#x3D;library</span><br><span class="line">registry_domain&#x3D;localhost</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># generate all component version by $DOWNLOAD_YML</span><br><span class="line">grep &#39;_version:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| sed &#39;s&#x2F;: &#x2F;&#x3D;&#x2F;g;s&#x2F;&#123;&#123;&#x2F;$&#123;&#x2F;g;s&#x2F;&#125;&#125;&#x2F;&#125;&#x2F;g&#39; | tr -d &#39; &#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br><span class="line"></span><br><span class="line"># generate download files url list</span><br><span class="line">grep &#39;_download_url:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| sed &#39;s&#x2F;: &#x2F;&#x3D;&#x2F;g;s&#x2F; &#x2F;&#x2F;g;s&#x2F;&#123;&#123;&#x2F;$&#123;&#x2F;g;s&#x2F;&#125;&#125;&#x2F;&#125;&#x2F;g;s&#x2F;|lower&#x2F;&#x2F;g;s&#x2F;^.*_url&#x3D;&#x2F;echo &#x2F;g&#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br><span class="line"></span><br><span class="line"># generate download images list</span><br><span class="line">grep -E &#39;_image_tag:|_image_repo:|_image_name:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| sed &quot;s#&#123;%- if image_arch !&#x3D; &#39;amd64&#39; -%&#125;-&#123;&#123; image_arch &#125;&#125;&#123;%- endif -%&#125;#&#123;&#123;arch&#125;&#125;#g&quot; \</span><br><span class="line">| sed &#39;s&#x2F;: &#x2F;&#x3D;&#x2F;g;s&#x2F;&#123;&#123;&#x2F;$&#123;&#x2F;g;s&#x2F;&#125;&#125;&#x2F;&#125;&#x2F;g&#39; | tr -d &#39; &#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br><span class="line"></span><br><span class="line">grep &#39;_image_name:&#39; $&#123;REPO_PATH&#125;&#x2F;$&#123;DOWNLOAD_YML&#125; \</span><br><span class="line">| cut -d &#39;:&#39; -f1 | sed &#39;s&#x2F;^&#x2F;echo $&#x2F;g&#39; &gt;&gt; &#x2F;tmp&#x2F;generate.sh</span><br></pre></td></tr></table></figure><p>为了同时支持 amd64 和 arm64 的 CPU 架构，需要为两种架构各自生成列表，需要特殊处理一下。在这里踩的一个坑就是不同的组件镜像的命名方法千差万别，大致可以分为如下四种情况：</p><ul><li>像 kube-apiserver 这些 k8s 组件的镜像，镜像名称和镜像 tag 是不需要加上 CPU 体系架构的；</li><li>cluster-proportional-autoscaler 的镜像则是在镜像的名称后面加上了 CPU 体系架构的名称如 cluster-proportional-autoscaler-amd64，cluster-proportional-autoscaler-arm64；</li><li>flannel 则是将 CPU 体系架构名称定义在镜像 tag 后面比如 <code>flannel:v0.14.0-amd64</code>；</li><li>还有 calico 更奇葩，amd64 架构的镜像不需要加体系架构的名称如 <code>calico/cni:v3.18.4</code>，而 arm64 的则必须要在镜像 tag 后面带上 CPU 体系架构比如 <code>calico/cni:v3.18.4-arm64</code>；</li></ul><p>在这里需要强调一下，文件列表和镜像列表一定要使用自动化的方式来管理，切勿手动更新，这样能节省大量的维护成本，不然的话每次都手动去更新这些列表成本实在是太高了，而且特别容易出出错或者遗漏某个组件。</p><h3><span id="kubespray-files">kubespray-files</span></h3><p>我们将 kubespray 部署所依赖的二进制文件构建在一个名为 kubespray-files 的镜像当中：</p><ul><li>生成的文件列表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;get.helm.sh&#x2F;helm-v3.6.3-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;containerd&#x2F;nerdctl&#x2F;releases&#x2F;download&#x2F;v0.8.1&#x2F;nerdctl-0.8.1-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;containernetworking&#x2F;plugins&#x2F;releases&#x2F;download&#x2F;v0.9.1&#x2F;cni-plugins-linux-amd64-v0.9.1.tgz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;v3.4.13&#x2F;etcd-v3.4.13-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;kubernetes&#x2F;releases&#x2F;download&#x2F;v1.21.3-patch-1.0&#x2F;kubeadm-linux-amd64</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;cri-tools&#x2F;releases&#x2F;download&#x2F;v1.21.0&#x2F;crictl-v1.21.0-linux-amd64.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;projectcalico&#x2F;calico&#x2F;archive&#x2F;v3.18.4.tar.gz</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;projectcalico&#x2F;calicoctl&#x2F;releases&#x2F;download&#x2F;v3.18.4&#x2F;calicoctl-linux-amd64</span><br><span class="line">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;v1.21.3&#x2F;bin&#x2F;linux&#x2F;amd64&#x2F;kubeadm</span><br><span class="line">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;v1.21.3&#x2F;bin&#x2F;linux&#x2F;amd64&#x2F;kubectl</span><br><span class="line">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;kubernetes-release&#x2F;release&#x2F;v1.21.3&#x2F;bin&#x2F;linux&#x2F;amd64&#x2F;kubelet</span><br></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest as files</span><br><span class="line">RUN apk --no-cache add wget ca-certificates</span><br><span class="line">WORKDIR &#x2F;build</span><br><span class="line">COPY build&#x2F;kubespray-files&#x2F;files_*.list &#x2F;build&#x2F;</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; sed &#39;&#x2F;#&#x2F;d&#39; *$&#123;ARCH&#125;.list &gt; all_files.list \</span><br><span class="line">    &amp;&amp; wget -q -x -P &#x2F;files -i all_files.list</span><br><span class="line"></span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;files &#x2F;files &#x2F;files</span><br></pre></td></tr></table></figure><ul><li>构建后的目录结构，通过目录层级的方式保留原有的 URL 地址，维护和使用起来比较方便</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">files&#x2F;</span><br><span class="line">├── get.helm.sh</span><br><span class="line">│   └── helm-v3.6.3-linux-amd64.tar.gz</span><br><span class="line">├── github.com</span><br><span class="line">│   ├── containerd</span><br><span class="line">│   │   └── nerdctl</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v0.8.1</span><br><span class="line">│   │                   └── nerdctl-0.8.1-linux-amd64.tar.gz</span><br><span class="line">│   ├── containernetworking</span><br><span class="line">│   │   └── plugins</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v0.9.1</span><br><span class="line">│   │                   └── cni-plugins-linux-amd64-v0.9.1.tgz</span><br><span class="line">│   ├── coreos</span><br><span class="line">│   │   └── etcd</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v3.4.13</span><br><span class="line">│   │                   └── etcd-v3.4.13-linux-amd64.tar.gz</span><br><span class="line">│   ├── k8sli</span><br><span class="line">│   │   └── kubernetes</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v1.21.3-patch-1.0</span><br><span class="line">│   │                   └── kubeadm-linux-amd64</span><br><span class="line">│   ├── kubernetes-sigs</span><br><span class="line">│   │   └── cri-tools</span><br><span class="line">│   │       └── releases</span><br><span class="line">│   │           └── download</span><br><span class="line">│   │               └── v1.21.0</span><br><span class="line">│   │                   └── crictl-v1.21.0-linux-amd64.tar.gz</span><br><span class="line">│   └── projectcalico</span><br><span class="line">│       ├── calico</span><br><span class="line">│       │   └── archive</span><br><span class="line">│       │       └── v3.18.4.tar.gz</span><br><span class="line">│       └── calicoctl</span><br><span class="line">│           └── releases</span><br><span class="line">│               └── download</span><br><span class="line">│                   └── v3.18.4</span><br><span class="line">│                       └── calicoctl-linux-amd64</span><br><span class="line">└── storage.googleapis.com</span><br><span class="line">    └── kubernetes-release</span><br><span class="line">        └── release</span><br><span class="line">            └── v1.21.3</span><br><span class="line">                └── bin</span><br><span class="line">                    └── linux</span><br><span class="line">                        └── amd64</span><br><span class="line">                            ├── kubeadm</span><br><span class="line">                            ├── kubectl</span><br><span class="line">                            └── kubelet</span><br></pre></td></tr></table></figure><h3><span id="kubespray-images">kubespray-images</span></h3><p>我们同样将 kubespray 部署所需要的组件镜像构建在一个名为 kubespray-images 的镜像当中：</p><ul><li>镜像列表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">library&#x2F;calico-cni:v3.18.4</span><br><span class="line">library&#x2F;calico-kube-controllers:v3.18.4</span><br><span class="line">library&#x2F;calico-node:v3.18.4</span><br><span class="line">library&#x2F;calico-pod2daemon-flexvol:v3.18.4</span><br><span class="line">library&#x2F;cluster-proportional-autoscaler-amd64:1.8.3</span><br><span class="line">library&#x2F;coredns:v1.8.0</span><br><span class="line">library&#x2F;flannel:v0.14.0-amd64</span><br><span class="line">library&#x2F;kube-apiserver:v1.21.3</span><br><span class="line">library&#x2F;kube-controller-manager:v1.21.3</span><br><span class="line">library&#x2F;kube-proxy:v1.21.3</span><br><span class="line">library&#x2F;kube-scheduler:v1.21.3</span><br><span class="line">library&#x2F;nginx:1.19</span><br><span class="line">library&#x2F;pause:3.3</span><br></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><p>在 Dockerfile 里完成所有镜像的下载，并使用 《<a href="https://blog.k8s.li/skopeo-to-registry.html" target="_blank" rel="noopener">如何使用 registry 存储的特性</a>》文中提到的骚操作，利用 registry 存储复用相同 layer 的特性，将 skopeo sync 下载的镜像转换成 registry 存储的结构。这样在部署的时候直接把这个 registry 存储目录挂载进 registry 容器的 <code>/var/lib/registry</code> 即可。特点是性能方面无论是构建和部署，都比常规使用 docker save 和 docker load 的方式要快至少 5 到 10 倍。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:3.12 as images</span><br><span class="line">ARG SKOPEO_VERSION&#x3D;v1.4.0</span><br><span class="line">ARG YQ_VERSION&#x3D;v4.11.2</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; apk --no-cache add bash wget ca-certificates \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;mikefarah&#x2F;yq&#x2F;releases&#x2F;download&#x2F;$&#123;YQ_VERSION&#125;&#x2F;yq_linux_$&#123;ARCH&#125; -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;yq \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;skopeo&#x2F;releases&#x2F;download&#x2F;$&#123;SKOPEO_VERSION&#125;&#x2F;skopeo-linux-$&#123;ARCH&#125; -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;skopeo \</span><br><span class="line">    &amp;&amp; chmod a+x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;*</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;build</span><br><span class="line">COPY build&#x2F;kubespray-images&#x2F;*  &#x2F;build&#x2F;</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; IMAGE_ARCH&#x3D;$&#123;ARCH&#125; bash build.sh</span><br><span class="line"></span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;images &#x2F;build&#x2F;docker &#x2F;docker</span><br></pre></td></tr></table></figure><ul><li>images_origin.yaml 镜像配置文件</li></ul><p>考虑到有将镜像导入到已经存在的镜像仓库中的场景，这里我们需要修改一下镜像仓库的 repo。因为 <code>library</code> 这个 repo 在 harbor 中是默认自带的，在导入到 harbor 的过程中也不需要创建一些额外的 project ，所以将所有镜像的 repo 全部统一为 <code>library</code> 更通用一些。</p><p>这里用一个 yaml 配置文件来记录原镜像地址和 library 镜像的地址的对应关系。比如上游的 <code>k8s.gcr.io/kube-apiserver</code> 映射为 <code>library/kube-apiserver</code>， <code>quay.io/calico/node</code> 映射为 <code>library/calico-node</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line"># kubeadm core images</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-apiserver</span><br><span class="line">  dest: library&#x2F;kube-apiserver</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-controller-manager</span><br><span class="line">  dest: library&#x2F;kube-controller-manager</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-proxy</span><br><span class="line">  dest: library&#x2F;kube-proxy</span><br><span class="line">- src: k8s.gcr.io&#x2F;kube-scheduler</span><br><span class="line">  dest: library&#x2F;kube-scheduler</span><br><span class="line">- src: k8s.gcr.io&#x2F;coredns&#x2F;coredns</span><br><span class="line">  dest: library&#x2F;coredns</span><br><span class="line">- src: k8s.gcr.io&#x2F;pause</span><br><span class="line">  dest: library&#x2F;pause</span><br><span class="line"></span><br><span class="line"># kubernetes addons</span><br><span class="line">- src: k8s.gcr.io&#x2F;dns&#x2F;k8s-dns-node-cache</span><br><span class="line">  dest: library&#x2F;k8s-dns-node-cache</span><br><span class="line">- src: k8s.gcr.io&#x2F;cpa&#x2F;cluster-proportional-autoscaler-amd64</span><br><span class="line">  dest: library&#x2F;cluster-proportional-autoscaler-amd64</span><br><span class="line">- src: k8s.gcr.io&#x2F;cpa&#x2F;cluster-proportional-autoscaler-arm64</span><br><span class="line">  dest: library&#x2F;cluster-proportional-autoscaler-arm64</span><br><span class="line"></span><br><span class="line"># network plugin</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;cni</span><br><span class="line">  dest: library&#x2F;calico-cni</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;node</span><br><span class="line">  dest: library&#x2F;calico-node</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;kube-controllers</span><br><span class="line">  dest: library&#x2F;calico-kube-controllers</span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;pod2daemon-flexvol</span><br><span class="line">  dest: library&#x2F;calico-pod2daemon-flexvol</span><br><span class="line"></span><br><span class="line">- src: quay.io&#x2F;calico&#x2F;typha</span><br><span class="line">  dest: library&#x2F;calico-typha</span><br><span class="line">- src: quay.io&#x2F;coreos&#x2F;flannel</span><br><span class="line">  dest: library&#x2F;flannel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># nginx for daemonset and offline</span><br><span class="line">- src: docker.io&#x2F;library&#x2F;nginx</span><br><span class="line">  dest: library&#x2F;nginx</span><br></pre></td></tr></table></figure><h3><span id="kubeplay">kubeplay</span></h3><p>kubeplay 部署的代码主要是由一些 shell 脚本和配置文件构成，用于完成 nginx 服务和 registry 服务的部署，以及最后调用 kubespray 来完成集群部署。</p><blockquote><p>kubeplay 项目地址：<a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">https://github.com/k8sli/kubeplay</a></p></blockquote><ul><li>代码结构</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kubeplay&#x2F;</span><br><span class="line">├── Dockerfile          # 构建完整安装包的 Dockerfile</span><br><span class="line">├── compose.yaml        # compose 启动配置 yaml 文件</span><br><span class="line">├── config</span><br><span class="line">│   ├── compose</span><br><span class="line">│   │   └── nginx.conf  # nginx 配置文件</span><br><span class="line">│   └── rootCA.cnf      # 生成镜像仓库证书用到的 openssl 配置文件</span><br><span class="line">├── config-sample.yaml  # 主配置文件</span><br><span class="line">├── install.sh          # 安装操作然后</span><br><span class="line">└── library             # 一些 shell 函数库</span><br></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest as downloader</span><br><span class="line">ARG SKOPEO_VERSION&#x3D;v1.4.0</span><br><span class="line">ARG YQ_VERSION&#x3D;v4.11.2</span><br><span class="line">ARG NERDCTL_VERSION&#x3D;0.11.0</span><br><span class="line">ARG NGINX_VERSION&#x3D;1.20-alpine</span><br><span class="line">ARG RERGISRRY_VERSION&#x3D;2.7.1</span><br><span class="line">ARG KUBESPRAY_VERSION&#x3D;latest</span><br><span class="line">ARG KUBESPRAY_IMAGE&#x3D;ghcr.io&#x2F;k8sli&#x2F;kubespray</span><br><span class="line"></span><br><span class="line"># 下载部署时需要的工具，如 yq、skopeo、nerdctl-fullsss</span><br><span class="line">WORKDIR &#x2F;tools</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; apk --no-cache add wget ca-certificates \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;mikefarah&#x2F;yq&#x2F;releases&#x2F;download&#x2F;$&#123;YQ_VERSION&#125;&#x2F;yq_linux_$&#123;ARCH&#125;  -O &#x2F;tools&#x2F;yq-linux-$&#123;ARCH&#125; \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;k8sli&#x2F;skopeo&#x2F;releases&#x2F;download&#x2F;v1.4.0&#x2F;skopeo-linux-$&#123;ARCH&#125; -O &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; \</span><br><span class="line">    &amp;&amp; wget -q -k https:&#x2F;&#x2F;github.com&#x2F;containerd&#x2F;nerdctl&#x2F;releases&#x2F;download&#x2F;v$&#123;NERDCTL_VERSION&#125;&#x2F;nerdctl-full-$&#123;NERDCTL_VERSION&#125;-linux-$&#123;ARCH&#125;.tar.gz \</span><br><span class="line">    &amp;&amp; chmod a+x &#x2F;tools&#x2F;* \</span><br><span class="line">    &amp;&amp; ln -s &#x2F;tools&#x2F;skopeo-linux-$&#123;ARCH&#125; &#x2F;usr&#x2F;bin&#x2F;skopeo</span><br><span class="line"></span><br><span class="line"># 下载一些镜像，如 nginx、registry、kubespray</span><br><span class="line">WORKDIR &#x2F;images</span><br><span class="line">RUN ARCH&#x3D;$(uname -m | sed &#39;s&#x2F;x86_64&#x2F;amd64&#x2F;;s&#x2F;aarch64&#x2F;arm64&#x2F;&#39;) \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag nginx:$&#123;NGINX_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;nginx:$&#123;NGINX_VERSION&#125; docker-archive:nginx-$&#123;NGINX_VERSION&#125;.tar \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag registry:$&#123;RERGISRRY_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;docker.io&#x2F;library&#x2F;registry:$&#123;RERGISRRY_VERSION&#125; docker-archive:registry-$&#123;RERGISRRY_VERSION&#125;.tar \</span><br><span class="line">    &amp;&amp; skopeo copy --insecure-policy --src-tls-verify&#x3D;false --override-arch $&#123;ARCH&#125; --additional-tag kubespray:$&#123;KUBESPRAY_VERSION&#125; \</span><br><span class="line">       docker:&#x2F;&#x2F;$&#123;KUBESPRAY_IMAGE&#125;:$&#123;KUBESPRAY_VERSION&#125; docker-archive:kubespray-$&#123;KUBESPRAY_VERSION&#125;.tar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FROM scratch</span><br><span class="line">COPY . .</span><br><span class="line"> # 将其它模块中的内容复制到 scratch 镜像中，构建的时候导出为 local 方式</span><br><span class="line">COPY --from&#x3D;downloader &#x2F;tools &#x2F;resources&#x2F;nginx&#x2F;tools</span><br><span class="line">COPY --from&#x3D;downloader &#x2F;images &#x2F;resources&#x2F;images</span><br><span class="line">COPY --from&#x3D;$&#123;OS_PACKAGES_IMAGE&#125;:$&#123;OS_PACKAGE_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;nginx</span><br><span class="line">COPY --from&#x3D;$&#123;KUBESPRAY_FILES_IMAGE&#125;:$&#123;KUBESPRAY_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;nginx</span><br><span class="line">COPY --from&#x3D;$&#123;KUBESPRAY_IMAGES_IMAGE&#125;:$&#123;KUBESPRAY_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;registry</span><br></pre></td></tr></table></figure><h3><span id="构建">构建</span></h3><p>由于最终的构建涉及多个模块和 repo，其流程比较复杂，详细的代码可参考源码 <a href="https://github.com/k8sli/kubeplay/blob/main/.github/workflows/build.yaml" target="_blank" rel="noopener">build.yaml</a> ，在这里只讲几个关键的部分</p><ul><li>checkout repo，将 kubespray 和 os-packages repo clone 到工作目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  build-package:</span><br><span class="line">    # 以 tag 的事件触发构建流水线</span><br><span class="line">    if: startsWith(github.ref, &#39;refs&#x2F;tags&#x2F;&#39;)</span><br><span class="line">    runs-on: ubuntu-20.04</span><br><span class="line">    steps:</span><br><span class="line">      - name: Checkout</span><br><span class="line">        uses: actions&#x2F;checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          # fetch all git repo tag for define image tag</span><br><span class="line">          fetch-depth: 0</span><br><span class="line"></span><br><span class="line">      - name: Checkout kubespray repo</span><br><span class="line">        uses: actions&#x2F;checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          ref: main</span><br><span class="line">          fetch-depth: 0</span><br><span class="line">          path: kubespray</span><br><span class="line">          repository: $&#123;&#123; github.repository_owner &#125;&#125;&#x2F;kubespray</span><br><span class="line"></span><br><span class="line">      - name: Checkout os-packages repo</span><br><span class="line">        uses: actions&#x2F;checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          ref: main</span><br><span class="line">          fetch-depth: 0</span><br><span class="line">          path: os-packages</span><br><span class="line">          repository: $&#123;&#123; github.repository_owner &#125;&#125;&#x2F;os-packages</span><br></pre></td></tr></table></figure><ul><li>获取 kubespray 和 os-packages 的 repo tag，根据它来确定 os-packages, kubespray-files, kubespray-images 这个三个镜像的 tag，并生成一个 All in One 的 Dockerfile 用于完成后续安装包的构建。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 获取一些组件的版本和变量传递给 Dockerfile</span><br><span class="line">- name: Prepare for build images</span><br><span class="line">  shell: bash</span><br><span class="line">  run: |</span><br><span class="line">    git describe --tags --always | sed &#39;s&#x2F;^&#x2F;IMAGE_TAG&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line"></span><br><span class="line">    cd kubespray &amp;&amp; git describe --tags --always | sed &#39;s&#x2F;^&#x2F;KUBESPRAY_VERSION&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV &amp;&amp; cd ..</span><br><span class="line">    cd os-packages &amp;&amp; git describe --tags --always | sed &#39;s&#x2F;^&#x2F;OS_PACKAGE_REPO_TAG&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV &amp;&amp; cd ..</span><br><span class="line">    cp -rf kubespray&#x2F;config config&#x2F;kubespray &amp;&amp; rm -rf kubespray os-packages</span><br><span class="line"></span><br><span class="line">    source $GITHUB_ENV</span><br><span class="line">    echo &quot;&quot; &gt;&gt; Dockerfile</span><br><span class="line">    echo &quot;COPY --from&#x3D;$&#123;OS_PACKAGES_IMAGE&#125;:$&#123;OS_PACKAGE_REPO_TAG&#125; &#x2F; &#x2F;resources&#x2F;nginx&quot; &gt;&gt; Dockerfile</span><br><span class="line">    echo &quot;COPY --from&#x3D;$&#123;KUBESPRAY_FILES_IMAGE&#125;:$&#123;KUBESPRAY_VERSION&#125; &#x2F; &#x2F;resources&#x2F;nginx&quot; &gt;&gt; Dockerfile</span><br><span class="line">    echo &quot;COPY --from&#x3D;$&#123;KUBESPRAY_IMAGES_IMAGE&#125;:$&#123;KUBESPRAY_VERSION&#125; &#x2F; &#x2F;resources&#x2F;registry&quot; &gt;&gt; Dockerfile</span><br><span class="line"></span><br><span class="line">    sed -n &#39;s|image: nginx:|NGINX_VERSION&#x3D;|p&#39; compose.yaml | tr -d &#39; &#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    sed -n &#39;s|image: registry:|RERGISRRY_VERSION&#x3D;|p&#39; compose.yaml | tr -d &#39; &#39; &gt;&gt; $GITHUB_ENV</span><br></pre></td></tr></table></figure><ul><li>使用 <code>outputs: type=local,dest=./</code> 构建镜像到本地目录而非 push 到 registry</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- name: Build kubeplay image to local</span><br><span class="line">  uses: docker&#x2F;build-push-action@v2</span><br><span class="line">  with:</span><br><span class="line">    context: .</span><br><span class="line">    file: Dockerfile</span><br><span class="line">    platforms: linux&#x2F;amd64,linux&#x2F;arm64</span><br><span class="line">    build-args: |</span><br><span class="line">      NGINX_VERSION&#x3D;$&#123;&#123; env.NGINX_VERSION &#125;&#125;</span><br><span class="line">      RERGISRRY_VERSION&#x3D;$&#123;&#123; env.RERGISRRY_VERSION &#125;&#125;</span><br><span class="line">      KUBESPRAY_IMAGE&#x3D;$&#123;&#123; env.KUBESPRAY_IMAGE &#125;&#125;</span><br><span class="line">      KUBESPRAY_VERSION&#x3D;$&#123;&#123; env.KUBESPRAY_VERSION &#125;&#125;</span><br><span class="line">    outputs: type&#x3D;local,dest&#x3D;.&#x2F;</span><br></pre></td></tr></table></figure><ul><li>打包并上传安装包到 GitHub release 存储</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">- name: Prepare for upload package</span><br><span class="line">  shell: bash</span><br><span class="line">  run: |</span><br><span class="line">    rm -rf linux_&#123;amd64,arm64&#125;&#x2F;&#123;Dockerfile,LICENSE&#125;</span><br><span class="line">    mv linux_amd64 kubeplay</span><br><span class="line">    tar -I pigz -cf kubeplay-$&#123;IMAGE_TAG&#125;-linux-amd64.tar.gz kubeplay --remove-files</span><br><span class="line">    mv linux_arm64 kubeplay</span><br><span class="line">    tar -I pigz -cf kubeplay-$&#123;IMAGE_TAG&#125;-linux-arm64.tar.gz kubeplay --remove-files</span><br><span class="line">    sha256sum kubeplay-$&#123;IMAGE_TAG&#125;-linux-&#123;amd64,arm64&#125;.tar.gz &gt; sha256sum.txt</span><br><span class="line"></span><br><span class="line">- name: Release and upload packages</span><br><span class="line">  uses: softprops&#x2F;action-gh-release@v1</span><br><span class="line">  env:</span><br><span class="line">    GITHUB_TOKEN: $&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125;</span><br><span class="line">  with:</span><br><span class="line">    files: |</span><br><span class="line">      sha256sum.txt</span><br><span class="line">      kubeplay-$&#123;&#123; env.IMAGE_TAG &#125;&#125;-linux-amd64.tar.gz</span><br><span class="line">      kubeplay-$&#123;&#123; env.IMAGE_TAG &#125;&#125;-linux-arm64.tar.gz</span><br></pre></td></tr></table></figure><p>由此一个完整的离线安装包就构建完成了，接下来再讲一下安装流程</p><h2><span id="安装流程">安装流程</span></h2><p>在 <a href="https://github.com/k8sli/kubeplay/releases" target="_blank" rel="noopener">GitHub release 页面</a> 将我们的离线安装包下载到本地，需要根据 CPU 架构的类型选择相应的安装包。</p><p><img src="https://p.k8s.li/2021-08-24-offline-deploy-k8s-1.png" alt></p><p>下载完成之后再将安装包通过 scp 或者其他方式上传到内网的部署节点上，部署的文档可参考 <a href="https://github.com/k8sli/kubeplay" target="_blank" rel="noopener">README</a> 。过程十分简单：只需要填写好 <code>config.yaml</code> 配置文件然后执行 <code>bash install.sh</code> 即可完成 K8s 集群的一键部署。</p><p>下面从源码而非 README 文档的角度来讲一下部署流程的实现细节</p><h3><span id="安装包结构">安装包结构</span></h3><ul><li>配置文件 <code>config.yaml</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"># nginx 端口和 registry 域名配置参数</span><br><span class="line">compose:</span><br><span class="line">  # Compose bootstrap node ip, default is local internal ip</span><br><span class="line">  internal_ip: 172.20.0.25</span><br><span class="line">  # Nginx http server bind port for download files and packages</span><br><span class="line">  nginx_http_port: 8080</span><br><span class="line">  # Registry domain for CRI runtime download images</span><br><span class="line">  registry_domain: kube.registry.local</span><br><span class="line"></span><br><span class="line"># kubespray 参数</span><br><span class="line">kubespray:</span><br><span class="line">  # Kubernetes version by default, only support v1.20.6</span><br><span class="line">  kube_version: v1.21.3</span><br><span class="line">  # For deploy HA cluster you must configure a external apiserver access ip</span><br><span class="line">  external_apiserver_access_ip: 127.0.0.1</span><br><span class="line">  # Set network plugin to calico with vxlan mode by default</span><br><span class="line">  kube_network_plugin: calico</span><br><span class="line">  #Container runtime, only support containerd if offline deploy</span><br><span class="line">  container_manager: containerd</span><br><span class="line">  # Now only support host if use containerd as CRI runtime</span><br><span class="line">  etcd_deployment_type: host</span><br><span class="line">  # Settings for etcd event server</span><br><span class="line">  etcd_events_cluster_setup: true</span><br><span class="line">  etcd_events_cluster_enabled: true</span><br><span class="line"></span><br><span class="line"># 集群节点 ssh 登录 inventory 配置</span><br><span class="line"># Cluster nodes inventory info</span><br><span class="line">inventory:</span><br><span class="line">  all:</span><br><span class="line">    vars:</span><br><span class="line">      ansible_port: 22</span><br><span class="line">      ansible_user: root</span><br><span class="line">      ansible_ssh_pass: Password</span><br><span class="line">      # ansible_ssh_private_key_file: &#x2F;kubespray&#x2F;config&#x2F;id_rsa</span><br><span class="line">    hosts:</span><br><span class="line">      node1:</span><br><span class="line">        ansible_host: 172.20.0.21</span><br><span class="line">      node2:</span><br><span class="line">        ansible_host: 172.20.0.22</span><br><span class="line">      node3:</span><br><span class="line">        ansible_host: 172.20.0.23</span><br><span class="line">      node4:</span><br><span class="line">        ansible_host: 172.20.0.24</span><br><span class="line">    children:</span><br><span class="line">      kube_control_plane:</span><br><span class="line">        hosts:</span><br><span class="line">          node1:</span><br><span class="line">          node2:</span><br><span class="line">          node3:</span><br><span class="line">      kube_node:</span><br><span class="line">        hosts:</span><br><span class="line">          node1:</span><br><span class="line">          node2:</span><br><span class="line">          node3:</span><br><span class="line">          node4:</span><br><span class="line">      etcd:</span><br><span class="line">        hosts:</span><br><span class="line">          node1:</span><br><span class="line">          node2:</span><br><span class="line">          node3:</span><br><span class="line">      k8s_cluster:</span><br><span class="line">        children:</span><br><span class="line">          kube_control_plane:</span><br><span class="line">          kube_node:</span><br><span class="line">      gpu:</span><br><span class="line">        hosts: &#123;&#125;</span><br><span class="line">      calico_rr:</span><br><span class="line">        hosts: &#123;&#125;</span><br><span class="line"></span><br><span class="line"># 一些默认的配置，一般情况下无需修改</span><br><span class="line">### Default parameters ###</span><br><span class="line">## This filed not need config, will auto update,</span><br><span class="line">## if no special requirement, do not modify these parameters.</span><br><span class="line">default:</span><br><span class="line">  # NTP server ip address or domain, default is internal_ip</span><br><span class="line">  ntp_server:</span><br><span class="line">    - internal_ip</span><br><span class="line">  # Registry ip address, default is internal_ip</span><br><span class="line">  registry_ip: internal_ip</span><br><span class="line">  # Offline resource url for download files, default is internal_ip:nginx_http_port</span><br><span class="line">  offline_resources_url: internal_ip:nginx_http_port</span><br><span class="line">  # Use nginx and registry provide all offline resources</span><br><span class="line">  offline_resources_enabled: true</span><br><span class="line">  # Image repo in registry</span><br><span class="line">  image_repository: library</span><br><span class="line">  # Kubespray container image for deploy user cluster or scale</span><br><span class="line">  kubespray_image: &quot;kubespray&quot;</span><br><span class="line">  # Auto generate self-signed certificate for registry domain</span><br><span class="line">  generate_domain_crt: true</span><br><span class="line">  # For nodes pull image, use 443 as default</span><br><span class="line">  registry_https_port: 443</span><br><span class="line">  # For push image to this registry, use 5000 as default, and only bind at 127.0.0.1</span><br><span class="line">  registry_push_port: 5000</span><br><span class="line">  # Set false to disable download all container images on all nodes</span><br><span class="line">  download_container: false</span><br></pre></td></tr></table></figure><ul><li>安装包目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">kubeplay&#x2F;</span><br><span class="line">.</span><br><span class="line">├── compose.yaml                 # compose 配置文件</span><br><span class="line">├── config</span><br><span class="line">│   ├── compose</span><br><span class="line">│   │   └── nginx.conf           # nginx 配置文件</span><br><span class="line">│   ├── kubespray</span><br><span class="line">│   │   ├── env.yml</span><br><span class="line">│   │   ├── group_vars           # kubespray group_vars  配置文件</span><br><span class="line">│   │   └── inventory.ini</span><br><span class="line">│   └── rootCA.cnf               # openssl 配置文件</span><br><span class="line">├── config-sample.yaml           # 主配置文件</span><br><span class="line">├── install.sh                   # 安装包入口脚本</span><br><span class="line">├── library</span><br><span class="line">└── resources                    # 所有离线资源</span><br><span class="line">    ├── images</span><br><span class="line">    │   ├── kubespray-v2.16.tar  # kubespray 镜像</span><br><span class="line">    │   ├── nginx-1.20-alpine.tar# nginx 镜像</span><br><span class="line">    │   └── registry-2.7.1.tar   # registry 镜像</span><br><span class="line">    ├── nginx                    # rpm&#x2F;deb 包以及一些二进制文件</span><br><span class="line">    │   ├── centos               # centos rpm 包</span><br><span class="line">    │   ├── debian               # debian deb 包</span><br><span class="line">    │   ├── files                # 一些二进制文件</span><br><span class="line">    │   ├── repos                # yum&#x2F;apt 配置文件</span><br><span class="line">    │   ├── tools                # 一些部署时依赖的工具</span><br><span class="line">    │   └── ubuntu               # ubuntu deb 包</span><br><span class="line">    └── registry</span><br><span class="line">        └── docker               # 组件镜像 registry 存储目录</span><br></pre></td></tr></table></figure><h3><span id="compose-节点">compose 节点</span></h3><p>需要单独划分出一个节点用户部署 nginx 和镜像仓库服务，并在该节点上运行 kubespray 来部署 K8s 集群。大致流程的代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">deploy_compose()&#123;</span><br><span class="line">  case $&#123;ID&#125; in</span><br><span class="line">    Debian|debian)</span><br><span class="line">      system::debian::config_repo</span><br><span class="line">      ;;</span><br><span class="line">    CentOS|centos)</span><br><span class="line">      system::centos::disable_selinux</span><br><span class="line">      system::centos::config_repo</span><br><span class="line">      ;;</span><br><span class="line">    Ubuntu|ubuntu)</span><br><span class="line">      system::ubuntu::config_repo</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      errorlog &quot;Not support system: $&#123;ID&#125;&quot;</span><br><span class="line">      exit 1</span><br><span class="line">      ;;</span><br><span class="line">  esac</span><br><span class="line">  system::disable_firewalld</span><br><span class="line">  system::install_pkgs</span><br><span class="line">  common::install_tools</span><br><span class="line">  common::rudder_config</span><br><span class="line">  common::update_hosts</span><br><span class="line">  common::generate_domain_certs</span><br><span class="line">  common::load_images</span><br><span class="line">  common::compose_up</span><br><span class="line">  common::health_check</span><br><span class="line">  system::install_chrony</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">  case $&#123;INSTALL_TYPE&#125; in</span><br><span class="line">    all)</span><br><span class="line">      deploy_compose</span><br><span class="line">      common::push_kubespray_image</span><br><span class="line">      common::run_kubespray &quot;bash &#x2F;kubespray&#x2F;run.sh deploy-cluster&quot;</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      echowarn &quot;unknow [TYPE] parameter: $&#123;INSTALL_TYPE&#125;&quot;</span><br><span class="line">      common::usage</span><br><span class="line">      ;;</span><br><span class="line">  esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main &quot;$@&quot;</span><br></pre></td></tr></table></figure><ul><li>首先初始化节点，关闭防火墙和 <code>SELinux</code></li><li>配置部署节点 yum/apt 离线源</li><li>安装一些部署依赖包，如 chrony、 libseccomp 等</li><li>安装一些工具如 yq, skopeo, kubectl 等</li><li>安装 nerdctl-full (containerd)</li><li>使用 nerdctl load -i 的方式导入nginx, registry, kubespray 镜像</li><li>使用 yq 渲染配置文件，生成 kubespray 需要的 env 文件和 inventory 文件</li><li>生成镜像仓库域名证书并将自签证书添加到主机的 CA trust 信任当中</li><li>在 <code>/etc/hosts</code> 中添加镜像仓库域名 hosts 映射</li><li>使用 nerdctl compose 启动 nginx 和 registry 服务</li><li>部署时钟同步服务 chrony</li><li>检查各个服务的状态</li><li>最后使用 nerdctl run 启动 kubespray 容器来部署 k8s 集群</li></ul><h3><span id="kubespray">kubespray</span></h3><p>部署的流程上基本上和 kubespray 官方大体一致，只不过我们引入里分层部署的特性</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">deploy_cluster()&#123;</span><br><span class="line">  touch $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">  STEPS&#x3D;&quot;00-default-ssh-config 01-cluster-bootstrap-os 02-cluster-etcd 03-cluster-kubernetes 04-cluster-network 05-cluster-apps&quot;</span><br><span class="line">  for step in $&#123;STEPS&#125;; do</span><br><span class="line">    if ! grep -q &quot;$&#123;step&#125;&quot; $&#123;INSTALL_STEPS_FILE&#125;; then</span><br><span class="line">      infolog &quot;start deploy $&#123;step&#125;&quot;</span><br><span class="line">      if ansible-playbook $&#123;ANSIBLE_ARGS&#125; $&#123;KUBE_ROOT&#125;&#x2F;playbooks&#x2F;$&#123;step&#125;.yml; then</span><br><span class="line">        echo $&#123;step&#125; &gt;&gt; $&#123;INSTALL_STEPS_FILE&#125;</span><br><span class="line">        infolog &quot;$&#123;step&#125; successfully installed&quot;</span><br><span class="line">      else</span><br><span class="line">        errorlog &quot;$&#123;step&#125; installation failed&quot;</span><br><span class="line">        exit 1</span><br><span class="line">      fi</span><br><span class="line">    else</span><br><span class="line">      warnlog &quot;$&#123;step&#125; is already installed, so skipped...&quot;</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>配置堡垒机 ssh 登录（可选）</li><li>配置节点 yum/apt 源为 nginx 服务提供的源</li><li>将自签的域名证书添加到主机的 CA trust 信任当中</li><li>在 <code>/etc/hosts</code> 中添加镜像仓库域名 hosts 映射</li><li>关闭防火墙，安装时钟同步服务，进行同步时钟</li><li>初始化集群节点，安装部署依赖</li><li>安装容器运行时，下载文件和组件镜像</li><li>部署 etcd 集群</li><li>部署 K8s 集群</li><li>部署 CNI 插件</li><li>安装一些额外的 addon 组件如 (coredns)</li></ul><p>至此整个打包和部署流程就完毕了，下面再讲几个打包/部署常见的问题</p><h2><span id="其他">其他</span></h2><h3><span id="kubeadm-证书">kubeadm 证书</span></h3><p>通过修改 kubeadm 源码的方式将证书续命到 10 年，开启 <code>kubeadm_patch_enabled</code> 参数部署时就将 kubeadm 替换为修改后的 kubeadm。关于 kubeadm 的修改和构建和参考我之前写过的《<a href="https://blog.k8s.li/build-k8s-binary-by-github-actions.html" target="_blank" rel="noopener">使用 GitHub Actions 编译 kubernetes 组件</a>》。</p><ul><li><a href="https://github.com/k8sli/kubespray/blob/main/roles/cluster/download/tasks/main.yml" target="_blank" rel="noopener">roles/cluster/download/tasks/main.yml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">- name: Relpace kubeadm binary file as patched version</span><br><span class="line">  get_url:</span><br><span class="line">    url: &quot;&#123;&#123; patched_kubeadm_download_url &#125;&#125;&quot;</span><br><span class="line">    dest: &quot;&#123;&#123; bin_dir &#125;&#125;&#x2F;kubeadm&quot;</span><br><span class="line">    mode: 0755</span><br><span class="line">    owner: root</span><br><span class="line">    group: root</span><br><span class="line">  tags:</span><br><span class="line">    - kubeadm</span><br><span class="line">  when: kubeadm_patch_enabled | default(true) | bool</span><br></pre></td></tr></table></figure><h3><span id="镜像缓存">镜像缓存</span></h3><p>os-packages, kubespray-base, kubespray-files, kubespray-images 这四个镜像在构建的时候都会采用 md5 值的方式校验是否需要重新构建镜像，这样能够大大提升 CI 的执行效率，下面以 kubespray-base 这个镜像为例介绍其原理和实现：</p><ul><li>在构建镜像前会有一个 md5 计算和校验的步骤，将与该镜像紧密相关的文件内容进行汇总并生成 md5 值，并将这个值得以 label 的方式保存在镜像的元数据信息当中。如果该值与上个最新的镜像中的 md5 值相等，那么就不需要重新构建该镜像，只需要进行 retag 即可。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- name: Prepare for build images</span><br><span class="line">  shell: bash</span><br><span class="line">  run: |</span><br><span class="line">    git describe --tags --always | sed &#39;s&#x2F;^&#x2F;IMAGE_TAG&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    git branch --show-current | sed &#39;s&#x2F;^&#x2F;BRANCH_NAME&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    git branch --show-current | sed &#39;s&#x2F;master&#x2F;latest&#x2F;;s&#x2F;main&#x2F;latest&#x2F;;s&#x2F;^&#x2F;IMAGE_TAG_BY_BRANCH&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    sed -n &#39;s&#x2F;^kube_version: &#x2F;KUBE_VERSION&#x3D;&#x2F;p&#39; roles&#x2F;kubespray-defaults&#x2F;defaults&#x2F;main.yaml &gt;&gt; $GITHUB_ENV</span><br><span class="line">    cat build&#x2F;kubespray-base&#x2F;Dockerfile requirements.txt tests&#x2F;requirements.txt .github&#x2F;workflows&#x2F;build.yaml \</span><br><span class="line">    | md5sum | tr -d &#39;\ -&#39; | sed &#39;s&#x2F;^&#x2F;BASE_MD5&#x3D;md5-&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line"></span><br><span class="line">    source $GITHUB_ENV</span><br><span class="line">    if skopeo inspect docker:&#x2F;&#x2F;$&#123;BASE_IMAGE_REPO&#125;:$&#123;BRANCH_NAME&#125; &gt; mainfest.json; then</span><br><span class="line">      jq -r &#39;.Labels.BASE_MD5&#39; mainfest.json | sed &#39;s&#x2F;^&#x2F;LATEST_BASE_MD5&#x3D;&#x2F;&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    else</span><br><span class="line">      echo &#39;LATEST_BASE_MD5&#x3D;null&#39; &gt;&gt; $GITHUB_ENV</span><br><span class="line">    fi</span><br></pre></td></tr></table></figure><ul><li>如果当前md5 的值与最新的 md5 值相等，就重新生成一个新的 Dockerfile 来进行镜像 retag 的操作。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- name: Replace Dockerfile if MD5 not update</span><br><span class="line">  if: $&#123;&#123; env.BASE_MD5 &#x3D;&#x3D; env.LATEST_BASE_MD5 &#125;&#125;</span><br><span class="line">  run: |</span><br><span class="line">    echo &quot;FROM $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.BASE_MD5 &#125;&#125;&quot; &gt; build&#x2F;kubespray-base&#x2F;Dockerfile</span><br></pre></td></tr></table></figure><ul><li>构建镜像并将 md5 值作为 labels 填充到镜像的元数据信息当中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- name: Build and push kubespray-base images</span><br><span class="line">  uses: docker&#x2F;build-push-action@v2</span><br><span class="line">  with:</span><br><span class="line">    context: .</span><br><span class="line">    push: $&#123;&#123; github.event_name !&#x3D; &#39;pull_request&#39; &#125;&#125;</span><br><span class="line">    file: build&#x2F;kubespray-base&#x2F;Dockerfile</span><br><span class="line">    platforms: linux&#x2F;amd64,linux&#x2F;arm64</span><br><span class="line">    cache-from: type&#x3D;local,src&#x3D;&#x2F;tmp&#x2F;.buildx-cache</span><br><span class="line">    cache-to: type&#x3D;local,dest&#x3D;&#x2F;tmp&#x2F;.buildx-cache-new</span><br><span class="line">    build-args: KUBE_VERSION&#x3D;$&#123;&#123; env.KUBE_VERSION &#125;&#125;</span><br><span class="line">    labels: BASE_MD5&#x3D;$&#123;&#123; env.BASE_MD5 &#125;&#125;</span><br><span class="line">    tags: |</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.IMAGE_TAG &#125;&#125;</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.BASE_MD5 &#125;&#125;</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.BRANCH_NAME &#125;&#125;</span><br><span class="line">      $&#123;&#123; env.BASE_IMAGE_REPO &#125;&#125;:$&#123;&#123; env.IMAGE_TAG_BY_BRANCH &#125;&#125;</span><br></pre></td></tr></table></figure><p>使用这种方式的好处就在于在不需要构建镜像的时候能大幅度提升 CI 的运行效率。</p><blockquote><p>本文转载自：「 木子的博客 」，原文：<a href="https://tinyurl.com/y9bekf67" target="_blank" rel="noopener">https://tinyurl.com/y9bekf67</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在企业私有云环境当中，出于对数据安全的考虑以及满足 &lt;a href=&quot;http://www.djbh.net/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;网络安全等级保护&lt;/a&gt; 的要求，往往会对内部环境中的服务器做出严格的访问限制。一般来讲生产环境都会禁止访问外部网络，开发人员要访问生产环境也必须通过堡垒机或者其他方式进行安全审计登录。在这种无网（无法访问公网）的环境中，想要部署好一个 K8s 集群并不是一件轻松的事儿。市面上 K8s 部署工具也多不胜数，对于离线部署的支持情况也各不相同：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Item&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Language&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Star&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;Fork&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;离线部署支持情况&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/kubernetes/kops&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kops&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;13.2k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;4.1k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;不支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/kubespray&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kubespray&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Ansible&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;11.1k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;4.7k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，需自行构建安装包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/easzlab/kubeasz&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kubeasz&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Ansible&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;7.2k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;2.7k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，需自行构建安装包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/fanux/sealos&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealos&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;4.1k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;790&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，需付费充值会员&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/rancher/rke&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RKE&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;2.5k&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;480&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;不支持，需自行安装 docker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/alibaba/sealer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealer&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;503&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;112&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;支持，源自 &lt;a href=&quot;https://github.com/fanux/sealos&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealos&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://github.com/kubesphere/kubekey&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kubekey&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;Golang&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;471&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;155&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;部分支持，仅镜像可离线&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;无网环境离线部署 K8s 往往是作为一个商业服务或者商业付费产品来出售（如 &lt;a href=&quot;https://www.sealyun.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sealos&lt;/a&gt; ），很少有开源免费的解决方案；或者虽然提供了离线部署方案，但想要操作起来十分繁琐，很难顺畅地做到一键部署；又或者只支持部分离线部署，还有一部分资源需要在部署的时候通过公网获取。&lt;/p&gt;
&lt;p&gt;针对上述问题，本文调研主流的 K8s 部署工具，并基于这些工具设计并实现一种从构建离线安装包到一键部署 K8s 集群全流程的解决方案，以满足在无网的环境中一键部署 K8s 集群的需求，比较适合基于 K8s 的 PaaS toB 产品使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>两个 99% 的人都遇到过的 Kubernetes 故障处理技巧</title>
    <link href="https://www.hi-linux.com/posts/19507.html"/>
    <id>https://www.hi-linux.com/posts/19507.html</id>
    <published>2021-08-30T01:00:00.000Z</published>
    <updated>2021-08-31T01:58:11.448Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>随着微服务的不断推进，使用 k8s 集群越来越多，越来越深入，随之而来会遇到一系列的问题，本文向大家介绍实际使用 k8s 遇到的一些问题以及解决方法。</p><h2><span id="问题一修复-k8s-内存泄露问题">问题一：修复 K8S 内存泄露问题</span></h2><h3><span id="问题描述">问题描述</span></h3><ol><li>当 k8s 集群运行日久以后，有的 node 无法再新建 pod，并且出现如下错误，当重启服务器之后，才可以恢复正常使用。查看 pod 状态的时候会出现以下报错。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">applying cgroup … caused: mkdir …no space left on device</span><br></pre></td></tr></table></figure><p>或者在 describe pod 的时候出现 cannot allocate memory。</p><p>这时候你的 k8s 集群可能就存在内存泄露的问题了，当创建的 pod 越多的时候内存会泄露的越多，越快。</p><ol start="2"><li>具体查看是否存在内存泄露</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;memory.kmem.slabinfo</span><br></pre></td></tr></table></figure><p>当出现 cat: /sys/fs/cgroup/memory/kubepods/memory.kmem.slabinfo: Input/output error 则说明不存在内存泄露的情况 如果存在内存泄露会出现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slabinfo - version: 2.1</span><br><span class="line"># name            &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt;</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="解决方案">解决方案</span></h3><ol><li><p>解决方法思路：关闭 runc 和 kubelet 的 kmem，因为升级内核的方案改动较大，此处不采用。</p></li><li><p>kmem 导致内存泄露的原因：</p></li></ol><p>内核对于每个 cgroup 子系统的的条目数是有限制的，限制的大小定义在 kernel/cgroup.c #L139，当正常在 cgroup 创建一个 group 的目录时，条目数就加 1。我们遇到的情况就是因为开启了 kmem accounting 功能，虽然 cgroup 的目录删除了，但是条目没有回收。这样后面就无法创建 65535 个 cgroup 了。也就是说，在当前内核版本下，开启了 kmem accounting 功能，会导致 memory cgroup 的条目泄漏无法回收。</p><h4><span id="21-编译-runc">2.1 编译 runc</span></h4><ul><li>配置 go 语言环境</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;dl.google.com&#x2F;go&#x2F;go1.12.9.linux-amd64.tar.gz</span><br><span class="line">$ tar xf go1.12.9.linux-amd64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line"></span><br><span class="line"># 写入bashrc</span><br><span class="line">$ vim ~&#x2F;.bashrc</span><br><span class="line">$ export GOPATH&#x3D;&quot;&#x2F;data&#x2F;Documents&quot;</span><br><span class="line">$ export GOROOT&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;go&quot;</span><br><span class="line">$ export PATH&#x3D;&quot;$GOROOT&#x2F;bin:$GOPATH&#x2F;bin:$PATH&quot;</span><br><span class="line">$ export GO111MODULE&#x3D;off</span><br><span class="line"></span><br><span class="line"># 验证</span><br><span class="line">$ source ~&#x2F;.bashrc</span><br><span class="line">$ go env</span><br></pre></td></tr></table></figure><ul><li>下载 runc 源码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p &#x2F;data&#x2F;Documents&#x2F;src&#x2F;github.com&#x2F;opencontainers&#x2F;</span><br><span class="line">$ cd &#x2F;data&#x2F;Documents&#x2F;src&#x2F;github.com&#x2F;opencontainers&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;opencontainers&#x2F;runc</span><br><span class="line">$ cd runc&#x2F;</span><br><span class="line">$ git checkout v1.0.0-rc9  # 切到v1.0.0-rc9 tag</span><br></pre></td></tr></table></figure><ul><li>编译</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装编译组件</span><br><span class="line">$ sudo yum install libseccomp-devel</span><br><span class="line">$ make BUILDTAGS&#x3D;&#39;seccomp nokmem&#39;</span><br><span class="line"># 编译完成之后会在当前目录下看到一个runc的可执行文件,等kubelet编译完成之后会将其替换</span><br></pre></td></tr></table></figure><h4><span id="22-编译-kubelet">2.2 编译 kubelet</span></h4><ul><li>下载 kubernetes 源码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p &#x2F;root&#x2F;k8s&#x2F;</span><br><span class="line">$ cd &#x2F;root&#x2F;k8s&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line">$ cd kubernetes&#x2F;</span><br><span class="line">$ git checkout v1.15.3</span><br></pre></td></tr></table></figure><ul><li>制作编译环境的镜像(Dockerfile 如下)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:centos7.3.1611</span><br><span class="line"></span><br><span class="line">ENV GOROOT &#x2F;usr&#x2F;local&#x2F;go</span><br><span class="line">ENV GOPATH &#x2F;usr&#x2F;local&#x2F;gopath</span><br><span class="line">ENV PATH &#x2F;usr&#x2F;local&#x2F;go&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line">RUN yum install rpm-build which where rsync gcc gcc-c++ automake autoconf libtool make -y \</span><br><span class="line">    &amp;&amp; curl -L https:&#x2F;&#x2F;studygolang.com&#x2F;dl&#x2F;golang&#x2F;go1.12.9.linux-amd64.tar.gz | tar zxvf - -C &#x2F;usr&#x2F;local</span><br></pre></td></tr></table></figure><ul><li>在制作好的 go 环境镜像中来进行编译 kubelet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker run  -it --rm   -v &#x2F;root&#x2F;k8s&#x2F;kubernetes:&#x2F;usr&#x2F;local&#x2F;gopath&#x2F;src&#x2F;k8s.io&#x2F;kubernetes   build-k8s:centos-7.3-go-1.12.9-k8s-1.15.3   bash</span><br><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;gopath&#x2F;src&#x2F;k8s.io&#x2F;kubernetes</span><br><span class="line">#编译</span><br><span class="line">$ GO111MODULE&#x3D;off KUBE_GIT_TREE_STATE&#x3D;clean KUBE_GIT_VERSION&#x3D;v1.15.3 make kubelet GOFLAGS&#x3D;&quot;-tags&#x3D;nokmem&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li>替换原有的 runc 和 kubelet</li></ol><ul><li>将原有 runc 和 kubelet 备份</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;kubelet &#x2F;home&#x2F;kubelet</span><br><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;docker-runc &#x2F;home&#x2F;docker-runc</span><br></pre></td></tr></table></figure><ul><li>停止 docker 和 kubelet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop docker</span><br><span class="line">$ systemctl stop kubelet</span><br></pre></td></tr></table></figure><ul><li>将编译好的 runc 和 kubelet 进行替换</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cp kubelet &#x2F;usr&#x2F;bin&#x2F;kubelet</span><br><span class="line">$ cp kubelet &#x2F;usr&#x2F;local&#x2F;bin&#x2F;kubelet</span><br><span class="line">$ cp runc &#x2F;usr&#x2F;bin&#x2F;docker-runc</span><br></pre></td></tr></table></figure><ul><li>检查 kmem 是否关闭前需要将此节点的 pod 杀掉重启或者重启服务器,当结果为 0 时成功</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;burstable&#x2F;memory.kmem.usage_in_bytes</span><br></pre></td></tr></table></figure><ul><li>检查是否还存在内存泄露的情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;kubepods&#x2F;memory.kmem.slabinfo</span><br></pre></td></tr></table></figure><h2><span id="问题二k8s-证书过期问题的两种处理方法">问题二：k8s 证书过期问题的两种处理方法</span></h2><h3><span id="前情提要">前情提要</span></h3><p>公司测试环境的 k8s 集群使用已经很长时间了,突然有一天开发联系我说 k8s 集群无法访问，开始以为是测试环境的机器磁盘空间不够了，导致组件异常或者把开发使用的镜像自动清理掉了，但是当登上机器去查验的时候发现不是这个原因。当时觉得也很疑惑。因为开发环境使用人数较少，不应该会出问题，所以就去查验 log 的相关报错信息。</p><h3><span id="问题现象">问题现象</span></h3><p>出现 k8s api 无法调取的现象，使用 kubectl 命令获取资源均返回如下报错:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Unable to connect to the server: x509: certificate has expired or is not yet valid</span><br></pre></td></tr></table></figure><p>经网上搜索之后发现应该是 k8s 集群的证书过期了，使用命令排查证书的过期时间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm alpha certs check-expiration</span><br></pre></td></tr></table></figure><p>发现确实是证书过期了</p><h3><span id="相关介绍以及问题解决">相关介绍以及问题解决</span></h3><p>因为我们是使用 kubeadm 部署的 k8s 集群，所以更新起证书也是比较方便的，默认的证书时间有效期是一年，我们集群的 k8s 版本是 1.15.3 版本是可以使用以下命令来更新证书的，但是一年之后还是会到期，这样就很麻烦，所以我们需要了解一下 k8s 的证书，然后我们来生成一个时间很长的证书，这样我们就可以不用去总更新证书了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm alpha certs renew all --config&#x3D;kubeadm.yaml</span><br><span class="line">$ systemctl restart kubelet</span><br><span class="line">$ kubeadm init phase kubeconfig all --config kubeadm.yaml</span><br><span class="line"># 然后将生成的配置文件替换,重启 kube-apiserver、kube-controller、kube-scheduler、etcd 这4个容器即可</span><br></pre></td></tr></table></figure><p>另外 kubeadm 会在控制面板升级的时候自动更新所有证书，所以使用 kubeadm 搭建的集群最佳的做法是经常升级集群，这样可以确保你的集群保持最新状态并保持合理的安全性。但是对于实际的生产环境我们可能并不会去频繁的升级集群，所以这个时候我们就需要去手动更新证书。</p><p>下面我们通过调用 k8s 的 api 来实现更新一个 10 年的证书</p><p>首先在 <code>/etc/kubernetes/manifests/kube-controller-manager.yaml</code> 文件加入配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    # 设置证书有效期为 10年</span><br><span class="line">    - --experimental-cluster-signing-duration&#x3D;87600h</span><br><span class="line">    - --client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br></pre></td></tr></table></figure><p>修改完成后 kube-controller-manager 会自动重启生效。然后我们需要使用下面的命令为 Kubernetes 证书 API 创建一个证书签名请求。如果您设置例如 cert-manager 等外部签名者，则会自动批准证书签名请求（CSRs）。否者，您必须使用 kubectl certificate 命令手动批准证书。以下 kubeadm 命令输出要批准的证书名称，然后等待批准发生：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 需要将全部 pending 的证书全部批准</span><br><span class="line">$ kubeadm alpha certs renew all --use-api --config kubeadm.yaml &amp;</span><br></pre></td></tr></table></figure><p>我们还不能直接重启控制面板的几个组件，这是因为使用 kubeadm 安装的集群对应的 etcd 默认是使用的 /etc/kubernetes/pki/etcd/ca.crt 这个证书进行前面的，而上面我们用命令 kubectl certificate approve 批准过后的证书是使用的默认的 /etc/kubernetes/pki/ca.crt 证书进行签发的，所以我们需要替换 etcd 中的 ca 机构证书:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 先拷贝静态 Pod 资源清单</span><br><span class="line">$ cp -r &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F; &#x2F;etc&#x2F;kubernetes&#x2F;manifests.bak</span><br><span class="line">$ vi &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;etcd.yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    # 修改为 CA 文件</span><br><span class="line">    - --peer-trusted-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">    - --trusted-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">......</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: &#x2F;var&#x2F;lib&#x2F;etcd</span><br><span class="line">      name: etcd-data</span><br><span class="line">    - mountPath: &#x2F;etc&#x2F;kubernetes&#x2F;pki  # 更改证书目录</span><br><span class="line">      name: etcd-certs</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: &#x2F;etc&#x2F;kubernetes&#x2F;pki  # 将 pki 目录挂载到 etcd 中去</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: &#x2F;var&#x2F;lib&#x2F;etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-data</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>由于 kube-apiserver 要连接 etcd 集群，所以也需要重新修改对应的 etcd ca 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vi &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-apiserver.yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    # 将etcd ca文件修改为默认的ca.crt文件</span><br><span class="line">    - --etcd-cafile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>除此之外还需要替换 requestheader-client-ca-file 文件，默认是 /etc/kubernetes/pki/front-proxy-ca.crt 文件，现在也需要替换成默认的 CA 文件，否则使用聚合 API，比如安装了 metrics-server 后执行 kubectl top 命令就会报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.crt</span><br><span class="line">$ cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.key</span><br></pre></td></tr></table></figure><p>这样我们就得到了一个 10 年证书的 k8s 集群，还可以通过重新编译 kubeadm 来实现一个 10 年证书的，这个我没有尝试，不过在初始化集群的时候也是一个方法。</p><blockquote><p>本文转载自：「 知乎 」，原文：<a href="https://tinyurl.com/h9yet6sd" target="_blank" rel="noopener">https://tinyurl.com/h9yet6sd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着微服务的不断推进，使用 k8s 集群越来越多，越来越深入，随之而来会遇到一系列的问题，本文向大家介绍实际使用 k8s 遇到的一些问题以及解决方法。&lt;/p&gt;
&lt;h2 id=&quot;问题一：修复-K8S-内存泄露问题&quot;&gt;问题一：修复 K8S 内存泄露问题&lt;/h2&gt;
&lt;h3 id=&quot;问题描述&quot;&gt;问题描述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;当 k8s 集群运行日久以后，有的 node 无法再新建 pod，并且出现如下错误，当重启服务器之后，才可以恢复正常使用。查看 pod 状态的时候会出现以下报错。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;applying cgroup … caused: mkdir …no space left on device&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;或者在 describe pod 的时候出现 cannot allocate memory。&lt;/p&gt;
&lt;p&gt;这时候你的 k8s 集群可能就存在内存泄露的问题了，当创建的 pod 越多的时候内存会泄露的越多，越快。&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;具体查看是否存在内存泄露&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ cat &amp;#x2F;sys&amp;#x2F;fs&amp;#x2F;cgroup&amp;#x2F;memory&amp;#x2F;kubepods&amp;#x2F;memory.kmem.slabinfo&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当出现 cat: /sys/fs/cgroup/memory/kubepods/memory.kmem.slabinfo: Input/output error 则说明不存在内存泄露的情况 如果存在内存泄露会出现&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;slabinfo - version: 2.1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# name            &amp;lt;active_objs&amp;gt; &amp;lt;num_objs&amp;gt; &amp;lt;objsize&amp;gt; &amp;lt;objperslab&amp;gt; &amp;lt;pagesperslab&amp;gt; : tunables &amp;lt;limit&amp;gt; &amp;lt;batchcount&amp;gt; &amp;lt;sharedfactor&amp;gt; : slabdata &amp;lt;active_slabs&amp;gt; &amp;lt;num_slabs&amp;gt; &amp;lt;sharedavail&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>服务网格除了 Istio，其实你还可以有其它 8 种选择</title>
    <link href="https://www.hi-linux.com/posts/1629.html"/>
    <id>https://www.hi-linux.com/posts/1629.html</id>
    <published>2021-08-26T01:00:00.000Z</published>
    <updated>2021-08-26T01:32:52.275Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>哪种服务网格最适合你的企业？近年来，Kubernetes 服务网格框架数量增加迅速，使得这成为一个棘手的问题。</p><p>下面将介绍 9 种较受欢迎的用以支撑微服务开发的服务网格框架，每种方案都给出了其适用场景。</p><h2><span id="什么是服务网格">什么是服务网格</span></h2><p>服务网格近年来有很高的话题度，背后的原因是什么？</p><p>微服务已经成为一种灵活快速的开发方式。然而，随着微服务数量成倍数地增长，开发团队开始遇到了部署和扩展性上的问题。</p><p>容器和 Kubernetes 这样的容器编排系统 ，将运行时和服务一起打包进镜像，调度容器到合适的节点，运行容器。这个方案可以解决开发团队遇到的不少问题[1]。然而，在这个操作流程中仍存在短板：如何管理服务间的通信。</p><p>在采用服务网格的场景下，以一种和应用代码解耦的方式，增强了应用间统一的网络通信能力。服务网格扩展了集群的管理能力，增强可观测性、服务发现、负载均衡、IT 运维监控及应用故障恢复等功能。</p><a id="more"></a><h2><span id="服务网格概览">服务网格概览</span></h2><p>服务网格一直有很高的热度。正如 Linkerd 的作者 William Morgan 所提到[2]的：“服务网格本质上无非就是和应用捆绑在一起的用户空间代理。” 此说法相当简洁，他还补充道，“如果你能透过噪音看清本质，服务网格能给你带来实实在在的重要价值。”</p><p>Envoy 是许多服务网格框架的核心组件，是一个通用的开源代理，常被用于 Pod 内的 sidecar 以拦截流量。也有服务网格使用另外的代理方案。</p><p>若论具体服务网格方案的普及程度，Istio 和 Linkerd 获得了更多的认可。也有其它可选项，包括 Consul Connect，Kuma，AWS App Mesh和OpenShift。下文会阐述9种服务网格提供的关键特性。</p><p><strong>Istio</strong></p><p>Istio 是基于 Envoy 构建的一个可扩展的开源服务网格。开发团队可以通过它连接、加密、管控和观察应用服务。Istio 于 2017 年开源，目前 IBM、Google、Lyft 仍在对其进行持续维护升级。Lyft 在 2017 年把 Envoy 捐赠给了 CNCF。</p><p>Istio 花了不少时间去完善增强它的功能特性。Istio 的关键特性包括负载均衡、流量路由、策略创建、可度量性及服务间认证。</p><p>Istio 有两个部分组成：数据平面和控制平面。数据平面负责处理流量管理，通过 Envoy 的 sidecar 代理来实现流量路由和服务间调用。控制平面是主要由开发者用来配置路由规则和观测指标。</p><p>Istio 观测指标是细粒度的属性，其中包含和服务行为相关的特定数据值。下面是个样例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">request.path: xyz&#x2F;abc </span><br><span class="line">request.size: 234 </span><br><span class="line">request.time: 12:34:56.789 04&#x2F;17&#x2F;2017 </span><br><span class="line">source.ip: [192 168 0 1] </span><br><span class="line">destination.service.name: example</span><br></pre></td></tr></table></figure><p>与其他服务网格相比，Istio 胜在其平台成熟度以及通过其 Dashbaord</p><p>着重突出的服务行为观测和业务管理功能，然而也因为这些高级特性和复杂的配置流程，Istio 可能并不如其它一些替代方案那样容易上手。</p><p><strong>Linkerd</strong></p><p>按照官网的说法，Linkerd 是一个轻量级、安全优先的 Kubernetes 服务网格。它的创建流程快到让人难以置信（据称在 Kubernetes 安装只需要 60 秒），这是大多数开发者喜闻乐见的。Linkerd 并没有采用基于 Envoy 的构建方案。而是使用了一个基于 Rust 的高性能代理 linkerd2-proxy，这个代理是专门为 Linkerd 服务网格编写的。</p><p>Linkerd 由社区驱动，是 100% 的 Apache 许可开源项目。它还是 CNCF 孵化项目。Linkerd 始于 2016 年，维护者也花了不少时间去解决其中的缺陷。</p><p>使用 Linkerd 服务网格，应用服务可以增强其可靠性、可观测性及其在 Kubernetes 上部署的安全性。举个例子，可观测性的增强可以帮助用户解决服务间的延迟问题。使用 Linkerd 不要求用户做很多代码调整或是花费大量时间写 YAML 配置文件。可靠的产品特性和正向的开发者使用回馈，使得 Linkerd 成为服务网格中一个强有力的竞争者。</p><p><strong>Consul Connect</strong></p><p>Consul Connect 是来自 HashiCorp 的服务网格，专注于路由和分段，通过应用级的 sidecar 代理来提供服务间的网络特性。Consult Connect 侧重于应用安全，提供应用间的双向 TLS 连接以实现授权和加密。</p><p>Consult Connect 独特的一点是提供了两种代理模式。一种是它内建的代理，同时它还支持 Envoy 方案。Connect 强调可观测性，集成了例如 Prometheus 这样的工具来监控来自 sidecar 代理的数据。Consul Connect 可以灵活地满足开发者使用需求。比如，它提供了多种方式注册服务：可以从编排系统注册，可以通过配置文件，通过 API 调用，或是命令行工具。</p><p><strong>Kuma</strong></p><p>Kuma 来源于 Kong，自称是一个非常好用的服务网格替代方案。Kuma 是一个基于 Envoy 的平台无关的控制平面。Kuma 提供了安全、观测、路由等网络特性，同时增强了服务间的连通性。Kuma 同时支持 Kubernetes 和虚拟机。</p><p>Kuma 让人感兴趣的一点是，它的企业版可以通过一个统一控制面板来运维管理多个互相隔离独立的服务网格。这项能力可以满足安全要求高的使用场景。既符合隔离的要求，又实现集中控制。</p><p>Kuma 也是相对容易安装的一个方案。因为它预先内置了不少策略。这些策略覆盖了常见需求，例如路由，双向 TLS，故障注入，流量控制，加密等场景。</p><p>Kuma 原生兼容 Kong，对于那些已经采用 Kong API 管理的企业组织，Kuma 是个非常自然而然的候选方案。</p><p><strong>Maesh</strong></p><p>Maesh 是来自 Containous 的容器原生的服务网格，标榜自己是比市场其它服务网格更轻量级更易用的方案。和很多基于 Envoy 构建的服务网格不同，Maesh 采用了 Traefik， 一个开源的反向代理和负载均衡器。</p><p>Maesh 并没有采用 sidecar 的方式进行代理，而是在每个节点部署一个代理终端。这样做的好处是不需要去编辑 Kubernetes 对象，同时可以让用户有选择性地修改流量，Maesh 相比其他服务网格侵入性更低。Maesh 支持的配置方式：在用户服务对象上添加注解或是在服务网格对象上添加注解来实现配置。</p><p>实际上，SMI 是一种新的服务网格规范格式，对 SMI 的支持 Maesh 独有的一大亮点。随着 SMI 在业界逐渐被采用，可以提高可扩展性和减缓供应商绑定的担忧。</p><p>Maesh 要求 Kubernetes 1.11 以上的版本，同时集群里安装了 CoreDNS/KubeDNS。这篇安装指南[3]演示了如何通过 Helm v3 快速安装 Maesh。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add maesh https:&#x2F;&#x2F;containous.github.io&#x2F;maesh&#x2F;charts </span><br><span class="line">$ helm repo update </span><br><span class="line">$ helm install maesh maesh&#x2F;maesh</span><br></pre></td></tr></table></figure><p><strong>ServiceComb-mesher</strong></p><p>Apache 软件基金会形容旗下的 ServiceComb-mesher “是一款用 Go 语言实现的高性能服务网格”。Mesher 基于一个非常受欢迎的 Go 语言微服务开发框架 Go Chassis[4] 来设计实现。因此，它沿袭了 Go Chassis 的一些特性如服务发现、负载均衡、错误容忍、路由管理和分布式追踪等特性。</p><p>Mesher 采用了 sidecar 方式；每个服务有一个 Mesher sidecar 代理。开发人员通过 Admin API 和 Mesher 交互，查看运行时信息。Mesher 同时支持 HTTP 和 gRPC，可快速移植到不同的基础设施环境，包括 Docker、Kubernetes、虚拟机和裸金属机环境。</p><p><strong>Network Service Mesh（NSM）</strong></p><p>Network Service Mesh（NSM）是一款专门为 telcos 和 ISPs 设计的服务网格。它提供了一层级用以增强服务在 Kubernetes 的低层级网络能力。NSM 目前是 CNCF 的沙箱项目。</p><p>根据 NSM 的文档说明，“经常接触 L2/L3 层的网络运维人员抱怨说，适合他们的下一代架构的容器网络解决方案几乎没有”。</p><p>因此，NSM 在设计时就考虑到一些不同使用场景，尤其是网络协议不同和网络配置混杂的场景。这使得 NSM 对某些特殊场景具备相当吸引力，例如边缘计算、5G 网络和 IOT 设备等场景。NSM 使用简单直接的 API 接口去实现容器和外部端点的之间的通信。</p><p>和其他服务网格相比，NSM 工作在另一个不同的网络层。VMware 形容 NSM“专注于连接”。GitHub 的文档[5]演示了 NSM 是如何与 Envoy协同工作的。</p><p><strong>AWS App Mesh</strong></p><p>AWS APP Mesh 为开发者提供了“适用于不同服务的应用层的网络”。它接管了服务的所有网络流量，使用开源的 Envoy 代理去控制容器的流量出入。AWS App Mesh 支持 HTTP/2 gRPC。</p><p>AWS App Mesh 对于那些已经将容器平台深度绑定 AWS 的公司而言，会是相当不错的服务网格方案。AWS 平台包括 AWS Fargate，Amazon Elastic Container Service，Amazon Elastic Kubernetes Service（EKS），Amazon Elastic Compute Cloud（EC2），Kubernetes on EC2，包括 AWS App Mesh 不需要付额外费用。</p><p>AWS App Mesh 和 AWS 生态内的监控工具无缝兼容。这些工具包括 CloudWatch 和 AWS X-Ray，以及一些来自第三方供应商的工具。因为 AWS 计算服务支持 AWS Outposts，AWS App Mesh 可以和混合云和已经部署的应用良好兼容。</p><p>AWS App Mesh 的缺点可能是使得开发者深度绑定了单一供应商方案，相对闭源，可扩展性缺失。</p><p><strong>OpenShift Service Mesh by Red Hat</strong></p><p>OpenShift 是来自红帽的一款帮助用户“连接、管理、观测微服务应用”的容器管理平台。OpenShift 预装了不少提升企业能力的组件，也被形容为企业级的混合云 Kubernetes 平台。</p><p>OpenShift Service Mesh 基于开源的 Istio 构建，具备 Isito 的控制平面和数据平面等特性。OpenShift 利用两款开源工具来增强 Isito 的追踪能力和可观测性。OpenShift 使用 Jaeger 实现分布式追踪，更好地跟踪请求是如何在服务间调用处理的。</p><p>另一方面，OpenShift 使用了 Kiali 来增强微服务配置、流量监控、跟踪分析等方面的可观测性。</p><h2><span id="如何选择">如何选择</span></h2><p>正如文中所提到的，可供选择的服务网格方案[6]有很多，同时还有新的方案在涌现。当然，每一种方案在技术实现上都略有不同。选择一款合适的服务网格，主要考虑的因素包括，你能接受它带来多大的侵入性，它的安全性如何，以及平台成熟度等。</p><p>以下几点可以帮助 DevOps 团队选择一款适合他们场景的服务网格：</p><ul><li>是否依赖Envoy。Envoy 有一个活跃的社区生态。开源，同时是许多服务网格的底座。Envoy 具备的丰富特性使得其成为一个很难绕过的因素。</li><li>具体使用场景。服务网格为微服务而生。如果你的应用是一个单体的庞然大物，那你在服务网格上的投入可能达不到预期的收益。如果不是所有应用都部署在 Kubernetes，则应该优先考虑平台无关的方案。</li><li>现有容器管理平台。有些企业已经使用了特定供应商的生态来解决容器编排问题，例如 AWS 的 EKS，红帽的 OpenShift，Consul。沿袭原有的生态，可以继承并拓展原有的特性。而这些可能是开源方案所不能提供的。</li><li>所在行业。许多服务网格不是为特定行业专门设计的。Kuma 统一管理多个隔离服务网格的能力可能更适用于收到高度管制的金融行业。底层网络 telcos 和 ISPs 则更应该考虑 Network Service Mesh。</li><li>对可视化的要求。可观测性是服务网格的核心能力之一。考虑进一步定制和更深度能力的团队应该优先考虑 Istio 或 Consul。</li><li>是否遵循开发标准。遵循开发标准使得你的平台更具备前瞻性和可扩展性。这使得企业会倾向于采用支持 SMI 的方案，Maesh 或其他基金会孵化的项目如 Linkerd。</li><li>是否重视用户体验。考虑运维人员的易用性是评判新工具的关键指标。这方 Linkerd 似乎在开发者中间口碑不错。</li><li>团队准备。评估你的团队所具备的资源和技术储备，在技术选型时决定你们适合用基于 Envoy 的 Istio，或是供应商抽象封装的方案，例如 OpenShift。</li></ul><p>这些考虑因素没有覆盖到全部场景。此处仅是抛砖引玉，引起读者的思考。希望读完上面所列的服务网格清单，和相关的决策因素之后，你们的团队能找到新的方法去改善微服务应用的网络特性。</p><p>相关链接：</p><ol><li><a href="https://techbeacon.com/app-dev-testing/3-reasons-why-you-should-always-run-microservices-apps-containers" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/3-reasons-why-you-should-always-run-microservices-apps-containers</a></li><li><a href="https://buoyant.io/service-mesh-manifesto/" target="_blank" rel="noopener">https://buoyant.io/service-mesh-manifesto/</a></li><li><a href="https://docs.mae.sh/quickstart/" target="_blank" rel="noopener">https://docs.mae.sh/quickstart/</a></li><li><a href="https://github.com/go-chassis/go-chassis" target="_blank" rel="noopener">https://github.com/go-chassis/go-chassis</a></li><li><a href="https://github.com/networkservicemesh/examples/tree/master/examples/envoy_interceptor" target="_blank" rel="noopener">https://github.com/networkservicemesh/examples/tree/master/examples/envoy_interceptor</a></li><li><a href="https://techbeacon.com/app-dev-testing/make-your-app-architecture-cloud-native-service-mesh" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/make-your-app-architecture-cloud-native-service-mesh</a></li></ol><p>原文链接：<a href="https://techbeacon.com/app-dev-testing/9-open-source-service-meshes-compared" target="_blank" rel="noopener">https://techbeacon.com/app-dev-testing/9-open-source-service-meshes-compared</a></p><blockquote><p>本文转载自：「  分布式实验室 」，原文：<a href="https://tinyurl.com/4xsy53bd" target="_blank" rel="noopener">https://tinyurl.com/4xsy53bd</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;哪种服务网格最适合你的企业？近年来，Kubernetes 服务网格框架数量增加迅速，使得这成为一个棘手的问题。&lt;/p&gt;
&lt;p&gt;下面将介绍 9 种较受欢迎的用以支撑微服务开发的服务网格框架，每种方案都给出了其适用场景。&lt;/p&gt;
&lt;h2 id=&quot;什么是服务网格&quot;&gt;什么是服务网格&lt;/h2&gt;
&lt;p&gt;服务网格近年来有很高的话题度，背后的原因是什么？&lt;/p&gt;
&lt;p&gt;微服务已经成为一种灵活快速的开发方式。然而，随着微服务数量成倍数地增长，开发团队开始遇到了部署和扩展性上的问题。&lt;/p&gt;
&lt;p&gt;容器和 Kubernetes 这样的容器编排系统 ，将运行时和服务一起打包进镜像，调度容器到合适的节点，运行容器。这个方案可以解决开发团队遇到的不少问题[1]。然而，在这个操作流程中仍存在短板：如何管理服务间的通信。&lt;/p&gt;
&lt;p&gt;在采用服务网格的场景下，以一种和应用代码解耦的方式，增强了应用间统一的网络通信能力。服务网格扩展了集群的管理能力，增强可观测性、服务发现、负载均衡、IT 运维监控及应用故障恢复等功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Istio" scheme="https://www.hi-linux.com/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>超给力，一款简单又实用的免费 GitHub 加速神器</title>
    <link href="https://www.hi-linux.com/posts/8698.html"/>
    <id>https://www.hi-linux.com/posts/8698.html</id>
    <published>2021-08-25T01:00:00.000Z</published>
    <updated>2021-08-25T02:41:30.820Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天给大家推荐一个堪称 GitHub 加速神器的开源项目。</p><p>这个开源项目就是：<strong>FastGitHub</strong>，它主要解决 GitHub 打不开、用户头像无法加载、releases 无法上传下载、git-clone、git-pull、git-push 失败等问题。</p><p>该项目的好处就是专门针对 GitHub 访问速度慢的问题，具有合法性，可靠性，稳定性。最重要的是它是免费的，而且不需要外网服务器资源。</p><h2><span id="fastgithub-加速原理">FastGitHub 加速原理</span></h2><ul><li>修改本机的 <code>DNS</code> 服务指向 FastGithub 自身</li><li>解析匹配的域名为 <code>FastGithub</code> 自身的 IP</li><li>请求安全 <code>DNS</code> 服务 (<code>dnscrypt-proxy</code>) 获取相应域名的 <code>IP</code></li><li>选择最优的 <code>IP</code> 进行 <code>SSH</code> 或 <code>HTTPS</code> 反向代理</li></ul><blockquote><ul><li><p>开源项目地址：<a href="https://github.com/dotnetcore/FastGithub" target="_blank" rel="noopener">https://github.com/dotnetcore/FastGithub</a></p></li><li><p>开源项目作者：.NET Core Community</p></li></ul></blockquote><h2><span id="使用方法">使用方法</span></h2><h3><span id="1-安装-fastgithub">1. 安装 FastGithub</span></h3><h4><span id="本地环境安装">本地环境安装</span></h4><p>运行 <code>FastGithub</code> 程序，本机的网络适配器的 <code>DNS</code> 会自动变成 127.0.0.1。</p><p>如果网络适配器的 <code>DNS</code> 没有变成 <code>127.0.0.1</code>，请手工修改网络适配器的 <code>DNS</code>。</p><blockquote><p>注： Linux 和 macOS 系统需要手动修改。</p></blockquote><h4><span id="局域网服务器安装推荐">局域网服务器安装(推荐)</span></h4><ul><li>在 Linux 服务器上运行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ yum install libicu # 安装依赖包</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;dotnetcore&#x2F;FastGithub&#x2F;releases&#x2F;download&#x2F;1.1.8&#x2F;FastGithub_linux-x64.zip</span><br><span class="line">$ unzip FastGithub_linux-x64.zip</span><br><span class="line">$ cd  FastGithub_linux-x64</span><br><span class="line">$ .&#x2F;FastGithub</span><br></pre></td></tr></table></figure><ul><li>在 Windows 服务器上运行</li></ul><p>以管理员身份运行 <code>cmd</code>，键入如下命令，其中 <code>D:\Softs</code> 为软件实际目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\Softs\FastGithub.exe start &#x2F;&#x2F; 以 Windows 服务安装并启动</span><br><span class="line">D:\Softs\FastGithub.exe stop &#x2F;&#x2F; 卸载并删除 Windows 服务</span><br></pre></td></tr></table></figure><h3><span id="2-使用-fastgithub">2. 使用 FastGithub</span></h3><p>FastGithub 安装完成后， 通过浏览器访问 <code>http://127.0.0.1</code> 或 <code>https://127.0.0.1</code> 以及所在机器的其它 IP 进入 FastGithub 的 Dashboard。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210824134508736-2021-08-24-HDI4u9.png" alt></p><p>接下来，根据实际情况按 <code>Dashboard</code> 页面的提示进行简单设置后，便可高速访问 Github。</p><ol><li>手工修改你电脑的 <code>DNS</code> 服务器的 IP 为 <code>127.0.0.1</code> 或局域网服务器的 <code>IP</code>。</li><li>手工下载和安装 <code>FastGithub.cer</code> 到受信任的根证书颁发机构</li></ol><p><img src="https://img.hi-linux.com/staticfile/image-20210824135233117-2021-08-24-0EnZhv.png" alt></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;p&gt;今天给大家推荐一个堪称 GitHub 加速神器的开源项目。&lt;/p&gt;
&lt;p&gt;这个开源项目就是：&lt;strong&gt;FastGitHub&lt;/strong&gt;，它主要解决 GitHub 打不开、用户头像无法加载、releases
        
      
    
    </summary>
    
    
      <category term="GitHub" scheme="https://www.hi-linux.com/categories/GitHub/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>6 张图带你搞懂 CI/CD 流水线</title>
    <link href="https://www.hi-linux.com/posts/22785.html"/>
    <id>https://www.hi-linux.com/posts/22785.html</id>
    <published>2021-08-20T01:00:00.000Z</published>
    <updated>2021-08-20T08:11:43.614Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>在CI/CD和DevOps领域中，持续交付和持续部署是一个老生常谈的话题。持续集成这个术语最早是在1994年由Grady Booch提出。微服务提出者Martin Flower在2014年发表的论文《Microservice》中也对软件开发持续集成提供了可参考原则。持续集成是借助工具对软件项目进行持续的自动化的编译打包构建测试发布，来检查软件交付质量的一种行为。而持续部署是基于持续交付的优势自动将经过测试的代码推入生产环境的过程。下文从细节描述了持续集成和持续部署各阶段的关键步骤，以下是原文。</p></blockquote><p>本文将探讨CI（持续集成）/CD（持续部署）流程中的各个阶段；以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。</p><p>CI/CD流水线工作流包括CI/CD流程开始时所有阶段等一系列步骤，负责创建自动、连贯的软件交付模型。</p><p>通过CI/CD流水线，软件研发可以实现从代码签入、测试、构建和部署直至生产阶段都在流水线中向前推进。此概念之所以高大上，是因为一旦实施了流水线，就可以将其部分或全部自动化，从而加快开发流程并减少错误。换句话说，CI/CD流水线使企业可以更轻松地应对软件的自动、快速、持续交付。</p><p>DevOps工程师经常会将CI/CD各阶段的和其CI/CD流水线混淆。尽管不同的工具可以将每个复杂阶段自动化完成分阶段的CI/CD，但是整体CI/CD软件链仍然可能由于不可避免的人工干预而中断。因此我们首先需要了解CI/CD流程中的各个阶段，以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。</p><a id="more"></a><h2><span id="cicd-阶段理解参与者-流程-技术">CI/CD 阶段：理解参与者、流程、技术</span></h2><p>企业应用程序开发参与者通常由开发人员，测试人员/QA工程师，运维工程师以及SRE（站点可靠性工程师）或IT运营团队组成。他们紧密合作，目标是高质量软件交付。CI/CD是两个独立过程的组合：持续集成和持续部署。下面列出了每个步骤中的主要步骤：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210616154923127-2021-06-16-Fyhe7J.png" alt></p><h2><span id="持续集成">持续集成</span></h2><p>持续集成（CI）是构建软件和完成初始测试的过程。持续部署（CD）是将代码与基础设施相结合的过程，确保完成所有测试并遵循策略，然后将代码部署到预期环境中。当然，许多公司也有自己特有流程，但主要步骤如下。</p><p><strong>CI：代码提交阶段</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616154929212-2021-06-16-5XICGL.png" alt></p><ul><li><p>参与者：开发工程师，数据库管理员（DBA），基础架构团队</p></li><li><p>技术：GitHub，GitLab，SVM，BitBucket</p></li><li><p>流程：代码提交阶段也称为版本控制。提交是将开发人员编写的最新代码变更发送到代码存储库的操作。开发人员编写的代码的每个版本都被无限期地存储。在与合作者讨论和审查变更之后，开发人员将编写代码，并在软件需求、特性增强、bug修复或变更请求完成后提交。管理编辑和提交变更的存储库称为源代码管理工具（配置管理工具）。在开发人员提交代码（代码推送请求）后，代码更改被合并到主线代码分支中，这些主线代码分支存储在GitHub这样的中央存储库中。</p></li></ul><p><strong>CI：静态代码检查阶段</strong></p><ul><li><p>参与者：开发工程师，数据库管理员（DBA），基础架构团队</p></li><li><p>技术：GitHub，GitLab，SVM，BitBucket</p></li><li><p>流程：开发人员编写代码并将其推送到存储库后，系统将自动触发以启动下一个代码分析过程。开发过程中存在这种情况：提交的代码可以构建成功，但在部署期间构建失败。无论从机器还是人力资源的利用率而言，这都是一个缓慢而昂贵的过程。因此必须检查代码中的静态策略。SAST（静态应用程序安全性测试）：SAST是一种白盒测试方法，可以使用SonarQube，Veracode，Appscan等SAST工具从内部检查代码，以发现软件缺陷，漏洞和弱点（例如SQL注入等）。这是一个快速检查过程，其中检查代码是否存在语法错误。尽管此阶段缺少检查运行时错误的功能，但该功能将在以后的阶段中执行。</p></li></ul><p>将额外的策略检查加入自动化流水线中可以显著减少流程中稍后发现的错误数量。</p><p><strong>CI：构建</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412585-2021-06-16-Ji7Bgv.png" alt></p><ul><li><p>参与者：开发工程师</p></li><li><p>技术：Jenkins，Bamboo CI，Circle CI，Travis CI，Maven，Azure DevOps</p></li><li><p>流程：持续集成过程的目标是提交的代码持续构建为二进制文件或构建产物。通过持续集成来检查添加的新模块是否与现有模块兼容，不仅有助于更快地发现bug，还有助于减少验证新代码更改的时间。构建工具可以根据几乎所有编程语言的源代码创建可执行文件或包（.exe，.dll，.jar等）。在构建过程中，还可以生成SQL脚本，配合基础设施配置文件一起进行测试。简而言之，构建阶段就是编译应用程序的阶段。Artifactory存储、构建验证测试和单元测试也可以作为构建过程的一部分。</p></li></ul><p>构建验证测试（BVT）/冒烟测试/单元测试：</p><p>创建构建后立即执行冒烟测试。BVT将检查所有模块是否正确集成，以及程序的关键功能是否正常运行。这样做的目的是拒绝严重损坏的应用程序，以使QA团队不会在安装和测试软件应用程序步骤浪费时间。</p><p>在完成这些检查后，将向流水线中执行UT（单元测试），以进一步减少生产中的故障。单元测试可验证开发人员编写的单个单元或组件是否按预期执行。</p><p>构建产物存储：</p><p>一旦构建就绪，程序包就会存储在称为Artifactory或Repository工具的中央数据库。随着每天构建量的增加，跟踪所有构建产物也会变得愈加困难。因此，一旦生成并验证了构建产物，就将其发送到存储库进行存储管理。诸如Jfrog Artifactory之类的存储库工具可用于存储诸如.rar，.war，.exe，Msi等之类的二进制文件。测试人员可以从此处手动进行选择，并在测试环境中部署构建产物以进行测试。</p><p><strong>CI：测试阶段</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412605-2021-06-16-52oF9C.png" alt></p><ul><li><p>参与者：测试人员、QA</p></li><li><p>技术：Selenium，Appium，Jmeter，SOAP UI，Tarantula</p></li><li><p>过程：发布构建过程后的一系列自动测试将验证代码的准确性。此阶段可帮助避免生产中的错误。根据构建的大小，此检查可能持续数秒至数小时。对于由多个团队提交和构建代码的大型组织，这些检查在并行环境中运行，以节省宝贵的时间并尽早将错误通知开发人员。</p></li></ul><p>测试人员（或称为QA工程师）基于用户描述的测试用例和场景设置自动化测试用例。他们执行回归分析、压力测试来检查与预期输出的偏差。测试中涉及的活动有完整性测试、集成测试、压力测试。这是一个高层次测试方法。在这个阶段，可以发现开发人员忽视的某些代码问题。</p><p>集成测试：</p><p>集成测试是使用Cucumber、Selenium等工具执行的，在这些工具中，单个应用程序模块被组合起来并作为一组进行测试，同时评估其是否符合指定的功能需求。在集成测试之后，需要有人批准该组中的更新集应该移到下一个阶段，这通常是性能测试。这个验证过程可能很麻烦，但它是整个过程的一个重要部分。验证这个过程业界有很多优秀的方案。</p><p>性能和压力测试：</p><p>Selenium、JMeter等自动化测试工具也可执行性能和压力测试，以检查应用程序在面对高负载时是否稳定和性能良好。该测试流程通常不会在每个更新提交上运行，因为完整的压力测试是长期运行的。当发布主要的新功能时，将对多个更新进行分组，并完成完整的性能测试。在单个更新被转移到下一阶段的情况下，流水线可能将金丝雀测试加入作为可选。</p><h2><span id="持续部署bake和部署">持续部署：Bake和部署</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210616152412635-2021-06-16-lr0ZjG.png" alt></p><ul><li><p>参与者：基础架构工程师，SRE，运维工程师</p></li><li><p>技术：Spinnaker，Argo CD，Tekton CD</p></li><li><p>过程：在测试阶段完成之后，可以部署到服务器的标准代码准备就绪。在部署到生产中之前，它们将被部署到产品团队内部使用的测试环境或beta环境。在将构建移至这些环境之前，构建必须经过Bake和Deploy的子阶段。这两个阶段都是Spinnaker所支持存在的。</p></li></ul><p><strong>CD：Bake</strong></p><p>Baking是指在生产时使用当前配置从源代码创建不可变的镜像实例。这些配置可能是数据库更改和其他基础结构更新之类的事情。Spinnaker可以触发Jenkins执行此任务，并且某些组织更喜欢使用Packer。</p><p><strong>CD：部署</strong></p><p>Spinnaker自动将已bake的镜像发送到部署阶段。这是将服务器组设置为部署到集群的位置。与上述测试过程类似，在部署阶段将执行功能相同的过程。首先将部署移至测试阶段，然后最终移至生产环境，以进行批准和检查。这个处理过程可以由Spinnaker等工具支持。</p><p><strong>CD：验证</strong></p><p>这也是团队优化整个CI/CD流程的关键位置。因为现在已经进行了如此多的测试，所以失败很少见。但是，此时必须尽快解决所有故障，以最大程度地减少对最终客户的影响。团队也应该考虑使流程的这一部分自动化。</p><p>使用蓝绿部署、金丝雀分析、滚动更新等策略部署到产品。在部署阶段，将监视正在运行的应用程序以验证当前部署是否正确或是否需要回滚。</p><p><strong>CD：监控</strong></p><ul><li><p>参与者：站点可靠性工程师（SRE）、运营团队</p></li><li><p>技术：Zabbix、Nagios、Prometheus、Elastic Search、Splunk、Appdynamics、Tivoli</p></li><li><p>过程：为了使软件发行版具有故障安全性和健壮性，在生产环境中跟踪发行版的运行状况至关重要。应用程序监视工具将跟踪性能指标，例如CPU利用率和发行版延迟。日志分析器将扫描由底层中间件和操作系统产生的大量日志，以识别行为并跟踪问题的根源。如果生产中出现任何问题，将通知利益相关者以确保生产环境的安全性和可靠性。此外，监视阶段可帮助组织收集有关其新软件更改如何为收入贡献的情报，帮助基础设施团队跟踪系统行为趋势并进行容量规划。</p></li></ul><h2><span id="持续交付cd反馈和协作工具">持续交付（CD）：反馈和协作工具</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210616154942237-2021-06-16-o4hfIX.png" alt></p><ul><li><p>参与者：站点可靠性工程师（SRE）、运营和维护团队。</p></li><li><p>技术：JIRA、ServiceNow、Slack、电子邮件、Hipchat。</p></li><li><p>过程：DevOps团队的目标是更快地持续发布，然后不断减少错误和性能问题。这是通过不时地通过发送电子邮件向开发人员、项目经理提供有关新版本的质量和性能的反馈。通常情况下，反馈系统是整个软件交付过程的一部分。因此，交付中的任何更改都会频繁地录入系统，以便交付团队可以对它采取行动。</p></li></ul><h2><span id="总结">总结</span></h2><p>企业必须评估一个整体的持续交付解决方案，该解决方案可以自动化或促进上述这些阶段的自动化。</p><p>原文链接：<a href="https://www.opsmx.com/blog/what-is-a-ci-cd-pipeline/" target="_blank" rel="noopener">https://www.opsmx.com/blog/what-is-a-ci-cd-pipeline/</a></p><blockquote><p>本文转载自：「 分布式实验室 」，原文：<a href="https://tinyurl.com/5dtbbk3x" target="_blank" rel="noopener">https://tinyurl.com/5dtbbk3x</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在CI/CD和DevOps领域中，持续交付和持续部署是一个老生常谈的话题。持续集成这个术语最早是在1994年由Grady Booch提出。微服务提出者Martin Flower在2014年发表的论文《Microservice》中也对软件开发持续集成提供了可参考原则。持续集成是借助工具对软件项目进行持续的自动化的编译打包构建测试发布，来检查软件交付质量的一种行为。而持续部署是基于持续交付的优势自动将经过测试的代码推入生产环境的过程。下文从细节描述了持续集成和持续部署各阶段的关键步骤，以下是原文。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文将探讨CI（持续集成）/CD（持续部署）流程中的各个阶段；以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。&lt;/p&gt;
&lt;p&gt;CI/CD流水线工作流包括CI/CD流程开始时所有阶段等一系列步骤，负责创建自动、连贯的软件交付模型。&lt;/p&gt;
&lt;p&gt;通过CI/CD流水线，软件研发可以实现从代码签入、测试、构建和部署直至生产阶段都在流水线中向前推进。此概念之所以高大上，是因为一旦实施了流水线，就可以将其部分或全部自动化，从而加快开发流程并减少错误。换句话说，CI/CD流水线使企业可以更轻松地应对软件的自动、快速、持续交付。&lt;/p&gt;
&lt;p&gt;DevOps工程师经常会将CI/CD各阶段的和其CI/CD流水线混淆。尽管不同的工具可以将每个复杂阶段自动化完成分阶段的CI/CD，但是整体CI/CD软件链仍然可能由于不可避免的人工干预而中断。因此我们首先需要了解CI/CD流程中的各个阶段，以及从快速、规模交付的视角探讨为什么CI/CD流水线对于我们的组织是必不可少的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevOps" scheme="https://www.hi-linux.com/categories/DevOps/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="DevOps" scheme="https://www.hi-linux.com/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>如何有效的在 60 秒内进行 Linux 服务器性能故障分析</title>
    <link href="https://www.hi-linux.com/posts/21098.html"/>
    <id>https://www.hi-linux.com/posts/21098.html</id>
    <published>2021-08-18T01:00:00.000Z</published>
    <updated>2021-08-18T02:23:32.294Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>感谢前辈，光荣属于前辈。</p></blockquote><p>掌握一些性能优化工具和方法，这就需要在工作中不断地积累；计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。</p><p>虽然监控工具可以帮助我们解决大多数问题，但我们有时需要登录实例并运行一些标准的 Linux 性能工具。</p><blockquote><p>来看 Netflix 性能工程团队的这篇博文：<a href="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55" target="_blank" rel="noopener">https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55</a></p></blockquote><p>看他们通过十条命令在一分钟内对机器性能问题进行诊断。在 60 秒内，您可以通过运行以下十个命令，对系统资源使用情况和正在运行的进程有一个高层次的了解。寻找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。饱和是指资源的负载超出其处理能力的情况，可以作为请求队列的长度或等待时间来公开。</p><a id="more"></a><p>当我们把 Linux 操作系统所有的关键一级计数器找完之后，就会得到这样一张图：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210722112925483-2021-07-22-hI8hui.jpg" alt></p><p>这些命令的输出，有助于快速定位性能瓶颈。主要检查出图中标红的计数器，所有资源（CPU、内存、磁盘 IO 等）的利用率（utilization）、饱和度（saturation）和错误（error）度量，也就是 Brendan Gregg 提出的 USE 方法。</p><blockquote><p>The USE Method: <a href="https://www.brendangregg.com/usemethod.html" target="_blank" rel="noopener">https://www.brendangregg.com/usemethod.html</a></p></blockquote><p><img src="https://img.hi-linux.com/staticfile/640-20210722112925497-2021-07-22-I7bgnm.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">uptime</span><br><span class="line">dmesg | tail</span><br><span class="line">vmstat 1</span><br><span class="line">mpstat -P ALL 1</span><br><span class="line">pidstat 1</span><br><span class="line">iostat -xz 1</span><br><span class="line">free -m</span><br><span class="line">sar -n DEV 1</span><br><span class="line">sar -n TCP,ETCP 1</span><br><span class="line">top</span><br></pre></td></tr></table></figure><p>下面我们来逐一介绍下这些命令，有关这些命令更多的参数和说明，请参照命令的手册。</p><h2><span id="uptime">uptime</span></h2><p>这个命令可以快速查看机器的负载情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ uptime</span><br><span class="line">23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02</span><br></pre></td></tr></table></figure><ul><li><p>在 Linux 系统中，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的。这些数据可以让我们对系统资源使用有一个宏观的了解。</p></li><li><p>命令的输出分别表示 1 分钟、5 分钟、15 分钟的平均负载情况。通过这三个数据，可以了解服务器负载是在趋于紧张还是区域缓解。如果 1 分钟平均负载很高，而 15 分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查 CPU 资源都消耗在了哪里。反之，如果 15 分钟平均负载很高，1 分钟平均负载较低，则有可能是 CPU 资源紧张时刻已经过去。</p></li><li><p>上面例子中的输出，可以看见最近 1 分钟的平均负载非常高，且远高于最近 15 分钟负载，因此我们需要继续排查当前系统中有什么进程消耗了大量的资源。可以通过下文将会介绍的 vmstat、mpstat 等命令进一步排查。</p></li></ul><h2><span id="dmesg-tail">dmesg | tail</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg | tail</span><br><span class="line">[1880957.563150] perl invoked oom-killer: gfp_mask&#x3D;0x280da, order&#x3D;0, oom_score_adj&#x3D;0</span><br><span class="line">[...]</span><br><span class="line">[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child</span><br><span class="line">[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB</span><br><span class="line">[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.</span><br></pre></td></tr></table></figure><p>这将查看最近 10 条系统消息（如果有）。查找可能导致性能问题的错误。上面的示例包括 oom-killer 和 TCP 丢弃请求。不要错过这一步！dmesg 总是值得检查。这些日志可以帮助排查性能问题。</p><h2><span id="vmstat">vmstat</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vmstat 1</span><br><span class="line">procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line">r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line">34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0</span><br><span class="line">32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0</span><br><span class="line">32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0</span><br><span class="line">32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0</span><br><span class="line">32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。后面跟的参数 1，表示每秒输出一次统计信息，表头提示了每一列的含义，这里介绍一些和性能调优相关的列：</p><ul><li>r：等待在 CPU 资源的进程数量。这个数据比平均负载更加能够体现 CPU 负载情况，数据中不包含等待 IO 的进程。如果这个数值大于机器 CPU 核数，那么机器的 CPU 资源已经饱和。</li><li>free：系统可用内存数（以千字节为单位），如果剩余内存不足，也会导致系统性能问题。下文介绍到的 free 命令，可以更详细的了解系统内存的使用情况。</li><li>si, so：交换区写入和读取的数量。如果这个数据不为 0，说明系统已经在使用交换区（swap），机器物理内存已经不足。</li><li>us, sy, id, wa, st：这些都代表了 CPU 时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）、IO 等待时间（wait）和被偷走的时间（stolen，一般被其他虚拟机消耗）。</li></ul><p>上述这些 CPU 时间，可以让我们很快了解 CPU 是否处于繁忙状态。一般情况下，如果用户时间和系统时间相加非常大，CPU 处于忙于执行指令。如果 IO 等待时间很长，那么系统的瓶颈可能在磁盘 IO。示例命令的输出可以看见，大量 CPU 时间消耗在用户态，也就是用户应用程序消耗了 CPU 时间。这不一定是性能问题，需要结合 r 队列，一起分析。</p><h2><span id="mpstat-p-all-1">mpstat -P ALL 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ mpstat -P ALL 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015  _x86_64_ (32 CPU)</span><br><span class="line">07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle</span><br><span class="line">07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78</span><br><span class="line">07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99</span><br><span class="line">07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00</span><br><span class="line">07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00</span><br><span class="line">07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><p>该命令可以显示每个 CPU 的占用情况，如果有一个 CPU 占用率特别高，那么有可能是一个单线程应用程序引起的。</p><h2><span id="pidstat-1">pidstat 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ pidstat 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015    _x86_64_    (32 CPU)</span><br><span class="line"></span><br><span class="line">07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos&#x2F;0</span><br><span class="line">07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave</span><br><span class="line">07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java</span><br><span class="line">07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java</span><br><span class="line">07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java</span><br><span class="line">07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat</span><br><span class="line"></span><br><span class="line">07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave</span><br><span class="line">07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java</span><br><span class="line">07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java</span><br><span class="line">07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass</span><br><span class="line">07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>pidstat 命令输出进程的 CPU 占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个 JAVA 进程占用了将近 1600% 的 CPU 时间，既消耗了大约 16 个 CPU 核心的运算资源。</p><h2><span id="iostat-xz-1">iostat -xz 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ iostat -xz 1</span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.13    0.00    0.10    0.01    0.00   99.76</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.62    0.03    0.89     0.57     7.97    18.52     0.00    0.68    1.96    0.64   0.60   0.06</span><br><span class="line">vdb               0.00     0.02    0.00    0.38     0.05     2.64    14.12     0.00    0.84    0.46    0.84   0.54   0.02</span><br><span class="line">dm-0              0.00     0.00    0.00    0.40     0.01     2.75    13.62     0.00    0.98    0.37    0.98   0.35   0.01</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.25    0.00    0.00    0.00    0.00   99.75</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.00    0.00    1.00     0.00     4.00     8.00     0.00    0.00    0.00    0.00   1.00   0.10</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           0.00    0.00    0.00    0.00    0.00  100.00</span><br></pre></td></tr></table></figure><p>iostat 命令主要用于查看机器磁盘 IO 情况。该命令输出的列，主要含义是：</p><ul><li>r/s, w/s, rkB/s, wkB/s：分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。</li><li>await：IO 操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括 IO 等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。</li><li>avgqu-sz：向设备发出的请求平均数量。如果这个数值大于 1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。</li><li>%util：设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过 60，可能会影响 IO 性能（可以参照 IO 操作平均等待时间）。如果到达 100%，说明硬件设备已经饱和。</li></ul><p>如果显示的是逻辑设备的数据，那么设备利用率不代表后端实际的硬件设备已经饱和。值得注意的是，即使 IO 性能不理想，也不一定意味应用程序会出现性能问题，可以利用诸如预读取、写缓存等策略提升应用性能。</p><h2><span id="free-m">free –m</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ free -m</span><br><span class="line">            total       used       free     shared    buffers     cached</span><br><span class="line">Mem:        245998      24545     221453         83         59        541</span><br><span class="line">-&#x2F;+ buffers&#x2F;cache:      23944     222053</span><br><span class="line">Swap:            0          0          0</span><br></pre></td></tr></table></figure><p>free 命令可以查看系统内存的使用情况，-m 参数表示按照兆字节展示。最后两列分别表示用于 IO 缓存的内存数，和用于文件系统页缓存的内存数。需要注意的是，第二行 -/+ buffers/cache，看上去缓存占用了大量内存空间。这是 Linux 系统的内存使用策略，尽可能的利用内存，如果应用程序需要内存，这部分内存会立即被回收并分配给应用程序。因此，这部分内存一般也被当成是可用内存。如果可用内存非常少，系统可能会动用交换区（如果配置了的话），这样会增加 IO 开销（可以在 iostat 命令中体现），降低系统性能。</p><h2><span id="sar-n-dev-1">sar -n DEV 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n DEV 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015     _x86_64_    (32 CPU)</span><br><span class="line">12:16:48 AM     IFACE   rxpck&#x2F;s   txpck&#x2F;s    rxkB&#x2F;s    txkB&#x2F;s   rxcmp&#x2F;s   txcmp&#x2F;s  rxmcst&#x2F;s   %ifutil</span><br><span class="line">12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:49 AM     IFACE   rxpck&#x2F;s   txpck&#x2F;s    rxkB&#x2F;s    txkB&#x2F;s   rxcmp&#x2F;s   txcmp&#x2F;s  rxmcst&#x2F;s   %ifutil</span><br><span class="line">12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00</span><br><span class="line">12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>sar 命令在这里可以查看网络设备的吞吐率。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。如示例输出中，eth0 网卡设备，吞吐率大概在 22 Mbytes/s，既 176 Mbits/sec，没有达到 1Gbit/sec 的硬件上限。</p><h2><span id="sar-n-tcpetcp-1">sar -n TCP,ETCP 1</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n TCP,ETCP 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07&#x2F;14&#x2F;2015    _x86_64_    (32 CPU)</span><br><span class="line">12:17:19 AM  active&#x2F;s passive&#x2F;s    iseg&#x2F;s    oseg&#x2F;s</span><br><span class="line">12:17:20 AM      1.00      0.00  10233.00  18846.00</span><br><span class="line">12:17:19 AM  atmptf&#x2F;s  estres&#x2F;s retrans&#x2F;s isegerr&#x2F;s   orsts&#x2F;s</span><br><span class="line">12:17:20 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:17:20 AM  active&#x2F;s passive&#x2F;s    iseg&#x2F;s    oseg&#x2F;s</span><br><span class="line">12:17:21 AM      1.00      0.00   8359.00   6039.00</span><br><span class="line">12:17:20 AM  atmptf&#x2F;s  estres&#x2F;s retrans&#x2F;s isegerr&#x2F;s   orsts&#x2F;s</span><br><span class="line">12:17:21 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>sar 命令在这里用于查看 TCP 连接状态，其中包括：</p><ul><li>active/s：每秒本地发起的 TCP 连接数，既通过 connect 调用创建的 TCP 连接；</li><li>passive/s：每秒远程发起的 TCP 连接数，即通过 accept 调用创建的 TCP 连接；</li><li>retrans/s：每秒 TCP 重传数量；</li></ul><p>TCP 连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP 重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。重传会严重影响tcp的效率，可以使用Brendan Gregg开发的一个轻量级tcp重传抓取工具: tcpretrans。</p><h2><span id="top">top</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92</span><br><span class="line">Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie</span><br><span class="line">%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers</span><br><span class="line">KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java</span><br><span class="line"> 4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave</span><br><span class="line">66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top</span><br><span class="line"> 5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java</span><br><span class="line"> 4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java</span><br><span class="line">    1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init</span><br><span class="line">    2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd</span><br><span class="line">    3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd&#x2F;0</span><br><span class="line">    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker&#x2F;0:0H</span><br><span class="line">    6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker&#x2F;u256:0</span><br><span class="line">    8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched</span><br></pre></td></tr></table></figure><p>top 命令包含了前面好几个命令的检查的内容。比如系统负载情况（uptime）、系统内存使用情况（free）、系统 CPU 使用情况（vmstat）等。因此通过这个命令，可以相对全面的查看系统负载的来源。同时，top 命令支持排序，可以按照不同的列排序，方便查找出诸如内存占用最多的进程、CPU 占用率最高的进程等。但是，top 命令相对于前面一些命令，输出是一个瞬间值，如果不持续盯着，可能会错过一些线索。这时可能需要暂停 top 命令刷新，来记录和比对数据。</p><h2><span id="总结">总结</span></h2><p>排查 Linux 服务器性能问题还有很多工具，上面介绍的一些命令，可以帮助我们快速的定位问题。例如前面的示例输出，多个证据证明有 JAVA 进程占用了大量 CPU 资源，之后的性能调优就可以针对应用程序进行。</p><blockquote><p>本文转载自：「 运维开发故事 」，原文：<a href="https://tinyurl.com/rsyjhzhw" target="_blank" rel="noopener">https://tinyurl.com/rsyjhzhw</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;感谢前辈，光荣属于前辈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;掌握一些性能优化工具和方法，这就需要在工作中不断地积累；计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。&lt;/p&gt;
&lt;p&gt;虽然监控工具可以帮助我们解决大多数问题，但我们有时需要登录实例并运行一些标准的 Linux 性能工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;来看 Netflix 性能工程团队的这篇博文：&lt;a href=&quot;https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看他们通过十条命令在一分钟内对机器性能问题进行诊断。在 60 秒内，您可以通过运行以下十个命令，对系统资源使用情况和正在运行的进程有一个高层次的了解。寻找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。饱和是指资源的负载超出其处理能力的情况，可以作为请求队列的长度或等待时间来公开。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="性能分析" scheme="https://www.hi-linux.com/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你如何给 Docker 开启 IPv6 网络支持</title>
    <link href="https://www.hi-linux.com/posts/47610.html"/>
    <id>https://www.hi-linux.com/posts/47610.html</id>
    <published>2021-08-09T01:00:00.000Z</published>
    <updated>2021-08-09T01:29:41.122Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Docker 默认是不开启 IPv6 支持的，但是我们某些业务往往又需要 IPv6 的支持，特别是 IPv6 普及大势所趋，本文主要介绍的是如何开启 Docker 桥接网络 IPv6 支持，这篇文章具体操作仅供参考，建议以官方文档为准。</p><p>本文最重要的先决条件是主机商已经分配给你一个公网 IPv6 地址段，我们可以通过查看主机控制面板中信息、询问主机供应商或者直接SSH登录主机使用命令<code>ip -f inet6 addr show eth0</code>获取。命令方式获取的 ipv6 地址输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">6: eth0:  mtu 9000 </span><br><span class="line">    inet6 2607:f0d0:1002:51::4&#x2F;64 scope global </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::230:48ff:fe33:bc33&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>其中<code>inet6 2607:f0d0:1002:51::4/64 scope global</code>这行指示的IPv6地址是我们需要的目标地址，注意我们这里选取的是公网IP，也就是后面<code>scope global</code>指示的，大家注意到后续还有一个fe80 开头的 IPv6 地址，这个后面没有 global，也就是通常意义内网 IPv6，本文不使用，当然读者可以根据实际需要选择内网 IPv6 继续参照下面介绍的步骤完成操作。</p><a id="more"></a><h2><span id="1-ipv6-地址段划分">1、IPv6 地址段划分</span></h2><p>Docker 可以配置多个虚拟网络，对于 IPv4 来说通过形如 <code>172.17.0.1/16</code>、<code>172.18.0.1/16</code>、<code>172.19.0.1/16</code> 这样内网私有IP地址段配置多个 IPv4 虚拟网段，那么同样的道理 IPv6 也建议划分多个段，如果手动划分不便，可以通过<a href="https://subnettingpractice.com/ipv6_subnetting.html" target="_blank" rel="noopener">IPv6 Subnetting Calculator</a>自动划分，如下图所示：</p><p><img src="https://img.hi-linux.com/staticfile/img-5ymjj9clsstvpr9p16zumuy8g-2021-06-22-onzc0g.png" alt></p><p>比如刚才的 IPv6 地址划分为 4 个网段如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2607:f0d0:1002:51::&#x2F;66</span><br><span class="line">2607:f0d0:1002:51:4000::&#x2F;66</span><br><span class="line">2607:f0d0:1002:51:8000::&#x2F;66</span><br><span class="line">2607:f0d0:1002:51:c000::&#x2F;66</span><br></pre></td></tr></table></figure><h2><span id="2-配置默认-docker-ipv6">2、配置默认 Docker IPv6</span></h2><p>编辑 Docker 配置文件<code>/etc/docker/daemon.json</code>，如果该文件不存在，请手动建立。配置文件内容如下，如果你已有的配置文件缺少相应的配置项，添加上即可，没有必要完全覆盖内容。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"experimental"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"ipv6"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"ip6tables"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"fixed-cidr-v6"</span>: <span class="string">"2607:f0d0:1002:51::/66"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里<code>ip6tables</code>是指由 Docker 自动配置 IPv6 的防火墙规则，如果你希望自己手动配置，请改为 false 或者移除此项，否则容器将无法连接 IPv6 网络；<code>fixed-cidr-v6</code> 则是我们划分的子网段的第一个，这里仅作示例请读者根据实际情况修改。</p><p>完成配置后请使用<code>systemctl restart docker</code>重启docker服务生效。完成此步后 Docker 算是完成对于 IPv6 的支持了。</p><h2><span id="3-配置-docker-compose-的-ipv6-支持可选">3、配置 Docker Compose 的 IPv6 支持（可选）</span></h2><p>这个主要是我编排容器时用的比较多，这里也记录一下作为一个备忘吧。</p><p>Docker Compose 的配置文件内容关于 IPv6 部分重点是网络节配置，如果另外配置网络的话，必须选择与默认<code>daemon.json</code>不同的 IPv6 子网段，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">networks:</span><br><span class="line">  example:</span><br><span class="line">    enable_ipv6: true</span><br><span class="line">    driver: bridge</span><br><span class="line">    driver_opts:</span><br><span class="line">      com.docker.network.enable_ipv6: &quot;true&quot;</span><br><span class="line">    ipam:</span><br><span class="line">      config:</span><br><span class="line">       - subnet: 172.23.0.0&#x2F;16</span><br><span class="line">       - subnet: &quot;2607:f0d0:1002:51:4000::&#x2F;66&quot;</span><br><span class="line">         gateway:2607:f0d0:1002:51:4000::1</span><br></pre></td></tr></table></figure><p>这里<code>example</code>网络我们通过配置开启IPv6支持，其中网络段配置IPv4是<code>172.23.0.0/16</code>，IPv6选用余下的第二个网段<code>2607:f0d0:1002:51:4000::/66</code>注意这里<strong>不能</strong>和<code>daemon.json</code>配置的 IPv6 网段一样。这里的 IP 配置同样是一个示例，读者请根据实际情况进行修改。</p><h2><span id="参考资料">参考资料</span></h2><ul><li><a href="https://docs.docker.com/config/daemon/ipv6/" target="_blank" rel="noopener">Enable IPv6 support</a></li></ul><blockquote><p>本文转载自：「 王晔的博客 」，原文：<a href="https://tinyurl.com/4y22pxx6" target="_blank" rel="noopener">https://tinyurl.com/4y22pxx6</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker 默认是不开启 IPv6 支持的，但是我们某些业务往往又需要 IPv6 的支持，特别是 IPv6 普及大势所趋，本文主要介绍的是如何开启 Docker 桥接网络 IPv6 支持，这篇文章具体操作仅供参考，建议以官方文档为准。&lt;/p&gt;
&lt;p&gt;本文最重要的先决条件是主机商已经分配给你一个公网 IPv6 地址段，我们可以通过查看主机控制面板中信息、询问主机供应商或者直接SSH登录主机使用命令&lt;code&gt;ip -f inet6 addr show eth0&lt;/code&gt;获取。命令方式获取的 ipv6 地址输出如下：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;6: eth0:  mtu 9000 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    inet6 2607:f0d0:1002:51::4&amp;#x2F;64 scope global &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       valid_lft forever preferred_lft forever&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    inet6 fe80::230:48ff:fe33:bc33&amp;#x2F;64 scope link &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       valid_lft forever preferred_lft forever&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中&lt;code&gt;inet6 2607:f0d0:1002:51::4/64 scope global&lt;/code&gt;这行指示的IPv6地址是我们需要的目标地址，注意我们这里选取的是公网IP，也就是后面&lt;code&gt;scope global&lt;/code&gt;指示的，大家注意到后续还有一个fe80 开头的 IPv6 地址，这个后面没有 global，也就是通常意义内网 IPv6，本文不使用，当然读者可以根据实际需要选择内网 IPv6 继续参照下面介绍的步骤完成操作。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes v1.22.0 正式发布，众多 API 和功能被移除</title>
    <link href="https://www.hi-linux.com/posts/43527.html"/>
    <id>https://www.hi-linux.com/posts/43527.html</id>
    <published>2021-08-05T01:00:00.000Z</published>
    <updated>2021-08-05T04:21:06.065Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>我们兴奋地向大家宣布，Kubernetes 在 2021 年内的第二个版本、即 1.22 版本已经正式来临！</p><p>新版本包含 53 项增强功能：其中13项功能已升级至稳定版，24 项功能顺利步入 beta 阶段，16 项功能刚刚开始 alpha 阶段。另有 3 项功能被彻底弃用。</p><p>今年 4 月，Kubernetes 的发布周期已经正式由每年4次调整为每年3次。而1.22版本正是调整之后的首个长周期发布版本。随着Kubernetes的逐渐成熟，每个发布周期中包含的增强功能数量一直在持续增加。这意味着贡献者社区及发布工程团队需要在两个版本之间完成更多开发工作，而新版本中的大量全新功能也会给最终用户社区带来一定的学习压力。</p><p>有鉴于此，Kubernetes 的发布节奏由一年四次调整为一年三次能够带来更好的均衡效果，包括贡献与版本管理、社区规划升级并为用户提供更舒适的更新上手体验。</p><a id="more"></a><h2><span id="版本要点">版本要点</span></h2><p><strong>Server-side Apply 迎来 GA 通用版本</strong></p><p>Server-side Apply[1]是一种面向 Kubernetes API 服务器的全新字段所有权及对象合并算法。Server-side Apply 通过声明式配置帮助用户及控制器管理其资源，包括以声明方式创建及/或修改对象、发送明确指定的意图等等。经过数个版本的测试之后，Server-side Apply 现已正式进入 GA 通用版阶段。</p><p><strong>外部凭证提供程序迎来稳定版</strong></p><p>自 1.11 版本以来，对 Kubernetes 客户端凭证插件的支持就一直处于测试阶段。而随着 Kubernetes 1.22 的推出，这项功能逐步趋于稳定。其中的 GA 功能集现在包括对交互式登录流程插件提供更好的支持，同时修复了多项 bug。感兴趣的插件作者可以参考 sample-exec-plugin[2] 以了解更多详细信息。</p><p><strong>etcd 更新至 3.5.0</strong></p><p>Kubernetes的默认后端存储etcd获得了3.5.0新版本。新版本改进了安全性、性能、监控以及开发者体验，修复了多项bug，同时带来了迁移为结构化日志记录与内置日志轮替等重要新功能。3.5.0版本还提出详尽的后续发展路线图，探索如何更好地解决流量过载问题。感兴趣的朋友可以参考<a href="http://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&amp;mid=2649730822&amp;idx=1&amp;sn=cbe9049035712f58e465f4108703168d&amp;chksm=88939065bfe419739df224da1c33bf8f9b9ef49ebe136cfdb2cf36e0470b8fa1c46e2d184eaa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">3.5.0发布公告</a>中的完整变更清单。</p><p><strong>用于内存资源的 Quality of Service（QoS）</strong></p><p>最初，Kubernetes使用的是 v1 cgroups API。通过这种设计，Pod的QoS类将仅可用于CPU资源（例如cpu_shares）。如今，Kubernetes 1.22版以alpha测试的形式使用cgroups v2 API控制内存分配与隔离，希望在内存资源发生争用时提高工作负载与节点的可用性、改善容器生命周期的可预测性。</p><p><strong>节点系统交换支持</strong></p><p>每一位系统管理员或Kubernetes用户在设置和使用 Kubernetes 时，都会不约而同地禁用掉交换空间。随着 Kubernetes 1.22 版本的发布，新的 alpha 功能已可支持运行具有交换内存的节点。这项变更使得管理员能够选择在Linux节点上配置交换，并将一部分块存储视为额外的虚拟内存。</p><p><strong>Windows 增强与功能</strong></p><p>SIG Windows继续为不断发展壮大的开发者社区提供支持，并在1.22新版本中发布了自己的开发环境。这些新工具支持多种CNI提供程序并能够在多个平台上顺畅运行。通过编译Windows kubelet与kube-proxy，再配合日常构建的其他Kubernetes组件，新版本为用户带来一种从零开始使用全新Windows功能的新方法。</p><p>CSI对Windows节点的支持也在1.22版本中达到GA通用阶段。另外，Kubernetes 1.22迎来了新的alpha功能——Windows特权容器。为了在Windows节点上使用CSI存储，CSIProxy允许我们将CSI节点插件部署为非特权Pod，并使用代理在节点上执行特权存储操作。</p><p><strong>seccomp 默认配置</strong></p><p>Kubelet以alpha功能的形式提供默认seccomp配置功能，同时附带新的命令行标志与配置。在使用时，这项新功能可提供集群范围内的seccomp默认值，并使用RuntimeDefault seccompt配置取代默认情况下的Unconfined，从而大大增强了Kubernetes部署的默认安全性。凭借更出色的默认工作负载安全效果，管理员们终于可以睡个好觉了。若需了解这项功能的更多详细信息，请参阅官方seccomp教程[3]。</p><p><strong>使用 kubeadm 提升控制平面安全</strong></p><p>这项新的alpha功能允许我们以非root用户身份运行kubeadm控制平面组件。长久以来，kubeadm一直要求采取这样一种安全措施。要实际体验，你需要在kubeadm中启用特定的RootlessControlPlane feature gate。在使用这项alpha功能部署集群时，你的控制平面将以较低权限运行。</p><p>对于kubeadm，Kubernetes 1.22还带来了新的v1beta3配置API。此次迭代带来了多项社区期待已久的功能，同时弃用了部分现有功能。v1beta3将成为目前的首选API版本；但v1beta2 API仍然正常可用，并未在1.22版中被淘汰。</p><h2><span id="主要变化">主要变化</span></h2><p><strong>删除了几个已弃用的 beta API</strong></p><p>1.22版本中删除了许多已经弃用的beta API，并发布这些API的GA通用版本。全部现有对象均可通过稳定的API进行交互。此次删除涉及 Ingress，IngressClass，Lease，APIService，ValidatingWebhookConfiguration，MutatingWebhookConfiguration，CustomResourceDefinition，TokenReview，SubjectAccessReview以及 CertificateSigningRequest API的beta版本。</p><p>关于完整清单，请参阅已弃用API迁移指南[4]以及博文《1.22版本中的Kubernetes API与功能删除：你需要了解的一切[5]》。</p><p><strong>临时容器的 API 变更与改进</strong></p><p>用于创建临时容器的 API 在 1.22 版本中也发生了变化。临时容器功能现为alpha版且默认禁用，新的API也不再响应客户端对旧有API的使用请求。</p><p>在稳定功能方面，kubectl 工具遵循 Kubernetes 版本倾斜策略，但kubectl v1.21及更早版本无法支持临时容器的新API。如果你打算使用kubectl debug创建临时容器，且你的集群运行有Kubernetes 1.22，则无法使用kubectl v1.21或更早版本完成这项操作。如果你希望将 kubectl debug 与多个集群版本混合使用，请务必将 kubectl 更新至1.22。</p><h2><span id="其他更新">其他更新</span></h2><p><strong>更新至稳定版</strong></p><ul><li>限定服务账户令牌数量</li><li>CSI服务账户令牌</li><li>Windows对CSI插件的支持</li><li>对于在操作中使用已弃用API的警告机制</li><li>清退PodDisruptionBudget</li></ul><p><strong>重要功能更新</strong></p><ul><li>引入新的 PodSecurity 准入 alpha 功能，用以替代原有 PodSecurityPolicy</li><li>The Momory Manager 进入 beta 阶段</li><li>推出新的alpha功能，用于实现 API Server Tracing</li><li>kubeadm配置格式迎来新的 v1beta3 版本</li><li>用于 PersistentVolumes 的通用数据填充器已提供 alpha 版</li><li>Kubernetes 控制平面现可始终使用 CronJobs v2 控制器</li><li>作为 alpha 功能，所有 Kubernetes 节点组件（包括 kubelet、kube-proxy 与容器运行时）都能够以非 root 用户身份运行</li></ul><h2><span id="发布说明">发布说明</span></h2><p>请点击此处[6]查看 1.22 版本的完整发布说明信息。</p><h2><span id="发布时间">发布时间</span></h2><p>Kubernetes 1.22 现已开放下载[7]并正式登陆GitHub[8]。</p><h2><span id="版本徽标">版本徽标</span></h2><p><img src="https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNmJEu8ECBEibyEwsP7eqc3IicbGd65ga9tP2X1g6RGkB4zIsJuw0qdwRc4UCuiaLwkl4XDOWltlzq7mQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p>面对新冠疫情、自然灾害与倦怠情绪的重重挑战，Kubernetes 1.22 仍然拿出了 53 项增强功能，这也使其成为迄今为止更新量最大的 Kubernetes 版本。这样辉煌的成就，离不开发布团队成员们的辛勤努力、热情奉献以及Kubernetes生态系统中杰出贡献者们的不懈支持。1.22 版本发布徽标提醒我们要不断突破新的极限、创造新的纪录。谨以此标，献给每一位发布团队成员、攀登者与前瞻者！</p><p>徽标由 Boris Zotkin 设计。作为 MathWorks的Mac/Linux 管理员，Boris 热爱生活中平淡简单的一切，喜欢与家人共度时光。这里再次感谢这位乐观技术人贡献的精美作品！</p><p>相关链接：</p><ol><li><a href="https://kubernetes.io/docs/reference/using-api/server-side-apply/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/using-api/server-side-apply/</a></li><li><a href="https://github.com/ankeesler/sample-exec-plugin" target="_blank" rel="noopener">https://github.com/ankeesler/sample-exec-plugin</a></li><li><a href="https://kubernetes.io/docs/tutorials/clusters/seccomp/#enable-the-use-of-runtimedefault-as-the-default-seccomp-profile-for-all-workloads" target="_blank" rel="noopener">https://kubernetes.io/docs/tutorials/clusters/seccomp/#enable-the-use-of-runtimedefault-as-the-default-seccomp-profile-for-all-workloads</a></li><li><a href="https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22</a></li><li><a href="https://blog.k8s.io/2021/07/14/upcoming-changes-in-kubernetes-1-22/" target="_blank" rel="noopener">https://blog.k8s.io/2021/07/14/upcoming-changes-in-kubernetes-1-22/</a></li><li><a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.22.md" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.22.md</a></li><li><a href="https://kubernetes.io/releases/download/" target="_blank" rel="noopener">https://kubernetes.io/releases/download/</a></li><li><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.22.0" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/releases/tag/v1.22.0</a></li></ol><p>原文链接：<a href="https://kubernetes.io/blog/2021/08/04/kubernetes-1-22-release-announcement/" target="_blank" rel="noopener">https://kubernetes.io/blog/2021/08/04/kubernetes-1-22-release-announcement/</a></p><blockquote><p>本文转载自：「 分布式实验室 」，原文：<a href="https://tinyurl.com/4dpzmp5c" target="_blank" rel="noopener">https://tinyurl.com/4dpzmp5c</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们兴奋地向大家宣布，Kubernetes 在 2021 年内的第二个版本、即 1.22 版本已经正式来临！&lt;/p&gt;
&lt;p&gt;新版本包含 53 项增强功能：其中13项功能已升级至稳定版，24 项功能顺利步入 beta 阶段，16 项功能刚刚开始 alpha 阶段。另有 3 项功能被彻底弃用。&lt;/p&gt;
&lt;p&gt;今年 4 月，Kubernetes 的发布周期已经正式由每年4次调整为每年3次。而1.22版本正是调整之后的首个长周期发布版本。随着Kubernetes的逐渐成熟，每个发布周期中包含的增强功能数量一直在持续增加。这意味着贡献者社区及发布工程团队需要在两个版本之间完成更多开发工作，而新版本中的大量全新功能也会给最终用户社区带来一定的学习压力。&lt;/p&gt;
&lt;p&gt;有鉴于此，Kubernetes 的发布节奏由一年四次调整为一年三次能够带来更好的均衡效果，包括贡献与版本管理、社区规划升级并为用户提供更舒适的更新上手体验。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>美国安全局 NSA、CISA 发布 Kubernetes 安全加固指南(内附免费下载地址)</title>
    <link href="https://www.hi-linux.com/posts/51218.html"/>
    <id>https://www.hi-linux.com/posts/51218.html</id>
    <published>2021-08-05T01:00:00.000Z</published>
    <updated>2021-08-05T04:21:06.067Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Kubernetes 最初由谷歌公司的工程师开发，随后由云原生计算基金会开源，它是当前最流行的容器协作软件。Kubernetes 主要用于基于云的基础设施内部，便于系统管理员使用软件容器部署新的 IT 资源。</p><p>Kubernetes 的攻击目标通常有以下三个原因：<strong>数据窃取、计算能力窃取或拒绝服务</strong>。传统上，数据盗窃是主要动机；然而，由于 Kubernetes 和 Docker 模型和传统的单片软件平台之间存在巨大不同，因此很多系统管理员在安全配置 Kubernetes 方面问题颇多。多年来，多款密币挖掘僵尸网络都在攻击这类配置错误问题。威胁行动者扫描互联网上被暴露的未认证的 Kubernetes 管理功能或者扫描在大型 Kubernetes 集群（如 Argo Workflow 或 Kubeflow）上运行的应用程序，获得对 Kubernetes 后端的访问权限，之后利用这种权限在受害者云基础设施上部署密币挖掘应用。这些攻击早在 2017 年初就已发生，而现在已发展为多个团伙为了利用同一个配置错误的集群而大打出手。</p><a id="more"></a><p>美国国家安全局 (NSA) 和网络安全与基础设施安全局 (CISA) 近日发布了一份 59 页的网络安全技术报告『Kubernetes 安全加固指南』。该报告详细介绍了对 Kubernetes 环境的威胁，并提供了配置指南以最大限度地降低风险。</p><p>CISA 和 NSA 发布的这份指南旨在为系统管理员提供关于未来 Kubernetes 配置的安全基线，以避免遭受此类攻击。另外除了基本的配置指南外，这份报告还详述了企业和政府机构可采取的基本缓解措施，阻止或限制 Kubernetes 安全事件的严重性，包括：</p><ul><li><p>扫描容器和 Pods，查找漏洞或配置错误问题。</p></li><li><p>尽可能以最小权限运行容器和 Pods。</p></li><li><p>使用网络分割来控制攻陷事件造成的损害。</p></li><li><p>使用防火墙来限制不必要的网络连接和加密以保护机密性。</p></li><li><p>使用强认证和授权限制用户和管理员访问权限以及限制攻击面。</p></li><li><p>使用日志审计，以便管理员能够监控活动并收到关于潜在恶意活动的警报。</p></li><li><p>定期审计所有的 Kubernetes 设置并使用漏洞扫描确保安全风险得到控制，补丁已应用。</p></li></ul><p>NSA 和 CISA 的这份指南侧重于安全挑战，并建议系统管理员尽可能强化他们的环境。NSA 发布此指南是支持美国国防部、国防工业基地和国家安全系统的使命的一部分。</p><p><strong>如需『 美国安全局 Kubernetes 安全加固指南 』 PDF 版，可在公众号对话框回复关键字：「<code>K8s-Hardening-Guidance</code>」免费获取。</strong></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes 最初由谷歌公司的工程师开发，随后由云原生计算基金会开源，它是当前最流行的容器协作软件。Kubernetes 主要用于基于云的基础设施内部，便于系统管理员使用软件容器部署新的 IT 资源。&lt;/p&gt;
&lt;p&gt;Kubernetes 的攻击目标通常有以下三个原因：&lt;strong&gt;数据窃取、计算能力窃取或拒绝服务&lt;/strong&gt;。传统上，数据盗窃是主要动机；然而，由于 Kubernetes 和 Docker 模型和传统的单片软件平台之间存在巨大不同，因此很多系统管理员在安全配置 Kubernetes 方面问题颇多。多年来，多款密币挖掘僵尸网络都在攻击这类配置错误问题。威胁行动者扫描互联网上被暴露的未认证的 Kubernetes 管理功能或者扫描在大型 Kubernetes 集群（如 Argo Workflow 或 Kubeflow）上运行的应用程序，获得对 Kubernetes 后端的访问权限，之后利用这种权限在受害者云基础设施上部署密币挖掘应用。这些攻击早在 2017 年初就已发生，而现在已发展为多个团伙为了利用同一个配置错误的集群而大打出手。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>巧用 Xpanes 实现多服务器批量管理</title>
    <link href="https://www.hi-linux.com/posts/36685.html"/>
    <id>https://www.hi-linux.com/posts/36685.html</id>
    <published>2021-08-04T01:00:00.000Z</published>
    <updated>2021-08-04T02:29:35.927Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>由 Tmux 提供支持的终极终端分屏器！</strong></p></blockquote><p>虽然我们已经可以使用 <code>tmux</code> 进行屏幕的分割和切换，但是如果需要对一批服务器进行操作的话，就只能一个一个的登录和执行了。如果使用过 <code>Xshell</code> 或者其他远程工具的话，肯定是使用过这个功能特性的，一次命令输出可以在登录的多个远程终端上面执行。现在我们可以使用 <code>tmux-xpanes</code> 来完成同样的事情了，撒花！</p><a id="more"></a><h2><span id="特点介绍">特点介绍</span></h2><blockquote><p>the features about xpanes</p></blockquote><ul><li>Split tmux window into multiple panes</li><li>将 tmux 窗口拆分为多个窗格<ul><li>Construct command lines &amp; execute them on the panes</li><li>构造命令行并在窗格上执行它们</li></ul></li><li>Runnable from outside of tmux session</li><li>Runnable from inside of tmux session</li><li>Record operation log</li><li>记录操作日志</li><li>Flexible layout arrangement for panes</li><li>窗格的灵活布局安排<ul><li>Select layout presets</li><li>选择布局预设</li><li>Set columns or rows as you like</li><li>根据需要设置列或行</li></ul></li><li>Display pane title on each pane</li><li>在每个窗格上显示窗格标题</li><li>Generate command lines from standard input (Pipe mode)</li><li>标准输入(管道模式)生成命令行</li></ul><h2><span id="工具安装">工具安装</span></h2><blockquote><p>requirements: bash3.2+ and tmux1.8+</p></blockquote><ul><li>macOS</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install tmux-xpanes</span><br></pre></td></tr></table></figure><ul><li>CentOS</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-$(rpm --<span class="built_in">eval</span> %rhel).noarch.rpm</span><br><span class="line">$ sudo yum install xpanes</span><br></pre></td></tr></table></figure><ul><li>Ubuntu</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install software-properties-common</span><br><span class="line">$ sudo add-apt-repository ppa:greymd/tmux-xpanes</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install tmux-xpanes</span><br></pre></td></tr></table></figure><ul><li>Manual</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download with wget</span></span><br><span class="line">$ wget https://raw.githubusercontent.com/greymd/tmux-xpanes/v4.1.3/bin/xpanes -O ./xpanes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Put it under PATH and make it executable.</span></span><br><span class="line">$ sudo install -m 0755 xpanes /usr/<span class="built_in">local</span>/bin/xpanes</span><br></pre></td></tr></table></figure><ul><li>Zsh Completion</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Clone the repository</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/greymd/tmux-xpanes.git /path/to/tmux-xpanes</span><br><span class="line"></span><br><span class="line"><span class="comment"># ~/.zshrc.</span></span><br><span class="line">$ <span class="built_in">source</span> /path/to/tmux-xpanes/completion.zsh</span><br></pre></td></tr></table></figure><h2><span id="工具帮助">工具帮助</span></h2><blockquote><p>tmux-xpanes is alias of xpanes</p></blockquote><ul><li>[Normal mode1] Outside of tmux session<ul><li>当 <code>tmux</code> 没有打开且 <code>xpanes</code> 在终端上执行时，<code>xpanes</code> 的行为如下:</li><li>它新建一个 tmux 会话，并在会话上新建窗口</li><li>此外，它将窗口分隔为多个窗格</li><li>最后，将会话附加上去</li></ul></li><li>[Normal mode2] Inside of tmux session<ul><li>当 <code>tmux</code> 已经打开并在现有的 <code>tmux</code> 会话上执行 <code>xpanes</code> 时，该命令的行为如下:</li><li>它会在现有活动会话上新建一个窗口</li><li>此外，它将窗口分隔为多个窗格</li><li>最后，窗口将处于活动状态</li></ul></li><li>[Pipe mode] Inside of tmux session &amp; Accepting standard input<ul><li>当 <code>xpanes</code> 在正常模式 <code>2</code> 下接受标准输入时，<code>xpanes</code> 的行为将是一个特殊的称为“管道模式”的行为。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">  xpanes [OPTIONS] [argument ...]</span><br><span class="line"></span><br><span class="line">Usage(Pipe mode):</span><br><span class="line">  <span class="built_in">command</span> ... | xpanes [OPTIONS] [&lt;<span class="built_in">command</span>&gt; ...]</span><br><span class="line"></span><br><span class="line">OPTIONS:</span><br><span class="line">  -h,--<span class="built_in">help</span>                    Display this <span class="built_in">help</span> and <span class="built_in">exit</span>.</span><br><span class="line">  -V,--version                 Output version information and <span class="built_in">exit</span>.</span><br><span class="line">  -B &lt;begin-command&gt;           Run &lt;begin-command&gt; before processing &lt;<span class="built_in">command</span>&gt; <span class="keyword">in</span> each pane. Multiple options are allowed.</span><br><span class="line">  -c &lt;<span class="built_in">command</span>&gt;                 Set &lt;<span class="built_in">command</span>&gt; to be executed <span class="keyword">in</span> each pane. Default is `<span class="built_in">echo</span> &#123;&#125;`.</span><br><span class="line">  -d,--desync                  Make synchronize-panes option off <span class="keyword">in</span> new window.</span><br><span class="line">  -e                           Execute given arguments as is. Same as -c <span class="string">'&#123;&#125;'</span></span><br><span class="line">  -I &lt;repstr&gt;                  Replacing one or more occurrences of &lt;repstr&gt; <span class="keyword">in</span> <span class="built_in">command</span> provided by -c or -B. Default is `&#123;&#125;`.</span><br><span class="line">  -C NUM,--cols=NUM            Number of columns of window layout.</span><br><span class="line">  -R NUM,--rows=NUM            Number of rows of window layout.</span><br><span class="line">  -l &lt;layout&gt;                  Set the preset of window layout. Recognized layout arguments are:</span><br><span class="line">                               t    tiled</span><br><span class="line">                               eh   even-horizontal</span><br><span class="line">                               ev   even-vertical</span><br><span class="line">                               mh   main-horizontal</span><br><span class="line">                               mv   main-vertical</span><br><span class="line">  -n &lt;number&gt;                  Set the maximum number of &lt;argument&gt; taken <span class="keyword">for</span> each pane.</span><br><span class="line">  -s                           Speedy mode: Run <span class="built_in">command</span> without opening an interactive shell.</span><br><span class="line">  -ss                          Speedy mode AND close a pane automatically at the same time as process exiting.</span><br><span class="line">  -S &lt;socket-path&gt;             Set a full alternative path to the server socket.</span><br><span class="line">  -t                           Display each argument on the each pane is border as their title.</span><br><span class="line">  -x                           Create extra panes <span class="keyword">in</span> the current active window.</span><br><span class="line">  --<span class="built_in">log</span>[=&lt;directory&gt;]          Enable logging and store <span class="built_in">log</span> files to ~/.cache/xpanes/logs or &lt;directory&gt;.</span><br><span class="line">  --<span class="built_in">log</span>-format=&lt;FORMAT&gt;        Make name of <span class="built_in">log</span> files follow &lt;FORMAT&gt;. Default is `[:ARG:].<span class="built_in">log</span>.%Y-%m-%d_%H-%M-%S`.</span><br><span class="line">  --ssh                        Same as `-t -s -c <span class="string">'ssh -o StrictHostKeyChecking=no &#123;&#125;'</span>`.</span><br><span class="line">  --stay                       Do not switch to new window.</span><br><span class="line">  --bulk-cols=NUM1[,NUM2 ...]  Set number of columns on multiple rows (i.e, <span class="string">"2,2,2"</span> represents 2 cols x 3 rows).</span><br><span class="line">  --debug                      Print debug message.</span><br></pre></td></tr></table></figure><h2><span id="使用介绍">使用介绍</span></h2><blockquote><p>介绍 xpanes 工具的使用方式和简单工作模式！</p></blockquote><p><img src="https://img.hi-linux.com/staticfile/learn-tmux-xpanes-tools-01-20210709162820791-2021-07-09-mNvwzx.gif" alt="使用xpanes来并发执行命令"></p><table><thead><tr><th style="text-align:left">编号</th><th style="text-align:left">参数</th><th style="text-align:left">含义解释</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong><code>-d</code></strong></td><td style="text-align:left">打开的窗口不同步输出命令</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong><code>-c</code></strong></td><td style="text-align:left">包含需要执行的命令</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong><code>-I</code></strong></td><td style="text-align:left">用来指定占位符</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong><code>-t</code></strong></td><td style="text-align:left">可以在每个窗格边框上显示每个参数</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong><code>--ssh</code></strong></td><td style="text-align:left">助于忽略 openssh 的警报消息</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><strong><code>--log</code></strong></td><td style="text-align:left">记录 SSH 连接多个主机并进行日志操作</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><strong><code>-s</code></strong></td><td style="text-align:left">将不会创建新的交互式 shell 命令</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><strong><code>-ss</code></strong></td><td style="text-align:left">屏蔽信息</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left"><strong><code>-x</code></strong></td><td style="text-align:left">可以在现有窗口上创建新窗格</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left"><strong><code>-e</code></strong></td><td style="text-align:left">可以在不同的窗格上执行不同的命令</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left"><strong><code>-B</code></strong></td><td style="text-align:left">可以对每个窗格进行预处理</td></tr><tr><td style="text-align:left">12</td><td style="text-align:left"><strong><code>-C</code></strong></td><td style="text-align:left">来控制窗口的列</td></tr><tr><td style="text-align:left">13</td><td style="text-align:left"><strong><code>-R</code></strong></td><td style="text-align:left">来控制窗口的行</td></tr><tr><td style="text-align:left">14</td><td style="text-align:left"><strong><code>--bulk-cols</code></strong></td><td style="text-align:left">指定对应每一行的列数</td></tr></tbody></table><ul><li>执行如下命令，将使用 <code>tmux</code> 工具打开四个窗口，分别执行 <code>echo n</code> 的命令。执行完成之后，我们就可以在任意一个窗口执行命令，其他窗口均会同步执行该命令。</li><li>默认情况下，执行 <code>xpanes</code> 命令之后，从键盘输入在多个窗格中是同步的。当我们使用完成之后，可以使用 <code>exit</code> 命令来退出所有打开的窗口。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个效果等同</span></span><br><span class="line">$ xpanes &#123;1..4&#125;</span><br><span class="line">$ xpanes 1 2 3 4</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 1                       │$ <span class="built_in">echo</span> 2                       │</span><br><span class="line">│1                              │2                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 3                       │$ <span class="built_in">echo</span> 4                       │</span><br><span class="line">│3                              │4                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br></pre></td></tr></table></figure><ul><li>如果希望，打开的窗口不同步输出命令的话，可以使用 <code>-d/--desync</code> 参数。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -d</span></span><br><span class="line">$ xpanes -d 1 2 3 4</span><br></pre></td></tr></table></figure><ul><li><code>xpanes</code> 的基本选项之一 <code>-c</code> 参数，用于表示需要执行的命令。我们使用 <code>-c</code> 参数将 <code>seq</code> 命令包裹在内，其中 <code>{}</code> 表示需要被替换的参数。这个占位符可以使用 <code>-I</code> 参数来指定。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -c</span></span><br><span class="line">$ xpanes -c <span class="string">'seq &#123;&#125;'</span> 1 2 3 4</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ seq 1                        │$ seq 2                        │</span><br><span class="line">│1                              │1                              │</span><br><span class="line">│                               │2                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ seq 3                        │$ seq 4                        │</span><br><span class="line">│1                              │1                              │</span><br><span class="line">│2                              │2                              │</span><br><span class="line">│3                              │3                              │</span><br><span class="line">│                               │4                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># -I</span></span><br><span class="line">$ xpanes -I@ -c <span class="string">'seq @'</span> 1 2 3 4</span><br><span class="line"></span><br><span class="line"><span class="comment"># -c</span></span><br><span class="line">$ xpanes -c <span class="string">"ssh myuser@&#123;&#125;"</span> host1 host2</span><br><span class="line">$ xpanes -c <span class="string">"ssh -t &#123;&#125; bash -ci 'll'"</span> host-&#123;1,2,3&#125;</span><br><span class="line">$ xpanes -c <span class="string">"tail -f &#123;&#125;"</span> /var/<span class="built_in">log</span>/apache/&#123;error,access&#125;.<span class="built_in">log</span> /var/<span class="built_in">log</span>/application/&#123;error,access&#125;.<span class="built_in">log</span></span><br><span class="line">$ xpanes -c <span class="string">"ssh user@host tail -f &#123;&#125;"</span> /var/<span class="built_in">log</span>/apache/&#123;error,access&#125;.<span class="built_in">log</span> /var/<span class="built_in">log</span>/application/&#123;error,access&#125;.<span class="built_in">log</span></span><br></pre></td></tr></table></figure><ul><li>使用 <code>--ssh</code> 选项有助于忽略 <code>openssh</code> 的警报消息，即不需要回答是/否的问题。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个效果等同</span></span><br><span class="line">$ xpanes --ssh myuser1@host1 myuser2@host2</span><br><span class="line">$ xpanes -t -s -c <span class="string">"ssh -o StrictHostKeyChecking=no &#123;&#125;"</span> myuser1@host1 myuser2@host2</span><br></pre></td></tr></table></figure><ul><li>使用 <code>--log</code> 选项可以记录 <code>SSH</code> 连接多个主机并进行日志操作。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes --<span class="built_in">log</span>=~/operation_log -c <span class="string">"ssh &#123;&#125;"</span> user1@host1 user2@host2</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ ssh user1@host1              │ $ ssh user2@host2             │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line">$ ls ~/operation_log/</span><br><span class="line">user1@host1-1.log.2017-03-15_21-30-07</span><br><span class="line">user2@host2-1.log.2017-03-15_21-30-07</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-s</code> 选项，<code>xpanes</code> 将不会创建新的交互式 <code>shell</code> 命令。这样的好处在于，打开多个新窗格需要很长时间(默认登录 <code>shell</code> 会加载 <code>.zshrc</code> 配置等事情)，不想在 <code>shell</code> 历史记录中留下命令。</li><li>当每个进程结束时，将显示 <strong>“窗格已死…”</strong> 之类的确认消息。如果需要禁用该消息的输出，可以使用 <code>-ss</code> 代替 <code>-s</code> 来进行屏蔽。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes -s -c <span class="string">"seq &#123;&#125;"</span> 2 3 4 5</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line">│1                                         │1                                         │</span><br><span class="line">│2                                         │2                                         │</span><br><span class="line">│Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │3                                         │</span><br><span class="line">│                                          │Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line">│1                                         │1                                         │</span><br><span class="line">│2                                         │2                                         │</span><br><span class="line">│3                                         │3                                         │</span><br><span class="line">│4                                         │4                                         │</span><br><span class="line">│Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │5                                         │</span><br><span class="line">│                                          │Pane is dead: Press [Enter] to <span class="built_in">exit</span>...    │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 屏蔽信息</span></span><br><span class="line">$ xpanes -ss -c <span class="string">"seq &#123;&#125;"</span> 2 3 4 5</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-t</code> 参数，可以在每个窗格边框上显示每个参数。它叫做“窗格标题”。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标题</span></span><br><span class="line">$ xpanes -t -c <span class="string">"ping &#123;&#125;"</span> 192.168.1.&#123;5..8&#125;</span><br><span class="line">+------------------------------------------+------------------------------------------+</span><br><span class="line">│ping 192.168.1.5                          │ping 192.168.1.6                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+---192.168.1.5----------------------------+---192.168.1.6----------------------------+</span><br><span class="line">│ping 192.168.1.7                          │ping 192.168.1.8                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">│                                          │                                          │</span><br><span class="line">+---192.168.1.7----------------------------+---192.168.1.8----------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-x</code> 参数，可以在现有窗口上创建新窗格。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># before</span></span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$                              │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│ $ xpanes -x 4 5 6                                             │</span><br><span class="line">│                                                               │</span><br><span class="line">│                                                               │</span><br><span class="line">│                                                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># after</span></span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$                              │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ xpanes -x 4 5 6              │$ <span class="built_in">echo</span> 4                       │</span><br><span class="line">│$                              │4                              │</span><br><span class="line">│                               │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 5                       │$ <span class="built_in">echo</span> 6                       │</span><br><span class="line">│5                              │6                              │</span><br><span class="line">│$                              │$                              │</span><br><span class="line">│                               │                               │</span><br><span class="line">+-------------------------------+-------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-e</code> 参数，可以在不同的窗格上执行不同的命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个效果等同</span></span><br><span class="line">$ xpanes -e <span class="string">"top"</span> <span class="string">"vmstat 1"</span> <span class="string">"watch -n 1 free"</span></span><br><span class="line">$ xpanes -I@ -c <span class="string">"@"</span> <span class="string">"top"</span> <span class="string">"vmstat 1"</span> <span class="string">"watch -n 1 free"</span></span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ top                          │$ vmstat 1                    │</span><br><span class="line">│                               │                              │</span><br><span class="line">│                               │                              │</span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ watch -n 1 free                                             │</span><br><span class="line">│                                                              │</span><br><span class="line">│                                                              │</span><br><span class="line">+--------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-B</code> 参数，可以对每个窗格进行预处理，<code>-B</code> 选项允许在处理 <code>-c</code> 选项之前执行另一条命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes -B <span class="string">'echo Preprocessing'</span> -c <span class="string">'echo Test'</span> _</span><br><span class="line">+-------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> Preprocessing           │</span><br><span class="line">│Preprocessing                  │</span><br><span class="line">│$ <span class="built_in">echo</span> Test                    │</span><br><span class="line">│Test                           │</span><br><span class="line">│                               │</span><br><span class="line">+-------------------------------+</span><br><span class="line"></span><br><span class="line">$ xpanes -B <span class="string">'echo Pre1'</span> -B <span class="string">'echo Pre2'</span> -B <span class="string">'echo Pre3'</span> -c <span class="string">'echo &#123;&#125;'</span> A B C D</span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> Pre1                    │$ <span class="built_in">echo</span> Pre1                   │</span><br><span class="line">│Pre1                           │Pre1                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre2                    │$ <span class="built_in">echo</span> Pre2                   │</span><br><span class="line">│Pre2                           │Pre2                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre3                    │$ <span class="built_in">echo</span> Pre3                   │</span><br><span class="line">│Pre3                           │Pre3                          │</span><br><span class="line">│$ <span class="built_in">echo</span> A                       │$ <span class="built_in">echo</span> B                      │</span><br><span class="line">+-------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> Pre1                    │$ <span class="built_in">echo</span> Pre1                   │</span><br><span class="line">│Pre1                           │Pre1                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre2                    │$ <span class="built_in">echo</span> Pre2                   │</span><br><span class="line">│Pre2                           │Pre2                          │</span><br><span class="line">│$ <span class="built_in">echo</span> Pre3                    │$ <span class="built_in">echo</span> Pre3                   │</span><br><span class="line">│Pre3                           │Pre3                          │</span><br><span class="line">│$ <span class="built_in">echo</span> C                       │$ <span class="built_in">echo</span> D                      │</span><br><span class="line">+-------------------------------+------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-C</code> 和 <code>-R</code> 参数，来控制窗口的列和行。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes -C 2 AAA BBB CCC DDD</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> AAA                    │$ <span class="built_in">echo</span> BBB                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> CCC                    │$ <span class="built_in">echo</span> DDD                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line"></span><br><span class="line">$ xpanes -R 5 AAA BBB CCC DDD EEE FFF GGG HHH</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> AAA                    │$ <span class="built_in">echo</span> BBB                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> CCC                    │$ <span class="built_in">echo</span> DDD                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> EEE                    │$ <span class="built_in">echo</span> FFF                    │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> GGG                                                   │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> HHH                                                   │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li>使用 <code>--bulk-cols</code> 参数可以接受逗号分隔的数字，每个数字对应每一行的列数。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ xpanes --bulk-cols=1,3,1,2,5 &#123;A..L&#125;</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> A                                                     │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> B            │$ <span class="built_in">echo</span> C            │$ <span class="built_in">echo</span> D           │</span><br><span class="line">│                    │                    │                   │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> E                                                     │</span><br><span class="line">│                                                             │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> F                      │$ <span class="built_in">echo</span> G                      │</span><br><span class="line">│                              │                              │</span><br><span class="line">+-------------------------------------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> H     │$ <span class="built_in">echo</span> I    │$ <span class="built_in">echo</span> J    │$ <span class="built_in">echo</span> K   │$ <span class="built_in">echo</span> L │</span><br><span class="line">│             │            │            │           │         │</span><br><span class="line">+-------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li>当 <code>xpanes</code> 命令接受标准输入时，将激活管道模式。在这种模式下，<code>xpanes</code> 的行为类似于 <code>UNIX</code> 系统的 <code>xargs</code> 命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ seq 3 | xpanes</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 1                      │$ <span class="built_in">echo</span> 2                      │</span><br><span class="line">│1                             │2                             │</span><br><span class="line">│                              │                              │</span><br><span class="line">│                              │                              │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line">│$ <span class="built_in">echo</span> 3                                                     │</span><br><span class="line">│3                                                            │</span><br><span class="line">│                                                             │</span><br><span class="line">│                                                             │</span><br><span class="line">+------------------------------+------------------------------+</span><br><span class="line"></span><br><span class="line">$ seq 4 | xpanes seq</span><br><span class="line">$ seq 4 | xpanes -c <span class="string">'seq &#123;&#125;'</span></span><br><span class="line">$ cat ~/.ssh/config | awk <span class="string">'$1=="Host"&#123;print $2&#125;'</span> | xpanes ssh</span><br></pre></td></tr></table></figure><ul><li>恢复断开连接的会话，即出现异常情况的话，终端断开连接，我们也可以使用 <code>xpanes</code> 来恢复 <code>Tmux</code> 会话。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认情况会创建：~/.cache/xpanes/socket.&lt;PID&gt;</span></span><br><span class="line">$ ls ~/.cache/xpanes/socket.*</span><br><span class="line">/home/user/.cache/xpanes/socket.1234</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话恢复</span></span><br><span class="line">$ tmux -S /home/user/.cache/xpanes/socket.1234 attach</span><br></pre></td></tr></table></figure><ul><li>使用 <code>-S</code> 参数，与他人共享终端会话</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 与他人共享终端会话 - user1</span></span><br><span class="line">[user1@host] $ xpanes -S /home/user1/mysocket a b c d ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 与他人共享终端会话 - user2</span></span><br><span class="line">[user2@host] $ tmux -S /home/user1/mysocket attach</span><br></pre></td></tr></table></figure><h2><span id="一个彩蛋">一个彩蛋</span></h2><blockquote><p>Let’s play!</p></blockquote><ul><li>terminal-parrot</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yes terminal-parrot | head -n 25 | xpanes -e</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/learn-tmux-xpanes-tools-03-2021-07-09-O0WfZo.gif" alt="使用xpanes来并发执行命令 - terminal-parrot"></p><ul><li>sl</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yes <span class="string">'sl -l'</span> | head | xpanes -elev</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/learn-tmux-xpanes-tools-02-2021-07-09-umfszo.gif" alt="使用xpanes来并发执行命令 - sl"></p><h2><span id="参考文档">参考文档</span></h2><ul><li><a href="https://github.com/greymd/tmux-xpanes" target="_blank" rel="noopener">github tmux-xpanes</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客]」，原文：<a href="https://tinyurl.com/y6jrmejf" target="_blank" rel="noopener">https://tinyurl.com/y6jrmejf</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;由 Tmux 提供支持的终极终端分屏器！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;虽然我们已经可以使用 &lt;code&gt;tmux&lt;/code&gt; 进行屏幕的分割和切换，但是如果需要对一批服务器进行操作的话，就只能一个一个的登录和执行了。如果使用过 &lt;code&gt;Xshell&lt;/code&gt; 或者其他远程工具的话，肯定是使用过这个功能特性的，一次命令输出可以在登录的多个远程终端上面执行。现在我们可以使用 &lt;code&gt;tmux-xpanes&lt;/code&gt; 来完成同样的事情了，撒花！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Xpanes" scheme="https://www.hi-linux.com/tags/Xpanes/"/>
    
  </entry>
  
  <entry>
    <title>一次由 Kubernetes HostPort 引发的服务故障排错记实</title>
    <link href="https://www.hi-linux.com/posts/43908.html"/>
    <id>https://www.hi-linux.com/posts/43908.html</id>
    <published>2021-08-03T01:00:00.000Z</published>
    <updated>2021-08-03T04:43:39.254Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近排查了一个 Kubernetes 中使用了 hostport 后遇到比较坑的问题，奇怪的知识又增加了。</p><h2><span id="问题背景">问题背景</span></h2><p>集群环境为 K8s v1.15.9，cni 指定了 flannel-vxlan 跟 portmap, kube-proxy 使用 mode 为 ipvs，集群 3 台 master,同时也是 node，这里以 node-1,node-2,node-3 来表示。</p><p>集群中有 2 个 mysql, 部署在两个 ns 下，mysql 本身不是问题重点，这里就不细说，这里以 mysql-A,mysql-B 来表示。</p><p>mysql-A 落在 node-1 上，mysql-B  落在 node-2 上， <strong>两个数据库svc名跟用户、密码完全不相同</strong></p><a id="more"></a><p>出现诡异的现象这里以一张图来说明会比较清楚一些:</p><p><img src="https://img.hi-linux.com/staticfile/20210729220711-2021-08-02-7dLd8i.png" alt></p><p>其中绿线的表示访问没有问题，红线表示连接Mysql-A提示用户名密码错误</p><p>特别诡异的是，当在 Node-2 上通过 svc 访问 Mysql-A 时，输入 Mysql-A 的用户名跟密码提示密码错误，密码确认无疑，但当输入 Mysql-B 的用户名跟密码，居然能够连接上，看了下数据，连上的是 Mysql-B 的数据库，给人的感觉就是请求转到了 Mysql-A, 最后又转到了 Mysql-B，当时让人大跌眼镜。</p><p>碰到诡异的问题那就排查吧，排查的过程倒是不费什么事，最主要的是要通过这次踩坑机会挖掘一些奇怪的知识出来。</p><h2><span id="排查过程">排查过程</span></h2><p>既然在 Node-1 上连接 Mysql-A/Mysql-B 都没有问题，那基本可以排查是 Mysql-A 的问题</p><p>经实验，在 Node-2 上所有的服务想要连 Mysql-A 时，都有这个问题，但是访问其它的服务又都没有问题，说明要么是 mysql-A 的 3306 这个端口有问题，通过上一步应该排查了 mysql-A 的问题，那问题只能出在 Node-2 上</p><p>在 k8s 中像这样的请求转发出现诡异现象，当排除了一些常见的原因之外，最大的嫌疑就是 iptables 了，作者遇到过多次</p><p>这次也不例外，虽然当前集群使用的 ipvs， 但还是照例看下 iptables 规则，查看 Node-2 上的 iptables 与 Node-1 的 iptables 比对，结果有蹊跷, 在 Node-2 上发现有以下的规则在其它节点上没有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-A CNI-DN-xxxx -p tcp -m tcp --dport 3306 -j DNAT --to-destination 10.224.0.222:3306</span><br><span class="line">-A CNI-HOSTPORT-DNAT -m comment --comment &quot;dnat name&quot;: \&quot;cni0\&quot; id: \&quot;xxxxxxxxxxxxx\&quot;&quot; -j CNI-DN-xxx</span><br><span class="line">-A CNI-HOSTPORT-SNAT -m comment --comment &quot;snat name&quot;: \&quot;cni0\&quot; id: \&quot;xxxxxxxxxxxxx\&quot;&quot; -j CNI-SN-xxx</span><br><span class="line">-A CNI-SN-xxx -s 127.0.0.1&#x2F;32 -d 10.224.0.222&#x2F;32 -p tcp -m tcp --dport 80 -j MASQUERADE</span><br></pre></td></tr></table></figure><p>其中 10.224.0.222 为 Mysql-B 的 pod ip, xxxxxxxxxxxxx 经查实为 Mysql-B 对应的 pause 容器的id</p><p>从上面的规则总结一下就是目的为 3306 端口的请求都会转发到 10.224.0.222 这个地址，即 Mysql-B</p><p>看到这里，作者明白了为什么在 Node-2 上去访问 Node-1 上 Mysql-A 的 3306 会提示密码错误而输入 Mysql-B 的密码却可以正常访问</p><p>虽然两个 mysql 的 svc 名不一样，但上面的 iptables 只要目的端口是 3306 就转发到 Mysql-B 了，当请求到达 mysql 后，使用正确的用户名密码自然可以登录成功</p><p>原因是找到了，但是又引出来了更多的问题?</p><ol><li>这几条规则是谁入到 iptables 中的？</li><li>怎么解决呢，是不是删掉就可以?</li></ol><h2><span id="问题复现">问题复现</span></h2><p>同样是 Mysql，为何 Mysql-A 没有呢? 那么比对一下这两个 Mysql 的部署差异</p><p>比对发现, 除了用户名密码，ns 不一样外，Mysql-B 部署时使用了 hostPort=3306, 其它的并无异常</p><p>难道是因为 hostPort ？</p><p>作者日常会使用 NodePort，倒却是没怎么在意 hostPort,也就停留在 hostPort 跟 NodePort 的差别在于 NodePort 是所有 Node 上都会开启端口，而 hostPort 只会在运行机器上开启端口，由于 hostPort 使用的也少，也就没太多关注，网上短暂搜了一番，描述的也不是很多，看起来大家也用的不多</p><p>那到底是不是因为 hostPort 呢?</p><p><strong>Talk is cheap, show me the code</strong></p><p>通过实验来验证，这里简单使用了三个nginx来说明问题, 其中两个使用了 hostPort，这里特意指定了不同的端口，其它的都完全一样，发布到集群中，yaml 文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-hostport2</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-hostport2</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: nginx-hostport2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: nginx-hostport2</span><br><span class="line">    spec:</span><br><span class="line">      nodeName: spring-38</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:latest</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">              hostPort: 31123</span><br></pre></td></tr></table></figure><p>Finally,问题复现:</p><p><img src="https://img.hi-linux.com/staticfile/20210728133243-2021-08-02-FIx5Us.png" alt></p><p>可以肯定，这些规则就是因为使用了 hostPort 而写入的,但是 <strong>由谁写入的这个问题还是没有解决?</strong></p><h2><span id="罪魁祸首">罪魁祸首</span></h2><p>作者开始以为这些 iptables 规则是由 kube-proxy 写入的, 但是查看 kubelet 的源码并未发现上述规则的关键字</p><p>再次实验及结合网上的探索，可以得到以下结论:</p><p>首先从 kubernetes 的官方发现以下描述:</p><blockquote><p>The CNI networking plugin supports <code>hostPort</code>. You can use the official <a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/portmap" target="_blank" rel="noopener">portmap</a> plugin offered by the CNI plugin team or use your own plugin with portMapping functionality.</p></blockquote><blockquote><p>If you want to enable <code>hostPort</code> support, you must specify <code>portMappings capability</code> in your <code>cni-conf-dir</code>. For example:<br>{<br>“name”: “k8s-pod-network”,<br>“cniVersion”: “0.3.0”,<br>“plugins”: [<br>{<br># …其它的plugin<br>}<br>{<br>“type”: “portmap”,<br>“capabilities”: {“portMappings”: true}<br>}<br>]<br>}</p><p>参考: <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/</a></p></blockquote><p><strong>也就是如果使用了 hostPort， 是由 portmap 这个 cni 提供 portMapping 能力，同时，如果想使用这个能力，在配置文件中一定需要开启 portmap，这个在作者的集群中也开启了，这点对应上了</strong></p><p>另外一个比较重要的结论是:</p><blockquote><p>The CNI ‘portmap’ plugin, used to setup HostPorts for CNI, inserts rules at the front of the iptables nat chains; which take precedence over the KUBE- SERVICES chain. Because of this, the HostPort/portmap rule could match incoming traffic even if there were better fitting, more specific service definition rules like NodePorts later in the chain</p><p>参考: <a href="https://ubuntu.com/security/CVE-2019-9946" target="_blank" rel="noopener">https://ubuntu.com/security/CVE-2019-9946</a></p></blockquote><p><strong>翻译过来就是使用 hostPort 后，会在 iptables 的 nat 链中插入相应的规则，而且这些规则是在 KUBE- SERVICES 规则之前插入的，也就是说会优先匹配 hostPort 的规则，我们常用的 NodePort 规则其实是在 KUBE- SERVICES 之中，也排在其后</strong></p><p>从 portmap 的源码中果然是可以看到相应的代码</p><p><img src="https://img.hi-linux.com/staticfile/20210729225847-2021-08-02-aHFg9f.png" alt></p><p>感兴趣的可以的<a href="https://github.com/containernetworking/plugins.git" target="_blank" rel="noopener"> plugins </a>项目的 meta/portmap/portmap.go 中查看完整的源码</p><p>所以，<strong>最终是调用portmap写入的这些规则.</strong></p><h2><span id="端口占用">端口占用</span></h2><p>进一步实验发现，hostport 可以通过 iptables 命令查看到， 但是无法在 ipvsadm 中查看到</p><p><strong>使用 lsof/netstat 也查看不到这个端口,这是因为 hostport 是通过 iptables 对请求中的目的端口进行转发的，并不是在主机上通过端口监听</strong></p><p><img src="https://img.hi-linux.com/staticfile/20210728133203-2021-08-02-TYPI7H.png" alt></p><p>既然 lsof 跟 netstat 都查不到端口信息，那这个端口相当于没有处于 listen 状态?</p><p>如果这时再部署一个 hostport 指定相同端口的应用会怎么样呢?</p><p>结论是: <strong>使用 hostPort 的应用在调度时无法调度在已经使用过相同 hostPort 的主机上，也就是说，在调度时会考虑 hostport</strong></p><p>如果强行让其调度在同一台机器上，那么就会出现以下错误，如果不删除的话，这样的错误会越来越多，吓的作者赶紧删了.</p><p><img src="https://img.hi-linux.com/staticfile/20210728132630-2021-08-02-B7YGwm.png" alt></p><p>如果这个时候创建一个 nodePort 类型的 svc， 端口也为 31123,结果会怎么样呢?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-nodeport2</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-nodeport2</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: nginx-nodeport2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: nginx-nodeport2</span><br><span class="line">    spec:</span><br><span class="line">      nodeName: spring-38</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:latest</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-nodeport2</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">    nodePort: 31123</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: nginx-nodeport2</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/20210728133425-2021-08-02-Tsej5S.png" alt></p><p>可以发现，NodePort 是可以成功创建的，同时监听的端口也出现了.</p><p><strong>从这也可以说明使用 hostposrt 指定的端口并没有 listen 主机的端口，要不然这里就会提示端口重复之类</strong></p><p>那么问题又来了，同一台机器上同时存在有 hostPort 跟 nodePort 的端口，这个时候如果 curl 31123 时， 访问的是哪一个呢?</p><p>经多次使用 curl 请求后，均是使用了 hostport 那个 nginx pod 收到请求</p><p><strong>原因还是因为 KUBE-NODE-PORT 规则在 KUBE-SERVICE 的链中是处于最后位置，而 hostPort 通过 portmap 写入的规则排在其之前</strong></p><p><img src="https://img.hi-linux.com/staticfile/20210728142725-2021-08-02-JE3uRL.png" alt></p><p>因此会先匹配到 hostport 的规则，自然请求就被转到 hostport 所在的 pod 中，这两者的顺序是没办法改变的，因此无论是 hostport 的应用发布在前还是在后都无法影响请求转发</p><p>另外再提一下，<strong>hostport 的规则在 ipvsadm 中是查询不到的，而 nodePort 的规则则是可以使用 ipvsadm 查询得到</strong></p><h2><span id="问题解决">问题解决</span></h2><p>要想把这些规则删除，可以直接将 hostport 去掉，那么规则就会随着删除,比如下图中去掉了一个 nginx 的 hostport</p><p><img src="https://img.hi-linux.com/staticfile/20210727230931-2021-08-02-DHTY1f.png" alt></p><p>另外使用较多的 port-forward 也是可以进行端口转发的，它又是个什么情况呢? 它其实使用的是 socat 及 netenter 工具，网上看到一篇文章，原理写的挺好的，感兴趣的可以看一看</p><blockquote><p>参考: <a href="https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html" target="_blank" rel="noopener">https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html</a></p></blockquote><h2><span id="生产建议">生产建议</span></h2><p>一句话，生产环境除非是 <strong>必要且无他法</strong>，不然<strong>一定不要使用hostport</strong>，除了会影响调度结果之外，还会出现上述问题，可能造成的后果是非常严重的。</p><h2><span id="参考文章">参考文章</span></h2><ul><li><a href="https://www.qikqiak.com/post/how-to-use-ipvs-in-kubernetes/" target="_blank" rel="noopener">https://www.qikqiak.com/post/how-to-use-ipvs-in-kubernetes/</a></li><li><a href="https://serenafeng.github.io/2020/03/26/kube-proxy-in-iptables-mode/" target="_blank" rel="noopener">https://serenafeng.github.io/2020/03/26/kube-proxy-in-iptables-mode/</a></li><li><a href="https://zhuanlan.zhihu.com/p/94418251" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/94418251</a></li><li><a href="https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/" target="_blank" rel="noopener">https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/</a></li><li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/</a></li><li><a href="https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html" target="_blank" rel="noopener">https://vflong.github.io/sre/k8s/2020/03/15/how-the-kubectl-port-forward-command-works.html</a></li></ul><blockquote><p>本文转载自：「 Z.S.K.'s Records 」，原文：<a href="https://tinyurl.com/35dczb5d" target="_blank" rel="noopener">https://tinyurl.com/35dczb5d</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近排查了一个 Kubernetes 中使用了 hostport 后遇到比较坑的问题，奇怪的知识又增加了。&lt;/p&gt;
&lt;h2 id=&quot;问题背景&quot;&gt;问题背景&lt;/h2&gt;
&lt;p&gt;集群环境为 K8s v1.15.9，cni 指定了 flannel-vxlan 跟 portmap, kube-proxy 使用 mode 为 ipvs，集群 3 台 master,同时也是 node，这里以 node-1,node-2,node-3 来表示。&lt;/p&gt;
&lt;p&gt;集群中有 2 个 mysql, 部署在两个 ns 下，mysql 本身不是问题重点，这里就不细说，这里以 mysql-A,mysql-B 来表示。&lt;/p&gt;
&lt;p&gt;mysql-A 落在 node-1 上，mysql-B  落在 node-2 上， &lt;strong&gt;两个数据库svc名跟用户、密码完全不相同&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>再见 Kubernetes，是时候拥抱下一代轻量级容器编排平台 K0s 了！</title>
    <link href="https://www.hi-linux.com/posts/9354.html"/>
    <id>https://www.hi-linux.com/posts/9354.html</id>
    <published>2021-08-02T01:00:00.000Z</published>
    <updated>2021-08-02T01:39:16.131Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>最近两年一直在使用 kubeadm 部署 kubernetes 集群，总体来说配合一些自己小脚本还有一些自动化工具还算是方便；但是全容器化稳定性确实担忧，也遇到过莫名其妙的证书过期错误，最后重启大法解决这种问题；所以也在探索比较方便的二进制部署方式，比如这个 k0s。</p></blockquote><h2><span id="k0s-介绍">k0s 介绍</span></h2><blockquote><p>The Simple, Solid &amp; Certified Kubernetes Distribution.</p></blockquote><p>k0s 可以认为是一个下游的 Kubernetes 发行版，与原生 Kubernetes 相比，k0s 并未阉割大量 Kubernetes 功能；k0s 主要阉割部分基本上只有 <strong>树内 Cloud provider</strong>，其他的都与原生 Kubernetes 相同。</p><p><strong>k0s 自行编译 Kubernetes 源码生成 Kubernetes 二进制文件，然后在安装后将二进制文件释放到宿主机再启动；这种情况下所有功能几乎与原生 Kubernetes 没有差异。</strong></p><h2><span id="k0sctl-使用">k0sctl 使用</span></h2><p>k0sctl 是 k0s 为了方便快速部署集群所提供的工具，有点类似于 kubeadm，但是其扩展性要比 kubeadm 好得多。在多节点的情况下，k0sctl 通过 ssh 连接目标主机然后按照步骤释放文件并启动 Kubernetes 相关服务，从而完成集群初始化。</p><a id="more"></a><h3><span id="21-使用-k0sctl-安装集群">2.1 使用 k0sctl 安装集群</span></h3><p>安装过程中会自动下载相关镜像，需要保证所有节点可以科学上网，如何离线安装我们后面讲解。<strong>安装前，你需要保证目标机器的 hostname 为非域名形式，否则可能会出现一些问题。</strong> 以下是一个简单的启动集群示例:</p><ul><li>首先安装 k0sctl</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装 k0sctl</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;k0sproject&#x2F;k0sctl&#x2F;releases&#x2F;download&#x2F;v0.9.0&#x2F;k0sctl-linux-x64</span><br><span class="line">$ chmod +x k0sctl-linux-x64</span><br><span class="line">$ mv k0sctl-linux-x64 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;k0sctl</span><br></pre></td></tr></table></figure><ul><li>然后编写 k0sctl.yaml 配置文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">$ vi k0sctl.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.12</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.13</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.14</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.15</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">  k0s:</span><br><span class="line">    version: 1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          address: 10.0.0.11</span><br><span class="line">          port: 6443</span><br><span class="line">          k0sApiPort: 9443</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">        storage:</span><br><span class="line">          type: etcd</span><br><span class="line">          etcd:</span><br><span class="line">            peerAddress: 10.0.0.11</span><br><span class="line">        network:</span><br><span class="line">          kubeProxy:</span><br><span class="line">            disabled: false</span><br><span class="line">            mode: ipvs</span><br></pre></td></tr></table></figure><p>当然你也可以通过 <code>k0sctl init --k0s  &gt; k0sctl.yaml</code> 命令直接生成。</p><ul><li>最后执行 <code>k0sctl apply</code> 命令安装即可</li></ul><blockquote><p>安装前确保你的操作机器可以 SSH 免密登陆所有目标机器。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ k0sctl apply -c k0sctl.yaml</span><br><span class="line"></span><br><span class="line">⠀⣿⣿⡇⠀⠀⢀⣴⣾⣿⠟⠁⢸⣿⣿⣿⣿⣿⣿⣿⡿⠛⠁⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀█████████ █████████ ███</span><br><span class="line">⠀⣿⣿⡇⣠⣶⣿⡿⠋⠀⠀⠀⢸⣿⡇⠀⠀⠀⣠⠀⠀⢀⣠⡆⢸⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀███          ███    ███</span><br><span class="line">⠀⣿⣿⣿⣿⣟⠋⠀⠀⠀⠀⠀⢸⣿⡇⠀⢰⣾⣿⠀⠀⣿⣿⡇⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀███          ███    ███</span><br><span class="line">⠀⣿⣿⡏⠻⣿⣷⣤⡀⠀⠀⠀⠸⠛⠁⠀⠸⠋⠁⠀⠀⣿⣿⡇⠈⠉⠉⠉⠉⠉⠉⠉⠉⢹⣿⣿⠀███          ███    ███</span><br><span class="line">⠀⣿⣿⡇⠀⠀⠙⢿⣿⣦⣀⠀⠀⠀⣠⣶⣶⣶⣶⣶⣶⣿⣿⡇⢰⣶⣶⣶⣶⣶⣶⣶⣶⣾⣿⣿⠀█████████    ███    ██████████</span><br><span class="line"></span><br><span class="line">k0sctl 0.0.0 Copyright 2021, k0sctl authors.</span><br><span class="line">Anonymized telemetry of usage will be sent to the authors.</span><br><span class="line">By continuing to use k0sctl you agree to these terms:</span><br><span class="line">https:&#x2F;&#x2F;k0sproject.io&#x2F;licenses&#x2F;eula</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Connect to hosts</span><br><span class="line">INFO [ssh] 10.0.0.15:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.11:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.12:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.14:22: connected</span><br><span class="line">INFO [ssh] 10.0.0.13:22: connected</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Detect host operating systems</span><br><span class="line">INFO [ssh] 10.0.0.11:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.12:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.14:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.13:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO [ssh] 10.0.0.15:22: is running Ubuntu 20.04.2 LTS</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Prepare hosts</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Gather host facts</span><br><span class="line">INFO [ssh] 10.0.0.11:22: discovered ens33 as private interface</span><br><span class="line">INFO [ssh] 10.0.0.13:22: discovered ens33 as private interface</span><br><span class="line">INFO [ssh] 10.0.0.12:22: discovered ens33 as private interface</span><br><span class="line">INFO &#x3D;&#x3D;&gt; Running phase: Download k0s on hosts</span><br><span class="line">INFO [ssh] 10.0.0.11:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.13:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.12:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.15:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">INFO [ssh] 10.0.0.14:22: downloading k0s 1.21.2+k0s.1</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>稍等片刻后带有三个 Master 和两个 Node 的集群将安装完成:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ k1.node ➜ ~ k0s kubectl get node -o wide</span><br><span class="line">NAME      STATUS   ROLES    AGE   VERSION       INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span><br><span class="line">k1.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.11     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k2.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.12     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k3.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.13     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k4.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.14     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br><span class="line">k5.node   Ready    &lt;none&gt;   10m   v1.21.2+k0s   10.0.0.15     &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-77-generic   containerd:&#x2F;&#x2F;1.4.6</span><br></pre></td></tr></table></figure><blockquote><p>注意: 目标机器 hostname 不应当为域名形式，这里的样例是已经修复了这个问题</p></blockquote><h3><span id="22-k0sctl-的扩展方式">2.2 k0sctl 的扩展方式</span></h3><p>与 kubeadm 不同，k0sctl 几乎提供了所有安装细节的可定制化选项，其通过三种行为来完成扩展:</p><ul><li><strong>文件上传:</strong> k0sctl 允许定义在安装前的文件上传，在安装之前 k0sctl 会把已经定义的相关文件全部上传到目标主机，包括不限于 k0s 本身二进制文件、离线镜像包、其他安装文件、其他辅助脚本等。</li><li><strong>Manifests 与 Helm:</strong> 当将特定的文件上传到 master 节点的 <code>/var/lib/k0s/manifests</code> 目录时，k0s 在安装过程中会自动应用这些配置，类似 kubelet 的 static pod 一样，只不过 k0s 允许全部资源(包括不限于 deployment、daemonset、namespace 等)；同样也可以直接在 <code>k0sctl.yaml</code> 添加 Helm 配置，k0s 也会以同样的方式帮你管理。</li><li><strong>辅助脚本:</strong> 可以在每个主机下配置 <code>hooks</code> 选项来实现执行一些特定的脚本(文档里没有，需要看源码)，以便在特定情况下做点骚操作。</li></ul><h3><span id="23-k0sctl-使用离线镜像包">2.3 k0sctl 使用离线镜像包</span></h3><p>基于上面的扩展，k0s 还方便的帮我们集成了离线镜像包的自动导入，我们只需要定义一个文件上传，将镜像包上传到 <code>/var/lib/k0s/images/</code> 目录后，k0s 会自定将其倒入到 containerd 中而无需我们手动干预:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    # files 配置将会在安装前将相关文件上传到目标主机</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      # 在该目录下的 image 压缩包将会被自动导入到 containerd 中</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p><strong>关于 image 压缩包(bundle_file)如何下载以及自己自定义问题请参考官方 <a href="https://docs.k0sproject.io/v1.21.2+k0s.1/airgap-install/" target="_blank" rel="noopener">Airgap install</a> 文档。</strong></p><p><img src="https://img.hi-linux.com/staticfile/LJIS7j-2021-07-30-GcLOTb.png" alt></p><h3><span id="24-切换-cni-插件">2.4 切换 CNI 插件</span></h3><p>默认情况下 k0s 内部集成了两个 CNI 插件: Calico 和 kube-router。如果我们需要使用其他的 CNI 插件，例如 Flannel，我们只需要将默认的 CNI 插件设置为 <code>custom</code>，然后将 Flannel 的部署 YAML 上传到一台 master 的 <code>/var/lib/k0s/manifests</code> 目录即可，k0s 会自动帮我门执行 <code>apply -f xxxx.yaml</code> 这种操作。</p><p>下面是切换到 Flannel 的样例，需要注意的是 Flannel 官方镜像不会帮你安装 CNI 的二进制文件，我们需要借助文件上传自己安装(<a href="https://github.com/containernetworking/plugins/releases" target="_blank" rel="noopener">CNI GitHub 插件下载地址</a>):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    files:</span><br><span class="line">    # 将 flannel 的 yaml 放到 manifests 里(需要单独创建一个目录)</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">    # 自己安装一下 CNI 插件</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  k0s:</span><br><span class="line">    version: v1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          address: 10.0.0.11</span><br><span class="line">          port: 6443</span><br><span class="line">          k0sApiPort: 9443</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">        storage:</span><br><span class="line">          type: etcd</span><br><span class="line">        network:</span><br><span class="line">          podCIDR: 10.244.0.0&#x2F;16</span><br><span class="line">          serviceCIDR: 10.96.0.0&#x2F;12</span><br><span class="line">          # 这里指定 CNI 为 custom 自定义类型，这样</span><br><span class="line">          # k0s 就不会安装 calico&#x2F;kube-router 了</span><br><span class="line">          provider: custom</span><br></pre></td></tr></table></figure><h3><span id="25-上传-k0s-二进制文件">2.5 上传 k0s 二进制文件</span></h3><p>除了普通文件、镜像压缩包等，默认情况下 k0sctl 在安装集群时还会在目标机器上下载 k0s 二进制文件；当然在离线环境下这一步也可以通过一个简单的配置来实现离线上传:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    # 声明需要上传二进制文件</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    # 指定二进制文件位置</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h3><span id="26-更换镜像版本">2.6 更换镜像版本</span></h3><p>默认情况下 k0s 版本号与 Kubernetes 保持一致，但是如果期望某个组件使用特定的版本，则可以直接配置这些内置组件的镜像名称:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">......</span><br><span class="line">  k0s:</span><br><span class="line">    version: v1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          address: 10.0.0.11</span><br><span class="line">          port: 6443</span><br><span class="line">          k0sApiPort: 9443</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">        # 指定内部组件的镜像使用的版本</span><br><span class="line">        images:</span><br><span class="line">          #konnectivity:</span><br><span class="line">          #  image: us.gcr.io&#x2F;k8s-artifacts-prod&#x2F;kas-network-proxy&#x2F;proxy-agent</span><br><span class="line">          #  version: v0.0.21</span><br><span class="line">          #metricsserver:</span><br><span class="line">          #  image: gcr.io&#x2F;k8s-staging-metrics-server&#x2F;metrics-server</span><br><span class="line">          #  version: v0.3.7</span><br><span class="line">          kubeproxy:</span><br><span class="line">            image: k8s.gcr.io&#x2F;kube-proxy</span><br><span class="line">            version: v1.21.3</span><br><span class="line">          #coredns:</span><br><span class="line">          #  image: docker.io&#x2F;coredns&#x2F;coredns</span><br><span class="line">          #  version: 1.7.0</span><br><span class="line">          #calico:</span><br><span class="line">          #  cni:</span><br><span class="line">          #    image: docker.io&#x2F;calico&#x2F;cni</span><br><span class="line">          #    version: v3.18.1</span><br><span class="line">          #  node:</span><br><span class="line">          #    image: docker.io&#x2F;calico&#x2F;node</span><br><span class="line">          #    version: v3.18.1</span><br><span class="line">          #  kubecontrollers:</span><br><span class="line">          #    image: docker.io&#x2F;calico&#x2F;kube-controllers</span><br><span class="line">          #    version: v3.18.1</span><br><span class="line">          #kuberouter:</span><br><span class="line">          #  cni:</span><br><span class="line">          #    image: docker.io&#x2F;cloudnativelabs&#x2F;kube-router</span><br><span class="line">          #    version: v1.2.1</span><br><span class="line">          #  cniInstaller:</span><br><span class="line">          #    image: quay.io&#x2F;k0sproject&#x2F;cni-node</span><br><span class="line">          #    version: 0.1.0</span><br><span class="line">          default_pull_policy: IfNotPresent</span><br><span class="line">          #default_pull_policy: Never</span><br></pre></td></tr></table></figure><h3><span id="27-调整-master-组件参数">2.7 调整 master 组件参数</span></h3><p>熟悉 Kubernetes 的应该清楚，master 上三大组件: apiserver、controller、scheduler 管控整个集群；在 k0sctl 安装集群的过程中也允许自定义这些组件的参数，这些调整通过修改使用的 <code>k0sctl.yaml</code> 配置文件完成。</p><ul><li><code>spec.api.extraArgs</code>: 用于自定义 kube-apiserver 的自定义参数(kv map)</li><li><code>spec.scheduler.extraArgs</code>: 用于自定义 kube-scheduler 的自定义参数(kv map)</li><li><code>spec.controllerManager.extraArgs</code>: 用于自定义 kube-controller-manager 自定义参数(kv map)</li><li><code>spec.workerProfiles</code>: 用于覆盖 kubelet-config.yaml 中的配置，该配置最终将于默认的 kubelet-config.yaml 合并</li></ul><p>除此之外在 <code>Host</code> 配置中还有一个 <code>InstallFlags</code> 配置用于传递 k0s 安装时的其他配置选项。</p><h2><span id="k0s-ha-搭建">K0s HA 搭建</span></h2><blockquote><p>上面的第二部分主要都是介绍 k0sctl 一些基础功能，为的就是给下面这部分 HA 生产级部署做铺垫。</p></blockquote><p>就目前来说，k0s HA 仅支持独立负载均衡器的 HA 架构。 <strong>即外部需要有一个高可用的 4 层负载均衡器，其他所有 Node 节点链接这个负载均衡器实现 master 的高可用。</strong> 在使用 k0sctl 命令搭建 HA 集群时很简单，只需要添加一个外部负载均衡器地址即可。</p><p>以下是一个完整的，全离线状态下的 HA 集群搭建配置。</p><h3><span id="31-外部负载均衡器">3.1 外部负载均衡器</span></h3><p><strong>在搭建之前我们假设已经有一个外部的高可用的 4 层负载均衡器，且负载均衡器已经负载了以下端口:</strong></p><ul><li><code>6443(for Kubernetes API)</code>: 负载均衡器 6443 负载所有 master 节点的 6443</li><li><code>9443 (for controller join API)</code>: 负载均衡器 9443 负载所有 master 节点的 9443</li><li><code>8132 (for Konnectivity agent)</code>: 负载均衡器 8132 负载所有 master 节点的 8132</li><li><code>8133 (for Konnectivity server)</code>: 负载均衡器 8133 负载所有 master 节点的 8133</li></ul><p>以下为一个 Nginx 4 层代理的样例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">error_log syslog:server&#x3D;unix:&#x2F;dev&#x2F;log notice;</span><br><span class="line"></span><br><span class="line">worker_processes auto;</span><br><span class="line">events &#123;</span><br><span class="line">multi_accept on;</span><br><span class="line">use epoll;</span><br><span class="line">worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line">    upstream kube_apiserver &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:6443;</span><br><span class="line">        server 10.0.0.12:6443;</span><br><span class="line">        server 10.0.0.13:6443;</span><br><span class="line">    &#125;</span><br><span class="line">    upstream konnectivity_agent &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:8132;</span><br><span class="line">        server 10.0.0.12:8132;</span><br><span class="line">        server 10.0.0.13:8132;</span><br><span class="line">    &#125;</span><br><span class="line">    upstream konnectivity_server &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:8133;</span><br><span class="line">        server 10.0.0.12:8133;</span><br><span class="line">        server 10.0.0.13:8133;</span><br><span class="line">    &#125;</span><br><span class="line">    upstream controller_join_api &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 10.0.0.11:9443;</span><br><span class="line">        server 10.0.0.12:9443;</span><br><span class="line">        server 10.0.0.13:9443;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:6443;</span><br><span class="line">        proxy_pass    kube_apiserver;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:8132;</span><br><span class="line">        proxy_pass    konnectivity_agent;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:8133;</span><br><span class="line">        proxy_pass    konnectivity_server;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen        0.0.0.0:9443;</span><br><span class="line">        proxy_pass    controller_join_api;</span><br><span class="line">        proxy_timeout 10m;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="32-搭建-k0s-ha-集群">3.2 搭建 K0s HA 集群</span></h3><p>以下为 k0sctl 的 HA + 离线部署样例配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0sctl.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s-cluster</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.11</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    # role 支持的值</span><br><span class="line">    # &#39;controller&#39; 单 master</span><br><span class="line">    # &#39;worker&#39; 单 worker</span><br><span class="line">    # &#39;controller+worker&#39; master 和 worker 都运行 </span><br><span class="line">    role: controller+worker</span><br><span class="line">    </span><br><span class="line">    # 从本地 上传 k0s bin 文件，不要在目标机器下载</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    </span><br><span class="line">    # 上传其他文件</span><br><span class="line">    files:</span><br><span class="line">    # 上传 flannel 配置，使用自定的 flannel 替换内置的 calico</span><br><span class="line">    - name: flannel</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;kube-flannel.yaml</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;manifests&#x2F;flannel</span><br><span class="line">      perm: 0644</span><br><span class="line">    </span><br><span class="line">    # 上传打包好的 image 镜像包，k0s 会自动导入到 containerd</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    </span><br><span class="line">    # 使用 flannel 后每个机器要上传对应的 CNI 插件</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.12</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.13</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: controller+worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.14</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  - ssh:</span><br><span class="line">      address: 10.0.0.15</span><br><span class="line">      user: root</span><br><span class="line">      port: 22</span><br><span class="line">      keyPath: &#x2F;Users&#x2F;bleem&#x2F;.ssh&#x2F;id_rsa</span><br><span class="line">    role: worker</span><br><span class="line">    uploadBinary: true</span><br><span class="line">    k0sBinaryPath: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;k0s</span><br><span class="line">    files:</span><br><span class="line">    - name: image-bundle</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;bundle_file</span><br><span class="line">      dstDir: &#x2F;var&#x2F;lib&#x2F;k0s&#x2F;images&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">    - name: cni-plugins</span><br><span class="line">      src: &#x2F;Users&#x2F;bleem&#x2F;tmp&#x2F;cni-plugins&#x2F;*</span><br><span class="line">      dstDir: &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;</span><br><span class="line">      perm: 0755</span><br><span class="line">  k0s:</span><br><span class="line">    version: v1.21.2+k0s.1</span><br><span class="line">    config:</span><br><span class="line">      apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">      kind: Cluster</span><br><span class="line">      metadata:</span><br><span class="line">        name: k0s</span><br><span class="line">      spec:</span><br><span class="line">        api:</span><br><span class="line">          # 此处填写外部的负载均衡器地址，所有 kubelet 会链接这个地址</span><br><span class="line">          externalAddress: 10.0.0.20</span><br><span class="line">          # 不要忘了为外部负载均衡器添加 api 证书的 SAN</span><br><span class="line">          sans:</span><br><span class="line">          - 10.0.0.11</span><br><span class="line">          - 10.0.0.12</span><br><span class="line">          - 10.0.0.13</span><br><span class="line">          - 10.0.0.20</span><br><span class="line">        # 存储类型使用 etcd，etcd 集群由 k0s 自动管理</span><br><span class="line">        storage:</span><br><span class="line">          type: etcd</span><br><span class="line">        network:</span><br><span class="line">          podCIDR: 10.244.0.0&#x2F;16</span><br><span class="line">          serviceCIDR: 10.96.0.0&#x2F;12</span><br><span class="line">          # 网络插件使用 custom，然后让 flannel 接管</span><br><span class="line">          provider: custom</span><br><span class="line">          kubeProxy:</span><br><span class="line">            disabled: false</span><br><span class="line">            # 开启 kubelet 的 ipvs 模式</span><br><span class="line">            mode: ipvs</span><br><span class="line">        # 不发送任何匿名统计信息</span><br><span class="line">        telemetry:</span><br><span class="line">          enabled: false</span><br><span class="line">        images:</span><br><span class="line">          default_pull_policy: IfNotPresent</span><br></pre></td></tr></table></figure><p>最后只需要执行 <code>k0sctl apply -c k0sctl.yaml</code> 稍等几分钟集群就搭建好了，安装过程中可以看到相关文件的上传流程:</p><p><img src="https://img.hi-linux.com/staticfile/4rQzJU-2021-07-30-x6oYQu.png" alt></p><h3><span id="33-证书续签和管理">3.3 证书续签和管理</span></h3><p>kubeadm 集群默认证书有效期是一年，到期要通过 kubeadm 重新签署。k0s 集群也差不多一样，但是不同的是 k0s 集群更加暴力。<strong>只要 CA(默认 10年) 不丢，k0s 每次重启都强行重新生成一年有效期的证书，所以在 HA 的环境下，快到期时重启一下 k0s 服务就行。</strong></p><p><strong>k0sctl 安装完的集群默认只有一个 <code>k0scontroller.service</code> 服务，master、node 上所有服务都由这个服务启动，所以到期之前 <code>systemctl restart k0scontroller.service</code> 一下就行。</strong></p><h2><span id="集群备份和恢复">集群备份和恢复</span></h2><p>k0sctl 提供了集群备份和恢复功能，默认情况下只需要执行 <code>k0sctl backup</code> 即可完成集群备份，该命令会在当前目录下生成一个 <code>k0s_backup_TIMESTAMP.tar.gz</code> 备份文件。</p><p>需要恢复集群时使用 <code>k0sctl apply --restore-from k0s_backup_TIMESTAMP.tar.gz</code> 命令进行恢复即可；需要注意的是恢复命令等同于在新机器重新安装集群，所以有一定风险。</p><p><strong>注：经过连续两天的测试，感觉这个备份恢复功能并不算靠谱，还是推荐使用 Velero 备份集群。</strong></p><h2><span id="其他高级功能">其他高级功能</span></h2><h3><span id="51-etcd-替换">5.1 Etcd 替换</span></h3><p>在小规模集群场景下可能并不需要特别完善的 Etcd 作为存储，k0s 借助于 kine 库可以实现使用 SQLite 或 MySQL 等传统数据库作为集群存储；如果想要切换存储只需要调整 <code>k0sctl.yaml</code> 配置即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: k0s.k0sproject.io&#x2F;v1beta1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: k0s</span><br><span class="line">spec:</span><br><span class="line">  storage:</span><br><span class="line">    type: kine</span><br><span class="line">    kine:</span><br><span class="line">      dataSource: &quot;sqlite:&#x2F;&#x2F;&#x2F;var&#x2F;lib&#x2F;k0s&#x2F;db&#x2F;state.db?more&#x3D;rwc&amp;_journal&#x3D;WAL&amp;cache&#x3D;shared&quot;</span><br></pre></td></tr></table></figure><h3><span id="52-集群用户管理">5.2 集群用户管理</span></h3><p>使用 k0sctl 搭建的集群通过 <code>k0s</code> 命令可以很方便的为集群添加用户，以下是添加样例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ k0s kubeconfig create --groups &quot;system:masters&quot; testUser &gt; k0s.config</span><br></pre></td></tr></table></figure><h3><span id="53-containerd-配置">5.3 Containerd 配置</span></h3><p>在不做配置的情况下 k0s 集群使用默认的 Containerd 配置，如果需要自己定义特殊配置，可以在安装时通过文件上传方式将 Containerd 配置文件上传到 <code>/etc/k0s/containerd.toml</code> 位置，该配置将会被 k0s 启动的 Containerd 读取并使用。</p><h2><span id="总结">总结</span></h2><p>k0s 是个不错的项目，对于二进制宿主机部署 Kubernetes 集群很方便，由于其直接采用 Kubernetes 二进制文件启动，所以基本没有功能阉割，而 k0sctl 又为自动化安装提供了良好的扩展性，所以值得一试。不过目前来说 k0s 在细节部分还有一定瑕疵，比如 <code>konnectivity</code> 服务在安装时无法选择性关闭等。k0s 综合来说是个不错的工具，也推荐看看源码，里面很多设计很新颖也比较利于了解集群引导过程。</p><blockquote><p>本文转载自：「 bleem 」，原文：<a href="https://tinyurl.com/puyt7f7d" target="_blank" rel="noopener">https://tinyurl.com/puyt7f7d</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;最近两年一直在使用 kubeadm 部署 kubernetes 集群，总体来说配合一些自己小脚本还有一些自动化工具还算是方便；但是全容器化稳定性确实担忧，也遇到过莫名其妙的证书过期错误，最后重启大法解决这种问题；所以也在探索比较方便的二进制部署方式，比如这个 k0s。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;k0s-介绍&quot;&gt;k0s 介绍&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The Simple, Solid &amp;amp; Certified Kubernetes Distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;k0s 可以认为是一个下游的 Kubernetes 发行版，与原生 Kubernetes 相比，k0s 并未阉割大量 Kubernetes 功能；k0s 主要阉割部分基本上只有 &lt;strong&gt;树内 Cloud provider&lt;/strong&gt;，其他的都与原生 Kubernetes 相同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;k0s 自行编译 Kubernetes 源码生成 Kubernetes 二进制文件，然后在安装后将二进制文件释放到宿主机再启动；这种情况下所有功能几乎与原生 Kubernetes 没有差异。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;k0sctl-使用&quot;&gt;k0sctl 使用&lt;/h2&gt;
&lt;p&gt;k0sctl 是 k0s 为了方便快速部署集群所提供的工具，有点类似于 kubeadm，但是其扩展性要比 kubeadm 好得多。在多节点的情况下，k0sctl 通过 ssh 连接目标主机然后按照步骤释放文件并启动 Kubernetes 相关服务，从而完成集群初始化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>一文搞懂 4 种常用的 Kubernetes 容器</title>
    <link href="https://www.hi-linux.com/posts/16821.html"/>
    <id>https://www.hi-linux.com/posts/16821.html</id>
    <published>2021-07-30T01:00:00.000Z</published>
    <updated>2021-07-30T08:34:23.759Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>截止目前 Kubernetes 1.18，Kubernetes 已经支持标准容器，Sidecar 容器，Init 容器，Ephemeral 容器 4 种类型的 Containers。本文我们详细介绍一下这 4 种容器的特性以及使用场景。</p><p><img src="https://pic2.zhimg.com/80/v2-fac0971dbc8d39235d81ffb07eb9c7cd_720w.jpg" alt></p><h2><span id="标准容器和-sidecar-容器">标准容器和 Sidecar 容器</span></h2><p>在  Kubernetes 1.18 之前，这两种容器从 Kubernetes 管理的角度来看，并没有什么区别。只不过人为从功能上做了区分。</p><p><img src="https://img.hi-linux.com/staticfile/v2-7240d284cc8376172e49e8105953d726_720w-2021-06-25-Spz7c6.jpg" alt></p><h3><span id="使用-sidecar-容器模块化具有的优点">使用 Sidecar 容器（模块化）具有的优点</span></h3><ul><li>加速应用程序开发，因为容器可以在团队甚至更大的社区之间重复使用</li><li>整理专家知识，因为每个人都在一个容器化的实现上进行协作，该实现反映了最佳实践，而不是无数种功能大致相同的自家生产的不同容器</li><li>启用敏捷团队，因为容器边界是自然边界，是团队职责的契约</li><li>提供关注点分离，并专注于特定功能，以减少意大利面条的依赖性和不可测的组件</li></ul><h3><span id="对于-sidecar-容器一般来说主要体现在以下-4-种角色">对于 Sidecar 容器一般来说主要体现在以下 4 种角色：</span></h3><ul><li>代理</li></ul><p>例如现在 Istio 中 的 Envoy。</p><p><img src="https://img.hi-linux.com/staticfile/v2-b134721a06da744cea35d5a399a3d857_720w-2021-06-25-ihOQPI.jpg" alt></p><p>通过这种 Sidercar 模式，代理可以拦截进出主容器的流量从而 Istio 可以提取有关流量行为的大量信号作为属性。 Istio 可以使用这些属性来执行策略决策，并将其发送到监视系统以提供有关整个网格行为的信息。</p><p>Sidecar 代理模型还允许您将 Istio 功能添加到现有部署中，而无需重新构造或重写代码。</p><ul><li>适配器</li></ul><p>适配器容器对输出进行标准化。考虑监视 N 个不同应用程序的任务。可以使用不同的导出监视数据的方式来构建每个应用程序。（例如 JMX，StatsD，特定于应用程序的统计信息），但每个监控系统都希望其收集的监控数据具有一致且统一的数据模型。</p><p>通过使用复合容器的适配器模式，您可以通过创建 Pod 来将来自不同系统的异构监视数据转换为一个统一的表示形式，该 Pod 将应用程序容器与知道如何进行转换的适配器分组在一起。同样，由于这些 Pod 共享名称空间和文件系统，因此这两个容器的协调非常简单明了。</p><p><img src="https://pic1.zhimg.com/80/v2-eab449fd16b6fb03512cbb7c6153fd60_720w.jpg" alt></p><ul><li>增强主容器功能</li></ul><p>Sidecar 容器扩展并增强了 “主” 容器，它们可以使用现有的容器并使它们变得更好。</p><p>例如，考虑一个运行 Nginx Web 服务器的容器。添加另一个将文件系统与 Git 存储库同步的容器，在这些容器之间共享文件系统，并且您已经构建了 Git Push-to-deploy。但是您已经以模块化的方式完成了此工作，其中 Git 同步器可以由不同的团队构建，并且可以在许多不同的Web服务器（Apache，Python，Tomcat等）上重复使用。</p><p>由于这种模块化，您只需编写和测试 Git 同步器一次，即可在众多应用程序中重复使用它。而且，如果有人编写它，您甚至不需要这样做。</p><ul><li>实现辅助功能</li></ul><p>这种场景一般出现在 DevOps 中。比如将收集日志的组件以 Sidecar 的方式部署，实现收集日志的用途，或是部署一个 Sidecar 组件从配置中心监听配置变化，实时更新本地配置。</p><h3><span id="生命周期">生命周期</span></h3><p>Sidecar 容器的所有问题都与容器生命周期相关性有关。由于和 Pod 中的常规容器之间没有区别，因此无法控制哪个容器首先启动或最后终止，但是先正确运行 Sidecar 容器通常是应用程序容器正确运行的要求。</p><p>从 1.18 版本开始，K8S 内置的 Sidecar 功能将确保 Sidecar 容器在正常业务流程开始之前就启动并运行，即通过更改 Pod 的启动生命周期，在 Init 容器完成后启动 Sidecar 容器，在 Sidecar 容器就绪后启动业务容器，从启动流程上保证顺序性。</p><p><img src="https://img.hi-linux.com/staticfile/v2-1389722cbb68cad9a4673ca4f3d918d7_b-2021-06-25-1nAhaU.jpg" alt></p><p>通过更改 Pod 规范中的 <code>container.lifecycle.type</code> 将容器标记为 Sidecar 类型：<code>Sidecar</code>，默认为 <code>Standard</code>，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: bookings-v1-b54bc7c9c-v42f6</span><br><span class="line">  labels:</span><br><span class="line">    app: demoapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: bookings</span><br><span class="line">    image: banzaicloud&#x2F;allspark:0.1.1</span><br><span class="line">    ...</span><br><span class="line">  - name: istio-proxy</span><br><span class="line">    image: docker.io&#x2F;istio&#x2F;proxyv2:1.4.3</span><br><span class="line">    lifecycle:</span><br><span class="line">      type: Sidecar</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><h2><span id="init-容器">Init 容器</span></h2><p>在 Kubernetes 中，Init 容器是在同一 Pod 中的其他容器之前开始并执行的容器。它旨在为 Pod 上托管的主应用程序执行初始化逻辑。例如，创建必要的用户帐户，执行数据库迁移，创建数据库结构等。</p><p>Init 容器与普通的容器非常像，除了如下两点：</p><ul><li>它们总是运行到完成。</li><li>每个都必须在下一个启动之前成功完成。</li></ul><h3><span id="与普通容器的不同之处">与普通容器的不同之处</span></h3><p></p><ul><li>Init 容器支持应用容器的全部字段和特性，包括资源限制、数据卷和安全设置。 然而，Init 容器对资源请求和限制的处理稍有不同。</li><li>同时 Init 容器不支持 Readiness Probe，因为它们必须在 Pod 就绪之前运行完成。</li><li>如果为一个 Pod 指定了多个 Init 容器，这些容器会按顺序逐个运行。每个 Init 容器必须运行成功，下一个才能够运行。当所有的 Init 容器运行完成时，Kubernetes 才会为 Pod 初始化应用容器并像平常一样运行。</li></ul><h3><span id="init-容器作用">Init 容器作用</span></h3><p>因为 Init 容器具有与应用容器分离的单独镜像，其启动相关代码具有如下优势：</p><ul><li>Init 容器可以包含一些安装过程中应用容器中不存在的实用工具或个性化代码。例如，没有必要仅为了在安装过程中使用类似 sed、 awk、 python 或 dig 这样的工具而去FROM 一个镜像来生成一个新的镜像。</li><li>Init 容器可以安全地运行这些工具，避免这些工具导致应用镜像的安全性降低。</li><li>应用镜像的创建者和部署者可以各自独立工作，而没有必要联合构建一个单独的应用镜像。</li><li>Init 容器能以不同于Pod内应用容器的文件系统视图运行。因此，Init容器可具有访问 Secrets 的权限，而应用容器不能够访问。</li><li>由于 Init 容器必须在应用容器启动之前运行完成，因此 Init 容器提供了一种机制来阻塞或延迟应用容器的启动，直到满足了一组先决条件。一旦前置条件满足，Pod内的所有的应用容器会并行启动。</li></ul><h3><span id="创建-initcontainer-时应考虑一些注意事项">创建 InitContainer 时应考虑一些注意事项：</span></h3><ul><li>它们总是在 Pod 中的其他容器之前执行。因此，它们不应包含需要很长时间才能完成的复杂逻辑。启动脚本通常很小而简洁。如果发现要向初始化容器添加太多逻辑，则应考虑将其中的一部分移至应用程序容器本身。</li><li>初始化容器按顺序启动和执行。除非一个初始化容器被成功执行，否则下一个初始化容器不会被开始执行。因此，如果启动任务很长，则可以考虑将其分为多个步骤，每个步骤都由一个初始化容器处理，以便您知道哪些步骤失败。</li><li>如果任何初始化容器失败，则将重新启动整个 Pod（除非您将 restartPolicy 设置为 Never）。重新启动 Pod 意味着再次重新执行所有容器，包括任何初始化容器。因此，您可能需要确保启动逻辑允许多次执行而不会导致重复。例如，如果数据库迁移已经完成，则应仅忽略再次执行迁移命令。</li><li>初始化容器是延迟应用程序初始化直到一个或多个依赖项可用的很好的选择。例如，如果您的应用程序依赖于施加API请求速率限制的 API，则您可能需要等待一段时间才能接收来自该 API 的响应。在应用程序容器中实现此逻辑可能很复杂；因为它需要与健康和就绪状态探测器结合使用。一种更简单的方法是创建一个初始化容器，该容器要等到API准备好后才能成功退出。只有在初始化容器成功完成其工作之后，应用程序容器才会启动。</li><li>初始化容器不能像应用程序容器那样使用运行状况和就绪探针。原因是它们要成功启动和退出，就像 Jobs 和 CronJobs 的行为一样。</li><li>同一Pod 上的所有容器共享相同的卷和网络。您可以利用此功能在应用程序及其初始化容器之间共享数据。</li></ul><blockquote><p>正如我们刚刚讨论的那样，Init 容器总是比同一个 Pod 上的其他应用程序容器先启动。结果，调度程序对 Init 容器的资源和限制赋予了更高的优先级。必须仔细考虑这种行为，因为这可能会导致不良后果。例如，如果您有一个初始化容器和一个应用程序容器，并且将初始化容器的资源和限制设置为高于应用程序容器的资源和限制，那么只有在有一个可用节点满足初始化的情况下，才调度整个 Pod 容器要求。换句话说，即使有一个未使用的节点可以在其中运行应用程序容器，但如果初始化容器具有该节点可以处理的更高资源先决条件，则 Pod 也不会部署到该节点。因此，在定义初始化容器的请求和限制时，您应尽可能严格。最佳做法是，除非绝对必要，否则请勿将这些参数设置为高于应用程序容器的值。</p></blockquote><h3><span id="使用-init-容器">使用 Init 容器</span></h3><p>下面的例子定义了一个具有 2 个 Init 容器的简单 Pod。 第一个等待 myservice 启动，第二个等待 mydb 启动。 一旦这两个 Init容器 都启动完成，Pod 将启动 spec 区域中的应用容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: myapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp-container</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: init-myservice</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &quot;until nslookup myservice.$(cat &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done&quot;]</span><br><span class="line">  - name: init-mydb</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &quot;until nslookup mydb.$(cat &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done&quot;]</span><br></pre></td></tr></table></figure><p>这是 Kubernetes 1.6 版本的新语法，尽管老的 annotation 语法仍然可以使用。我们已经把 Init 容器的声明移到 spec 中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: myapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp-container</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: init-myservice</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#39;]</span><br><span class="line">  - name: init-mydb</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#39;]</span><br></pre></td></tr></table></figure><p>1.5 版本的语法在 1.6 版本仍然可以使用，但是我们推荐使用 1.6 版本的新语法。 在 Kubernetes 1.6 版本中，Init 容器在 API 中新建了一个字段。 虽然期望使用 beta 版本的 annotation，但在未来发行版将会被废弃掉。</p><p>在所有的 Init 容器没有成功之前，Pod 将不会变成 Ready 状态。 Init 容器的端口将不会在 Service 中进行聚集。 正在初始化中的 Pod 处于 Pending 状态，但应该会将条件 Initializing 设置为 true。</p><p>如果 Pod 重启，所有 Init 容器必须重新执行。</p><p>对 Init 容器 spec 的修改，被限制在容器 image 字段中。 更改 Init 容器的 image 字段，等价于重启该 Pod。</p><h3><span id="ephemeral-容器">Ephemeral 容器</span></h3><p>临时容器与其他容器的不同之处在于，它们缺少对资源或执行的保证，并且永远不会自动重启，因此不适用于构建应用程序。临时容器使用与常规容器相同的 <code>ContainerSpec</code> 段进行描述，但许多字段是不相容且不允许的。</p><ul><li>临时容器没有端口配置，因此像 <code>ports</code>，<code>livenessProbe</code>，<code>readinessProbe</code> 这样的字段是不允许的。</li><li>Pod 资源分配是不可变的，因此 <code>resources</code> 配置是不允许的。</li><li>有关允许字段的完整列表，请参见<a href="https://link.zhihu.com/?target=https%3A//kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/%23ephemeralcontainer-v1-core">临时容器参考文档</a>。</li></ul><p>临时容器是使用 API 中的一种特殊的 <code>ephemeralcontainers</code> 处理器进行创建的，而不是直接添加到 <code>pod.spec</code> 段，因此无法使用 <code>kubectl edit</code> 来添加一个临时容器。</p><p>与常规容器一样，将临时容器添加到 Pod 后，将不能更改或删除临时容器。</p><h3><span id="为什么我们需要-ephemeral-容器">为什么我们需要 Ephemeral 容器？</span></h3><p>我们知道容器的优点是它们通过使用不变方法提供所有必需的依赖项来运行隔离的进程。通过仅将所需的依赖项添加到镜像中，容器可以降低攻击面并提供更快的启动和部署。使用 “distroless” 方法构建容器镜像（基于 Scratch ），通过仅包含已编译的应用程序二进制文件，将容器镜像提升到了一个新的水平。与普通的容器镜像不同，它们不基于任何种类的 Linux 发行版，因此不包含任何其他可通过 <code>kubectl exec</code>  执行以进行故障排除的二进制文件和工具。这就决定了该容器有助于提供安全可靠的运行时环境，但也很难在问题发生时进行调试。</p><p>在这种情况下，临时容器发挥作用。它们实现了调试容器附加到主进程的功能，然后你可以用于调试任何类型的问题。调试容器可以基于任何镜像，因此可以根据您的需求进行定制。您可以构建自己的调试镜像，其中包含特殊的调试二进制文件或仅包含 curl，OpenSSL 和 MongoDB客户端之类的工具。但是，您也可以选择Linux发行版（如Ubuntu）或仅运行Busybox镜像，这两个镜像都已经包含了许多有用的工具。</p><h3><span id="如何使用临时容器">如何使用临时容器？</span></h3><p>临时容器是alpha功能，因此默认情况下处于禁用状态。您将需要激活以下功能门才能使用它们：</p><ul><li>临时容器</li><li>PodShareProcessNamespace（v1.16中的beta版，因此默认情况下已启用）</li></ul><p>本节中的示例演示了临时容器如何出现在 API 中。 通常，您可以使用 <code>kubectl</code> 插件进行故障排查，从而自动化执行这些步骤。</p><p>临时容器是使用 Pod 的 <code>ephemeralcontainers</code> 子资源创建的，可以使用 <code>kubectl --raw</code> 命令进行显示。首先描述临时容器被添加为一个 <code>EphemeralContainers</code> 列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">    &quot;kind&quot;: &quot;EphemeralContainers&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;example-pod&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;ephemeralContainers&quot;: [&#123;</span><br><span class="line">        &quot;command&quot;: [</span><br><span class="line">            &quot;sh&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;image&quot;: &quot;busybox&quot;,</span><br><span class="line">        &quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;,</span><br><span class="line">        &quot;name&quot;: &quot;debugger&quot;,</span><br><span class="line">        &quot;stdin&quot;: true,</span><br><span class="line">        &quot;tty&quot;: true,</span><br><span class="line">        &quot;terminationMessagePolicy&quot;: &quot;File&quot;</span><br><span class="line">    &#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用如下命令更新已运行的临时容器 <code>example-pod</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl replace --raw &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;example-pod&#x2F;ephemeralcontainers  -f ec.json</span><br></pre></td></tr></table></figure><p>这将返回临时容器的新列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;kind&quot;:&quot;EphemeralContainers&quot;,</span><br><span class="line">   &quot;apiVersion&quot;:&quot;v1&quot;,</span><br><span class="line">   &quot;metadata&quot;:&#123;</span><br><span class="line">      &quot;name&quot;:&quot;example-pod&quot;,</span><br><span class="line">      &quot;namespace&quot;:&quot;default&quot;,</span><br><span class="line">      &quot;selfLink&quot;:&quot;&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;example-pod&#x2F;ephemeralcontainers&quot;,</span><br><span class="line">      &quot;uid&quot;:&quot;a14a6d9b-62f2-4119-9d8e-e2ed6bc3a47c&quot;,</span><br><span class="line">      &quot;resourceVersion&quot;:&quot;15886&quot;,</span><br><span class="line">      &quot;creationTimestamp&quot;:&quot;2019-08-29T06:41:42Z&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;ephemeralContainers&quot;:[</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;name&quot;:&quot;debugger&quot;,</span><br><span class="line">         &quot;image&quot;:&quot;busybox&quot;,</span><br><span class="line">         &quot;command&quot;:[</span><br><span class="line">            &quot;sh&quot;</span><br><span class="line">         ],</span><br><span class="line">         &quot;resources&quot;:&#123;</span><br><span class="line"></span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;terminationMessagePolicy&quot;:&quot;File&quot;,</span><br><span class="line">         &quot;imagePullPolicy&quot;:&quot;IfNotPresent&quot;,</span><br><span class="line">         &quot;stdin&quot;:true,</span><br><span class="line">         &quot;tty&quot;:true</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以使用以下命令查看新创建的临时容器的状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod example-pod</span><br><span class="line">...</span><br><span class="line">Ephemeral Containers:</span><br><span class="line">  debugger:</span><br><span class="line">    Container ID:  docker:&#x2F;&#x2F;cf81908f149e7e9213d3c3644eda55c72efaff67652a2685c1146f0ce151e80f</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable:&#x2F;&#x2F;busybox@sha256:9f1003c480699be56815db0f8146ad2e22efea85129b5b5983d0e0fb52d9ab70</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sh</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Thu, 29 Aug 2019 06:42:21 +0000</span><br><span class="line">    Ready:          False</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:         &lt;none&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以使用以下命令连接到新的临时容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl attach -it example-pod -c debugger</span><br></pre></td></tr></table></figure><p>如果启用了进程命名空间共享，则可以查看该 Pod 所有容器中的进程。 例如，运行上述 <code>attach</code> 操作后，在调试器容器中运行 <code>ps</code> 操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在 &quot;debugger&quot; 临时容器内中运行此 shell 命令</span><br><span class="line">$ ps auxww</span><br></pre></td></tr></table></figure><p>运行命令后，输出类似于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 &#x2F;pause</span><br><span class="line">    6 root      0:00 nginx: master process nginx -g daemon off;</span><br><span class="line">   11 101       0:00 nginx: worker process</span><br><span class="line">   12 101       0:00 nginx: worker process</span><br><span class="line">   13 101       0:00 nginx: worker process</span><br><span class="line">   14 101       0:00 nginx: worker process</span><br><span class="line">   15 101       0:00 nginx: worker process</span><br><span class="line">   16 101       0:00 nginx: worker process</span><br><span class="line">   17 101       0:00 nginx: worker process</span><br><span class="line">   18 101       0:00 nginx: worker process</span><br><span class="line">   19 root      0:00 &#x2F;pause</span><br><span class="line">   24 root      0:00 sh</span><br><span class="line">   29 root      0:00 ps auxww</span><br></pre></td></tr></table></figure><h3><span id="总结">总结</span></h3><p>本文简单介绍了标准容器，Sidecar 容器，Init 容器，Ephemeral 容器 4 种类型的 Containers。随着 Kubernetes 日益普及，我们需要充分掌握这几种类型容器原理和使用方法，才能更好地服务业务。</p><p>此外 Sidecar 容器将会成为未来软件交付的一种新的方式，参照 Dapr 等，不同的团队提供自己的功能容器，然后选择性注入 Sidecar 到主业务容器，实现解耦。</p><h2><span id="参考文档">参考文档</span></h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://zhuanlan.zhihu.com/p/145233597" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/145233597</a></li><li><a href="https://cloud.tencent.com/developer/article/1645954" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1645954</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;p&gt;截止目前 Kubernetes 1.18，Kubernetes 已经支持标准容器，Sidecar 容器，Init 容器，Ephemeral 容器 4 种类型的 Containers。本文我们详细介绍一下这 4
        
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>超赞，腾讯开源运维必备海量服务器管理系统！</title>
    <link href="https://www.hi-linux.com/posts/4224.html"/>
    <id>https://www.hi-linux.com/posts/4224.html</id>
    <published>2021-07-27T01:00:00.000Z</published>
    <updated>2021-07-28T01:17:17.351Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天推荐的这个项目是「bk-job」—— 蓝鲸作业平台 (Job)，一套腾讯开源的运维脚本管理系统，具备海量任务并发处理能力。</p><p>除了支持脚本执行、文件分发、定时任务等一系列基础运维场景以外，还支持通过流程调度能力将零碎的单个任务组装成一个自动化作业流程；</p><p>而每个作业都可做为一个原子节点，提供给上层或周边系统/平台使用，实现跨系统调度自动化。</p><a id="more"></a><h2><span id="优势">优势</span></h2><ul><li><p>安全可靠的高危命令检测能力</p></li><li><p>完善的脚本版本管理</p></li><li><p>作业编排，一切皆场景</p></li><li><p>原汁原味的 Cron 定时任务</p></li><li><p>高扩展性的文件源管理能力</p></li></ul><p><code>bk-job</code> 提供了快速执行、任务编排、定时执行等核心服务，多重组合，满足企业不同场景的需求：</p><ul><li><p>快速执行：提供临时性且多变的快速一次性操作入口，用完即走</p></li><li><p>任务编排：对于重复性的操作组合，可以通过编排功能将其沉淀为 “作业”，方便管理和使用</p></li><li><p>定时执行：支持用户按业务逻辑诉求设置周期性或一次性的定期执行计划</p></li><li><p>脚本管理：将脚本以云化模式统一管理，更好的支持作业编排和周边系统调度的灵活度</p></li><li><p>账号管理：管理服务器 OS 的执行账户，如 Linux 的 root，Windows 的 administrator 等等</p></li><li><p>消息通知：满足业务按管理需求设置任务不同状态的执行结果消息通知</p></li><li><p>文件源管理：开放文件源对接插件能力，满足从不同文件系统类型拉取文件并传输的诉求</p></li><li><p>运营分析：提供平台的运营统计数据展示，助力管理员更全方位的了解平台的运行情况</p></li><li><p>平台管理：丰富的平台管理员工具，包括但不仅限于信息更改、消息渠道设置、高危语句检测规则、功能限制设置、公共脚本管理、后台服务状态展示等等</p></li></ul><h2><span id="架构设计">架构设计</span></h2><p><img src="https://img.hi-linux.com/staticfile/architecture-2021-07-15-b41cpq.png" alt></p><p>更多项目详情请查看项目地址：<a href="https://github.com/Tencent/bk-job" target="_blank" rel="noopener">https://github.com/Tencent/bk-job</a></p><blockquote><p>本文转载自：「 GitHub 精选 」，原文：<a href="https://tinyurl.com/6cudv978%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/6cudv978，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天推荐的这个项目是「bk-job」—— 蓝鲸作业平台 (Job)，一套腾讯开源的运维脚本管理系统，具备海量任务并发处理能力。&lt;/p&gt;
&lt;p&gt;除了支持脚本执行、文件分发、定时任务等一系列基础运维场景以外，还支持通过流程调度能力将零碎的单个任务组装成一个自动化作业流程；&lt;/p&gt;
&lt;p&gt;而每个作业都可做为一个原子节点，提供给上层或周边系统/平台使用，实现跨系统调度自动化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="开源" scheme="https://www.hi-linux.com/categories/%E5%BC%80%E6%BA%90/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="腾迅" scheme="https://www.hi-linux.com/tags/%E8%85%BE%E8%BF%85/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>微软开源自有云服务器专属 Linux 发行版 CBL-Mariner，可在 GitHub 免费下载！</title>
    <link href="https://www.hi-linux.com/posts/9114.html"/>
    <id>https://www.hi-linux.com/posts/9114.html</id>
    <published>2021-07-23T01:00:00.000Z</published>
    <updated>2021-07-23T07:43:18.687Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>近年来，微软对 Linux 的爱越来越多，这已经不是什么秘密了–看看 Windows Subsystem for Linux 就是一个例子。尽管如此，在得知微软还有自己的 Linux 发行版时，你还是可能会感到惊讶。</p></blockquote><p>微软近日开源了一款内部使用的 Linux 发行版——CBL-Mariner（CBL 即 Common Base Linux）。CBL-Mariner 不是桌面 Linux 而是服务器端 Linux，它被用于微软的云基础设施以及边缘产品和服务。CBL-Mariner 旨在为这些设备和服务提供一个一致的平台，并增强微软在 Linux 更新方面与时俱进的能力。</p><p><img src="https://img.hi-linux.com/staticfile/maxresdefault-2021-07-22-yRdZjc.jpg" alt></p><p>CBL-Mariner 的设计理念是通过提供一组小的通用核心软件包来满足云和边缘服务的普遍需求，同时允许各团队在通用核心之上根据需要引入额外的软件包。它是轻量级的发行版，只消耗非常小的磁盘和内存资源，可作为容器或容器主机使用。</p><p>CBL-Mariner 遵循 “默认安全(secure-by-default)” 原则，操作系统的大多数方面都以安全为重点。它包含加固内核、签名更新、ASLR、基于编译器的加固和防篡改日志等众多功能。所有 CBL-Mariner 安全功能都已罗列在 GitHub Repo 中。</p><p><strong>CBL-Mariner 软件包系统是基于 RPM 的，软件包更新系统同时使用 dnf 和 tdnf，后者全称 Tiny DNF，是一个基于 dnf 的软件包管理器，来自 VMware 的 Photon OS。</strong></p><p>CBL-Mariner 还支持基于镜像的更新机制，其使用 RPM-OSTree 来实现，rpm-ostree 是一个基于OSTree 的开源工具，用于管理可启动的、不可变的、版本化的文件系统树。rpm-ostree 背后的想法是使用一个客户-服务器架构，以可靠的方式保持 Linux 主机的更新和与最新的软件包同步。</p><p>微软表示，开源 CBL-Mariner Linux 发行版是他们对广泛的 Linux 技术不断增加投资的一部分，就如同此前的 SONiC, Azure Sphere OS 和 Windows Subsystem for Linux (WSL) 等项目。此外这也是微软对开源承诺的兑现，以及对 Linux 社区的回馈。微软还表示，CBL-Mariner 不会改变他们对任何现有第三方 Linux 发行版的态度或承诺。</p><blockquote><p>项目地址：<a href="https://github.com/microsoft/CBL-Mariner" target="_blank" rel="noopener">https://github.com/microsoft/CBL-Mariner</a></p></blockquote><p>根据微软 Azure 团队成员 Juan Manuel Rey 的介绍，CBL-Mariner 由 WSL2 团队创造，但目前没有提供 ISO 镜像，需要自己进行构建。</p><p><img src="https://img.hi-linux.com/staticfile/8f06c7d5-3d30-40d4-b611-270fd3cc8cd0-2021-07-22-S9ksIe.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/22f55ae0-d3ae-4488-b4ab-89536a8623f2-2021-07-22-9D2rI6.png" alt></p><p>详细教程可参考：</p><blockquote><ol><li><a href="https://linuxiac.com/microsoft-cbl-mariner-linux-1/" target="_blank" rel="noopener">https://linuxiac.com/microsoft-cbl-mariner-linux-1/</a></li><li><a href="https://blog.jreypo.io/2021/07/09/a-look-into-cbl-mariner-microsoft-internal-linux-distribution/" target="_blank" rel="noopener">https://blog.jreypo.io/2021/07/09/a-look-into-cbl-mariner-microsoft-internal-linux-distribution/</a></li></ol></blockquote><p>如果你觉得上面的英文文档看起来比较费劲，也可以看看下面这篇中文文档：</p><blockquote><ol><li><a href="https://blog.csdn.net/aw77520/article/details/118958510" target="_blank" rel="noopener">https://blog.csdn.net/aw77520/article/details/118958510</a></li></ol></blockquote><p><strong>参考文档</strong></p><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://mp.weixin.qq.com/s/1d7tP_kKfXHrmqKYeyxyKA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/1d7tP_kKfXHrmqKYeyxyKA</a></li><li><a href="https://www.cnbeta.com/articles/tech/1152045.htm" target="_blank" rel="noopener">https://www.cnbeta.com/articles/tech/1152045.htm</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;近年来，微软对 Linux 的爱越来越多，这已经不是什么秘密了–看看 Windows Subsystem for Linux 就是一个例子。尽管如此，在得知微软还有自己的 Linux
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微软" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E8%BD%AF/"/>
    
      <category term="CBL-Mariner" scheme="https://www.hi-linux.com/tags/CBL-Mariner/"/>
    
  </entry>
  
  <entry>
    <title>两个 Docker 使用神技，99% 的人都不知道！</title>
    <link href="https://www.hi-linux.com/posts/47156.html"/>
    <id>https://www.hi-linux.com/posts/47156.html</id>
    <published>2021-07-22T01:00:00.000Z</published>
    <updated>2021-07-22T01:38:22.462Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近发现两个非常好用的工具，一个是 <code>runlike</code>，一个是 <code>whaler</code></p><ul><li><p><code>runlike</code>：通过容器打印出容器的启动命令</p></li><li><p><code>whaler</code>：通过镜像导出<code>dockerfile</code></p></li></ul><p>听起来是不是想说 <code>N...B...</code> 哈哈，那就走起？</p><a id="more"></a><h2><span id="找回-docker-容器运行的命令">找回 Docker 容器运行的命令</span></h2><p>平时可能因为测试或者一些规范的操作方式导致启动一个容器，忘记了这个容器的启动命令是什么了，又需要找回来在别的机器上创建的时候，就很麻烦，可能很多人会想到通过 <code>docker inspect</code> 分析输出的 json 文件中的<code>volume</code>、<code>ports</code>、<code>Env</code>等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect $container_name</span><br></pre></td></tr></table></figure><p>这个命令应该是很熟悉的，查看容器的基本信息。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712102727538-2021-07-12-TYza77.jpg" alt></p><p>虽然这样也能找到运行容器的命令，但是依旧还需要时间去整理，因此这里分享一个可以直接打印运行命令的工具<strong>runlike</strong>[1]，在runlike传递一个容器名称，就会直接打印出该容器的运行命令。<code>runlike</code>使用起来非常方便，可以直接通过<code>pip</code>安装，也可以通过容器方式免安装使用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># pip</span><br><span class="line">$ pip install runlike</span><br><span class="line"># by docker</span><br><span class="line">$ alias runlike&#x3D;&quot;docker run --rm -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock assaflavie&#x2F;runlike&quot;</span><br></pre></td></tr></table></figure><p>下面还是通过上面那个容器测试一下是否可以:</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712101519855-2021-07-12-8zSm4J.jpg" alt></p><p>这样使用起来就方便很多了。关于 <code>runlike</code> 一些其他的选项，可以直接通过<code>--help</code>学习。</p><h2><span id="从镜像导出dockerfile">从镜像导出Dockerfile</span></h2><p>平时可能会构建很多不同的镜像，比如维护一些基础Docker镜像、想查看一些公开仓库的Docker镜像是怎么构建的，或因为长时间不维护找不到当时构建镜像的 Dockerfile，或者因为网络无法查看时，能从镜像导出Dockerfile就显得很重要，这里可以通过 <strong>whaler</strong>[2] 来快速的导出. 这里我们依旧不安装，通过容器化的方式使用dfimage命令，便于使用，我们将该命令写成命令别名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># alias export docker image to dockerfile</span><br><span class="line">$ alias whaler&#x3D;&quot;docker run -t --rm -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock:ro pegleg&#x2F;whaler&quot;</span><br></pre></td></tr></table></figure><p>然后通过<code>whaler</code>命令输出 <code>pegleg/whaler</code> 镜像的dockerfile文件:</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712102326684-2021-07-12-58iXFO.jpg" alt></p><p>这样就输出<code>pegleg/whaler</code>这个镜像的 Dockerfile 大致的内容了，还是彩色的输出呢？哈哈，有心了。从上图可以看到输出的 Dockerfile 也与<code>平常写的不太一样</code>，可以在 Github 上看下仓库内的 Dockerfile 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">FROM golang:1.14.4 AS builder</span><br><span class="line">WORKDIR $GOPATH</span><br><span class="line">RUN go get -u github.com&#x2F;P3GLEG&#x2F;Whaler</span><br><span class="line">WORKDIR $GOPATH&#x2F;src&#x2F;github.com&#x2F;P3GLEG&#x2F;Whaler</span><br><span class="line">RUN export CGO_ENABLED&#x3D;0 &amp;&amp; go build .</span><br><span class="line">RUN cp Whaler &#x2F;root&#x2F;Whaler</span><br><span class="line"></span><br><span class="line">FROM alpine:3.12.0</span><br><span class="line">WORKDIR &#x2F;root&#x2F;</span><br><span class="line">COPY --from&#x3D;builder &#x2F;root&#x2F;Whaler .</span><br><span class="line">ENTRYPOINT [&quot;.&#x2F;Whaler&quot;]</span><br></pre></td></tr></table></figure><p>由 Dockerfile 来看，这个 <code>whaler</code> 采用的多阶段构建，所以无法输出 <code>--from=builder</code> 的构建内容，这个锅 <code>whaler</code> 不背，我们可以换一个镜像看看：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210712102331953-2021-07-12-0wmUwI.jpg" alt></p><p>这个就显示的很自然，很有熟悉的味道了。<code>whaler</code> 支持同时分析多个镜像等等功能，这里就不在说了，感兴趣的可以自己看一下。至于 <code>whaler</code> 是怎么实现的，其实看一下源码就明白了。</p><blockquote><p>本文转载自：「 云原生生态圈 」，原文：<a href="https://tinyurl.com/wbm4x5aw" target="_blank" rel="noopener">https://tinyurl.com/wbm4x5aw</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近发现两个非常好用的工具，一个是 &lt;code&gt;runlike&lt;/code&gt;，一个是 &lt;code&gt;whaler&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;runlike&lt;/code&gt;：通过容器打印出容器的启动命令&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;whaler&lt;/code&gt;：通过镜像导出&lt;code&gt;dockerfile&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;听起来是不是想说 &lt;code&gt;N...B...&lt;/code&gt; 哈哈，那就走起？&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
</feed>
