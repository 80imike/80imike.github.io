<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>奇妙的 Linux 世界</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2021-07-21T02:09:49.990Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何优雅的在 Linux 下开机自动重启脚本</title>
    <link href="https://www.hi-linux.com/posts/36782.html"/>
    <id>https://www.hi-linux.com/posts/36782.html</id>
    <published>2021-07-21T01:00:00.000Z</published>
    <updated>2021-07-21T02:09:49.990Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="简介">简介</span></h2><p>经常碰到机器断电之后需要重启一大堆服务，为了防止这种事情发生，设置开机自启的脚本十分的重要，我们习惯性的做法就是编写一个重启脚本，然后在 <code>/etc/rc.local</code> 中去完成开机执行。例如下面这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;etc&#x2F;rc.local</span><br><span class="line">bash &#x2F;root&#x2F;script&#x2F;restart.sh</span><br></pre></td></tr></table></figure><p>这样的方法虽然可行，但并不优雅。今天我们就给大家介绍两种更好的实现方式：</p><h2><span id="通过-crontab-实现">通过 Crontab 实现</span></h2><p>Crontab 可以使用 <code>@reboot</code> 来执行主机启动之后的命令。首先在命令行输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br></pre></td></tr></table></figure><p>然后添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@reboot &#x2F;root&#x2F;script&#x2F;restart.sh</span><br></pre></td></tr></table></figure><p>完成后，这个脚本就可以在重启的时候自动执行了。其它的一些进阶玩法：</p><ul><li>在启动完成后的指定时间内运行脚本</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在启动 5 分钟后运行指定脚本</span><br><span class="line">@reboot sleep 300 &amp;&amp; &#x2F;home&#x2F;wwwjobs&#x2F;clean-static-cache.sh</span><br></pre></td></tr></table></figure><h2><span id="通过-systemd-实现">通过 Systemd 实现</span></h2><p>首先编写一个名为 restart 的 Systemd 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ vim &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;restart.service</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;restart</span><br><span class="line">After&#x3D;default.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart&#x3D;&#x2F;root&#x2F;script&#x2F;restart.sh</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;default.target</span><br></pre></td></tr></table></figure><p>然后启用这个 Systemd 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl enable restart.service</span><br></pre></td></tr></table></figure><p>完成后，这个服务对应的脚本就可以自动开机自启了。</p><h2><span id="参考文档">参考文档</span></h2><ul><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://tinyurl.com/6ryafefw" target="_blank" rel="noopener">https://tinyurl.com/6ryafefw</a></li><li><a href="https://www.cyberciti.biz/faq/linux-execute-cron-job-after-system-reboot/" target="_blank" rel="noopener">https://www.cyberciti.biz/faq/linux-execute-cron-job-after-system-reboot/</a></li></ul></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;div id=&quot;vip-container&quot;&gt;&lt;h2&gt;&lt;span id=&quot;简介&quot;&gt;简介&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;经常碰到机器断电之后需要重启一大堆服务，为了防止这种事情发生，设置开机自启的脚本十分的重要，我们习惯性的做法就是编写一个重启脚本，然后在
        
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款面向开发者友好的 Kubernetes 持续交付工作流管理软件 Devtron</title>
    <link href="https://www.hi-linux.com/posts/45793.html"/>
    <id>https://www.hi-linux.com/posts/45793.html</id>
    <published>2021-07-15T01:00:00.000Z</published>
    <updated>2021-07-15T08:28:23.181Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Devtron(<a href="https://devtron.ai" target="_blank" rel="noopener">https://devtron.ai</a>) 是用 go 编写的用于 Kubernetes 交付工作流管理的开源软件。它被设计为一个自我服务平台，以开发者友好的方式在 Kubernetes 上运维和维护应用程序（AppOps）。</p><blockquote><p>仓库地址：<a href="https://github.com/devtron-labs/devtron" target="_blank" rel="noopener">https://github.com/devtron-labs/devtron</a></p></blockquote><a id="more"></a><h2><span id="特性">🎉 特性</span></h2><ul><li><p>零代码软件交付工作流</p><ul><li>了解 kubernetes、测试、CD、SecOps 等领域的工作流，这样你就不必写脚本。</li><li>可重复使用和可组合的组件，使工作流易于构建使用。</li></ul></li><li><p>多云部署</p><ul><li>天然支持部署到多个 kubernetes 集群上</li></ul></li><li><p>轻松实现开发-安全-运维一体化</p><ul><li>全局、集群、环境和应用的多层次安全策略，实现高效的分层策略管理</li><li>行为驱动的安全策略</li><li>kubernetes 资源定义策略和异常情况</li><li>定义事件的策略，以便更快地解决问题</li></ul></li><li><p>应用程序调试面板</p><ul><li>所有历史的 kubernetes 事件都集中在一个地方</li><li>安全地访问所有清单，如 secret、configmap</li><li>cpu、ram、http 状态码和延迟等应用指标，并进行新旧对比</li><li>使用 grep 和 json 搜索日志</li><li>事件和日志之间的智能关联性</li></ul></li><li><p>企业级的安全性和合规性</p><ul><li>细粒度的访问控制；控制谁可以编辑配置，谁可以部署</li><li>审计日志，了解谁做了什么，什么时候做的</li><li>所有 CI 和 CD 事件的历史记录</li><li>影响应用程序的 Kubernetes 事件</li><li>相关的云事件及其对应用程序的影响</li><li>先进的工作流程策略，如分支环境，确保构建和部署管道的安全</li></ul></li><li><p>了解 Gitops</p><ul><li>通过 API 和 UI 暴露的 Gitops，使你不必与 Git 客户端交互</li><li>由 postgres 支持的 Gitops 更容易分析</li><li>实施比 git 更精细的访问控制</li></ul></li><li><p>业务洞察</p><ul><li>部署指标来衡量敏捷过程的成功，它可以捕捉到 mttr、变更失败率、部署频率、部署规模等。</li><li>审计日志以了解失败的原因</li><li>监测跨部署的变化，并轻松恢复</li></ul></li></ul><h2><span id="安装">🚀 安装</span></h2><p>默认的安装配置会使用 MinIO 来存储构建日志和缓存，可以直接使用下面的命令进行安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add devtron https:&#x2F;&#x2F;helm.devtron.ai</span><br><span class="line">$ helm install devtron devtron&#x2F;devtron-operator --create-namespace --namespace devtroncd \</span><br><span class="line">--set secrets.POSTGRESQL_PASSWORD&#x3D;change-me</span><br></pre></td></tr></table></figure><p>但是官方的安装方式会从 GitHub 上面去下载很多脚本进行初始化，由于某些原因，可能我们没办法正常访问，这里我已经将所有的安装脚本和代码同步到了 <code>gitee</code> 上面，不用担心安装不上了。</p><p>首先 clone 安装脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;gitee.com&#x2F;cnych&#x2F;devtron-installation-script.git</span><br><span class="line">$ cd devtron-installation-script</span><br></pre></td></tr></table></figure><p>这里我们使用 Helm3 来进行安装，我们只需要安装 <code>devtron-operator</code> 即可帮我们自动安装 devtron 了，命令如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ helm upgrade --install devtron .&#x2F;charts&#x2F;devtron --create-namespace --namespace devtroncd</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: &#x2F;Users&#x2F;ych&#x2F;.kube&#x2F;config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: &#x2F;Users&#x2F;ych&#x2F;.kube&#x2F;config</span><br><span class="line">W0624 11:00:57.798698 56125 warnings.go:67] apiextensions.k8s.io&#x2F;v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io&#x2F;v1 CustomResourceDefinition</span><br><span class="line">W0624 11:00:59.829583 56125 warnings.go:67] apiextensions.k8s.io&#x2F;v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io&#x2F;v1 CustomResourceDefinition</span><br><span class="line">NAME: devtron</span><br><span class="line">LAST DEPLOYED: Thu Jun 24 11:01:00 2021</span><br><span class="line">NAMESPACE: devtroncd</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line"></span><br><span class="line">1. Run the following command to get the default admin password. Default username is admin</span><br><span class="line"></span><br><span class="line">   kubectl -n devtroncd get secret devtron-secret -o jsonpath&#x3D;&#39;&#123;.data.ACD_PASSWORD&#125;&#39; | base64 -d</span><br><span class="line"></span><br><span class="line">2. You can watch the progress of Devtron microservices installation by the following command</span><br><span class="line"></span><br><span class="line">   kubectl -n devtroncd get installers installer-devtron -o jsonpath&#x3D;&#39;&#123;.status.sync.status&#125;&#39;</span><br></pre></td></tr></table></figure><p>上面的命令会帮我们创建一个用于安装 devtron 的 Pod，该 Pod 会去读取我们的 <code>installaction-script</code> 脚本进行初始化安装，这个安装过程需要花一点时间，不过需要注意的是需要提供一个默认的 StorageClass，否则 MinIO 对应的 PVC 没办法绑定，也就安装不成功了，我这里是在代码仓库中明确指定的一个名为 <code>nfs-storage</code> 的 StorageClass，正常安装后会产生很多 Pod：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113548589-2021-06-30-Zl4ugu.jpg" alt="devtron pods"></p><p>为了访问方便我这里还创建了一个 IngressRoute 对象用来绑定 Dashboard：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># devtron-ingressroute.yaml</span><br><span class="line">apiVersion: traefik.containo.us&#x2F;v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: devtron</span><br><span class="line">  namespace: devtroncd</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - web</span><br><span class="line">  routes:</span><br><span class="line">    - kind: Rule</span><br><span class="line">      match: Host(&#96;devtron.k8s.local&#96;)</span><br><span class="line">      services:</span><br><span class="line">        - name: devtron-service</span><br><span class="line">          port: 80</span><br></pre></td></tr></table></figure><p>创建完成后我们就可以通过域名（提前做好解析）就可以访问 devtron 了。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630130148000-2021-06-30-tQSDbk.jpg" alt="login devtron"></p><p>登录的时候使用的默认用户名为 <code>admin</code>，密码则可以使用上面安装 Helm Charts 的时候的提示命令获取:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n devtroncd get secret devtron-secret -o jsonpath&#x3D;&#39;&#123;.data.ACD_PASSWORD&#125;&#39; | base64 -d</span><br></pre></td></tr></table></figure><p>登录后就可以进入到 Dashboard 的主页了：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113548607-2021-06-30-W9dUld.jpg" alt></p><p>进入 Dashboard 后我们还需要做一些配置才能使用，比如添加 Docker 镜像仓库、配置 gitops 等。具体使用方法可以参考官方文档说明 <a href="https://docs.devtron.ai" target="_blank" rel="noopener">https://docs.devtron.ai</a>，后续我们再提供一个详细的使用文档。</p><blockquote><p>本文转载自：「 Github爱好者 」，原文：<a href="https://tinyurl.com/4y93htj9" target="_blank" rel="noopener">https://tinyurl.com/4y93htj9</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Devtron(&lt;a href=&quot;https://devtron.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://devtron.ai&lt;/a&gt;) 是用 go 编写的用于 Kubernetes 交付工作流管理的开源软件。它被设计为一个自我服务平台，以开发者友好的方式在 Kubernetes 上运维和维护应用程序（AppOps）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;仓库地址：&lt;a href=&quot;https://github.com/devtron-labs/devtron&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/devtron-labs/devtron&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Devtron" scheme="https://www.hi-linux.com/tags/Devtron/"/>
    
  </entry>
  
  <entry>
    <title>GitHub 访问慢？手把手教你几招解决它！</title>
    <link href="https://www.hi-linux.com/posts/50785.html"/>
    <id>https://www.hi-linux.com/posts/50785.html</id>
    <published>2021-07-12T01:00:00.000Z</published>
    <updated>2021-07-13T03:08:10.355Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>由于众所周知的原因，在国内的网络环境下，访问 Github 时，网络会阻断或者很慢。本文提供了若干访问方法。</p></blockquote><h2><span id="1-使用-github-mirror-下载">1. 使用 Github Mirror 下载</span></h2><p>直接在 GitHub 仓库前面拼接 Proxy 地址，不同的 Mirror 拼接方式可能有所不同。下面以拉取 <a href="https://github.com/shaowenchen/scripts" target="_blank" rel="noopener">https://github.com/shaowenchen/scripts</a> 仓库为例。</p><ul><li><a href="https://mirror.ghproxy.com/" target="_blank" rel="noopener">https://mirror.ghproxy.com</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;mirror.ghproxy.com&#x2F;https:&#x2F;&#x2F;github.com&#x2F;shaowenchen&#x2F;scripts</span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com.cnpmjs.org/" target="_blank" rel="noopener">https://github.com.cnpmjs.org</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com.cnpmjs.org&#x2F;shaowenchen&#x2F;scripts</span><br></pre></td></tr></table></figure><a id="more"></a><h2><span id="2-通过-gitee-导入-github-项目">2. 通过 Gitee 导入 GitHub 项目</span></h2><p>可以参考文档: <a href="https://gitee.com/help/articles/4284" target="_blank" rel="noopener">GitHub仓库快速导入Gitee及同步更新</a>, 将 GitHub 仓库导入 Gitee。然后使用 Gitee 的地址拉取代码。</p><blockquote><p>文档链接：<a href="https://gitee.com/help/articles/4284" target="_blank" rel="noopener">https://gitee.com/help/articles/4284</a></p></blockquote><h2><span id="3-配置-github-host-地址">3. 配置 Github Host 地址</span></h2><p>打开 <a href="https://www.ipaddress.com/" target="_blank" rel="noopener">https://www.ipaddress.com/</a> 查询 <a href="https://github.com.ipaddress.com/" target="_blank" rel="noopener">github.com</a> 的 IP 地址</p><p>编辑本地 /etc/hosts 文件，添加如下内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">140.82.112.4 github.com</span><br></pre></td></tr></table></figure><p>或者直接使用开源项目 GitHub520 获取最新的 IP 地址。</p><blockquote><p>项目地址：<a href="https://github.com/521xueweihan/GitHub520" target="_blank" rel="noopener">https://github.com/521xueweihan/GitHub520</a></p></blockquote><p>接着就可以拉取代码了，但是速度并不会很快，因为 Github 用的是美国 IP。</p><h2><span id="4-配置命令行代理">4. 配置命令行代理</span></h2><p>如果有可用的代理服务，那么在本地 Terminal 中配置代理即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Proxy</span><br><span class="line">function proxy_off()&#123;</span><br><span class="line">    unset http_proxy</span><br><span class="line">    unset HTTP_PROXY</span><br><span class="line">    unset https_proxy</span><br><span class="line">    unset HTTPS_PROXY</span><br><span class="line">    echo -e &quot;已关闭代理&quot;</span><br><span class="line">&#125;</span><br><span class="line">function proxy_on()&#123;</span><br><span class="line">    export http_proxy&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    export HTTP_PROXY&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    export https_proxy&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    export HTTPS_PROXY&#x3D;&quot;http:&#x2F;&#x2F;127.0.0.1:1087&quot;;</span><br><span class="line">    echo -e &quot;已开启代理&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「陈少文的网站」，原文：<a href="https://tinyurl.com/4tubycn9" target="_blank" rel="noopener">https://tinyurl.com/4tubycn9</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;由于众所周知的原因，在国内的网络环境下，访问 Github 时，网络会阻断或者很慢。本文提供了若干访问方法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-使用-Github-Mirror-下载&quot;&gt;1. 使用 Github Mirror 下载&lt;/h2&gt;
&lt;p&gt;直接在 GitHub 仓库前面拼接 Proxy 地址，不同的 Mirror 拼接方式可能有所不同。下面以拉取 &lt;a href=&quot;https://github.com/shaowenchen/scripts&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/shaowenchen/scripts&lt;/a&gt; 仓库为例。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://mirror.ghproxy.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mirror.ghproxy.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git clone https:&amp;#x2F;&amp;#x2F;mirror.ghproxy.com&amp;#x2F;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;shaowenchen&amp;#x2F;scripts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com.cnpmjs.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com.cnpmjs.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git clone https:&amp;#x2F;&amp;#x2F;github.com.cnpmjs.org&amp;#x2F;shaowenchen&amp;#x2F;scripts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/categories/WireGuard/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>Wintun：一款惊艳的 WireGuard 虚拟网卡接口驱动</title>
    <link href="https://www.hi-linux.com/posts/42946.html"/>
    <id>https://www.hi-linux.com/posts/42946.html</id>
    <published>2021-07-07T01:00:00.000Z</published>
    <updated>2021-07-08T08:13:31.352Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>前一段时间，一直在找寻 Windows 操作系统上的虚拟网卡接口，主要是为了搭建隧道使用。但是 Windows 操作系统不像 Linux 操作系统，它的代码不开源，导致这方面的资料很少，因此花费了较长时间来寻找相关实现框架，最终找到了两款开源项目的虚拟接口驱动：</p><ul><li>Wireguard 项目的 Wintun 接口[1]</li><li>OpenVPN 的 Tap 接口[2]</li></ul><p>这两个项目都是非常出名的搭建隧道的开源 V.P.N 项目。由于目前对 openVPN 项目不太了解，也没有适配 Tap 接口，因此这里重点介绍下 WinTun 接口。此接口实现我是非常非常的喜欢，喜欢到简直不要不要的。</p><a id="more"></a><h2><span id="简介">简介</span></h2><p>说到 Wintun 项目，就不得不说到它的父亲：WireGuard 项目（以下简称 WG）。<strong>Github 传送门</strong>[3]</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113612450-2021-06-30-Tfcrxr.png" alt></p><p>WG 项目作为开源 V.P.N 项目，不同于 OpenVPN, Openswan, Strongswan 等，它的实现非常简介，Linux 内核代码实现不到 4000 行。相对于上述的三个 “按行收费” 的项目（代码 10 万行起步），它简直是太简洁了。故而得到了众多好评，其中就包括 Linux 鼻祖：Linus Torvalds。他的评价如下：</p><blockquote><p>Btw, on an unrelated issue: I see that Jason actually made the pull request to have wireguard included in the kernel.</p><p>Can I just once again state my love for it and hope it gets merged soon? Maybe the code isn’t perfect, but I’ve skimmed it, and compared to the horrors that are OpenVPN and IPSec, it’s a work of art.</p><p>Linus</p></blockquote><p>简而言之就是：<strong>劳资稀罕你，要把你合入我的 Linux 项目中</strong>。因此 Linux 内核自 5.6 之后便自带 WG 隧道功能，配置非常的简单。通过几行代码便可以完成一个 WG 隧道：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip link add dev wg0 type wireguard</span><br><span class="line">$ ip address add dev wg0 10.0.0.1&#x2F;24</span><br><span class="line">$ wg set wg0 listen-port 51820 private-key .&#x2F;private.key peer NIk5TyDpRDoU9tfIckTTXCsz1eht2aEmdN7l0Q31ow0&#x3D; allowed-ips 10.0.0.2&#x2F;32 endpoint 192.168.1.5:51820</span><br><span class="line">$ ip link set dev wg0 up</span><br></pre></td></tr></table></figure><p>配置非常简单。除此之外，还提供了 Windows 客户端，这也是此项目为何包含 Wintun 虚拟网络接口的原因。</p><p>客户端页面也是非常简洁，没有多余的东西 (<strong>客户端链接</strong>[4])：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113622279-2021-06-30-pTYDow.png" alt></p><p>客户端上隧道协商成功之后，会根据隧道名称建立一个虚拟网卡，隧道拆除后接口自动删除。由于我的隧道名称为 Tun-1，因此在 “控制版面” 的“网络连接”中出现了一个 Tun-1 的网络接口：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113627967-2021-06-30-a6Sb0B.png" alt></p><p>好了，下面开始介绍此虚拟网络接口。</p><h2><span id="wintun-虚拟网络接口">WinTun 虚拟网络接口</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-20210630113633922-2021-06-30-rnV9d1.png" alt></p><ul><li><p><strong>Github 传送门</strong>[5]</p></li><li><p><strong>wintun 官网传送门</strong>[6]</p></li></ul><p>常见的 <strong>windwos 的接口驱动开发</strong>[7]、安装比较复杂。常见的驱动安装包有：.inf 文件、.sys 文件、.cat 文件; 除此之外还涉及驱动程序签名，否则无法安装成功。尤其在开发调试阶段，每次都得签名，太磨叽了。</p><p>但是 WinTun 接口用法<strong>非常简单高效</strong>。<strong>非常简单高效</strong>。<strong>非常简单高效</strong>。</p><blockquote><ol><li>引入头文件：wintun.h</li><li>加载动态库，解析动态库中的函数指针</li></ol></blockquote><p>它通过<strong>动态库</strong>中方式来提供接口，我们可以加载此动态库，然后调用动态库中的函数指针来完成虚拟接口的创建、销毁、收发数据包等工作。此外<strong>它提供了一个示例供大家学习</strong>[8]，我便是通过参考开源代码中的示例（example.c），将 Wintun 接口移植到我的工程之中。非常简单，我太喜欢它了。</p><p>实例代码就 400 行，其中大部分为 log 信息，供大家查看程序运行状态和报文收发信息。</p><h3><span id="加载动态库中的函数指针">加载动态库中的函数指针</span></h3><p>此函数的作用：</p><ul><li><strong>加载动态库，获取到动态库中的函数指针，后面通过函数指针来操作虚拟网卡接口。</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">static HMODULE</span><br><span class="line">InitializeWintun(void)</span><br><span class="line">&#123;</span><br><span class="line">    HMODULE Wintun &#x3D;</span><br><span class="line">        LoadLibraryExW(L&quot;wintun.dll&quot;, NULL, LOAD_LIBRARY_SEARCH_APPLICATION_DIR | LOAD_LIBRARY_SEARCH_SYSTEM32);</span><br><span class="line">    if (!Wintun)</span><br><span class="line">        return NULL;</span><br><span class="line">#define X(Name, Type) ((Name &#x3D; (Type)GetProcAddress(Wintun, #Name)) &#x3D;&#x3D; NULL)</span><br><span class="line">    if (X(WintunCreateAdapter, WINTUN_CREATE_ADAPTER_FUNC) || X(WintunDeleteAdapter, WINTUN_DELETE_ADAPTER_FUNC) ||</span><br><span class="line">        X(WintunDeletePoolDriver, WINTUN_DELETE_POOL_DRIVER_FUNC) || X(WintunEnumAdapters, WINTUN_ENUM_ADAPTERS_FUNC) ||</span><br><span class="line">        X(WintunFreeAdapter, WINTUN_FREE_ADAPTER_FUNC) || X(WintunOpenAdapter, WINTUN_OPEN_ADAPTER_FUNC) ||</span><br><span class="line">        X(WintunGetAdapterLUID, WINTUN_GET_ADAPTER_LUID_FUNC) ||</span><br><span class="line">        X(WintunGetAdapterName, WINTUN_GET_ADAPTER_NAME_FUNC) ||</span><br><span class="line">        X(WintunSetAdapterName, WINTUN_SET_ADAPTER_NAME_FUNC) ||</span><br><span class="line">        X(WintunGetRunningDriverVersion, WINTUN_GET_RUNNING_DRIVER_VERSION_FUNC) ||</span><br><span class="line">        X(WintunSetLogger, WINTUN_SET_LOGGER_FUNC) || X(WintunStartSession, WINTUN_START_SESSION_FUNC) ||</span><br><span class="line">        X(WintunEndSession, WINTUN_END_SESSION_FUNC) || X(WintunGetReadWaitEvent, WINTUN_GET_READ_WAIT_EVENT_FUNC) ||</span><br><span class="line">        X(WintunReceivePacket, WINTUN_RECEIVE_PACKET_FUNC) ||</span><br><span class="line">        X(WintunReleaseReceivePacket, WINTUN_RELEASE_RECEIVE_PACKET_FUNC) ||</span><br><span class="line">        X(WintunAllocateSendPacket, WINTUN_ALLOCATE_SEND_PACKET_FUNC) || X(WintunSendPacket, WINTUN_SEND_PACKET_FUNC))</span><br><span class="line">#undef X</span><br><span class="line">    &#123;</span><br><span class="line">        DWORD LastError &#x3D; GetLastError();</span><br><span class="line">        FreeLibrary(Wintun);</span><br><span class="line">        SetLastError(LastError);</span><br><span class="line">        return NULL;</span><br><span class="line">    &#125;</span><br><span class="line">    return Wintun;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="main-函数">main() 函数</span></h3><p>作用：</p><ul><li><strong>通过函数指针创建虚拟网卡</strong></li><li><strong>创建虚拟网卡的收发线程</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">int</span><br><span class="line">main(void)</span><br><span class="line">&#123;</span><br><span class="line">    HMODULE Wintun &#x3D; InitializeWintun();</span><br><span class="line">    if (!Wintun)</span><br><span class="line">        return LogError(L&quot;Failed to initialize Wintun&quot;, GetLastError());</span><br><span class="line">    WintunSetLogger(ConsoleLogger);</span><br><span class="line">    Log(WINTUN_LOG_INFO, L&quot;Wintun library loaded&quot;);</span><br><span class="line">    WintunEnumAdapters(L&quot;Example&quot;, PrintAdapter, 0);</span><br><span class="line"></span><br><span class="line">    DWORD LastError;</span><br><span class="line">    HaveQuit &#x3D; FALSE;</span><br><span class="line">    QuitEvent &#x3D; CreateEventW(NULL, TRUE, FALSE, NULL);</span><br><span class="line">    if (!QuitEvent)</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogError(L&quot;Failed to create event&quot;, GetLastError());</span><br><span class="line">        goto cleanupWintun;</span><br><span class="line">    &#125;</span><br><span class="line">    if (!SetConsoleCtrlHandler(CtrlHandler, TRUE))</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogError(L&quot;Failed to set console handler&quot;, GetLastError());</span><br><span class="line">        goto cleanupQuit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    GUID ExampleGuid &#x3D; &#123; 0xdeadbabe, 0xcafe, 0xbeef, &#123; 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef &#125; &#125;;</span><br><span class="line">    WINTUN_ADAPTER_HANDLE Adapter &#x3D; WintunOpenAdapter(L&quot;Example&quot;, L&quot;Demo&quot;);</span><br><span class="line">    if (!Adapter)</span><br><span class="line">    &#123;</span><br><span class="line">        Adapter &#x3D; WintunCreateAdapter(L&quot;Example&quot;, L&quot;Demo&quot;, &amp;ExampleGuid, NULL);</span><br><span class="line">        if (!Adapter)</span><br><span class="line">        &#123;</span><br><span class="line">            LastError &#x3D; GetLastError();</span><br><span class="line">            LogError(L&quot;Failed to create adapter&quot;, LastError);</span><br><span class="line">            goto cleanupQuit;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    DWORD Version &#x3D; WintunGetRunningDriverVersion();</span><br><span class="line">    Log(WINTUN_LOG_INFO, L&quot;Wintun v%u.%u loaded&quot;, (Version &gt;&gt; 16) &amp; 0xff, (Version &gt;&gt; 0) &amp; 0xff);</span><br><span class="line"></span><br><span class="line">    MIB_UNICASTIPADDRESS_ROW AddressRow;</span><br><span class="line">    InitializeUnicastIpAddressEntry(&amp;AddressRow);</span><br><span class="line">    WintunGetAdapterLUID(Adapter, &amp;AddressRow.InterfaceLuid);</span><br><span class="line">    AddressRow.Address.Ipv4.sin_family &#x3D; AF_INET;</span><br><span class="line">    AddressRow.Address.Ipv4.sin_addr.S_un.S_addr &#x3D; htonl((10 &lt;&lt; 24) | (6 &lt;&lt; 16) | (7 &lt;&lt; 8) | (7 &lt;&lt; 0)); &#x2F;* 10.6.7.7 *&#x2F;</span><br><span class="line">    AddressRow.OnLinkPrefixLength &#x3D; 24; &#x2F;* This is a &#x2F;24 network *&#x2F;</span><br><span class="line">    LastError &#x3D; CreateUnicastIpAddressEntry(&amp;AddressRow);</span><br><span class="line">    if (LastError !&#x3D; ERROR_SUCCESS &amp;&amp; LastError !&#x3D; ERROR_OBJECT_ALREADY_EXISTS)</span><br><span class="line">    &#123;</span><br><span class="line">        LogError(L&quot;Failed to set IP address&quot;, LastError);</span><br><span class="line">        goto cleanupAdapter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    WINTUN_SESSION_HANDLE Session &#x3D; WintunStartSession(Adapter, 0x400000);</span><br><span class="line">    if (!Session)</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogLastError(L&quot;Failed to create adapter&quot;);</span><br><span class="line">        goto cleanupAdapter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Log(WINTUN_LOG_INFO, L&quot;Launching threads and mangling packets...&quot;);</span><br><span class="line"></span><br><span class="line">    HANDLE Workers[] &#x3D; &#123; CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)ReceivePackets, (LPVOID)Session, 0, NULL),</span><br><span class="line">                         CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)SendPackets, (LPVOID)Session, 0, NULL) &#125;;</span><br><span class="line">    if (!Workers[0] || !Workers[1])</span><br><span class="line">    &#123;</span><br><span class="line">        LastError &#x3D; LogError(L&quot;Failed to create threads&quot;, GetLastError());</span><br><span class="line">        goto cleanupWorkers;</span><br><span class="line">    &#125;</span><br><span class="line">    WaitForMultipleObjectsEx(_countof(Workers), Workers, TRUE, INFINITE, TRUE);</span><br><span class="line">    LastError &#x3D; ERROR_SUCCESS;</span><br><span class="line"></span><br><span class="line">cleanupWorkers:</span><br><span class="line">    HaveQuit &#x3D; TRUE;</span><br><span class="line">    SetEvent(QuitEvent);</span><br><span class="line">    for (size_t i &#x3D; 0; i &lt; _countof(Workers); ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        if (Workers[i])</span><br><span class="line">        &#123;</span><br><span class="line">            WaitForSingleObject(Workers[i], INFINITE);</span><br><span class="line">            CloseHandle(Workers[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    WintunEndSession(Session);</span><br><span class="line">cleanupAdapter:</span><br><span class="line">    WintunDeleteAdapter(Adapter, FALSE, NULL);</span><br><span class="line">    WintunFreeAdapter(Adapter);</span><br><span class="line">cleanupQuit:</span><br><span class="line">    SetConsoleCtrlHandler(CtrlHandler, FALSE);</span><br><span class="line">    CloseHandle(QuitEvent);</span><br><span class="line">cleanupWintun:</span><br><span class="line">    FreeLibrary(Wintun);</span><br><span class="line">    return LastError;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>收发报文的接口操作也非常简单，但是与 windows 网络协议栈之间的关系仍需要继续摸索。</p><h3><span id="特别说明">特别说明</span></h3><p>Wintun 接口是严格意义上的 3 层逻辑接口。原文如下：</p><blockquote><p>Wintun is a very simple and minimal TUN driver for the Windows kernel, which provides userspace programs with a simple network adapter for reading and writing packets. It is akin to Linux’s /dev/net/tun and BSD’s /dev/tun. Originally designed for use in WireGuard, Wintun is meant to be generally useful for a wide variety of layer 3 networking protocols and experiments. The driver is open source, so anybody can inspect and build it. Due to Microsoft’s driver signing requirements, we provide precompiled and signed versions that may be distributed with your software. The goal of the project is to be as simple as possible, opting to do things in the most pure and straight-forward way provided by NDIS.</p></blockquote><p>这里出现了一个小小的问题：<strong>Wireshark 上无法抓取此接口报文</strong>。如果想看封装后的报文信息，则需要单独记录日志而非抓包来完成。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113648931-2021-06-30-rB5kXq.png" alt></p><p>导致这个问题原因没有找到，我认为是：<strong>wireshark 抓取的报文是二层报文 (一个完整的以太网帧)，而 3 层逻辑接口上的报文尚未封装以太网帧，故无法抓取此接口。这只是个人猜测，根本原因不得而知。</strong></p><p><img src="https://img.hi-linux.com/staticfile/640-20210630113654931-2021-06-30-0mF6hi.png" alt></p><p>好了，基本介绍完毕，重新表达下我对 WireGuard 和 WinTun 的态度：<strong>劳资稀罕你，very 喜欢。</strong></p><blockquote><p>原文链接：<a href="https://blog.csdn.net/s2603898260/article/details/117389372" target="_blank" rel="noopener">https://blog.csdn.net/s2603898260/article/details/117389372</a></p></blockquote><h3><span id="脚注">脚注</span></h3><p>[1]Wireguard 项目的 Wintun 接口: <em><a href="https://github.com/WireGuard" target="_blank" rel="noopener">https://github.com/WireGuard</a></em></p><p>[2]OpenVPN 的 Tap 接口: <em><a href="https://github.com/Toney-Sun/openvpn" target="_blank" rel="noopener">https://github.com/Toney-Sun/openvpn</a></em></p><p>[3]Github 传送门: <em><a href="https://github.com/WireGuard" target="_blank" rel="noopener">https://github.com/WireGuard</a></em></p><p>[4]客户端链接: <em><a href="https://www.wireguard.com/install/" target="_blank" rel="noopener">https://www.wireguard.com/install/</a></em></p><p>[5]Github 传送门: <em><a href="https://github.com/Toney-Sun/wintun" target="_blank" rel="noopener">https://github.com/Toney-Sun/wintun</a></em></p><p>[6]wintun 官网传送门: <em><a href="https://www.wintun.net/" target="_blank" rel="noopener">https://www.wintun.net/</a></em></p><p>[7]windwos 的接口驱动开发: <em><a href="https://docs.microsoft.com/zh-cn/windows-hardware/drivers/install/components-of-a-driver-package" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/windows-hardware/drivers/install/components-of-a-driver-package</a></em></p><p>[8]它提供了一个示例供大家学习: <em><a href="https://git.zx2c4.com/wintun/tree/example/example.c" target="_blank" rel="noopener">https://git.zx2c4.com/wintun/tree/example/example.c</a></em></p><blockquote><p>本文转载自：「云原生实验室」，原文：<a href="https://tinyurl.com/y6mv2ym2" target="_blank" rel="noopener">https://tinyurl.com/y6mv2ym2</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一段时间，一直在找寻 Windows 操作系统上的虚拟网卡接口，主要是为了搭建隧道使用。但是 Windows 操作系统不像 Linux 操作系统，它的代码不开源，导致这方面的资料很少，因此花费了较长时间来寻找相关实现框架，最终找到了两款开源项目的虚拟接口驱动：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wireguard 项目的 Wintun 接口[1]&lt;/li&gt;
&lt;li&gt;OpenVPN 的 Tap 接口[2]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个项目都是非常出名的搭建隧道的开源 V.P.N 项目。由于目前对 openVPN 项目不太了解，也没有适配 Tap 接口，因此这里重点介绍下 WinTun 接口。此接口实现我是非常非常的喜欢，喜欢到简直不要不要的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/categories/WireGuard/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/tags/WireGuard/"/>
    
  </entry>
  
  <entry>
    <title>写给 Linux 小白用户的命令行极简教程</title>
    <link href="https://www.hi-linux.com/posts/38789.html"/>
    <id>https://www.hi-linux.com/posts/38789.html</id>
    <published>2021-07-06T01:00:00.000Z</published>
    <updated>2021-07-06T04:38:08.156Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>电脑图形化的交互方式对用户使用来说更加的友好，而对于命令行的操作方式来说，通常会有更加高的学习曲线。但你不得不承认，使用图形化的界面会需要更多的计算资源，而且通常来说是比较难通过脚本的方式进行自动化的。</p><p>所以我们要辩证的来看这个问题，图形界面操作方式虽好，但是对于工程师来说，如果我们要更高效的完成我们的工作，命令行是一个比较好的通过自动化的方式提高我们工作效率的方式。</p><p>今天要推荐的开源项目汇总了我们日常会使用的命令行的列表，并增加了有趣的讲解方式，相信能够帮助你很好的入门命令行操作方式。</p><a id="more"></a><p><img src="https://img.hi-linux.com/staticfile/image-20210630104614098-2021-06-30-j5qxxN.png" alt></p><p>以上是一个目录列表，基本覆盖了日常经常用到的，如果能使用上一定会极大提高你的效率。</p><p>以下是对搜索文档的命令解释：</p><p><img src="https://img.hi-linux.com/staticfile/image-20210630104542733-2021-06-30-F5F6qf.png" alt></p><p>更多详情请查看 <code>You-Dont-Need-GUI</code> 开源项目链接：<a href="https://github.com/you-dont-need/You-Dont-Need-GUI" target="_blank" rel="noopener">https://github.com/you-dont-need/You-Dont-Need-GUI</a></p><blockquote><p>本文转载自：「 GitHub 精选 」，原文：<a href="https://tinyurl.com/hehuhfjj" target="_blank" rel="noopener">https://tinyurl.com/hehuhfjj</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;电脑图形化的交互方式对用户使用来说更加的友好，而对于命令行的操作方式来说，通常会有更加高的学习曲线。但你不得不承认，使用图形化的界面会需要更多的计算资源，而且通常来说是比较难通过脚本的方式进行自动化的。&lt;/p&gt;
&lt;p&gt;所以我们要辩证的来看这个问题，图形界面操作方式虽好，但是对于工程师来说，如果我们要更高效的完成我们的工作，命令行是一个比较好的通过自动化的方式提高我们工作效率的方式。&lt;/p&gt;
&lt;p&gt;今天要推荐的开源项目汇总了我们日常会使用的命令行的列表，并增加了有趣的讲解方式，相信能够帮助你很好的入门命令行操作方式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟搞懂高性能分布式消息系统 Kafka</title>
    <link href="https://www.hi-linux.com/posts/21173.html"/>
    <id>https://www.hi-linux.com/posts/21173.html</id>
    <published>2021-07-05T01:00:00.000Z</published>
    <updated>2021-07-06T04:38:08.154Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>kafka 由 LinkedIn 公司推出的一个高吞吐的分布式消息系统，通俗的说就是一个基于发布和订阅的消息队列。</p><blockquote><p>官网地址：<a href="https://kafka.apache.org/intro" target="_blank" rel="noopener">https://kafka.apache.org/intro</a></p></blockquote><h2><span id="应用场景">应用场景</span></h2><ul><li>异步解构：在上下游没有强依赖的业务关系或针对单次请求不需要立刻处理的业务；</li><li>系统缓冲：有利于解决服务系统的吞吐量不一致的情况，尤其对处理速度较慢的服务来说起到缓冲作用；</li><li>消峰作用：对于短时间偶现的极端流量，对后端的服务可以启动保护作用；</li><li>数据流处理：集成 spark 做实事数据流处理。</li></ul><a id="more"></a><h2><span id="kafka-拓扑图多副本机制">Kafka 拓扑图（多副本机制）</span></h2><p><img src="https://img.hi-linux.com/staticfile/640-2021-06-08-UybUKS.jpg" alt></p><p>由上图我们可以发现 Kafka 是分布式，同时对于每一个分区都存在多副本，同时整个集群的管理都通过 zookeeper 管理。</p><h2><span id="kafka-核心组件">Kafka 核心组件</span></h2><h3><span id="broker">broker</span></h3><p>Kafka 服务器，负责消息存储和转发；一 broker 就代表一个 kafka 节点。<strong>一个 broker 可以包含多个 topic</strong></p><h3><span id="topic">topic</span></h3><p>消息类别，Kafka 按照 topic 来分类消息</p><h3><span id="partition">partition</span></h3><ul><li>topic 的分区，一个 topic 可以包含多个 partition，topic 消息保存在各个 partition 上；由于一个 topic 能被分到多个分区上，给 kafka 提供给了并行的处理能力，这也正是 kafka 高吞吐的原因之一。</li><li>partition 物理上由多个 segment 文件组成，每个 segment 大小相等，<strong>顺序读写（这也是 kafka 比较快的原因之一，不需要随机写）</strong>。每个 Segment 数据文件以该段中最小的 offset ，文件扩展名为.log。当查找 offset 的 Message 的时候，通过二分查找快找到 Message 所处于的 Segment 中。</li></ul><p><img src="https://img.hi-linux.com/staticfile/640-20210608153214599-2021-06-08-1TbIEn.jpg" alt></p><h3><span id="offset">offset</span></h3><ul><li>消息在日志中的位置，可以理解是消息在 partition 上的偏移量，也是代表该消息的 <strong>唯一序号</strong>。</li><li>同时也是主从之间的需要同步的信息。</li></ul><p><img src="https://img.hi-linux.com/staticfile/640-20210608171653851-2021-06-08-vYXtZy.png" alt></p><h3><span id="producer">Producer</span></h3><p>生产者，负责向 Kafka Broker 发消息的客户端</p><h3><span id="consumer">Consumer</span></h3><p>消息消者，负责消费 Kafka Broker 中的消息</p><h3><span id="consumer-group">Consumer Group</span></h3><p>消费者组，每个 Consumer 必须属于一个 group；（<strong>注意的是 一个分区只能由组内一个消费者消费，消费者组之间互不影响。</strong>）</p><h3><span id="zookeeper">Zookeeper</span></h3><p>管理 kafka 集群，负责存储了集群 broker、topic、partition 等 meta 数据存储，同时也负责 broker 故障发现，partition leader 选举，负载均衡等功能。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210608153214949-2021-06-08-k34ndR.jpg" alt></p><h2><span id="服务治理">服务治理</span></h2><p>既然 Kafka 是分布式的发布/订阅系统，这样如果做的集群之间数据同步和一致性，kafka 是不是肯定不会丢消息呢？以及宕机的时候如果进行 Leader 选举呢？</p><h3><span id="数据同步">数据同步</span></h3><p>在 Kafka 中的 Partition 有一个 leader 与多个 follower，producer 往某个 Partition 中写入数据是，只会往 leader 中写入数据，然后数据才会被复制进其他的 Replica 中。而每一个 follower 可以理解成一个消费者，定期去 leader 去拉去消息。而只有数据同步了后，kafka 才会给生产者返回一个 ACK 告知消息已经存储落地了。</p><h4><span id="isr">ISR</span></h4><p>在 Kafka 中，为了保证性能，Kafka 不会采用强一致性的方式来同步主从的数据。而是维护了一个：in-sync Replica 的列表，Leader 不需要等待所有 Follower 都完成同步，只要在 ISR 中的 Follower 完成数据同步就可以发送 ack 给生产者即可认为消息同步完成。同时如果发现 ISR 里面某一个 follower 落后太多的话，就会把它剔除。</p><p>具体流程如下：</p><p><img src="https://img.hi-linux.com/staticfile/640-20210608171703950-2021-06-08-xMVWIS.jpg" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210608153215253-2021-06-08-YVCeg5.jpg" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210608171710748-2021-06-08-xDzUTa.jpg" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210608153215595-2021-06-08-0UxZSM.jpg" alt></p><p><strong>上述的做法并无法保证 kafka 一定不丢消息。</strong> 虽然 Kafka 通过多副本机制中最大限度保证消息不会丢失，但是如果数据已经写入系统 page cache 中但是还没来得及刷入磁盘，此时突然机器宕机或者掉电，那消息自然而然的就会丢失。</p><h4><span id="kafka-故障恢复">Kafka 故障恢复</span></h4><p><img src="https://img.hi-linux.com/staticfile/640-20210608171719734-2021-06-08-qboDya.jpg" alt></p><p>Kafka 通过 Zookeeper 连坐集群的管理，所以这里的选举机制采用的是 Zab(zookeeper 使用)。</p><ul><li>生产者发生消息给 leader，这个时候 leader 完成数据存储，突然发生故障，没有给 producer 返回 ack；</li><li>通过 ZK 选举，其中一个 follower 成为 leader，这个时候 producer 重新请求新的 leader，并存储数据。</li></ul><h2><span id="kafka-为什么这么快">Kafka 为什么这么快</span></h2><h3><span id="顺序写磁盘">顺序写磁盘</span></h3><p>Kafka 采用了顺序写磁盘，而由于顺序写磁盘相对随机写，减少了寻地址的耗费时间。（在 Kafka 的每一个分区里面消息是有序的。</p><h3><span id="page-cache">Page Cache</span></h3><p>Kafka 在 OS 系统方面使用了 Page Cache 而不是我们平常所用的 Buffer。Page Cache 其实不陌生，也不是什么新鲜事物。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210608171726453-2021-06-08-U7ZUfO.jpg" alt></p><p>我们在linux上查看内存的时候，经常可以看到buff/cache，两者都是用来加速IO读写用的，而cache是作用于读，也就是说，磁盘的内容可以读到cache里面这样，应用程序读磁盘就非常快；而buff是作用于写，我们开发写磁盘都是，一般如果写入一个buff里面再flush就非常快。而kafka正是把这两者发挥了极致：Kafka虽然是scala写的，但是依旧在Java的虚拟机上运行，尽管如此，kafka它还是尽量避开了JVM的限制，它利用了Page cache来存储，这样躲开了数据在JVM因为GC而发生的STW。另一方面也是Page Cache使得它实现了零拷贝，具体下面会讲。</p><h3><span id="零拷贝">零拷贝</span></h3><p>无论是优秀的 Netty 还是其他优秀的 Java 框架，基本都在零拷贝减少了 CPU 的上下文切换和磁盘的 IO。当然 Kafka 也不例外。零拷贝的概念具体这里不作太详细的复述，大致的给大家讲一下这个概念。</p><h4><span id="传统的一次应用程请求数据的过程">传统的一次应用程请求数据的过程</span></h4><p><img src="https://img.hi-linux.com/staticfile/640-20210608171732790-2021-06-08-v7LMHm.jpg" alt></p><p>这里大致可以发传统的方式发生了 4 次拷贝，2 次 DMA 和 2 次 CPU，而 CPU 发生了 4 次的切换。_（DMA 简单理解就是，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情）。</p><h4><span id="零拷贝的方式">零拷贝的方式</span></h4><p><img src="https://img.hi-linux.com/staticfile/640-20210608171739895-2021-06-08-yevm8J.jpg" alt></p><p>通过优化我们可以发现，CPU 只发生了 2 次的上下文切换和 3 次数据拷贝。（linux 系统提供了系统事故调用函数“ sendfile()”，这样系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态）。</p><h4><span id="分区分段">分区分段</span></h4><p>我们上面也介绍过了，kafka 采取了分区的模式，而每一个分区又对应到一个物理分段，而查找的时候可以根据二分查找快速定位。这样不仅提供了数据读的查询效率，也提供了并行操作的方式。</p><h4><span id="数据压缩">数据压缩</span></h4><p>Kafka 对数据提供了：Gzip 和 Snappy 压缩协议等压缩协议，对消息结构体进行了压缩，一方面减少了带宽，也减少了数据传输的消耗。</p><h2><span id="kafka-安装">Kafka 安装</span></h2><h3><span id="安装-jdk">安装 JDK</span></h3><p>由于使用压缩包还需要自己配置环境变量，所以这里推荐直接用 yum 安装，熟悉查看目前 Java 的版本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum -y list Java*</span><br></pre></td></tr></table></figure><p>安装你想要的版本，这里我是 1.8</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install java-1.8.0-openjdk-devel.x86_64</span><br></pre></td></tr></table></figure><p>查看是否安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Java -version</span><br></pre></td></tr></table></figure><h3><span id="安装-zookeeper">安装 Zookeeper</span></h3><p>首先需要去官网下载安装包，然后解压</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf zookeeper-3.4.9.tar.gz</span><br></pre></td></tr></table></figure><p><strong>要做的就是将这个文件复制一份，并命名为：zoo.cfg，然后在 zoo.cfg 中修改自己的配置即可</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp zoo_sample.cfg zoo.cfg</span><br><span class="line">$ vim zoo.cfg</span><br></pre></td></tr></table></figure><p>主要配置解释如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># zookeeper内部的基本单位，单位是毫秒，这个表示一个tickTime为2000毫秒，在zookeeper的其他配置中，都是基于tickTime来做换算的</span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line"># 集群中的follower服务器(F)与leader服务器(L)之间 初始连接 时能容忍的最多心跳数（tickTime的数量）。</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line">#syncLimit：集群中的follower服务器(F)与leader服务器(L)之间 请求和应答 之间能容忍的最多心跳数（tickTime的数量）</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line"># 数据存放文件夹，zookeeper运行过程中有两个数据需要存储，一个是快照数据（持久化数据）另一个是事务日志</span><br><span class="line">dataDir&#x3D;&#x2F;tmp&#x2F;zookeeper</span><br><span class="line">## 客户端访问端口</span><br><span class="line">clientPort&#x3D;2181</span><br></pre></td></tr></table></figure><p>配置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim ~&#x2F;.bash_profile</span><br><span class="line">$ export ZK&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;apache-zookeeper-3.7.0-bin</span><br><span class="line">$ export PATH&#x3D;$PATH:$ZK&#x2F;bin</span><br><span class="line">$ export PATH</span><br><span class="line"># 启动</span><br><span class="line">$ zkServer.sh start</span><br></pre></td></tr></table></figure><p>下面能看启动成功</p><p><img src="https://img.hi-linux.com/staticfile/640-20210608171748740-2021-06-08-xFDssz.jpg" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210608171754226-2021-06-08-BKOjow.jpg" alt></p><h3><span id="安装-kafka">安装 Kafka</span></h3><ul><li>下载 kafka</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;www.apache.org&#x2F;dyn&#x2F;closer.cgi?path&#x3D;&#x2F;kafka&#x2F;2.8.0&#x2F;kafka-2.8.0-src.tgz</span><br></pre></td></tr></table></figure><ul><li>安装 kafka</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -xzvf kafka_2.12-2.0.0.tgz</span><br></pre></td></tr></table></figure><ul><li>配置环境变量</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ export ZK&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;apache-zookeeper-3.7.0-bin</span><br><span class="line">$ export PATH&#x3D;$PATH:$ZK&#x2F;bin</span><br><span class="line">$ export KAFKA&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;kafka</span><br><span class="line">$ export PATH&#x3D;$PATH:$KAFKA&#x2F;bin</span><br></pre></td></tr></table></figure><ul><li>启动 Kafka</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup kafka-server-start.sh 自己的配置文件路径&#x2F;server.properties &amp;</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/640-20210608153215851-2021-06-08-wXh4n6.jpg" alt></p><p>大功告成！</p><h2><span id="参考资料">参考资料</span></h2><ul><li>《深入理解 Kafka：核心设计实践原理》</li></ul><blockquote><p>本文转载自：「 腾讯技术工程 」，原文：<a href="https://tinyurl.com/2ssfz7rk" target="_blank" rel="noopener">https://tinyurl.com/2ssfz7rk</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kafka 由 LinkedIn 公司推出的一个高吞吐的分布式消息系统，通俗的说就是一个基于发布和订阅的消息队列。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://kafka.apache.org/intro&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://kafka.apache.org/intro&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;应用场景&quot;&gt;应用场景&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;异步解构：在上下游没有强依赖的业务关系或针对单次请求不需要立刻处理的业务；&lt;/li&gt;
&lt;li&gt;系统缓冲：有利于解决服务系统的吞吐量不一致的情况，尤其对处理速度较慢的服务来说起到缓冲作用；&lt;/li&gt;
&lt;li&gt;消峰作用：对于短时间偶现的极端流量，对后端的服务可以启动保护作用；&lt;/li&gt;
&lt;li&gt;数据流处理：集成 spark 做实事数据流处理。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="https://www.hi-linux.com/categories/Kafka/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Kafka" scheme="https://www.hi-linux.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>一文带你理解云原生 | 云原生全景图详解</title>
    <link href="https://www.hi-linux.com/posts/14157.html"/>
    <id>https://www.hi-linux.com/posts/14157.html</id>
    <published>2021-07-01T01:00:00.000Z</published>
    <updated>2021-07-01T01:37:18.903Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="带你了解云原生技术图谱">带你了解云原生技术图谱</span></h2><p>如果你研究过云原生应用程序和相关技术，大概率你遇到过 CNCF 的云原生全景图。这张全景图技术之多规模之大无疑会让人感到震惊，该如何去理解这张图呢？</p><p>如果把它拆开来一次只分析一小块内容，你会发现整个全景图没有那么复杂。事实上，该全景图按照功能有序地组织在一起，一旦你了解了每个类别代表的内容，你就可以轻松游走于全景图中。</p><p>本章节我们将把整个全景图拆解开来，并对整个全景图进行综述。在后续章节中，我们将聚焦在每一层（or 每一列），对每个类别解决的问题和原理进行更为详细的解读。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701092946955-2021-07-01-NjRgpd.png" alt="云原生全景图的 4 层"></p><p>首先，我们剥离掉所有单个的技术，仅查看类别（如下图）。图中有不同的“行”，像建筑的不同层，每层都有自己的子类别。最底层提供了构建云原生基础设施的工具。往上，你可以开始添加运行和管理应用程序所需的工具，比如运行时和调度层。在最上层，有定义和开发应用程序的工具，比如数据库、镜像构建和 CI/CD 工具（我们将在后文讨论）。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701092955887-2021-07-01-CCKzaW.png" alt></p><p>好了，现在你应该记住了云原生全景图始于基础设施，往上的每一层都更接近实际的应用程序。这就是每层代表的意思（后面我们会讨论上图右边的两“列”）。下面我们就从最底层开始，逐层进行解析。</p><a id="more"></a><p><strong>供应层 （Provisioning）</strong></p><p>供应指的是为云原生应用准备标准基础环境所涉及的工具。它包含了基础设施的创建、管理、配置流程的自动化，以及容器镜像的扫描、签名和存储等。供应层通过提供设置和实施策略，在应用程序和平台中构建身份验证和授权，以及处理密钥分发等等的工具，也拓展到了安全领域。</p><p>供应层包括：</p><ul><li><p>自动化和部署工具：帮助工程师在无需人工干预情况下即可构建计算环境；</p></li><li><p>容器注册表：存储应用程序的可执行文件；</p></li><li><p>不同安全领域的安全和合规框架；密钥管理解决方案：通过加密确保只有授权的用户才能访问特定的应用程序。</p></li><li><p>这些工具使工程师可以编写基础设施参数，使系统可以按需搭建新环境，确保了一致性和安全性。</p></li></ul><p><strong>运行时层（Runtime）</strong></p><p>接下来是运行时层。这个词可能会让你感到迷惑。像很多 IT 术语一样，运行时没有严格的定义，且可以根据语境有不同的用法。狭义上讲，运行时是特定机器上准备运行应用程序的沙盒——也就是保障应用程序正常运行所需的最低配置。广义上讲，运行时是运行一个应用程序所需的所有工具。</p><p>在 CNCF 云原生全景图中，运行时保障了容器化应用程序组件的运行和通信， 包括：</p><ul><li><p>云原生存储：为容器化应用提供虚拟磁盘或持久化存储；</p></li><li><p>容器运行时：为容器提供隔离、资源和安全；</p></li><li><p>云网络：分布式系统的节点（机器或进程）通过其连接和通信。</p></li></ul><p><strong>编排和管理层（Orchestration and Management）</strong></p><p>一旦按照安全和合规性标准（供应层）自动化基础设施供应，并安装了应用程序运行所需的工具（运行时层），工程师就需要弄清楚如何编排和管理应用程序。编排和管理层将所有容器化服务（应用程序组件）作为一个群组管理。这些容器化服务需要相互识别和通信，并需要进行协调。这一层可为云原生应用提供自动化和弹性能力，使云原生应用天然具有可扩展性。</p><p>这一层包含：</p><ul><li><p>编排和调度：部署和管理容器集群，确保它们具有弹性伸缩能力，相互之间低耦合，并且可扩展。事实上，编排工具（绝大多数情况下就是 Kubernetes）通过管理容器和操作环境构成了集群；</p></li><li><p>协调和服务发现：使得服务（应用程序组件）之间可以相互定位和通信；</p></li><li><p>远程进程调用（RPC）：使跨节点服务间通信的技术；</p></li><li><p>服务代理：服务间通信的中介。服务代理的唯一目的就是对服务之间的通信进行更多控制，而不会对通信本身添加任何内容。服务代理对下面将提到的服务网格（Service Mesh）至关重要。</p></li><li><p>API 网关：一个抽象层，外部应用可通过 API 网关进行通信；</p></li><li><p>Service Mesh：某种程度上类似于 API 网关，它是应用程序进行通信的专用基础架构层，提供基于策略的内部服务间通信。此外，它还可能包含流量加密、服务发现、应用程序监控等内容。</p></li></ul><p><strong>应用定义和开发层 （Application Definition and Developement)</strong></p><p>现在，我们来到了最顶层。应用定义和开发层，顾名思义，聚集了让工程师构建和运行应用程序的工具。上述所有内容都是关于构建可靠、安全的环境，以及提供全部所需的应用程序依赖。</p><p>这一层包括：</p><ul><li><p>数据库：使应用程序能以有序的方式收集数据；</p></li><li><p>流和消息传递：使应用程序能发送和接收消息（事件和流）。它不是网络层，而是让消息成为队列并处理消息的工具；</p></li><li><p>应用程序定义和镜像构建：用于配置、维护和运行容器镜像（应用程序的可执行文件）的服务；</p></li><li><p>持续集成和持续交付（CI/CD）：使开发者可自动测试代码是否与代码库（应用程序的其余部分）兼容。如果团队足够成熟，甚至可以自动部署代码到生产环境。</p></li></ul><p><strong>贯穿所有层的工具</strong></p><p>接下来我们将进入到云原生全景图右侧贯穿所有层的两列。可观察性和分析（Observability&amp;analysis）是监控各层的工具，平台则将各层中不同的技术捆绑为一个解决方案。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093003517-2021-07-01-Oa1xSU.png" alt="可观察性和分析（Observability and Analysis）"></p><p>为了限制服务中断并降低解决问题的平均时间（MRRT），你需要监控和分析应用层序的方方面面，以便在出现异常时可立即发现并纠正。复杂环境中容易出现故障，这些工具可快速识别并解决故障，从而降低故障带来的影响。由于这一类别贯穿并监控各层，因此它在侧面，而不是嵌入到某一层中。</p><p>这一类别你将发现：</p><ul><li><p>日志工具：收集事件日志（有关进程的信息）；</p></li><li><p>监控方案：收集指标（以数字表示的系统参数，例如 RAM 可用性）；</p></li><li><p>追踪工具：追踪比监控更进了一步，它们监控用户请求的传播，与服务网格相关。</p></li><li><p>混沌工程（Chaos Engineering）：在生产环境中测试软件的工具，可识别缺陷并进行修复，减少其对服务交付的影响。</p></li></ul><p><strong>平台类（Platform）</strong></p><p>可以看到，图中每一个模块解决一个特定的问题。但我们知道，仅有存储并不能提供应用程序所需的全部功能。你还需要编排工具，容器运行时，服务发现，网络，API 网关等等。平台覆盖多层，将不同的工具组合在一起，以解决更大的问题。</p><p>配置和微调不同的模块使其安全可靠，并确保它利用的技术都能及时更新、所有漏洞都打了补丁，这并不是一件容易的事情。使用平台时，用户不用额外担心这些细节问题。</p><p>你可能会注意到，所有的类别都围绕着 Kubernetes 展开。这是因为 Kubernetes 虽然只是云原生景观图这张拼图中的一块，但它却是云原生技术栈的核心。顺便说一下，CNCF 刚创建时，Kubernetes 就是其中的第一个种子项目，后来才有了其他项目。</p><p>平台可分为四类：</p><ul><li><p>Kubernetes 发行版：采用未经修改的开放源代码（尽管有人对其进行了修改），并根据市场需要增加了其他功能；</p></li><li><p>托管的 Kubernetes：类似于 Kubernetes 发行版，但是由提供商托管；</p></li><li><p>Kubernetes 安装程序：自动执行 Kubernetes 的安装和配置过程；</p></li><li><p>PaaS/容器服务：类似于托管的 Kubernetes，但是包含了一套更广泛的应用部署工具（通常是来自云原生景观图）。</p></li></ul><p><strong>小结</strong></p><p>在每个类别中，针对相同或相似的问题，都有不同的工具可选择。有一些是适用于新现实的预云原生技术，还有一些则是全新的。区别在于它们的实现和设计方法。没有完美的技术符合你的所有需求。大多数情况下，技术受设计和架构选择的限制——始终需要权衡取舍。</p><p>在选择技术栈时，工程师必须仔细考虑每种能力和需要权衡取舍的地方，以确定最合适的选项。虽然这样会让情况变得更复杂，但在选择应用程序所需的最适合的数据存储、基础设施管理、消息系统等方案时，这样做是最可行的办法。现在，构建一个系统比云原生之前的时代容易多了。如果构建恰当，云原生技术将提供更强大的灵活性。在现如今快速变化的技术生态中，这可能是最重要的能力之一。</p><p>下面详细介绍云原生全景图的每一层。</p><h2><span id="供应层">供应层</span></h2><p>云原生全景图的最底层是供应层（provisioning）。这一层包含构建云原生基础设施的工具，如基础设施的创建、管理、配置流程的自动化，以及容器镜像的扫描、签名和存储等。供应层也跟安全相关，该层中的一些工具可用于设置和实施策略，将身份验证和授权内置到应用程序和平台中，以及处理 secret 分发等。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093009951-2021-07-01-xOFCfR.png" alt></p><p>接下来让我们看一下供应层的每个类别，它所扮演的角色以及这些技术如何帮助应用程序适应新的云原生环境。</p><h3><span id="自动化和配置">自动化和配置</span></h3><p><strong>是什么</strong></p><p>自动化和配置工具可加快计算资源（虚拟机、网络、防火墙规则、负载均衡器等）的创建和配置过程。这些工具可以处理基础设施构建过程中不同部分的内容，大多数工具都可与该空间中其他项目和产品集成。</p><p><strong>解决的问题</strong></p><p>传统上，IT 流程依赖高强度的手动发布过程，周期冗长，通常可达 3-6 个月。这些周期伴随着许多人工流程和管控，让生产环境的变更非常缓慢。这种缓慢的发布周期和静态的环境与云原生开发不匹配。为了缩短开发周期，必须动态配置基础设施且无需人工干预。</p><p><strong>如何解决问题</strong></p><p>供应层的这些工具使工程师无需人工干预即可构建计算环境。通过代码化环境设置，只需点击按钮即可实现环境配置。手动设置容易出错，但是一旦进行了编码，环境创建就会与所需的确切状态相匹配，这是一个巨大的优势。</p><p>尽管不同工具实现的方法不同，但它们都是通过自动化来简化配置资源过程中的人工操作。</p><p><strong>对应工具</strong></p><p>当我们从老式的人工驱动构建方式过渡到云环境所需的按需扩展模式时，会发现以前的模式和工具已经无法满足需求，组织也无法维持一个需要创建、配置和管理服务器的 7×24 员工队伍。Terraform 之类的自动化工具减少了扩展数服务器和相关网络以及防火墙规则所需的工作量。Puppet，Chef 和 Ansible 之类的工具可以在服务器和应用程序启动时以编程方式配置它们，并允许开发人员使用它们。</p><p>一些工具直接与 AWS 或 vSphere 等平台提供的基础设施 API 进行交互，还有一些工具则侧重于配置单个计算机以使其成为 Kubernetes 集群的一部分。Chef 和 Terraform 这类的工具可以进行互操作以配置环境。OpenStack 这类工具可提供 IaaS 环境让其他工具使用。</p><p>从根本上讲，在这一层，你需要一个或多个工具来为 Kubernetes 集群搭建计算环境、CPU、内存、存储和网络。此外，你还需要其中的一些工具来创建和管理 Kubernetes 集群本身。</p><p>在撰写本文时，该领域中有三个 CNCF 项目：KubeEdge（一个沙盒项目）以及 Kubespray 和 Kops（后两个是 Kubernetes 子项目，虽然未在全景图中列出，但它们也属于 CNCF）。此类别中的大多数工具都提供开源和付费版本。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093015958-2021-07-01-emmUPF.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093021222-2021-07-01-teXcLx.png" alt></p><h3><span id="container-registry">Container Registry</span></h3><p><strong>是什么</strong></p><p>在定义 Container Registry 之前，我们首先讨论三个紧密相关的概念：</p><ul><li><p>容器是执行流程的一组技术约束。容器内启动的进程会相信它们正在自己的专用计算机上运行，而不是在与其他进程（类似于虚拟机）共享的计算机上运行。简而言之，容器可以使你在任何环境中都能控制自己的代码运行。</p></li><li><p>镜像是运行容器及其过程所需的一组存档文件。你可以将其视为模板的一种形式，可以在其上创建无限数量的容器。</p></li><li><p>仓库是存储镜像的空间。</p></li></ul><p>回到 Container Registry，这是分类和存储仓库的专用 Web 应用程序。</p><p>镜像包含执行程序（在容器内）所需的信息，并存储在仓库中，仓库被分类和分组。构建、运行和管理容器的工具需要访问（通过引用仓库）这些镜像。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093027683-2021-07-01-Dt5D0A.png" alt></p><p><strong>解决的问题</strong></p><p>云原生应用程序被打包后以容器的方式运行。Container Registry 负责存储和提供这些容器镜像。</p><p><strong>如何解决</strong></p><p>通过在一个地方集中存储所有容器镜像，这些容器镜像可以很容易地被应用程序的开发者访问。</p><p><strong>对应工具</strong></p><p>Container Registry 要么存储和分发镜像，要么以某种方式增强现有仓库。本质上，它是一种 Web API，允许容器引擎存储和检索镜像。许多 Container Registry 提供接口，使容器扫描/签名工具来增强所存储镜像的安全性。有些 Container Registry 能以特别有效的方式分发或复制图像。任何使用容器的环境都需要使用一个或多个仓库。</p><p>该空间中的工具可以提供集成功能，以扫描，签名和检查它们存储的镜像。在撰写本文时，Dragonfly 和 Harbor 是该领域中的 CNCF 项目，而 Harbor 最近成为了第一个遵循 OCI 的仓库。主要的云提供商都提供自己的托管仓库，其他仓库可以独立部署，也可以通过 Helm 之类的工具直接部署到 Kubernetes 集群中。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093033771-2021-07-01-wYlIC9.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093039766-2021-07-01-bTwe5x.png" alt></p><h3><span id="安全和合规">安全和合规</span></h3><p><strong>是什么</strong></p><p>云原生应用程序的目标是快速迭代。为了定期发布代码，必须确保代码和操作环境是安全的，并且只能由获得授权的工程师访问。这一部分的工具和项目可以用安全的方式创建和运行现代应用程序。</p><p><strong>解决什么问题</strong></p><p>这些工具和项目可为平台和应用程序加强、监控和实施安全性。它们使你能在容器和 Kubernetes 环境中设置策略（用于合规性），深入了解存在的漏洞，捕获错误配置，并加固容器和集群。</p><p><strong>如何解决</strong></p><p>为了安全地运行容器，必须对其进行扫描以查找已知漏洞，并对其进行签名以确保它们未被篡改。Kubernetes 默认的访问控制比较宽松，对于想攻击系统的人来说， Kubernetes 集群很容易成为目标。该空间中的工具和项目有助于增强群集，并在系统运行异常时提供工具来检测。</p><p><strong>对应工具</strong></p><p>为了在动态、快速发展的环境中安全运行，我们必须将安全性视为平台和应用程序开发生命周期的一部分。这部分的工具种类繁多，可解决安全领域不同方面的问题。大多数工具属于以下类别：</p><ul><li><p>审计和合规</p></li><li><p>生产环境强化工具的路径：</p><ul><li><p>代码扫描</p></li><li><p>漏洞扫描</p></li><li><p>镜像签名</p></li></ul></li><li><p>策略制定和执行</p></li><li><p>网络层安全</p></li></ul><p>其中的一些工具和项目很少会被直接使用。例如 Trivy、Claire 和 Notary，它们会被 Registry 或其他扫描工具所利用。还有一些工具是现代应用程序平台的关键强化组件，例如 Falco 或 Open Policy Agent（OPA）。</p><p>该领域有许多成熟的供应商提供解决方案，也有很多创业公司的业务是把 Kubernetes 原生框架推向市场。在撰写本文时，Falco、Notary/TUF 和 OPA 是该领域中仅有的 CNCF 项目。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093047903-2021-07-01-eGPSRj.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093054334-2021-07-01-RMVXhu.png" alt></p><h3><span id="密钥和身份管理">密钥和身份管理</span></h3><p><strong>是什么</strong></p><p>在进入到密钥管理之前，我们首先定义一下密钥。密钥是用于加密或签名数据的字符串。和现实中的钥匙一样，密钥锁定（加密）数据，只有拥有正确密钥的人才能解锁（解密）数据。</p><p>随着应用程序和操作开始适应新的云原生环境，安全工具也在不断发展以满足新的需求。此类别中的工具和项目可用于安全地存储密码和其他 secrets（例如 API 密钥，加密密钥等敏感数据）、从微服务环境中安全删除密码和 secret 等。</p><p><strong>解决的问题</strong></p><p>云原生环境是高度动态的，需要完全编程（无人参与）和自动化的按需 secret 分发。应用程序还必须知道给定的请求是否来自有效来源（身份验证），以及该请求是否有权执行操作（授权）。通常将其称为 AuthN 和 AuthZ。</p><p><strong>如何解决</strong></p><p>每个工具或项目实施的方法不同，但他们都提供：</p><ul><li><p>安全分发 secret 或密钥的方法。</p></li><li><p>身份认证或（和）授权的服务或规范。</p></li></ul><p><strong>对应的工具</strong></p><p>此类别中的工具可以分为两组：</p><ul><li><p>一些工具专注于密钥生成、存储、管理和轮转。</p></li><li><p>另一些专注于单点登录和身份管理。</p></li></ul><p>拿 Vault 来说，它是一个通用的密钥管理工具，可管理不同类型的密钥。而 Keycloak 则是一个身份代理工具，可用于管理不同服务的访问密钥。</p><p>在撰写本文时，SPIFFE/SPIRE 是该领域中唯一的 CNCF 项目。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093101081-2021-07-01-7b4gvL.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093106887-2021-07-01-q655GC.png" alt></p><p>供应层专注于构建云原生平台和应用程序的基础，其中的工具涉及基础设施供应、容器注册表以及安全性。本章节详细介绍了云原生全景图的最底层。</p><h2><span id="运行时层">运行时层</span></h2><p>本章节我们将一起了解运行时层（runtime），这一层包含了容器在云原生环境中运行所需的一切。即：启动容器的代码，也叫运行时引擎；使容器获得持久化存储的工具；以及管理容器环境网络的工具。</p><p>但是注意，不要将这一层的资源与基础设施和供应层的网络和存储弄混淆，后者的工作是让容器平台运行起来。容器直接使用运行时层的工具来启动或停止，存储数据，以及相互通信。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093113293-2021-07-01-8EjriE.png" alt></p><h3><span id="云原生存储">云原生存储</span></h3><p><strong>是什么</strong></p><p>存储是存放一个应用程序持久数据的地方，也叫做持久卷（persistent volume)。轻松访问持久卷对于应用程序可靠运行至关重要。通常，当我们说持久数据的时候，我们是指数据库、消息之类的，或其他任何在应用重新启动时不会丢失的信息。</p><p><strong>解决的问题</strong></p><p>云原生架构具有高度的灵活性和弹性，这使得重启应用时存储持久数据变得很有挑战性。容器化应用程序在扩容、缩容或自动恢复时，会不断地创建或删除实例，并随着时间改变物理位置。因此，必须以与节点无关的方式提供云原生存储。但是，要存储数据，就需要硬件（具体来说是磁盘）。磁盘和其他硬件一样，受到基础设施的限制。这是第一个大的挑战。</p><p>第二个挑战是存储接口。该接口在数据中心之间可能会发生很大的变化（在以前，不同的基础设施都有自己的存储解决方案，并带有自己的接口），这使得可移植性变得非常困难。</p><p>最后，由于云的弹性，存储必须以自动化方式进行配置，因为手动配置和自动扩展不兼容。面临以上这些问题，云原生存储就是为新的云原生环境量身定制的。</p><p><strong>如何解决</strong></p><p>该类别的工具可以：</p><ul><li><p>为容器提供云原生存储选项；</p></li><li><p>标准化容器与存储提供者之间的接口；</p></li><li><p>通过备份和还原操作提供数据保护。</p></li></ul><p>云原生存储意味着使用兼容云原生环境的容器存储接口（也就是下一个类别中的工具），并且可以自动配置，通过消除人力瓶颈从而实现了自动扩展和自我恢复。</p><p><strong>对应工具</strong></p><p>容器存储接口（CSI）在很大程度上使云原生存储变成了可能。CSI 允许使用标准 API 向容器提供文件和块存储。该领域中有很多工具，既有开源的也有供应商提供的，都可利用 CSI 为容器提供按需存储。</p><p>除了这一及其重要的功能，还有一些其他的工具和技术旨在解决云原生空间中的存储问题。Minio 是一个受欢迎的项目，它提供了兼容 S3 的 API 用于对象存储。Velero 之类的工具可帮助简化 Kubernetes 集群本身以及应用程序使用的持久化数据的备份和还原过程。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093121093-2021-07-01-TJZOf4.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093126617-2021-07-01-SjPyDB.png" alt></p><h3><span id="容器运行时">容器运行时</span></h3><p><strong>是什么</strong></p><p>前面我们提到过，容器是一组用于执行应用程序的技术约束。容器化的应用程序相信自己正在专用计算机上运行，而忽略了它们其实是与其他进程（类似于虚拟机）共享资源。</p><p>容器运行时是执行容器化（或“隔离”）应用的软件。如果没有运行时，将只有容器镜像——指定容器化应用程序外观的文件。运行时将在容器中启动应用程序，并为其提供所需的资源。</p><p><strong>解决的问题</strong></p><p>容器镜像（带有应用程序规范的文件）必须以标准化、安全和隔离的方式启动：</p><ul><li><p>标准化：无论它们在何处运行，都需要标准操作规则；</p></li><li><p>安全：访问权限应该要注意设置；</p></li><li><p>隔离：该应用程序不应影响其他应用程序或受到其他应用程序的影响（例如，位于同一位置的应用程序崩溃）。隔离基本上起到保护作用。</p></li></ul><p>此外，必须为应用程序提供 CPU、存储、内存等资源。</p><p><strong>如何解决</strong></p><p>容器运行时可以完成所有这些工作。它以标准化方式在所有环境中启动应用程序，并设置安全边界。安全边界是运行时和其他工具不同的地方，CRI-O 或 gVisor 等运行时强化了它们的安全性边界。运行时还为容器设置资源限制。没有资源限制，应用程序可能会根据需要消耗资源，这样就有可能占用其他应用程序的资源。因此设置资源限制是很必要的。</p><p><strong>对应的工具</strong></p><p>不是所有此类别中的工具都一样。Containerd（Docker 产品的一部分）和 CRI-O 是标准的容器运行时实现。有一些工具可以将容器的使用扩展到其他技术，例如 Kata，它允许将容器作为 VM 运行。其他工具旨在解决与容器相关的特定问题，例如 gVisor，它在容器和 OS 之间提供了额外的安全层。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093132603-2021-07-01-8jh68O.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093137560-2021-07-01-rPR0k3.png" alt></p><h3><span id="云原生网络">云原生网络</span></h3><p><strong>是什么</strong></p><p>容器通过云原生网络实现相互之间及和基础设施层之间的通信。分布式应用程序具有多个组件，这些组件将网络用于不同目的。此类别中的工具将虚拟网络覆盖在现有网络之上，专门用于应用程序进行通信，称为覆盖网络（overlay network)。</p><p><strong>解决什么问题</strong></p><p>通常我们将在容器中运行的代码称为应用程序，但实际上，大多数容器中仅包含大型应用程序的一小部分特定功能。诸如 Netflix 或 Gmail 之类的现代应用程序实际上由许多较小的组件组成，每个组件都在自己的容器中运行。为了使所有这些独立的部分正常运行组成一个完整的应用，容器之间需要相互通信。此类别的工具就提供该专用通信网络。</p><p>此外，这些容器之间交换的消息可能是私密的、敏感的或者非常重要的。这导致了其他要求：例如为各种组件提供隔离，检查流量以识别网络问题的能力。在某些情况下，可能还需要拓展这些网络及网络策略（如防火墙和访问规则），以便应用程序可以连接到容器网络外部运行的 VM 或服务。</p><p><strong>如何解决</strong></p><p>此类别中的项目和产品使用 CNCF 中的项目——容器网络接口（Container Network Interface, CNI）为容器化应用提供网络功能。某些工具（例如 Flannel）仅为容器提供基本连接。其他工具（如 NSX-T）提供了完整的软件定义网络层，可为每个 Kubernetes 名称空间创建一个隔离的虚拟网络。</p><p>容器网络至少应该能为 Pod（Kubernetes 中运行容器化应用的地方）分配 IP 地址，以允许其他进程访问。</p><p><strong>对应工具</strong></p><p>CNI 标准化了网络层为 Pod 提供功能的方式，这在很大程度上实现了该领域的多样性和创新性。为 Kubernetes 环境选择网络非常关键，有许多工具可选。Weave Net，Antrea，Calico 和 Flannel 均提供有效的开源网络层，它们的功能各不相同，应根据特定需求进行选择。</p><p>此外，许多供应商已准备好使用软件定义网络（SDN）工具来支持和扩展 Kubernetes 网络，这些工具可使你深入了解网络流量，执行网络策略，甚至将容器网络和策略扩展到更广泛的数据中心。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093142946-2021-07-01-Y6M0IO.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093148358-2021-07-01-L7I3yd.png" alt></p><p>本文是对运行时层的概述，该层提供了容器在云原生环境中运行所需的工具，包括：</p><ul><li><p>存储：使应用程序轻松快速访问运行所需的数据；</p></li><li><p>容器运行时：执行应用程序代码；</p></li><li><p>网络：确保容器化应用程序之间的通信。</p></li></ul><p>在下一章节中，我们将探索编排和管理层，该层处理的是如何将所有容器化应用程序作为一个组进行管理。</p><h2><span id="编排和管理层">编排和管理层</span></h2><p>编排和管理层是 CNCF 云原生全景图的第三层。在使用这一层的工具之前，工程师大概已经按照安全合规标准自动配置了基础设施，并为应用程序设置了运行时（运行时层）。现在，他们必须弄清楚如何将所有应用程序组件作为整体来编排和管理。这些组件必须相互识别以进行通信，并通过协调实现共同的目标。编排和管理层的工具可实现自动化和弹性伸缩，基于此云原生应用程序天然具有可扩展性。</p><h3><span id="编排和调度">编排和调度</span></h3><p><strong>是什么</strong></p><p>编排和调度是指在集群中运行和管理容器（一种打包和运送应用的新方式）。集群是通过网络连接的一组机器（物理机或虚拟机均可）。</p><p>容器编排器（和调度器）与电脑上管理所有应用程序（如微软 360、Zoom、Slack 等）的操作系统类似。操作系统执行你想使用的应用程序，并规划哪个应用程序该在何时使用电脑的 CPU 和其他硬件资源。</p><p>虽然在一台机器上运行所有东西很棒，但如今大多数应用程序的大小远非一台机器所能处理，大多数现代的应用程序都是分布式的，这就需要一种软件能够管理在不同机器上运行的组件。简单来说，你需要一个“集群操作系统”。这就是编排工具。</p><p>你可能已经注意到了，在本系列的前几篇文章中，容器频繁出现。容器可以让应用程序运行在不同的环境中，这种能力是关键。容器编排器（大多数情况下是指 Kubernetes）也是如此。容器和 Kubernetes 是云原生架构的核心，所以我们总是听到别人提起它们。</p><p><strong>解决的问题</strong></p><p>在云原生架构中，应用程序被分解成很多小的组件或服务，每个组件或服务都放在一个容器里。你可能已经听说过微服务，指的就是这种情况。现在，你拥有的不再是一个大型的应用程序，而是多个小型的服务，每个服务都需要资源、要被监控，在出现问题的时候也需要修复。对单个服务来说手动执行这些操作是可行的，但当你有上百个容器时，你就需要自动化的流程。</p><p><strong>如何解决</strong></p><p>容器编排器自动化了容器管理的过程。这在实际操作中意味着什么？让我们以 Kubernetes 来回答这个问题，因为 Kubernetes 是事实上的容器编排器。</p><p>Kubernetes 做的事情是“期望状态协调”：将集群中容器的当前状态与期望状态匹配。工程师在文件中指定所需状态，例如：服务 A 的 10 个实例在三个节点（即：机器）上运行，可访问 B 数据库，等等。该状态需持续与实际状态进行比较。如果预期状态与实际状态不匹配，Kubernetes 会通过创建或销毁对象来进行协调（例如：如果某个容器崩溃了，Kubernetes 会启动一个新的容器）。</p><p>简而言之，Kubernetes 允许你将集群视为一台计算机。它仅关注环境并为你处理实现细节。</p><p><strong>对应工具</strong></p><p>Kubernetes 与其他容器编排器（Docker Swarm，Mesos 等）都是编排调度工具，其基本目的是允许将多个不同的计算机作为一个资源池进行管理，并以声明式的方式管理它们，即不必告诉 Kubernetes 如何做，而是提供要完成的工作的定义。这样可以在一个或多个 YAML 文件中维护所需的状态，并将其应用于其他 Kubernetes 集群。然后，编排器本身会创建缺失的内容或删除无需存在的东西。</p><p>虽然 Kubernetes 不是 CNCF 托管的唯一编排器（Crossplane 和 Volcano 是另外两个孵化项目），但它是最常用的，项目也有大量积极的维护者。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093201238-2021-07-01-bGT6MM.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093205543-2021-07-01-STL1m3.png" alt></p><h3><span id="协调和服务发现">协调和服务发现</span></h3><p><strong>是什么</strong></p><p>现代应用程序由多个单独的服务组成，这些服务之间需要相互协作才能为最终用户提供价值。要进行协作，这些服务通过网络进行通信（我们在运行时层已经讨论过）。要通信，服务需要能相互定位。服务发现就是解决这个问题的。</p><p><strong>解决的问题</strong></p><p>云原生架构是动态的，总是在不断变化。当一个节点上的某个容器崩溃时，一个新的容器会在另一个节点上启动来替代它。或者，当一个应用程序扩展时，它的副本会散布在整个网络中。没有一个地方可以提供特定服务，一切的位置在不断变化。此类别的工具跟踪网络中的服务，以便服务在需要时可以相互查找。</p><p><strong>如何解决</strong></p><p>服务发现工具可提供一个公共的位置来查找和识别单个的服务。该类别中有两种工具：</p><ul><li><p>服务发现引擎：类似数据库的工具，存储的信息包括：存在什么哪些服务以及如何定位它们；</p></li><li><p>名称解析工具（如 CoreDNS）：接收服务位置请求并返回网络地址信息。</p></li></ul><p>注：在 Kubernetes 中，为了使 Pod 可达，引入了一个称为“Service”的新抽象层。Service 为动态变化的 Pod 组提供了单一稳定的地址。</p><p>请注意，“Service” 在不同的语境中有不同的含义，可能会造成混淆。“services” 通常指位于容器/Pod 中的服务，是实际应用程序中具有特定功能的应用组件或微服务（例如：iPhone 的面部识别算法）。<br>而 Kubernetes 的 Service 是一种抽象，可帮助 Pod 相互查找和定位。它是服务（功能上的）作为进程或 Pod 的入口点。在 Kubernetes 中，当你创建了一个 Service （抽象），你就创建了一组 Pod，这些 Pod 一起通过单一 endpoint （入口）提供一个服务（功能）。</p><p><strong>对应工具</strong></p><p>随着分布式系统变得越来越普遍，传统的 DNS 流程和负载均衡器已经无法跟上不断变化的 Endpoint 信息，因此有了服务发现工具。它们可用来处理快速对自身进行注册和注销的各个应用程序实例。一些服务发现工具（例如 etcd 和 CoreDNS）是 Kubernetes 原生的，其他一些工具有自定义的库或工具让服务有效运行。CoreDNS 和 etcd 是 CNCF 项目，并且内置在 Kubernetes 中。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093212167-2021-07-01-tNqnoy.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093215933-2021-07-01-4ZjVnW.png" alt></p><h3><span id="远程进程调用">远程进程调用</span></h3><p><strong>是什么</strong></p><p>远程进程调用（RPC，Remote Procedure Call）是一种使应用程序相互通信的特殊技术。它代表了应用程序相互之间构建通信的一种方法。</p><p><strong>解决的问题</strong></p><p>现代应用程序由众多单独的服务组成，这些服务必须通过通信才能进行协作。RPC 是应用程序之间进行通信的一种方法。</p><p><strong>如何解决</strong></p><p>RPC 可以一种紧耦合且高度自觉的方式处理服务之间的通信。它允许带宽高效的通信，并且许多语言支持 RPC 接口实现。RPC 不是解决此问题的唯一方法，也不是最常见的方法。</p><p><strong>对应工具</strong></p><p>RPC 为服务之间的通信提供了高度结构化且紧密耦合的接口。gRPC 是非常流行的 RPC 实现，已被 CNCF 采用。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093222708-2021-07-01-YGvWn7.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093226688-2021-07-01-P4glNj.png" alt></p><h3><span id="服务代理">服务代理</span></h3><p><strong>是什么</strong></p><p>服务代理工具用于拦截进出某个服务的流量，对其应用一些逻辑，然后转发该流量到另一个服务。服务代理的本质是一种“中间人”，收集网络流量的信息并对其应用规则。简单如充当负载均衡器将流量转发到单个应用程序，也可复杂如并排运行的代理网格，由单个的容器化应用程序处理所有网络连接。</p><p>服务代理本身很有用，尤其是在将流量从更广泛的网络引到 Kubernetes 集群时。服务代理同时也为其他系统（如 API 网关或服务网格）搭建了基础，我们将在下文讨论。</p><p><strong>解决的问题</strong></p><p>应用程序应以受控方式发送和接收网络流量。为了跟踪流量并对其进行转换或重定向，我们需要收集数据。传统上，开启数据收集和网络流量管理的代码嵌入在每个应用程序中。服务代理可以使我们“外部化”该功能，使其无需再存在于应用程序中，而是嵌入到平台层（应用程序运行的地方）。</p><p>这是非常强大的功能，因为它使开发人员可以完全专注于编写应用程序逻辑，而处理流量的通用任务由平台团队管理（这是平台团队的首要职责）。通过从单个公共位置集中分配和管理全局所需的服务功能（例如路由或 TLS 终止），服务之间的通信将更加可靠，安全和高效。</p><p><strong>如何解决</strong></p><p>代理充当用户和服务之间或不同服务之间的守门员。通过这种独特的定位，他们可以洞悉正在发生的通信类型。根据洞察，他们可以确定将特定请求发送到哪里，甚至完全拒绝该请求。</p><p>代理收集关键数据，管理路由（在服务之间平均分配流量或在某些服务发生故障时重新路由），加密连接和缓存内容（减少资源消耗）。</p><p><strong>对应工具</strong></p><p>服务代理的工作原理是拦截服务之间的流量，对它们执行一些逻辑，然后可能会允许流量继续前进。通过将一组集中控制的功能放入此代理，管理员可以完成几件事。他们可以收集有关服务间通信的详细指标，防止服务过载，并将其他通用标准应用于服务。服务代理是服务网格等其他工具的基础，因为它们提供了对所有网络流量实施更高级别策略的方法。</p><p>请注意，CNCF 将负载均衡器和 ingress provider 包括在此类别中。Envoy，Contour 和 BFE 都是 CNCF 项目。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093233111-2021-07-01-5S9Thb.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093237043-2021-07-01-088mPy.png" alt></p><h3><span id="api-网关">API 网关</span></h3><p><strong>是什么</strong></p><p>人们通常通过网页或（桌面）应用程序之类的 GUI（图形用户界面）与计算机程序进行交互，计算机则通过 API（应用程序编程接口）相互进行交互。但是，请勿将 API 与 API 网关混淆。</p><p>API 网关允许组织将关键功能（例如授权或限制应用程序之间的请求数量）移动到集中管理的位置。它还用作（通常是外部的）API 使用者的通用接口。</p><p>通过 API 网关，组织可以集中控制（限制或启用）应用程序之间的交互并跟踪它们，从而实现 拒绝请求、身份验证之类的功能，并防止服务被过度使用（也称为速率限制）。</p><p><strong>解决的问题</strong></p><p>尽管大多数容器和核心应用程序都具有 API，但 API 网关不仅仅是 API。API 网关简化了组织管理规则和将规则应用于所有交互的方式。</p><p>API 网关允许开发人员编写和维护较少的自定义代码。他们还使团队能够查看和控制用户与应用程序本身之间的交互。</p><p><strong>如何解决</strong></p><p>API 网关位于用户和应用程序之间。它充当中介，将来自用户的消息（请求）转发给适当的服务。但是在交出请求之前，它会评估用户的请求是否被允许，并详细记录发出请求的人以及发出的请求数量。</p><p>简而言之，API 网关为应用程序用户提供了具有通用用户界面的单入口点。它还可以将原本在应用程序中实现的任务移交给网关，从而为开发人员节省时间和金钱。</p><p><strong>对应工具</strong></p><p>像该层中的许多类别一样，API 网关从应用程序中删除自定义代码，并将其带入中央系统。API 网关的工作原理是拦截对后端服务的调用，执行某种增值活动，例如验证授权、收集指标或转换请求，然后执行它认为适当的操作。API 网关是一组下游应用程序的通用入口点，同时为团队提供了可以注入业务逻辑以处理授权，速率限制和拒绝请求的地方。它们使应用开发者可以从客户那里提取对下游 API 的更改，并将添加新客户之类的任务交给网关。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093243827-2021-07-01-Qx1HJs.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093247594-2021-07-01-utpero.png" alt></p><h3><span id="服务网格">服务网格</span></h3><p><strong>是什么</strong></p><p>如果你已经了解了一些云原生相关的知识，则“服务网格”这个术语可能已经听说过。最近服务网格引起了很多关注。TNS 的长期贡献者 Janakiram MSV 表示，“在 Kubernetes 之后，服务网格技术已成为云原生技术栈中最关键的部分。” 服务网格管理服务之间的流量（即通信）。它们使平台团队能够无需更改任何代码即可在集群内运行的所有服务之间统一添加可靠性，可观察性和安全性功能。</p><p><strong>解决什么问题</strong></p><p>在云原生环境中，我们要处理很多服务，这些服务都需要通信。这意味着在本来不可靠且通常很慢的网络上需要来回传输更多流量。为了应对这些新挑战，工程师必须实施额外的功能。在服务网格之前，必须将该功能编码到每个单独的应用程序中。这些代码通常会成为技术债，并导致失败或漏洞。</p><p><strong>如何解决</strong></p><p>服务网格在平台层的所有服务之间统一增加了可靠性，可观察性和安全性，而无需触及应用程序代码。它们与任何编程语言兼容，使开发团队可以专注于编写业务逻辑。</p><p>注：传统上必须将这些服务网格功能编码到每个服务中，因此每次发布或更新新服务时，开发人员都必须确保这些功能也能使用，会导致很多人为错误。事实上，开发人员更喜欢专注于业务逻辑（产生价值的功能），而不是建立可靠性，可观察性和安全性功能。但对于平台所有者来说，可靠性、可观察性和安全是核心功能，对于他们所做的一切至关重要。让开发人员负责添加平台所有者需要的功能本身很难。服务网格和 API 网关解决了这个问题，因为它们是由平台所有者实现并普遍应用于所有服务的。</p><p><strong>对应工具</strong></p><p>服务网格通过服务代理将集群上运行的所有服务绑定在一起，从而创建了服务的网格。这些是通过服务网格控制平面进行管理和控制的。服务网格允许平台所有者在不要求开发人员编写自定义逻辑的情况下执行常见操作或在应用程序上收集数据。本质上，服务网格是通过向服务代理的网络或网格提供命令和控制信号来管理服务间通信的基础结构层。它的能力在于无需修改应用程序即可提供关键系统功能。</p><p>某些服务网格将通用服务代理（请参见上文）用于其数据平面。另外一些则使用专用代理。例如，Linkerd 使用 Linkerd2-proxy “微型代理”来获得性能和资源消耗方面的优势。这些代理通过边车（sidecar) 统一地附加到每个服务上。Sidecar 是指代理在自己的容器中运行但存在于同一个 Pod 中，就像摩托车边车一样，它是一个单独的模块，附着在摩托车上。</p><p>服务网格提供了许多有用的功能，包括显示详细指标，加密所有流量，限制服务可授权的操作，为其他工具提供额外插件等等。更多详细信息，请查看服务网格接口规范：<a href="https://smi-spec.io/" target="_blank" rel="noopener">https://smi-spec.io/</a></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093253303-2021-07-01-2vllxs.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093258142-2021-07-01-UBbI8l.png" alt></p><p><strong>小结</strong></p><p>编排和管理层的工具旨在将独立的容器化应用作为一个组进行管理。编排和调度工具可以看作是集群操作系统，用于管理整个集群中的容器化应用程序。协调和服务发现，服务代理和服务网格确保服务可以找到彼此并进行有效通信，彼此协作以成为一个流畅的应用程序。API 网关是一个附加层，可对服务通信加以更多控制，尤其是对外部应用程序之间的通信。在下一章节中，我们将讨论应用程序定义和开发层——CNCF 全景图的最后一层。它涵盖数据库、数据流和消息传递、应用程序定义和镜像构建，以及持续集成和交付。</p><h2><span id="应用程序定义和开发层">应用程序定义和开发层</span></h2><p>现在我们来到了云原生全景图的最上层。应用程序定义和开发层，顾名思义，聚焦在帮助工程师构建应用程序并使其运行的工具上。本文前面的内容都是关于构建可靠安全的环境以及提供所有必需的应用程序依赖，应用程序定义和开发层则是关于构建软件。</p><h3><span id="数据库">数据库</span></h3><p><strong>是什么</strong></p><p>数据库管理系统是一个应用程序，可帮助其他应用程序高效地存储和检索数据。</p><p>数据库能保障数据存储，仅授权的用户能访问数据，并且允许用户通过专门的请求来检索数据。尽管数据库类型繁多，但它们的总体目标都是相同的。</p><p><strong>解决的问题</strong></p><p>大多数应用程序都需要有效的方式来存储和检索数据，并且保证数据安全。数据库使用成熟的技术以结构化的方式进行此操作。</p><p><strong>如何解决</strong></p><p>数据库提供存储和检索应用程序数据的通用接口。开发人员使用这些标准接口，并用一种简单的查询语言来存储、查询和检索信息。同时，数据库允许用户连续备份和保存数据以及加密和管理数据访问权限。</p><p><strong>对应工具</strong></p><p>我们已经了解了数据库管理系统是一种用于存储和检索数据的应用程序。它使用一种通用的语言和界面，并且可以被多种语言和框架轻松使用。</p><p>常见的两种数据库类型为：结构化查询语言（SQL）数据库和 NoSQL 数据库。应用程序该使用哪种数据库应该由其需求来驱动。</p><p>Kubernetes 支持有状态的应用程序，近年来使用 Kubernetes 的使用越来越广泛，我们已经看到了利用容器化技术的新一代数据库。这些新的云原生数据库旨在将 Kubernetes 的扩展性和可用性优势引入数据库。YugaByte 和 Couchbase 之类的工具是典型的云原生数据库，Vitess 和 TiKV 是该领域的 CNCF 项目。</p><p>注意：查看此类别时会发现以 DB 结尾的多个名称（例如 MongoDB、CockroachDB、FaunaDB），你可能会猜测它们代表数据库。还有以 SQL 结尾的各种名称（例如 MySQL 或 MemSQL）。一些是已经适应了云原生环境的“老派”数据库，还有一些是兼容 SQL 的 NoSQL 数据库，例如 YugaByte 和 Vitess。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093304995-2021-07-01-3QynTd.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093312213-2021-07-01-6mHNQW.png" alt></p><h3><span id="数据流和消息传递">数据流和消息传递</span></h3><p><strong>是什么</strong></p><p>数据流和消息传递工具通过在系统之间传输消息（即事件）来实现服务到服务的通信。单个服务连接到消息传递服务以发布事件和（或）从其他服务读取消息。这种动态变化创造了一个环境，在这个环境中单个应用要么是发布者，即可编写事件；要么是订阅事件的订阅者，或者更可能是两者兼而有之。</p><p><strong>解决的问题</strong></p><p>随着服务激增，应用程序环境变得越来越复杂，应用程序之间的通信编排也更具挑战性。数据流或消息平台提供了一个中心位置来发布和读取系统中发生的所有事件，从而使应用程序可以一起工作，而不必相互了解。</p><p><strong>如何解决</strong></p><p>当一个服务执行其他服务应该知道的事情时，它会将事件“发布”到数据流或消息传递工具。需要了解这些事件类型的服务将订阅并监视数据流或消息传递工具。这就是“发布-订阅”的本质。</p><p>通过引入管理通信的“中间层”可以使服务彼此解耦。服务只是监视事件、采取行动并发布新事件，这样能建立高度分离的体系结构。在此体系结构中，服务可以协作而无需彼此了解。这种解耦使工程师能够添加新功能，而无需更新下游应用程序（消费者）或发送大量查询。系统的解耦程度越高，更改的灵活性和适应性就越高，而这正是工程师在系统中所追求的。</p><p><strong>对应工具</strong></p><p>数据流和消息传递工具早在云原生技术成为现实之前就已经存在了。为了集中管理关键业务事件，组织建立了大型的企业级服务总线。但是，当我们在云原生环境中谈论数据流和消息传递时，通常是指 NATS、RabbitMQ、Kafka 或云提供的消息队列之类的工具。</p><p>消息传递和数据流传输系统为编排系统进行通信提供了一个中心位置。消息总线提供了所有应用程序都可以访问的公共位置，应用程序都可以通过发布消息来告诉其服务它们在做什么，或者通过订阅消息来查看正在发生的事情。</p><p>NATS 和 Cloudevents 项目都是这个领域的孵化项目，NATS 提供了一个成熟的消息传递系统，而 Cloudevents 则致力于标准化系统之间的消息格式。Strimzi，Pravega 和 Tremor 是沙盒项目，每个项目都针对数据流和消息传递的独特用例进行了量身定制。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093318671-2021-07-01-gHqk5T.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093324256-2021-07-01-qymLXJ.png" alt></p><h3><span id="应用程序定义和镜像构建">应用程序定义和镜像构建</span></h3><p><strong>是什么</strong></p><p>应用程序定义和镜像构建是一个广泛的类别，可以分为两个主要的子类别：</p><ul><li><p>聚焦于开发的工具：可帮助将应用程序代码构建到容器和（或）Kubernetes 中；</p></li><li><p>聚焦于运维的工具：以标准化的方式部署应用。</p></li></ul><p>无论是加快或简化开发环境，提供标准化的方式来部署第三方应用程序，还是简化编写新的 Kubernetes 扩展的过程，此类别的工具都可以优化 Kubernetes 开发和运维人员的体验。</p><p><strong>解决的问题</strong></p><p>Kubernetes（或者容器化环境）非常灵活且功能强大。这种灵活性也带来了复杂性，主要体现在对于各种新用例有众多配置选项。开发人员必须将代码容器化，并在类生产环境中进行开发。在快速的发布计划周期下，运维人员需要以一种标准化的方法来将应用程序部署到容器环境中。</p><p><strong>如何解决</strong></p><p>该领域的工具旨在解决开发或运维人员面临的一些挑战。对于开发者，有一些工具可以简化扩展 Kubernetes 的过程以构建、部署和连接应用程序。许多项目和产品可以存储或部署预打包的应用程序，使运维人员可以快速部署 Kafka 之类的流服务或安装 Linkerd 之类的服务网格。</p><p>开发云原生应用程序带来了一系列全新的挑战，因此需要大量多样化的工具来简化应用程序的构建和部署。当你需要解决环境中的开发和运维问题时，可以看看此类别中的工具。</p><p><strong>对应的工具</strong></p><p>应用程序定义和构建工具涵盖了广泛的功能，比如使用 KubeVirt 将 Kubernetes 扩展到虚拟机，或使用 Telepresence 之类的工具将开发环境移植到 Kubernetes 中来加速应用程序开发等。从整体上讲，该领域中的工具可以解决开发人员面临的正确编写、打包、测试或运行自定义应用程序的问题，也可以解决运维人员面临的部署和管理应用程序的问题。</p><p>Helm 是该类别中唯一一个毕业的项目，为许多应用程序部署模式奠定了基础。Helm 允许 Kubernetes 用户部署和自定义一些流行的第三方应用程序，Artifact Hub（CNCF 沙箱项目）和 Bitnami 等项目已采用 Helm 来提供精选的应用程序目录。Helm 也足够灵活，允许用户自定义自己的应用程序部署。</p><p>Operator Framework 是一个孵化项目，旨在简化构建和部署 Operator 的过程。Operator 不在本文讨论范围之内，但请注意，它类似于 Helm，有助于部署和管理应用程序。Cloud Native Buildpacks 是另一个孵化项目，旨在简化将应用程序代码构建到容器中的过程。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093331777-2021-07-01-pEdIp6.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093345215-2021-07-01-PskDZz.png" alt></p><h3><span id="持续集成和持续交付">持续集成和持续交付</span></h3><p><strong>是什么</strong></p><p>持续集成（CI）和持续交付（CD）工具可通过嵌入式质量保证实现快速高效的开发过程。CI 通过立即构建和测试代码来自动化代码变更，确保生成可部署的制品。CD 则更进一步，推动该制品进入部署阶段。</p><p>成熟的 CI/CD 系统会监视源代码中的变更，自动构建和测试代码，然后将其从开发阶段转移到生产阶段。在此过程中，CI/CD 系统必须通过各种测试或验证来决定该过程是继续还是失败。</p><p><strong>解决的问题</strong></p><p>构建和部署应用程序是一个困难重重且容易出错的过程，特别是当过程中涉及很多人为干预和手动步骤时。如果不将代码集成到代码库中，开发人员在软件上花的时间越长，识别错误所花费的时间就越长，问题修复也就越困难。通过定期集成代码，可以及早发现错误并更轻松地排除故障。毕竟，在几行代码中查找错误比在几百行代码中查找错误要容易得多。</p><p>尽管 Kubernetes 之类的工具为运行和管理应用程序提供了极大的灵活性，它们也为 CI/CD 工具带来了新的挑战和机遇。云原生 CI/CD 系统能够利用 Kubernetes 本身来构建、运行和管理 CI/CD 流程（通常称为流水线）。Kubernetes 还提供应用程序运行状况的信息，从而使云原生 CI/CD 工具能够更轻松地确定给定的变更是否成功，是否需要回滚。</p><p><strong>如何解决</strong></p><p>CI 工具可确保开发人员引入的任何代码更改或更新都能自动、连续地与其他更改进行构建、验证并集成。开发人员每次添加更新时都会触发自动测试，确保只有良好的代码才能将其导入系统。CD 扩展了 CI，能将 CI 流程的结果推送到类生产和生产环境中。</p><p>假设开发人员更改了 Web 应用的代码。CI 系统会看到代码更改，然后构建并测试该 Web 应用的新版本。CD 系统获取该新版本，并将其部署到开发、测试、预生产以及最终生产环境中。在流程的每个步骤之后测试已部署的应用程序时，它会执行此操作。这些系统一起构成了该 Web 应用的 CI/CD 管道。</p><p><strong>对应工具</strong></p><p>随着时间的流逝，市面上已经有了许多工具来帮助将代码从存储库移至运行最终应用程序的生产环境。像大多数其他计算领域一样，云原生开发的到来改变了 CI/CD 系统。类似 Jenkins （可能是市场上使用最广泛的 CI 工具）的传统工具已经通过完善迭代，以更好地适应 Kubernetes 生态系统。Flux 和 Argo 等公司率先开发了一种称为 GitOps 的持续交付的新方法。</p><p>通常，该领域的项目和产品是：</p><ul><li><p>CI 系统；</p></li><li><p>CD 系统；</p></li><li><p>帮助 CD 系统确定代码是否准备好投入生产的工具；和（或）</p></li><li><p>前三者的合集（Spinnaker 和 Argo 就是如此）。</p></li></ul><p>Argo 和 Brigade 是该领域中仅有的 CNCF 项目，但是你可以找到由持续交付基金会（Continuous Delivery Foundation）托管的更多项目。在此空间中寻找工具，可以帮助组织自动化生产路径。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093351066-2021-07-01-XbCg1R.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093357187-2021-07-01-6b4TjE.png" alt></p><p><strong>小结</strong></p><p>应用程序定义和开发层中的工具使工程师能够构建云原生应用程序。该层的工具包括：</p><ul><li><p>数据库：存储和检索数据；</p></li><li><p>数据流和消息传递工具：实现相互分离、精心设计的架构；</p></li><li><p>应用程序定义和镜像构建工具：包含可改善开发人员和操作员体验的多种技术；</p></li><li><p>CI/CD 工具：确保代码处于可部署状态，并帮助工程师及早发现错误，从而确保代码质量。</p></li></ul><h2><span id="托管-kubernetes-和-paas-解决什么问题">托管 Kubernetes 和 PaaS 解决什么问题</span></h2><p>在之前的内容中，我们讨论了 CNCF 云原生全景图的各层：供应层、运行时层、编排管理层以及应用定义和开发层。本章节我们将聚焦在平台层。</p><p>正如我们在本系列文章中看到的那样，每个类别都解决了特定的问题。仅仅存储并不能提供管理应用程序所需的全部功能，你还需要编排管理、容器运行时、服务发现、网络、API 网关等工具。平台将来自不同层的工具捆绑在一起，以解决更大的问题。</p><p>平台里其实没有新的工具。你当然可以构建自己的平台，事实上，许多组织都这样做。但是，可靠、安全地配置和微调不同的模块，同时确保始终更新所有技术并修补漏洞，这不是一件容易的事。你需要一支专门的团队来构建和维护它。如果没有所需的专业知识，那么使用平台可能会更好。对于某些组织，尤其是工程团队规模较小的组织，平台是采用云原生技术的唯一方法。</p><p>你可能已经注意到了，所有的平台都是围绕 Kubernetes 来演化的，因为 Kubernetes 是云原生技术栈的核心。</p><h3><span id="kubernetes-发行版">Kubernetes 发行版</span></h3><p><strong>是什么</strong></p><p>发行版是指供应商以 Kubernetes 为核心（采用未经修改的开源代码，尽管有些人对其进行了修改），并将其打包以进行重新发行。通常这个过程需要查找和验证 Kubernetes 软件，并提供集群安装和升级的机制。许多 Kubernetes 发行版都包含其他闭源或开源的应用程序。</p><p><strong>解决的问题</strong></p><p>开源 Kubernetes 并未指定特定的安装工具，而是将许多设置配置选项提供给用户。此外，有限的社区资源（包括社区论坛、StackOverflow、Slack 或 Discord 等）已经不能解决所有的问题。</p><p>随着 Kubernetes 的普及，Kubernetes 的使用变得越来越容易，但是查找和使用开源安装程序可能会面临挑战。用户需要了解使用哪个版本，在何处获取，以及特定组件是否能兼容。此外，还需要决定集群上部署什么软件，要使用哪些设置来确保平台的安全性、稳定性和高性能。所有这些都需要丰富的 Kubernetes 专业知识，而这些知识可能并不容易获得。</p><p><strong>如何解决</strong></p><p>Kubernetes 发行版提供了一种安装 Kubernetes 的可靠方式，并提供了合理的默认值以创建更好、更安全的操作环境。Kubernetes 发行版为供应商和项目提供了所需的掌控度和可预测性，以帮助他们支持客户部署、维护和升级 Kubernetes 集群。</p><p>这种可预测性使发行版提供商在客户遇到生产问题时可为其提供支持。发行版常常提供经过测试和受支持的升级路径，使用户的 Kubernetes 集群保持最新的版本。此外，发行版通常提供可在 Kubernetes 上部署的软件，从而使其更易于使用。</p><p><strong>对应的工具</strong></p><p>如果你已经安装了 Kubernetes，那你可能已经使用了 kubeadm 之类的工具来启动和运行集群。即便如此，你可能还需要 CNI（容器网络接口）来安装和配置它。然后，你可能已经添加了一些存储类，一个处理日志消息的工具，可能还需要个 ingress controller，以及更多其他的工具。Kubernetes 发行版将自动执行部分或全部设置。它还将根据自己对最佳实践或智能默认值的理解提供配置设置。此外，大多数发行版都将捆绑一些经过测试的扩展或附件，以确保用户可以尽快使用新集群。</p><p>我们以 Kublr 为例。它以 Kubernetes 为核心，主要捆绑了来自供应层、运行时层、编排管理层的工具。所有模块都预先配置了一些选项并且开箱即用。不同的平台聚焦不同的功能。就 Kublr 而言，重点是在运维方面，而其他平台则可能聚焦在开发工具上。</p><p>此类别中有很多工具选项。如下图所示，企业可以选择和供应商达成技术合作，比如国外的 Canonical、VMware、Mirantis、SUSE，国内的网易、火山引擎和京东，它们都可以提供出色的开源和商业工具，建议在评估发行版时仔细考虑自己的需求。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093404009-2021-07-01-fNGqFM.png" alt></p><h3><span id="托管-kubernetes">托管 Kubernetes</span></h3><p><strong>是什么</strong></p><p>托管 Kubernetes 是由 Amazon Web Services（AWS）、DigitalOcean、Azure 或 Google 等基础设施提供商（云厂商）提供的服务，允许客户按需启动 Kubernetes 集群。云厂商负责管理 Kubernetes 集群的一部分，通常称为控制平面。托管 Kubernetes 服务与发行版相似，但由云厂商在其基础架构上进行管理。</p><p><strong>解决的问题</strong></p><p>托管 Kubernetes 使团队只需在云厂商开设一个账户即可开始使用 Kubernetes。它解决了 Kubernetes 入门五个过程中的“五 W”问题：</p><ul><li><p>Who：云厂商；</p></li><li><p>What：他们托管的 Kubernetes 产品；</p></li><li><p>When：现在；</p></li><li><p>Where：云厂商的基础架构上；</p></li><li><p>Why：由你决定。</p></li></ul><p><strong>如何解决</strong></p><p>由于 Kuberentes 托管服务提供商负责管理所有细节，因此托管的 Kubernetes 服务是开始云原生之路的最简单方法。用户所需要做的就是开发自己的应用程序并将其部署在托管的 Kubernetes 服务上，这非常方便。托管产品允许用户启动 Kubernetes 集群并立即开始，同时对集群可用性承担一些责任。值得注意的是，这些服务的额外便利性会造成灵活性的降低：托管的 Kubernetes 服务和云厂商绑定，且用户无法访问 Kubernetes 控制平面，因此某些配置选项会受到限制。</p><p>AWS 的 EKS 略有例外，因为它还要求用户采取一些其他步骤来准备集群。</p><p><strong>对应的工具</strong></p><p>托管 Kubernetes 是由供应商（通常是基础架构托管提供商）提供的按需使用的 Kubernetes 集群，供应商负责配置群集和管理 Kubernetes 控制平面。再次说明，值得注意的例外是 EKS，其上的单个节点配置由客户端决定。</p><p>托管 Kubernetes 服务使组织可以将基础架构组件管理外包出去，这样可以快速配置新集群并降低运营风险。主要的权衡取舍在于可能需要为控制平面管理付费，并且用户的管理权限有限。与自己搭建 Kubernetes 群集相比，托管服务在配置 Kubernetes 群集方面有更严格的限制。</p><p>在这个领域中有许多供应商和项目，在撰写本文时，尚无 CNCF 项目。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093412427-2021-07-01-87PjDr.png" alt></p><h3><span id="kubernetes-安装程序">Kubernetes 安装程序</span></h3><p><strong>是什么</strong></p><p>Kubernetes 安装程序可帮助你在机器上安装 Kubernetes，它们可自动化 Kubernetes 的安装和配置过程，甚至可以帮助升级。Kubernetes 安装程序通常与 Kubernetes 发行版或托管 Kubernetes 产品结合使用或由它们使用。</p><p><strong>解决的问题</strong></p><p>与 Kubernetes 发行版相似，Kubernetes 安装程序可简化 Kubernetes 的上手过程。开源的 Kubernetes 依赖于 kubeadm 之类的安装程序。截至本文撰写之时，kubeadm 可用于启动和运行 Kubernetes 集群，是 CKA（Kubernetes 管理员认证） 测试的一部分。</p><p><strong>如何解决</strong></p><p>Kubernetes 安装程序简化了 Kubernetes 的安装过程。像发行版一样，它们为源代码和版本提供经过审核的源。它们还经常自带 Kubernetes 环境配置。像 kind （Docker 中的 Kubernetes）这样的 Kubernetes 安装程序允许通过单个命令获得 Kubernetes 集群。</p><p><strong>对应的工具</strong></p><p>无论是在 Docker 上本地安装 Kubernetes，启动和配置新的虚拟机，还是准备新的物理服务器，都需要一个工具来处理各种 Kubernetes 组件的准备工作。</p><p>Kubernetes 安装程序可简化该过程。有些处理节点启动，还有一些仅配置已供应的节点。它们都提供不同程度的自动化，并且适合不同的用例。开始使用 Kubernetes 安装程序时，应先了解自己的需求，然后选择可以满足这些需求的安装程序。在撰写本文时，kubeadm 是 Kubernetes 生态系统中至关重要的工具，已包含在 CKA 测试中。Minikube、kind、kops 和 kubespray 都是 CNCF 中的 Kubernetes 安装程序项目。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093420040-2021-07-01-E21xtN.png" alt></p><h3><span id="paas容器服务">PaaS/容器服务</span></h3><p><strong>是什么</strong></p><p>PaaS（平台即服务）是一种环境，允许用户运行应用程序而不必了解底层计算资源。此类别中的 PaaS 和容器服务是一种机制，可为开发人员托管 PaaS 或托管他们可以使用的服务。</p><p><strong>解决的问题</strong></p><p>在本篇文章中，我们讨论了有关“云原生”的工具和技术。PaaS 连接了此领域中的许多技术，可为开发人员提供直接价值。它回答了以下问题：</p><ul><li><p>我如何在各种环境中运行应用程序？</p></li><li><p>一旦应用程序运行起来，我的团队和用户将如何与它们交互？</p></li></ul><p><strong>如何解决</strong></p><p>PaaS 为组合运行应用程序所需的开源和闭源工具提供了选择。许多 PaaS 产品包含处理 PaaS 安装和升级的工具，以及将应用程序代码转换为正在运行的应用程序的机制。此外，PaaS 可以处理应用程序实例的运行时需求，包括按需扩展单个组件以及可视化单个应用程序的性能和日志消息。</p><p><strong>对应的工具</strong></p><p>组织正在采用云原生技术来实现特定的业务或目标。与构建自定义应用程序平台相比，PaaS 可快速让组织实现价值。Heroku 或 Cloud Foundry Application Runtime 之类的工具可帮助组织快速启动并运行新的应用程序，它们可提供运行云原生应用程序所需的工具。任何 PaaS 都有自身的限制。大多数只支持一种语言或一部分应用程序类型，其自带的一些工具选项可能并不适合你的需求。无状态应用程序通常在 PaaS 中表现出色，而数据库等有状态应用程序通常不太适合 PaaS。目前在这个领域没有 CNCF 项目，但是大多数产品都是开源的。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093426736-2021-07-01-ggxJ1v.png" alt></p><p><strong>小结</strong></p><p>如文中所介绍，有多种工具可帮助简化 Kubernetes 的采用。Kubernetes 发行版、托管 Kubernetes 服务、Kubernetes 安装程序以及 PaaS 都承担了一些安装和配置的工作，可进行预打包。每个解决方案都有其自己的特点。</p><p>在采用上述任何一种方法之前，需要进行一些研究，以确定适合自己需求的最佳解决方案。你可能需要考虑：</p><ul><li><p>我会遇到一些需要掌控控制平面的场景吗？如果有，托管解决方案可能不是一个很好的选择。</p></li><li><p>我有没有一个小型团队来管理“标准”工作负载，并需要分流尽可能多的操作任务？如果有，托管解决方案可能非常合适你。</p></li><li><p>便携性对我来说重要吗？</p></li><li><p>生产就绪情况如何？</p></li></ul><p>还有更多问题需要考虑。没有一个“最佳工具”，但是对于你的特定需求，肯定可以选择一个有效工具。希望本文能帮助你将搜索范围缩小到正确的区域。</p><h2><span id="可观察性是什么有哪些相关工具">可观察性是什么，有哪些相关工具</span></h2><p>终于我们来到了云原生全景图详解的最后一章节。本章节将向大家介绍云原生全景图中的可观察性和分析这一“列”。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093432994-2021-07-01-uGBbn0.png" alt></p><p>首先我们定义一下可观察性和分析（Observability &amp; analysis)。可观察性是一种系统特性，描述了通过外部输出可以理解系统的程度。通过衡量 CPU 时间、内存、磁盘空间、延迟、error 等指标，可以或多或少地观察到计算机系统的状态。分析则是尝试理解这些可用于观察的数据。</p><p>为了确保服务不会中断，我们需要观察和分析应用程序的各个方面，以便立即发现并修复异常情况。这就是可观察性和分析这个类别要做的事情。它贯穿并观察所有层，因此在整个全景图的侧面而不是嵌在某一层。</p><p>此类别中的工具包括日志记录 (logging)、监控 (monitoring)、追踪（tracing) 和混沌工程（chaos engineering)。虽然混沌工程在这里列出，但它更多的是一种可靠性工具，而不是可观察性或分析工具。</p><h3><span id="日志记录">日志记录</span></h3><p><strong>是什么</strong></p><p>应用程序会输出稳定的日志消息流，以描述自身在何时做了什么。这些日志消息会捕获系统中发生的各种事件，例如失败或成功的操作、审计信息或运行状况。日志记录工具将收集、存储和分析这些消息，以追溯错误报告和相关数据。日志记录（loging）、度量（metrics)、追踪（tracing) 是可观察性的三大支柱。</p><p><strong>解决的问题</strong></p><p>收集、存储和分析日志是构建现代平台的关键部分，日志记录可帮助执行这其中的某一项或全部任务。一些工具可处理从收集到分析全方位的工作，还有一些工具则专注于单个任务（例如收集）。所有日志记录工具都旨在帮助组织更好地控制日志消息。</p><p><strong>如何解决</strong></p><p>在收集、存储和分析应用程序的日志消息时，我们将了解应用程序在任何给定时间的通信内容。但请注意，日志代表应用程序有意输出的消息，它们不一定能查明给定问题的根本原因。尽管如此，随时收集和保留日志消息是一项非常强大的功能，它将帮助团队诊断问题并满足合规性要求。</p><p><strong>常用工具</strong></p><p>尽管收集、存储和处理日志消息不是什么新鲜事，但云原生模式和 Kubernetes 的出现极大地改变了我们处理日志的方式。适用于虚拟机和物理机的传统日志记录方法（例如将日志写入文件）不适用于容器化的应用程序，因为在这些容器化应用程序中，文件系统的生命周期可能并不会比应用程序持久。在云原生环境中，诸如 Fluentd 之类的日志收集工具与应用程序容器一起运行，并直接从应用程序收集消息，然后将消息转发到中央日志存储以进行汇总和分析。</p><p>CNCF 中的日志记录工具只有 Fluentd。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093439248-2021-07-01-7kMmtk.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093444220-2021-07-01-SXtfQd.png" alt></p><h3><span id="监控">监控</span></h3><p><strong>是什么</strong></p><p>监控是指对应用程序进行检测，收集、聚合和分析日志和指标，以增进我们对应用程序行为的理解。日志描述了特定的事件，而指标则是在给定时间点对系统的度量。日志和 metrics 是两种不同的事物，但是要全面了解系统的运行状况，二者都是必需的。监控的内容包括观察磁盘空间、CPU 使用率、单个节点上的内存消耗，以及执行详细的综合事务以查看系统或应用程序是否正确且及时地进行了响应等。有许多不同的方法可用来监控系统和应用程序。</p><p><strong>解决的问题</strong></p><p>在运行应用程序或平台时，我们希望它完成既定的任务，并确保只有被授权的用户才能访问。通过监控，我们可以知道应用程序/平台是否在正常、安全且高效地运行，是否仅有被授权的用户可以访问。</p><p><strong>如何解决</strong></p><p>良好的监控方法使运维人员能够在发生事故时迅速做出响应，甚至可以自动响应。监控可以让我们洞察系统当前运行的状况，监测到问题进行修复。它能跟踪应用程序运行状况、用户行为等内容，是有效运行应用程序的重要组成部分。</p><p><strong>常用工具</strong></p><p>云原生环境中的监控和传统应用程序的监控类似。我们需要跟踪指标、日志和事件以了解应用程序的运行状况。主要区别在于云原生环境中的某些托管对象是临时的，它们可能不会持久，因此将监控系统与自动生成的资源名称联系在一起并不是一个好策略。CNCF 中有许多监控工具，最主要的是 Prometheus（已经从 CNCF 毕业）。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093449905-2021-07-01-2e77yb.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093455255-2021-07-01-H2Vq8G.png" alt></p><h3><span id="追踪">追踪</span></h3><p><strong>是什么</strong></p><p>在微服务架构中，服务之间不断通过网络相互通信。追踪是日志记录的一种专门用法，可以跟踪请求在分布式系统中移动的路径。</p><p><strong>解决的问题</strong></p><p>了解微服务应用程序在某个时间点的行为是一项极具挑战的任务。尽管有许多工具可以提供服务行为相关的洞察，但我们可能难以通过单个服务的行为来理解整个应用程序的运行情况。</p><p><strong>如何解决</strong></p><p>追踪对应用程序发送的消息添加唯一标识符，可解决上述问题。该唯一标识符可以跟随/追踪各个事务在系统中移动的路径，可以通过追踪的信息了解应用程序的运行状况，以及调试有问题的微服务或行为。</p><p><strong>常用工具</strong></p><p>追踪是一种功能强大的调试工具，可以对分布式应用程序的行为进行故障排除和 fine-tune。要实现追踪也需要一些成本，比如需要修改应用程序代码以发出跟踪数据，并且所有 Span 都需要由应用程序数据路径中的基础架构组件传播。CNCF 中的追踪工具有 Jaeger 和 Open Tracing。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093502109-2021-07-01-JAr0k7.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093506710-2021-07-01-WuBCTJ.png" alt></p><h3><span id="混沌工程">混沌工程</span></h3><p><strong>是什么</strong></p><p>混沌工程（chaos engineering）是指有意将故障引入系统以创建更具弹性的应用程序和工程团队的实践。混乱工程工具以一种可控的方式在系统中引入故障，并针对应用程序的特定实例运行特定的实验。</p><p><strong>解决的问题</strong></p><p>复杂的系统会出现故障。故障的原因有多种，给分布式系统带来的后果也很难预测。一些组织已经接受了这一点，他们愿意采用混沌工程技术，不去试图防止故障的发生，而是设法练习从故障中恢复。这被称为优化平均修复时间（MTTR）。</p><p><strong>如何解决</strong></p><p>在云原生环境中，应用程序必须动态适应故障——这是一个相对较新的概念。这意味着当出现故障时，系统不会完全崩溃，而是可以优雅地降级或恢复。混沌工程工具可以在生产环境的系统上进行实验，以确保在发生真正的故障时系统也能应对。</p><p>简言之，对一个系统进行混沌工程实验，是为了确保该系统可以承受意外情况。使用混沌工程工具，不必等待故障发生后再进行应对，而是可以在可控条件下为系统注入故障，以发现漏洞并在变更覆盖这些漏洞之前加以修复。</p><p><strong>常用工具</strong></p><p>混沌工程工具和实践对于应用程序的高可用至关重要。分布式系统通常过于复杂，而且任何变更过程都无法完全确定其对环境的影响。通过有意引入混沌工程实践，团队可以练习从故障中恢复，并将这个过程自动化。CNCF 中的混沌工程工具有 Chaos Mesh 和 Litmus Chaos。还有一些其他的开源和闭源的混沌工程工具。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093512020-2021-07-01-CnD3uw.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/640-20210701093517172-2021-07-01-JULM6r.png" alt></p><p><strong>小结</strong></p><p>可观察性和分析这一列的工具可用于了解系统的运行状况，并确保系统即使在恶劣的条件下也能正常运行。日志记录工具可捕获应用程序发出的事件消息，监控工具可监测日志和指标，追踪工具可跟踪单个请求的路径。结合使用这些工具，理想情况下可以 360 度全方位查看系统中正在发生的事情。混沌工程提供了一种安全的方法来保证系统可以承受意外事件，基本上可以确保系统的健康运行。</p><blockquote><p>本文转载自：「 K8sMeetup社区 」，原文：<a href="https://tinyurl.com/2t79rh7m" target="_blank" rel="noopener">https://tinyurl.com/2t79rh7m</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;带你了解云原生技术图谱&quot;&gt;带你了解云原生技术图谱&lt;/h2&gt;
&lt;p&gt;如果你研究过云原生应用程序和相关技术，大概率你遇到过 CNCF 的云原生全景图。这张全景图技术之多规模之大无疑会让人感到震惊，该如何去理解这张图呢？&lt;/p&gt;
&lt;p&gt;如果把它拆开来一次只分析一小块内容，你会发现整个全景图没有那么复杂。事实上，该全景图按照功能有序地组织在一起，一旦你了解了每个类别代表的内容，你就可以轻松游走于全景图中。&lt;/p&gt;
&lt;p&gt;本章节我们将把整个全景图拆解开来，并对整个全景图进行综述。在后续章节中，我们将聚焦在每一层（or 每一列），对每个类别解决的问题和原理进行更为详细的解读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/640-20210701092946955-2021-07-01-NjRgpd.png&quot; alt=&quot;云原生全景图的 4 层&quot;&gt;&lt;/p&gt;
&lt;p&gt;首先，我们剥离掉所有单个的技术，仅查看类别（如下图）。图中有不同的“行”，像建筑的不同层，每层都有自己的子类别。最底层提供了构建云原生基础设施的工具。往上，你可以开始添加运行和管理应用程序所需的工具，比如运行时和调度层。在最上层，有定义和开发应用程序的工具，比如数据库、镜像构建和 CI/CD 工具（我们将在后文讨论）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/640-20210701092955887-2021-07-01-CCKzaW.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;好了，现在你应该记住了云原生全景图始于基础设施，往上的每一层都更接近实际的应用程序。这就是每层代表的意思（后面我们会讨论上图右边的两“列”）。下面我们就从最底层开始，逐层进行解析。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="云原生" scheme="https://www.hi-linux.com/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 官方出品调试工具上手指南(无需安装，开箱即用)</title>
    <link href="https://www.hi-linux.com/posts/48532.html"/>
    <id>https://www.hi-linux.com/posts/48532.html</id>
    <published>2021-06-29T01:00:00.000Z</published>
    <updated>2021-06-29T05:38:45.659Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>本文介绍了 Kubectl debug 和临时容器等调试方法。</p><blockquote><p>作者：Martin Heinz</p><p>翻译：Bach (K8sMeetup)</p><p>校对：星空下的文仔</p></blockquote><p>调试容器化工作负载和 Pod 是每位使用 Kubernetes 的开发人员和 DevOps 工程师的日常任务。通常情况下，我们简单地使用 <code>kubectl logs</code> 或者 <code>kubectl describe pod</code> 便足以找到问题所在，但有时候，一些问题会特别难查。这种情况下，大家可能会尝试使用 <code>kubectl exec</code>，但有时候这样也还不行，因为 Distroless 等容器甚至不允许通过 SSH 进入 shell。那么，如果以上所有方法都失败了，我们要怎么办？</p><h2><span id="更好的方法">更好的方法</span></h2><p>其实我们只需要使用更合适的工具。<strong>如果在 Kubernetes 上调试工作负载，那么合适的工具就是 <code>kubectl debug</code>。</strong> 这是不久前添加的一个新命令（v1.18），允许调试正在运行的 pod。它会将名为 EphemeralContainer（临时容器）的特殊容器注入到问题 Pod 中，让我们查看并排除故障。<code>kubectl debug</code> 看起来非常不错，但要使用它需要临时容器，临时容器到底是什么？</p><p><strong>临时容器其实是 Pod 中的子资源，类似普通 <code>container</code>。但与普通容器不同的是，临时容器不用于构建应用程序，而是用于检查。</strong> 我们不会在创建 Pod 时定义它们，而使用特殊的 API 将其注入到运的行 Pod 中，来运行命令并检查 Pod 环境。除了这些不同，临时容器还缺少一些基本容器的字段，例如 <code>ports</code>、<code>resources</code>。</p><p>那么我们为什么不直接使用基本容器？这是因为我们不能向 Pod 添加基本容器，它们应该是一次性的（需要随时删除或重新创建），这会导致难以重现问题 Pod 的错误，排除故障也会很麻烦。这就是将临时容器添加到 API 的原因——它们允许我们将临时容器添加到现有 Pod，从而检查正在运行的 Pod。</p><p>虽然临时容器是作为 Kubernetes 核心的 Pod 规范的一部分，但很多人可能还没有听说过。这是因为临时容器处于早期 Alpha 阶段，这意味着默认情况下不启用。Alpha 阶段的资源和功能可能会出现重大变化，或者在 Kubernetes 的某个未来版本中被完全删除。<strong>因此，要使用它们必须在 kubelet 中使用Feature Gate（功能门）显式启用。</strong></p><a id="more"></a><h2><span id="configuring-feature-gates">Configuring Feature Gates</span></h2><p><strong>现在如果确定要试用 <code>kubectl debug</code>，那么如何启用临时容器的功能门？这取决于集群设置。</strong> 例如，现在使用kubeadm启动创建集群，那么可以使用以下集群配置来启用临时容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io&#x2F;v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.20.2</span><br><span class="line">apiServer:</span><br><span class="line">  extraArgs:</span><br><span class="line">    feature-gates: EphemeralContainers&#x3D;true</span><br></pre></td></tr></table></figure><p>在以下示例中，为了简单和测试目的，我们使用 KinD（Docker 中的 Kubernetes）集群，这允许我们指定要启用的功能门。创建我们的测试集群：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># File: config.yaml</span><br><span class="line"># Run:  kind create cluster --config .&#x2F;config.yaml --name kind --image&#x3D;kindest&#x2F;node:v1.20.2</span><br><span class="line">kind: Cluster</span><br><span class="line">apiVersion: kind.x-k8s.io&#x2F;v1alpha4</span><br><span class="line">featureGates:</span><br><span class="line">  EphemeralContainers: true</span><br><span class="line">nodes:</span><br><span class="line">- role: control-plane</span><br></pre></td></tr></table></figure><p>随着集群的运行，我们需要验证其有效性。最简单方法是检查 Pod API，它现在应该包含临时容器部分以及通常容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl explain pod.spec.ephemeralContainers</span><br><span class="line">KIND:     Pod</span><br><span class="line">VERSION:  v1</span><br><span class="line"></span><br><span class="line">RESOURCE: ephemeralContainers &lt;[]Object&gt;</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">     List of ephemeral containers run in this pod....</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>现在都有了，可以开始使用 <code>kubectl debug</code>。从简单的例子开始：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl run some-app --image&#x3D;k8s.gcr.io&#x2F;pause:3.1 --restart&#x3D;Never</span><br><span class="line">~ $ kubectl debug -it some-app --image&#x3D;busybox --target&#x3D;some-app</span><br><span class="line">Defaulting debug container name to debugger-tfqvh.</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line">&#x2F; #</span><br><span class="line"># From other terminal...</span><br><span class="line">~ $ kubectl describe pod some-app</span><br><span class="line">...</span><br><span class="line">Containers:</span><br><span class="line">  some-app:</span><br><span class="line">    Container ID:   containerd:&#x2F;&#x2F;60cc537eee843cb38a1ba295baaa172db8344eea59de4d75311400436d4a5083</span><br><span class="line">    Image:          k8s.gcr.io&#x2F;pause:3.1</span><br><span class="line">    Image ID:       k8s.gcr.io&#x2F;pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea</span><br><span class="line">...</span><br><span class="line">Ephemeral Containers:</span><br><span class="line">  debugger-tfqvh:</span><br><span class="line">    Container ID:   containerd:&#x2F;&#x2F;12efbbf2e46bb523ae0546b2369801b51a61e1367dda839ce0e02f0e5c1a49d6</span><br><span class="line">    Image:          busybox</span><br><span class="line">    Image ID:       docker.io&#x2F;library&#x2F;busybox@sha256:ce2360d5189a033012fbad1635e037be86f23b65cfd676b436d0931af390a2ac</span><br><span class="line">    Port:           &lt;none&gt;</span><br><span class="line">    Host Port:      &lt;none&gt;</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Mon, 15 Mar 2021 20:33:51 +0100</span><br><span class="line">    Ready:          False</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:         &lt;none&gt;</span><br></pre></td></tr></table></figure><p>我们首先启动一个名为 <code>some-app</code> 的 Pod 来进行“调试”。然后针对这个 Pod 运行 <code>kubectl debug</code>，指定 <code>busybox</code> 为临时容器的镜像，并作为原始容器的目标。此外，还需要包括 <code>-it</code> 参数，以便我们立即附加到容器获得 shell 会话。</p><p>在上面的代码中可以看到，如果我们在 Pod 上运行 kubectl debug 后对其进行描述，那么它的描述将包括具有之前指定为命令选项值的临时容器部分。</p><h2><span id="process-namespace-sharing">Process Namespace Sharing</span></h2><p><code>kubectl debug</code> 是非常强大的工具，但有时向 Pod 添加一个容器还不足以获取 Pod 的另一个容器中运行的应用程序相关信息。当故障容器不包括必要的调试工具甚至 shell 时，可能就是这种情况。<strong>在这种情况下，我们可以使用 Process Sharing（进程共享）来使用注入的临时容器检查 Pod 的原有容器。</strong></p><p>进程共享的一个问题是它不能应用于现有的 Pod，因此我们必须创建一个新 Pod，将其 <code>spec.shareProcessNamespace</code> 设置为 <code>true</code>，并将一个临时容器注入其中。这样有点麻烦，尤其是需要调试多个 Pod 或容器，亦或者需要重复执行该操作时。幸运的是，<code>kubectl debug</code> 可以使用 <code>--share-processes</code> 做到：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl run some-app --image&#x3D;nginx --restart&#x3D;Never</span><br><span class="line">~ $ kubectl debug -it some-app --image&#x3D;busybox --share-processes --copy-to&#x3D;some-app-debug</span><br><span class="line">Defaulting debug container name to debugger-tkwst.</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line">&#x2F; # ps ax</span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 &#x2F;pause</span><br><span class="line">    8 root      0:00 nginx: master process nginx -g daemon off;</span><br><span class="line">   38 101       0:00 nginx: worker process</span><br><span class="line">   39 root      0:00 sh</span><br><span class="line">   46 root      0:00 ps ax</span><br><span class="line">~ $ cat &#x2F;proc&#x2F;8&#x2F;root&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf </span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    listen  [::]:80;</span><br><span class="line">    server_name  localhost;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>上面的代码表明，通过进程共享，我们可以看到 Pod 中另一个容器内的所有内容，包括其进程和文件，这对于调试来说非常方便。另外，除了 <code>--share-processes</code> 还包括了 <code>--copy-to=new-pod-name</code>，这是因为我们需要创建一个新的 Pod，其名称由该 flag 指定。如果我们从另一个终端列出正在运行的 Pod，我们将看到以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># From other terminal:</span><br><span class="line">~ $ kubectl get pods</span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE</span><br><span class="line">some-app         1&#x2F;1     Running   0          23h</span><br><span class="line">some-app-debug   2&#x2F;2     Running   0          20s</span><br></pre></td></tr></table></figure><p>这就是我们在原始应用程序 Pod 上的新调试 Pod。与原始容器相比，它有 2 个容器，因为它还包括临时容器。此外，如果想在任何时候验证 Pod 中是否允许进程共享，那么可以运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl get pod some-app-debug -o json  | jq .spec.shareProcessNamespace</span><br><span class="line">true</span><br></pre></td></tr></table></figure><h2><span id="好好使用">好好使用</span></h2><p><strong>既然我们已经启用了功能并且知道命令是如何工作的，那就试着使用它并调试一些应用程序。</strong> 想象这样一个场景——我们有一个问题应用程序，我们需要在它的容器中对网络相关的问题进行故障排除。该应用程序没有我们可以使用的必要的网络 CLI 工具。为了解决这个问题，我们通过以下方式使用 <code>kubectl debug</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl run distroless-python --image&#x3D;martinheinz&#x2F;distroless-python --restart&#x3D;Never</span><br><span class="line">~ $ kubectl exec -it distroless-python -- &#x2F;bin&#x2F;sh</span><br><span class="line"># id</span><br><span class="line">&#x2F;bin&#x2F;sh: 1: id: not found</span><br><span class="line"># ls</span><br><span class="line">&#x2F;bin&#x2F;sh: 2: ls: not found</span><br><span class="line"># env</span><br><span class="line">&#x2F;bin&#x2F;sh: 3: env: not found</span><br><span class="line">#</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">kubectl debug -it distroless-python --image&#x3D;praqma&#x2F;network-multitool --target&#x3D;distroless-python -- sh</span><br><span class="line">Defaulting debug container name to debugger-rvtd4.</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line">&#x2F; # ping localhost</span><br><span class="line">PING localhost(localhost (::1)) 56 data bytes</span><br><span class="line">64 bytes from localhost (::1): icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.025 ms</span><br><span class="line">64 bytes from localhost (::1): icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.044 ms</span><br><span class="line">64 bytes from localhost (::1): icmp_seq&#x3D;3 ttl&#x3D;64 time&#x3D;0.027 ms</span><br></pre></td></tr></table></figure><p>在启动一个 Pod 之后，我们首先尝试将 shell 会话放入它的容器中，这看起来有效，但是实际上我们尝试运行一些基本命令时，将看到那里什么都没有。所以，我们要使用 <code>praqma/network-multitool</code> 将临时容器注入到 Pod 中，该镜像包含了 <code>curl</code>、<code>ping</code>、<code>telnet</code> 等工具，现在我们可以进行所有必要的故障排除。</p><p>在上面的例子中，我们进入 Pod 的另一个容器中就足够了。但有时可能需要直接查看有问题的容器。这种情况下，我们可以像这样使用进程共享：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl run distroless-python --image&#x3D;martinheinz&#x2F;distroless-python --restart&#x3D;Never</span><br><span class="line">~ $ kubectl debug -it distroless-python --image&#x3D;busybox --share-processes --copy-to&#x3D;distroless-python-debug</span><br><span class="line">Defaulting debug container name to debugger-l692h.</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line">&#x2F; # ps ax</span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 &#x2F;pause</span><br><span class="line">    8 root      0:00 &#x2F;usr&#x2F;bin&#x2F;python3.5 sleep.py  # Original container is just sleeping forever</span><br><span class="line">   14 root      0:00 sh</span><br><span class="line">   20 root      0:00 ps ax</span><br><span class="line">&#x2F; # cat &#x2F;proc&#x2F;8&#x2F;root&#x2F;app&#x2F;sleep.py </span><br><span class="line">import time</span><br><span class="line">print(&quot;sleeping for 1 hour&quot;)</span><br><span class="line">time.sleep(3600)</span><br></pre></td></tr></table></figure><p>在这里，我们再次运行使用 Distroless 镜像的容器。我们无法在它的 shell 中做任何事情。我们运行 <code>kubectl debug</code> 以及 <code>--share-processes --copy-to=...</code>，它创建了一个新的 Pod，带有额外的临时容器，可以访问所有进程。当我们列出正在运行的进程时，能看到应用程序容器的进程有 PID 8，可以用它来探索文件和环境。为此，我们需要通过 <code>/proc/&lt;PID&gt;/...</code> 目录，这个例子中是 <code>/proc/8/root/app/...</code>。</p><p>另一种常见情况是应用程序在容器启动时不断崩溃，这让调试非常困难，因为没有足够的时间将 shell 会话导入容器并运行故障排除命令。<strong>在这种情况下，解决方案是创建具有不同入口点、命令的容器，这可以阻止应用程序立即崩溃并允许我们调试：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl get pods</span><br><span class="line">NAME                READY   STATUS             RESTARTS   AGE</span><br><span class="line">crashing-app        0&#x2F;1     CrashLoopBackOff   1          8s</span><br><span class="line"></span><br><span class="line">~ $ kubectl debug crashing-app -it --copy-to&#x3D;crashing-app-debug --container&#x3D;crashing-app -- sh</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line"># id</span><br><span class="line">uid&#x3D;0(root) gid&#x3D;0(root) groups&#x3D;0(root)</span><br><span class="line">#</span><br><span class="line">...</span><br><span class="line"># From another terminal</span><br><span class="line">~ $ kubectl get pods</span><br><span class="line">NAME                READY   STATUS             RESTARTS   AGE</span><br><span class="line">crashing-app        0&#x2F;1     CrashLoopBackOff   3          2m7s</span><br><span class="line">crashing-app-debug  1&#x2F;1     Running            0          16s</span><br></pre></td></tr></table></figure><h2><span id="调试集群节点">调试集群节点</span></h2><p>本文主要关注 Pod 及其容器的调试，但任何集群管理员都知道常常需要调试的是节点而不是 Pod。幸运的是，<code>kubectl debug</code> 允许通过创建 Pod 来调试节点，该 Pod 将在指定节点上运行，节点的根文件系统安装在 <code>/root</code> 目录中。我们甚至可以用 <code>chroot</code> 访问主机二进制文件，这本质上充当了节点的 SSH 连接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">~ $ kubectl get nodes</span><br><span class="line">NAME                 STATUS   ROLES                  AGE   VERSION</span><br><span class="line">kind-control-plane   Ready    control-plane,master   25h   v1.20.2</span><br><span class="line"></span><br><span class="line">~ $ kubectl debug node&#x2F;kind-control-plane -it --image&#x3D;ubuntu</span><br><span class="line">Creating debugging pod node-debugger-kind-control-plane-hvljt with container debugger on node kind-control-plane.</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line">root@kind-control-plane:&#x2F;# chroot &#x2F;host</span><br><span class="line"># head kind&#x2F;kubeadm.conf</span><br><span class="line">apiServer:</span><br><span class="line">  certSANs:</span><br><span class="line">  - localhost</span><br><span class="line">  - 127.0.0.1</span><br><span class="line">  extraArgs:</span><br><span class="line">    feature-gates: EphemeralContainers&#x3D;true</span><br><span class="line">    runtime-config: &quot;&quot;</span><br><span class="line">apiVersion: kubeadm.k8s.io&#x2F;v1beta2</span><br><span class="line">clusterName: kind</span><br><span class="line">controlPlaneEndpoint: kind-control-plane:6443</span><br></pre></td></tr></table></figure><p>在上面的代码中，我们首先确定了想要调试的节点，然后使用 <code>node/...</code> 作为参数显式运行 <code>kubectl debug</code> 以访问我们集群的节点。在那之后，当连接到Pod后，我们使用 <code>chroot /host</code> 突破 <code>chroot</code>，并完全进入主机。最后，为了验证是否真的可以看到主机上的所有内容，我们了查看一部分的 <code>kubeadm.conf</code>，最终看到我们在文章开头配置的内容 <code>feature-gates: EphemeralContainers=true</code>。</p><h2><span id="小结">小结</span></h2><p><strong>能够快速有效地调试应用程序和服务可以节省大量时间，但更重要的是，它能极大地帮助解决那些如果不立即解决可能最终会花费大量资金的问题。</strong> 这就是为什么 kubectl debug 之类的工具能随意使用非常重要，即使它们尚未正式发布或默认启用。如果启用临时容器不是一种选择，那么尝试替代调试方法可能是一个好主意，例如使用包含故障排除工具的应用程序镜像的调试版本；或临时更改 Pod 的容器命令以阻止其崩溃。</p><p>原文链接：<a href="https://towardsdatascience.com/the-easiest-way-to-debug-kubernetes-workloads-ff2ff5e3cc75" target="_blank" rel="noopener">https://towardsdatascience.com/the-easiest-way-to-debug-kubernetes-workloads-ff2ff5e3cc75</a></p><blockquote><p>本文转载自：「 K8sMeetup社区 」，原文：<a href="https://tinyurl.com/5bp67tpm" target="_blank" rel="noopener">https://tinyurl.com/5bp67tpm</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文介绍了 Kubectl debug 和临时容器等调试方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;作者：Martin Heinz&lt;/p&gt;
&lt;p&gt;翻译：Bach (K8sMeetup)&lt;/p&gt;
&lt;p&gt;校对：星空下的文仔&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;调试容器化工作负载和 Pod 是每位使用 Kubernetes 的开发人员和 DevOps 工程师的日常任务。通常情况下，我们简单地使用 &lt;code&gt;kubectl logs&lt;/code&gt; 或者 &lt;code&gt;kubectl describe pod&lt;/code&gt; 便足以找到问题所在，但有时候，一些问题会特别难查。这种情况下，大家可能会尝试使用 &lt;code&gt;kubectl exec&lt;/code&gt;，但有时候这样也还不行，因为 Distroless 等容器甚至不允许通过 SSH 进入 shell。那么，如果以上所有方法都失败了，我们要怎么办？&lt;/p&gt;
&lt;h2 id=&quot;更好的方法&quot;&gt;更好的方法&lt;/h2&gt;
&lt;p&gt;其实我们只需要使用更合适的工具。&lt;strong&gt;如果在 Kubernetes 上调试工作负载，那么合适的工具就是 &lt;code&gt;kubectl debug&lt;/code&gt;。&lt;/strong&gt; 这是不久前添加的一个新命令（v1.18），允许调试正在运行的 pod。它会将名为 EphemeralContainer（临时容器）的特殊容器注入到问题 Pod 中，让我们查看并排除故障。&lt;code&gt;kubectl debug&lt;/code&gt; 看起来非常不错，但要使用它需要临时容器，临时容器到底是什么？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;临时容器其实是 Pod 中的子资源，类似普通 &lt;code&gt;container&lt;/code&gt;。但与普通容器不同的是，临时容器不用于构建应用程序，而是用于检查。&lt;/strong&gt; 我们不会在创建 Pod 时定义它们，而使用特殊的 API 将其注入到运的行 Pod 中，来运行命令并检查 Pod 环境。除了这些不同，临时容器还缺少一些基本容器的字段，例如 &lt;code&gt;ports&lt;/code&gt;、&lt;code&gt;resources&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;那么我们为什么不直接使用基本容器？这是因为我们不能向 Pod 添加基本容器，它们应该是一次性的（需要随时删除或重新创建），这会导致难以重现问题 Pod 的错误，排除故障也会很麻烦。这就是将临时容器添加到 API 的原因——它们允许我们将临时容器添加到现有 Pod，从而检查正在运行的 Pod。&lt;/p&gt;
&lt;p&gt;虽然临时容器是作为 Kubernetes 核心的 Pod 规范的一部分，但很多人可能还没有听说过。这是因为临时容器处于早期 Alpha 阶段，这意味着默认情况下不启用。Alpha 阶段的资源和功能可能会出现重大变化，或者在 Kubernetes 的某个未来版本中被完全删除。&lt;strong&gt;因此，要使用它们必须在 kubelet 中使用Feature Gate（功能门）显式启用。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>HTTP 故障图解指南</title>
    <link href="https://www.hi-linux.com/posts/28200.html"/>
    <id>https://www.hi-linux.com/posts/28200.html</id>
    <published>2021-06-28T01:00:00.000Z</published>
    <updated>2021-06-28T01:47:12.544Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>网页打开某个网站，可以看到正常的内容，这个 <code>HTTP Status code</code> 是 <code>200</code>，没有显示在页面上。</p><p>但是偶尔会看到整页白底，但是上面写 <code>400</code>、<code>403</code>、<code>500</code>，或者画面比较好看的 <code>404</code> 此页面找不到等等，那这些代码是什么意思呢？</p><p>做为一个运维工程师，遇到这样的情况，你又应该怎么判断是哪里出问题了呢？</p><a id="more"></a><h2><span id="http-状态代码决策图">HTTP 状态代码决策图</span></h2><p>对于超文本传输协议（又称 HTTP 状态代码），代码的第一个数字表示五类响应中的一类。HTTP 客户端至少要认识这五类。</p><p>第一类代码是信息性的，表示在继续处理时的临时响应。<br>第二类状态代码传达了客户的请求被接收并成功处理。<br>第三类 HTTP 状态代码表明，为了完成请求，需要代表客户采取进一步的行动，如 URL 重定向。<br>第四类代码是在客户出错时使用的。<br>第五类状态代码表示服务器出了错误，无法完成一个明显有效的请求。</p><table><thead><tr><th style="text-align:left">1xx Informational</th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left">100 - Continue</td><td style="text-align:left">The server has received the initial request, and the client should continue sending the remainder of the request.</td></tr><tr><td style="text-align:left">101 - Switching Protocols</td><td style="text-align:left">The server is acknowledging that it is switching protocols based on the requesterÕs instructions.</td></tr><tr><td style="text-align:left">102 - Processing Request (WebDAV; RFC 2518)</td><td style="text-align:left">To avoid timing out, the server acknowledges that a request has been received and is being processed, though no response is available.</td></tr><tr><td style="text-align:left">103 - Checkpoint</td><td style="text-align:left">Resumes aborted PUT or POST requests in Resumable HTTP Requests Proposal.</td></tr><tr><td style="text-align:left">122 - Too Long</td><td style="text-align:left">An IE7-only code that indicates that the URI is longer than the maximum 2,083 characters.</td></tr><tr><td style="text-align:left">200 - OK</td><td style="text-align:left">The standard response for successful HTTP requests. Varies according to request method. For GET requests, responses contain an entity corresponding to the requested resource. For POST requests, responses contain an entity describing or containing the result of the action.</td></tr><tr><td style="text-align:left">201 - Created</td><td style="text-align:left">The request has been fulfilled, resulting in the creation of a new resource.</td></tr><tr><td style="text-align:left">202 - Accepted</td><td style="text-align:left">The request has been accepted, but processing is still pending. Upon processing, the request might be disallowed, meaning it might or might not actually be acted upon.</td></tr><tr><td style="text-align:left">203 - Non-Authoritative Information (since HTTP/1.1)</td><td style="text-align:left">The request has been successfully processed by the server, but the information being returned may be from another source.</td></tr><tr><td style="text-align:left">204 - No Content</td><td style="text-align:left">The request has been successfully processed by the server, but no content is being returned. Often a successful delete request.</td></tr><tr><td style="text-align:left">205 - Reset Content</td><td style="text-align:left">Though the request was successfully processed, no content is being returned and the requester must reset the document view.</td></tr><tr><td style="text-align:left">206 - Partial Content (RFC 7233)</td><td style="text-align:left">Because of the range header sent by the client, only part of the resource is being delivered by the server.</td></tr><tr><td style="text-align:left">207 - Multi-Status (WebDAV; RFC 4918)</td><td style="text-align:left">Depending on the number of sub-requests made by the client, the XML message that follows might contain multiple separate response codes.</td></tr><tr><td style="text-align:left">208 - Already Reported (WebDAV; RFC 5842)</td><td style="text-align:left">The results have been included in a previous reply and are not being returned again.</td></tr><tr><td style="text-align:left">226 - IM Used (RFC 3229)</td><td style="text-align:left">A request for this resource has been fulfilled by the server. The response represents the result of one or more instance manipulations for the current instance.</td></tr><tr><td style="text-align:left">2xx Success</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">300 - Multiple Choices</td><td style="text-align:left">Indicates multiple options for the resource delivered, such as format options for video or list files with different extensions. The user can select preferred representation and redirect the request to that location.</td></tr><tr><td style="text-align:left">301 - Moved Permanently</td><td style="text-align:left">This request and all future ones should be directed to the given URI.</td></tr><tr><td style="text-align:left">302 - Found</td><td style="text-align:left">Indicates that the requested resource can be found temporarily via an alternative URI. Because many popular user agent implementations treat 302 responses similar to 303 responses, both status codes 303 and 307 were added to allow servers more specificity.</td></tr><tr><td style="text-align:left">303 - See Other (since HTTP/1.1)</td><td style="text-align:left">Indicates the response to the request can be found via alternative URI using GET method. Many pre-HTTP/1.1 user agents do not recognize 303, in which case the 302 status code can be used instead.</td></tr><tr><td style="text-align:left">304 - Not Modified (RFC 7232)</td><td style="text-align:left">Indicates that the resource has not been modified since last requested, and there is no need to retransmit as the client has a previously downloaded copy.</td></tr><tr><td style="text-align:left">305 - Use Proxy (since HTTP/1.1)</td><td style="text-align:left">Requested resource is located elsewhere and can be accessed through a proxy provided in the response. For security reasons, HTTP clients like Firefox and Internet Explorer do not correctly handle 305 responses.</td></tr><tr><td style="text-align:left">306 - Switch Proxy</td><td style="text-align:left">Originally indicated that subsequent requests should use the proxy specified. This status code is no longer used.</td></tr><tr><td style="text-align:left">307 - Temporary Redirect (since HTTP/1.1)</td><td style="text-align:left">Indicates that the request should be repeated with a different URI as specified, but future requests should use the original URI.</td></tr><tr><td style="text-align:left">308 - Permanent Redirect (RFC 7538)</td><td style="text-align:left">This and all future requests should be repeated using a different URI as specified. Unlike 301 and 302, with 307 and 308 status codes the HTTP method should not change.</td></tr><tr><td style="text-align:left">3xx Redirection</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">400 - Bad Request</td><td style="text-align:left">The request cannot be processed by the server because of a client error such as syntax, framing, or routing.</td></tr><tr><td style="text-align:left">401 - Unauthorized</td><td style="text-align:left">Indicates that authentication is required and was either not provided or has failed. If the request already included authorization credentials, then the 401 status code indicates that those credentials were not accepted.</td></tr><tr><td style="text-align:left">402 - Payment Required</td><td style="text-align:left">Reserved for future use. Originally intended to be part of a digital cash or micropayment model, this code is not currently widely used.</td></tr><tr><td style="text-align:left">403 - Forbidden</td><td style="text-align:left">Indicates that though the request was valid, the server refuses to respond to it. Unlike the 401 status code, providing authentication will not change the outcome.</td></tr><tr><td style="text-align:left">404 - Not Found</td><td style="text-align:left">Indicates that the requested resource could not be found but may be available in the future.</td></tr><tr><td style="text-align:left">405 - Method Not Allowed</td><td style="text-align:left">The request method is not supported by the resource requested, as when using GET on a form that requires data to be presented via POST.</td></tr><tr><td style="text-align:left">406 - Not Acceptable</td><td style="text-align:left">The requested content is not acceptable according to the requestÕs Accept headers.</td></tr><tr><td style="text-align:left">407 - Proxy Authentication Required (RFC 7235)</td><td style="text-align:left">The client must first authenticate itself with the proxy.</td></tr><tr><td style="text-align:left">408 - Request Timeout</td><td style="text-align:left">Indicates that the server timed out while waiting for the request, though the client may repeat the request without modifications.</td></tr><tr><td style="text-align:left">409 - Conflict</td><td style="text-align:left">There is a conflict in the request that prevents it from being processedÑfor example, an edit conflict in the case of multiple updates.</td></tr><tr><td style="text-align:left">410 - Gone</td><td style="text-align:left">The requested resource is no longer available and will not be available again, as when a resource has been intentionally removed and should be purged. The client should not request the resource again.</td></tr><tr><td style="text-align:left">411 - Length Required</td><td style="text-align:left">The request did not specify the length of its content, though length is required by the requested source.</td></tr><tr><td style="text-align:left">412 - Precondition Failed (RFC 7232)</td><td style="text-align:left">Indicates that the server does not meet the request preconditions as specified by requester.</td></tr><tr><td style="text-align:left">413 - Request Entity Too Large</td><td style="text-align:left">Indicates that the request is larger than the server can or will process.</td></tr><tr><td style="text-align:left">414 - Request-URI Too Long</td><td style="text-align:left">The provided URI was too long to be processed by the server. When resulting from too much data encoded as GET request query-string, convert to a POST request.</td></tr><tr><td style="text-align:left">415 - Unsupported Media Type</td><td style="text-align:left">The server does not support the media type included by the request entity.</td></tr><tr><td style="text-align:left">416 - Requested Range Not Satisfiable (RFC 7233)</td><td style="text-align:left">Indicates that the client has requested a portion of the file that the server is unable to provide, such as a part of the file that lies beyond the end of the file.</td></tr><tr><td style="text-align:left">417 - Expectation Failed</td><td style="text-align:left">Indicates that the server is unable to meet the requirements of Expect request-header field.</td></tr><tr><td style="text-align:left">418 - I’m a teapot (RFC 2324)</td><td style="text-align:left">Defined in 1998 as a traditional IETF April FoolÕs joke and is not expected to be implemented by actual HTTP servers. The RFC specifies that this code should be returned by teapots requested to brew coffee.</td></tr><tr><td style="text-align:left">419 - Authentication Timeout (not in RFC 2616)</td><td style="text-align:left">Indicates that previously valid authentication has expired. Though not a part of the HTTP standard, the 419 status code is used as an alternative to 401 to differentiate from unauthorized clients being denied access.</td></tr><tr><td style="text-align:left">420 - Enhance Your Calm (Twitter)</td><td style="text-align:left">Returned by version 1 of the Twitter Search and Trends API when the client is being rate limited. Not a part of the HTTP standard.</td></tr><tr><td style="text-align:left">420 - Method Failure (Spring Framework)</td><td style="text-align:left">Defined by Spring in the HttpStatus class to be used when a method fails. Not a part of the HTTP standard, this status code is deprecated by Spring.</td></tr><tr><td style="text-align:left">421 - Misdirected Request (HTTP/2)</td><td style="text-align:left">Indicates that the request is directed at a server that is unable to produce a response.</td></tr><tr><td style="text-align:left">422 - Unprocessable Entity (WebDAV; RFC 4918)</td><td style="text-align:left">Indicates that the request is unable to be followed due to semantic errors.</td></tr><tr><td style="text-align:left">423 - Locked (WebDAV; RFC 4918)</td><td style="text-align:left">Indicates that the resource that is being accessed is locked.</td></tr><tr><td style="text-align:left">424 - Failed Dependency (WebDAV; RFC 4918)</td><td style="text-align:left">Indicates that the request failed because of the failure of a previous request.</td></tr><tr><td style="text-align:left">426 - Upgrade Required</td><td style="text-align:left">Indicates that the client should switch to a different protocol as specified in the Upgrade header field.</td></tr><tr><td style="text-align:left">428 - Precondition Required (RFC 6585)</td><td style="text-align:left">Indicates that origin server requires the request to be conditional to prevent the Òlost updateÓ problem.</td></tr><tr><td style="text-align:left">429 - Too Many Requests (RFC 6585)</td><td style="text-align:left">Occurs when the user has sent too many requests in a given amount of time. For use with rate limiting.</td></tr><tr><td style="text-align:left">431 - Request Header Fields Too Large (RFC 6585)</td><td style="text-align:left">Indicates that the request cannot be processed by the server because a single header field or all headers are collectively too large.</td></tr><tr><td style="text-align:left">440 - Login Timeout (Microsoft)</td><td style="text-align:left">Microsoft extension indicating that the session has expired.</td></tr><tr><td style="text-align:left">444 - No Response (Nginx)</td><td style="text-align:left">In Nginx logs as a malware deterrent, indicates that the server returned no information and closed the connection.</td></tr><tr><td style="text-align:left">449 - Retry With (Microsoft)</td><td style="text-align:left">Microsoft extension indicating that the request should be retried after performing a specific action.</td></tr><tr><td style="text-align:left">450 - Blocked by Windows Parental Controls (Microsoft)</td><td style="text-align:left">Microsoft extension indicating that Windows Parental Controls are turned on and blocking access to the page in question.</td></tr><tr><td style="text-align:left">451 - Redirect (Microsoft)</td><td style="text-align:left">In Exchange ActiveSync, used when there is a more efficient server or the server cannot access the clientÕs mailbox. Client should re-run the HTTP Autodiscovery protocol to find a better suited server.</td></tr><tr><td style="text-align:left">451 - Unavailable For Legal Reasons (Internet draft)</td><td style="text-align:left">Indicates that resource access has been denied for legal reasons such as censorship or government-mandated blocked access. Defined in the Internet draft as “A New HTTP Status Code for Legally-restricted Resources.” References the dystopian novel Fahrenheit 451 (1953), in which books are outlawed.</td></tr><tr><td style="text-align:left">494 - Request Header Too Large (Nginx)</td><td style="text-align:left">Similar to 431, Nginx internal code earlier in version 0.9.4.</td></tr><tr><td style="text-align:left">495 - Cert Error (Nginx)</td><td style="text-align:left">Nginx internal code indicating that SSL client certificate error has occurred</td></tr><tr><td style="text-align:left">496 - No Cert (Nginx)</td><td style="text-align:left">Nginx internal code indicating that the client didn’t provide certificate.</td></tr><tr><td style="text-align:left">497 - HTTP to HTTPS (Nginx)</td><td style="text-align:left">Nginx internal code indicating that plain HTTP requests were sent to HTTPS port.</td></tr><tr><td style="text-align:left">498 - Token Expired/Invalid (Esri)</td><td style="text-align:left">Returned by ArcGIS for Server when token is expired or otherwise invalid.</td></tr><tr><td style="text-align:left">499 - Client Closed Request (Nginx)</td><td style="text-align:left">In Nginx logs, indicates that the connection has been closed by the client while the server is still processing its request, in which case the server is unable to send a status code back.</td></tr><tr><td style="text-align:left">499 - Token Required (Esri)</td><td style="text-align:left">Returned by ArcGIS for Server when a token is required but was not submitted.</td></tr><tr><td style="text-align:left">4xx Client Error</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">500 - Internal Server Error</td><td style="text-align:left">Generic error message for when there is no suitable specific information. Indicates an unexpected condition.</td></tr><tr><td style="text-align:left">501 - Not Implemented</td><td style="text-align:left">Indicates that the server does not recognize the method or is unable to fulfill it. Can indicate future availability.</td></tr><tr><td style="text-align:left">502 - Bad Gateway</td><td style="text-align:left">Indicates that server, when acting as gateway or proxy, received an invalid response from the upstream server.</td></tr><tr><td style="text-align:left">503 - Service Unavailable</td><td style="text-align:left">Indicates that the server is temporarily unavailable, often because of maintenance or overloading.</td></tr><tr><td style="text-align:left">504 - Gateway Timeout</td><td style="text-align:left">Indicates that the server, when acting as gateway or proxy, did not receive a timely response from the upstream server.</td></tr><tr><td style="text-align:left">505 - HTTP Version Not Supported</td><td style="text-align:left">Occurs when the server does not support the requestÕs HTTP protocol version.</td></tr><tr><td style="text-align:left">506 - Variant Also Negotiates (RFC 2295)</td><td style="text-align:left">Indicates that transparent content negotiation for the request is causing a circular reference.</td></tr><tr><td style="text-align:left">507 - Insufficient Storage (WebDAV; RFC 4918)</td><td style="text-align:left">Occurs when the server cannot store the representation necessary for completing the request.</td></tr><tr><td style="text-align:left">508 - Loop Detected (WebDAV; RFC 5842)</td><td style="text-align:left">Indicates that the server detected an infinite loop while processing the request.</td></tr><tr><td style="text-align:left">509 - Bandwidth Limit Exceeded (Apache BW/Limited Extension)</td><td style="text-align:left">Use unknown. Status code not specified by any RFCs.</td></tr><tr><td style="text-align:left">510 - Not Extended (RFC 2774)</td><td style="text-align:left">Indicates that the server requires further extensions in order to fulfill the request.</td></tr><tr><td style="text-align:left">511 - Network Authentication Required (RFC 6585)</td><td style="text-align:left">Client must authenticate in order to gain network access. Often used by proxies that control network access such as Wi-Fi hotspots.</td></tr><tr><td style="text-align:left">598 - Network Read Timeout Error (Unknown)</td><td style="text-align:left">Used by Microsoft HTTP proxies to indicate a network read time-out behind the proxy to a client in front of the proxy. Not specified in any RFCs.</td></tr><tr><td style="text-align:left">599 - Network connect timeout error (Unknown)</td><td style="text-align:left">Used by Microsoft HTTP proxies to indicate a network connect time-out behind the proxy to a client in front of the proxy. Not specified in any RFCs.</td></tr><tr><td style="text-align:left">5xx server error</td><td style="text-align:left"></td></tr></tbody></table><p>为了更直观的快速定位问题，有大神将这五类 HTTP 状态码做成一个决策图，可以很方便看到 HTTP 状态由 <code>1xx ~ 5xx</code> 的含义，并提供了常用解决思路。</p><p><img src="https://img.hi-linux.com/staticfile/http-decision-diagram-2021-06-23-HqYYCV.png" alt></p><p>有了这张图后，是不是当你再遇到 <code>HTTP</code> 报错时，就可以愉快的<strong>将锅扔给开发了</strong>呢，哈哈！更多 HTTP 排错指南可参考： <a href="https://documentation.solarwinds.com/en/success_center/loggly/content/admin/troubleshooting-http.htm" target="_blank" rel="noopener">Troubleshooting HTTP</a>。</p><p><strong>如需『 HTTP 故障图解指南 』 高清版，可在公众号对话框回复关键字：「<code>HTTPTroubleshoot</code>」免费获取。</strong></p><h2><span id="参考文档">参考文档</span></h2><ul><li><a href="https://tinyurl.com/srs4z5vj" target="_blank" rel="noopener">https://tinyurl.com/srs4z5vj</a></li><li><a href="https://www.loggly.com/blog/http-status-code-diagram/" target="_blank" rel="noopener">https://www.loggly.com/blog/http-status-code-diagram/</a></li><li><a href="https://documentation.solarwinds.com/en/success_center/loggly/content/admin/troubleshooting-http.htm" target="_blank" rel="noopener">https://documentation.solarwinds.com/en/success_center/loggly/content/admin/troubleshooting-http.htm</a></li></ul></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;网页打开某个网站，可以看到正常的内容，这个 &lt;code&gt;HTTP Status code&lt;/code&gt; 是 &lt;code&gt;200&lt;/code&gt;，没有显示在页面上。&lt;/p&gt;
&lt;p&gt;但是偶尔会看到整页白底，但是上面写 &lt;code&gt;400&lt;/code&gt;、&lt;code&gt;403&lt;/code&gt;、&lt;code&gt;500&lt;/code&gt;，或者画面比较好看的 &lt;code&gt;404&lt;/code&gt; 此页面找不到等等，那这些代码是什么意思呢？&lt;/p&gt;
&lt;p&gt;做为一个运维工程师，遇到这样的情况，你又应该怎么判断是哪里出问题了呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="HTTP" scheme="https://www.hi-linux.com/categories/HTTP/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="HTTP" scheme="https://www.hi-linux.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 之父创造的 Rocky Linux 8.4 正式版发布了！(内附镜像下载地址）</title>
    <link href="https://www.hi-linux.com/posts/24084.html"/>
    <id>https://www.hi-linux.com/posts/24084.html</id>
    <published>2021-06-25T01:00:00.000Z</published>
    <updated>2021-06-25T01:51:52.060Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>跟随上个月的 Red Hat Enterprise Linux 8.4 版本的发布，再到后来的基于 RHEL 8.4 的 Alma Linux、Oracle Linux 和 CentOS 8的更新，RockyLinux 今天的 v8.4 版本已经全面上线。<strong>Rocky Linux 是CentOS创始人Greg Kurtzer等人瞄准的免费 RHEL替代品。</strong></p></blockquote><p>Rocky Linux 8.4 现已正式发布。Rocky Linux 是一个社区版的企业操作系统，旨在与 Red Hat Enterprise Linux 8.4 实现 100% 的 bug-for-bug 兼容。官方表示，由于这是 Rocky Linux 的第一个版本，所以发布说明只反映了各版本之间上游功能的变化。且不支持从 Rocky Linux 8.3 RC1、Rocky Linux 8.4 RC1 或任何其他候选版本迁移到 Rocky Linux 8.4。</p><p>Rocky Linux 团队提供了 migrate2rocky 工具用于帮助使用者从其他企业 Linux 系统迁移到 Rocky Linux 8.4。此工具已经过测试并且可以正常运行，但使用时需自担风险。</p><h2><span id="新模块">新模块</span></h2><p>Rocky Linux 8.4 中全新的 module streams 包括以下内容：</p><ul><li>Python 3.9</li><li>SWIG 4.0</li><li>Subversion 1.14</li><li>Redis 6</li><li>PostgreSQL 13</li><li>MariaDB 10.5</li></ul><a id="more"></a><h2><span id="主要变化">主要变化</span></h2><p>Rocky Linux 8.4 的主要变化体现在安全、网络、内核和高可用以及集群等方面。</p><h3><span id="安全">安全</span></h3><ul><li>Libreswan 提供的 IPsec VPN 现在支持 IKEv2 的 TCP 封装和安全标签</li><li>scap-security-guide 已更新到到 0.1.54 ，OpenSCAP 已更新到 1.3.4。这更新提供了实质性的改进，包括优化内存管理</li><li>fapolicyd 框架现在提供完整性检查，并且 RPM 插件注册由 YUM 包管理器或 RPM 包管理器更新</li></ul><h3><span id="网络">网络</span></h3><ul><li>完全支持 Nmstate（主机的网络 API），这些 nmstate 包提供了一个库和 nmstatectl 命令行，以声明方式管理主机网络设置</li><li>支持 MPLS（多协议标签交换）</li><li>iproute2 引入了三个新的流量控制 (tc) 操作：<code>mac_push</code>, <code>push_eth</code>, 和<code>pop_eth</code>，并添加 MPLS 标签</li></ul><h3><span id="内核">内核</span></h3><ul><li>主动压缩功能：在发出分配请求之前定期启动内存压缩工作。因此，降低了特定内存分配请求的延迟。</li><li>提供了用于控制组技术的平板内存控制器。Slab 内存控制器优化了内存的利用率，并且能够将内存记帐从页面级别转移到对象级别。因此，可以观察到总内核内存占用量显著下降，并改善了内存碎片情况。</li><li>时间命名空间功能：此功能适用于更改 Linux 容器内的日期和时间。现在也可以在检查点恢复后进行容器内时钟的调整。</li><li>支持第 8、 9 代英特尔酷睿处理器中设置的错误检测和纠正 (EDAC) 内核模块。</li></ul><h3><span id="高可用和集群">高可用和集群</span></h3><ul><li>维护状态数据的持久性：Pacemaker 资源代理可以异步检测故障并立即将故障注入 Pacemaker，而无需等待下一个监控间隔。持久性资源代理还可以加快具有高状态开销的服务的集群响应时间，因为维护状态数据可以通过不为每个操作单独调用状态来减少集群操作（例如启动、停止和监控）的状态开销。</li></ul><h3><span id="编译器和开发工具">编译器和开发工具</span></h3><p>以下编译器工具集已更新：</p><ul><li>GCC Toolset 10</li><li>LLVM Toolset 11.0.0</li><li>Rust Toolset 1.49.0</li><li>Go Toolset 1.15.7</li></ul><h3><span id="身份管理">身份管理</span></h3><ul><li>Rocky Linux 8.4 提供了 Ansible 模块，用于自动化管理身份管理（IdM）中基于角色的访问控制（RBAC），一个 Ansible role 用于备份和恢复 IdM 服务器，以及一个 Ansible 模块用于位置管理。</li></ul><p>更多详情可查看：<a href="https://docs.rockylinux.org/zh_CN/release_notes/8.4/" target="_blank" rel="noopener">https://docs.rockylinux.org/zh_CN/release_notes/8.4/</a></p><p><strong>Rocky Linux 8.4 正式版官方下载地址：</strong> <a href="https://rockylinux.org/download/" target="_blank" rel="noopener">https://rockylinux.org/download/</a></p><blockquote><p>本文转载自：「 开源中国 」，原文：<a href="https://tinyurl.com/3b2p5mv3" target="_blank" rel="noopener">https://tinyurl.com/3b2p5mv3</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;跟随上个月的 Red Hat Enterprise Linux 8.4 版本的发布，再到后来的基于 RHEL 8.4 的 Alma Linux、Oracle Linux 和 CentOS 8的更新，RockyLinux 今天的 v8.4 版本已经全面上线。&lt;strong&gt;Rocky Linux 是CentOS创始人Greg Kurtzer等人瞄准的免费 RHEL替代品。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Rocky Linux 8.4 现已正式发布。Rocky Linux 是一个社区版的企业操作系统，旨在与 Red Hat Enterprise Linux 8.4 实现 100% 的 bug-for-bug 兼容。官方表示，由于这是 Rocky Linux 的第一个版本，所以发布说明只反映了各版本之间上游功能的变化。且不支持从 Rocky Linux 8.3 RC1、Rocky Linux 8.4 RC1 或任何其他候选版本迁移到 Rocky Linux 8.4。&lt;/p&gt;
&lt;p&gt;Rocky Linux 团队提供了 migrate2rocky 工具用于帮助使用者从其他企业 Linux 系统迁移到 Rocky Linux 8.4。此工具已经过测试并且可以正常运行，但使用时需自担风险。&lt;/p&gt;
&lt;h2 id=&quot;新模块&quot;&gt;新模块&lt;/h2&gt;
&lt;p&gt;Rocky Linux 8.4 中全新的 module streams 包括以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.9&lt;/li&gt;
&lt;li&gt;SWIG 4.0&lt;/li&gt;
&lt;li&gt;Subversion 1.14&lt;/li&gt;
&lt;li&gt;Redis 6&lt;/li&gt;
&lt;li&gt;PostgreSQL 13&lt;/li&gt;
&lt;li&gt;MariaDB 10.5&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CentOS" scheme="https://www.hi-linux.com/categories/CentOS/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="CentOS" scheme="https://www.hi-linux.com/tags/CentOS/"/>
    
  </entry>
  
  <entry>
    <title>一文读懂 eBPF 对 Kubernetes 可观测的重要性</title>
    <link href="https://www.hi-linux.com/posts/14561.html"/>
    <id>https://www.hi-linux.com/posts/14561.html</id>
    <published>2021-06-23T01:00:00.000Z</published>
    <updated>2021-06-23T04:32:40.108Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>作者：Lavanya Chockalingam，New Relic 高级产品营销经理。最初发表在 <strong>New Relic 的博客[1]</strong>。</p></blockquote><p>在 Linux 内核中工作是实现安全性、网络和可观察性特性的理想选择。然而，这并不是没有挑战。无论是修改内核源代码，还是添加模块，开发人员传统上发现他们要与难以调试的复杂基础设施和抽象层作斗争。<strong>Extended BPF</strong>[2]（eBPF）解决了这两个问题。</p><p>Extended Berkeley Packet Filter（eBPF）是一种内核技术（从 Linux 4.x 开始），它允许程序在无需更改内核源代码，或添加额外模块的情况下运行。你可以将其视为 Linux 内核中的轻量级沙箱虚拟机（VM），程序员可以在其中运行 BPF 字节码，从而利用特定的内核资源。</p><p>使用 eBPF 消除了更改内核源代码的需要，并简化了软件利用现有层的能力。因此，它是一项强大的技术，有可能从根本上改变网络、可观察性和安全性等服务的交付方式。</p><p>下面详细介绍一下它是什么，它是如何工作的，以及何时考虑实施它。</p><a id="more"></a><h2><span id="ebpf-是如何工作">eBPF 是如何工作</span></h2><p>eBPF 程序是事件驱动的，并附加到代码路径上。代码路径包含特定的触发器（称为钩子），这些触发器在传递附加的 eBPF 程序时执行它们。钩子的一些例子包括网络事件、系统调用、函数项和内核追踪点。</p><p>当触发时，代码首先被编译为 BPF 字节码。然后，字节码在运行之前会被验证，以确保它不会创建循环。这个步骤可以防止程序无意或故意损害 Linux 内核。</p><p>在钩子上触发程序之后，它就会进行助手调用。这些助手调用是为 eBPF 配备许多用于访问内存的特性的函数。助手调用需要由内核预先定义，但是存在的函数列表在<strong>不断增长</strong>[3]。</p><p>eBPF 最初被用作过滤网络数据包时，提高可观察性和安全性的一种方法。然而，随着时间的推移，它成为了一种使用户提供的代码实现更安全、更方便和性能更好的方法。</p><h2><span id="ebpf-的优点">eBPF 的优点</span></h2><p>eBPF 通常用于<strong>追踪</strong>[4]用户空间进程，它的优点在这里很明显。这是一个安全和有用的方法来确保：</p><ul><li>速度和性能。eBPF 可以将包处理从内核空间转移到用户空间。同样，eBPF 是即时（JIT）编译器。编译字节码后，将调用 eBPF，而不是为每个方法调用字节码的新解释。</li><li>低侵入性。当作为调试器使用时，eBPF 不需要停止程序来观察其状态。</li><li>安全。程序实际上是沙箱化的，这意味着内核源代码仍然受到保护并且没有改变。验证步骤确保资源不会被运行无限循环的程序堵塞。</li><li>方便。创建钩子内核函数的代码比构建和维护内核模块的工作要少。</li><li>统一的追踪。eBPF 为你提供了一个用于追踪流程的单一、强大且可访问的框架。这增加了可见性和安全性。</li><li>可编程性。使用 eBPF 有助于增加环境的特性丰富度，而无需添加额外的层。同样，由于代码直接在内核中运行，因此可以在 eBPF 事件之间存储数据，而不像其他追踪程序那样转储数据。</li><li>表达能力。eBPF 具有表达性，能够执行通常只能在高级语言中找到的功能。</li></ul><h2><span id="ebpf-的最佳实践">eBPF 的最佳实践</span></h2><p>由于 eBPF 是一项如此新的技术，许多东西仍未被探索。随着技术的发展，围绕 eBPF 的最佳实践仍在不断发展。虽然没有明确的最佳实践集存在，但你可以做一些事情来确保有效、高效的程序。</p><p>如果你正在为你的生态系统使用 eBPF，我们建议你：</p><ul><li>使用<strong>LLVM Clang</strong>[5]将 C 编译成字节码。当 eBPF 首次出现时，需要手工编写和组装程序。然后，开发人员使用内核的汇编程序生成字节码。幸运的是，现在不再需要这样做了。Clang 提供了 C 语言的前端基础设施和工具。</li><li>编写 BPF 程序时请使用 BCC 工具包。<strong>BPF Compiler Collection</strong>[6]（BCC）是一个工具包，可以帮助你创建高效的内核追踪和操作程序。它特别适合于性能分析和网络流量控制相关的任务。</li></ul><h2><span id="ebpf-的缺点">eBPF 的缺点</span></h2><p>尽管 eBPF 功能强大，但它并不是适合每个项目或生态系统的灵丹妙药。eBPF 确实有一些明显的缺点，这可能会使它在某些实例中工作起来令人沮丧。一些开发人员可能会发现 eBPF 不适合使用，原因如下：</p><ul><li>它仅限于 Linux 和一个最新的内核。eBPF 是在 Linux 内核中开发的，并且是完全面向 Linux 内核的。这使得它比其他追踪器更难携带。此外，你需要一个相当新的内核。如果你运行的是比 v4.13 更老的版本，你将无法使用它。</li><li>沙箱程序是有限的。eBPF 通过限制程序可以访问的资源来提高安全性。然而，通过限制程序可以访问的操作系统部分，功能也可能受到限制。</li></ul><h2><span id="ebpf-的常用情况">eBPF 的常用情况</span></h2><p>eBPF 在<strong>云原生应用</strong>[7]中正迅速获得关注。因此，eBPF 最常用于两种情况：</p><ul><li>需要使用内核追踪实现可观察性。在这种情况下，eBPF 更快、更准确。这里不涉及<strong>上下文切换</strong>[8]，而且 eBPF 程序是基于事件的，因此没有特定的触发器就不会运行任何程序——你不会错过任何事件。</li><li>传统的安全监控不起作用。eBPF 在分布式和基于容器的环境中得到了广泛的应用，包括<strong>Kubernetes</strong>[9]。在这些环境中，eBPF 可以缩小可见性差距，因为它可以提供对 HTTP 通信的可见性。</li></ul><p>你可能还会发现 eBPF 被部署用于其他安全措施，包括：</p><ul><li>防火墙</li><li>设备驱动程序</li><li>网络性能监控</li></ul><h2><span id="new-relic-和-ebpf">New Relic 和 eBPF</span></h2><p><strong>Pixie</strong>[10]（早前被 New Relic 收购了）是一个开源的 kubernetes-native-in-cluster 可观察平台，它提供了 Kubernetes 工作负载的即时可见性，无需手动检测。eBPF 提供了 Pixie 平台背后的大部分魔力。如前所述，eBPF 允许在触发事件时运行受限制的代码。这个事件可以是内核空间（kprobes）或用户空间（uprobes）中的函数调用。Pixie 同时使用 uprobes 和 kprobes 来支持跨服务和应用程序的可观察性。</p><p>Pixie 利用 eBPF 自动获取遥测数据，其边缘机智能将这些数据与 Kubernetes 元数据连接起来，在保持数据局部性的同时提供可见性。这种可见性补充了 New Relic 强大的 Kubernetes 可观测性解决方案。从 5 月底开始，你将能够将 Pixie 生成的遥测数据发送到 New Relic One，获得可扩展的留存率、强大的可视化、高级关联和智能警报功能。</p><h2><span id="ebpf-是有效的可观察性">eBPF 是有效的可观察性</span></h2><p>eBPF 是一种新技术，它改进了 Linux 内核中的可观察性、联网和安全性。它消除了更改内核源代码或添加模块的需要，因此你可以创建更丰富的基础设施来支持你的系统，而不会使其过于复杂。</p><h2><span id="总结">总结</span></h2><p>我们了解了 eBPF 是什么，它是如何工作的，以及为什么它在分布式环境中如此有用。通过从内核层进行监控，许多与云中的可观测性相关的挑战都得到了解决。你可以在数据中享受更深入的可见性、更多的上下文和更准确的信息。</p><h3><span id="参考资料">参考资料</span></h3><ol><li>New Relic 的博客: <a href="https://newrelic.com/blog/best-practices/what-is-ebpf" target="_blank" rel="noopener">https://newrelic.com/blog/best-practices/what-is-ebpf</a></li><li>Extended BPF: <a href="https://www.kernel.org/doc/html/latest/bpf/index.html" target="_blank" rel="noopener">https://www.kernel.org/doc/html/latest/bpf/index.html</a></li><li>不断增长: <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html" target="_blank" rel="noopener">https://man7.org/linux/man-pages/man7/bpf-helpers.7.html</a></li><li>追踪: <a href="https://blog.pixielabs.ai/ebpf-function-tracing/post/" target="_blank" rel="noopener">https://blog.pixielabs.ai/ebpf-function-tracing/post/</a></li><li>LLVM Clang: <a href="https://clang.llvm.org/" target="_blank" rel="noopener">https://clang.llvm.org/</a></li><li>BPF Compiler Collection: <a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener">https://github.com/iovisor/bcc</a></li><li>云原生应用: <a href="https://newrelic.com/solutions/cloud-native" target="_blank" rel="noopener">https://newrelic.com/solutions/cloud-native</a></li><li>上下文切换: <a href="https://www.quora.com/What-is-context-switching-in-Linux" target="_blank" rel="noopener">https://www.quora.com/What-is-context-switching-in-Linux</a></li><li>Kubernetes: <a href="https://kubernetes.io/blog/2017/12/using-ebpf-in-kubernetes/" target="_blank" rel="noopener">https://kubernetes.io/blog/2017/12/using-ebpf-in-kubernetes/</a></li><li>Pixie: <a href="http://pixielabs.ai/" target="_blank" rel="noopener">http://pixielabs.ai/</a></li></ol><blockquote><p>本文转载自：「  CNCF 」，原文：<a href="https://tinyurl.com/ymz2kh4j" target="_blank" rel="noopener">https://tinyurl.com/ymz2kh4j</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;作者：Lavanya Chockalingam，New Relic 高级产品营销经理。最初发表在 &lt;strong&gt;New Relic 的博客[1]&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 Linux 内核中工作是实现安全性、网络和可观察性特性的理想选择。然而，这并不是没有挑战。无论是修改内核源代码，还是添加模块，开发人员传统上发现他们要与难以调试的复杂基础设施和抽象层作斗争。&lt;strong&gt;Extended BPF&lt;/strong&gt;[2]（eBPF）解决了这两个问题。&lt;/p&gt;
&lt;p&gt;Extended Berkeley Packet Filter（eBPF）是一种内核技术（从 Linux 4.x 开始），它允许程序在无需更改内核源代码，或添加额外模块的情况下运行。你可以将其视为 Linux 内核中的轻量级沙箱虚拟机（VM），程序员可以在其中运行 BPF 字节码，从而利用特定的内核资源。&lt;/p&gt;
&lt;p&gt;使用 eBPF 消除了更改内核源代码的需要，并简化了软件利用现有层的能力。因此，它是一项强大的技术，有可能从根本上改变网络、可观察性和安全性等服务的交付方式。&lt;/p&gt;
&lt;p&gt;下面详细介绍一下它是什么，它是如何工作的，以及何时考虑实施它。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="eBPF" scheme="https://www.hi-linux.com/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>再见 Teamviewer，是时候拥抱下一代远程控制工具 RustDesk 了！</title>
    <link href="https://www.hi-linux.com/posts/23378.html"/>
    <id>https://www.hi-linux.com/posts/23378.html</id>
    <published>2021-06-22T01:00:00.000Z</published>
    <updated>2021-06-22T01:15:28.032Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>对很多 Mac 用户来说，想用远程控制请教下大佬，太难了。</p><p>在 Windows 上一个 QQ 就能搞定的事，而 Mac 用户几乎只能依赖 Teamviewer。</p><p>Teamviewer 还遭到不少吐槽：占用高、打开慢，有时还因为被识别为商用而收费……</p><p>现在，你不必再和它较劲了。</p><a id="more"></a><p>这款名叫 <strong>RustDesk</strong> 的远程桌面软件火了！已经在 Github 上获得了 <strong>6.1k</strong> 颗星。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210618093429673-2021-06-18-XpQTXT.png" alt></p><p>这个名字已经 “暴露” 了它，没错，这款软件的开发语言正是 <strong>Rust</strong>。</p><p>RustDesk 支持多个平台，并且 “安装包” 只有 8~9MB，相当<strong>轻量</strong>了。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210618093608925-2021-06-18-t14cEh.png" alt></p><p>而且，这款软件属于半便携式，无需安装和配置，<strong>开箱即用</strong>。用户界面也是非常直观、简单：</p><p><img src="https://img.hi-linux.com/staticfile/113112362-ae4deb80-923b-11eb-957d-ff88daad4f06-2021-06-18-5qp5lD.png" alt></p><p>RustDesk 采用的是<strong>加密直连</strong>，先尝试打洞直连，帮助两者建立连接，如果失败再通过服务器转发。</p><p>它支持<strong>跨平台传输</strong>文件。比如，Mac 和 Windows 电脑之间进行文件传输时，界面长这样：</p><p><img src="https://img.hi-linux.com/staticfile/113112857-3fbd5d80-923c-11eb-9836-768325faf906-2021-06-18-GlY6Fx.png" alt></p><p>RustDesk 开发者还是一位<strong>中国程序员</strong>，当然软件也支持中文版。</p><p>苦远程久矣的我，上手试了一下～</p><p>选择 Mac 和 Android 手机客户端，下载安装一气呵成。</p><p>打开后，界面的确非常清爽，大概是这样：</p><p><img src="https://img.hi-linux.com/staticfile/image-20210618094901549-2021-06-18-UW6X7G.png" alt></p><p><img src="https://img.hi-linux.com/staticfile/113112619-f705a480-923b-11eb-911d-97e984ef52b6-20210618101248945-2021-06-18-6mxGk1.png" alt></p><blockquote><p>注意：公共服务器目前是<strong>不支持</strong>修改 ID 的。</p></blockquote><p>从去年开始，作者已经开始不断更新软件版本。有不少网友表示：软件体积小、界面简洁，比 Teamviewer 香～</p><p>不过也有人基于安全性提出质疑。</p><p>作者在 V2EX 上表示，已经在 GitHub 上开源了 90% 的代码（算上总代码量），但是保留了服务器代码以及移动端。</p><p>此外，由于存在内网穿透失败而连接很慢的情况，RustDesk 还支持<strong>自建中继服务器</strong>，并且提供了教程。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210618095504045-2021-06-18-lxFYtq.png" alt></p><p>想要了解更多详情，可戳下方链接～</p><p>传送门：</p><ul><li><a href="https://rustdesk.com/zh/" target="_blank" rel="noopener">https://rustdesk.com/zh/</a></li><li><a href="https://github.com/rustdesk/rustdesk" target="_blank" rel="noopener">https://github.com/rustdesk/rustdesk</a></li><li><a href="https://gitee.com/rustdesk" target="_blank" rel="noopener">https://gitee.com/rustdesk</a></li><li><a href="https://gitee.com/rustdesk/rustdesk-server/blob/master/id-relay-set.md" target="_blank" rel="noopener">https://gitee.com/rustdesk/rustdesk-server/blob/master/id-relay-set.md</a></li></ul><p>参考链接：</p><ul><li><a href="https://www.v2ex.com/t/772047" target="_blank" rel="noopener">https://www.v2ex.com/t/772047</a></li><li><a href="https://www.v2ex.com/t/712086?p=1" target="_blank" rel="noopener">https://www.v2ex.com/t/712086?p=1</a></li><li><a href="https://juejin.cn/post/6881056112909500430" target="_blank" rel="noopener">https://juejin.cn/post/6881056112909500430</a></li></ul><blockquote><p>本文转载自：「 量子位 」，原文：<a href="https://tinyurl.com/p6msym8h" target="_blank" rel="noopener">https://tinyurl.com/p6msym8h</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对很多 Mac 用户来说，想用远程控制请教下大佬，太难了。&lt;/p&gt;
&lt;p&gt;在 Windows 上一个 QQ 就能搞定的事，而 Mac 用户几乎只能依赖 Teamviewer。&lt;/p&gt;
&lt;p&gt;Teamviewer 还遭到不少吐槽：占用高、打开慢，有时还因为被识别为商用而收费……&lt;/p&gt;
&lt;p&gt;现在，你不必再和它较劲了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="RustDesk" scheme="https://www.hi-linux.com/categories/RustDesk/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="RustDesk" scheme="https://www.hi-linux.com/tags/RustDesk/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你使用 Kube-Vip 部署一个生产级别的高可用 Kubernetes 集群</title>
    <link href="https://www.hi-linux.com/posts/13616.html"/>
    <id>https://www.hi-linux.com/posts/13616.html</id>
    <published>2021-06-21T01:00:00.000Z</published>
    <updated>2021-06-21T01:37:47.488Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>kube-vip</code> 可以在你的控制平面节点上提供一个 Kubernetes 原生的 HA 负载均衡，我们不需要再在外部设置 HAProxy 和 Keepalived 来实现集群的高可用了。</p><p><code>kube-vip</code> 是一个为 Kubernetes 集群内部和外部提供高可用和负载均衡的开源项目，在 Vmware 的 Tanzu 项目中已经使用 kube-vip 替换了用于 vSphere 部署的 HAProxy 负载均衡器，本文我们将先来了解 kube-vip 如何用于 Kubernetes 控制平面的高可用和负载均衡功能。</p><h2><span id="特点">特点</span></h2><p>Kube-Vip 最初是为 Kubernetes 控制平面提供 HA 解决方案而创建的，随着时间的推移，它已经发展为将相同的功能合并到 Kubernetes 的 LoadBalancer 类型的 Service 中了。</p><ul><li>VIP 地址可以是 IPv4 或 IPv6</li><li>带有 ARP（第2层）或 BGP（第3层）的控制平面</li><li>使用领导选举或 raft 控制平面</li><li>带有 kubeadm（静态 Pod）的控制平面 HA</li><li>带有 K3s/和其他（DaemonSets）的控制平面 HA</li><li>使用 ARP 领导者选举的 Service LoadBalancer（第 2 层）</li><li>通过 BGP 使用多个节点的 Service LoadBalancer</li><li>每个命名空间或全局的 Service LoadBalancer 地址池</li><li>Service LoadBalancer 地址通过 UPNP 暴露给网关</li></ul><a id="more"></a><h2><span id="haproxy-和-kube-vip-的-ha-集群">HAProxy 和 kube-vip 的 HA 集群</span></h2><p>在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件/软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用 HAProxy + Keepalived 来实现这个功能。一般情况下我们创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP 为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes 控制器平面节点上。</p><p><img src="https://img.hi-linux.com/staticfile/640-2021-06-17-heYabg.jpg" alt></p><p>接下来我们再来看看如果我们使用 kube-vip 的话会怎样呢？</p><p><img src="https://img.hi-linux.com/staticfile/640-20210617164455474-2021-06-17-weRMv3.jpg" alt></p><p>kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过ARP 对话来识别每个节点上的其他主机，所以需要在 hosts 文件中设置每个节点的 IP 地址，我们可以选择 BGP 或 ARP 来设置负载平衡器，这与 Metal LB 比较类似。这里我们没有 BGP 服务，只是想快速测试一下，所以这里我们使用 ARP 与静态 pod 的方式。</p><h2><span id="kube-vip-架构">kube-vip 架构</span></h2><p>kube-vip 有许多功能设计选择提供高可用性或网络功能，作为VIP/负载平衡解决方案的一部分。</p><h3><span id="cluster">Cluster</span></h3><p>kube-vip 建立了一个多节点或多模块的集群来提供高可用性。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的领导者，而在 BGP 模式下，所有节点都会通知 VIP 地址。</p><p>当使用 ARP 或 layer2 时，它将使用领导者选举，当然也可以使用 raft 集群技术，但这种方法在很大程度上已经被领导者选举所取代，特别是在集群中运行时。</p><h3><span id="虚拟ip">虚拟IP</span></h3><p>集群中的领导者将分配 vip，并将其绑定到配置中声明的选定接口上。当领导者改变时，它将首先撤销 vip，或者在失败的情况下，vip 将直接由下一个当选的领导者分配。</p><p>当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的 <code>vip &lt;-&gt; MAC</code> 地址映射，直到 ARP 过期（通常是30秒）并检索到一个新的 <code>vip &lt;-&gt; MAC</code> 映射，这可以通过使用无偿的 ARP 广播来优化。</p><h3><span id="arp">ARP</span></h3><p>kube-vip可以被配置为广播一个无偿的 arp（可选），通常会立即通知所有本地主机 <code>vip &lt;-&gt; MAC</code> 地址映射已经改变。</p><p>下面我们可以看到，当 ARP 广播被接收时，故障转移通常在几秒钟内完成。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">64 bytes from 192.168.0.75: icmp_seq&#x3D;146 ttl&#x3D;64 time&#x3D;0.258 ms</span><br><span class="line">64 bytes from 192.168.0.75: icmp_seq&#x3D;147 ttl&#x3D;64 time&#x3D;0.240 ms</span><br><span class="line">92 bytes from 192.168.0.70: Redirect Host(New addr: 192.168.0.75)</span><br><span class="line">Vr HL TOS  Len   ID Flg  off TTL Pro  cks      Src      Dst</span><br><span class="line"> 4  5  00 0054 bc98   0 0000  3f  01 3d16 192.168.0.95  192.168.0.75</span><br><span class="line"></span><br><span class="line">Request timeout for icmp_seq 148</span><br><span class="line">92 bytes from 192.168.0.70: Redirect Host(New addr: 192.168.0.75)</span><br><span class="line">Vr HL TOS  Len   ID Flg  off TTL Pro  cks      Src      Dst</span><br><span class="line"> 4  5  00 0054 75ff   0 0000  3f  01 83af 192.168.0.95  192.168.0.75</span><br><span class="line"></span><br><span class="line">Request timeout for icmp_seq 149</span><br><span class="line">92 bytes from 192.168.0.70: Redirect Host(New addr: 192.168.0.75)</span><br><span class="line">Vr HL TOS  Len   ID Flg  off TTL Pro  cks      Src      Dst</span><br><span class="line"> 4  5  00 0054 2890   0 0000  3f  01 d11e 192.168.0.95  192.168.0.75</span><br><span class="line"></span><br><span class="line">Request timeout for icmp_seq 150</span><br><span class="line">64 bytes from 192.168.0.75: icmp_seq&#x3D;151 ttl&#x3D;64 time&#x3D;0.245 ms</span><br></pre></td></tr></table></figure><h2><span id="使用-kube-vip">使用 kube-vip</span></h2><p>接下来我们来使用 kube-vip 搭建一个高可用的 Kubernetes 集群。先准备6个节点：</p><ul><li>3个控制平面节点</li><li>3个 worker 节点</li></ul><p><img src="https://img.hi-linux.com/staticfile/640-20210617164502472-2021-06-17-q1QUur.jpg" alt></p><p>首先在宿主机上面安装相关依赖，包括 kubeadm、kubelet、kubectl 以及一个容器运行时，这里我们使用的是 containerd。</p><p>获取 kube-vip 的 docker 镜像，并在 <code>/etc/kuberentes/manifests</code> 中设置静态 pod 的 yaml 资源清单文件，这样 Kubernetes 就会自动在每个控制平面节点上部署 kube-vip 的 pod 了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 设置VIP地址</span><br><span class="line">$ export VIP&#x3D;192.168.0.100</span><br><span class="line">$ export INTERFACE&#x3D;eth0</span><br><span class="line">$ ctr image pull docker.io&#x2F;plndr&#x2F;kube-vip:0.3.1</span><br><span class="line">$ ctr run --rm --net-host docker.io&#x2F;plndr&#x2F;kube-vip:0.3.1 vip \</span><br><span class="line">&#x2F;kube-vip manifest pod \</span><br><span class="line">--interface $INTERFACE \</span><br><span class="line">--vip $VIP \</span><br><span class="line">--controlplane \</span><br><span class="line">--services \</span><br><span class="line">--arp \</span><br><span class="line">--leaderElection | tee  &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-vip.yaml</span><br></pre></td></tr></table></figure><p>接下来就可以配置 kubeadm 了，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; ~&#x2F;init_kubelet.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubeadm.k8s.io&#x2F;v1beta2</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- token: &quot;9a08jv.c0izixklcxtmnze7&quot;</span><br><span class="line">description: &quot;kubeadm bootstrap token&quot;</span><br><span class="line">ttl: &quot;24h&quot;</span><br><span class="line">nodeRegistration:</span><br><span class="line">criSocket: &quot;&#x2F;var&#x2F;run&#x2F;containerd&#x2F;containerd.sock&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeadm.k8s.io&#x2F;v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">controlPlaneEndpoint: &quot;192.168.0.100:6443&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: kubelet.config.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">cgroupDriver: &quot;systemd&quot;</span><br><span class="line">protectKernelDefaults: true</span><br><span class="line">EOF</span><br><span class="line">$ kubeadm init --config init_kubelet.yaml --upload-certs</span><br></pre></td></tr></table></figure><p>然后安装 CNI，比如我们选择使用 Cilium。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ curl https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;helm&#x2F;helm&#x2F;master&#x2F;scripts&#x2F;get-helm-3 | bash</span><br><span class="line">$ helm repo add cilium https:&#x2F;&#x2F;helm.cilium.io&#x2F;</span><br><span class="line">$ helm install cilium cilium&#x2F;cilium --version 1.9.4 \</span><br><span class="line">--namespace kube-system</span><br></pre></td></tr></table></figure><p>在第一个控制平面节点准备好后，让其他节点加入你的集群。对于其他控制平面节点，运行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm join 192.168.0.100:6443 --token hash.hash\</span><br><span class="line">     --discovery-token-ca-cert-hash sha256:hash \</span><br><span class="line">     --control-plane --certificate-key key</span><br></pre></td></tr></table></figure><p>对于工作节点，运行类似命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm join 192.168.0.100:6443 --token hash.hash\</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:hash</span><br></pre></td></tr></table></figure><p>正常执行完成后集群就可以启动起来了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node -o wide</span><br><span class="line">NAME           STATUS   ROLES                  AGE    VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span><br><span class="line">k8s-master-0   Ready    control-plane,master   121m   v1.20.2   192.168.0.201   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-45-generic   containerd:&#x2F;&#x2F;1.4.3</span><br><span class="line">k8s-master-1   Ready    control-plane,master   114m   v1.20.2   192.168.0.202   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-45-generic   containerd:&#x2F;&#x2F;1.4.3</span><br><span class="line">k8s-master-2   Ready    control-plane,master   113m   v1.20.2   192.168.0.203   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-45-generic   containerd:&#x2F;&#x2F;1.4.3</span><br><span class="line">k8s-worker-0   Ready    &lt;none&gt;                 114m   v1.20.2   192.168.0.204   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-45-generic   containerd:&#x2F;&#x2F;1.4.3</span><br><span class="line">k8s-worker-1   Ready    &lt;none&gt;                 114m   v1.20.2   192.168.0.205   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-45-generic   containerd:&#x2F;&#x2F;1.4.3</span><br><span class="line">k8s-worker-2   Ready    &lt;none&gt;                 112m   v1.20.2   192.168.0.206   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-45-generic   containerd:&#x2F;&#x2F;1.4.3</span><br></pre></td></tr></table></figure><p>现在可以看到我们的控制面的端点是 192.168.0.100，没有其他额外的节点，是不是非常方便。</p><p>参考文档： <a href="https://inductor.medium.com/say-good-bye-to-haproxy-and-keepalived-with-kube-vip-on-your-ha-k8s-control-plane-bb7237eca9fc" target="_blank" rel="noopener">https://inductor.medium.com/say-good-bye-to-haproxy-and-keepalived-with-kube-vip-on-your-ha-k8s-control-plane-bb7237eca9fc</a></p><blockquote><p>本文转载自：「 k8s 技术圈 」，原文：<a href="https://tinyurl.com/f66ejhbc" target="_blank" rel="noopener">https://tinyurl.com/f66ejhbc</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;kube-vip&lt;/code&gt; 可以在你的控制平面节点上提供一个 Kubernetes 原生的 HA 负载均衡，我们不需要再在外部设置 HAProxy 和 Keepalived 来实现集群的高可用了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kube-vip&lt;/code&gt; 是一个为 Kubernetes 集群内部和外部提供高可用和负载均衡的开源项目，在 Vmware 的 Tanzu 项目中已经使用 kube-vip 替换了用于 vSphere 部署的 HAProxy 负载均衡器，本文我们将先来了解 kube-vip 如何用于 Kubernetes 控制平面的高可用和负载均衡功能。&lt;/p&gt;
&lt;h2 id=&quot;特点&quot;&gt;特点&lt;/h2&gt;
&lt;p&gt;Kube-Vip 最初是为 Kubernetes 控制平面提供 HA 解决方案而创建的，随着时间的推移，它已经发展为将相同的功能合并到 Kubernetes 的 LoadBalancer 类型的 Service 中了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VIP 地址可以是 IPv4 或 IPv6&lt;/li&gt;
&lt;li&gt;带有 ARP（第2层）或 BGP（第3层）的控制平面&lt;/li&gt;
&lt;li&gt;使用领导选举或 raft 控制平面&lt;/li&gt;
&lt;li&gt;带有 kubeadm（静态 Pod）的控制平面 HA&lt;/li&gt;
&lt;li&gt;带有 K3s/和其他（DaemonSets）的控制平面 HA&lt;/li&gt;
&lt;li&gt;使用 ARP 领导者选举的 Service LoadBalancer（第 2 层）&lt;/li&gt;
&lt;li&gt;通过 BGP 使用多个节点的 Service LoadBalancer&lt;/li&gt;
&lt;li&gt;每个命名空间或全局的 Service LoadBalancer 地址池&lt;/li&gt;
&lt;li&gt;Service LoadBalancer 地址通过 UPNP 暴露给网关&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>科普 | 抖音服务器带宽有多大，为什么能够供上亿用户同时刷？</title>
    <link href="https://www.hi-linux.com/posts/58624.html"/>
    <id>https://www.hi-linux.com/posts/58624.html</id>
    <published>2021-06-20T01:00:00.000Z</published>
    <updated>2021-06-20T12:20:43.394Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>最近看到一个有意思的提问：抖音服务器带宽有多大，为什么能够供那么多人同时刷？今天来给大家科普一下。</p></blockquote><p>抖音，百度，阿里云，腾讯都是自建的数据中心，都是 T 级别出口带宽（总出口带宽），也就是达到 1T=1024G/s 的出口带宽，服务器总数基本都在 20 万台以上，甚至阿里云都超过了 100 万台。</p><p>字节跳动的数据中心总带宽，可能在 10TB 级别左右，预期突破 15TB 级别不远了。</p><a id="more"></a><p>一般情况下：总出口带宽 1TB，实际机房出口带宽可能只有 100G 上下，这是采用双（多）链路设计，双出口实现动态流量分担，总的出口带宽可以达到 T 级别。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210618125403552-2021-06-18-Ast4Xn.jpg" alt="大型数据中心"></p><p>想要同一时间有数亿人在线，TB 级别带宽，CDN 加速和多节点，负载均衡等等技术缺一不可。（这个设计技术过于复杂，有相关专业朋友，可以评论简要概述）</p><p><img src="https://img.hi-linux.com/staticfile/640-20210618132137982-2021-06-18-SKL3gf.jpg" alt="CDN 加速"></p><h2><span id="字节跳动有多少台服务器">字节跳动有多少台服务器？</span></h2><p>根据网络数据整理，2017 年 2-3 万台服务器，这个时候主要是租用服务器为主。</p><p>2018 年，字节跳动自己建设了数据中心，最大的数据中心在河北怀来官厅湖新媒体产业园，一期 5 万台服务器，二期 9 万台服务器。</p><p>2018 年，租用+自建的服务器数量达到 17 万台服务器。</p><p>2020 年，根据字节跳动招聘公告的数据，显示有 42 万台服务器。比 2018 年增长了 1.5 倍。（数据来自网络）</p><p><img src="https://img.hi-linux.com/staticfile/640-20210618132143644-2021-06-18-yYrcJJ.jpg" alt="一个机柜中 10-20 台服务器"></p><p>这部分服务器都是给中国区域使用，主要应用国内的抖音，西瓜视频，今日头条，飞书等产品。</p><p>在美国的 TIKTOK 是独立出来的运营，数据在美国当地存储和分发。2020 年 Tiktok 在美国也租用了近 10 万台服务器</p><p>据 Business Insider 公布数据，2020 年上半年，字节跳动在美国弗吉尼亚州北部租用了能耗达 53 兆瓦的数据中心。可以容纳数十万台服务器，占地面积可达数十万平方英尺。</p><p>Tiktok 在印度，新加坡都在投资建设数据中心。</p><h2><span id="字节跳动大型的数据中心出口带宽是多少">字节跳动大型的数据中心出口带宽是多少？</span></h2><p>聊完了服务器数量，那么咱们来点硬核的东西：字节跳动大型的数据中心出口带宽是多少？</p><blockquote><p>知识点：所谓的出口带宽，其实就是咱们普通人所说的下载带宽。就是服务器给每一个手机分发数据总速度。</p></blockquote><p>一般情况下，小型的 IDC 公司自建机房，比如一些网站公司，租用联通，移动，电信的机房，可能总体出口带宽只有 5G。超过 30G 那都是具备一定规模的企业。网络公司营收少说也是几千万的企业。</p><p>所以，经常能够看到，一些规模还不错的企业，基本上都不再自建机房，都是使用云主机。例如阿里云的 ECS，腾讯云，百度云，AWS（亚马逊）。</p><p>一般一个企业网站（企业官网），20M 带宽，4G 内存，100G 硬盘，一年价格也就 4000-5000 块钱就足够了，赶上做活动价格可能更便宜。</p><p>这里面就是带宽最贵，当然增加带宽，达到一定等级，例如访问量增大，必须要增加内存和硬盘。</p><p>相比来说，带宽增加的话，费用更贵一些。这里就跟你说明一下：带宽比较昂贵，属于稀缺资源。</p><p>我们来看中国移动的一个机房，中国移动（河北石家庄）数据中心的数据：占地面积 174 亩，总建筑面积 13 万平方米，规划 10 栋单体建筑，全部建成后可提供约 3 万个机架的装机能力。</p><p>3 个 IDC 机房共可提供 3.1 万架机柜，15T 带宽资源。一个机柜，全 1U 设备部署数量一般不超过 16 台，全 2U 设备一般不超过 12 台，全 4U 设备一般 4 到 7 台。</p><p>我们取高性能的 2U 和 4U 服务器进行平均折中，各算一半（毕竟移动也算是有钱的大户，不能买低端的 1U 设备）。</p><p>那么 3.1 万架机柜就可以安装，最多 21-36 万台服务器。这里粗略取一个平均值：30 万台服务器。</p><p>享受 15T 的出口带宽资源。当然作为电信的干路网，移动拿带宽资源肯定是要比字节跳动更有优势的。</p><p>所以，我们粗略地估计字节跳动自建的 17 万台服务器的数据中心。总出口带宽可能在 7Tb-10TB 上下。</p><p>基本上肯定会采用双出口流量设计，再加上多链路的部署方式：可以做到实际出口带宽在 800G-1TG 就可以实现 10T 左右的总出口带宽。【这是技术方式】</p><p><img src="https://img.hi-linux.com/staticfile/640-20210618125403637-2021-06-18-0b9MmZ.jpg" alt="字节跳动 2018 年河北怀化数据中心"></p><p>T 级别出口带宽是什么概念，如果我告诉你 2009 年，整个上海的出口带宽才 1140G，也就是刚刚达到 1TB。</p><p>在短短的 10 年后，一个企业的数据中心的出口带宽就超过 1TB，这个速度真的不可想象。</p><p>要知道 2009 年，虽然智能手机不发达，但是个人 PC 销量已经非常庞大了。</p><p>CDN 加速，让大众刷抖音，看视频都不再卡。</p><blockquote><p>知识点：CDN（Content Delivery Network，内容分发网络）。</p></blockquote><p>将服务端的内容发布到最接近用户的边缘节点，使用户可以就近取得所需的内容。</p><p>解决 Internet 网络拥塞状况，提高用户访问网站的响应速度。多种加速的方案集合。</p><p><strong>用通俗的话解释 CDN 就是：</strong> 会把一些页面，专门压缩，有的压缩为静态页面，静态页面直接分发速度快。用户可以在 2s 内看到内容，体验感更好。【这是静态传输】</p><p>对于动态视频，首先通过智能路由，寻找最佳路径，然后协议优化将长连接，内容进行压缩，去除冗余。【这就是动态压缩】</p><p>给你们看一下 2015 年腾讯 5 亿日活，集合了音乐，即时通讯等等产品的 CDN 的级别，达到了 10TB 带宽。每天请求万亿次。</p><p><img src="https://img.hi-linux.com/staticfile/640-20210618132155242-2021-06-18-RoPW9i.jpg" alt="2015 年腾讯 CDN 的级别"></p><p>因此，我这里说字节跳动整体服务器有 10TB 应该只少不多。毕竟抖音日活有 6 亿，西瓜视频+今日头条我们粗略算是 2 亿，总计有 8 亿的日活。</p><p>就是这么大的带宽和技术实力，才能让我们看视频这么顺畅。</p><blockquote><p>本文转载自：「 新浪 」，原文：<a href="https://tinyurl.com/khheksc5" target="_blank" rel="noopener">https://tinyurl.com/khheksc5</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;最近看到一个有意思的提问：抖音服务器带宽有多大，为什么能够供那么多人同时刷？今天来给大家科普一下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;抖音，百度，阿里云，腾讯都是自建的数据中心，都是 T 级别出口带宽（总出口带宽），也就是达到 1T=1024G/s 的出口带宽，服务器总数基本都在 20 万台以上，甚至阿里云都超过了 100 万台。&lt;/p&gt;
&lt;p&gt;字节跳动的数据中心总带宽，可能在 10TB 级别左右，预期突破 15TB 级别不远了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="网络" scheme="https://www.hi-linux.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="抖音" scheme="https://www.hi-linux.com/tags/%E6%8A%96%E9%9F%B3/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 Yadm 优雅管理你的应用配置和数据</title>
    <link href="https://www.hi-linux.com/posts/64799.html"/>
    <id>https://www.hi-linux.com/posts/64799.html</id>
    <published>2021-06-18T01:00:00.000Z</published>
    <updated>2021-06-18T01:16:59.484Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>开始，开始，开始使用吧！</strong></p></blockquote><h2><span id="1-功能简介">1. 功能简介</span></h2><blockquote><p><strong>User-specific app config is stored in so called dotfiles</strong></p></blockquote><p>您开始尝试对配置进行新的更改，现在一切都被破坏了。<code>yadm</code> 可以帮助你决定什么改变了，或者简单地恢复你所有的改变。</p><ul><li><strong>Yadm 可以恢复你的配置</strong></li></ul><p>您已经花费了时间调整您的计算环境。一切都按照你想要的方式运作。太棒了！然后你的硬盘出了故障，电脑需要重建。</p><ul><li><strong>Yadm 可以帮你协调机器之间的配置</strong></li></ul><p>你得到了一台新电脑，你想要重新创建那个环境。您可能希望两台机器的配置保持同步。</p><a id="more"></a><h2><span id="2-工作方式">2. 工作方式</span></h2><blockquote><p><strong>Yet Another Dotfiles Manager</strong></p></blockquote><p><code>yadm</code> 就像有一个版本的 <code>Git</code>，它只在你的 <code>dotfiles</code> 上运行。如果你知道如何使用 <code>Git</code> 工具的话，你已经知道如何使用 <code>yadm</code> 了。</p><ol><li>如果您的工作目录是另一个 <code>Git</code> 管理的存储库，这并不重要。</li><li>不必移动 <code>dotfiles</code> 或者将它们从另一个位置符号链接起来。</li><li><code>Yadm</code> 自动继承了 <code>Git</code> 的所有特性，允许你分支、合并、重建、使用子模块等。</li></ol><p>实际上 <code>yadm</code> 底层依旧是使用 <code>Git</code> 来做管理的，即 <code>yadm</code> 在管理 <code>dotfiles</code> 的时候，实际上是用 <code>Git</code> 来进行版本控制、远程同步等操作的。但是，<code>yadm</code> 在 <code>Git</code> 工具功能的基础之上，进行了合理的功能拓展。</p><ol><li>使用单一存储库</li><li>几乎没有任何依赖</li><li>能够使用基于操作系统或主机的备用文件</li><li>能够加密和跟踪机密文件</li></ol><h2><span id="3-安装方式">3. 安装方式</span></h2><blockquote><p><strong>安装方式原来很简单</strong></p></blockquote><ul><li><strong>OSX</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install yadm</span><br></pre></td></tr></table></figure><ul><li><strong>Ubuntu/Debian</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install -y yadm</span><br></pre></td></tr></table></figure><ul><li><strong>Download</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -fLo /usr/<span class="built_in">local</span>/bin/yadm https://github.com/TheLocehiliosan/yadm/raw/master/yadm</span><br><span class="line">$ chmod a+x /usr/<span class="built_in">local</span>/bin/yadm</span><br></pre></td></tr></table></figure><h2><span id="4-快速开始">4. 快速开始</span></h2><blockquote><p><strong>只需要简单几个步骤，</strong></p></blockquote><ul><li><strong>[1] 创建一个新的远程仓库</strong></li></ul><p>在 <code>Github</code> 上面创建一个空的仓库，推荐使用私有仓库，况且现在私有仓库已经免费开放了。不然，一旦将私有的内容同步上去的话，那就非常尴尬且危险了。之后，再我们的家目录(<code>~/</code>)下面进行初始化并添加到仓库里面进行管理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化yadm仓库</span></span><br><span class="line">$ yadm init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用yadm添加文件或目录</span></span><br><span class="line">$ yadm add &lt;file/dir&gt;</span><br><span class="line">$ yadm commit -m <span class="string">"info"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送到远程仓库</span></span><br><span class="line">$ yadm remote add origin &lt;github url&gt;</span><br><span class="line">$ yadm push -u origin master</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 已经有了远程存储库</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接使用</span></span><br><span class="line">$ yadm <span class="built_in">clone</span> &lt;github url&gt;</span><br><span class="line">$ yadm status</span><br></pre></td></tr></table></figure><p>从此开始，我们就可以使用 <code>yadm</code> 来专属管理我们分散在系统中各个地方的配置文件或者重要目录了，即专属的 <code>Dotfiles</code> 管家。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看使用yadm管理的Dotfiles列表</span></span><br><span class="line">$ yadm list | head -2</span><br><span class="line">.tmux.conf</span><br><span class="line">.zshrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看每个Dotfiles文件的修改情况</span></span><br><span class="line">$ yadm status</span><br><span class="line">On branch master</span><br><span class="line">Your branch is up to date with <span class="string">'origin/master'</span></span><br><span class="line">nothing to commit (use -u to show untracked files)</span><br></pre></td></tr></table></figure><h2><span id="5-命令使用">5. 命令使用</span></h2><blockquote><p><strong>先来掌握下 yadm 命令的使用吧！</strong></p></blockquote><table><thead><tr><th style="text-align:left">编号</th><th style="text-align:left">Yadm 命令参数</th><th style="text-align:left">参数对应含义解释</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong><code>yadm status</code></strong></td><td style="text-align:left">查看状态</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong><code>yadm fetch</code></strong></td><td style="text-align:left">远程获取</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong><code>yadm push</code></strong></td><td style="text-align:left">推送配置</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong><code>yadm diff</code></strong></td><td style="text-align:left">对比差异</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong><code>yadm diff --cached</code></strong></td><td style="text-align:left">对比差异</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><strong><code>yadm list</code></strong></td><td style="text-align:left">管理列表</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><strong><code>yadm list -a</code></strong></td><td style="text-align:left">管理列表</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><strong><code>yadm clone</code></strong></td><td style="text-align:left">克隆项目</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left"><strong><code>yadm clone --bootstrap</code></strong></td><td style="text-align:left">克隆项目</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left"><strong><code>yadm checkout</code></strong></td><td style="text-align:left">状态迁出</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left"><strong><code>yadm checkout -b</code></strong></td><td style="text-align:left">状态迁出</td></tr><tr><td style="text-align:left">12</td><td style="text-align:left"><strong><code>yadm encrypt</code></strong></td><td style="text-align:left">文件解密</td></tr><tr><td style="text-align:left">13</td><td style="text-align:left"><strong><code>yadm decrypt</code></strong></td><td style="text-align:left">文件解密</td></tr><tr><td style="text-align:left">14</td><td style="text-align:left"><strong><code>yadm decrypt -l</code></strong></td><td style="text-align:left">文件加密</td></tr><tr><td style="text-align:left">15</td><td style="text-align:left"><strong><code>yadm commit --amend</code></strong></td><td style="text-align:left">用新的提交替换上次提交</td></tr><tr><td style="text-align:left">16</td><td style="text-align:left"><strong><code>yadm alt</code></strong></td><td style="text-align:left">创建符号链接</td></tr><tr><td style="text-align:left">17</td><td style="text-align:left"><strong><code>yadm remote -v</code></strong></td><td style="text-align:left">查看远程仓库地址</td></tr></tbody></table><h2><span id="6-自动配置">6. 自动配置</span></h2><blockquote><p><strong>使用 Yadm 来自动配置环境</strong></p></blockquote><ul><li>咳咳咳，我们使用 <code>yadm</code> 工具不光光是可以管理我们的 <code>Dotfiles</code> 文件或者目录，而且还可以使用它的 <code>bootstrap</code> 功能来完成初始化电脑时许多工具的安装。</li><li>使用 <code>bootstrap</code> 功能可以自动将任务脚本的执行 <code>hook</code> 在 <code>yadm</code> 克隆之后，来完成环境的全自动部署。这里不论是 <code>Bash</code> 脚本、<code>Python</code> 脚本还是什么别的，只要是可执行文件就可以。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认位置</span></span><br><span class="line"><span class="variable">$HOME</span>/.config/yadm/bootstrap/</span><br></pre></td></tr></table></figure><ul><li>创建和准备好下述脚本之后，我们就可以执行 <code>yadm bootstrap</code> 命令来手动执行检测一下了。当然，我们编写的 <code>bootstrap</code> 文件也是可以使用 <code>yadm</code> 工具来进行管理的。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">system_type=$(uname -s)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">is_command</span></span>() &#123;</span><br><span class="line">    <span class="built_in">command</span> -v <span class="string">"<span class="variable">$1</span>"</span> &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$&#123;system_type&#125;</span> = <span class="string">"Darwin"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> ! is_command zsh; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Installing zsh..."</span></span><br><span class="line">        brew install zsh</span><br><span class="line">        <span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"All packages are installed."</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"Install zsh error."</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/use-yadm-manager-dotfiles-01-2021-01-26-gdrSJR.png" alt></p><h2><span id="7-隐私保护">7. 隐私保护</span></h2><blockquote><p><strong>使用 Yadm 来隐私保护</strong></p></blockquote><ul><li>对敏感文件(比如 <code>SSH</code> 密钥)进行加密、解密，提供私有仓库以外的额外一层保护，非常有用且重要。但是，这样做会将纯文本数据放入 <code>Git</code> 存储库，后者通常驻留在公共系统中。</li><li>然而 <code>yadm</code> 实现了一个特性，可以很容易地对一组文件进行加密和解密，这样加密后的版本就可以保存在 <code>Git</code> 仓库中。这个特性只有在 <code>gpg</code> 命令可用的情况下才能工作。建议您在保存机密文件时使用私有存储库，即使这些文件是加密的。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认位置</span></span><br><span class="line"><span class="variable">$HOME</span>/.config/yadm/encrypt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加密后位置</span></span><br><span class="line"><span class="variable">$HOME</span>/.config/yadm/files.gpg</span><br></pre></td></tr></table></figure><ul><li>要使用这个特性，必须创建一个模式列表，保存对应内容到上述的默认配置文件中即可。这样 <code>yadm</code> 加密命令会找到所有与模式匹配的文件，并提示输入密码。一旦确认了密码，匹配的文件将被加密并保存为 <code>files.gpg</code> 文件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat <span class="variable">$HOME</span>/.config/yadm/encrypt</span><br><span class="line">.ssh/*.key</span><br></pre></td></tr></table></figure><ul><li>接下来需要做的就是和普通添加文件或目录操作一致，即使用 <code>yadm</code> 提交到远程仓库中去。以后要解密这些文件，或者在另一个系统上运行 <code>yadm</code> 解密并提供正确的密码。默认情况下，任何解密文件都会被删除其 <strong>“group”</strong> 和 <strong>“others”</strong> 权限。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加文件并提交</span></span><br><span class="line">$ yadm add .config/yadm/encrypt</span><br><span class="line">$ yadm add .config/yadm/files.gpg</span><br></pre></td></tr></table></figure><ul><li>默认情况下使用的是对称加密，但使用 <code>yadm.gpg-receiver</code> 配置可以启用非对称加密。要做到这一点，请运行如下命令即可。为此，接收者地址中必须存在 <code>gpg</code> 的秘钥才可以。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 非对称加密</span></span><br><span class="line">$ yadm config yadm.gpg-recipient &lt;recipient-address&gt;</span><br></pre></td></tr></table></figure><h2><span id="8-配置分类">8. 配置分类</span></h2><blockquote><p><strong>使用 Yadm 来配置分类</strong></p></blockquote><p>如果可能的话，最好在所有系统上使用相同的文件。但是，在某些场合您需要不同的文件。即针对不同的操作系统、不同的环境，需要维护不同种类的同一软件或插件的 <code>dotfile</code> 文件，可以使用如下两个插件来解决。</p><ul><li><a href="https://yadm.io/docs/templates" target="_blank" rel="noopener">yadm Docs - Templates</a></li><li><a href="https://yadm.io/docs/alternates" target="_blank" rel="noopener">yadm Docs - Alternate Files</a></li></ul><blockquote><p><strong>Alternate Files</strong></p></blockquote><ul><li>使用上述的 <code>Alternate Files</code> 功能时，<code>Yadm</code> 为不同的操作系统、主机、用户会自动创建一个符号链接到适当的文件版本上，一个有效的后缀被附加到文件名，即后缀中包含使用该文件必须满足的条件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 格式如下</span></span><br><span class="line"><span class="comment">##&lt;condition&gt;[,&lt;condition&gt;,…]</span></span><br></pre></td></tr></table></figure><ul><li>每个条件都是一个 <strong>属性/值</strong> 对，由一个句点分隔。有些条件不需要 <strong>“值”</strong>，在这种情况下，可以省略句点和值，且大多数属性可以缩写为一个单独的字母。</li></ul><table><thead><tr><th style="text-align:left">Attribute</th><th style="text-align:left">Meaning</th></tr></thead><tbody><tr><td style="text-align:left"><code>template</code>, <code>t</code></td><td style="text-align:left">Valid when the value matches a supported template processor. See the <a href="https://yadm.io/docs/templates" target="_blank" rel="noopener">Templates</a> section for more details.</td></tr><tr><td style="text-align:left"><code>user</code>, <code>u</code></td><td style="text-align:left">Valid if the value matches the current user. Current user is calculated by running <code>id ‑u ‑n</code>.</td></tr><tr><td style="text-align:left"><code>distro</code>, <code>d</code></td><td style="text-align:left">Valid if the value matches the distro. Distro is calculated by running <code>lsb_release ‑si</code> or inspecting <code>/etc/os-release</code></td></tr><tr><td style="text-align:left"><code>os</code>, <code>o</code></td><td style="text-align:left">Valid if the value matches the OS. OS is calculated by running <code>uname ‑s</code>.</td></tr><tr><td style="text-align:left"><code>class</code>, <code>c</code></td><td style="text-align:left">Valid if the value matches the local.class configuration. Class must be manually set using <code>yadm config local.class &lt;class&gt;</code>.</td></tr><tr><td style="text-align:left"><code>hostname</code>, <code>h</code></td><td style="text-align:left">Valid if the value matches the short hostname. Hostname is calculated by running <code>hostname</code>, and trimming off any domain.</td></tr><tr><td style="text-align:left"><code>default</code></td><td style="text-align:left">Valid when no other alternate is valid.</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例演示</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##default</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##class.Work</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##os.Darwin</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##os.Darwin,hostname.host1</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##os.Darwin,hostname.host2</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##os.Linux</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##os.Linux,hostname.host1</span></span><br><span class="line"><span class="variable">$HOME</span>/path/example.txt<span class="comment">##os.Linux,hostname.host2</span></span><br></pre></td></tr></table></figure><ul><li>模板是另一个在每个主机上创建替代内容的强大工具，你应该尝试在每个系统上使用相同的文件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .vimrc</span></span><br><span class="line"><span class="built_in">let</span> OS=substitute(system(<span class="string">'uname -s'</span>),<span class="string">"\n"</span>,<span class="string">""</span>,<span class="string">""</span>)</span><br><span class="line"><span class="keyword">if</span> (OS == <span class="string">"Darwin"</span>)</span><br><span class="line">    <span class="string">" do something that only makes sense on a Mac</span></span><br><span class="line"><span class="string">endif</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># . bash_profile</span></span><br><span class="line">system_type=$(uname -s)</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$system_type</span>"</span> = <span class="string">"Darwin"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">eval</span> $(gdircolors <span class="variable">$HOME</span>/.dir_colors)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">eval</span> $(dircolors -b <span class="variable">$HOME</span>/.dir_colors)</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>Templates</strong></p></blockquote><ul><li>模板是一种特殊的 <code>alternate</code> 文件，模板内容和主机特定的数据结合起来作为输入到一个模板处理文件中，该文件产生一个新的文件作为其输出。如果你需要改变一个文件的一小部分，这会非常有用，但是它不支持任何类型的头文件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 格式如下</span></span><br><span class="line"><span class="comment">##template.&lt;template processor&gt;</span></span><br></pre></td></tr></table></figure><ul><li><strong>支持的模板处理器</strong></li></ul><table><thead><tr><th style="text-align:left">Processor</th><th style="text-align:left">Suffixes</th><th style="text-align:left">Dependencies</th></tr></thead><tbody><tr><td style="text-align:left">default</td><td style="text-align:left"><code>##template</code>, <code>##template.default</code></td><td style="text-align:left"><code>awk</code> must be installed. (This should be installed on all linux systems)</td></tr><tr><td style="text-align:left">esh</td><td style="text-align:left"><code>##template.esh</code></td><td style="text-align:left"><code>esh</code> must be installed.</td></tr><tr><td style="text-align:left">j2cli</td><td style="text-align:left"><code>##template.j2</code>, <code>##template.j2cli</code></td><td style="text-align:left"><code>j2cli</code> must be installed.</td></tr><tr><td style="text-align:left">envtpl</td><td style="text-align:left"><code>##template.j2</code>, <code>##template.envtpl</code></td><td style="text-align:left"><code>envtpl</code> must be installed.</td></tr></tbody></table><ul><li><strong>内置指令集</strong></li></ul><table><thead><tr><th style="text-align:left">Default (built-in)</th><th style="text-align:left">Jinja or ESH</th><th style="text-align:left">Description</th><th style="text-align:left">Source</th></tr></thead><tbody><tr><td style="text-align:left"><code>yadm.class</code></td><td style="text-align:left"><code>YADM_CLASS</code></td><td style="text-align:left">Locally defined yadm class</td><td style="text-align:left"><code>yadm config local.class</code></td></tr><tr><td style="text-align:left"><code>yadm.distro</code></td><td style="text-align:left"><code>YADM_DISTRO</code></td><td style="text-align:left">Distribution</td><td style="text-align:left"><code>lsb_release ‑si</code></td></tr><tr><td style="text-align:left">or <code>/etc/os-release</code></td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><code>yadm.hostname</code></td><td style="text-align:left"><code>YADM_HOSTNAME</code></td><td style="text-align:left">Hostname</td><td style="text-align:left"><code>hostname</code> (without domain)</td></tr><tr><td style="text-align:left"><code>yadm.os</code></td><td style="text-align:left"><code>YADM_OS</code></td><td style="text-align:left">Operating system</td><td style="text-align:left"><code>uname ‑s</code></td></tr><tr><td style="text-align:left"><code>yadm.user</code></td><td style="text-align:left"><code>YADM_USER</code></td><td style="text-align:left">Current user</td><td style="text-align:left"><code>id ‑u ‑n</code></td></tr><tr><td style="text-align:left"><code>yadm.source</code></td><td style="text-align:left"><code>YADM_SOURCE</code></td><td style="text-align:left">Template filename</td><td style="text-align:left">(fully qualified path)</td></tr></tbody></table><ul><li><strong>实例演示</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> yadm.os == <span class="string">"Darwin"</span> %&#125;</span><br><span class="line">This block is included <span class="keyword">for</span> MacOS</span><br><span class="line">&#123;% <span class="keyword">else</span> %&#125;</span><br><span class="line">This block is included <span class="keyword">for</span> any other OS</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><h2><span id="9-扩展配合">9. 扩展配合</span></h2><blockquote><p><strong>管理 $HOME 以外的文件</strong></p></blockquote><ul><li>在默认的情况下，<code>yadm</code> 工具仅仅只会管理 <code>$HOME</code> 下的文件和目录，这大部分情况下也是完全合理以及必要的。即我们家目录下面的文件，并不会管理其他的目录层级，比如 <code>/etc/</code> 等。</li><li>但是，我们要想管理 <code>$HOME</code> 以外的文件，即扩大文件树的管理范围，就要对其进行一些必要的改造。首先，需要管理的区域要有可读写的权限。然后，执行如下操作即可。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用.yadm作为yadm的系统文件管理目录</span></span><br><span class="line">$ <span class="built_in">alias</span> sysyadm=<span class="string">"sudo yadm -Y <span class="variable">$HOME</span>/.yadm"</span></span><br></pre></td></tr></table></figure><ul><li>配置好上面的命令别名之后，就可以使用 <code>sysyadm</code> 命令创建一个单独的远程仓库，来单独管理系统文件。即我们单独使用 <code>sysyadm</code> 命令来管理系统配置，和上面我们管理家目录的互不干扰，各司其职。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将/目录初始化为sysyadm的文件树</span></span><br><span class="line">$ sysyadm init -w /</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加文件、签入版本控制系统、同步远程仓库</span></span><br><span class="line">$ sysyadm add /etc/nginx/nginx.conf</span><br><span class="line">$ sysyadm commit -m <span class="string">"add nginx config"</span></span><br><span class="line">$ yadm push</span><br></pre></td></tr></table></figure><h2><span id="10-参考文档">10. 参考文档</span></h2><ul><li><a href="https://github.com/TheLocehiliosan/yadm" target="_blank" rel="noopener">Yadm 的 GitHub 地址</a></li><li><a href="https://yadm.io/" target="_blank" rel="noopener">Yadm 的官方文档地址</a></li><li><a href="https://blog.spencerwoo.com/2020/07/how-i-manage-my-dotfiles/" target="_blank" rel="noopener">我是如何同步并管理我的 Dotfiles 的</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/y4r6d5fu%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/y4r6d5fu，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;开始，开始，开始使用吧！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-功能简介&quot;&gt;1. 功能简介&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;User-specific app config is stored in so called dotfiles&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;您开始尝试对配置进行新的更改，现在一切都被破坏了。&lt;code&gt;yadm&lt;/code&gt; 可以帮助你决定什么改变了，或者简单地恢复你所有的改变。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Yadm 可以恢复你的配置&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;您已经花费了时间调整您的计算环境。一切都按照你想要的方式运作。太棒了！然后你的硬盘出了故障，电脑需要重建。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Yadm 可以帮你协调机器之间的配置&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你得到了一台新电脑，你想要重新创建那个环境。您可能希望两台机器的配置保持同步。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Yadm" scheme="https://www.hi-linux.com/tags/Yadm/"/>
    
  </entry>
  
  <entry>
    <title>巧用 Docker Buildx 构建多种系统架构镜像</title>
    <link href="https://www.hi-linux.com/posts/58027.html"/>
    <id>https://www.hi-linux.com/posts/58027.html</id>
    <published>2021-06-17T01:00:00.000Z</published>
    <updated>2021-06-17T01:23:31.834Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Docker Buildx 是一个 Docker CLI 插件，其扩展了 Docker 命令，支持 Moby BuildKit 提供的功能。提供了与 Docker Build 相同的用户体验，并增加了许多新功能。</p><p>BuildKit 是下一代的镜像构建组件，主要特点有很多，本文主要使用其可以编译多种系统架构的特性。</p><blockquote><p>网址：<a href="https://github.com/moby/buildkit" target="_blank" rel="noopener">https://github.com/moby/buildkit</a></p></blockquote><p>需要注意的是，该功能仅适用于 Docker v19.03+ 版本。</p><p>本文将讲解如何使用 Buildx 构建多种系统架构的镜像。</p><a id="more"></a><p>在开始之前，已经默认你在 Linux 系统（各大发行版）下安装好了 64 位的 Docker。</p><p>在写本文时，Docker 最新版本号是 19.03.13。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ docker version</span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           19.03.13</span><br><span class="line"> API version:       1.40</span><br><span class="line"> Go version:        go1.13.15</span><br><span class="line"> Git commit:        4484c46d9d</span><br><span class="line"> Built:             Wed Sep 16 17:03:45 2020</span><br><span class="line"> OS&#x2F;Arch:           linux&#x2F;amd64</span><br><span class="line"> Experimental:      true</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          19.03.13</span><br><span class="line">  API version:      1.40 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.13.15</span><br><span class="line">  Git commit:       4484c46d9d</span><br><span class="line">  Built:            Wed Sep 16 17:02:21 2020</span><br><span class="line">  OS&#x2F;Arch:          linux&#x2F;amd64</span><br><span class="line">  Experimental:     false</span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.3.7</span><br><span class="line">  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.0.0-rc10</span><br><span class="line">  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.18.0</span><br><span class="line">  GitCommit:        fec3683</span><br></pre></td></tr></table></figure><h2><span id="1-启用-buildx">1. 启用 Buildx</span></h2><p>buildx 命令属于实验特性，因此首先需要开启该特性。</p><p>上面的查看 Docker 版本返回的内容中，如果出现 <code>Experimental: true</code> 字样就代表已经开启该特性了。下面的这一步骤就可以省略。</p><p>编辑 <code>~/.docker/config.json</code> 文件，新增如下内容（以下的演示适用于事先不存在 .docker 目录的情况下）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir ~&#x2F;.docker</span><br><span class="line">$ cat &gt; ~&#x2F;.docker&#x2F;config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">&quot;experimental&quot;: &quot;enabled&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>Linux/macOS 下可以通过设置环境变量的方式启用（不推荐）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ export DOCKER_CLI_EXPERIMENTAL&#x3D;enabled</span><br></pre></td></tr></table></figure><h2><span id="2-新建-builder-实例">2. 新建 Builder 实例</span></h2><p>在 Docker 19.03+ 版本中可以使用 <code>docker buildx build</code> 命令使用 BuildKit 构建镜像。该命令支持 <code>--platform</code> 参数可以同时构建支持多种系统架构的 Docker 镜像，大大简化了构建步骤。</p><p>由于 Docker 默认的 builder 实例不支持同时指定多个 <code>--platform</code> ，我们必须首先创建一个新的 Builder 实例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker buildx create --name mybuilder --driver docker-container</span><br></pre></td></tr></table></figure><p>返回新的 Builder 实例名，为「mybuilder」</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mybuilder</span><br></pre></td></tr></table></figure><p>使用新创建好的 Builder 实例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker buildx use mybuilder</span><br></pre></td></tr></table></figure><p>查看已有的 Builder 实例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker buildx ls</span><br><span class="line">NAME&#x2F;NODE    DRIVER&#x2F;ENDPOINT             STATUS   PLATFORMS</span><br><span class="line">mybuilder *  docker-container</span><br><span class="line">  mybuilder0 unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock inactive </span><br><span class="line">default      docker</span><br><span class="line">  default    default                     running  linux&#x2F;amd64, linux&#x2F;386</span><br></pre></td></tr></table></figure><p>Docker 在 Linux/AMD64 系统架构下是不支持 ARM 架构镜像，因此我们可以运行一个新的容器（Emulator）让其支持该特性，Docker 桌面版则无需进行此项设置。</p><ul><li>方法一：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm --privileged docker&#x2F;binfmt:a7996909642ee92942dcd6cff44b9b95f08dad64</span><br></pre></td></tr></table></figure><blockquote><p>注：docker/binfmt 可以参考网址：<a href="https://hub.docker.com/r/docker/binfmt/tags" target="_blank" rel="noopener">https://hub.docker.com/r/docker/binfmt/tags</a> 获取最新镜像</p></blockquote><ul><li>方法二（推荐）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm --privileged tonistiigi&#x2F;binfmt --install all</span><br></pre></td></tr></table></figure><blockquote><p>可参考网址：<a href="https://hub.docker.com/r/tonistiigi/binfmt" target="_blank" rel="noopener">https://hub.docker.com/r/tonistiigi/binfmt</a> 获取最新镜像。目前（2021/04/20 更新）的 <code>Qemu version: 5.0.0</code></p></blockquote><h2><span id="3-新建-dockerfile-文件">3. 新建 Dockerfile 文件</span></h2><p>要想构建多种系统架构的镜像，还需要一个支持的 Dockerfile 文件。</p><p>以下是一个示例的 Dockerfile 文件。</p><blockquote><p>参考链接：<a href="https://github.com/teddysun/across/blob/master/docker/kms/Dockerfile.architecture" target="_blank" rel="noopener">https://github.com/teddysun/across/blob/master/docker/kms/Dockerfile.architecture</a></p></blockquote><p>该 Dockerfile 文件内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">FROM --platform&#x3D;$TARGETPLATFORM alpine:latest AS builder</span><br><span class="line">WORKDIR &#x2F;root</span><br><span class="line">RUN apk add --no-cache git make build-base &amp;&amp; \</span><br><span class="line">    git clone --branch master --single-branch https:&#x2F;&#x2F;github.com&#x2F;Wind4&#x2F;vlmcsd.git &amp;&amp; \</span><br><span class="line">    cd vlmcsd&#x2F; &amp;&amp; \</span><br><span class="line">    make</span><br><span class="line"></span><br><span class="line">FROM --platform&#x3D;$TARGETPLATFORM alpine:latest</span><br><span class="line">LABEL maintainer&#x3D;&quot;Teddysun &lt;i@teddysun.com&gt;&quot;</span><br><span class="line"></span><br><span class="line">COPY --from&#x3D;builder &#x2F;root&#x2F;vlmcsd&#x2F;bin&#x2F;vlmcsd &#x2F;usr&#x2F;bin&#x2F;vlmcsd</span><br><span class="line">EXPOSE 1688</span><br><span class="line">CMD [ &quot;vlmcsd&quot;, &quot;-D&quot;, &quot;-e&quot; ]</span><br></pre></td></tr></table></figure><p><code>$TARGETPLATFORM</code> 是内置变量，由 <code>--platform</code> 参数来指定其值。</p><p>由于是基于 <a href="https://hub.docker.com/_/alpine" target="_blank" rel="noopener">alpine 的镜像</a>来制作的，而 <a href="https://hub.docker.com/_/alpine?tab=tags" target="_blank" rel="noopener">alpine</a> 是支持以下 7 种系统架构的，因此我们制作的镜像也就跟着支持这 7 种系统架构。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linux&#x2F;amd64, linux&#x2F;arm&#x2F;v6, linux&#x2F;arm&#x2F;v7, linux&#x2F;arm64, linux&#x2F;386, linux&#x2F;ppc64le, linux&#x2F;s390x</span><br></pre></td></tr></table></figure><p>更友好一点的架构名称如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">amd64, arm32v6, arm32v7, arm64v8, i386, ppc64le, s390x</span><br></pre></td></tr></table></figure><p>这里穿插一句吐槽。简单统计了一下，ARM 的系统架构有如下各种简称：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arm64, armv8l, arm64v8, aarch64</span><br><span class="line">arm, arm32, arm32v7, armv7, armv7l, armhf</span><br><span class="line">arm32v6, armv6, armv6l, arm32v5, armv5,  armv5l, armel, aarch32</span><br></pre></td></tr></table></figure><p>看完了是不是很想打人？</p><p>而对比 Intel 和 AMD 的就简单多了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x86, 386, i386, i686</span><br><span class="line">x86_64, x64, amd64</span><br></pre></td></tr></table></figure><h2><span id="4-构建镜像">4. 构建镜像</span></h2><p>先来本地构建一个。</p><p><code>git clone</code> 刚才的示例 Dockerfile 文件，并进入其目录下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cd ~ &amp;&amp; git clone https:&#x2F;&#x2F;github.com&#x2F;teddysun&#x2F;across.git &amp;&amp; cd across&#x2F;docker&#x2F;kms&#x2F;</span><br></pre></td></tr></table></figure><p>在本地构建支持 7 种 Platform 的镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker buildx build --platform linux&#x2F;amd64,linux&#x2F;arm&#x2F;v6,linux&#x2F;arm&#x2F;v7,linux&#x2F;arm64,linux&#x2F;ppc64le,linux&#x2F;s390x,linux&#x2F;386 -t teddysun&#x2F;kms -o type&#x3D;local,dest&#x3D;.docker -f .&#x2F;Dockerfile.architecture .</span><br></pre></td></tr></table></figure><p>docker buildx build 的具体参数含义，参考下面的官方文档:</p><blockquote><p><a href="https://docs.docker.com/engine/reference/commandline/buildx_build/" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/commandline/buildx_build/</a></p></blockquote><p>做完上面的那一步，实际上是把构建好的镜像放在了本地路径下。</p><p>此时我们再来查看一下已有的 builder 实例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker buildx ls</span><br><span class="line">NAME&#x2F;NODE    DRIVER&#x2F;ENDPOINT             STATUS  PLATFORMS</span><br><span class="line">mybuilder *  docker-container                    </span><br><span class="line">  mybuilder0 unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock running linux&#x2F;amd64, linux&#x2F;arm64, linux&#x2F;riscv64, linux&#x2F;ppc64le, linux&#x2F;s390x, linux&#x2F;386, linux&#x2F;arm&#x2F;v7, linux&#x2F;arm&#x2F;v6</span><br><span class="line">default      docker                              </span><br><span class="line">  default    default                     running linux&#x2F;amd64, linux&#x2F;386</span><br></pre></td></tr></table></figure><p>你会发现 mybuilder 下存在 8 种支持的架构（riscv64 目前还用不上，但是已经支持）。</p><p>此时查看一下 docker image 的运行情况，会发现存在一个名为 <code>buildx_buildkit_mybuilder0</code> 的容器在运行。</p><p>这是刚才在本地构建时，自动创建的，切记不要将其停止，也不要删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps -as</span><br><span class="line">CONTAINER ID        IMAGE                           COMMAND           CREATED             STATUS              PORTS             NAMES                        SIZE</span><br><span class="line">be753fa16090        moby&#x2F;buildkit:buildx-stable-1   &quot;buildkitd&quot;       15 minutes ago      Up 15 minutes                         buildx_buildkit_mybuilder0   0B (virtual 78.6MB)</span><br></pre></td></tr></table></figure><p>再来构建一个多系统架构镜像，并将构建好的镜像推送到 Docker 仓库（也就是 <a href="https://hub.docker.com/" target="_blank" rel="noopener">hub.docker.com</a>）。</p><p>在此操作之前，你需要事先注册一个账号（演示过程省略），并登录。登录命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker login</span><br></pre></td></tr></table></figure><p>输入你的用户名和密码即可登录。</p><blockquote><p>注意，以下演示的命令中 tag 的前面是我的用户名 <code>teddysun</code>，如果你想制作自己的镜像，请自行替换为你自己的用户名。</p></blockquote><p>使用 <code>--push</code> 参数构建好的镜像推送到 Docker 仓库。</p><p>此时仍然是在刚才的 <code>~/across/docker/kms</code> 目录下，文件 <code>Dockerfile.architecture</code> 是为多系统架构构建准备的。命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker buildx build --platform linux&#x2F;386,linux&#x2F;amd64,linux&#x2F;arm&#x2F;v6,linux&#x2F;arm&#x2F;v7,linux&#x2F;arm64,linux&#x2F;ppc64le,linux&#x2F;s390x -t teddysun&#x2F;kms --push -f .&#x2F;Dockerfile.architecture .</span><br></pre></td></tr></table></figure><p>命令执行成功后，你就会在 Docker Hub 看到你上传的镜像啦。示例图如下：</p><p><img src="https://img.hi-linux.com/staticfile/kms_docker_hub-20210429161527270-2021-04-29-vT9VO3.png" alt></p><h2><span id="5-写在最后">5. 写在最后</span></h2><p>在制作多系统架构的 Docker 镜像时，建议使用 CPU 比较强或者多核心的 VPS 来构建，否则会非常耗时。</p><blockquote><p>本文转载自：「秋水逸冰」，原文：<a href="https://teddysun.com/581.html" target="_blank" rel="noopener">https://teddysun.com/581.html</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker Buildx 是一个 Docker CLI 插件，其扩展了 Docker 命令，支持 Moby BuildKit 提供的功能。提供了与 Docker Build 相同的用户体验，并增加了许多新功能。&lt;/p&gt;
&lt;p&gt;BuildKit 是下一代的镜像构建组件，主要特点有很多，本文主要使用其可以编译多种系统架构的特性。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;网址：&lt;a href=&quot;https://github.com/moby/buildkit&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/moby/buildkit&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;需要注意的是，该功能仅适用于 Docker v19.03+ 版本。&lt;/p&gt;
&lt;p&gt;本文将讲解如何使用 Buildx 构建多种系统架构的镜像。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>4 种优雅的在 Kubernetes 中调试网络流量的方式</title>
    <link href="https://www.hi-linux.com/posts/22651.html"/>
    <id>https://www.hi-linux.com/posts/22651.html</id>
    <published>2021-06-17T01:00:00.000Z</published>
    <updated>2021-06-17T01:29:36.606Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="前言">前言</span></h2><p>在当今世界, 分布式系统, 微服务/SOA架构遍地, 服务之间的许多交互和通信都不再是同一主机的不同线程或进程, 而是跨主机, 甚至跨网络区域. 那么一旦相关服务出现问题, 我们就会需要调试服务间的通讯, 主机间的网络…</p><p><img src="https://img.hi-linux.com/staticfile/smartscape-complex-environment-572-9c4b25ca16-2021-04-08-u3bMoJ.png" alt="复杂的网络架构"></p><p>Kubernetes 中的应用出了问题, 往往需要进行网络抓包分析. 本文介绍了在 Kubernetes 中网络调试分析的4种方法.</p><ol><li>使用 sidecar</li><li>使用 <a href="https://github.com/nicolaka/netshoot" target="_blank" rel="noopener">netshoot</a> - 一个 Docker + Kubernetes网络故障排除的瑞士军刀容器</li><li>利用Network Namespace</li><li>使用 kubectl 插件 - <code>ksniff</code></li></ol><a id="more"></a><h2><span id="方法一-使用-sidecar">方法一 使用 Sidecar</span></h2><p>在分布式计算、容器和微服务的世界中，服务之间的许多交互和通信都是通过 RESTful Api 完成的。在开发这些 Api 和服务之间的交互时，我经常需要调试服务之间的通信，特别是当事情看起来不像预期的那样工作时。</p><p>在容器出现之前，我只需将服务部署到本地机器上，启动 Wireshark，执行测试，并分析服务之间的HTTP通信。对我来说，这是一种快速分析软件中通信问题的简单而有效的方法。然而，这种调试方法在一个容器化的世界中并不适用。</p><p>首先，容器很可能在您的机器无法直接访问的内部容器平台网络上运行。第二个问题是，按照容器设计最佳实践，容器只包含执行其任务所需的最小应用程序和库集。这意味着像 Tcpdump 这样的工具通常在容器中不可用。这使得调试和分析容器之间的网络通信变得更加困难，从而使得调试微服务间的通信比在非容器环境中更加困难。本文展示了一种解决方案。</p><h3><span id="sidecar-前来救援">Sidecar 前来救援</span></h3><p><img src="https://img.hi-linux.com/staticfile/sidecar-20210408104152197-2021-04-08-aw0bbq.jpg" alt="Sidecar"></p><p>在过去的几个月里，我尝试了各种方法来克服这个问题，最终形成了我将在本文中概述的方法。它是捕获Kubernetes/OpenShift Pods 之间的网络流量数据的简单方法，允许开发人员更好地分析和调试容器化应用程序中的通信问题，并更快、更有效地解决问题。</p><p>我们将使用 Tcpdump 捕获一个所谓的 PCAP(packet capture)文件，该文件将包含 Pod 的网络流量。然后可以将这个 PCAP 文件加载到 Wireshark 之类的工具中来分析流量，在本例中，分析在 Pod 中运行的服务的 RESTful 通信。在本文中，我将使用 Red Hat Process Automation Manager 产品的 KIE 服务器(执行服务器)作为示例，但是这种方法应该适用于任何类型的容器化应用程序。</p><p>要克服的第一个问题是 Kubernetes Pod 中 Tcpdump 命令的可用性。KIE 服务器容器映像没有安装Tcpdump。其次，容器不提供从 Red Hat 存储库安装 Tcpdump 的实用程序。为了克服这个问题，我们使用了 “Sidecar 容器” 的概念。</p><h4><span id="sidecar-概念">Sidecar 概念</span></h4><p>Sidecar 容器是与实际服务/应用程序运行在相同 Pod 中的容器，能够为服务/应用程序提供附加功能。<strong>Sidecar 容器的一个例子是 Istio 的 Envoy sidecar，它使pod成为服务网格的一部分</strong> 。在本例中，我们将部署一个 Sidecar 容器，该容器提供 Tcpdump 实用程序。由于 <strong>pod中的多个容器共享相同的网络层</strong> ，所以我们可以使用 Sidecar 来捕获进出 KIE 服务器的网络流量。</p><h3><span id="部署-sidecar">部署 Sidecar</span></h3><p>在这个例子中，我部署了<a href="https://github.com/jbossdemocentral/rhpam7-mortgage-demo" target="_blank" rel="noopener">Red Hat Process Automation Manager 7 Mortgage Demo</a>，它将在我的 OpenShift namespace 中创建两个 Pod。一个 Pod 运行 Business Central workbench，另一个 Pod 是执行服务器的 Pod。这两个组件之间的通信是通过 REST 完成的，这是我们将要捕获的流量。</p><p><img src="https://img.hi-linux.com/staticfile/Screenshot-2019-02-20-at-09.04.48-20210408103149938-2021-04-08-ZXh8d2.png" alt="OpenShift Namespace Overview"></p><p>我们的目标是捕获 KIE 服务器 Pod 上的网络流量，以便分析 Business Central Workbench 发送给 KIE 服务器的 RESTful 命令。要做到这一点，我们首先需要附加 (attach)一个 Sidecar 到 KIE 服务器的 Pod.</p><ol><li><p>在 Overview 页面中，单击要分析的 Pod 的名称。这将打开 <em>部署配置(Deployment Config, 简称DC)</em> 页面。</p></li><li><p>在 <em>部署配置</em> 屏幕的右上角，单击 Actions -&gt; Edit YAML。这将打开 DC 的 YAML配置。</p></li></ol><p><img src="https://img.hi-linux.com/staticfile/Screenshot-2019-02-20-at-09.08.55-2021-04-08-XCDrsY.png" alt></p><ol start="3"><li>向下滚动，直到看到单词 <code>containers</code>。我们将添加一个额外的容器，安装了 Tcpdump 的Sidecar 到 Pod 中。直接在 <code>containers</code> 定义下添加以下 YAML 片段:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- name: tcpdump</span><br><span class="line">   image: corfr&#x2F;tcpdump</span><br><span class="line">   command:</span><br><span class="line">     - &#x2F;bin&#x2F;sleep</span><br><span class="line">     - infinity</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/Screenshot-2019-02-20-at-09.17.56-2021-04-08-ci10cL.png" alt></p><ol start="4"><li>保存配置。这将部署一个新的 Pod，它现在由两个容器组成: 一个容器包含 KIE 服务器，另一个容器包含我们的 Tcpdump 工具，它将无限期地持续运行。</li></ol><h3><span id="捕获和分析流量">捕获和分析流量</span></h3><p>随着 Sidecar 的部署和运行，我们现在可以开始捕获数据了。我尝试的方法之一是使用 <code>oc rsh</code> 命令远程执行 Sidecar 中的 <code>tcpdump</code> 命令，将网络数据流输出到 FIFO 文件，并将数据直接导入 Wireshark。由于各种原因，这种方法失败了。其中一个问题是，<code>tcpdump</code> 向 <code>stderr</code> 发送信息消息，但是这些消息与 <code>stdout</code> 在相同的流中, 并且是通过 SSH 接收，从而破坏了进入 Wireshark 的数据。</p><p>我最后使用的方法是登录到 Sidecar 容器，并在 Sidecar 中运行 <code>tcpdump</code> 命令来创建 PCAP 文件。当您捕获了足够的数据后，就可以停止捕获过程并将 PCAP 文件复制到您希望使用 Wireshark 进行网络流量分析的机器上。具体步骤如下:</p><ol><li>在您的开发机器上，用 <code>oc</code> 客户端连接到 OpenShift 实例，并激活正确的项目( project, 即namespace)，运行 <code>oc get pods</code> 命令来列出您的 Pods:</li></ol><p><img src="https://img.hi-linux.com/staticfile/Screenshot-2019-02-20-at-09.26.30-2021-04-08-Xyw4s5.png" alt></p><ol start="2"><li><p>使用以下命令登录到我们的 KIE 服务器 Pod 的 tcpdump 容器中: <code>oc rsh -c tcpdump rhpam7-mortgage-kieserver-2-zcpsn</code></p></li><li><p>在 <code>tcpdump</code> 容器中，运行此命令以启动网络流量捕获过程: <code>tcpdump -s 0 -n -w /tmp/kieserver.pcap</code></p></li><li><p>运行要分析的网络流量的测试。在本例中，我将从 Business Central workbench 中启动一个业务流程，它将向 KIE 服务器发送一个 RESTful 请求。</p></li><li><p>捕获足够的数据后，在 <code>tcpdump</code> 容器中使用 <code>Ctrl+C</code> 完成捕获过程。</p></li><li><p>回到本地机器。将 PCAP 文件从 Pod 复制到本地机器: <code>oc cp -c tcpdump rhpam7-mortgage-kieserver-2-zcpsn:tmp/kieserver.pcap kieserver.pcap</code></p></li><li><p>用 Wireshark 打开 PCAP 文件并分析网络流量。在这个例子中，我正在分析我的 HTTP POST 方法，它创建了 Mortgage 进程的一个新实例:</p></li></ol><p><img src="https://img.hi-linux.com/staticfile/Screenshot-2019-02-20-at-09.45.47-2021-04-08-FBOqZz.png" alt="Wireshark 分析"></p><h3><span id="总结">总结</span></h3><p>在容器环境(如 Kubernetes 和/或 OpenShift )中分析 Pod 之间的网络通信可能比在非容器环境中更困难一些。然而，Sidecar 容器的概念为开发人员提供了一种简单的工具，可以将容器连同所需的开发工具和实用程序附加到微服务pod上。<strong>这避免了开发人员必须在应用程序容器映像本身中安装这些调试工具，从而保持容器的轻便和干净。</strong> 使用像 <code>oc rsh</code> 和 <code>oc cp</code> 这样的 OpenShift 工具，我展示了如何轻松地从 Pod 捕获网络流量数据并将数据带到开发机器进行分析。</p><h2><span id="方法二-使用-netshoot">方法二 使用 netshoot</span></h2><p><a href="https://github.com/nicolaka/netshoot" target="_blank" rel="noopener">Netshoot</a> - Docker + Kubernetes网络故障排除的瑞士军刀容器</p><p><img src="https://img.hi-linux.com/staticfile/403141-2021-04-08-17rDoq.jpg" alt="瑞士军刀"></p><h3><span id="用途">用途</span></h3><p>Docker 和 Kubernetes 网络故障排除变得复杂。通过正确理解 Docker 和 Kubernetes 网络的工作方式和正确的工具集，您可以排除故障并解决这些网络问题。netshoot 容器有一组强大的网络troubleshoot 工具，可以用来排除 Docker 网络问题。与这些工具一起出现的还有一组用例，展示了如何在真实场景中使用这个容器。</p><h3><span id="network-namespaces-网络名称空间">Network Namespaces - 网络名称空间</span></h3><p>在开始使用这个工具之前，有一点很重要:网络名称空间。网络名称空间提供与网络相关的系统资源的隔离。Docker使用网络和其他类型的名称空间(<code>pid</code>、<code>mount</code>、<code>user</code>…)为每个容器创建一个隔离的环境。从接口、路由到 ip 的所有内容都完全隔离在容器的网络名称空间中。</p><p>Kubernetes 也使用网络名称空间。<strong>Kubelets为每个pod创建一个网络名称空间，其中该 Pod 中的所有容器共享相同的网络名称空间(eths、IP、tcp套接字……)。这是 Docker 容器和Kubernetes pod之间的关键区别。</strong></p><p>名称空间很酷的一点是您可以在它们之间进行切换。您可以输入不同容器的网络名称空间，使用甚至没有安装在该容器上的工具在其网络堆栈上执行一些故障排除。此外，netshoot 可以通过使用主机的网络名称空间来对主机本身进行故障排除。这允许您在不直接在主机或应用程序包上安装任何新包的情况下执行任何故障排除。</p><h3><span id="针对容器的用法">针对容器的用法</span></h3><ul><li><strong>容器的网络名称空间</strong> :如果您的应用程序的容器存在网络问题，您可以像这样使用容器的网络名称空间启动 netshoot: <code>$ docker run -it --net container:&lt;container_name&gt; nicolaka/netshoot</code></li><li><strong>主机的网络名称空间</strong> :如果您认为网络问题在于主机本身，那么可以使用该主机的网络名称空间启动 netshoot。命令: <code>$ docker run -it --net host nicolaka/netshoot</code></li><li><strong>网络的网络名称空间</strong> :如果要对Docker网络进行故障排除，可以使用 <code>nsenter</code> 输入网络的名称空间。这将在下面的 <code>nsenter</code> 部分进行解释。</li></ul><h3><span id="针对-kubernetes-的用法">针对 Kubernetes 的用法</span></h3><p><strong>Kubernetes</strong>: 如果你想打开一个临时的容器来调试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run --generator&#x3D;run-pod&#x2F;v1 tmp-shell --rm -i --tty --image nicolaka&#x2F;netshoot -- &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>如果您想在主机的网络名称空间上 spin up 一个容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run tmp-shell --generator&#x3D;run-pod&#x2F;v1 --rm -i --tty --overrides&#x3D;&#39;&#123;&quot;spec&quot;: &#123;&quot;hostNetwork&quot;: true&#125;&#125;&#39; --image nicolaka&#x2F;netshoot -- &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><blockquote><p>同样的原理, <code>netshoot</code> 也可以通过 Sidecar 的方式进行使用.</p></blockquote><h3><span id="网络问题">网络问题</span></h3><p>许多网络问题可能导致应用程序性能下降。其中一些问题可能与底层网络基础设施有关。其他问题可能与主机或 Docker 级别的配置错误有关。让我们来看看常见的网络问题</p><ul><li>延迟(latency)</li><li>路由(routing)</li><li>DNS解析(DNS resolution)</li><li>防火墙(firewall)</li><li>不完整的 ARP(incomplete ARPs)</li></ul><p>为了解决这些问题，<code>netshoot</code> 包含了一组强大的工具，如图所示。</p><p><img src="https://img.hi-linux.com/staticfile/netshoot-all-tools-2021-04-08-oPnkeD.png" alt="netshoot 工具集"></p><h3><span id="被包含的包">被包含的包</span></h3><p>以下包被包含在 <code>netshoot</code> 中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">apache2-utils</span><br><span class="line">bash</span><br><span class="line">bind-tools</span><br><span class="line">bird</span><br><span class="line">bridge-utils</span><br><span class="line">busybox-extras</span><br><span class="line">calicoctl</span><br><span class="line">conntrack-tools</span><br><span class="line">ctop</span><br><span class="line">curl</span><br><span class="line">dhcping</span><br><span class="line">drill</span><br><span class="line">ethtool</span><br><span class="line">file</span><br><span class="line">fping</span><br><span class="line">iftop</span><br><span class="line">iperf</span><br><span class="line">iproute2</span><br><span class="line">ipset</span><br><span class="line">iptables</span><br><span class="line">iptraf-ng</span><br><span class="line">iputils</span><br><span class="line">ipvsadm</span><br><span class="line">libc6-compat</span><br><span class="line">liboping</span><br><span class="line">mtr</span><br><span class="line">net-snmp-tools</span><br><span class="line">netcat-openbsd</span><br><span class="line">netgen</span><br><span class="line">nftables</span><br><span class="line">ngrep</span><br><span class="line">nmap</span><br><span class="line">nmap-nping</span><br><span class="line">openssl</span><br><span class="line">py-crypto</span><br><span class="line">py2-virtualenv</span><br><span class="line">python2</span><br><span class="line">scapy</span><br><span class="line">socat</span><br><span class="line">strace</span><br><span class="line">tcpdump</span><br><span class="line">tcptraceroute</span><br><span class="line">util-linux</span><br><span class="line">vim</span><br></pre></td></tr></table></figure><h2><span id="方法三-利用network-namespace">方法三 利用Network Namespace</span></h2><p>正如方法二中提到的 Network Namespace 概念, 实际上, 不同的容器, <strong>只是在宿主机上不同 namespace 运行的进程而已</strong> . 因此要在不同的容器抓包可以简单地使用命令切换 Network Namespace 即可，可以使用在宿主机上的 <code>tcpdump</code> 等应用进行抓包。</p><blockquote><p>前提条件: 宿主机上已安装<code>tcpdump</code></p><p>参考链接: <a href="https://ruofeng.me/2018/09/19/capture-packets-in-kubernetes/" target="_blank" rel="noopener">在 k8s 中对指定 Pod 进行抓包</a></p></blockquote><p>具体操作步骤如下:</p><ol><li>查看指定 Pod 运行在哪个宿主机上:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubctl describe pod &lt;pod&gt; -n mservice</span><br></pre></td></tr></table></figure><ol start="2"><li>获得容器的 Pid:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect -f &#123;&#123;.State.Pid&#125;&#125; &lt;container&gt;</span><br></pre></td></tr></table></figure><ol start="3"><li>进入该容器的 network namespace:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nsenter --target &lt;PID&gt; -n</span><br></pre></td></tr></table></figure><ol start="4"><li>使用宿主机的 <code>tcpdump</code> 抓包, 指定 eth0 网卡:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 tcp and port 80 -vvv</span><br></pre></td></tr></table></figure><ol start="5"><li>或者直接抓包并导出到文件:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -w &#x2F;tmp&#x2F;out.cap</span><br></pre></td></tr></table></figure><ol start="6"><li>从远程 <code>scp</code> 到本地:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ipaddr:&#x2F;tmp&#x2F;out.cap .&#x2F;</span><br></pre></td></tr></table></figure><ol start="7"><li>之后在 Wireshark 中可以打开文件非常直观得查看过滤抓到的数据。</li></ol><h2><span id="方法四-使用-kubectl-插件-ksniff">方法四 使用 kubectl 插件 ksniff</span></h2><p>ksniff 项目地址：<a href="https://github.com/eldadru/ksniff" target="_blank" rel="noopener">https://github.com/eldadru/ksniff</a></p><h3><span id="题外话-krew-kubectl-插件包管理器">题外话: krew - kubectl 插件包管理器</span></h3><blockquote><p>前提条件: kubectl v1.12 或更高.</p><p>项目地址：<a href="https://github.com/kubernetes-sigs/krew/" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/krew/</a></p></blockquote><p>Krew 是 kubectl 插件的包管理器。</p><h4><span id="什么是-krew">什么是 <code>krew</code></span></h4><p>krew 是一个使 <a href="https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/" target="_blank" rel="noopener">kubectl插件</a> 易于使用的工具。krew 帮助您发现插件，并在您的机器上安装和管理它们。它类似于 apt、dnf 或 brew 等工具。</p><ul><li><strong>对于 kubectl 用户</strong> : krew 帮助您以一致的方式查找、安装和管理 kubectl插件。</li></ul><p>krew 易于使用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl krew search                 # show all plugins</span><br><span class="line">kubectl krew install view-secret    # install a plugin named &quot;view-secret&quot;</span><br><span class="line">kubectl view-secret                 # use the plugin</span><br><span class="line">kubectl krew upgrade                # upgrade installed plugins</span><br><span class="line">kubectl krew uninstall view-secret  # uninstall a plugin</span><br></pre></td></tr></table></figure><p>详细文档请参阅<a href="https://krew.sigs.k8s.io/docs/user-guide/" target="_blank" rel="noopener">用户指南</a>。</p><p>查看在 krew 上<a href="http://sigs.k8s.io/krew-index/plugins.md" target="_blank" rel="noopener">可用的 kubectl 插件列表</a>，或者运行 <code>kubectl krew search</code> 来发现可用的插件。</p><h4><span id="安装-krew">安装 krew</span></h4><p><strong>Bash 和 ZSH</strong>:</p><ol><li>确保 <code>git</code> 已安装;</li><li>运行如下命令, 下载并安装 <code>krew</code></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(</span><br><span class="line">  set -x; cd &quot;$(mktemp -d)&quot; &amp;&amp;</span><br><span class="line">  curl -fsSLO &quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;krew&#x2F;releases&#x2F;download&#x2F;v0.3.1&#x2F;krew.&#123;tar.gz,yaml&#125;&quot; &amp;&amp;</span><br><span class="line">  tar zxvf krew.tar.gz &amp;&amp;</span><br><span class="line">  .&#x2F;krew-&quot;$(uname | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;)_amd64&quot; install \</span><br><span class="line">    --manifest&#x3D;krew.yaml --archive&#x3D;krew.tar.gz</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol><li>添加 <code>$HOME/.krew/bin</code> 目录到 <code>PATH</code> 环境变量. 如下: <code>export PATH=&quot;${KREW_ROOT:-$HOME/.krew}/bin:$PATH&quot;</code> 并重启下 Shell 生效.</li></ol><h3><span id="安装-ksniff">安装 ksniff</span></h3><p>通过 <code>krew</code>: <code>kubectl krew install sniff</code></p><h3><span id="使用方法">使用方法</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># kubectl &lt; 1.12:</span><br><span class="line">$ kubectl plugin sniff &lt;POD_NAME&gt; [-n &lt;NAMESPACE_NAME&gt;] [-c &lt;CONTAINER_NAME&gt;] [-i &lt;INTERFACE_NAME&gt;] [-f &lt;CAPTURE_FILTER&gt;] [-o OUTPUT_FILE] [-l LOCAL_TCPDUMP_FILE] [-r REMOTE_TCPDUMP_FILE]</span><br><span class="line"></span><br><span class="line"># kubectl &gt;&#x3D; 1.12:</span><br><span class="line">$ kubectl sniff &lt;POD_NAME&gt; [-n &lt;NAMESPACE_NAME&gt;] [-c &lt;CONTAINER_NAME&gt;] [-i &lt;INTERFACE_NAME&gt;] [-f &lt;CAPTURE_FILTER&gt;] [-o OUTPUT_FILE] [-l LOCAL_TCPDUMP_FILE] [-r REMOTE_TCPDUMP_FILE]</span><br><span class="line"></span><br><span class="line">POD_NAME: Required. the name of the kubernetes pod to start capture it&#39;s traffic.</span><br><span class="line">NAMESPACE_NAME: Optional. Namespace name. used to specify the target namespace to operate on.</span><br><span class="line">CONTAINER_NAME: Optional. If omitted, the first container in the pod will be chosen.</span><br><span class="line">INTERFACE_NAME: Optional. Pod Interface to capture from. If omited, all Pod interfaces will be captured.</span><br><span class="line">CAPTURE_FILTER: Optional. specify a specific tcpdump capture filter. If omitted no filter will be used.</span><br><span class="line">OUTPUT_FILE: Optional. if specified, ksniff will redirect tcpdump output to local file instead of wireshark.</span><br><span class="line">LOCAL_TCPDUMP_FILE: Optional. if specified, ksniff will use this path as the local path of the static tcpdump binary.</span><br><span class="line">REMOTE_TCPDUMP_FILE: Optional. if specified, ksniff will use the specified path as the remote path to upload static tcpdump to.</span><br></pre></td></tr></table></figure><p>举例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl sniff mypod -n myproject -o &#x2F;tmp&#x2F;mypod.pcap</span><br></pre></td></tr></table></figure><h2><span id="总结">总结</span></h2><p>为了在容器或 K8S 中进行网络调试和分析, 本文列举了 4 种方法, 现在进行总结归纳:</p><ol><li><p>使用 Sidecar - Sidecar 容器所在的 <strong>Pod 中的多个容器共享相同的网络层</strong>, 且Sidecar 容器可以包含 <code>tcpdump</code> 等工具;</p></li><li><p>利用 Network Namespace - 不同的容器, <strong>只是在宿主机上不同 namespace 运行的进程而已</strong>. 容器的网络也是如此.</p></li><li><p>使用 <code>netshoot</code> - <code>netshoot</code> 其实是包含一系列的常用网络分析调试工具集的容器, 真正的使用方法其实还是以上 2 种:</p><ol><li>通过 sidecar 挂载</li><li>利用 Network Namespace 分析调试</li></ol></li><li><p>使用 kubectl 插件 - <code>ksniff</code>.</p></li></ol><p>以上这些方法, 有不同的前提条件和使用场景, 希望本文读完会让你的 K8S 调试技能有所提升.</p><blockquote><p>本文转载自：「 个人技术分享 」，原文：<a href="http://t.cn/AimWk1Wl%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">http://t.cn/AimWk1Wl，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;在当今世界, 分布式系统, 微服务/SOA架构遍地, 服务之间的许多交互和通信都不再是同一主机的不同线程或进程, 而是跨主机, 甚至跨网络区域. 那么一旦相关服务出现问题, 我们就会需要调试服务间的通讯, 主机间的网络…&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/smartscape-complex-environment-572-9c4b25ca16-2021-04-08-u3bMoJ.png&quot; alt=&quot;复杂的网络架构&quot;&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes 中的应用出了问题, 往往需要进行网络抓包分析. 本文介绍了在 Kubernetes 中网络调试分析的4种方法.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用 sidecar&lt;/li&gt;
&lt;li&gt;使用 &lt;a href=&quot;https://github.com/nicolaka/netshoot&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;netshoot&lt;/a&gt; - 一个 Docker + Kubernetes网络故障排除的瑞士军刀容器&lt;/li&gt;
&lt;li&gt;利用Network Namespace&lt;/li&gt;
&lt;li&gt;使用 kubectl 插件 - &lt;code&gt;ksniff&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>弹指一挥间，揭秘诞生 30 周年 Linux 成功的真正原因</title>
    <link href="https://www.hi-linux.com/posts/43403.html"/>
    <id>https://www.hi-linux.com/posts/43403.html</id>
    <published>2021-06-11T01:00:00.000Z</published>
    <updated>2021-06-11T03:46:46.656Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><ul><li>作者丨 Jeremy Andrews</li><li>译者丨屠灵</li><li>策划丨蔡芳芳</li></ul><blockquote><p>Linux 诞生于 1991 年，距今已经 30 年了。虽然它一开始只是 Linus 的一个个人项目，而非出于要开发一个新操作系统的伟大梦想，但如今的 Linux 早已无处不在。</p></blockquote><p>30 年前，当 Linus Torvalds 第一次发布 Linux 内核时，他还是赫尔辛基大学的一名 21 岁的学生。他宣布说：“我正在开发一个（免费的）操作系统（这只是个爱好，不会做得很大，也不会很专业……）”。30 年后，500 强超级计算机和 70% 以上的智能手机都在运行 Linux。很显然，Linux 不仅大，而且很专业。</p><p>30 年来，Linus Torvalds 一直在领导着 Linux 内核的开发，启发了无数开发者和开源项目。2005 年，Linus 开发了 Git，用来管理内核开发过程。Git 现在已经成为最流行的版本控制系统，受到无数开源和私有项目的信任。</p><p>正值 Linux 诞生 30 周年之际，Linus Torvalds 通过电子邮件回复了 Tag 1 咨询公司的创始合伙人 / 首席执行官 Jeremy Andrews 的访谈问题（《An Interview With Linus Torvalds: Linux and Git - Part 1》），回顾并总结了过去这些年他在领导大型开源项目过程中得到的真知灼见。本文着重介绍 Linux 内核开发和 Git。InfoQ 对访谈内容进行了翻译，以飨读者。</p><a id="more"></a><h2><span id="linux-内核开发">Linux 内核开发</span></h2><h3><span id="linux-发展的关键我不认识的人都在使用-linux">Linux 发展的关键：“我不认识的人都在使用 Linux”</span></h3><p><strong>Jeremy Andrews：Linux 无处不在，它是整个开源世界的灵感源泉。当然，事情并不是从一开始就这样的。1991 年，你在 comp.os.minix Usenet 新闻组中发布了一个 Linux 内核。十年后，你写了一本书，叫作“Just for Fun: The Story of an Accidental Revolutionary”（中译名：《只是为了好玩：Linux 之父林纳斯自传》），对那段历史进行了深度回顾。今年 8 月，Linux 将迎来它的 30 周年纪念日！在这个过程中，你是在什么时候开始意识到 Linux 并不仅仅是一个“爱好”的？</strong></p><p><strong>Linus Torvalds</strong>：这听起来可能有点荒谬，实际上我很早就开始意识到了。在 1991 年末（以及 1992 年初），Linux 已经比我预想的要大得多。</p><p>那时候可能只有几百个用户（确切地说不是“用户”，因为人们还要不断地对它进行修修补补），从没想过 Linux 后来能够发展壮大。在我看来，<strong>最大的转折点是当我意识到其他人正在使用它，并对它感兴趣，它开始有了自己的生命</strong>。人们开始发送补丁，这个系统能做的事情比我最初预想的要多得多。</p><p>1992 年 4 月的某个时候，X11 被移植到 Linux 上（其实我也记不太清具体时间了，毕竟那是很久以前的事了），这是一个重大进步，Linux 系统突然间有了 GUI 和一系列全新的功能。</p><p>我一开始并没有什么大计划。这只是一个个人项目，并不是出于要开发一个新操作系统的伟大梦想。我当时只是想了解我的新 PC 硬件的来龙去脉。</p><p>所以，在发布第一个版本时，实际上更多的是想“看看自己都做了些什么”。当然，我希望其他人会觉得它有趣，但它并不是一个真正可用的操作系统。它更多的是一种概念验证，而且只是一个我在当时做了几个月的个人项目。</p><p>从“个人项目”到其他人开始使用它、给我反馈（和 bug 报告）和发送补丁，对我来说是一个巨大的转变。</p><p>举个最基本的例子：最初的版权许可是“你可以以源代码的形式发布它，但不能用它赚钱”。</p><p>对于当时的我来说，商业版 Unix 太贵了（作为穷学生，我已经为了买新 PC 花光了所有钱），所以我希望这个操作系统的源代码是公开可用的（这样人们就可以提供补丁），<strong>我希望将它开放给像我这样负担不起昂贵电脑和操作系统的人</strong>。</p><p>1991 年末（或是 1992 年初），我把许可改为 GPLv2，因为有人想把它以软盘的形式分发给本地 Unix 用户组，但又想收回软盘的成本，并补偿他们拷贝软盘所花费的时间。我觉得这很合理，因为“免费”与否并不是最重要的，最重要的是要“公开源码”。</p><p>最终的结果是：人们不仅在 Unix 用户组中发布它，在几个月之内还出现了 SLS 和 Slackware 的软盘发行版。</p><p>与最初的那些根本性的变化相比，后来的一切都是“增量式”的。当然，有些增量式的变化也是大跨步（IBM 的加入、Oracle 数据库的移植、Red Hat 的首次公开募股，Android 在手机上的应用，等等），但在我看来，它们仍然不如最初的“我不认识的人都在使用 Linux”那样具有革命性。</p><h3><span id="linux-成功的重要原因修改开源许可协议采用-gplv2">Linux 成功的重要原因：修改开源许可协议，采用 GPLv2</span></h3><p>Jeremy Andrews：你是否曾经后悔修改了许可协议？或者说，其他人或公司用你开发的系统赚了很多钱，你因此感到后悔吗？</p><p><strong>Linus Torvalds</strong>：我从来没有后悔过。</p><p>首先，我过得还不错。我不是特别富有，但我是一个薪水很高的软件工程师，可以按照自己的节奏做我喜欢做的事情。</p><p>关键是我百分之百认为这个许可是 Linux（以及 Git）取得成功的重要原因。我认为，当所有人都认为他们有平等的权利，没有人在这方面有特权的时候，他们才会变得更快乐。</p><p>有很多项目采用了“双重许可”，一方面，原作者保留了商业许可（“只要你支付了许可费用，就可以使用它”），另一方面，项目也可以在 GPL 许可下开源。</p><p>我认为要在这种情况下建立好的社区是非常困难的，因为开源那一方知道自己是“二等公民”。另外，为了让享有特权的那一方一直享有特殊的权利，需要做很多许可文书工作，这给项目带来了额外的阻力。</p><p>另一方面，我见过很多基于 BSD（或 MIT 等类似的许可）许可的开源项目，当它们变得足够强大，大到具备商业价值时，它们就开始分裂，相关的公司不可避免地会将自己的那部分变成专有的。</p><p>我认为 <strong>GPLv2 能够在“每个人都处于相同的规则之下”和“要求人们回馈社区”之间取得完美的平衡</strong>。每个人都知道，所有参与者都受到相同的规则的约束，所以这是非常公平的。</p><p>当然，你的投入总会得到回报。如果你只是想轻度参与项目，或者只是想作为一名用户，那也是可以的。如果你真的只是这样，就也无法控制这个项目。如果你真的只需要一个基本的操作系统，而 Linux 已经具备你想要的所有功能，那也完全没有问题。但如果你有特殊的需求，想要为这个项目做一点事情，那么唯一的方法就是参与其中。</p><p>这让每个人都秉持诚实的态度，包括我在内。任何人都可以 fork 这个项目，用他们自己的方式，然后说“再见了，Linus，我要维护自己的 Linux 版本”。我之所以“特别”，仅仅是因为人们相信我能把工作做好。</p><p>“任何人都可以维护自己的 Linux 版本”，这让一些人对 GPLv2 产生了怀疑，但我认为这是一种优势，而不是劣势。我认为，这实际上是避免 Linux 出现分裂的原因：每个人都可以创建自己的项目分支。事实上，这也是“Git”的核心设计原则之一——代码库的每一个克隆都是一个分支，人们（和公司）再 fork 出自己的版本，完成开发工作。</p><p>所以，分支不是问题，只要你能把好的部分合并回来。这就是 GPLv2 发挥作用的地方。能够拉取分支，并按照自己的方式修改代码，拥有这些权利很重要，但另一方面也同样重要——当一个分支被证明取得了成功，有权利把它合并回去。</p><p>另一个问题是，除了要有支持这种工作流的工具，也要有可以支持它的心态。合并分支的一大障碍不仅是许可问题，还有“嫌隙”问题。如果分支是源于对立，那么要合并两个分支就非常困难——不是因为许可或技术方面的原因，而是因为分支之间太过对立。我认为 Linux 避免了这种情况的发生，主要是因为我们一直认为分支是一件很自然的事情。而且，当一些开发工作被证明取得了成功，尝试将其合并回来也是很自然的。</p><p>虽然这个答案有点偏离正题，但我认为它很重要——我不后悔修改了许可，因为我真的认为 GPLv2 是 Linux 取得成功的一个重要原因。</p><p>金钱不是一种很好的激励方式，它无法让人们团结在一起。我认为，参与一个共同的项目，并感觉到自己可以成为这个项目的合作伙伴，这样才能激励人们。</p><p><strong>Jeremy Andrews：现在，人们基于 GPLv2 发布源代码通常是因为 Linux。你当时是怎么找到这个许可的？你在调研其他许可方面又投入了多少时间和精力呢？</strong></p><p><strong>Linus Torvalds</strong>：那个时候，有关 BSD 和 GPL 的争论非常激烈。我在阅读各种新闻组（比如 comp.arch、comp.os.minix 等）时看到了一些有关许可的讨论。</p><p>其中两个最主要的原因可能是 gcc 和 Lars Wirzenius。gcc 对 Linux 的发展起到了很大作用，因为我肯定需要一个 C 语言编译器。Lars Wirzenius 是我在念大学时另一个说瑞典语（瑞典语在芬兰是小语种）的计算机系学生。</p><p>Lasu 比我更喜欢讨论与许可相关的事情。</p><p>在我看来，选择 GPLv2 并不算是什么重大的政治问题，主要是因为我最初在选择许可时太过仓促，后来需要做出修改。况且，我很感恩有 gcc，并且 GPLv2 更符合我对“你必须把源代码合并回来”这种想法的期望。</p><p>因此，与其另起炉灶新建一个许可，不如选择一个人们已经知道并且有一些律师参与其中的许可。</p><h3><span id="linux-之父的一天">Linux 之父的一天</span></h3><p><strong>Jeremy Andrews：通常情况下，你的一天是怎么过的？其中有多少时间花在写代码上，多少花在评审代码上，多少花在电子邮件上？你如何平衡个人生活和 Linux 内核开发工作？</strong></p><p><strong>Linus Torvalds</strong>：我现在写的代码很少，而且已经很久没写了。再要写代码，通常是因为人们对某些特定的问题存在争议。我修改代码，并将其作为补丁发布出去，作为对解决方案的解释说明。</p><p>换句话说，我写的大部分代码更多的是作为解决方案的示例，而补丁是一种非常具体的例子。人们很容易陷入理论讨论的陷阱，而我发现描述解决方案最好的方式是写代码片段，不一定要完整的程序，只要让解决方案具体化一些即可。</p><p>我的工作时间都花在电子邮件上了。主要是沟通，而不是写代码。事实上，我认为这种与记者和技术博主之间的交流就是我工作的一部分——它可能比技术讨论优先级低一些，但我也花了相当多的时间在这类事情上。</p><p>当然，我也会花一些时间在代码评审上。但老实说，当我收到一个 PR 时，有问题的代码通常已经被其他人评审过了。所以，虽然我仍然会看一下补丁，但实际上会更多地去关注注解，以及补丁的演化过程。但对于那些与我共事很久的人，我不会这么做：他们是自己子系统的维护者，我不需要对他们的工作指手画脚。</p><p>所以，很多时候，我的主要工作就是“待在那里”，执行管理和发布任务。换句话说，我的工作通常更多地是关于维护过程，而不是底层代码。</p><h3><span id="linux-之父的工作环境">Linux 之父的工作环境</span></h3><p>Jeremy Andrews：你的工作环境是怎样的？比如，你是喜欢黑暗、不会受人打扰的房间，还是喜欢能看到风景的房间？你喜欢在安静的环境下工作，还是喜欢一边听音乐一边工作？你通常使用哪种硬件？你是在终端上使用 vi 来评审代码，还是使用某种奇特的 IDE？你是否有偏爱的 Linux 发行版作为开发环境？</p><p><strong>Linus Torvalds</strong>：我的房间并不“暗”，但我确实把桌子旁边窗户上的百叶窗关上了，因为我不想要强烈的阳光。所以，我的房间没有什么风景视野，<strong>只有一张（凌乱的）桌子，配了两个 4k 显示器，桌子下面有一台强劲的电脑主机</strong>。还有几台笔记本电脑供我测试和在路上用。</p><p>我喜欢安静地工作。我很讨厌机械硬盘的滴答声，所以我把它们扔进了垃圾桶，现在只使用 SSD。这样已经 10 多年了。嘈杂的 CPU 风扇声也是不可接受的。</p><p>代码评审都是在传统的终端上完成的，不过我没有使用 vi。我使用的是“<strong>micro-emacs</strong>”这个令人讨厌的东西。它与 GNU emacs 完全没有关系，只是有些键绑定与它相似。我在赫尔辛基大学时就习惯用它了，到现在还没改掉这个习惯。几年前，我给它增加了（非常有限的）utf-8 支持，但它确实很老旧了，所有的迹象都表明它是在 80 年代开发的，我使用的版本是一个自 90 年代中期以来就没有更新过的分支。</p><p>赫尔辛基大学选择了这个工具，因为它可以在 DOS、VAX/VMS 和 Unix 上运行，这也是为什么我也会用它。到现在，我的手指已经对它形成肌肉记忆了。我真的需要换个有人维护并支持 utf-8 的工具，只是我增强的那部分功能用起来还好，所以一直没有强迫我的手指去接受新的工具。</p><p>我的工作桌面相当简单：几个文本终端，一个打开了电子邮箱的浏览器（还打开了其他几个标签，主要是新闻和科技网站）。我喜欢大的桌面空间，因为我习惯使用大终端窗口（100x40 是我的默认初始大小），并且并排打开好几个。我使用了两个 4k 显示器。</p><p>我在所有的机器上都安装了 Fedora 发行版，并不是因为我偏爱它，而是因为我习惯了。我并不太关心使用哪个发行版——对于我来说，选择发行版只是在机器上安装 Linux 和开发工具的一种方式。</p><h3><span id="如何处理大量电子邮件">如何处理大量电子邮件？</span></h3><p><strong>Jeremy Andrews：Linux 内核邮件组（<a href="https://lore.kernel.org/lkml/%EF%BC%89" target="_blank" rel="noopener">https://lore.kernel.org/lkml/）</a> 是人们公开交流内核开发的地方，流量非常高。你是怎么处理这么多电子邮件的？你尝试过邮件组之外的其他协作和沟通解决方案吗？或者说，这种简单的邮件组对你的工作来说足够好吗？</strong></p><p><strong>Linus Torvalds</strong>：我没有直接阅读内核邮件组里的邮件，而且好几年都没有。邮件太多了。</p><p>内核邮件组里的邮件会被抄送到所有的讨论当中。当新人加入讨论时，他们可以通过查看内核邮件组来了解相关的历史和背景。</p><p>过去我会订阅邮件组，让所有没有抄送给我的电子邮件自动归档，默认不看它们。当一些问题需要我介入时，我可以找到所有相关的讨论，因为它们都在我的电子邮件里，只是在需要时才会出现在我的收件箱里。</p><p>现在，我使用的是 <a href="http://lore.kernel.org" target="_blank" rel="noopener">lore.kernel.org</a> 提供的功能，因为它很好用，而且我们还基于它开发了一些工具。这样就不需要让邮件自动归档了，我们换了一种讨论方式，但基本的工作流程是一样的。</p><p>但很显然，我仍然会收到很多邮件——但从很多方面来看，这些年来情况变得越来越好，而不是越来越糟。其中很大一部分原因是 Git 和内核发布流程的改进：我们过去在代码流程和工具方面存在很多问题。在本世纪初是最为糟糕的，当时我们仍然在处理巨大的补丁炸弹，我们的开发流程存在严重的可伸缩性问题。</p><p>邮件组模式确实运作得很好，但并不是说人们就不使用除电子邮件之外的其他沟通方式了：有些人喜欢各种实时聊天工具（比如传统的 IRC）。虽然我不是很喜欢这样，但很显然有些人喜欢用它们来进行头脑风暴。但这种“邮件组存档”模式运作得非常好，并且能够无缝地与“开发者之间以邮件的形式发送补丁”和“以邮件的形式发送问题报告”相结合。</p><p>所以电子邮件仍然是主要的沟通渠道，并且因为邮件中可以包含补丁，我们可以更容易地讨论技术问题。而且邮件可以跨越时区，当参与者分布在不同地区时，这一点非常重要。</p><h3><span id="linux-30-以来内核开发的有趣事情">Linux 3.0 以来，内核开发的有趣事情</span></h3><p><strong>Jeremy Andrews：我密切关注内核开发大约有 10 年了，并在 KernelTrap 上写与内核有关的博文，大概是在 3.0 内核发布时停止更新博客。3.0 内核的发布与 2.6.x 内核的发布相隔了 8 年。请总结一下自 3.0 版本以来内核开发中发生的一些有趣的事情。</strong></p><p><strong>Linus Torvalds</strong>：那是很久以前的事了，我不知道该从哪里开始总结。从 3.0 版本到现在已经 10 年了，在这 10 年中发生了很多技术上的变化。ARM 已经发展成熟，ARM64 已经成为我们的主要架构之一，并出现了大量新的驱动程序和核心功能。</p><p>如果说过去 10 年有什么有趣的事情，那一定是我们努力保持开发模式的稳定，以及那些没有发生改变的东西。</p><p>在过去的几十年里，我们经历了多种不同的版本号方案和不同的开发模式，3.0 版本最终确定了后来一直使用的模式。它让“基于时间发布，版本号只是数字，与特性无关”这一说法落地了。</p><p>在 2.6.x 版本中，我们就有了基于时间的发布模式，所以它并不是什么新东西，但 3.0 版本确实是让这种模式板上钉钉的至关重要的一步。</p><p>我们以前使用随机编号方案（主要是在 1.0 版本之前），然后用“奇数表示开发版内核，偶数表示稳定的生产就绪版内核”，然后在 2.6.x 版本中，我们开始进入基于时间的发布模式。但人们仍然对“什么时候需要增加主版本号”存在疑问。3.0 版本正式发布后，宣告了主版本号没有任何意义，我们尽量简化数字，不要让它们变得太大。</p><p>因此，在过去的 10 年里，我们做了巨大的改变（有了 Git，就可以很容易地得到一些数字统计数据：超过 1.7 万人提交了大约 75 万次代码），但开发模式仍然相当稳定。</p><p>但并非一直都是这样的，内核开发的前 20 年经历了相当痛苦的开发模式变更，只是在过去 10 年中，发布可预测性才得到大幅提升。</p><h3><span id="linux-发布流程">Linux 发布流程</span></h3><p><strong>Jeremy Andrews：目前，最新的版本是 5.12-rc5。现在的发布流程标准是怎样的？例如，-rc1 和 -rc2 有什么不同？你会在什么情况下决定正式发布其中一个给定的版本？如果在正式发布之后出现了大量的回归会怎样？这种情况发生的频率是怎样的？这些年来，这个过程是如何演变的？</strong></p><p><strong>Linus Torvalds</strong>：我之前提到过，这个过程本身是很标准的，并且在过去十年里一直如此。在此之前，它经历了几次演变，但实际上从 3.0 开始它就像时钟一样走得很稳定。</p><p>到现在为止，我们的发布节奏是这样的：先是两周的合并时间窗口，然后是大约 6 到 8 周的候选版本，然后是最终版本。这样子差不多 15 年了。</p><p>规则一直都是一样的，尽管它们并不总是被完全严格执行：合并时间窗口是针对那些被认为已经“经过测试和准备就绪”的新代码，然后在接下来的大约两个月里进行修复，以确保所有的问题都得到解决。有时候，那些所谓的“就绪”代码会在发布之前会被禁用或完全推翻。</p><p>这个过程会重复，所以我们大约每 10 周发布一次。</p><p>达到可以发布的标准是我对候选版本有足够的信心，而这是以各种问题报告为基础的。如果某些方面在 rc 后期仍然会出问题，我就极力推翻这些内容，并建议将其放在后续的版本中。但总体而言，很少会出现这种情况。</p><p>这样就完全没有问题了吗？不是的。一旦内核发布了，就会有新用户，他们会发现一些在 rc 版本中没有被发现的问题。这几乎是不可避免的。这也是为什么我们需要“稳定内核”树。在发布之后，我们可以继续修复代码。一些稳定内核比其他版本内核维护的时间更长，被称为 LTS（“Long Term Support”）版本。</p><p>所有这些在过去十年里都没有什么变化，尽管后来有了更多的自动化流程。一般来说，内核测试自动化是很困难的——因为很多内核是驱动程序，十分依赖硬件的可用性。不过，我们有几个测试场同时进行引导和性能测试，以及各种随机负载测试。这些在这几年有了很大的改善。</p><h3><span id="一直等待可用的-arm-机器">一直等待可用的 ARM 机器</span></h3><p><strong>Jeremy Andrews：去年 11 月，有人说你对苹果公司在部分新款电脑中使用的 ARM64 芯片十分感兴趣。Linux 会支持它们吗？我看到一些代码被合并到 for-next。即将到来的 5.13 内核有可能在苹果 MacBook 上启动吗？你有可能是它的早期采用者吗？ARM64 有什么重大的意义？</strong></p><p><strong>Linus Torvalds</strong>：我偶尔会跟进一下，但现在说这些还为时过早。正如你所说的，早期支持可能会被合并到 5.13 中，但这只是一个开始，并不能说明 Linux 和苹果电脑将来会怎样。</p><p>主要问题不是 arm64 架构，而是与之相关的所有硬件驱动程序（特别是 SSD 和 GPU）。到目前为止，一些底层的东西得到了支持，但除了可以启用硬件之外，没有任何有用的结果。要想达到可以被人们使用的程度，还需要一些时间。</p><p>不仅仅是苹果的硬件得到了改进——arm64 架构总体上也已经成长了很多，内核在服务器领域也更具竞争力了。不久前，arm64 在服务器领域的竞争力还很弱，但亚马逊的 Graviton2 和安培的 Altra 处理器——都是基于改进后的 ARM Neoverse IP——比几年前的产品要好很多。</p><p>我已经等了十多年都没能等到一个可用的 ARM 机器，可能还要继续等下去，但情况明显比以前好了一些。</p><p>事实上，我很早之前就想要一台 ARM 机器。当我还是个少年，我真正想要的是一台 Acorn Archimedes，但可用性和价格让我最终选择了 Sinclair QL（M68008 处理器），然后几年后换成了 i386。</p><p>所以，这个想法已经酝酿了几十年。但到现在它们还没有被广泛使用，而且对于我来说，它们在价格和性能方面都不具竞争力。希望在不久的将来，这个想法能够变成现实。</p><h3><span id="重写内核会做出的改变">重写内核会做出的改变</span></h3><p><strong>Jeremy Andrews：内核中有什么东西需要进行完全的重写才能达到最优的吗？或者说，内核已经有 30 年的历史了，知识、编程语言和硬件在这 30 年里发生了很大的变化：如果现在让你从头开始重写，你会做出哪些改变？</strong></p><p><strong>Linus Torvalds</strong>：如果有必要的话我们会这么做的。我们真的很擅长重写，那些本来会造成灾难的东西很久以前就被我们重写了。</p><p>我们有很多“兼容”层，不过它们一般不会造成太大问题。如果从头开始重写，这些兼容层是否要去掉，我们还不清楚——它们存在的目的是为了与旧二进制文件向后兼容（通常是与旧架构向后兼容，例如在 x86-64 上运行 32 位的 x86 应用程序）。因为我认为向后兼容是非常重要的，所以即使重写，我也希望保留这些兼容层。</p><p>所以很明显，有很多东西并不是最优的，毕竟任何东西都有改进的空间。但就你提的这个问题，我不得不说，我不鄙视任何东西。有一些遗留驱动程序，可能没有人关心，也没有人去清理，会做一些丑陋的事情，但这主要是因为“没有人关心”。这些在过去不是问题，而一旦成为问题，我们就会积极把这些没人关心的东西移除掉。多年来，我们已经移除了很多驱动程序，当维护不再有任何意义时，我们会放弃整个架构支持。</p><p>“重写”的主要原因是：整个架构不再有意义，但仍然存在一些应用场景。最有可能的情况是，一些小型嵌入式系统并不需要 Linux 提供的所有东西，它们的硬件很小，需要的是更简单、更少的系统功能。</p><p>Linux 已经有了长足的发展。现在，即使是小硬件（比如手机等）也比当初开发 Linux 所使用的机器强大得多。</p><h3><span id="不会用-rust-取代-c-语言来开发内核">不会用 Rust 取代 C 语言来开发内核</span></h3><p><strong>Jeremy Andrews：如果用 Rust 来重写一部分系统会怎样？在这方面还有改进的余地吗？在内核开发方面，你觉得是否有可能用另一种语言（比如 Rust）来取代 C 语言？</strong></p><p><strong>Linus Torvalds</strong>：我不认为我们会用 Rust 取代 C 语言来开发内核，但可能会用来开发一些驱动程序，也许是整个驱动子系统，也许是文件系统。所以不是“取代 C 语言”，而是“在一些有意义的地方扩展我们的 C 代码”。</p><p>当然，驱动程序几乎占了内核的一半代码，有非常大的重写空间，但我不认为所有人都会很期待使用 Rust 全盘重写现有的驱动程序。可能“有些人会用 Rust 开发新驱动程序，或者适当地重写一部分旧驱动程序”。</p><p>现在更多的是“人们在尝试和体验”Rust，仅此而已。Rust 优势的背后肯定存在复杂性，所以我会采取观望的态度，看看这些优势是否真的奏效。</p><h3><span id="内核中最令-linux-之父自豪的部分">内核中最令 Linux 之父自豪的部分</span></h3><p><strong>Jeremy Andrews：内核中是否有你个人感到最自豪的部分？</strong></p><p><strong>Linus Torvalds</strong>：我最想说的是 VFS 层（虚拟文件系统，特别是路径名查找）和 VM。前者是因为 Linux 在做一些基础任务（在操作系统中查找文件名确实是一个核心的操作）时比其他系统都要好得多，后者主要是因为我们支持 20 多种架构，但仍然在使用一个基本统一的 VM 层，我认为这一点很了不起。</p><p>但与此同时，这很大程度上取决于“你最关注内核的哪一部分”。内核很大，不同的开发者（和不同的用户）会关注不同的方面。有些人认为调度是内核中最令人感到兴奋的部分，有些人则关注设备驱动程序的细节（我们有很多这样的驱动程序）。我个人在 VM 和 VFS 这两个方面参与得更多，所以自然会提到它们。</p><h3><span id="linux-在这个方面比其他操作系统做得更好">Linux 在这个方面比其他操作系统做得更好</span></h3><p><strong>Jeremy Andrews：我看了这个关于路径名查找的描述（<a href="https://www.kernel.org/doc/html/latest/filesystems/path-lookup.html%EF%BC%89%EF%BC%8C%E5%AE%83%E6%AF%94%E6%88%91%E9%A2%84%E6%83%B3%E7%9A%84%E8%A6%81%E5%A4%8D%E6%9D%82%E3%80%82%E6%98%AF%E4%BB%80%E4%B9%88%E8%AE%A9" target="_blank" rel="noopener">https://www.kernel.org/doc/html/latest/filesystems/path-lookup.html），它比我预想的要复杂。是什么让</a> Linux 在这方面比其他操作系统做得更好？你说的“更好”是什么意思？</strong></p><p><strong>Linus Torvalds</strong>：路径名查找是一个非常常见和基础的任务，以至于大多数非内核开发者不认为它会是一个问题：他们只知道打开文件，并认为这是理所当然的。</p><p>但要做好其实是相当复杂的。确切地说，因为几乎所有地方都在用路径名查找，所以对性能要求很高，而且大家都希望它在 SMP 环境中具有良好的伸缩性，而在锁定方面又很复杂。你不想发生 IO，那么缓存就非常重要。路径名查找是如此的重要，以至于你不能把它留给底层的文件系统，因为我们有 20 多种不同的文件系统，让它们各自拥有自己的缓存和锁定机制将是一场彻头彻尾的灾难。</p><p>所以，VFS 层的一个主要任务是处理所有路径名组件的锁定和缓存问题，以及所有的序列化和挂载点遍历问题，这些都是通过无锁算法（RCU）来完成的，但也会有一些非常智能的锁（Linux 内核的“lockref”锁是一种非常特殊的“带有引用计数的自旋锁”，表面上看是为 dcache 缓存而设计的，但本质上是一个专门的锁感知引用计数，可以在某些常见情况下消除锁）。</p><p>最终结果是：底层文件系统仍然需要对未缓存的内容进行查找，但它们不需要关心缓存和一致性规则以及与路径名查找相关的原子性规则。VFS 会为它们处理好所有这些问题。</p><p>而且它的性能比任何其他操作系统都要好，基本上可以在拥有数千个 CPU 的机器上完美运行。</p><p>所以不仅仅是“更好”，而是“大写”的更好。没有什么能与之相提并论的了。Linux dcache 是独一无二的。</p><h3><span id="新冠疫情对内核开发的影响">新冠疫情对内核开发的影响</span></h3><p><strong>Jeremy Andrews：过去的一年对全世界来说是艰难的一年。新冠疫情对内核开发进程带来了哪些影响？</strong></p><p><strong>Linus Torvalds</strong>：实际上，得益于我们一直以来的工作方式，它的影响非常小。电子邮件真的是一个很好的工具，我们并不依赖面对面的会议。</p><p>是的，它确实影响了去年的年度内核峰会（今年的峰会仍悬而未决），大多数会议被取消或转为线上进行。以前在办公室工作的人大都开始在家里工作（但很多核心内核维护者在之前已经这么做了）。所以，周围的很多东西都发生了改变，但内核开发还是像以前一样。</p><p>很显然，新冠疫情在其他方面影响了我们所有人的生活，但总的来说，作为几乎完全通过电子邮件进行交流的内核开发人员，我们可能是受影响最小的。</p><h2><span id="版本控制系统-git">版本控制系统 Git</span></h2><h3><span id="对-git-项目领导权主动放手">对 Git 项目领导权主动放手</span></h3><p><strong>Jeremy Andrews：Linux 只是你对开源做出的众多贡献中的一个。在 2005 年，你还创建了 Git，一个非常流行的分布式源代码控制系统。你快速地将 Linux 内核源代码树从专有的 Bitkeeper 迁移到开源的 Git 系统中，并在同年将维护工作移交给了 Junio Hamano。这里有很多有趣的故事，是什么原因促使你这么快就将项目的领导权移交了出来，你是如何找到并选择了 Junio 的？</strong></p><p><strong>Linus Torvalds</strong>：答案可以分为两个部分。</p><p>首先，我并不想创建一个新的源代码控制系统。开发 Linux 是因为硬件和软件之间的底层接口很吸引我——基本上是出于个人的热爱和兴趣。相反，开发 Git 是因为确实有这个需要：不是因为我觉得源代码控制很有趣，而是因为我十分鄙视市面上的大多数源代码控制系统。而我觉得最合适的、在 Linux 开发当中很好用的 BitKeeper 已经无法维持下去了。</p><p>我开发 Linux 已经超过 30 年了（距离第一个版本的周年纪念还有几个月，但在 30 年前我就开始研究 Linux 的“前身”了），并且一直在维护它。但 Git 呢？我从来没有想过我真的想要长期维护它。我喜欢用它，而且在某种程度上，我认为它是最好的 SCM，但它并不是我的兴趣所在。</p><p>所以我总是希望别人来为我维护 SCM——事实上，如果当初我不用自己开发这个 SCM，我会很开心。</p><p>以上就是故事的背景。</p><p>至于 Junio，他实际上是最早加入 Git 开发队伍的人员之一。他在我将 Git 的第一个非常粗糙的版本公开后的几天内提交了第一次变更代码，所以 Junio 在 Git 一开始就参与其中了。</p><p>但我之所以把项目交给 Junio，并不是因为他是第一批参与项目的人。在维护了 Git 几个月之后，让我决定将项目交给 Junio 维护者的真正原因是“好品味”——一个很难描述的概念。我真的想不到还有什么更好的描述：编程主要是为了解决技术问题，但如何解决这些问题以及如何思考也很重要。随着时间的推移，你开始意识到：有些人就有这种“好品味”，他总能选择正确的解决方案。</p><p>我不想将编程说成是一门艺术，因为它实际上主要是关于“好的工程”。我很喜欢托马斯·爱迪生的那句“天才是百分之一的灵感加上百分之九十九的汗水”：编程涉及的几乎都是细枝末节的东西和日常繁重的工作。但是，那百分之一的“灵感”，也就是“好品味”，不仅要解决问题，而且要干净、漂亮地解决。</p><p>Junio 就有那种“好品味”。</p><p>每次提到 Git，我都想试着讲清楚：我在一开始提出了 Git 的核心思想，并经常因为这部分工作而获得太多荣誉。Git 的这 15 年，我也只是在第一年真正参与了项目。Junio 是一个优秀的维护者，是他让 Git 变成现在的样子。</p><p>顺便说一下，关于“好品味”，以及找到拥有好品味的人，并信任他们——不仅仅 Git 是这样，Linux 也是这样。与 Git 不一样的是，Linux 这个项目我仍然在积极维护，但与 Git 一样的是，Linux 也是一个有很多人共同参与的项目。我认为，Linux 的一大成功是它拥有数百名维护者，他们都具备了“好品味”，并维护着内核的不同部分。</p><h3><span id="项目维护并非非黑即白">项目维护并非“非黑即白”</span></h3><p><strong>Jeremy Andrews：你有没有过这样的经历：把控制权交给维护者，然后发现这是一个错误的决定？</strong></p><p><strong>Linus Torvalds</strong>：我们的维护体系从来就不是非黑即白的，所以不会出现这种情况。事实上，我们甚至没有将维护权正式记录下来：我们确实有一个 MAINTAINERS 文件，但那只是为了让你在遇到问题时能够找到对的人，并不是某种排他所有权的标志。</p><p>所以，“谁负责什么东西”更像是一种流动的指南，以及“这个人很活跃，工作做得很好”，而不是“我们把所有权给了那个人，然后他搞砸了”。</p><p>从某种意义上说，我们的维护体系也是流动的。假设你是某个子系统的维护者，如果你需要另一个子系统的东西，是可以跨界的。通常人们在这样做之前都会进行广泛的沟通，而且这种事情确实发生了。这并不是“你只能动这个文件”之类的硬性规定。</p><p>实际上，这与前面讨论的有关许可的事情有些联系。“Git”的另一个设计原则是“每个人都有自己的代码树，但没有哪一个代码树是特殊的”。</p><p>因为很多其他项目都使用了工具——比如 CVS 或 SVN——这些工具会让一些人变得“特殊”，赋予了他们某种“所有权”。在 BSD 世界里，他们称之为“commit bit”：给一个维护者“commit bit”意味着他可以将代码提交到中央代码库。</p><p>我一直很讨厌这种模式，因为它会不可避免地导致政治“小团体”的出现。在这种模式下，总有一些人是特殊、隐性受信任的。问题的关键甚至不在于“隐性受信任”，而在于硬币的另一面——其他人不被信任，他们被定义成局外人，必须受制于监护者。</p><p>同样，在 Git 开发中也不存在这种情况。每个人都是平等的，任何人都可以克隆代码，做自己的开发，做好了，就可以合并回来。</p><p>所以，没有必要给人们特权，也不需要“commit bit”。这样就可以避免出现政治“小团体”，也不需要“隐性信任”。如果他们做得不好——或者更常见的是，最终消失了，并转向了另一个兴趣——他们的代码就不会被合并回来，也不会阻碍其他有新想法的人。</p><h3><span id="对-git-特性的看法">对 Git 特性的看法</span></h3><p><strong>Jeremy Andrews：Git 有没有哪些新特性让你印象深刻，并成为你工作流的一部分？还有哪些特性是你想要增加的？</strong></p><p><strong>Linus Torvalds</strong>：我对 Git 的需求总是最早得到满足的，所以，对于我来说，Git 没有“新”特性。</p><p>这些年来，Git 确实有很大的改进，有一些在我的工作流中已经体现出来了。例如，Git 的速度一直都很快——毕竟这是我的设计目标之一——但它的大部分特性最初是围绕 shell 脚本而构建的。多年来，大多数 shell 脚本都已经消失了，这意味着我可以比原来更快地应用 Andrew Morton 的补丁。这一点令人感到欣慰，因为这实际上是我早期用于性能测试的基准之一。</p><p>所以，Git 对我来说一直都很好，而且变得越来越好。</p><p>Git 最大的改进在于“普通用户”的使用体验变得更好了。一部分原因是人们在学习 Git 工作流的过程中逐渐习惯了它，但更多的是因为 Git 本身变得更易于使用。</p><blockquote><p>本文转载自：「 架构头条 」，原文：<a href="https://tinyurl.com/wxejbh4w" target="_blank" rel="noopener">https://tinyurl.com/wxejbh4w</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;作者丨 Jeremy Andrews&lt;/li&gt;
&lt;li&gt;译者丨屠灵&lt;/li&gt;
&lt;li&gt;策划丨蔡芳芳&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Linux 诞生于 1991 年，距今已经 30 年了。虽然它一开始只是 Linus 的一个个人项目，而非出于要开发一个新操作系统的伟大梦想，但如今的 Linux 早已无处不在。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;30 年前，当 Linus Torvalds 第一次发布 Linux 内核时，他还是赫尔辛基大学的一名 21 岁的学生。他宣布说：“我正在开发一个（免费的）操作系统（这只是个爱好，不会做得很大，也不会很专业……）”。30 年后，500 强超级计算机和 70% 以上的智能手机都在运行 Linux。很显然，Linux 不仅大，而且很专业。&lt;/p&gt;
&lt;p&gt;30 年来，Linus Torvalds 一直在领导着 Linux 内核的开发，启发了无数开发者和开源项目。2005 年，Linus 开发了 Git，用来管理内核开发过程。Git 现在已经成为最流行的版本控制系统，受到无数开源和私有项目的信任。&lt;/p&gt;
&lt;p&gt;正值 Linux 诞生 30 周年之际，Linus Torvalds 通过电子邮件回复了 Tag 1 咨询公司的创始合伙人 / 首席执行官 Jeremy Andrews 的访谈问题（《An Interview With Linus Torvalds: Linux and Git - Part 1》），回顾并总结了过去这些年他在领导大型开源项目过程中得到的真知灼见。本文着重介绍 Linux 内核开发和 Git。InfoQ 对访谈内容进行了翻译，以飨读者。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="杂谈" scheme="https://www.hi-linux.com/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>6 张图带你搞懂微服务</title>
    <link href="https://www.hi-linux.com/posts/39095.html"/>
    <id>https://www.hi-linux.com/posts/39095.html</id>
    <published>2021-06-10T01:00:00.000Z</published>
    <updated>2021-06-10T09:50:38.832Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>虽说<a href="https://martinfowler.com/articles/microservices.html" target="_blank" rel="noopener">微服务</a>早已是一个老生常谈的话题了，在 <a href="https://www.infoq.cn/topic/microservice" target="_blank" rel="noopener">infoq</a> 或者 <a href="https://insights.thoughtworks.cn/tag/microservices/" target="_blank" rel="noopener">thoughtworks</a> 上可以找到很多案例，不过可惜的是其中相当比例的案例是失败的案例，究其原因，除了<a href="https://microservices.io/index.html" target="_blank" rel="noopener">技术门槛</a>之外，主要是因为很多人脱离了实际情况，只是为了微服务而微服务。本文通过一个例子带领大家从头到尾体验一下微服务的演化过程，不仅要做到知其然，更要做到知其所以然。</p><a id="more"></a><p>假设我们正在开发一个在线购物项目，其主要功能包括商城、推荐、评论、用户等，它是一个典型的<a href="https://microservices.io/patterns/monolithic.html" target="_blank" rel="noopener">单体架构</a>：不同团队的技术人员工作在同一个版本库上，系统功能按模块划分，不同模块之间通过本地函数调用，通常操作同一个数据库。</p><p><img src="https://img.hi-linux.com/staticfile/ms01-20210514145248915-2021-05-14-k5YOD0.png" alt></p><p>在项目早期，单体架构往往能很好的适应快速迭代的需求，不过随着项目的发展，项目本身会变得复杂，其弊端不可避免的出现，比如下面列举的一些情况：</p><ul><li>因为大家都工作在同一个版本库上，所以可能会遇到：商城模块完成了新功能，准备上线，结果推荐模块刚提交了还没来得及测试的代码，于是不得不推迟上线。</li><li>不同的需求采用不同的技术栈：负责评论模块的同事想用 PHP + MySQL 来构建系统，负责用户模块的同事却想用 Golang + PostgreSQL 来构建系统。</li><li>有的模块需要高性能 CPU，有的模块需要大内存，因为不同的模块是耦合在一起的，所以我们的服务器不得不同时具备高性能 CPU，大内存，从而增加了成本。</li></ul><p>如何解决此类问题？<a href="https://zh.wikipedia.org/wiki/%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B" target="_blank" rel="noopener">康威定律</a>给出了很好的建议：「设计系统的架构受制于产生这些设计的组织的沟通结构」，通俗点说就是：「有什么样的组织架构就会设计出什么样的系统架构」。在本例中，因为不同的团队负责不同的模块，所以很自然的可以通过模块来把系统切分成商城、推荐、评论、用户等几个独立的服务：每个服务有自己独立的版本库和数据库，服务之间通过 RPC 来通信。不同的服务拥有自己的版本库，可以使用适合自己的技术栈和硬件，独立开发独立部署。</p><p>一个需要注意的问题是如何确定服务粒度的大小，虽然按照康威定律的描述只要按照组织架构的大小来确定服务的大小即可，但是如何规划一个合理的团队规模呢？实际上并没有一个精确的答案，我们需要按照客观情况来确定一个适合自己的大小适中的服务粒度，过小的粒度会导致服务之间强耦合，过大的粒度则背离了微服务的初衷，Uber 甚至还针对服务粒度大小问题发明了一个<a href="https://mp.weixin.qq.com/s/1P_5mMeZQ8YQzybLmjENLg" target="_blank" rel="noopener">宏服务</a>的概念，有兴趣的读者不妨看看。</p><p><img src="https://img.hi-linux.com/staticfile/ms02-20210514145255339-2021-05-14-mujm29.png" alt></p><p>当我们把单体架构切分成独立的服务之后，原本模块间本地的函数调用变成了服务间远程的 RPC 调用，我们不得不处理服务治理之类的问题，随着微服务数量的增加，问题会变得越来越棘手，好在随着云原生的发展，特别是 <a href="https://kubernetes.io/" target="_blank" rel="noopener">K8S</a> 和 <a href="https://istio.io/" target="_blank" rel="noopener">istio</a> 等技术的成熟，我们的架构可以演化到 <a href="https://www.servicemesher.com/" target="_blank" rel="noopener">service mesh</a> 阶段，通过 sidecar 透明实现服务治理。</p><p><img src="https://img.hi-linux.com/staticfile/ms03-2021-05-14-7Q6UhO.png" alt></p><p>如果仅仅是把原本模块间本地的函数调用变成了服务间远程的 RPC 调用的话，那么我们的微服务很可能会沦为「<a href="https://skyao.io/talk/202007-microservice-avoiding-distributed-monoliths/" target="_blank" rel="noopener">分布式单体</a>」。问题的症结在于过度使用 RPC，导致服务与服务之间强耦合，解决方法是引入 Event，通过 Event 实现服务与服务的解耦。</p><p>看看如何实现下面的业务逻辑：当一个用户注册后，要在商城里给用户一张优惠券。</p><ul><li>使用 RPC（强调做什么）：当用户模块创建了一个新用户的时候，通过 RPC 调用商城模块给用户一张优惠券，过程中用户模块和商城模块是强耦合的。</li><li>使用 Event（强调发生了什么）：当用户模块创建了一个新用户的时候，它发出一个 UserCreated 事件，商城模块观察到对应的事件后，给用户一张优惠券，过程中用户模块和商城模块是弱耦合的。</li></ul><p>实际情况中应该按需求来选择使用 RPC 或者 Event：如果是业务逻辑的实现部分，倾向于选择使用 RPC；如果是业务逻辑完成之后的后续通知部分，强烈建议选择使用 Event。</p><p><img src="https://img.hi-linux.com/staticfile/ms04-2021-05-14-mw4b0B.png" alt></p><p>服务部署好了之后，接下来我们还需要考虑如何暴露服务以供前端调用，比如用户浏览某个商品的详情页，内容包括商品数据、以及对应的推荐数据和评论数据，如果直接操作服务的话，那么需要多次查询商品服务、推荐服务、评论服务，并不可取，此时可以加入 <a href="https://microservices.io/patterns/apigateway.html" target="_blank" rel="noopener">API Gateway</a> 充当代理，前端只要请求 API Gateway 一次就可以拿到数据。</p><p><img src="https://img.hi-linux.com/staticfile/ms05-2021-05-14-oA6Kbk.png" alt></p><p>有了 API Gateway 之后，它可以帮我们完成聚合之类的逻辑。不过有一个问题是前端可能有多种不同的类型，比如 PC 前端，Mobile 前端，它们的业务逻辑不可避免的会有各种各样的差异，如果在 API Gateway 中处理这些差异的话，那么会出现坏味道，为了解决此类问题，我们引入 <a href="https://microservices.io/patterns/apigateway.html" target="_blank" rel="noopener">BFF</a>（Backend For Frontend），每一种前端都有属于自己的 BFF，用来处理专属于自己的业务逻辑，至于 API Gateway，则只处理鉴权，日志等公共业务逻辑。</p><p><img src="https://img.hi-linux.com/staticfile/ms06-2021-05-14-teyyms.png" alt></p><p>微服务是个极其复杂的概念，本文仅就一些表面问题浅谈一二，其他诸如 <a href="https://microservices.io/patterns/data/saga.html" target="_blank" rel="noopener">SAGA</a> 之类的复杂问题，由于篇幅所限，并未涉猎，大家如果有兴趣的话请自行查阅。</p><p>最后把 <a href="https://martinfowler.com/" target="_blank" rel="noopener">Martin Fowler</a> 在 <a href="https://www.martinfowler.com/books/eaa.html" target="_blank" rel="noopener">PoEAA</a> 中提出的<a href="https://martinfowler.com/bliki/FirstLaw.html" target="_blank" rel="noopener">分布式对象第一定律</a>送给大家：不要分布你的对象！套用这个说法的话，不难引申出微服务第一定律：不要使用微服务！虽然话里有一些戏虐的成份，但是它至少告诫我们在面对微服务的时候要怀揣着一颗敬畏的心。</p><blockquote><p>本文转载自：「 火丁笔记 」，原文：<a href="http://t.cn/A6VzZPdg" target="_blank" rel="noopener">http://t.cn/A6VzZPdg</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;虽说&lt;a href=&quot;https://martinfowler.com/articles/microservices.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微服务&lt;/a&gt;早已是一个老生常谈的话题了，在 &lt;a href=&quot;https://www.infoq.cn/topic/microservice&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;infoq&lt;/a&gt; 或者 &lt;a href=&quot;https://insights.thoughtworks.cn/tag/microservices/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;thoughtworks&lt;/a&gt; 上可以找到很多案例，不过可惜的是其中相当比例的案例是失败的案例，究其原因，除了&lt;a href=&quot;https://microservices.io/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;技术门槛&lt;/a&gt;之外，主要是因为很多人脱离了实际情况，只是为了微服务而微服务。本文通过一个例子带领大家从头到尾体验一下微服务的演化过程，不仅要做到知其然，更要做到知其所以然。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>如何在 Linux下优雅的进行大文件切割与合并</title>
    <link href="https://www.hi-linux.com/posts/15581.html"/>
    <id>https://www.hi-linux.com/posts/15581.html</id>
    <published>2021-06-10T01:00:00.000Z</published>
    <updated>2021-06-10T09:50:38.834Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>往往是因为网络传输的限制，导致很多时候，我们需要在 Linux 系统下进行大文件的切割。这样将一个大文件切割成为多个小文件，进行传输，传输完毕之后进行合并即可。</strong></p></blockquote><h2><span id="1-文件切割-split">1. 文件切割 - split</span></h2><blockquote><p><strong>在 Linux 系统下使用 split 命令进行大文件切割很方便</strong></p></blockquote><ul><li><strong>[1] 命令语法</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -a: 指定输出文件名的后缀长度(默认为2个:aa,ab...)</span></span><br><span class="line"><span class="comment"># -d: 指定输出文件名的后缀用数字代替</span></span><br><span class="line"><span class="comment"># -l: 行数分割模式(指定每多少行切成一个小文件;默认行数是1000行)</span></span><br><span class="line"><span class="comment"># -b: 二进制分割模式(支持单位:k/m)</span></span><br><span class="line"><span class="comment"># -C: 文件大小分割模式(切割时尽量维持每行的完整性)</span></span><br><span class="line">split [-a] [-d] [-l &lt;行数&gt;] [-b &lt;字节&gt;] [-C &lt;字节&gt;] [要切割的文件] [输出文件名]</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li><strong>[2] 使用实例</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 行切割文件</span></span><br><span class="line">$ split -l 300000 users.sql /data/users_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用数字后缀</span></span><br><span class="line">$ split -d -l 300000 users.sql /data/users_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按字节大小分割</span></span><br><span class="line">$ split -d -b 100m users.sql /data/users_</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 帮助信息</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 帮助信息</span></span><br><span class="line">$ split --<span class="built_in">help</span></span><br><span class="line">Usage: split [OPTION]... [FILE [PREFIX]]</span><br><span class="line">Output pieces of FILE to PREFIXaa, PREFIXab, ...;</span><br><span class="line">default size is 1000 lines, and default PREFIX is <span class="string">'x'</span>.</span><br><span class="line"></span><br><span class="line">With no FILE, or when FILE is -, <span class="built_in">read</span> standard input.</span><br><span class="line"></span><br><span class="line">Mandatory arguments to long options are mandatory <span class="keyword">for</span> short options too.</span><br><span class="line">  -a, --suffix-length=N   generate suffixes of length N (default 2)            后缀名称的长度(默认为2)</span><br><span class="line">      --additional-suffix=SUFFIX  append an additional SUFFIX to file names</span><br><span class="line">  -b, --bytes=SIZE        put SIZE bytes per output file                       每个输出文件的字节大小</span><br><span class="line">  -C, --line-bytes=SIZE   put at most SIZE bytes of records per output file    每个输出文件的最大字节大小</span><br><span class="line">  -d                      use numeric suffixes starting at 0, not alphabetic   使用数字后缀代替字母后缀</span><br><span class="line">      --numeric-suffixes[=FROM]  same as -d, but allow setting the start value</span><br><span class="line">  -e, --elide-empty-files  <span class="keyword">do</span> not generate empty output files with <span class="string">'-n'</span>        不产生空的输出文件</span><br><span class="line">      --filter=COMMAND    write to shell COMMAND; file name is <span class="variable">$FILE</span>           写入到shell命令行</span><br><span class="line">  -l, --lines=NUMBER      put NUMBER lines/records per output file             设定每个输出文件的行数</span><br><span class="line">  -n, --number=CHUNKS     generate CHUNKS output files; see explanation below  产生chunks文件</span><br><span class="line">  -t, --separator=SEP     use SEP instead of newline as the record separator;  使用新字符分割</span><br><span class="line">                            <span class="string">'\0'</span> (zero) specifies the NUL character</span><br><span class="line">  -u, --unbuffered        immediately copy input to output with <span class="string">'-n r/...'</span>     无需缓存</span><br><span class="line">      --verbose           <span class="built_in">print</span> a diagnostic just before each                  显示分割进度</span><br><span class="line">                            output file is opened</span><br><span class="line">      --<span class="built_in">help</span>     display this <span class="built_in">help</span> and <span class="built_in">exit</span>                                    显示帮助信息</span><br><span class="line">      --version  output version information and <span class="built_in">exit</span>                           显示版本信息</span><br><span class="line"></span><br><span class="line">The SIZE argument is an <span class="built_in">integer</span> and optional unit (example: 10K is 10*1024).</span><br><span class="line">Units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).</span><br><span class="line"></span><br><span class="line">CHUNKS may be:</span><br><span class="line">  N       split into N files based on size of input</span><br><span class="line">  K/N     output Kth of N to stdout</span><br><span class="line">  l/N     split into N files without splitting lines/records</span><br><span class="line">  l/K/N   output Kth of N to stdout without splitting lines/records</span><br><span class="line">  r/N     like <span class="string">'l'</span> but use round robin distribution</span><br><span class="line">  r/K/N   likewise but only output Kth of N to stdout</span><br><span class="line"></span><br><span class="line">GNU coreutils online <span class="built_in">help</span>: &lt;http://www.gnu.org/software/coreutils/&gt;</span><br><span class="line">Full documentation at: &lt;http://www.gnu.org/software/coreutils/split&gt;</span><br><span class="line">or available locally via: info <span class="string">'(coreutils) split invocation'</span></span><br></pre></td></tr></table></figure><h2><span id="2-文件合并-cat">2. 文件合并 - cat</span></h2><blockquote><p><strong>在 Linux 系统下使用 cat 命令进行多个小文件的合并也很方便</strong></p></blockquote><ul><li><strong>[1] 命令语法</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -n: 显示行号</span></span><br><span class="line"><span class="comment"># -e: 以$字符作为每行的结尾</span></span><br><span class="line"><span class="comment"># -t: 显示TAB字符(^I)</span></span><br><span class="line">cat [-n] [-e] [-t] [输出文件名]</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 使用实例</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 合并文件</span></span><br><span class="line">$ cat /data/users_* &gt; users.sql</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 帮助信息</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 帮助信息</span></span><br><span class="line">$ cat --h</span><br><span class="line">Usage: cat [OPTION]... [FILE]...</span><br><span class="line">Concatenate FILE(s) to standard output.</span><br><span class="line"></span><br><span class="line">With no FILE, or when FILE is -, <span class="built_in">read</span> standard input.</span><br><span class="line"></span><br><span class="line">  -A, --show-all           equivalent to -vET</span><br><span class="line">  -b, --number-nonblank    number nonempty output lines, overrides -n</span><br><span class="line">  -e                       equivalent to -vE</span><br><span class="line">  -E, --show-ends          display $ at end of each line</span><br><span class="line">  -n, --number             number all output lines</span><br><span class="line">  -s, --squeeze-blank      suppress repeated empty output lines</span><br><span class="line">  -t                       equivalent to -vT</span><br><span class="line">  -T, --show-tabs          display TAB characters as ^I</span><br><span class="line">  -u                       (ignored)</span><br><span class="line">  -v, --show-nonprinting   use ^ and M- notation, except <span class="keyword">for</span> LFD and TAB</span><br><span class="line">      --<span class="built_in">help</span>     display this <span class="built_in">help</span> and <span class="built_in">exit</span></span><br><span class="line">      --version  output version information and <span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line">Examples:</span><br><span class="line">  cat f - g  Output f<span class="string">'s contents, then standard input, then g'</span>s contents.</span><br><span class="line">  cat        Copy standard input to standard output.</span><br><span class="line"></span><br><span class="line">GNU coreutils online <span class="built_in">help</span>: &lt;http://www.gnu.org/software/coreutils/&gt;</span><br><span class="line">Full documentation at: &lt;http://www.gnu.org/software/coreutils/cat&gt;</span><br><span class="line">or available locally via: info <span class="string">'(coreutils) cat invocation'</span></span><br></pre></td></tr></table></figure><h2><span id="3-参考文档">3. 参考文档</span></h2><ul><li><a href="https://www.cnblogs.com/bymo/p/7571320.html" target="_blank" rel="noopener">Linux 大文件的分割与合并</a></li><li><a href="https://www.jianshu.com/p/014ec71b0215" target="_blank" rel="noopener">Linux 学习–文件分割与合并</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/y3zhsyyw%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://tinyurl.com/y3zhsyyw，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;往往是因为网络传输的限制，导致很多时候，我们需要在 Linux 系统下进行大文件的切割。这样将一个大文件切割成为多个小文件，进行传输，传输完毕之后进行合并即可。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-文件切割-split&quot;&gt;1. 文件切割 - split&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;在 Linux 系统下使用 split 命令进行大文件切割很方便&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;[1] 命令语法&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# -a: 指定输出文件名的后缀长度(默认为2个:aa,ab...)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# -d: 指定输出文件名的后缀用数字代替&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# -l: 行数分割模式(指定每多少行切成一个小文件;默认行数是1000行)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# -b: 二进制分割模式(支持单位:k/m)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# -C: 文件大小分割模式(切割时尽量维持每行的完整性)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;split [-a] [-d] [-l &amp;lt;行数&amp;gt;] [-b &amp;lt;字节&amp;gt;] [-C &amp;lt;字节&amp;gt;] [要切割的文件] [输出文件名]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
</feed>
