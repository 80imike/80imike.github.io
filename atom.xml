<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维之美</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2020-05-23T13:48:31.455Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何在不杀进程的前提下关闭一个 TCP Socket 连接</title>
    <link href="https://www.hi-linux.com/posts/62556.html"/>
    <id>https://www.hi-linux.com/posts/62556.html</id>
    <published>2020-05-23T02:03:00.000Z</published>
    <updated>2020-05-23T13:48:31.455Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>要在线关闭一个 TCP Socket 连接，你可能会说很简单，<code>netstat -antp</code> 找到连接，<code>kill</code> 掉这个进程就行了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># netstat -antp|grep 6789</span><br><span class="line">tcp        0      0 1.1.1.1:59950      1.1.1.2:6789        ESTABLISHED 45059&#x2F;ceph-fuse</span><br><span class="line"># kill 45059</span><br></pre></td></tr></table></figure><p>连接确实关掉了，进程也跟着一起杀死了。达不到 “在线” 的要求。</p><p>有没有办法不杀死进程，但还是可以关闭 Socket 连接呢？</p><p>我们知道，在编码的时候，要关闭一个 Socket，只要调用 close 函数就可以了，但是进程在运行着呢，怎么让它调用 close 呢？</p><p>在 superuser 上看到一个很棒的方法，原理就是 <code>gdb attach</code> 到进程上下文，然后 call close($fd)。</p><a id="more"></a><ol><li>使用 <code>netstat</code> 找到进程</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># netstat -antp|grep 6789</span><br><span class="line">tcp        0      0 1.1.1.1:59950      1.1.1.2:6789        ESTABLISHED 45059&#x2F;ceph-fuse</span><br></pre></td></tr></table></figure><p>如上，进程 pid 为 45059。</p><ol start="2"><li>使用 <code>lsof</code> 找到进程 45059 打开的所有文件描述符，并找到对应的 Socket 连接。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># lsof -np 45059</span><br><span class="line">COMMAND     PID USER   FD   TYPE             DEVICE SIZE&#x2F;OFF       NODE NAME</span><br><span class="line">ceph-fuse 45059 root  rtd    DIR                8,2     4096          2 &#x2F;</span><br><span class="line">ceph-fuse 45059 root  txt    REG                8,2  6694144    1455967 &#x2F;usr&#x2F;bin&#x2F;ceph-fuse</span><br><span class="line">ceph-fuse 45059 root  mem    REG                8,2   510416    2102312 &#x2F;usr&#x2F;lib64&#x2F;libfreeblpriv3.so</span><br><span class="line">...</span><br><span class="line">ceph-fuse 45059 root   12u  IPv4         1377072656      0t0        TCP 1.1.1.1:59950-&gt;1.1.1.2:smc-https (ESTABLISHED)</span><br></pre></td></tr></table></figure><p>其中 12u 就是上面对应 Socket 连接的文件描述符。</p><ol start="3"><li>gdb 连接到进程</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gdb -p 45059</span><br></pre></td></tr></table></figure><ol start="4"><li>关闭 Socket 连接</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) call close(12u)</span><br></pre></td></tr></table></figure><p>Socket 连接就可以关闭了，但是进程 45059 还是好着的。</p><p>你可能会问，什么时候会用到这个特性呢？场景还是比较多的，比如你想测试下应用是否会自动重连 MySQL，通过这个办法就可以比较方便的测试了。</p><blockquote><p>来源：Zlatan Eevee</p><p>原文：<a href="http://t.cn/AijmTykM" target="_blank" rel="noopener">http://t.cn/AijmTykM</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;要在线关闭一个 TCP Socket 连接，你可能会说很简单，&lt;code&gt;netstat -antp&lt;/code&gt; 找到连接，&lt;code&gt;kill&lt;/code&gt; 掉这个进程就行了。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# netstat -antp|grep 6789&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 1.1.1.1:59950      1.1.1.2:6789        ESTABLISHED 45059&amp;#x2F;ceph-fuse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# kill 45059&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;连接确实关掉了，进程也跟着一起杀死了。达不到 “在线” 的要求。&lt;/p&gt;
&lt;p&gt;有没有办法不杀死进程，但还是可以关闭 Socket 连接呢？&lt;/p&gt;
&lt;p&gt;我们知道，在编码的时候，要关闭一个 Socket，只要调用 close 函数就可以了，但是进程在运行着呢，怎么让它调用 close 呢？&lt;/p&gt;
&lt;p&gt;在 superuser 上看到一个很棒的方法，原理就是 &lt;code&gt;gdb attach&lt;/code&gt; 到进程上下文，然后 call close($fd)。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟理解微博云原生技术实践之路</title>
    <link href="https://www.hi-linux.com/posts/25333.html"/>
    <id>https://www.hi-linux.com/posts/25333.html</id>
    <published>2020-05-23T02:01:00.000Z</published>
    <updated>2020-05-23T13:36:09.057Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>现在越来越多的企业开始全面拥抱云计算，开始关注云原生技术。从管理物理数据中心到使用云主机，我们不用再关心基础运维。从云主机到 Kubernetes 容器，我们不用再关心机器的管理。云上抽象层级越高，就越少人需要关心底层问题，企业就能够节省大量的人力成本与资源投入。云原生技术就是更高一层的抽象，CNCF 对云原生技术的定义是：</p><blockquote><p>有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展应用。通过容器、服务网格、微服务、不可变基础设施和声明式API等技术，构建容错性好、易于管理和便于观察的松耦合系统。</p></blockquote><p>例如 FaaS 架构，开发者可以完全不用考虑服务器，构建并运行应用程序和服务。还有面向开源架构的的云原生技术，与提供 MySQL, Redis 云服务类似，提供基于 Spring Cloud、Dubbo、HSF 等开源微服务架构的应用管理服务，开发者无需考虑部署、监控、运维的问题。</p><p>微博也一直在致力于推动基础设施云原生化，我们围绕 Kubernetes 构建面向容器的云原生基础设施，形成了物理数据中心加多个公有云的混合云 Kubernetes 平台，提供秒级伸缩能力。构建开箱即用的 CI/CD 体系，依托云原生伸缩能力，保证大量的 Job 稳定运行，让开发人员摆脱代码发布泥沼。接下介绍这几方面的实践经验。</p><h2 id="物理数据中心-kubernetes-化">物理数据中心 Kubernetes 化</h2><p>面向单机器的基础设施架构已经无法发挥云的最大优势。把容器按照服务颗粒度进行管理，每个服务对应一组虚拟机，虽然基础运维通过 IaaS 层抽象得到了极大简化，但是业务的运维成本依然很高，业务 SRE 需要维护复杂的设备配置脚本，管理不同服务设备配置的差异性，需要 7 * 24 小时对故障设备进行干预。而且资源利用率无法最大化，服务池是按设备划分，一个新设备添加到服务池后只能被这个服务使用，它的冗余的计算能力并不能为其他服务使用。另外不同业务容器运行在不同的机器上，容器网络架构更关注性能而非隔离性，通常会采用 Host 模式，这也提高了服务混合部署的运维成本。</p><p>基础设施只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势。目前 Kubernetes 已经容器编排系统的事实标准，提供面向应用的容器集群部署和管理系统，消除物理（虚拟）机，网络和存储基础设施的负担。同时 CNCF 推出一致性认证，推动各公有云厂商提供标准的 Kubernetes 服务，这就确保通过 Kubernetes 部署的应用在不同云厂商之间具有可迁移性，避免被厂商锁定。</p><p>之前提到微博的容器会独占物理机的网络协议栈，虽然能够做到网络效率的最大化，但是会导致多容器部署时出现端口冲突，无法满足 Kubernetes 动态编排的需求。为了解决端口冲突问题，我们首先测试了 vxlan 网络架构，因为其数据平面需要进行封装、解封操作，网络性能损耗超过5%，并不满足微博后端服务对网络性能的要求。最后我们评估可行的网络方案有两种 MacVlan 和 Calico BGP。</p><p>其中 MacVlan 成熟稳定，通过机房上联交换机改为 Vlan Trunk 模式，在物理机上创建 MacVlan 网卡子接口，通过 CNI 插件将虚拟网卡插入 Pause 容器中，实现容器网络与物理网络打通。容器的网络通信直接通过 MacVlan 物理子接口，发出的报文在网卡上打 VlanTag，数据平面基本没有性能损耗。控制平面因需要对所有上联交换机进行 Vlan Trunk 改造，工作量较大，所以这个方案仅针对高配物理机所在网络进行了改造。</p><p>Calico BGP 是可以同时实现数据平面 0 损耗与控制平面自动化的容器网络解决方案。与 MacVlan 实现的扁平二层网络不同，Calico 在每个节点上部署 BGP Client 与 Reflector 实现了一个扁平的三层网络，每个节点发布的路由状态由 Felix 维护。不过由于 Felix 采用 iptables 实现路由 ACLs 功能，对性能存在一定影响。因为物理数据中心不面向外部用户开放，所以 ACLs 功能对微博是可以去除的，我们对 Calico 进行了优化，去除 iptables 依赖。</p><p><img src="https://catrixs.github.io/images/calico_acls.png" alt=""></p><p>微博也主动回馈 Kubernetes 社区，也包括为 Kubernetes 代码库做贡献，例如修复多租户下网络隔离TC资源泄露问题。</p><p>之前的运维是面向物理机的，所以物理机上存在很多运维工具，如日志推送、域名解析、时钟同步、定时任务等。业务通过 Kubernetes 编排后，以上的功能都需要进行容器化改造。例如在容器中使用 systemd 会涉及到提权问题，在实践过程中发现用 systemd 如果权限控制不当会造成容器被 Kill 的情况。所以我们单独开发了兼容 linux crontab 语法的定时任务工具 gorun，把这个工具集成在了运维容器里面。</p><p>因为业务容器会产生大量日志，出于 I/O 性能考虑，同时为了方便快速定位，日志会存储于本地 PVC 中，支持配额管理，避免一个容器把磁盘写满。运维基础设施容器通过监听文件，对老旧日志进行压缩清理，性能 Profile 日志会在本地进行统计计算后通过 UDP 协议推送到 Graphite 或 Prometheus。对于关键日志，会通过 Flume 推送到 Kafka 集群，而且支持失败重传，保证日志的一致性。</p><p><img src="https://catrixs.github.io/images/pod_log.jpg" alt=""></p><p>通过对运维容器化后，所有业务 Pod 都具备相同的运维能力，形成标准化的监控报警、运维决策、流量切换、服务降级，异常封杀、日志查询的服务保障体系，服务可运维性大幅度提升。</p><a id="more"></a><h2 id="容器编排">容器编排</h2><p>Kubernetes 的 Deployment 支持 Pod 自我修复，滚动升级和回滚，扩容和缩容，这些特性都是云原生基础设施必备的。但是 Kubernetes 设计原则中对集群的管理尤其是服务升级过程中保持“无损”升级，对 Deployment 进行滚动升级，会创建新 Pod 替换老 Pod，以保证 Deployment 中 Pod 的副本数量。原有里面的IP地址和滚动升级之前的IP地址是不会相同的。而如果集群够大，一次滚动发布就会导致负载均衡变更 （集群副本数／滚动发布步长）次。对于微博服务来说，频繁变更会导致这个负载均衡辖下，所以后端实例的接口不稳定。</p><p>微博实现了常备 Pod 的 In-place Rolling Updates 功能，根据业务冗余度及业务实际需要来调整上线的步长，上线过程中保持容器的IP不变，减少在上线过程中业务的抖动。因为业务的启动需要一定时间，不能按照容器启停来做步长控制，我们利用 Kubernetes 容器生命周期管理的 liveness/readiness probe 实现容器提供服务的状态，避免了上线过程中容器大面积重启的问题。同时优化了 Kubernetes 的 postStar 的原生实现，因为原生里面只调用一次，不管成功与否都会杀掉容器，改成不成功会按照指定的次数或时间进行重试。IP 的静态分配使用 Calico CNI 实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: wb_service</span><br><span class="line">  annotations:</span><br><span class="line">      &quot;cni.projectcalico.org&#x2F;ipAddrs&quot;: &quot;[\&quot;10.142.0.50\&quot;]&quot;</span><br></pre></td></tr></table></figure><p>Kubernetes 的编排策略相对灵活，分为三个阶段，初筛阶段用于筛选出符合基本要求的物理机节点，优选阶段用于得到在初筛的节点里面根据策略来完成选择最优节点。在优选完毕之后，还有一个绑定过程，用于把Pod和物理机进行绑定，锁定机器上的资源。这三步完成之后，位于节点上的 kubelet 才开始创建 Pod。在实际情况中，把物理机上的容器迁移到 Kubernetes，需要保持容器的部署结构尽量一致，例如一个服务池中每台物理机上分配部署了 <code>wb_service_a和wb_service_b</code> 两个容器，可以通过 podAffinity 来完成服务混部的编排：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: wb_service_b</span><br><span class="line">  annotations:</span><br><span class="line">      &quot;cni.projectcalico.org&#x2F;ipAddrs&quot;: &quot;[\&quot;10.142.0.50\&quot;]&quot;</span><br><span class="line">  labels:</span><br><span class="line">  service: wb_service_b</span><br><span class="line">spec:</span><br><span class="line">affinity:</span><br><span class="line">podAffinity:</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">  - labelSelector:</span><br><span class="line">      matchExpressions:</span><br><span class="line">      - key: service</span><br><span class="line">        operator: In</span><br><span class="line">        values: [&quot;wb_service_a&quot;]</span><br><span class="line">    topologyKey: &quot;kubernetes.io&#x2F;hostname&quot;</span><br></pre></td></tr></table></figure><p>一些比较复杂的，运维复杂的集群，通过 Kubernetes Operator 进行容器编排。Operator 是由 CoreOS 开发的，用来扩展 Kubernetes API，特定的应用程序控制器，它用来创建、配置和管理复杂的有状态应用，如数据库、缓存和监控系统。Operator基于Kubernetes的资源和控制器概念之上构建，但同时又包含了应用程序特定的领域知识。Operator 可以将运维人员对软件操作的知识给代码化，同时利用 Kubernetes 强大的抽象来管理大规模的软件应用。例如 CacheService 的运维是比较复杂的，需要资源编排，数据同步，HA 结构编排，备份与恢复，故障恢复等等。通过实现 CacheService Operator 可以让开发一通过声明式的 Yaml 文件即可创建、配置、管理复杂的 Cache 集群。CacheService Operator 支持：</p><ol><li><p>创建/销毁：通过 Yaml 声明 CacheService 规格，即可通过 Kubernetes 一键部署，删除</p></li><li><p>伸缩：可以修改 Yaml 中声明的副本数量，Operator 实现扩容，配置主从结构，挂载域名等操作</p></li><li><p>备份：Operator 根据 Yaml 中声明的备份机制，实现自动的备份功能，例如定期备份，错峰备份等</p></li><li><p>升级：实现不停机版本升级，并支持回滚</p></li><li><p>故障恢复：单机故障时，自动 HA 切换，同时恢复副本数量，并自动恢复主从结构</p></li></ol><p>复杂的应用在 Kubernetes 上部署，服务数量众多，服务间的依赖关系也比较复杂，每个服务都有自己的资源文件，并且可以独立的部署与伸缩，这给采用 Kubernetes 做应用编排带来了诸多挑战：</p><ol><li><p>管理、编辑与更新大量的 Yaml 配置文件，</p></li><li><p>部署一个含有大量配置文件的复杂 Kubernetes 应用，例如上面提到的 CacheService Operator</p></li><li><p>参数化配置模板支持多个环境</p></li></ol><p>Helm 可以解决这些问题。Helm 把 Kubernetes 资源（如Pods, Deployments, Services等) 打包到一个 Chart 中，实现可配置的发布是通过模板加配置文件，动态生成资源清单文件。</p><h2 id="弹性伸缩">弹性伸缩</h2><p>在云时代，弹性已经成为新常态。而且微博的社交媒体属性，不可提前预期的突发峰值是家常便饭，所以基础设施不但需要具备弹性，而且需要具备在短时间内提供足够资源的能力。Kubernetes 基于容器技术在启动时间方面比虚拟机更具优势，省去了虚拟机创建、环境初始化、配置管理等诸多环节，直接拉起业务 Pod，扩容时间可以从分钟级缩短到秒级。</p><p>而且峰值流量突发时，运维、开发同学可能是在吃饭、睡觉、休假，这个时候靠人为干预肯定是来不及的，所以系统需要自动做出扩容决策。对于复杂的分布式系统，实现自动决策需要解决两个问题，一个是容量决策，一个是依赖关系。Kubernetes 的 HPA (Horizontal Pod Autoscaling) 可以根据 Metric 自动伸缩一个 Deployment 中的 Pod 数量。HPA 由一个控制循环实现，循环周期由 horizontal-pod-autoscaler-sync-period 标志指定（默认是 30 秒）。在每个周期内，查询 HPA 中定义的资源利用率。并且在扩容前会有一个冷静期，一般是 5 分钟（可通过horizontal-pod-autoscaler-downscale-stabilization参数设置），然后通过下面的公式进行扩缩容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desired &#x3D; ceil[current * ( currentMetric &#x2F; desiredMetric )]</span><br></pre></td></tr></table></figure><p>但是这种容量决策存在两个问题。因为突发峰值流量上涨迅速，上述扩容机制第一次扩容往往扩不到位，触发连续多次扩容，导致服务在流量上涨期间一直处于过载状态，影响服务SLA。另一个问题是冷静期问题，如果冷静期过长，会导致峰值流量无法得到及时扩容，冷静期过短会错把抖动当做峰值，造成不必要的成本浪费。第三个问题是复杂的业务系统依赖关系复杂，每个服务根据各自指标进行伸缩，由于上面还未伸缩流量被挡在了上游，下游这时感知不到准确流量趋势，从整体应用角度看很容易出现上游泄洪下游被淹的问题。</p><p>微博整体的弹性伸缩架构是基于混合云的架构，内网私有云，公有云虚机，云 Kubernetes 一体化 Kubernetes 弹性集群，实现快速自动化资源调度，解决了跨 IDC 调度、定制的调度算法与策略、容量评估、服务间扩容依赖关系等，构建了全链路，压测，指标，报警，干预多维度的能力：</p><ol><li><p>全链路是构建一个应用整体的容量决策体系，各服务不再独自判定容量，而是根据全链路容量指标作出一致性扩容决策</p></li><li><p>压测可以帮助了解目前部署的冗余情况，合理的设定扩容公式，避免多次重复性扩容</p></li><li><p>指标体系是要从成千上万个 Metric 中抽象出可以作为决策的依据，打通负载均衡，Web 服务，数据库资源等多维度指标</p></li><li><p>报警及时多路径触达，避免单点</p></li><li><p>干预不但要支持快速伸缩，还应支持快速优雅降级，为服务扩容争取时间</p></li></ol><h2 id="cicd">CI/CD</h2><p>云计算技术的普及，研发流程也随之变化，越来越多的组织和团队开始接受 DevOps 理念。持续集成（CI）和持续交付（CD）是 DevOps 的基石。但是 CI/CD 在实际落地过程中存在诸多困难，导致实际效果不理想。以 CI 为例，开发同学应该对“顺利的话，会有大约 100 个失败的测试” 这种情形并不陌生。由于开发环境与测试环境并不一致等诸多因素，CI 经常出现不相干的偶发失败，长此以往开发同学会默认选择忽略 CI 环节的报错警告，最终导致 CI/CD 沦为一句口号。</p><p>利用云原生的声明性基础架构，可以将应用系统的和应用程序存放在 Git 的版本控制库中，每个开发人员都可以提交拉取请求代码，轻松在 Kubernetes 上部署应用程序和运维任务，开发人员可以更高效地将注意力集中在创建新功能而不是运维相关任务上。基于 Git 的持续交付流水线，有诸多优势和特点：</p><ol><li><p>版本控制的声明性容器编排，Kubermetes 作为一个云原生的工具，可以把它的 “声明性” 看作是 “代码”，声明意味着配置由一组事实而不是一组指令组成，例如，“有十个 Redis 服务器”，而不是 “启动十个 Redis 服务器，告诉我它是否有效”</p></li><li><p>Git 作为事实的唯一真实来源，任何能够被描述的内容都必须存储在 Git 库中，包括系统相关的：策略，代码，配置，甚至监控事件</p></li><li><p>与其他工具相结合，例如监控系统可以方便地监控集群，以及检查比较实际环境的状态与代码库上的状态是否一致</p></li></ol><p>目前大多数 CI/CD 工具都使用基于推送的模型。基于推送的流水线意味着代码从 CI 系统开始，通过一系列构建测试等最终生成镜像，最后手动使用 “kubectl” 将部署到 Kubernetes 集群。程序员是最不喜欢开发流程被打断，多个系统间的切换会极大影响程序员的开发效率。所以我们通过 CI 和 IDE 结合，把 CI 流程融入到开发自测环节中，让程序员可以进行面向 CI 的测试驱动开发，提高对交付代码质量的信心。</p><p>CI/CD 流水线是围绕程序员经常使用的 GitLab 构建，程序员可以对 Merge Request 的 CI 结果一目了然，避免了在多个系统间来回切换。每次代码提交都要执行基于分支的完整 CI 流程，借助云原生的弹性能力和共享存储，解决了大量并发的 Job 的计算资源瓶颈，同时缓解了 Job 间共享数据的带宽压力以及网络传输延时。</p><p><img src="https://catrixs.github.io/images/ci_cd.png" alt=""></p><p>持续部署要比持续集成更加复杂。部署流程中依赖人工的环节非常多，例如灰度是由运维部署到生产环境部分机器，验证需要依靠开发和运维同学经验检查新版本各项指标是否正常，滚动发布与回滚也需要运维同学全程干预。金丝雀部署可以有效规避风险，在生产环境的基础设施中小范围的部署新的应用代码，如果没有错误，新版本才逐渐推广到整个服务，而不用一次性从老版本切换到新版本。不过如何验证没有错误是比较有挑战的，微服务依赖复杂、部署范围广、指标维度多，是最易出错，最耗时的环节。我们针对这个问题，开发了智能时序数据异常识别服务，覆盖操作系统，JVM，资源 SLA，业务 SLA 的上千维度指标。它不但可以自动准确识别异常识别，性能衰减等人工经验能够发现的问题，也能够识别如资源不合理访问等人工很难察觉的问题。现在的 CD 流程包含部署、集成测试、金丝雀验证、滚动发布、回滚自动化环节。</p><h2 id="weibo-mesh">Weibo Mesh</h2><p>Service Mesh 并不是什么新的技术，它所关注的高性能、高可用、服务发现和治理等有服务化的一天就已经存在，社区也不乏这方面的最佳实践。不过之前主要是两种方式，一种是微服务 RPC 框架形式，例如 Motan, gRPC, Thrift, Dubbo 等。传统微服务框架有诸多弊端：</p><ol><li><p>升级困难，框架、SDK 的与业务代码强绑定</p></li><li><p>多语言问题，各种语言的服务治理能力天差地别，服务质量体系难以统一</p></li></ol><p>还有一种是集中式 Proxy 形式，例如 Nginx, Twemproxy, SQL Proxy 等。虽然 Proxy 的形式一定程度上解决了胖客户端的问题，没有了升级问题，多语言可以统一接入。但是在性能方面的损耗，对于耗时较长的请求来说还可以接受，但这在服务间调用这种毫秒级请求时，性能是不能容忍的，而且服务的拆分势必导致整个体系内耗时随着微服务规模的扩大而剧增，而且 Proxy 本身很容易成为整个系统中的瓶颈点。所以经常可以看到后端服务是同时使用 Proxy 和 RPC 的情况。</p><p>而 Cloud Native 会催生出如此火爆的 Service Mesh，最主要的因素是 Kubernetes 使基础设施的标准化，大家发现之前这些很重的 RPC 框架可以抽离出来，原本需要增加维护的复杂性被 Kubernetes 解决掉了，跨语言、服务治理等收益凸显出来。而且 Mesh 的 SideCard 形式，相比 Proxy 在请求耗时方面优势也相当明显。</p><p><img src="https://philcalcado.com/img/service-mesh/6-b.png" alt=""></p><p>图片来自：Pattern: Service Mesh</p><p>微博将 Motan RPC 胖客户端实现的治理功能下沉到 Agent 上，服务注册和发现依赖微博自研 Vintage 命名和配置服务，对服务的订阅和发现来建立服务间依赖的逻辑网络。业务与 的通信协议保持一致，Agent 支持 HTTP 和 RPC 的调用，业务只需把原有的调用指向 Agent 即可，不需要改造业务代码。在跨语言通信协议设计方面，Google 的 Protocol Buffers（pb）序列化能够提供优秀的跨语言序列化能力，但是在一是老旧 HTTP 迁移到 pb 协议的改造成本过高，二是部分语言（例如 PHP） 在做复杂 pb 对象序列化时性能比较差，甚至比 json 序列化还要慢 3 倍左右。微博实现了全新语言无关的通信协议 Motan2 和跨语言友好的数据序列化协议 Simple 来应对跨语言。</p><p>除了代理 Service 的能力外，Mesh 体系提供了缓存、队列等服务化代理，业务方可以与依赖缓存、队列资源治理解耦的能力。可以大幅提高那些治理能力比较薄弱的业务和语言的架构水平。随着云原生技术的日趋完善，会有越来越多的基础设施从原有的 SDK 中抽象出来。未来数据库访问会以 Database Mesh 形式提供访问，封装数据分片、读写分离、从库负载均衡、熔断、链路采集能力，例如 Google Cloud SQL 提供本地 Proxy，业务方无需将 IP 地址列入白名单或配置 SSL，即可安全地访问 Cloud SQL。</p><blockquote><p>来源：Fatrix’s Blog</p><p>原文：<a href="https://url.cn/5fdD1qF" target="_blank" rel="noopener">https://url.cn/5fdD1qF</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在越来越多的企业开始全面拥抱云计算，开始关注云原生技术。从管理物理数据中心到使用云主机，我们不用再关心基础运维。从云主机到 Kubernetes 容器，我们不用再关心机器的管理。云上抽象层级越高，就越少人需要关心底层问题，企业就能够节省大量的人力成本与资源投入。云原生技术就是更高一层的抽象，CNCF 对云原生技术的定义是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展应用。通过容器、服务网格、微服务、不可变基础设施和声明式API等技术，构建容错性好、易于管理和便于观察的松耦合系统。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如 FaaS 架构，开发者可以完全不用考虑服务器，构建并运行应用程序和服务。还有面向开源架构的的云原生技术，与提供 MySQL, Redis 云服务类似，提供基于 Spring Cloud、Dubbo、HSF 等开源微服务架构的应用管理服务，开发者无需考虑部署、监控、运维的问题。&lt;/p&gt;
&lt;p&gt;微博也一直在致力于推动基础设施云原生化，我们围绕 Kubernetes 构建面向容器的云原生基础设施，形成了物理数据中心加多个公有云的混合云 Kubernetes 平台，提供秒级伸缩能力。构建开箱即用的 CI/CD 体系，依托云原生伸缩能力，保证大量的 Job 稳定运行，让开发人员摆脱代码发布泥沼。接下介绍这几方面的实践经验。&lt;/p&gt;
&lt;h2 id=&quot;物理数据中心-Kubernetes-化&quot;&gt;物理数据中心 Kubernetes 化&lt;/h2&gt;
&lt;p&gt;面向单机器的基础设施架构已经无法发挥云的最大优势。把容器按照服务颗粒度进行管理，每个服务对应一组虚拟机，虽然基础运维通过 IaaS 层抽象得到了极大简化，但是业务的运维成本依然很高，业务 SRE 需要维护复杂的设备配置脚本，管理不同服务设备配置的差异性，需要 7 * 24 小时对故障设备进行干预。而且资源利用率无法最大化，服务池是按设备划分，一个新设备添加到服务池后只能被这个服务使用，它的冗余的计算能力并不能为其他服务使用。另外不同业务容器运行在不同的机器上，容器网络架构更关注性能而非隔离性，通常会采用 Host 模式，这也提高了服务混合部署的运维成本。&lt;/p&gt;
&lt;p&gt;基础设施只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势。目前 Kubernetes 已经容器编排系统的事实标准，提供面向应用的容器集群部署和管理系统，消除物理（虚拟）机，网络和存储基础设施的负担。同时 CNCF 推出一致性认证，推动各公有云厂商提供标准的 Kubernetes 服务，这就确保通过 Kubernetes 部署的应用在不同云厂商之间具有可迁移性，避免被厂商锁定。&lt;/p&gt;
&lt;p&gt;之前提到微博的容器会独占物理机的网络协议栈，虽然能够做到网络效率的最大化，但是会导致多容器部署时出现端口冲突，无法满足 Kubernetes 动态编排的需求。为了解决端口冲突问题，我们首先测试了 vxlan 网络架构，因为其数据平面需要进行封装、解封操作，网络性能损耗超过5%，并不满足微博后端服务对网络性能的要求。最后我们评估可行的网络方案有两种 MacVlan 和 Calico BGP。&lt;/p&gt;
&lt;p&gt;其中 MacVlan 成熟稳定，通过机房上联交换机改为 Vlan Trunk 模式，在物理机上创建 MacVlan 网卡子接口，通过 CNI 插件将虚拟网卡插入 Pause 容器中，实现容器网络与物理网络打通。容器的网络通信直接通过 MacVlan 物理子接口，发出的报文在网卡上打 VlanTag，数据平面基本没有性能损耗。控制平面因需要对所有上联交换机进行 Vlan Trunk 改造，工作量较大，所以这个方案仅针对高配物理机所在网络进行了改造。&lt;/p&gt;
&lt;p&gt;Calico BGP 是可以同时实现数据平面 0 损耗与控制平面自动化的容器网络解决方案。与 MacVlan 实现的扁平二层网络不同，Calico 在每个节点上部署 BGP Client 与 Reflector 实现了一个扁平的三层网络，每个节点发布的路由状态由 Felix 维护。不过由于 Felix 采用 iptables 实现路由 ACLs 功能，对性能存在一定影响。因为物理数据中心不面向外部用户开放，所以 ACLs 功能对微博是可以去除的，我们对 Calico 进行了优化，去除 iptables 依赖。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://catrixs.github.io/images/calico_acls.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;微博也主动回馈 Kubernetes 社区，也包括为 Kubernetes 代码库做贡献，例如修复多租户下网络隔离TC资源泄露问题。&lt;/p&gt;
&lt;p&gt;之前的运维是面向物理机的，所以物理机上存在很多运维工具，如日志推送、域名解析、时钟同步、定时任务等。业务通过 Kubernetes 编排后，以上的功能都需要进行容器化改造。例如在容器中使用 systemd 会涉及到提权问题，在实践过程中发现用 systemd 如果权限控制不当会造成容器被 Kill 的情况。所以我们单独开发了兼容 linux crontab 语法的定时任务工具 gorun，把这个工具集成在了运维容器里面。&lt;/p&gt;
&lt;p&gt;因为业务容器会产生大量日志，出于 I/O 性能考虑，同时为了方便快速定位，日志会存储于本地 PVC 中，支持配额管理，避免一个容器把磁盘写满。运维基础设施容器通过监听文件，对老旧日志进行压缩清理，性能 Profile 日志会在本地进行统计计算后通过 UDP 协议推送到 Graphite 或 Prometheus。对于关键日志，会通过 Flume 推送到 Kafka 集群，而且支持失败重传，保证日志的一致性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://catrixs.github.io/images/pod_log.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过对运维容器化后，所有业务 Pod 都具备相同的运维能力，形成标准化的监控报警、运维决策、流量切换、服务降级，异常封杀、日志查询的服务保障体系，服务可运维性大幅度提升。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="云原生" scheme="https://www.hi-linux.com/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>漫谈云计算、虚拟化、容器化</title>
    <link href="https://www.hi-linux.com/posts/2749.html"/>
    <id>https://www.hi-linux.com/posts/2749.html</id>
    <published>2020-05-23T02:00:00.000Z</published>
    <updated>2020-05-23T13:30:24.745Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h3 id="什么是云计算">什么是云计算？</h3><p>1.1 云计算概念</p><p>云计算是最近几年才兴起的概念，但是这样的需求其实早都有了，现阶段广为接受的是美国国家标准与技术研究院（NIST）定义：云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。</p><p>云计算最基本的特性是：“按使用量付费”、“资源共享池”和多租户隔离。</p><p>1.2 云计算的特点</p><ul><li>超大规模</li></ul><p>云具有相当的规模，Google 云计算已经拥有 100 多万台服务器， Amazon、IBM、微软、Yahoo 等的云均拥有几十万台服务器。企业私有云一般拥有数百上千台服务器。云能赋予用户前所未有的计算能力。</p><ul><li>虚拟化</li></ul><p>云计算支持用户在任意位置、使用各种终端获取应用服务。所请求的资源来自云，而不是固定的有形的实体。应用在云中某处运行，但实际上用户无需了解、也不用担心应用运行的具体位置。只需要一台笔记本或者一个手机，就可以通过网络服务来实现我们需要的一切，甚至包括超级计算这样的任务。</p><ul><li>高可靠性</li></ul><p>云使用了数据多副本容错、计算节点同构可互换等措施来保障服务的高可靠性，使用云计算比使用本地计算机可靠。</p><ul><li>通用性</li></ul><p>云计算不针对特定的应用，在云的支撑下可以构造出千变万化的应用，同一个云可以同时支撑不同的应用运行。</p><ul><li>高可扩展性</li></ul><p>云的规模可以动态伸缩，满足应用和用户规模增长的需要。</p><ul><li>按需服务</li></ul><p>云是一个庞大的资源池，你按需购买;云可以像自来水，电，煤气那样计费。</p><ul><li>极其廉价</li></ul><p>由于云的特殊容错措施可以采用极其廉价的节点来构成云，云的自动化集中式管理使大量企业无需负担日益高昂的数据中心管理成本，云的通用性使资源的利用率较之传统系统大幅提升，因此用户可以充分享受云的低成本优势，经常只要花费几百美元、几天时间就能完成以前需要数万美元、数月时间才能完成的任务。</p><ul><li>潜在的危险性</li></ul><p>云计算服务除了提供计算服务外，还必然提供了存储服务。但是云计算服务当前垄断在私人机构(企业)手中，而他们仅仅能够提供商业信用。对于政府机构、商业机构(特别像银行这样持有敏感数据的商业机构)对于选择云计算服务应保持足够的警惕。一旦商业用户大规模使用私人机构提供的云计算服务，无论其技术优势有多强，都不可避免地让这些私人机构以数据(信息)的重要性挟制整个社会。</p><p>对于信息社会而言，信息是至关重要的。另一方面，云计算中的数据对于数据所有者以外的其他用户云计算用户是保密的，但是对于提供云计算的商业机构而言确实毫无秘密可言。所有这些潜在的危险，是商业机构和政府机构选择云计算服务、特别是国外机构提供的云计算服务时，不得不考虑的一个重要的前提。</p><a id="more"></a><p>1.3  云计算的分类</p><ul><li>公有云：只有使用权，使用的时候进行按需付费。但数据放在别人家。数据安全没有保障。而且银行不会使用公有云，金融行业不要使用公有云。公有云的核心属性是共享资源服务。</li><li>私有云：自己的机房搭建的云，私有云有局限性，资源固定；数据比较安全。私有云的核心属性是专有资源。</li><li>混合云：主要任务放到私有云，临时需要时利用混合云，它将公有云和私有云进行混合匹配，以获得最佳的效果，这种个性的解决方案，达到二既省钱又安全的目的。</li></ul><p>1.4 云计算分层</p><p>云计算也是层的，大概有以下几种：</p><p><img src="https://images2015.cnblogs.com/blog/936003/201612/936003-20161213225505511-661553597.png" alt=""></p><ul><li>传统 IT</li></ul><p>基本所有的都需要自行管理，比如：网络、存储、服务器、虚拟化，操作系统、中间件、运行环境、数据、应用等。</p><ul><li>IaaS: Infrastructure-as-a-Service（基础设施即服务）</li></ul><p>IaaS 主要作用是提供虚拟机或者其他资源作为服务提供给用户。</p><ul><li>PaaS: Platform-as-a-Service（平台即服务）</li></ul><p>PaaS, 中文名为平台即服务。如果以传统计算机架构中 “硬件+操作系统/开发工具+应用软件” 的观点来看待，那么云计算的平台层应该提供类似操作系统和开发工具的功能。实际上也的确如此，PaaS 定位于通过互联网为用户提供一整套开发、运行和运行应用软件的支撑平台。就像在个人计算机软件开发模式下，程序员可能会在一台装有 Windows 或 Linux 操作系统的计算机上使用开发工具开发并部署应用软件一样。PaaS 某些时候也叫做中间件，主要作用是提供一个开发和运行平台给用户。</p><ul><li>SaaS: Software-as-a-Service（软件即服务）</li></ul><p>SaaS，软件即服务。简单地说，就是一种通过互联网提供软件服务的软件应用模式。在这种模式下，用户不需要再花费大量投资用于硬件、软件和开发团队的建设，只需要支付一定的租赁费用，就可以通过互联网享受到相应的服务，而且整个系统的维护也由厂商负责。</p><p>如果要用一句话来概括 IaaS、PaaS 和 SaaS 的话，那就是：如果把云计算比喻成一部手机，那么 IaaS 就是硬件，你要自己写代码研发系统才能用；PaaS 是手机系统，你要实现什么功能还是要装各种软件；SaaS 就是硬件+系统+软件，你要干什么一句话就能解决。</p><h3 id="什么是虚拟化">什么是虚拟化？</h3><p>2.1 虚拟化概念</p><p>虚拟化是通过软件手段对计算机硬件资源镜像整合管理和再分配的一种技术，常用的手段有基于虚拟机的虚拟化和基于容器的虚拟化。</p><p>2.2 虚拟化技术分类</p><p>2.2.1 按应用场景分类</p><ul><li>操作系统虚拟化</li><li>应用程序虚拟化</li><li>桌面应用虚拟化</li><li>存储虚拟化</li><li>网络虚拟化</li></ul><p>2.2.2 按照应用模式分类</p><ul><li>一对多：其中将一个物理服务器划分为多个虚拟服务器，这是典型的服务器整合模式。</li><li>多对一：其中整合了多个虚拟服务器，并将它们作为一个资源池，这是典型的网格计算模式。</li><li>多对多：将前两种模式结合在一起。</li></ul><p>2.2.3 按硬件资源调用模式分类</p><p><img src="https://images2015.cnblogs.com/blog/936003/201612/936003-20161214132509308-445646843.png" alt=""></p><ul><li>全虚拟化</li></ul><p>全虚拟化，虚拟化操作系统与底层硬件完全隔离。由中间的 Hypervisor 层转化虚拟化客户操作系统对底层硬件的调用代码，全虚拟化无需更改客户端操作系统，并兼容性好。典型代表有：Vmware Workstation、KVM。</p><ul><li>半虚拟化</li></ul><p>半虚拟化，在虚拟客户操作系统中加入特定的虚拟化指令，通过这些指令可以直接通过 Hypervisor 层调用硬件资源，免除有 Hypervisor 层转换指令的性能开销。半虚拟化的典型代表 Microsoft Hyper-V、Vmware 的 vSphere。</p><blockquote><p>注：针对 IO 层面半虚拟化要比全虚拟化要好，因为磁盘 IO 多一层必定会慢。一般说 IO 就是网络 IO 和磁盘 IO，因为这两个相对而言是比较慢的。</p></blockquote><p>2.3 基于虚拟机（Hypervisor-based）的虚拟化</p><p>它通过一个软件层的封装，提供和物理硬件相同的输入输出表现。实现了操作系统和计算机硬件的解耦，将 OS 和计算机间从 1 对 1 变成了多对多（实际上是 1 对多）的关系。该软件层称为虚拟机管理器（VMM / Hypervisor），它可以直接运行在裸机上（Xen、VMware EXSi），也可以运行在操作系统上（KVM、VMware Workstation）。这项技术已经很成熟了,（发展了40 多年），但仍然存在以下几个问题：</p><ul><li>在虚拟机上运行了一个完整的操作系统（GuestOS），在其下执行的还有虚拟化层和宿主机操作系统，一定比直接在物理机上运行相同的服务性能差；</li><li>有 GuestOS 的存在，虚拟机镜像往往有几个 G 到几十个 G，占用的存储空间大，便携性差；</li><li>想要使用更多硬件资源，需要启动一台新的虚拟机。要等待 GuesOS 启动，可能需要几十秒到几分钟不等。</li></ul><p>实际使用场景中，我们使用虚拟化技术其实是为了按需分配资源来完成服务的部署和使用，同时对服务所依赖的环境进行隔离，不被其它服务感知或干扰。为此启动一个 GuestOS 并不是必需的，为什么不考虑让多个虚拟机公用一个操作系统内核，只隔离开服务运行环境同时控制服务使用的系统资源呢？基于容器的虚拟化就是这样一种技术。</p><p>2.4 基于容器的虚拟化</p><p>容器是没有 GuestOS 的轻量级虚拟机，多个容器共享一个 OS 内核，容器中包含需要部署的应用和它依赖的系统环境，容器大小通常只有几十到几百 MB。由于共享操作系统内核，所以容器依赖于底层的操作系统，各个操作系统大都有自己的容器技术和容器工具。</p><p>Docker 是一个 Linux 容器管理工具，随着 Docker 的兴起，Linux 容器技术也是当下最时兴的容器虚拟化技术。Linux 容器工具有很多，OpenVZ、LXC、Docker、Rocket、Lmctfy 等等，大都是基于 Linux 内核提供的两个机制：Cgroups（实现资源按需分配）和 Namespace（实现任务隔离）。</p><p>2.5 二种虚拟化技术的区别</p><ul><li>虚拟机技术已经发展了很多年，虚拟机和虚拟化层间的接口、虚拟机镜像格式等都已经标准化了。相应的管理工具、分布式集群管理工具都有比较完善的解决方案，而容器最近几年才兴起，配套技术和标准还在完善中；</li><li>虚拟机由于有 GuestOS 存在，可以和宿主机运行不同 OS，而容器只能支持和宿主机内核相同的操作系统；</li><li>虚拟机由于有 VMM 的存在，虚拟机之间、虚拟机和宿主机之间隔离性很好。而容器之间公用宿主机的内核，共享系统调用和一些底层的库，隔离性相对较差；</li><li>容器比虚拟机明显更轻量级，对宿主机操作系统而言，容器就跟一个进程差不多。因此容器有着更快的启动速度（秒级甚至更快），更高密度的存储和使用（镜像小）、更方便的集群管理等优点。同时由于没有 GuestOS 存在，在容器中运行应用和直接在宿主机上几乎没有性能损失，比虚拟机明显性能上有优势。</li></ul><h3 id="云计算和虚拟化差别">云计算和虚拟化差别</h3><p>对云计算和虚拟化差别的描述，有一句经典的话：虚拟化是云计算构建资源池的一个主要方式。只要这句话你理解透了就知道他俩的关系了。</p><p>简单来说，云计算是一个概念，而不是具体技术。虚拟化是一种具体技术，指把硬件资源虚拟化，实现隔离性、可扩展性、安全性、资源可充分利用等特点的产品。</p><p>目前云计算，大多是依赖虚拟化，通过把多台服务器实体虚拟化后，构成一个资源池，实现共同计算，共享资源。也就是现在所谓云计算，其实这个词提出来之前，过去的服务器集群就已经实现这些功能了，只不过没有现在那么先进而已。</p><p>3.1 各领域代表的产品</p><ul><li><p>云计算架构的开源产品是 OpenStack，OpenStack 是一个由 NASA 和 Rackspace 合作研发并发起的，以 Apache 许可证授权的自由软件和开放源代码项目。</p></li><li><p>虚拟机的虚拟化：VM 的商业付费 vSphere 或者开源的 KVM。</p></li><li><p>容器的虚拟化：Docker。</p></li></ul><p>3.2 OpenStack</p><p>Openstack 是众多技术的组合体，有涉及网络组件的 Neutron，有涉及 Dashboard 的 Horizon，也有涉及计算资源分配的 Nova。</p><p>虚拟化技术只是其中一个涉及到资源池构建的方式。当然你也可以用其它方式构建资源池,比如物理机还有容器。</p><p>Openstack 经过几年十几个版本的更迭，已经拥有了 Keystone、Nova、Neutron、Cinder、Glance、Swift、Heat、Ceilometer 等等组件，比较完整的提供了一个云平台应有的各个模块。</p><p>3.3 在云计算中，不同层的选型</p><p>选取基于虚拟机的虚拟化呢，还是基于容器的虚拟化。早期由于容器技术的不完善，云计算只有虚拟机这一种选择。</p><p>随着现在容器技术兴起，基于容器的虚拟化性能更高，交付速度快，方便管理，而且资源利用率高，看起来是比虚拟机更好的方案。但是它现有的两个比较大的缺点（隔离性不够强、操作系统依赖性）让他无法完全替代 VM，对于 SaaS 用户和部分 PaaS 用户而言这两个缺点可能不那么明显。现阶段 Container 和云计算主要结合的场景也是在 SaaS 和 PaaS 中，事实上大多数 SaaS 和 PaaS 服务提供商都使用了容器技术。</p><p>但是对于 IaaS 的用户来说，他们租用的是基础设施。上面承载着他们自己运行的系统和服务，隔离性不强意味着安全性和可信性不高。在这种情况下大客户们，肯定是不放心的。同时操作系统依赖性也是限制 Container 在 IaaS 层应用的一个主要问题，也是绝大多数解决方案都是将Container 运行在 VM 上的原因，这样 Container 性能好的优势实际上在云上根本发挥不出来，优点只有启动快了。</p><h3 id="参考文档">参考文档</h3><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="http://t.cn/Ai98v0mw" target="_blank" rel="noopener">http://t.cn/Ai98v0mw</a></li><li><a href="http://t.cn/E5fCarY" target="_blank" rel="noopener">http://t.cn/E5fCarY</a></li><li><a href="http://t.cn/EzJpfCn" target="_blank" rel="noopener">http://t.cn/EzJpfCn</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是云计算？&quot;&gt;什么是云计算？&lt;/h3&gt;
&lt;p&gt;1.1 云计算概念&lt;/p&gt;
&lt;p&gt;云计算是最近几年才兴起的概念，但是这样的需求其实早都有了，现阶段广为接受的是美国国家标准与技术研究院（NIST）定义：云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。&lt;/p&gt;
&lt;p&gt;云计算最基本的特性是：“按使用量付费”、“资源共享池”和多租户隔离。&lt;/p&gt;
&lt;p&gt;1.2 云计算的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;超大规模&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云具有相当的规模，Google 云计算已经拥有 100 多万台服务器， Amazon、IBM、微软、Yahoo 等的云均拥有几十万台服务器。企业私有云一般拥有数百上千台服务器。云能赋予用户前所未有的计算能力。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;虚拟化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算支持用户在任意位置、使用各种终端获取应用服务。所请求的资源来自云，而不是固定的有形的实体。应用在云中某处运行，但实际上用户无需了解、也不用担心应用运行的具体位置。只需要一台笔记本或者一个手机，就可以通过网络服务来实现我们需要的一切，甚至包括超级计算这样的任务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高可靠性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云使用了数据多副本容错、计算节点同构可互换等措施来保障服务的高可靠性，使用云计算比使用本地计算机可靠。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通用性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算不针对特定的应用，在云的支撑下可以构造出千变万化的应用，同一个云可以同时支撑不同的应用运行。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高可扩展性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云的规模可以动态伸缩，满足应用和用户规模增长的需要。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按需服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云是一个庞大的资源池，你按需购买;云可以像自来水，电，煤气那样计费。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;极其廉价&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于云的特殊容错措施可以采用极其廉价的节点来构成云，云的自动化集中式管理使大量企业无需负担日益高昂的数据中心管理成本，云的通用性使资源的利用率较之传统系统大幅提升，因此用户可以充分享受云的低成本优势，经常只要花费几百美元、几天时间就能完成以前需要数万美元、数月时间才能完成的任务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;潜在的危险性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算服务除了提供计算服务外，还必然提供了存储服务。但是云计算服务当前垄断在私人机构(企业)手中，而他们仅仅能够提供商业信用。对于政府机构、商业机构(特别像银行这样持有敏感数据的商业机构)对于选择云计算服务应保持足够的警惕。一旦商业用户大规模使用私人机构提供的云计算服务，无论其技术优势有多强，都不可避免地让这些私人机构以数据(信息)的重要性挟制整个社会。&lt;/p&gt;
&lt;p&gt;对于信息社会而言，信息是至关重要的。另一方面，云计算中的数据对于数据所有者以外的其他用户云计算用户是保密的，但是对于提供云计算的商业机构而言确实毫无秘密可言。所有这些潜在的危险，是商业机构和政府机构选择云计算服务、特别是国外机构提供的云计算服务时，不得不考虑的一个重要的前提。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>又一款好用的 Kubernetes 集群终端管理工具 Kubebox</title>
    <link href="https://www.hi-linux.com/posts/53405.html"/>
    <id>https://www.hi-linux.com/posts/53405.html</id>
    <published>2020-05-23T01:50:00.000Z</published>
    <updated>2020-05-23T04:51:38.875Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-kubebox">什么是 Kubebox</h2><p>Kubebox 是 <code>Kubernetes</code> 集群的终端控制台，允许使用界面管理和监控集群实时状态。Kubebox 可显示 Pod 资源使用情况、集群监视和容器日志等。此外，用户可轻松导航到所需的命名空间并执行到所需容器，以便快速排障或恢复。</p><blockquote><p>项目地址：<a href="https://github.com/astefanutti/kubebox" target="_blank" rel="noopener">https://github.com/astefanutti/kubebox</a></p></blockquote><h2 id="安装-kubebox">安装 KubeBox</h2><p>KubeBox 安装非常的简单，只需根据不同平台下载对应的二进制文件就可以了。</p><h3 id="下载二进制文件">下载二进制文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Linux</span><br><span class="line">$ curl -Lo kubebox https:&#x2F;&#x2F;github.com&#x2F;astefanutti&#x2F;kubebox&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;kubebox-linux &amp;&amp; chmod +x kubebox</span><br><span class="line"></span><br><span class="line"># OSX</span><br><span class="line">$ curl -Lo kubebox https:&#x2F;&#x2F;github.com&#x2F;astefanutti&#x2F;kubebox&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;kubebox-macos &amp;&amp; chmod +x kubebox</span><br><span class="line"></span><br><span class="line"># Windows</span><br><span class="line">$ curl -Lo kubebox.exe https:&#x2F;&#x2F;github.com&#x2F;astefanutti&#x2F;kubebox&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;kubebox-windows.exe</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="运行-kubebox">运行 KubeBox</h3><p>下载完成二进制文件后，我们只需直接执行就可以运行 KubeBox。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;kubebox</span><br></pre></td></tr></table></figure><p>执行成功之后，我们将会看到如下图一样的运行界面。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox1.png" alt=""></p><p>如果你觉得上面的方法太麻烦，当然你也可以使用 <code>Docker</code> 一键启动 Kubebox 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --rm -v ~&#x2F;.kube&#x2F;:&#x2F;home&#x2F;node&#x2F;.kube&#x2F;:ro astefanutti&#x2F;kubebox</span><br></pre></td></tr></table></figure><blockquote><p>注意：KubeBox 需要依赖本地的 <code>Kuberctl</code> 才能正常启动。你需要提前将 Kubernetes Master 节点下的 Kubeconfig 配置文件放在你所在机器的 <code>~/.kube/</code> 目录下，并修改 config 文件中 Server 的 IP 为你本地可访问的 IP 地址，或者设置环境变量 <code>KUBECONFIG</code>。</p></blockquote><h2 id="kubebox-的基本使用">KubeBox 的基本使用</h2><h3 id="1-kubebox-常用操作方式">1. KubeBox 常用操作方式</h3><ol><li><p>按回车键可进行条目选择。</p></li><li><p>按 M 键可查看内存使用情况。</p></li><li><p>按 C 键可查看 CPU 使用情况。</p></li><li><p>按 T 键可查看网络使用情况。</p></li><li><p>按 R 键可进入 CMD 命令终端。</p></li><li><p>按 Q 键直接退出 KubeBox。</p></li></ol><p>更多操作说明可参考下图中的详细说明。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox2.png" alt=""></p><h3 id="2-操作-namespace">2. 操作 Namespace</h3><p>你可以使用 「⬆️⬇️」选择需要操作的 Namespace，按「回车键」确认选择。如果需要再次唤起 Namespace 选项，你可以按「N 键」。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox3.png" alt=""></p><h3 id="3-操作-pod">3. 操作 Pod</h3><p>进入具体的 Namespace 空间后，你可以使用「⬆️⬇️」 选择指定的 Pod，按「回车键」确认选择，此时会显示 Pod 的如下信息。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox4.png" alt=""></p><p>此时你可以对 Pod 进行以下操作。</p><ol><li><p>按「M 键」查看内存使用的具体情况。</p></li><li><p>按「C 键」查看 CPU 使用的具体情况。</p></li><li><p>按「T 键」查看网络使用的具体情况。</p></li><li><p>鼠标点击 Logs 框后，按 「⬆️⬇️」键滚动浏览日志文件。</p></li></ol><h3 id="4-操作容器">4. 操作容器</h3><p>鼠标点击 Pods 框后，你可以按「⬆️⬇️」键选中指定的容器，然后按「R 键」进入容器。如果需要退出容器，你可以输入 <code>exit</code> 命令进行退出。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox5.png" alt=""></p><h3 id="5-debug-选项">5. Debug 选项</h3><p>按「⬅️➡️」键可以进行 Namespace 和 Debug 的菜单切换，或者直接按「2 键」进入 Debug 选项卡。这里将记录一些你在 Kubebox 上的操作日志。</p><p><img src="https://www.hi-linux.com/img/linux/KubeBox6.png" alt=""></p><h2 id="kubebox-web-模式">Kubebox Web 模式</h2><p>Kubebox 不但可以直接运行在终端，你也可以将它直接部署到 Kubernetes 集群中。下面是一个部署的 YAML 资源文件示例，你也可以根据自身实际情况修改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"># Create Service Account</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Create ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: admin-user</span><br><span class="line">    namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Deploy Kubebox</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-box</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-box</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: kube-box</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-box</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: admin-user</span><br><span class="line">      containers:</span><br><span class="line">        - image: astefanutti&#x2F;kubebox:server</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          name: kube-box</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8080</span><br><span class="line">              protocol: TCP</span><br><span class="line">---</span><br><span class="line"># Expose kubebox service</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name:  kube-box-service</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      targetPort: 8080</span><br><span class="line">      nodePort: 30001</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app:  kube-box</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure><p>部署完成后，你可以直接通过 Web 的方式对其进行访问，其默认访问地址为：<code>http://&lt;kubernetes-master-ip&gt;:30001/</code>。</p><p>如果你觉得部署太复杂，你也可以先通过官方的演示地址 <code>https://kube.sh/</code> 提前体验下。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://www.jianshu.com/p/d7c3cae2214f" target="_blank" rel="noopener">https://www.jianshu.com/p/d7c3cae2214f</a></p></li><li><p><a href="https://blog.csdn.net/qq_21816375/article/details/90765673" target="_blank" rel="noopener">https://blog.csdn.net/qq_21816375/article/details/90765673</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Kubebox&quot;&gt;什么是 Kubebox&lt;/h2&gt;
&lt;p&gt;Kubebox 是 &lt;code&gt;Kubernetes&lt;/code&gt; 集群的终端控制台，允许使用界面管理和监控集群实时状态。Kubebox 可显示 Pod 资源使用情况、集群监视和容器日志等。此外，用户可轻松导航到所需的命名空间并执行到所需容器，以便快速排障或恢复。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/astefanutti/kubebox&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/astefanutti/kubebox&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;安装-KubeBox&quot;&gt;安装 KubeBox&lt;/h2&gt;
&lt;p&gt;KubeBox 安装非常的简单，只需根据不同平台下载对应的二进制文件就可以了。&lt;/p&gt;
&lt;h3 id=&quot;下载二进制文件&quot;&gt;下载二进制文件&lt;/h3&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# Linux&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ curl -Lo kubebox https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;astefanutti&amp;#x2F;kubebox&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v0.6.1&amp;#x2F;kubebox-linux &amp;amp;&amp;amp; chmod +x kubebox&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# OSX&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ curl -Lo kubebox https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;astefanutti&amp;#x2F;kubebox&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v0.6.1&amp;#x2F;kubebox-macos &amp;amp;&amp;amp; chmod +x kubebox&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Windows&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ curl -Lo kubebox.exe https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;astefanutti&amp;#x2F;kubebox&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v0.6.1&amp;#x2F;kubebox-windows.exe&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Kubebox" scheme="https://www.hi-linux.com/tags/Kubebox/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟学会写一个自己的 Prometheus Exporter</title>
    <link href="https://www.hi-linux.com/posts/10846.html"/>
    <id>https://www.hi-linux.com/posts/10846.html</id>
    <published>2020-05-23T01:40:00.000Z</published>
    <updated>2020-05-23T04:17:04.473Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>去年底我写了一个阿里云云监控的 Prometheus Exporter, 后续迭代的过程中有一些经验总结, 这篇文章就将它们串联起来做一个汇总, 讲讲为什么要写 Exporter 以及怎么写一个好用的 Exporter?</p><h2 id="何为-prometheus-exporter">何为 Prometheus Exporter?</h2><p>Prometheus 监控基于一个很简单的模型: 主动抓取目标的指标接口(HTTP 协议)获取监控指标, 再存储到本地或远端的时序数据库. Prometheus 对于指标接口有一套固定的格式要求, 格式大致如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># HELP http_requests_total The total number of HTTP requests.</span><br><span class="line"># TYPE http_requests_total counter</span><br><span class="line">http_requests_total&#123;method&#x3D;&quot;post&quot;,code&#x3D;&quot;200&quot;&#125; 1027</span><br><span class="line">http_requests_total&#123;method&#x3D;&quot;post&quot;,code&#x3D;&quot;400&quot;&#125;    3</span><br></pre></td></tr></table></figure><p>对于自己写的代码, 我们当然可以使用 Prometheus 的 SDK 暴露出上述格式的指标. 但对于大量现有服务, 系统甚至硬件, 它们并不会暴露 Prometheus 格式的指标. 比如说:</p><ul><li>Linux 的很多指标信息以文件形式记录在 /proc/ 下的各个目录中, 如 /proc/meminfo 里记录内存信息, /proc/stat 里记录 CPU 信息;</li><li>Redis 的监控信息需要通过 INFO 命令获取;</li><li>路由器等硬件的监控信息需要通过 `SNMP** 协议获取;</li><li>…</li></ul><a id="more"></a><p>要监控这些目标, 我们有两个办法, 一是改动目标系统的代码, 让它主动暴露 Prometheus 格式的指标, 当然, 对于上述几个场景这种办法完全是不现实的. 这时候就只能采用第二种办法:</p><ol><li>编写一个代理服务, 将其它监控信息转化为 Prometheus 格式的指标</li></ol><p>这个代理服务的基本运作方式, 可以用下面这张图来表示:</p><p><img src="https://aleiwu.com/img/exporter/exporter.png" alt=""></p><p>而这样的代理服务, 就称作 Prometheus Exporter, 对于上面那些常见的情形, 社区早就写好了成熟的 Exporter, 它们就是 node_exporter, redis_exporter 和 snmp_exporter.</p><h2 id="为什么要写-exporter">为什么要写 Exporter?</h2><p>嗯, 写 exporter 可以把监控信息接进 Prometheus, 那为什么非要接进 Prometheus 呢?</p><p>我们不妨以阿里云云监控为例, 看看接进 Prometheus 的好处都有啥:</p><p>阿里云免费提供了一部分云监控服务, 但云监控的免费功能其实很有限, 没办法支持这些痛点场景:</p><ul><li>Adhoc TopN 查询: 比如”找到当前对公网带宽消耗最大的 10 台服务器”;</li><li>容量规划: 比如”分析过去一个月某类型服务的资源用量”;</li><li>高级报警: 比如”对比过去一周的指标值, 根据标准差进行报警”;</li><li>整合业务监控: 业务的监控信息存在于另一套监控系统中, 两套系统的看板, 警报都很难联动;</li></ul><p>幸好, 云监控提供了获取监控信息的 API, 那么我们很自然地就能想到: 只要写一个阿里云云监控的 Exporter, 不就能将阿里云的监控信息整合到 Prometheus 体系当中了吗?</p><p>当然, Exporter 就是做这个的!</p><p>集成到 Prometheus 监控之后, 借助 PromQL 强大的表达能力和 Alertmanager, Grafana 的强大生态, 我们不仅能实现所有监控信息的整合打通, 还能获得更丰富的报警选择和更强的看板能力. 下面就是一个对 RDS 进行 TopN 查询的例子:</p><p><img src="https://aleiwu.com/img/exporter/RDS.png" alt=""></p><p>这个动机对于其它类型的 Exporter 也都是适用的: 当一个系统本身暴露了监控信息, 却又无法接入 Prometheus, 我们就可以考虑写一个 exporter 把它接进来了.</p><h2 id="写一个好用的-exporter">写一个好用的 Exporter</h2><p>类似 “阿里云 Exporter” 这种形式的 Exporter 是非常好写的, 逻辑就是一句话:</p><ol><li>写一个 Web 服务, 每当 Prometheus 请求我们这个服务问我们要指标的时候, 我们就请求云监控的 API 获得监控信息, 再转化为 Prometheus 的格式返回出去;<br>但这样写完之后仅仅是”能用”, 要做到”好用”, 还有诸多考量.</li></ol><h2 id="从文档开始">从文档开始</h2><p>Prometheus 官方文档中 Writing Exporter 这篇写得非常全面, 假如你要写 exporter 推荐先通读一遍, 限于篇幅, 这里只概括一下:</p><ul><li>做到开箱即用(默认配置就可以直接开始用)</li><li>推荐使用 YAML 作为配置格式</li><li>指标使用下划线命名</li><li>为指标提供 HELP String (指标上的 # HELP 注释, 事实上这点大部分 exporter 都没做好)</li><li>为 Exporter 本身的运行状态提供指标</li><li>可以提供一个落地页</li></ul><p>下面几节中, 也会有和官方文档重复的部分, 但会略去理论性的部分(官方文档已经说的很好了), 着重讲实践例子.</p><h2 id="可配置化">可配置化</h2><p>官方文档里讲了 Exporter 需要开箱即用, 但其实这只是基本需求, 在开箱即用的基础上, 一个良好的 Exporter 需要做到高度可配置化. 这是因为大部分 Exporter 暴露的指标中, 真正会用到的大概只有 20%, 冗余的 80% 指标不仅会消耗不必要的资源还会拖累整体的性能. 对于一般的 Exporter 而言, BP 是默认只提供必要的指标, 并且提供 extra 和 filter 配置, 允许用户配置额外的指标抓取和禁用一部分的默认指标. 而对于阿里云 Exporter 而言, 由于阿里云有数十种类型的资源(RDS, ECS, SLB…), 因此我们无法推测用户到底希望抓哪些监控信息, 因此只能全部交给用户配置. 当然, 项目还是提供了包含 SLB, RDS, ECS 和 Redis 的默认配置文件, 尽力做到开箱即用.</p><h2 id="info-指标">Info 指标</h2><p>针对指标标签(Label), 我们考虑两点: “唯一性” 和 “可读性”:</p><p>“唯一性”: 对于指标, 我们应当只提供有”唯一性” 的(Label), 比如说我们暴露出 “ECS 的内存使用” 这个指标. 这时, “ECS ID” 这个标签就可以唯一区分所有的指标. 这时我们假如再加入 “IP”, “操作系统”, “名字” 这样的标签并不会增加额外的区分度, 反而会在某些状况下造成一些问题. 比方说某台 ECS 的名字变了, 那么在 Prometheus 内部就会重新记录一个时间序列, 造成额外的开销和部分 PromQL 计算的问题, 比如下面的示意图:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">序列A &#123;id&#x3D;&quot;foo&quot;, name&#x3D;&quot;旧名字&quot;&#125; ..................</span><br><span class="line">序列B &#123;id&#x3D;&quot;foo&quot;, name&#x3D;&quot;新名字&quot;&#125;                   .................</span><br></pre></td></tr></table></figure><p>“可读性”: 上面的论断有一个例外, 那就是当标签涉及”可读性”时, 即使它不贡献额外的区分度, 也可以加上. 比如 “IP” 这样的标签, 假如我们只知道 ECS ID 而不知道 IP, 那么根本对不上号, 排查问题也会异常麻烦.</p><p>可以看到, 唯一性和可读性之间其实有一些权衡, 那么有没有更好的办法呢?</p><p>答案就是 Info 指标(Info Metric). 单独暴露一个指标, 用 label 来记录实例的”额外信息”, 比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ecs_info&#123;id&#x3D;&quot;foo&quot;, name&#x3D;&quot;DIO&quot;, os&#x3D;&quot;linux&quot;, region&#x3D;&quot;hangzhou&quot;, cpu&#x3D;&quot;4&quot;, memory&#x3D;&quot;16GB&quot;, ip&#x3D;&quot;188.188.188.188&quot;&#125; 1</span><br></pre></td></tr></table></figure><p>这类指标的值习惯上永远为 1, 它们并记录实际的监控值, 仅仅记录 ecs 的一些额外信息. 而在使用的时候, 我们就可以通过 PromQL 的 “Join”(group_left) 语法将这些信息加入到最后的查询结果中:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 这条 PromQL 将 aliyun_meta_rds_info 中记录的描述和状态从添加到了 aliyun_acs_rds_dashboard_MemoryUsage 中</span><br><span class="line">aliyun_acs_rds_dashboard_MemoryUsage </span><br><span class="line">    * on (instanceId) group_left(DBInstanceDescription,DBInstanceStatus) </span><br><span class="line">    aliyun_meta_rds_info</span><br></pre></td></tr></table></figure><p>阿里云 Exporter 就大量使用了 Info 指标这种模式来提供实例的详细信息, 最后的效果就是监控指标本身非常简单, 只需要一个 ID 标签, 而看板上的信息依然非常丰富:</p><p><img src="https://aleiwu.com/img/exporter/ECS-detail.png" alt=""></p><h2 id="记录-exporter-本身的信息">记录 Exporter 本身的信息</h2><p>任何时候元监控(或者说自监控)都是首要的, 我们不可能依赖一个不被监控的系统去做监控. 因此了解怎么监控 exporter 并在编写时考虑到这点尤为重要.</p><p>首先, 所有的 Prometheus 抓取目标都有一个 up 指标用来表明这个抓取目标能否被成功抓取. 因此, 假如 exporter 挂掉或无法正常工作了, 我们是可以从相应的 up 指标立刻知道并报警的.</p><p>但 up 成立的条件仅仅是指标接口返回 200 并且内容可以被解析, 这个粒度太粗了. 假设我们用 exporter 监控了好几个不同的模块, 其中有几个模块的指标无法正常返回了, 这时候 up 就帮不上忙了.</p><p>因此一个 BP 就是针对各个子模块, 甚至于各类指标, 记录细粒度的 up 信息, 比如阿里云 exporter 就选择了为每类指标都记录 up 信息:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aliyun_acs_rds_dashboard_MemoryUsage&#123;id&#x3D;&quot;foo&quot;&#125; 1233456</span><br><span class="line">aliyun_acs_rds_dashboard_MemoryUsage&#123;id&#x3D;&quot;bar&quot;&#125; 3215123</span><br><span class="line"></span><br><span class="line">aliyun_acs_rds_dashboard_MemoryUsage_up 1</span><br></pre></td></tr></table></figure><p>当 aliyun_acs_rds_dashboard_MemoryUsage_up 这个指标出现 0 的时候, 我们就能知道 aliyun rds 内存信息的抓取不正常, 需要报警出来人工介入处理了.</p><p>另外, 阿里云的指标抓取 API 是有流控和每月配额的, 因此阿里云 exporter 里还记录了各种抓取请求的次数和响应时间的分布, 分别用于做用量的规划和基于响应时间的监控报警. 这也是”监控 exporter”本身的一个例子.</p><h2 id="设计落地页">设计落地页</h2><p>用过 node_exporter 的会知道, 当访问它的主页, 也就是根路径 / 时, 它会返回一个简单的页面, 这就是 exporter 的落地页(Landing Page).</p><p>落地页什么都可以放, 我认为最有价值的是放文档和帮助信息(或者放对应的链接). 而文档中最有价值的莫过于对于每个指标项的说明, 没有人理解的指标没有任何价值.</p><h2 id="可选-一键起监控">可选: 一键起监控</h2><p>这一点超出了 exporter 本身的范畴, 但确确实实是 exporter “好用” 的一个极大助力. exporter 本身是无法单独使用的, 而现实情况是 Prometheus, Grafana, Alertmanager 再对接 Slack, 钉钉啥的, 这一套假如需要从头搭建, 还是有一定的门槛(用 k8s 的话至少得看一下 helm chart 吧), 甚至于有些时候想搭建监控的是全栈(gan)工程师, 作为全公司的独苗, 很可能更多的精力需要花在跟进前端的新技术上(不我没有黑前端…). 这时候, 一个一键拉起整套监控系统的命令诱惑力是非常大的.</p><p>要一键拉起整套监控栈, 首先 kubernetes 就不考虑了, 能无痛部署生产级 kubernetes 集群的大佬不会需要这样的命令. 这时候, 反倒凉透的 docker-compose 是一个很好的选择. 还是以阿里云 exporter 为例, 仓库提供的 docker-compose stack 里提供了 Prometheus, aliyun-exporter, Grafana(看板), Alertmanager(发警报), alertmanager-dingtalk-webhook(适配 alertmanager 的警报到钉钉机器人) 的一键部署并且警报规则和 Grafana 看板页一并配置完毕. 这么一来, 只要用户有一台装了 docker 的机器, 他就能在5分钟之内打开 Grafana 看到这些效果(还有钉钉警报…假如这位用户的服务器不太健康的话):</p><p><img src="https://aleiwu.com/img/exporter/stack.gif" alt=""></p><p>当然了, 想要稳固地部署这套架构, 还是需要多机做高可用或者直接扔到 k8s, swarm 这样的编排系统上. 但假如没有”一键部署”的存在, 很多对 Prometheus 生态不熟悉的开发者就会被拒之门外; 另外, 对于有经验的用户, “一键部署”也能帮助他们快速理解这个 exporter 的特性, 帮助他们判断是否需要启用这个组件.</p><h2 id="结语">结语</h2><p>你可能已经看出来了, 这篇文章的本意是打广告(当然, 我已经非常努力地写了我所认为的”干货”!). aliyun-exporter 这个项目其实最开始只是我练习 Python 用的, 但在前几天碰到一位用户告诉我他们在生产中使用了这个项目, 这给了莫大的鼓舞, 正好我还没有在公开场合 Promote 过这个项目, 因此这周就捞一把, 希望项目本身或这些衍生出来的经验中有一样能帮到大家吧.</p><blockquote><p>来源：Aylei’s Blog</p><p>原文：<a href="http://j.mp/2QkCn8T" target="_blank" rel="noopener">http://j.mp/2QkCn8T</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;去年底我写了一个阿里云云监控的 Prometheus Exporter, 后续迭代的过程中有一些经验总结, 这篇文章就将它们串联起来做一个汇总, 讲讲为什么要写 Exporter 以及怎么写一个好用的 Exporter?&lt;/p&gt;
&lt;h2 id=&quot;何为-Prometheus-Exporter&quot;&gt;何为 Prometheus Exporter?&lt;/h2&gt;
&lt;p&gt;Prometheus 监控基于一个很简单的模型: 主动抓取目标的指标接口(HTTP 协议)获取监控指标, 再存储到本地或远端的时序数据库. Prometheus 对于指标接口有一套固定的格式要求, 格式大致如下:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# HELP http_requests_total The total number of HTTP requests.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# TYPE http_requests_total counter&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;http_requests_total&amp;#123;method&amp;#x3D;&amp;quot;post&amp;quot;,code&amp;#x3D;&amp;quot;200&amp;quot;&amp;#125; 1027&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;http_requests_total&amp;#123;method&amp;#x3D;&amp;quot;post&amp;quot;,code&amp;#x3D;&amp;quot;400&amp;quot;&amp;#125;    3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;对于自己写的代码, 我们当然可以使用 Prometheus 的 SDK 暴露出上述格式的指标. 但对于大量现有服务, 系统甚至硬件, 它们并不会暴露 Prometheus 格式的指标. 比如说:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux 的很多指标信息以文件形式记录在 /proc/ 下的各个目录中, 如 /proc/meminfo 里记录内存信息, /proc/stat 里记录 CPU 信息;&lt;/li&gt;
&lt;li&gt;Redis 的监控信息需要通过 INFO 命令获取;&lt;/li&gt;
&lt;li&gt;路由器等硬件的监控信息需要通过 `SNMP** 协议获取;&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/categories/Prometheus/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>推荐一个 Linux 计划任务 Crontab 在线生成器</title>
    <link href="https://www.hi-linux.com/posts/23704.html"/>
    <id>https://www.hi-linux.com/posts/23704.html</id>
    <published>2020-05-23T01:30:00.000Z</published>
    <updated>2020-05-23T04:12:40.611Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Linux / Unix</code> 系统里有一个很方便的程序「例行性计划任务」（Crontab），接触过的朋友一定不陌生。Crontab 主要是让系统去执行一些固定时间要自动进行的例行性工作，最常用的例如备份资料、移除暂存文件、更新或重新启动等等。如果将某个周期执行一次的指令写进 <code>Crontab</code>，它就会随着系统时间的推移在你指定的时间自动执行，减少每次都必须重复执行相同工作的麻烦。</p><p><code>Crontab</code> 有几种设定方法，最直观的是在图形化控制台（例如 <code>cPanel</code>）上操作，一般使用者可能会在命令行编辑 <code>/etc/crontab</code> 文件。但令我困扰的是 <code>Crontab</code> 时间格式写法有些复杂，如果没有参考说明文档就很难写出正确格式。或者你想要让计划任务时间更细粒度、更有弹性，你就必须知道怎么样以标准格式来描述要执行某个例行性工作的时间。</p><p>最近无意间发现一个很好用的免费工具「<code>Crontab.guru</code>」，它是一个更快速、更简单的在线计划任务编辑器。无须额外下载安装任何程序，只要依照 <code>Crontab.guru</code> 指定每列的时间，就可以快速完成计划任务时间的设定。它除了会以英文来描述这个时间，让使用者更容易理解外，你只要将结果复制粘贴到 <code>Crontab</code> 就能设定好指定的计划任务。</p><p>下面我们将以图文方式来叙述「<code>Crontab.guru</code>」工具的使用方法。</p><blockquote><ol><li><p>网站名称：Crontab.guru</p></li><li><p>网站链接：<a href="https://crontab.guru/" target="_blank" rel="noopener">https://crontab.guru/</a></p></li></ol></blockquote><a id="more"></a><h2 id="使用方法">使用方法</h2><ol><li>STEP 1</li></ol><p>开启 <code>Crontab.guru</code> 网站后，主要功能就在网站上方，也就是你看到的那一条可编辑列。</p><p><img src="https://i2.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1242.png" alt=""></p><p>预设情况每次开启 <code>Crontab.guru</code> 网站时都会自动跳出一组计划任务时间写法。你可以注意看一下每一个数字底下都会有对应的单位，由左至右分别是分钟、小时、日、月和周。下方还会告诉你这些列的表示法，例如可以用 <code>*</code> 代表任何数值、以 <code>,</code> 分隔多个数值等等。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1243.png" alt=""></p><ol start="2"><li>STEP 2</li></ol><p>前面我们有说过 <code>Crontab.guru</code> 本身就是一个简单方便的 <code>Crontab</code> 编辑器，因此使用者可以直接选取数字将它改成你要的计划时间。在编辑时 <code>Crontab.guru</code> 还会同步在上方「描述」标示出这个数值代表的意思，例如：下图我在编辑的「21」是代表 <code>hour</code>，也就是指晚上九点 。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1247.png" alt=""></p><p>每列都有不同的表达方式，例如加上 <code>,</code> 逗号来分隔多个数值、加上 <code>*</code> 代表任何数值，也能使用 <code>–</code> 来描述某个区间，修改时底下会告诉你可以使用的数值有那一些。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1247-1.png" alt=""></p><ol start="3"><li>STEP 3</li></ol><p>如果要描述「0 0,12 1 */2 *」这样复杂的计划任务，或许你很难马上理解过来。<code>Crontab.guru</code> 的好处是它会转为英文描述显示于网站上方，我们就能很清楚知道这是指「每两个月的第一天当日的 0 点、12 点」。</p><p><img src="https://i0.wp.com/free.com.tw/blog/wp-content/uploads/2017/01/Crontab.guru2017-01-12_1248.png" alt=""></p><p>如果你想知道一些固定的时间写法范本，<code>Crontab.guru</code> 也有一个「Examples」页面。里面收录许多范例，例如：每小时、每半天、每周、每季或每半年等等。</p><h2 id="总结">总结</h2><p>至此，利用 <code>Crontab.guru</code> 快速设定计划任务的方法就介绍完了。最后在这里再推荐另一个类似的在线计划任务生成工具 <code>Linux Crontab Generator</code>，它的使用方法和 <code>Crontab.guru</code> 类似，但功能更加强大！</p><blockquote><p>项目地址：<a href="https://helloacm.com/crontab-generator/" target="_blank" rel="noopener">https://helloacm.com/crontab-generator/</a></p></blockquote><p><img src="https://i.loli.net/2019/11/12/Q8Gr37qzdpuh4mD.png" alt=""></p><blockquote><p>来源：免费资源网络社群</p><p>原文：<a href="https://url.cn/5SzHje6" target="_blank" rel="noopener">https://url.cn/5SzHje6</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Linux / Unix&lt;/code&gt; 系统里有一个很方便的程序「例行性计划任务」（Crontab），接触过的朋友一定不陌生。Crontab 主要是让系统去执行一些固定时间要自动进行的例行性工作，最常用的例如备份资料、移除暂存文件、更新或重新启动等等。如果将某个周期执行一次的指令写进 &lt;code&gt;Crontab&lt;/code&gt;，它就会随着系统时间的推移在你指定的时间自动执行，减少每次都必须重复执行相同工作的麻烦。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Crontab&lt;/code&gt; 有几种设定方法，最直观的是在图形化控制台（例如 &lt;code&gt;cPanel&lt;/code&gt;）上操作，一般使用者可能会在命令行编辑 &lt;code&gt;/etc/crontab&lt;/code&gt; 文件。但令我困扰的是 &lt;code&gt;Crontab&lt;/code&gt; 时间格式写法有些复杂，如果没有参考说明文档就很难写出正确格式。或者你想要让计划任务时间更细粒度、更有弹性，你就必须知道怎么样以标准格式来描述要执行某个例行性工作的时间。&lt;/p&gt;
&lt;p&gt;最近无意间发现一个很好用的免费工具「&lt;code&gt;Crontab.guru&lt;/code&gt;」，它是一个更快速、更简单的在线计划任务编辑器。无须额外下载安装任何程序，只要依照 &lt;code&gt;Crontab.guru&lt;/code&gt; 指定每列的时间，就可以快速完成计划任务时间的设定。它除了会以英文来描述这个时间，让使用者更容易理解外，你只要将结果复制粘贴到 &lt;code&gt;Crontab&lt;/code&gt; 就能设定好指定的计划任务。&lt;/p&gt;
&lt;p&gt;下面我们将以图文方式来叙述「&lt;code&gt;Crontab.guru&lt;/code&gt;」工具的使用方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;网站名称：Crontab.guru&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;网站链接：&lt;a href=&quot;https://crontab.guru/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://crontab.guru/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Crontab" scheme="https://www.hi-linux.com/tags/Crontab/"/>
    
  </entry>
  
  <entry>
    <title>推荐一个强大到可让任何程序秒变系统服务的神器 EasyService</title>
    <link href="https://www.hi-linux.com/posts/9752.html"/>
    <id>https://www.hi-linux.com/posts/9752.html</id>
    <published>2020-05-23T01:20:00.000Z</published>
    <updated>2020-05-23T04:05:17.728Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-easyservice">什么是 EasyService</h2><p>如果你的 <code>Windows</code> 程序需要在后台长期运行，而且你希望它在开机后用户登录之前就自动运行、且在用户注销之后也不停止，那么你需要将程序注册为一个系统服务。</p><p>然而，在 <code>Windows</code> 下编写一个可注册为系统服务的程序并不是一件简单的事情。首先，程序必须是二进制的可执行程序，这就排除了脚本语言和虚拟机语言；其次，程序必须按系统服务的格式编写，过程相当繁琐。</p><p><code>EasyService</code> 是一个可以将常规程序注册为系统服务的工具，体积只有 16KB 。你可以按常规的方法编写程序，然后用 <code>EasyService</code> 注册为一个系统服务，这样你的程序就可以在开机后用户登录之前自动运行、且在用户注销之后也不会停止。</p><p>如果你需要在 <code>Windows</code> 系统下部署网站、<code>API</code> 或其他需要长期在后台运行的服务， <code>EasyService</code> 将是一个很有用的工具。</p><blockquote><p>项目地址：<a href="https://github.com/pandolia/easy-service/" target="_blank" rel="noopener">https://github.com/pandolia/easy-service/</a></p></blockquote><a id="more"></a><h3 id="easyservice-实现原理">EasyService 实现原理</h3><p><code>EasyService</code> 实质是将自己（<code>svc.exe</code>）注册为一个系统服务，此服务启动时，会读取 <code>svc.conf</code> 中的配置。然后创建一个子进程运行 <code>Worker</code> 中指定的程序及命令行参数并监视该子进程。如果发现子进程停止运行，会重新启动一个子进程。而当此服务停止时，会向子进程的标准输入中写入数据 “<code>exit</code>” ，并等待子进程退出，如果等待时间超过 10 秒，则直接终止子进程。</p><h2 id="使用-easyservice">使用 EasyService</h2><ol><li><code>EasyService</code> 对程序仅有一个强制要求和一个建议。</li></ol><ul><li><p>强制要求： 程序应持续运行</p></li><li><p>建议： 当程序的标准输入接收到 “<code>exit</code>” 后在 10 秒之内退出</p></li></ul><p>这类型典型的程序有很多，比如：命令行内网穿透 <code>frp</code> 工具、各种 <code>Nodejs</code>、<code>Python</code> 小工具等等。</p><ol start="2"><li>安装 EasyService</li></ol><p>安装 <code>EasyService</code> 的前提是系统已安装 <code>.NetFramework 4.0</code> （大部分 <code>Windows</code> 系统都已自带）。然后你就可以通过下面的地址下载对应的安装程序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;pandolia&#x2F;easy-service&#x2F;archive&#x2F;master.zip</span><br></pre></td></tr></table></figure><ol start="3"><li>编辑配置文件</li></ol><p>解压上面的安装压缩包，然后打开 <code>svc.conf</code> 文件，并根据需求修改配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 需要注册成 Windows 系统服务的名称，不能与系统中已有服务重名</span><br><span class="line">ServiceName: An Easy Service</span><br><span class="line"></span><br><span class="line"># 需要运行的可执行程序及命令行参数</span><br><span class="line">Worker: node index.js</span><br><span class="line"></span><br><span class="line"># 程序运行的工作目录，请确保该目录已存在</span><br><span class="line">WorkingDir: worker</span><br><span class="line"></span><br><span class="line"># 输出目录，程序运行过程的输出将会写到这个目录下面，请确保该目录已存在</span><br><span class="line">OutFileDir: outfiles</span><br><span class="line"></span><br><span class="line"># 程序输出的编码形式，如果不确定，请设为空或 none</span><br><span class="line">WorkerEncoding: utf8</span><br></pre></td></tr></table></figure><ol start="4"><li>注册成为一个服务</li></ol><p>用管理员账号登录系统后，在 <code>svc.exe</code> 所在的目录下打开命令行窗口。</p><ul><li><p>首先，运行 <code>svc check</code> 命令检查配置是否合法。</p></li><li><p>其次，运行 <code>svc test-worker</code> 命令测试 <code>Worker</code> 程序是否能正常运行。</p></li></ul><p>测试无误后，接着执行以下命令。</p><ul><li>运行 <code>svc install</code> 命令注册并启动系统服务，此时你的程序就已经开始运行了。即便用户注销也不会停止运行，且系统开机后、用户登录之前就会自动运行。你在服务管理控制台中也可以查看已注册的服务。</li></ul><blockquote><p>注意：<code>Windows 10</code> 系统下，需要先在开始菜单中搜索 <code>cmd</code> 命令。然后右键以管理员身份运行后，再切换到 <code>svc.conf</code> 所在的目录并执行以上命令。</p></blockquote><p>如果要在命令行下管理新注册的服务，你可以使用以下这些命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ svc stop # 停止一个服务</span><br><span class="line">$ svc start # 启动一个服务</span><br><span class="line">$ svc restart # 重启一个服务</span><br><span class="line">$ svc remove # 删除一个服务</span><br></pre></td></tr></table></figure><ol start="5"><li>注册多个服务</li></ol><p>如果需要注册多个服务，你可以先新建多个目录，并将 <code>svc.exe</code> 和 <code>svc.conf</code> 拷贝到这些目录。然后修改各目录 <code>svc.conf</code> 文件中的服务名和程序名等内容。最后，再在这些目录下以管理员权限打开命令行窗口执行 <code>svc check|test-worker|install</code> 等命令就可以了。需要注意的是：</p><ul><li><p>不同目录下的服务名不能相同，也不能和系统已有的服务同名。</p></li><li><p>配置文件中的 <code>Worker/WorkingDir/OutFileDir</code> 都是相对于该配置文件的路径。</p></li><li><p>注册服务之前，<code>WorkingDir/OutFileDir</code> 所指定的目录必须先创建好。</p></li></ul><p>至此，如何利用 <code>EasyService</code> 快速注册一个服务的方法就介绍完了，你学会了吗？</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://github.com/pandolia/easy-service" target="_blank" rel="noopener">https://github.com/pandolia/easy-service</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-EasyService&quot;&gt;什么是 EasyService&lt;/h2&gt;
&lt;p&gt;如果你的 &lt;code&gt;Windows&lt;/code&gt; 程序需要在后台长期运行，而且你希望它在开机后用户登录之前就自动运行、且在用户注销之后也不停止，那么你需要将程序注册为一个系统服务。&lt;/p&gt;
&lt;p&gt;然而，在 &lt;code&gt;Windows&lt;/code&gt; 下编写一个可注册为系统服务的程序并不是一件简单的事情。首先，程序必须是二进制的可执行程序，这就排除了脚本语言和虚拟机语言；其次，程序必须按系统服务的格式编写，过程相当繁琐。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EasyService&lt;/code&gt; 是一个可以将常规程序注册为系统服务的工具，体积只有 16KB 。你可以按常规的方法编写程序，然后用 &lt;code&gt;EasyService&lt;/code&gt; 注册为一个系统服务，这样你的程序就可以在开机后用户登录之前自动运行、且在用户注销之后也不会停止。&lt;/p&gt;
&lt;p&gt;如果你需要在 &lt;code&gt;Windows&lt;/code&gt; 系统下部署网站、&lt;code&gt;API&lt;/code&gt; 或其他需要长期在后台运行的服务， &lt;code&gt;EasyService&lt;/code&gt; 将是一个很有用的工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/pandolia/easy-service/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/pandolia/easy-service/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Windows" scheme="https://www.hi-linux.com/categories/Windows/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="EasyService" scheme="https://www.hi-linux.com/tags/EasyService/"/>
    
      <category term="Windows" scheme="https://www.hi-linux.com/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>分享一些让你提升命令行效率的 Bash 快捷键( 强烈建议收藏！)</title>
    <link href="https://www.hi-linux.com/posts/33391.html"/>
    <id>https://www.hi-linux.com/posts/33391.html</id>
    <published>2020-05-23T01:10:00.000Z</published>
    <updated>2020-05-23T03:59:53.200Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>做为一个 <code>Linux</code> 用户，一定经常和命令行打交道。而绝大多数 <code>Linux</code> 发行版默认的 <code>Shell</code> 都是 <code>Bash</code>，本文将给大家介绍一些 <code>Bash</code> 中非常实用的快捷键操作方法。你只要掌握了这些快捷键后，将极大的提高你的命令行操作效率，让你在使用 <code>SHELL</code> 的时候效率可以快得飞起来。</p><h2 id="编辑命令">编辑命令</h2><ul><li><p><code>Ctrl + a</code>：移到命令行首</p></li><li><p><code>Ctrl + e</code> ：移到命令行尾</p></li><li><p><code>Ctrl + f</code> ：按字符前移（右向）</p></li><li><p><code>Ctrl + b</code> ：按字符后移（左向）</p></li><li><p><code>Alt + f</code> ：按单词前移（右向）</p></li><li><p><code>Alt + b</code> ：按单词后移（左向）</p></li><li><p><code>Ctrl + xx</code>：在命令行首和光标之间移动</p></li><li><p><code>Ctrl + u</code> ：从光标处删除至命令行首</p></li><li><p><code>Ctrl + k</code> ：从光标处删除至命令行尾</p></li><li><p><code>Ctrl + w</code> ：从光标处删除至字首</p></li><li><p><code>Alt + d</code> ：从光标处删除至字尾</p></li><li><p><code>Ctrl + d</code> ：删除光标处的字符</p></li><li><p><code>Ctrl + h</code> ：删除光标前的字符</p></li><li><p><code>Ctrl + y</code> ：粘贴至光标后</p></li><li><p><code>Alt + c</code> ：从光标处更改为首字母大写的单词</p></li><li><p><code>Alt + u</code> ：从光标处更改为全部大写的单词</p></li><li><p><code>Alt + l</code> ：从光标处更改为全部小写的单词</p></li><li><p><code>Ctrl + t</code> ：交换光标处和之前的字符</p></li><li><p><code>Alt + t</code> ：交换光标处和之前的单词</p></li><li><p><code>Alt + Backspace</code>：与 <code>Ctrl + w</code> 相同，分隔符有些差别。</p></li></ul><a id="more"></a><h2 id="重新执行命令">重新执行命令</h2><ul><li><p><code>Ctrl + r</code>：逆向搜索命令历史</p></li><li><p><code>Ctrl + g</code>：从历史搜索模式退出</p></li><li><p><code>Ctrl + p</code>：历史中的上一条命令</p></li><li><p><code>Ctrl + n</code>：历史中的下一条命令</p></li><li><p><code>Alt + .</code>：使用上一条命令的最后一个参数</p></li></ul><h2 id="控制命令">控制命令</h2><ul><li><p><code>Ctrl + l</code>：清屏</p></li><li><p><code>Ctrl + o</code>：执行当前命令，并选择上一条命令</p></li><li><p><code>Ctrl + s</code>：阻止屏幕输出</p></li><li><p><code>Ctrl + q</code>：允许屏幕输出</p></li><li><p><code>Ctrl + c</code>：终止命令</p></li><li><p><code>Ctrl + z</code>：挂起命令</p></li></ul><h2 id="bang-命令">Bang (!) 命令</h2><ul><li><p><code>!!</code>：执行上一条命令</p></li><li><p><code>!blah</code>：执行最近的以 <code>blah</code> 开头的命令，如 <code>!ls</code></p></li><li><p><code>!blah:p</code>：仅打印输出，而不执行</p></li><li><p><code>!$</code>：上一条命令的最后一个参数，与 <code>Alt + .</code> 相同</p></li><li><p><code>!$:p</code>：打印输出 <code>!$</code> 的内容</p></li><li><p><code>!*</code>：上一条命令的所有参数</p></li><li><p><code>!*:p</code>：打印输出 <code>!*</code> 的内容</p></li><li><p><code>^blah</code>：删除上一条命令中的 <code>blah</code></p></li><li><p><code>^blah^foo</code>：将上一条命令中的 <code>blah</code> 替换为 <code>foo</code></p></li><li><p><code>^blah^foo^</code>：将上一条命令中所有的 <code>blah</code> 都替换为 <code>foo</code></p></li></ul><p><strong>友情提示：</strong></p><ol><li><p>以上介绍的大多数 <code>Bash</code> 快捷键仅当在 <code>Emacs</code> 编辑模式时有效。若你将 <code>Bash</code> 配置为 <code>VI</code> 编辑模式，那将遵循 <code>VI</code>  的按键绑定。<code>Bash</code> 默认为 <code>Emacs</code> 编辑模式，如果你的 <code>Bash</code> 不在 <code>Emacs</code> 编辑模式，可通过 <code>set -o emacs</code> 进行设置。</p></li><li><p><code>^S</code>、<code>^Q</code>、<code>^C</code>、<code>^Z</code> 是由终端设备处理的，可用 <code>stty</code> 命令设置。</p></li></ol><blockquote><p>来源：LinuxTOY</p><p>原文：<a href="https://url.cn/5Sj2PRE" target="_blank" rel="noopener">https://url.cn/5Sj2PRE</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;做为一个 &lt;code&gt;Linux&lt;/code&gt; 用户，一定经常和命令行打交道。而绝大多数 &lt;code&gt;Linux&lt;/code&gt; 发行版默认的 &lt;code&gt;Shell&lt;/code&gt; 都是 &lt;code&gt;Bash&lt;/code&gt;，本文将给大家介绍一些 &lt;code&gt;Bash&lt;/code&gt; 中非常实用的快捷键操作方法。你只要掌握了这些快捷键后，将极大的提高你的命令行操作效率，让你在使用 &lt;code&gt;SHELL&lt;/code&gt; 的时候效率可以快得飞起来。&lt;/p&gt;
&lt;h2 id=&quot;编辑命令&quot;&gt;编辑命令&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + a&lt;/code&gt;：移到命令行首&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + e&lt;/code&gt; ：移到命令行尾&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + f&lt;/code&gt; ：按字符前移（右向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + b&lt;/code&gt; ：按字符后移（左向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + f&lt;/code&gt; ：按单词前移（右向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + b&lt;/code&gt; ：按单词后移（左向）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + xx&lt;/code&gt;：在命令行首和光标之间移动&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + u&lt;/code&gt; ：从光标处删除至命令行首&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + k&lt;/code&gt; ：从光标处删除至命令行尾&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + w&lt;/code&gt; ：从光标处删除至字首&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + d&lt;/code&gt; ：从光标处删除至字尾&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + d&lt;/code&gt; ：删除光标处的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + h&lt;/code&gt; ：删除光标前的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + y&lt;/code&gt; ：粘贴至光标后&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + c&lt;/code&gt; ：从光标处更改为首字母大写的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + u&lt;/code&gt; ：从光标处更改为全部大写的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + l&lt;/code&gt; ：从光标处更改为全部小写的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Ctrl + t&lt;/code&gt; ：交换光标处和之前的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + t&lt;/code&gt; ：交换光标处和之前的单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Alt + Backspace&lt;/code&gt;：与 &lt;code&gt;Ctrl + w&lt;/code&gt; 相同，分隔符有些差别。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>推荐一个强大的环境变量管理工具 direnv</title>
    <link href="https://www.hi-linux.com/posts/8174.html"/>
    <id>https://www.hi-linux.com/posts/8174.html</id>
    <published>2020-05-23T01:00:00.000Z</published>
    <updated>2020-05-23T03:54:11.650Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>direnv</code> 是一个强大的环境变量管理工具，可以帮助我们简化环境变量管理。它可以根据当前目录自动加载或卸载环境变量，允许不同项目使用特定的环境变量。</p><p>项目地址：<a href="https://github.com/direnv/direnv/releases" target="_blank" rel="noopener">https://github.com/direnv/direnv/releases</a></p><h2 id="direnv-安装">direnv 安装</h2><p><code>direnv</code> 是基于 Go 语言开发，原生支持多平台，安装起来也是很简单的。</p><ol><li>通过二进制版本安装</li></ol><p>这里以 <code>Linux</code> 平台为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget -c https:&#x2F;&#x2F;github.com&#x2F;direnv&#x2F;direnv&#x2F;releases&#x2F;download&#x2F;v2.20.0&#x2F;direnv.linux-amd64</span><br><span class="line">$ mv direnv.linux-amd64 direnv</span><br><span class="line">$ sudo mv direnv &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p>如果你使用的是其它平台，可在官方项目地址的 Releases 页面自行下载对应操作系统的文件。</p><a id="more"></a><ol start="2"><li>配置以及集成 Shell</li></ol><p>针对不同的 Shell 使用不同的 Hook 方式进行关联，这里我们说说最常用的两种 Bash 和 ZSH。</p><ul><li>Bash</li></ul><p>如果你使用的是 Bash，直接运行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;$(direnv hook bash)&quot;</span><br></pre></td></tr></table></figure><p>如果你想长期使用 <code>direnv</code>，可以将以上命令加入到 <code>~/.bashrc</code> 文件中。</p><ul><li>ZSH</li></ul><p>如果你使用的是 ZSH，直接运行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;$(direnv hook zsh)&quot;</span><br></pre></td></tr></table></figure><p>同样，如果你需要长期使用 <code>direnv</code>，可以将以上命令加入到 <code>~/.zshrc</code> 文件中。</p><p>到这里，安装就算完成了，下面我们看看怎么使用吧。</p><h2 id="direnv-使用">direnv 使用</h2><p>这里我们创建两个目录，分别叫 myenv1 和 myenv2，然后我们测试分别进入不同目录时自动切换环境变量。</p><ol><li>在 myenv1 目录下创建一个 <code>.envrc</code> 文件，并设置了一个环境变量并打印欢迎消息，内容如下：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim .envrc</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">export myenv&#x3D;myenv1</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m#               Welcome to $myenv                #\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br></pre></td></tr></table></figure><ol start="2"><li>同样也在 myenv2 目录下创建一个 <code>.envrc</code> 文件，并设置了一个环境变量并打印欢迎消息，内容如下：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim .envrc</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">export myenv&#x3D;myenv2</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m#               Welcome to $myenv                #\e[0m&quot;</span><br><span class="line">echo -e &quot;\e[1;34m##################################################\e[0m&quot;</span><br></pre></td></tr></table></figure><p>这里需要注意一下，在编辑文件保存退出时会提示下面的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">direnv: error .envrc is blocked. Run &#96;direnv allow&#96; to approve its content.</span><br></pre></td></tr></table></figure><p>此时，我们需要使用下面命令使修改生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ direnv allow</span><br></pre></td></tr></table></figure><ol start="3"><li>下面看看分别进入 myenv1 和 myenv2 目录时环境变量的变化。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 进行 myenv1 目录</span><br><span class="line">$ cd myenv1</span><br><span class="line">direnv: loading .envrc</span><br><span class="line">##################################################</span><br><span class="line">#               Welcome to myenv1                #</span><br><span class="line">##################################################</span><br><span class="line">direnv: export +myenv</span><br><span class="line"></span><br><span class="line">$ env | grep myenv</span><br><span class="line">DIRENV_DIR&#x3D;-&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv1</span><br><span class="line">PWD&#x3D;&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv1</span><br><span class="line">myenv&#x3D;myenv1</span><br><span class="line"></span><br><span class="line"># 进行 myenv2 目录</span><br><span class="line">$ cd myenv2</span><br><span class="line">direnv: loading .envrc</span><br><span class="line">##################################################</span><br><span class="line">#               Welcome to myenv2                #</span><br><span class="line">##################################################</span><br><span class="line">direnv: export +myenv</span><br><span class="line"></span><br><span class="line">$ env | grep myenv</span><br><span class="line">DIRENV_DIR&#x3D;-&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv2</span><br><span class="line">PWD&#x3D;&#x2F;home&#x2F;mike&#x2F;test&#x2F;myenv2</span><br><span class="line">myenv&#x3D;myenv2</span><br></pre></td></tr></table></figure><p>至此，<code>direnv</code> 的基本功能就演示完了。但 <code>direnv</code> 的功能远不止这些，更多的高级功能如果你有兴趣可以自行发掘。</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.cnblogs.com/rongfengliang/p/10730008.html" target="_blank" rel="noopener">https://www.cnblogs.com/rongfengliang/p/10730008.html</a></li><li><a href="https://www.jianshu.com/p/efbc215f65ef" target="_blank" rel="noopener">https://www.jianshu.com/p/efbc215f65ef</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;direnv&lt;/code&gt; 是一个强大的环境变量管理工具，可以帮助我们简化环境变量管理。它可以根据当前目录自动加载或卸载环境变量，允许不同项目使用特定的环境变量。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/direnv/direnv/releases&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/direnv/direnv/releases&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;direnv-安装&quot;&gt;direnv 安装&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;direnv&lt;/code&gt; 是基于 Go 语言开发，原生支持多平台，安装起来也是很简单的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过二进制版本安装&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里以 &lt;code&gt;Linux&lt;/code&gt; 平台为例：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ wget -c https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;direnv&amp;#x2F;direnv&amp;#x2F;releases&amp;#x2F;download&amp;#x2F;v2.20.0&amp;#x2F;direnv.linux-amd64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ mv direnv.linux-amd64 direnv&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ sudo mv direnv &amp;#x2F;usr&amp;#x2F;local&amp;#x2F;bin&amp;#x2F;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如果你使用的是其它平台，可在官方项目地址的 Releases 页面自行下载对应操作系统的文件。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>全功能开源的企业级安全主动攻击型蜜罐钓鱼系统 HFish，你很有必要部署一套！</title>
    <link href="https://www.hi-linux.com/posts/9153.html"/>
    <id>https://www.hi-linux.com/posts/9153.html</id>
    <published>2020-05-22T01:30:00.000Z</published>
    <updated>2020-05-22T07:08:17.409Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>前段时间我们在「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247489680&amp;idx=1&amp;sn=3ac65051d44f2772a3ffc0a45ed68d46&amp;chksm=eac539b9ddb2b0afafdaa26e02e7553da883086c9682861b2fe9ecb551adfbf7cb2a9e29b96b&amp;token=1365898234&amp;lang=zh_CN#rd" target="_blank" rel="noopener">巧用 Cowrie 部署 SSH 蜜罐，让黑客攻击无处遁形！</a>」 一文中给大家介绍了一款好用开源的 <code>SSH</code> 蜜罐系统，但遗憾的是这个蜜罐系统只支持 <code>SSH</code> 这一种协议。</p><p>今天，我们就给大家介绍一套功能更加强大、支持跨平台和多种协议的全功能蜜罐钓鱼开源系统 <code>HFish</code>。</p><h2 id="什么是-hfish">什么是 HFish ？</h2><p><code>HFish</code> 是一款基于 <code>Golang + SqlLite</code> 开发的跨平台多功能主动攻击型蜜罐钓鱼平台框架系统。</p><blockquote><p>项目地址：<a href="https://github.com/hacklcx/HFish" target="_blank" rel="noopener">https://github.com/hacklcx/HFish</a></p></blockquote><p><strong>HFish 支持的特性</strong></p><p><img src="https://i.loli.net/2019/12/20/fUC8QWAjn9sc1bB.png" alt=""></p><ul><li><p>多功能：不仅仅支持 <code>HTTP(S)</code> 钓鱼，还支持 <code>SSH</code>、<code>SFTP</code>、<code>Redis</code>、<code>MySQL</code>、<code>MemCache</code>、<code>VNC</code>、<code>ES</code> 等多种蜜罐。</p></li><li><p>扩展性：<code>HFish</code> 提供 <code>API</code> 接口，使用者可以随意扩展钓鱼模块。</p></li><li><p>便捷性：<code>HFish</code> 使用 <code>Golang</code> 开发，使用者可以在多平台上(<code>Windows</code>、<code>MacOS</code>、<code>Linux</code> 等) 上快速进行部署。</p></li></ul><a id="more"></a><p><strong>什么是蜜罐？</strong></p><p>蜜罐技术本质上是一种对攻击方进行 欺骗的技术，通过布置一些作为诱饵的主机、网络服务或者信息，诱使攻击方对它们实施攻击，从而可以对攻击行为进行捕获和分析，了解攻击方所使用的工具与方法，推测攻击意图和动机，能够让防御方清晰地了解他们所面对的安全威胁，并通过技术和管理手段来增强实际系统的安全防护能力。</p><p>蜜罐好比是情报收集系统。蜜罐好像是故意让人攻击的目标，引诱黑客前来攻击。所以攻击者入侵后，你就可以知道他是如何得逞的，随时了解针对服务器发动的最新的攻击和漏洞。还可以通过窃听黑客之间的联系，收集黑客所用的种种工具，并且掌握他们的社交网络。</p><h2 id="部署-hfish">部署 HFish</h2><p><code>HFish</code> 支持单机、集群、<code>Docker</code> 多种形式的部署，部署方法也是非常简单的。</p><h3 id="二进制部署模式">二进制部署模式</h3><ol><li>下载当前系统二进制安装包</li></ol><p>首先通过浏览器打开 <code>https://github.com/hacklcx/HFish/releases</code>，然后下载对应系统的二进制安装包。</p><p><img src="https://i.loli.net/2019/12/20/rqGYfR7nvCKX6pN.png" alt=""></p><ul><li><p><code>darwin</code> 为 <code>MacOS</code> 版本</p></li><li><p><code>arm64</code> 为 <code>ARM</code> 架构的 64 位，可用于树莓派</p></li><li><p><code>386</code> 为 <code>32</code> 位系统， <code>amd64</code> 为 <code>64</code> 位系统</p></li></ul><ol start="2"><li>快速启动 HFish</li></ol><p>二进制安装包下载完成，解压后执行即可。</p><p>2.1 Linux + Mac 平台</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 名字是下载的压缩包，根据实际情况修改</span></span><br><span class="line">$ tar -zxvf HFish-0.5-linux-amd64.tar.gz</span><br><span class="line"><span class="comment"># 名字是解压后压缩包，根据实际情况修改         </span></span><br><span class="line">$ <span class="built_in">cd</span> HFish-0.5-linux-amd64                       </span><br><span class="line">$ chmod 777 -R db                                                        <span class="comment"># sqlite 临时文件需要最高权限</span></span><br><span class="line">$ ./HFish run</span><br></pre></td></tr></table></figure><blockquote><p>注意： db 目录必须要设置 777 最高权限，否则会报 unable to open database file。</p></blockquote><p>2.2 Windown 平台</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 鼠标右键解压压缩包,打开命令终端 (cmd.exe) 进入程序跟目录</span></span><br><span class="line"><span class="comment"># 名字是解压后压缩包，根据实际情况修改</span></span><br><span class="line">$ <span class="built_in">cd</span> c:/HFish-0.5-win-amd64</span><br><span class="line"><span class="comment"># Windows 一样要给 db 目录所有权限，具体方法谷歌搜索。</span></span><br><span class="line">$ ./HFish.exe run</span><br></pre></td></tr></table></figure><ol start="3"><li>访问 HFish</li></ol><p>启动成功后，直接通过浏览器访问 <code>IP：9001</code> 端口即可进行访问。</p><p>默认登陆账号/密码为：admin/admin</p><p><img src="https://hfish.io/docs/images/2.png" alt=""></p><h3 id="docker-部署模式">Docker 部署模式</h3><p>如果你对 <code>Docker</code> 比较了解还可以直接通过 <code>Docker</code> 来一键完成单节点部署或集群部署。</p><ol><li>单节点部署</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name hfish -p 21:21 -p 22:22 -p 23:23 -p 3306:3306 -p 6379:6379 -p 8080:8080 -p 8989:8989 -p 9000:9000 -p 9001:9001 -p 11211:11211 imdevops/hfish:latest</span><br></pre></td></tr></table></figure><ol start="2"><li>集群部署</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主节点部署</span></span><br><span class="line">$ docker run -d --name hfish-master -p 21:21 -p 22:22 -p 23:23 -p 3306:3306 -p 6379:6379 -p 7879:7879 -p 8080:8080 -p 8989:8989 -p 9000:9000 -p 9001:9001 -p 11211:11211 imdevops/hfish:latest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 客户端子节点部署</span></span><br><span class="line">$ docker run -d --name hfish-client -p 21:21 -p 22:22 -p 23:23 -p 3306:3306 -p 6379:6379 -p 8080:8080 -p 8989:8989 -p 9000:9000 -p 11211:11211 -e CLUSTER_IP=master_ip:7879 -e NODE_NAME=clinet imdevops/hfish:latest</span><br></pre></td></tr></table></figure><p>具体方法可以参考官方文档：<a href="https://hfish.io/docs/#/deploy/docker" target="_blank" rel="noopener">https://hfish.io/docs/#/deploy/docker</a></p><h2 id="配置-hfish">配置 HFish</h2><p><code>HFish</code> 的配置分为服务器端和客户端，大致配置内容基本相同。官方也说得很清楚了，只要按需启用相应服务即可，这里就不再赘述了。</p><h3 id="服务端配置">服务端配置</h3><p>本配置为 <code>Demo</code> 服务端，需要启动 <code>rpc</code> , 修改状态 <code>status</code> 为 <code>1</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">[rpc]</span><br><span class="line">status &#x3D; 1                                   # 模式 0关闭 1服务端 2客户端</span><br><span class="line">addr &#x3D; 127.0.0.1:7879                        # RPC 服务端地址 or 客户端地址</span><br><span class="line">name &#x3D; Server                                # 状态1 服务端名称 状态2 客户端名称</span><br><span class="line"></span><br><span class="line">[admin]                                      # RPC 状态为 2 集群客户端的时候 admin 可以删掉</span><br><span class="line">addr &#x3D; 127.0.0.1:9001                        # 管理后台启动地址</span><br><span class="line">account &#x3D; admin                              # 登录账号</span><br><span class="line">password &#x3D; admin                             # 登录密码</span><br><span class="line"></span><br><span class="line">[api]</span><br><span class="line">status &#x3D; 1                                   # 是否启动 API 1 启动 0 关闭</span><br><span class="line">web_url &#x3D; &#x2F;api&#x2F;v1&#x2F;post&#x2F;report                # 管理后台启动地址</span><br><span class="line">deep_url &#x3D; &#x2F;api&#x2F;v1&#x2F;post&#x2F;deep_report          # 管理后台启动地址</span><br><span class="line">plug_url &#x3D; &#x2F;api&#x2F;v1&#x2F;post&#x2F;plug_report          # 插件蜜罐上报 API</span><br><span class="line">sec_key &#x3D; 9cbf8a4dcb8e30682b927f352d6559a0   # API 认证秘钥</span><br><span class="line"></span><br><span class="line">[plug]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 蜜罐插件 0 关闭 1 启动, 需要先启动 API</span><br><span class="line">addr &#x3D; 0.0.0.0:8989                          # 蜜罐插件 启动地址</span><br><span class="line"></span><br><span class="line">[web]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 WEB 1 启动 0 关闭, 启动 API 后 WEB 方可上报结果</span><br><span class="line">addr &#x3D; 0.0.0.0:9000                          # WEB 启动地址，0.0.0.0 对外开放，127.0.0.1 对内开放 可走 Nginx 反向代理</span><br><span class="line">template &#x3D; wordPress&#x2F;html                    # WEB 模板路径</span><br><span class="line">index &#x3D; index.html                           # WEB 首页文件</span><br><span class="line">static &#x3D; wordPress&#x2F;static                    # WEB 静态文件路径  注意：必须存在两个目录，html 文件 和静态文件 不能平级</span><br><span class="line">url &#x3D; &#x2F;                                      # WEB 访问目录，默认 &#x2F; 可更改成 index.html index.asp index.php</span><br><span class="line"></span><br><span class="line">[deep]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 暗网 1 启动 0 关闭, 启动 API 后 方可上报结果</span><br><span class="line">addr &#x3D; 0.0.0.0:8080                          # 暗网 WEB 启动地址</span><br><span class="line">template &#x3D; deep&#x2F;html                         # 暗网 WEB 模板路径</span><br><span class="line">index &#x3D; index.html                           # 暗网 WEB 首页文件</span><br><span class="line">static &#x3D; deep&#x2F;static                         # 暗网 WEB 静态文件路径  注意：必须存在两个目录，html 文件 和静态文件 不能平级</span><br><span class="line">url &#x3D; &#x2F;                                      # 暗网 WEB 访问目录，默认 &#x2F; 可更改成 index.html index.asp index.php</span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 SSH 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:22                            # SSH 服务端地址 注意端口冲突，请先关闭服务器 openssh 服务 或 修改端口</span><br><span class="line"></span><br><span class="line">[redis]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Redis 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:6379                          # Redis 服务端地址 注意端口冲突</span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Mysql 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:3306                          # Mysql 服务端地址 注意端口冲突</span><br><span class="line">files &#x3D; &#x2F;etc&#x2F;passwd,&#x2F;etc&#x2F;group               # Mysql 服务端读取客户端任意文件; 多写逗号分隔，会随机取</span><br><span class="line"></span><br><span class="line">[telnet]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Telnet 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:23                            # Telnet 服务端地址 注意端口冲突</span><br><span class="line"></span><br><span class="line">[ftp]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Ftp 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:21                            # Ftp 服务端地址 注意端口冲突</span><br><span class="line"></span><br><span class="line">[mem_cache]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 MemCache 0 关闭 1 启动</span><br><span class="line">addr &#x3D; 0.0.0.0:11211                         # Memcache 服务端地址 注意端口冲突</span><br><span class="line">rate_limit &#x3D; 4                               # 每秒响应次数</span><br></pre></td></tr></table></figure><h3 id="客户端配置">客户端配置</h3><p>本配置为 <code>Demo</code> 客户端，可删除 <code>admin</code> 配置项。客户端需要启动 <code>rpc</code> , 修改状态 <code>status</code> 为 <code>2</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">[rpc]</span><br><span class="line">status &#x3D; 2                                   # 模式 0关闭 1服务端 2客户端</span><br><span class="line">addr &#x3D; 127.0.0.1:7879                        # RPC 服务端地址 or 客户端地址</span><br><span class="line">name &#x3D; Beijing_Clinet                        # 状态1 服务端名称 状态2 客户端名称</span><br><span class="line"></span><br><span class="line">[api]</span><br><span class="line">status &#x3D; 1                                   # 是否启动 API 1 启动 0 关闭</span><br><span class="line">web_url &#x3D; &#x2F;api&#x2F;v1&#x2F;post&#x2F;report                # 管理后台启动地址</span><br><span class="line">deep_url &#x3D; &#x2F;api&#x2F;v1&#x2F;post&#x2F;deep_report          # 管理后台启动地址</span><br><span class="line">plug_url &#x3D; &#x2F;api&#x2F;v1&#x2F;post&#x2F;plug_report          # 插件蜜罐上报 API</span><br><span class="line">sec_key &#x3D; 9cbf8a4dcb8e30682b927f352d6559a0   # API 认证秘钥</span><br><span class="line"></span><br><span class="line">[plug]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 蜜罐插件 0 关闭 1 启动, 需要先启动 API</span><br><span class="line">addr &#x3D; 0.0.0.0:8989                          # 蜜罐插件 启动地址</span><br><span class="line"></span><br><span class="line">[web]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 WEB 1 启动 0 关闭, 启动 API 后 WEB 方可上报结果</span><br><span class="line">addr &#x3D; 0.0.0.0:9000                          # WEB 启动地址，0.0.0.0 对外开放，127.0.0.1 对内开放 可走 Nginx 反向代理</span><br><span class="line">template &#x3D; wordPress&#x2F;html                    # WEB 模板路径</span><br><span class="line">index &#x3D; index.html                           # WEB 首页文件</span><br><span class="line">static &#x3D; wordPress&#x2F;static                    # WEB 静态文件路径  注意：必须存在两个目录，html 文件 和静态文件 不能平级</span><br><span class="line">url &#x3D; &#x2F;                                      # WEB 访问目录，默认 &#x2F; 可更改成 index.html index.asp index.php</span><br><span class="line"></span><br><span class="line">[deep]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 暗网 1 启动 0 关闭, 启动 API 后 方可上报结果</span><br><span class="line">addr &#x3D; 0.0.0.0:8080                          # 暗网 WEB 启动地址</span><br><span class="line">template &#x3D; deep&#x2F;html                         # 暗网 WEB 模板路径</span><br><span class="line">index &#x3D; index.html                           # 暗网 WEB 首页文件</span><br><span class="line">static &#x3D; deep&#x2F;static                         # 暗网 WEB 静态文件路径  注意：必须存在两个目录，html 文件 和静态文件 不能平级</span><br><span class="line">url &#x3D; &#x2F;                                      # 暗网 WEB 访问目录，默认 &#x2F; 可更改成 index.html index.asp index.php</span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 SSH 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:22                            # SSH 服务端地址 注意端口冲突，请先关闭服务器 openssh 服务 或 修改端口</span><br><span class="line"></span><br><span class="line">[redis]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Redis 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:6379                          # Redis 服务端地址 注意端口冲突</span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Mysql 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:3306                          # Mysql 服务端地址 注意端口冲突</span><br><span class="line">files &#x3D; &#x2F;etc&#x2F;passwd,&#x2F;etc&#x2F;group               # Mysql 服务端读取客户端任意文件; 多写逗号分隔，会随机取</span><br><span class="line"></span><br><span class="line">[telnet]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Telnet 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:23                            # Telnet 服务端地址 注意端口冲突</span><br><span class="line"></span><br><span class="line">[ftp]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 Ftp 1 启动 0 关闭</span><br><span class="line">addr &#x3D; 0.0.0.0:21                            # Ftp 服务端地址 注意端口冲突</span><br><span class="line"></span><br><span class="line">[mem_cache]</span><br><span class="line">status &#x3D; 0                                   # 是否启动 MemCache 0 关闭 1 启动</span><br><span class="line">addr &#x3D; 0.0.0.0:11211                         # Memcache 服务端地址 注意端口冲突</span><br><span class="line">rate_limit &#x3D; 4                               # 每秒响应次数</span><br></pre></td></tr></table></figure><p>除了这些，<code>Hfish</code> 还支持通过 <code>API 请求</code>、<code>白名单</code>、<code>WebHook</code>、<code>插件扩展</code>等很多强大的功能。如果你很感兴趣，可自行前往官网进一步探索哟！</p><h2 id="更多功能演示截图">更多功能演示截图</h2><ol><li>HFish 管理界面</li></ol><p><img src="https://bithack.io/images/cache/201908051053X8EpubVFzS.png" alt=""></p><ol start="2"><li>HFish 数据统计界面</li></ol><p><img src="https://bithack.io/images/cache/201908051051VPAyJszh4H.png" alt=""></p><ol start="3"><li>HFish SSH 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/5.png" alt=""></p><ol start="4"><li>HFish Telnet 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/8.png" alt=""></p><ol start="5"><li>HFish Redis 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/6.png" alt=""></p><ol start="6"><li>HFish Memcache 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/11.png" alt=""></p><ol start="7"><li>HFish MySQL 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/7.png" alt=""></p><ol start="8"><li>HFish FTP 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/9.png" alt=""></p><ol start="9"><li>HFish Web 蜜罐后台界面</li></ol><p><img src="https://hfish.io/docs/images/10.png" alt=""></p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://hfish.io/docs/" target="_blank" rel="noopener">https://hfish.io/docs/</a></p></li><li><p><a href="https://bithack.io/forum/484" target="_blank" rel="noopener">https://bithack.io/forum/484</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间我们在「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247489680&amp;amp;idx=1&amp;amp;sn=3ac65051d44f2772a3ffc0a45ed68d46&amp;amp;chksm=eac539b9ddb2b0afafdaa26e02e7553da883086c9682861b2fe9ecb551adfbf7cb2a9e29b96b&amp;amp;token=1365898234&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;巧用 Cowrie 部署 SSH 蜜罐，让黑客攻击无处遁形！&lt;/a&gt;」 一文中给大家介绍了一款好用开源的 &lt;code&gt;SSH&lt;/code&gt; 蜜罐系统，但遗憾的是这个蜜罐系统只支持 &lt;code&gt;SSH&lt;/code&gt; 这一种协议。&lt;/p&gt;
&lt;p&gt;今天，我们就给大家介绍一套功能更加强大、支持跨平台和多种协议的全功能蜜罐钓鱼开源系统 &lt;code&gt;HFish&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&quot;什么是-HFish-？&quot;&gt;什么是 HFish ？&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;HFish&lt;/code&gt; 是一款基于 &lt;code&gt;Golang + SqlLite&lt;/code&gt; 开发的跨平台多功能主动攻击型蜜罐钓鱼平台框架系统。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/hacklcx/HFish&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/hacklcx/HFish&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;HFish 支持的特性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/12/20/fUC8QWAjn9sc1bB.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;多功能：不仅仅支持 &lt;code&gt;HTTP(S)&lt;/code&gt; 钓鱼，还支持 &lt;code&gt;SSH&lt;/code&gt;、&lt;code&gt;SFTP&lt;/code&gt;、&lt;code&gt;Redis&lt;/code&gt;、&lt;code&gt;MySQL&lt;/code&gt;、&lt;code&gt;MemCache&lt;/code&gt;、&lt;code&gt;VNC&lt;/code&gt;、&lt;code&gt;ES&lt;/code&gt; 等多种蜜罐。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;扩展性：&lt;code&gt;HFish&lt;/code&gt; 提供 &lt;code&gt;API&lt;/code&gt; 接口，使用者可以随意扩展钓鱼模块。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;便捷性：&lt;code&gt;HFish&lt;/code&gt; 使用 &lt;code&gt;Golang&lt;/code&gt; 开发，使用者可以在多平台上(&lt;code&gt;Windows&lt;/code&gt;、&lt;code&gt;MacOS&lt;/code&gt;、&lt;code&gt;Linux&lt;/code&gt; 等) 上快速进行部署。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="HFish" scheme="https://www.hi-linux.com/tags/HFish/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款让你的代码变得更漂亮的神器 Codeimg</title>
    <link href="https://www.hi-linux.com/posts/63761.html"/>
    <id>https://www.hi-linux.com/posts/63761.html</id>
    <published>2020-05-22T01:20:00.000Z</published>
    <updated>2020-05-22T05:47:50.057Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>如果你想把一小段代码分享到各大社交网站，透过 GitHub Gist 产生链接是个不错的方式。若是要转为精美的图片， Carbon、CodeZen 这类可以将代码转成图片、加上窗口阴影和上色效果的线上工具，或许来说会更好用。</p><p>大家都知道社交网站在不同区块或类别都有不一样的图片尺寸限制，接下来要介绍的这项服务就是整合了各大社交网站模版和代码的转图片工具，让你可以做出更适合分享的代码图片。</p><h2 id="什么是-codeimgio">什么是 <a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a></h2><p>「<a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a>」是一款帮你把源代码转换成漂亮图片格式的在线工具，以便于在社交网络分享。它可以对一段代码加入高亮颜色标注效果，按照使用者选择的社交网站位置制作为特定大小的图片。</p><p>举例来说：Facebook 分享图片大小为 1200×630、封面图片 820×312、Twitter 推文适用的 506×253，亦可选择边框样式、配色、主题等等，制作出来的图片相当专业。</p><p>虽然制作成图片的代码或许适合阅读，对于要复制特定内容来说就会有些麻烦。但如果只是想让社交网站上的人方便浏览，相较于直接把代码贴上来说转为图片、加入高亮效果会更有用。</p><p>Codeimg 不仅适用于社交网站，也能直接指定图片长宽，选择建立成 .jpeg、.png 或 .svg 图片格式。</p><blockquote><p>网站名称：<a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a><br>网站链接：<a href="https://codeimg.io/" target="_blank" rel="noopener">https://codeimg.io/</a></p></blockquote><p>「<a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a>」支持功能列表：</p><ul><li>宽度、高度</li><li>边框宽度</li><li>背景色</li><li>样式（Win/macOS）</li><li>显示按钮</li><li>显示标题</li><li>圆角边框</li><li>阴影大小、颜色</li><li>主题</li><li>程序语言</li><li>字体大小</li><li>显示行数</li></ul><a id="more"></a><h2 id="codeimgio使用教学">「<a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a>」使用教学</h2><h3 id="step-1">STEP 1</h3><p>开启 <a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a> 后选择要套用的社交网站模版尺寸，选项上会提示你这个尺寸适用于那个区块，以及对应的图片大小。</p><p><a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a> 提供包括 Facebook、Twitter、Instagram 三种最常用的社交平台。Facebook 包括 Profile、Cover、Shared、Event Image 样式，Twitter 包括 Profile、Header、In-Stream Photo，Instagram 包括 Profile、Thumbnails、Stories 等样式。或是透过自定义功能自己输入图片长宽。</p><p>在下方项目名称的命名后面可预先选择要使用的图片格式，<a href="http://Codeimg.io" target="_blank" rel="noopener">Codeimg.io</a> 亦可制作 .svg 矢量图。</p><p><img src="https://i.loli.net/2019/08/19/kXV2EzHRSdrQU1g.jpg" alt=""></p><h3 id="step-2">STEP 2</h3><p>接着把 Codeimg 预设程式码移除，在第一行将你要转为图片的代码贴上。</p><p><img src="https://i.loli.net/2019/08/19/POILXaiCHV3ZUF5.jpg" alt=""></p><p>Codeimg 会自动对代码进行高亮，让其他使用者更容易阅读。预设情况下是 MacOS 窗口效果带上深色的高亮效果。</p><p><img src="https://i.loli.net/2019/08/19/MekD6t5LsziZCoS.jpg" alt=""></p><h3 id="step-3">STEP 3</h3><p>左侧有几个选项，点开后会有更多可以设定的功能，例如窗口外框可调整为 macOS 或 Windows 样式，外框尺寸、对齐位置、圆角和阴影等等，设定后右边预览会即时更新。</p><p><img src="https://i.loli.net/2019/08/19/3pdWAhGgzXCskxF.jpg" alt=""></p><h3 id="step-4">STEP 4</h3><p>如果你对于预设的高亮效果不满意，可以从 Editor 的「Theme」可选择各种不同的代码高亮方式，包括浅色和深色背景，以及不同的高亮标注颜色。若 Codeimg 无法正确判断你的代码类型，可以从「Language」手动选择，并能决定是否要显示代码的行数。</p><p><img src="https://i.loli.net/2019/08/19/Wx9FQdAgn3likhp.jpg" alt=""></p><h3 id="step-5">STEP 5</h3><p>最后，点选右上角的「Download」就能将这张代码图片导出，保存为预先选择的图片格式。</p><p><img src="https://i.loli.net/2019/08/19/JFrdG3QRjzVnoAZ.jpg" alt=""></p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.appinn.com/codeimg-online/" target="_blank" rel="noopener">https://www.appinn.com/codeimg-online/</a></li><li><a href="https://free.com.tw/codeimg-io/" target="_blank" rel="noopener">https://free.com.tw/codeimg-io/</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果你想把一小段代码分享到各大社交网站，透过 GitHub Gist 产生链接是个不错的方式。若是要转为精美的图片， Carbon、CodeZen 这类可以将代码转成图片、加上窗口阴影和上色效果的线上工具，或许来说会更好用。&lt;/p&gt;
&lt;p&gt;大家都知道社交网站在不同区块或类别都有不一样的图片尺寸限制，接下来要介绍的这项服务就是整合了各大社交网站模版和代码的转图片工具，让你可以做出更适合分享的代码图片。&lt;/p&gt;
&lt;h2 id=&quot;什么是-Codeimg-io&quot;&gt;什么是 &lt;a href=&quot;http://Codeimg.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Codeimg.io&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;「&lt;a href=&quot;http://Codeimg.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Codeimg.io&lt;/a&gt;」是一款帮你把源代码转换成漂亮图片格式的在线工具，以便于在社交网络分享。它可以对一段代码加入高亮颜色标注效果，按照使用者选择的社交网站位置制作为特定大小的图片。&lt;/p&gt;
&lt;p&gt;举例来说：Facebook 分享图片大小为 1200×630、封面图片 820×312、Twitter 推文适用的 506×253，亦可选择边框样式、配色、主题等等，制作出来的图片相当专业。&lt;/p&gt;
&lt;p&gt;虽然制作成图片的代码或许适合阅读，对于要复制特定内容来说就会有些麻烦。但如果只是想让社交网站上的人方便浏览，相较于直接把代码贴上来说转为图片、加入高亮效果会更有用。&lt;/p&gt;
&lt;p&gt;Codeimg 不仅适用于社交网站，也能直接指定图片长宽，选择建立成 .jpeg、.png 或 .svg 图片格式。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;网站名称：&lt;a href=&quot;http://Codeimg.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Codeimg.io&lt;/a&gt;&lt;br&gt;
网站链接：&lt;a href=&quot;https://codeimg.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://codeimg.io/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;「&lt;a href=&quot;http://Codeimg.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Codeimg.io&lt;/a&gt;」支持功能列表：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;宽度、高度&lt;/li&gt;
&lt;li&gt;边框宽度&lt;/li&gt;
&lt;li&gt;背景色&lt;/li&gt;
&lt;li&gt;样式（Win/macOS）&lt;/li&gt;
&lt;li&gt;显示按钮&lt;/li&gt;
&lt;li&gt;显示标题&lt;/li&gt;
&lt;li&gt;圆角边框&lt;/li&gt;
&lt;li&gt;阴影大小、颜色&lt;/li&gt;
&lt;li&gt;主题&lt;/li&gt;
&lt;li&gt;程序语言&lt;/li&gt;
&lt;li&gt;字体大小&lt;/li&gt;
&lt;li&gt;显示行数&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Codeimg" scheme="https://www.hi-linux.com/tags/Codeimg/"/>
    
  </entry>
  
  <entry>
    <title>如何在一秒之内优雅的处理 1000 万个网络数据包攻击</title>
    <link href="https://www.hi-linux.com/posts/6500.html"/>
    <id>https://www.hi-linux.com/posts/6500.html</id>
    <published>2020-05-22T01:10:00.000Z</published>
    <updated>2020-05-22T05:28:53.261Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>偶然看到一篇 Cloudflare 的博客 How to drop 10 million packets per second，如何实现单核情况下一秒钟丢弃 1000 万个数据包，原文循序渐进，从最简单的用户态丢弃到使用非常新的技术 XDP，逐步将单核丢包性能提升到 10 mpps，很有意思，网上也没有看到原文的中文版本，所以这里顺便翻译一下，看看 Cloudflare 是如何处理类似的情况的。</p><p>在公司内部，我们的抗 DDoS 团队有时会被人们称作 “数据包丢弃者”。当其他团队为流经我们网络的流量做了很多令人兴奋的聪明玩意时，我们也很享受探索如何丢弃这些流量的新方法。</p><p>能以最快速度丢掉网络包，对于抵抗 DDoS 攻击来说，是非常重要的。丢掉发送到我们服务器的数据包，和听上去一样简单，可以在很多层面上进行。每个技术都有他的优点和缺陷，在这篇 Blog 里，我们会一起看一下我们到目前为止用到的技术。</p><a id="more"></a><h2 id="试验台">试验台</h2><p>为了说明方法的相对性能，我们将通过一些基准测试，这些测试是设计好的，可以得到一系列的数据。我们使用了一台 Intel 的服务器，这台机器有一块 10Gbps 网卡，机器的其他配置信息其实并不是很重要，因为这些测试的目标是为了显示出操作系统而不是硬件层面的限制。</p><p>我们的测试设置如下：</p><ul><li><p>我们传输大量小的 UDP 数据包，达到 14Mpps（每秒数百万个数据包）。</p></li><li><p>此流量指向目标服务器上的单个 CPU。</p></li><li><p>我们测量内核在该 CPU 上处理的数据包数量。</p></li></ul><p>我们并没有尝试优化用户空间应用程序的速度，也没有尝试提升数据吞吐量 - 相反，我们尝试专门展示内核层的瓶颈。</p><p>生成的流量可以对 conntrack 施加最大压力 - 数据包使用随机源IP和端口字段。 tcpdump 的结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -ni vlan100 -c 10 -t udp and dst port 1234</span><br><span class="line">IP 198.18.40.55.32059 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.51.16.30852 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.35.51.61823 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.44.42.30344 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.106.227.38592 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.48.67.19533 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.49.38.40566 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.50.73.22989 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.43.204.37895 &gt; 198.18.0.12.1234: UDP, length 16</span><br><span class="line">IP 198.18.104.128.1543 &gt; 198.18.0.12.1234: UDP, length 16</span><br></pre></td></tr></table></figure><p>在目标机器，我们将所有的流量都定向到网卡同一个 RX 队列上，也就是说所有的数据都只会被一个 CPU 核处理。我们通过硬件流转向实现这一目标：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ethtool -N ext0 flow-type udp4 dst-ip 198.18.0.12 dst-port 1234 action 2</span><br></pre></td></tr></table></figure><p>基准测试通常也很困难，当我们在准备测试的过程中，我们发现如果系统中有活动的 raw socket 也会影响性能，事后看很明显，但是也很容易忽略类似的问题。所以在测试之前需要确认没有任何 tcpdump 进程在运行，可以通过下面的方式查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ss -A raw,packet_raw -l -p|cat</span><br><span class="line">Netid  State      Recv-Q Send-Q Local Address:Port</span><br><span class="line">p_raw  UNCONN     525157 0      *:vlan100          users:((&quot;tcpdump&quot;,pid&#x3D;23683,fd&#x3D;3))</span><br></pre></td></tr></table></figure><p>最后，我们要关闭 Intel Turbo Boost 特性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 | sudo tee &#x2F;sys&#x2F;devices&#x2F;system&#x2F;cpu&#x2F;intel_pstate&#x2F;no_turbo</span><br></pre></td></tr></table></figure><p>虽然 Turbo Boost 很好，而且可以提升至少 20% 的吞吐量，但是也会极大的影响测试结果的标准差，在开启状态下偏大达到了 ±1.5%，而关闭之后偏差下降到了 0.25%。</p><p><img src="https://www.hi-linux.com/img/linux/network-1000-1.jpg" alt=""></p><h2 id="第一阶段-在应用程序中丢弃包">第一阶段 在应用程序中丢弃包</h2><p>让我们从将数据包传递到应用程序并在用户空间代码中忽略它们的想法开始。 对于测试设置，首先需要确保 iptables 不会影响性能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iptables -I PREROUTING -t mangle -d 198.18.0.12 -p udp --dport 1234 -j ACCEPT</span><br><span class="line">iptables -I PREROUTING -t raw -d 198.18.0.12 -p udp --dport 1234 -j ACCEPT</span><br><span class="line">iptables -I INPUT -t filter -d 198.18.0.12 -p udp --dport 1234 -j ACCEPT</span><br></pre></td></tr></table></figure><p>应用程序的代码就是一个简单的循环，获取数据，然后直接丢弃：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s &#x3D; socket.socket(AF_INET, SOCK_DGRAM)</span><br><span class="line">s.bind((&quot;0.0.0.0&quot;, 1234))</span><br><span class="line">while True:</span><br><span class="line">    s.recvmmsg([...])</span><br></pre></td></tr></table></figure><p>这里有准备好的 C 代码，运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;dropping-packets&#x2F;recvmmsg-loop</span><br><span class="line">packets&#x3D;171261 bytes&#x3D;1940176</span><br></pre></td></tr></table></figure><p>对于这个实现，我们利用 ethtool 和 mmwatch 工具可以实现从硬件队列中以 175kpps 的速度读取数据包。</p><p>硬件上看接收的速度是 14Mpps，但是针对单核处理的 RX 队列，这些数据包已经无法处理了。可以通过 mpstat 工具确认：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ watch &#39;mpstat -u -I SUM -P ALL 1 1|egrep -v Aver&#39;</span><br><span class="line">01:32:05 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle</span><br><span class="line">01:32:06 PM    0    0.00    0.00    0.00    2.94    0.00    3.92    0.00    0.00    0.00   93.14</span><br><span class="line">01:32:06 PM    1    2.17    0.00   27.17    0.00    0.00    0.00    0.00    0.00    0.00   70.65</span><br><span class="line">01:32:06 PM    2    0.00    0.00    0.00    0.00    0.00  100.00    0.00    0.00    0.00    0.00</span><br><span class="line">01:32:06 PM    3    0.95    0.00    1.90    0.95    0.00    3.81    0.00    0.00    0.00   92.38</span><br></pre></td></tr></table></figure><p>可以看到用户代码不是瓶颈，在 CPU #1 上有 27% sys + 2% userspace 的占用，但是 CPU #2 被网络软中断( SOFTIRQ )占用了 100%。</p><p>需要说明的是，使用 recvmmsg(2) 很重要，在 Spectre 漏洞被发现的现在，系统调用的成本变得更加高了，我们使用了 4.14 版本的内核，并开启了 KPTI 和 Retpoline：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ tail -n +1 &#x2F;sys&#x2F;devices&#x2F;system&#x2F;cpu&#x2F;vulnerabilities&#x2F;*</span><br><span class="line">&#x3D;&#x3D;&gt; &#x2F;sys&#x2F;devices&#x2F;system&#x2F;cpu&#x2F;vulnerabilities&#x2F;meltdown &lt;&#x3D;&#x3D;</span><br><span class="line">Mitigation: PTI</span><br><span class="line">&#x3D;&#x3D;&gt; &#x2F;sys&#x2F;devices&#x2F;system&#x2F;cpu&#x2F;vulnerabilities&#x2F;spectre_v1 &lt;&#x3D;&#x3D;</span><br><span class="line">Mitigation: __user pointer sanitization</span><br><span class="line">&#x3D;&#x3D;&gt; &#x2F;sys&#x2F;devices&#x2F;system&#x2F;cpu&#x2F;vulnerabilities&#x2F;spectre_v2 &lt;&#x3D;&#x3D;</span><br><span class="line">Mitigation: Full generic retpoline, IBPB, IBRS_FW</span><br></pre></td></tr></table></figure><h2 id="第二阶段-干掉-conntrack">第二阶段 干掉 conntrack</h2><p>我们特别的设计了这个测试，用随机的原 IP 和端口，用来给 conntrack 层施加压力。这个可以通过查看 conntrack 数量的方式确认，在测试中，conntrack 数量达到最大：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ conntrack -C</span><br><span class="line">2095202</span><br><span class="line">$ sysctl net.netfilter.nf_conntrack_max</span><br><span class="line">net.netfilter.nf_conntrack_max &#x3D; 2097152</span><br></pre></td></tr></table></figure><p>也能从 dmesg 中看到 conntrack 日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[4029612.456673] nf_conntrack: nf_conntrack: table full, dropping packet</span><br><span class="line">[4029612.465787] nf_conntrack: nf_conntrack: table full, dropping packet</span><br><span class="line">[4029617.175957] net_ratelimit: 5731 callbacks suppressed</span><br></pre></td></tr></table></figure><p>为了加速我们的测试，把它关掉：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t raw -I PREROUTING -d 198.18.0.12 -p udp -m udp --dport 1234 -j NOTRACK</span><br></pre></td></tr></table></figure><p>然后重新测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;dropping-packets&#x2F;recvmmsg-loop</span><br><span class="line">packets&#x3D;331008 bytes&#x3D;5296128</span><br></pre></td></tr></table></figure><p>程序性能里面提升到了 333kpps，赞！</p><blockquote><p>PS：通过 <code>SO_BUSY_POLL</code> 选项，我们可以将性能提升到 470k pps，但是这个是另一个话题了。</p></blockquote><h2 id="第三阶段-利用-bpf-进行丢包操作">第三阶段 利用 BPF 进行丢包操作</h2><p>更进一步，为什么我们要在用户态进行丢包呢？虽然这个技术不常见，但是我们可以使用 setsockopt(SO_ATTACH_FILTER) 添加一个 cBPF 过滤器到一个 socket 上，让程序在内核态进行丢包操作。</p><p>这里是代码，运行一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bpf-drop</span><br><span class="line">packets&#x3D;0 bytes&#x3D;0</span><br></pre></td></tr></table></figure><p>使用 BPF 进行丢弃操作（ cBPF 和 eBPF 有相似的性能），我们大致达到了 512kpps 的性能。所有的包都在 BPF 过滤器中丢弃了，由于依然需要使用到软中断，所以只是省掉了唤醒用户态程序的 CPU 消耗。</p><h2 id="第四阶段-使用-iptables-在路由阶段结束后丢弃">第四阶段 使用 iptables 在路由阶段结束后丢弃</h2><p>在下个阶段，我们可以简单的设置 iptables INPUT 规则来丢弃包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -I INPUT -d 198.18.0.12 -p udp --dport 1234 -j DROP</span><br></pre></td></tr></table></figure><p>需要注意的是我们之前已经通过 <code>-j NOTRACK</code> 关闭了 conntrack，这两条规则实现了 608kbps 的性能。</p><p>看下 iptables 的统计信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mmwatch &#39;iptables -L -v -n -x | head&#39;</span><br><span class="line">Chain INPUT (policy DROP 0 packets, 0 bytes)</span><br><span class="line">    pkts      bytes target     prot opt in     out     source               destination</span><br><span class="line">605.9k&#x2F;s    26.7m&#x2F;s DROP       udp  --  *      *       0.0.0.0&#x2F;0            198.18.0.12          udp dpt:1234</span><br></pre></td></tr></table></figure><p>600kpps 不差了，但是我们能做到更好！</p><h2 id="第五阶段-使用-iptables-在路由之前丢弃">第五阶段 使用 iptables 在路由之前丢弃</h2><p>有一个更快的方法，就是在包路由之前丢弃，可以通过下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -I PREROUTING -t raw -d 198.18.0.12 -p udp --dport 1234 -j DROP</span><br></pre></td></tr></table></figure><p>这个方法的性能高达 1.688 pps。</p><p>这是非常明显的性能提升，我并不是特别明白多了一次路由差距这么大，要么是我们的路由层非常的复杂，或者在服务器的配置上有 bug。</p><p>在任何情况下，通过 iptables 的 raw 表进行操作绝对是最快的方法。</p><h2 id="第六阶段使用-nftables-在-conntrack-之前丢弃">第六阶段，使用 nftables 在 CONNTRACK 之前丢弃</h2><p>iptables 在现在已经有点过时了，更新的玩意是 nftables，关于为什么 nftables 技术更优越，请参阅此视频。 由于许多原因，Nftables 承诺比老旧的 iptables 更快，其中有一个说法是 retpolines（没有间接跳跃的猜测）严重影响了 iptables 性能。</p><p>由于这篇文章不是关于比较nftables和iptables的速度，让我们尝试一下我能想到的最快的方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nft add table netdev filter</span><br><span class="line">nft -- add chain netdev filter input &#123; type filter hook ingress device vlan100 priority -500 \; policy accept \; &#125;</span><br><span class="line">nft add rule netdev filter input ip daddr 198.18.0.0&#x2F;24 udp dport 1234 counter drop</span><br><span class="line">nft add rule netdev filter input ip6 daddr fd00::&#x2F;64 udp dport 1234 counter drop</span><br></pre></td></tr></table></figure><p>相关的统计信息可以通过这个命令查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ mmwatch &#39;nft --handle list chain netdev filter input&#39;</span><br><span class="line">table netdev filter &#123;</span><br><span class="line">    chain input &#123;</span><br><span class="line">        type filter hook ingress device vlan100 priority -500; policy accept;</span><br><span class="line">        ip daddr 198.18.0.0&#x2F;24 udp dport 1234 counter packets    1.6m&#x2F;s bytes    69.6m&#x2F;s drop # handle 2</span><br><span class="line">        ip6 daddr fd00::&#x2F;64 udp dport 1234 counter packets 0 bytes 0 drop # handle 3</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Nftables “ingress” Hook 性能卡在了 1.53 mpps。 这比 PREROUTING 层中的 iptables 稍慢。 这令人费解 - 理论上 ingress 在 PREROUTING 之前发生，所以应该更快。</p><p>在我们的测试中 nftables 比 iptables 略慢，但不是很多。 Nftables 仍然更好。</p><h2 id="第七阶段-利用-tc-的-ingress-策略丢包">第七阶段 利用 tc 的 ingress 策略丢包</h2><p>有个比较令人震惊的事实是 tc (traffic control) 的 ingress hook 发生在 PREROUTING 之前。tc 可以并且确实能做到根据一定的标准来选择并丢弃数据包，但是做法确实比较 hacky，所以建议利用这个脚本进行设置，我们需要的是一个稍微复杂点的匹配，参考下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tc qdisc add dev vlan100 ingress</span><br><span class="line">tc filter add dev vlan100 parent ffff: prio 4 protocol ip u32 match ip protocol 17 0xff match ip dport 1234 0xffff match ip dst 198.18.0.0&#x2F;24 flowid 1:1 action drop</span><br><span class="line">tc filter add dev vlan100 parent ffff: protocol ipv6 u32 match ip6 dport 1234 0xffff match ip6 dst fd00::&#x2F;64 flowid 1:1 action drop</span><br></pre></td></tr></table></figure><p>可以验证：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ mmwatch &#39;tc -s filter  show dev vlan100  ingress&#39;</span><br><span class="line">filter parent ffff: protocol ip pref 4 u32 </span><br><span class="line">filter parent ffff: protocol ip pref 4 u32 fh 800: ht divisor 1 </span><br><span class="line">filter parent ffff: protocol ip pref 4 u32 fh 800::800 order 2048 key ht 800 bkt 0 flowid 1:1  (rule hit   1.8m&#x2F;s success   1.8m&#x2F;s)</span><br><span class="line">  match 00110000&#x2F;00ff0000 at 8 (success   1.8m&#x2F;s ) </span><br><span class="line">  match 000004d2&#x2F;0000ffff at 20 (success   1.8m&#x2F;s ) </span><br><span class="line">  match c612000c&#x2F;ffffffff at 16 (success   1.8m&#x2F;s ) </span><br><span class="line">        action order 1: gact action drop</span><br><span class="line">         random type none pass val 0</span><br><span class="line">         index 1 ref 1 bind 1 installed 1.0&#x2F;s sec</span><br><span class="line">        Action statistics:</span><br><span class="line">        Sent    79.7m&#x2F;s bytes   1.8m&#x2F;s pkt (dropped   1.8m&#x2F;s, overlimits 0 requeues 0) </span><br><span class="line">        backlog 0b 0p requeues 0</span><br></pre></td></tr></table></figure><p>通过 tc 的 ingress hook 的 u32 匹配，可以让我们实现单核 1.8mpps 的丢包能力，这个很棒！</p><p>但是，我们可以更快一点…</p><h2 id="第八阶段-xdp_drop">第八阶段 XDP_DROP</h2><p>最后，终极武器是 XDP - eXpress Data Path。通过 XDP，我们可以在网络驱动层运行 eBPF 代码。最重要的是，这个阶段发生在分配 skbuff 内存之前，可以获得超高的速度。</p><p>通常 XDP 项目包含两部分：</p><ul><li><p>被加载到内核的 eBPB 代码</p></li><li><p>用户态的加载器，可以将代码加载到正确的网卡，并且控制他们</p></li></ul><p>编写加载器很难，但是我们可以利用 iproute2 的这个新特性，用一个很简单的命令加载：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip link set dev ext0 xdp obj xdp-drop-ebpf.o</span><br></pre></td></tr></table></figure><p>搞定！</p><p>这个 eBPF 的代码在这里。这个程序解析IP数据包，然后寻找对应的特征：IP 传输、UDP 协议、对应的子网和端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if (h_proto &#x3D;&#x3D; htons(ETH_P_IP)) &#123;</span><br><span class="line">    if (iph-&gt;protocol &#x3D;&#x3D; IPPROTO_UDP</span><br><span class="line">        &amp;&amp; (htonl(iph-&gt;daddr) &amp; 0xFFFFFF00) &#x3D;&#x3D; 0xC6120000 &#x2F;&#x2F; 198.18.0.0&#x2F;24</span><br><span class="line">        &amp;&amp; udph-&gt;dest &#x3D;&#x3D; htons(1234)) &#123;</span><br><span class="line">        return XDP_DROP;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>XDP 程序需要用现代的 clang 编译器编译成 BPF 字节码，完成之后可以加载并验证：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip link show dev ext0</span><br><span class="line">4: ext0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 xdp qdisc fq state UP mode DEFAULT group default qlen 1000</span><br><span class="line">    link&#x2F;ether 24:8a:07:8a:59:8e brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    prog&#x2F;xdp id 5 tag aedc195cc0471f51 jited</span><br></pre></td></tr></table></figure><p>然后通过 <code>ethtool -S</code> 查看网卡的统计信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mmwatch &#39;ethtool -S ext0|egrep &quot;rx&quot;|egrep -v &quot;: 0&quot;|egrep -v &quot;cache|csum&quot;&#39;</span><br><span class="line">     rx_out_of_buffer:     4.4m&#x2F;s</span><br><span class="line">     rx_xdp_drop:         10.1m&#x2F;s</span><br><span class="line">     rx2_xdp_drop:        10.1m&#x2F;s</span><br></pre></td></tr></table></figure><p>利用 XDP ，我们实现了在单核上，每秒钟丢弃 1000 万个包！</p><p><img src="https://www.hi-linux.com/img/linux/network-1000-2.jpg" alt=""></p><h2 id="总结">总结</h2><p>我们在 IPv4 和 IPv6 上重复了实验，并画了这张图：</p><p><img src="https://www.hi-linux.com/img/linux/network-1000-3.jpg" alt=""></p><p>总的来说在我们现在的设置下，IPv6 比 IPv4 要稍微慢一些，需要注意的是 IPv6 的包也稍微大了一些，所以这性能上的区别还是可以理解的。</p><p>Linux 提供了很多过滤数据包的 Hook，每个都有不同的性能和易用性。</p><p>对于应对 DDoS 的场景，在用户态的应用程序里处理这些数据包是合理的，通过调整应用程序，也可以获得不错的性能。</p><p>而对于有随机源 IP 和端口的攻击，关闭 conntrack 的特性来获得性能提升也是值得的，但是 conntrack 在某些攻击情况下，还是很有用的。</p><p>针对其他情况下，利用 Linux 的防火墙来作为抗 DDoS 的一部分还是很有意义的，在这种情况下要尽量利用 <code>-t raw PREROUTING</code> 这一层，因为这一层比 <code>filter</code> 表要快很多。</p><p>对于要求更高的工作负载，我们还有 XDP，而且他很强大，下面是和上面相同的图表，但是加上了 XDP：</p><p><img src="https://www.hi-linux.com/img/linux/network-1000-4.jpg" alt=""></p><p>如果需要重现这些数据，可以看看项目代码的 README。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://blog.cloudflare.com/how-to-drop-10-million-packets/" target="_blank" rel="noopener">https://blog.cloudflare.com/how-to-drop-10-million-packets/</a></p></li><li><p><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/recvmmsg-loop.c" target="_blank" rel="noopener">https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/recvmmsg-loop.c</a></p></li><li><p><a href="https://blog.cloudflare.com/three-little-tools-mmsum-mmwatch-mmhistogram/" target="_blank" rel="noopener">https://blog.cloudflare.com/three-little-tools-mmsum-mmwatch-mmhistogram/</a></p></li><li><p><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/bpf-drop.c" target="_blank" rel="noopener">https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/bpf-drop.c</a></p></li><li><p><a href="https://www.youtube.com/watch?v=9Zr8XqdET1c" target="_blank" rel="noopener">https://www.youtube.com/watch?v=9Zr8XqdET1c</a></p></li><li><p><a href="https://github.com/netoptimizer/network-testing/blob/master/tc/tc_ingress_drop.sh" target="_blank" rel="noopener">https://github.com/netoptimizer/network-testing/blob/master/tc/tc_ingress_drop.sh</a></p></li><li><p><a href="https://prototype-kernel.readthedocs.io/en/latest/networking/XDP/" target="_blank" rel="noopener">https://prototype-kernel.readthedocs.io/en/latest/networking/XDP/</a></p></li><li><p><a href="https://cilium.readthedocs.io/en/latest/bpf/#iproute2" target="_blank" rel="noopener">https://cilium.readthedocs.io/en/latest/bpf/#iproute2</a></p></li><li><p><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/xdp-drop-ebpf.c" target="_blank" rel="noopener">https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/xdp-drop-ebpf.c</a></p></li><li><p><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/README.md" target="_blank" rel="noopener">https://github.com/cloudflare/cloudflare-blog/blob/master/2018-07-dropping-packets/README.md</a></p></li></ol><blockquote><p>本文转载自：「C0reFast 记事本」，原文：<a href="https://url.cn/58wrb9u%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/58wrb9u，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;偶然看到一篇 Cloudflare 的博客 How to drop 10 million packets per second，如何实现单核情况下一秒钟丢弃 1000 万个数据包，原文循序渐进，从最简单的用户态丢弃到使用非常新的技术 XDP，逐步将单核丢包性能提升到 10 mpps，很有意思，网上也没有看到原文的中文版本，所以这里顺便翻译一下，看看 Cloudflare 是如何处理类似的情况的。&lt;/p&gt;
&lt;p&gt;在公司内部，我们的抗 DDoS 团队有时会被人们称作 “数据包丢弃者”。当其他团队为流经我们网络的流量做了很多令人兴奋的聪明玩意时，我们也很享受探索如何丢弃这些流量的新方法。&lt;/p&gt;
&lt;p&gt;能以最快速度丢掉网络包，对于抵抗 DDoS 攻击来说，是非常重要的。丢掉发送到我们服务器的数据包，和听上去一样简单，可以在很多层面上进行。每个技术都有他的优点和缺陷，在这篇 Blog 里，我们会一起看一下我们到目前为止用到的技术。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="网络" scheme="https://www.hi-linux.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>如何优雅的在 Docker 容器中指定用户及组权限的三种方式</title>
    <link href="https://www.hi-linux.com/posts/44367.html"/>
    <id>https://www.hi-linux.com/posts/44367.html</id>
    <published>2020-05-22T01:00:00.000Z</published>
    <updated>2020-05-22T04:50:00.598Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>如果平常有在玩 Docker 的用户肯定知道透过 <code>docker command</code> 启动的容器预设是使用 <code>root</code> 用户来当作预设使用者及群组的。这样就会遇到一个问题，当主机环境你拥有 root 权限时就没有此问题。如果你没有 root 权限，又有需求在 Docker 容器內挂上 Volume，会发现产生出来的文件皆会是 root 权限，这时候在主机完全是无法写入的。本篇文章将教大家三种方式来设定容器使用者权限，以解决上述遇到的问题。</p><h2 id="使用-docker-指令时指定使用者">使用 docker 指令时指定使用者</h2><p>以进入一个 Ubuntu 容器为例，通过以下指令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -ti ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>这时候我们可以通过 <code>-u</code> 方式将使用者 <code>uid</code> 及群组 <code>gid</code> 传入容器内。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir tmp</span><br><span class="line">$ docker run -ti -v $PWD&#x2F;tmp:&#x2F;test \</span><br><span class="line">  -u uid:gid ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>如何找到目前使用者 uid 及 gid 呢，可以通过下面的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ id -u</span><br><span class="line">$ id -g</span><br></pre></td></tr></table></figure><p>为了更加方便，上述指令可以改成:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -ti -v $PWD&#x2F;tmp:&#x2F;test \</span><br><span class="line">  -u $(id -u):$(id -g) ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="使用-dockerfile-指定使用者">使用 Dockerfile 指定使用者</h2><p>除了在 Docker 命令行指定外，你也可以在 <code>dockerfile</code> 内直接指定使用者。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">USER 1000:1000</span><br></pre></td></tr></table></figure><p>我个人不是很推荐这方式，除非是在 <code>container</code> 内独立建立使用者，并且指定权限。</p><h3 id="通过-docker-compose-指定权限">通过 docker-compose 指定权限</h3><p>通过 <code>docker-compose</code> 可以一次启动多个服务。用 <code>user</code> 可以指定使用者权限来写入特定的 volume。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">services:</span><br><span class="line">  agent:</span><br><span class="line">    image: xxxxxxxx</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - proxy</span><br><span class="line">    logging:</span><br><span class="line">      options:</span><br><span class="line">        max-size: &quot;100k&quot;</span><br><span class="line">        max-file: &quot;3&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - $&#123;STORAGE_PATH&#125;:&#x2F;data</span><br><span class="line">    user: $&#123;CURRENT_UID&#125;</span><br></pre></td></tr></table></figure><p>接着可以通过 .env 来指定变量的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">STORAGE_PATH&#x3D;&#x2F;home&#x2F;deploy&#x2F;xxxx</span><br><span class="line">CURRENT_UID&#x3D;1001:1001</span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>以上场景通常会发生在有挂载主机 Volume 进入容器内，但是你又没有 root 用户权限时。如果此时不指定使用者权限，这样生成出来的文件都会是 root 权限，一般用户无法写入，只能读取。</p><p>如果你觉得以上方法都过于麻烦，最后在提供一个终极解决方案，那就是使用 <code>Podman</code>。具体使用方法可以参考 「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247488720&amp;idx=1&amp;sn=56a3f0c46d3272f103216cf8330cf6af&amp;chksm=eac535f9ddb2bcefc5347ac1db0d290d384847ef3ef602522721a3308c8c7240b1ddb58533cf&amp;token=2039868521&amp;lang=zh_CN#rd" target="_blank" rel="noopener">再见 Docker，是时候拥抱下一代容器工具了</a>」 一文。</p><blockquote><p>来源：小恶魔</p><p>原文：<a href="https://url.cn/5KhaLSm" target="_blank" rel="noopener">https://url.cn/5KhaLSm</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果平常有在玩 Docker 的用户肯定知道透过 &lt;code&gt;docker command&lt;/code&gt; 启动的容器预设是使用 &lt;code&gt;root&lt;/code&gt; 用户来当作预设使用者及群组的。这样就会遇到一个问题，当主机环境你拥有 root 权限时就没有此问题。如果你没有 root 权限，又有需求在 Docker 容器內挂上 Volume，会发现产生出来的文件皆会是 root 权限，这时候在主机完全是无法写入的。本篇文章将教大家三种方式来设定容器使用者权限，以解决上述遇到的问题。&lt;/p&gt;
&lt;h2 id=&quot;使用-docker-指令时指定使用者&quot;&gt;使用 docker 指令时指定使用者&lt;/h2&gt;
&lt;p&gt;以进入一个 Ubuntu 容器为例，通过以下指令:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ docker run -ti ubuntu &amp;#x2F;bin&amp;#x2F;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这时候我们可以通过 &lt;code&gt;-u&lt;/code&gt; 方式将使用者 &lt;code&gt;uid&lt;/code&gt; 及群组 &lt;code&gt;gid&lt;/code&gt; 传入容器内。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ mkdir tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ docker run -ti -v $PWD&amp;#x2F;tmp:&amp;#x2F;test \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  -u uid:gid ubuntu &amp;#x2F;bin&amp;#x2F;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如何找到目前使用者 uid 及 gid 呢，可以通过下面的方式。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ id -u&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ id -g&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了更加方便，上述指令可以改成:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ docker run -ti -v $PWD&amp;#x2F;tmp:&amp;#x2F;test \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  -u $(id -u):$(id -g) ubuntu &amp;#x2F;bin&amp;#x2F;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你 3 个 Linux 中快速检测端口的小技巧</title>
    <link href="https://www.hi-linux.com/posts/27009.html"/>
    <id>https://www.hi-linux.com/posts/27009.html</id>
    <published>2020-05-21T01:00:00.000Z</published>
    <updated>2020-05-21T06:46:20.557Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>无论是要解决网络连接问题还是配置防火墙，第一件事是要检查系统实际打开了哪些端口。</p><p>本文介绍了几种快速查找 <code>Linux</code> 系统上哪些端口向外部开放的方法。</p><a id="more"></a><h2 id="什么是开放端口">什么是开放端口</h2><p>监听端口是应用程序监听的网络端口。你要得到的监听端口名单通常可以通过如 <code>ss</code>、<code>netstat</code> 或 <code>lsof</code> 命令查询系统上网络堆栈。每个监听端口都可以使用防火墙打开或关闭（过滤）。</p><p>一般而言，开放端口是一个网络端口，它接受来自远程位置的传入数据包。</p><p>例如：如果你正在运行的监听端口 80、443 的 <code>Web</code> 服务器，并把这些端口在防火墙上对任何人开放。使用浏览器将能够访问托管在 Web 服务器上的网站。在这种情况下，80 和 443 都是开放端口。</p><p>开放端口可能会带来安全风险，因为攻击者可以使用每个开放端口来利用漏洞或执行任何其他类型的攻击。您应该只公开应用程序功能所需的端口，然后关闭所有其他端口。</p><h2 id="使用-nmap-命令检查开放端口">使用 Nmap 命令检查开放端口</h2><p>Nmap 是功能强大的网络扫描工具，可以扫描单个主机和大型网络。它主要用于安全审核和渗透测试。</p><p>Nmap 是端口扫描的首选工具。除端口扫描外，Nmap 还可以检测 Mac 地址、操作系统类型、内核版本等。</p><p>从控制台发出以下命令确定哪些端口正在监听来自网络的 TCP 连接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nmap -sT -p- 10.10.8.8</span><br></pre></td></tr></table></figure><p><code>-sT</code> 选项告诉 Nmap 扫描 TCP 端口， <code>-p-</code> 扫描所有端口（65535 个）。如果不使用 <code>-p-</code>，<code>Nmap</code> 将仅扫描 1000 个端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Starting Nmap 7.60 ( https:&#x2F;&#x2F;nmap.org ) at 2019-07-09 23:10 CEST</span><br><span class="line">Nmap scan report for 10.10.8.8</span><br><span class="line">Host is up (0.0012s latency).</span><br><span class="line">Not shown: 998 closed ports</span><br><span class="line">PORT   STATE SERVICE</span><br><span class="line">22&#x2F;tcp open  ssh</span><br><span class="line">80&#x2F;tcp open  http</span><br><span class="line">MAC Address: 08:00:27:05:49:23 (Oracle VirtualBox virtual NIC)</span><br><span class="line"></span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 0.41 seconds</span><br></pre></td></tr></table></figure><p>以上显示，只有端口 22、80 以及 8069 在目标系统上打开。</p><p>要扫描 UDP 端口，请使用 <code>-sU</code> 代替 <code>-sT</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nmap -sU -p- 10.10.8.8</span><br></pre></td></tr></table></figure><p>有关更多信息，请访问 Nmap 手册页，并了解此工具的所有其他强大功能。</p><h2 id="使用-netcat-命令检查开放端口">使用 Netcat 命令检查开放端口</h2><p>Netcat（或nc）是一种命令行工具，可以使用 <code>TCP</code> 或 <code>UDP</code> 协议跨网络连接读取和写入数据。</p><p>使用 netcat 可以扫描单个端口或端口范围。</p><p>例如，要扫描 IP 地址为 10.10.8.8 的远程计算机上端口范围为 20-80 之间打开的 TCP 端口，你可以使用以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v 10.10.8.8 20-80</span><br></pre></td></tr></table></figure><p><code>-z</code> 选项指示 <code>nc</code> 仅扫描打开的端口，而不发送任何数据，并且 <code>-v</code> 用于获取更多详细信息。</p><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nc: connect to 10.10.8.8 port 20 (tcp) failed: Connection refused</span><br><span class="line">nc: connect to 10.10.8.8 port 21 (tcp) failed: Connection refused</span><br><span class="line">Connection to 10.10.8.8 22 port [tcp&#x2F;ssh] succeeded!</span><br><span class="line">...</span><br><span class="line">Connection to 10.10.8.8 80 port [tcp&#x2F;http] succeeded!</span><br></pre></td></tr></table></figure><p>如果只希望将以上开放端口的行打印在屏幕上，则可以使用 <code>grep</code> 命令过滤结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v 10.10.8.8 20-80 2&gt;&amp;1 | grep succeeded</span><br><span class="line"></span><br><span class="line">Connection to 10.10.8.8 22 port [tcp&#x2F;ssh] succeeded!</span><br><span class="line">Connection to 10.10.8.8 80 port [tcp&#x2F;http] succeeded!</span><br></pre></td></tr></table></figure><p>要扫描 <code>UDP</code> 端口，请将 <code>-u</code> 选项传递给 nc 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v -u 10.10.8.8 20-80 2&gt;&amp;1 | grep succeeded</span><br></pre></td></tr></table></figure><h2 id="使用-bash-伪设备检查打开的端口">使用 Bash 伪设备检查打开的端口</h2><p>检查某个端口是打开还是关闭的另一种方法是使用 <code>Bash Shell</code> 检查 <code>/dev/tcp/..</code> 或 <code>/dev/udp/..</code> 下的伪设备。</p><p>在 <code>/dev/$PROTOCOL/$HOST/$IP</code> 伪设备上执行命令时，<code>Bash</code> 将在指定端口上打开到指定主机的 <code>TCP</code> 或 <code>UDP</code> 连接。</p><p>以下 <code>if..else</code> 语句将检查端口 443 在 <code>kernel.org</code> 是否打开：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if timeout 5 bash -c &#39;&lt;&#x2F;dev&#x2F;tcp&#x2F;kernel.org&#x2F;443 &amp;&gt;&#x2F;dev&#x2F;null&#39;</span><br><span class="line">then</span><br><span class="line">  echo &quot;Port is open&quot;</span><br><span class="line">else</span><br><span class="line">  echo &quot;Port is closed&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Port is open</span><br></pre></td></tr></table></figure><h3 id="上面的代码如何工作">上面的代码如何工作？</h3><p>使用伪设备连接到端口时的默认超时时间非常长，因此我们使用 <code>timeout</code> 命令在 <code>5</code> 秒后终止测试命令。如果建立了 <code>kernel.org</code> 端口连接，则 <code>443</code> 测试命令将返回 true。你也可以使用 <code>for</code> 循环来检查指定的端口范围：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for PORT in &#123;20..80&#125;; do</span><br><span class="line">  timeout 1 bash -c &quot;&lt;&#x2F;dev&#x2F;tcp&#x2F;10.10.8.8&#x2F;$PORT &amp;&gt;&#x2F;dev&#x2F;null&quot; &amp;&amp;  echo &quot;port $PORT is open&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">port 22 is open</span><br><span class="line">port 80 is open</span><br></pre></td></tr></table></figure><h2 id="结论">结论</h2><p>我们为你展示了几种如何使用扫描开放端口的工具，当然你也可以使用其它工具来达到同样的目的，例如：<code>Python Socket</code> 模块、<code>Curl</code>、<code>Telnet</code> 或 <code>Wget</code>。</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://url.cn/52WWOOH" target="_blank" rel="noopener">https://url.cn/52WWOOH</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;无论是要解决网络连接问题还是配置防火墙，第一件事是要检查系统实际打开了哪些端口。&lt;/p&gt;
&lt;p&gt;本文介绍了几种快速查找 &lt;code&gt;Linux&lt;/code&gt; 系统上哪些端口向外部开放的方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>实战 Btrfs 文件系统之 Subvolume 与 Snapshot</title>
    <link href="https://www.hi-linux.com/posts/25994.html"/>
    <id>https://www.hi-linux.com/posts/25994.html</id>
    <published>2020-05-20T01:00:00.000Z</published>
    <updated>2020-05-20T05:02:06.187Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>对于大部分文件系统来说，在磁盘上创建好文件系统，然后再挂载到系统中去就完事了。但对于 Btrfs 来说，除了在格式化和挂载的时候指定不同的参数外，还支持很多其他的功能。比如：管理多块硬盘、支持 LVM 和 RAID 等，具体的可以参考它的「官方文档」或者「Linux 下常见文件系统对比」。</p><blockquote><p>Btrfs 是 Oracle 07 年基于 GPL 协议开源的 Linux 文件系统，其目的是替换传统的 Ext3、Ext4 系列文件系统。Ext 系列文件系统存在着诸多问题，比如反删除能力有限等；而 Btrfs 在解决问题同时提供了更加强大的高级特性。</p></blockquote><p><strong>Btrfs 特性</strong></p><p>Btrfs 在文件系统级别支持写时复制 (COW) 机制，并且支持快照 (增量快照)、支持对单个文件快照；同时支持单个超大文件、文件检查、内建 RAID；支持 B 树子卷 (组合多个物理卷，多卷支持) 等。具体如下：</p><p>Btrfs 核心特性：</p><ul><li><p>多物理卷支持：Btrfs 可有多个物理卷组成 (类似 LVM)；支持 RAID 以及联机 添加、删除、修改</p></li><li><p>写时复制更新机制 (COW)：复制、更新、替换指针，而非传统意义上的覆盖</p></li><li><p>支持数据及元数据校验码：Checksum 机制</p></li><li><p>支持创建子卷：Subvolume 机制，同时可多层创建</p></li><li><p>支持快照：基于 COW 实现快照，并且相对于 LVM 可以实现快照的快照 (增量快照)</p></li><li><p>支持透明压缩：后台自动压缩文件(消耗一定 CPU)，对前端程序透明</p></li></ul><a id="more"></a><p>Btrfs 是 Linux 下大家公认的将会替代 ext4 的下一代文件系统，功能非常强大。本篇不会介绍 Btrfs 的原理，也不会介绍 Btrfs 的所有功能，只是挑了其中的 Subvolume 和 Snapshot 这两个特性来进行介绍。</p><p>本篇所有例子都在 Ubuntu-Server-X86_64 16.04 下执行通过。</p><h2 id="准备环境">准备环境</h2><p>先创建一个虚拟的硬盘，然后将它格式化成 Btrfs，最后将它挂载到目录 /mnt/btrfs 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 为了简单起见，这里只使用一块硬盘来做测试（Btrf s可以管理多块硬盘或分区）。</span><br><span class="line"># 新建一个文件，用来虚拟一块硬盘。</span><br><span class="line">dev@ubuntu:~$ fallocate -l 512M &#x2F;tmp&#x2F;btrfs.img</span><br><span class="line"></span><br><span class="line"># 在上面创建 Btrfs 文件系统</span><br><span class="line">dev@ubuntu:~$ mkfs.btrfs &#x2F;tmp&#x2F;btrfs.img</span><br><span class="line">btrfs-progs v4.4</span><br><span class="line">See http:&#x2F;&#x2F;btrfs.wiki.kernel.org for more information.</span><br><span class="line"></span><br><span class="line">Label:              (null)</span><br><span class="line">UUID:               fd5efcd3-adc2-406b-a684-e6c87dde99a1</span><br><span class="line">Node size:          16384</span><br><span class="line">Sector size:        4096</span><br><span class="line">Filesystem size:    512.00MiB</span><br><span class="line">Block group profiles:</span><br><span class="line">  Data:             single            8.00MiB</span><br><span class="line">  Metadata:         DUP              40.00MiB</span><br><span class="line">  System:           DUP              12.00MiB</span><br><span class="line">SSD detected:       no</span><br><span class="line">Incompat features:  extref, skinny-metadata</span><br><span class="line">Number of devices:  1</span><br><span class="line">Devices:</span><br><span class="line">   ID        SIZE  PATH</span><br><span class="line">    1   512.00MiB  &#x2F;tmp&#x2F;btrfs.img</span><br><span class="line"></span><br><span class="line"># 创建文件夹并挂载</span><br><span class="line">dev@ubuntu:~$ sudo mkdir &#x2F;mnt&#x2F;btrfs</span><br><span class="line">dev@ubuntu:~$ sudo mount &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;btrfs</span><br><span class="line"></span><br><span class="line"># 修改权限，这样后面的部分操作就不再需要 sudo</span><br><span class="line">dev@ubuntu:~$ sudo chmod 777 &#x2F;mnt&#x2F;btrfs</span><br></pre></td></tr></table></figure><h2 id="subvolume">Subvolume</h2><p>可以把 Subvolume 理解为一个虚拟的设备，由 Btrfs 管理，创建好了之后就自动挂载到了 Btrfs 文件系统的一个目录上，所以我们在文件系统里面看到的 Subvolume 就是一个目录，但它是一个特殊的目录，具有挂载点的一些属性。</p><p>新创建的 Btrfs 文件系统会创建一个路径为 “/” 的默认 Subvolume，即 Root Subvolume。其 ID 为 5（别名为 0），这是一个 ID 和目录都预设好的 Subvolume。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 这里从 mount 的参数 “subvolid&#x3D;5,subvol&#x3D;&#x2F;” 就可以看出来默认的 Root Subvolume 的 id 为 5，路径为 “&#x2F;” 。</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ mount|grep btrfs</span><br><span class="line">&#x2F;dev&#x2F;loop1 on &#x2F;mnt&#x2F;btrfs type btrfs (rw,relatime,space_cache,subvolid&#x3D;5,subvol&#x3D;&#x2F;)</span><br></pre></td></tr></table></figure><h3 id="创建-subvolume">创建 Subvolume</h3><p>这里我们将会利用 Btrfs 提供的工具创建两个新 Subvolume 和两个文件夹，来看看他们之间的差别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">dev@ubuntu:~$ cd &#x2F;mnt&#x2F;btrfs</span><br><span class="line"># btrfs 命令是 Btrfs 提供的应用层工具，可以用来管理 Btrfs。</span><br><span class="line"># 这里依次创建两个 Subvolume，创建完成之后会自动在当前目录下生成两个目录。</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs subvolume create sub1</span><br><span class="line">Create subvolume &#39;.&#x2F;sub1&#39;</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs subvolume create sub2</span><br><span class="line">Create subvolume &#39;.&#x2F;sub2&#39;</span><br><span class="line"></span><br><span class="line"># 创建两个文件夹</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ mkdir dir1 dir2</span><br><span class="line"></span><br><span class="line"># 在sub1、sub2 和 dir1 中分别创建一个文件</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch dir1&#x2F;dir1-01.txt</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch sub1&#x2F;sub1-01.txt</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch sub2&#x2F;sub2-01.txt</span><br><span class="line"></span><br><span class="line"># 最后看看目录结构，是不是看起来 sub1 和 dir1 没什么区别？</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">├── dir2</span><br><span class="line">├── sub1</span><br><span class="line">│   └── sub1-01.txt</span><br><span class="line">└── sub2</span><br><span class="line">    └── sub2-01.txt</span><br></pre></td></tr></table></figure><p>不过由于每个 Subvolume 都是一个单独的虚拟设备，所以无法跨 Subvolume 建立硬链接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 虽然 sub1 和 sub2 属于相同的 Btrfs 文件系统，并且在一块物理硬盘上。但由于他们属于不同的 Subvolume，所以在它们之间建立硬链接失败。</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ ln .&#x2F;sub1&#x2F;sub1-01.txt .&#x2F;sub2&#x2F;</span><br><span class="line">ln: failed to create hard link &#39;.&#x2F;sub2&#x2F;sub1-01.txt&#39; &#x3D;&gt; &#39;.&#x2F;sub1&#x2F;sub1-01.txt&#39;: Invalid cross-device link</span><br></pre></td></tr></table></figure><h3 id="删除-subvolume">删除 Subvolume</h3><p>Subvolume 不能用 rm 命令来删除的，只能通过 btrfs 命令来删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 普通的目录通过 rm 命令就可以被删除</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ rm -r dir2</span><br><span class="line"></span><br><span class="line"># 通过 rm 命令删除 Subvolume 就会失败</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo rm -r sub2</span><br><span class="line">rm: cannot remove &#39;sub2&#39;: Operation not permitted</span><br><span class="line"></span><br><span class="line"># 需要通过 btrfs 命令才能删除，删除 sub2 成功（就算 Subvolume 里面有文件也能被删除）</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del sub2</span><br><span class="line">Delete subvolume (no-commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;sub2&#39;</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line">    └── sub1-01.txt</span><br></pre></td></tr></table></figure><p>上面删除的时候可以看到这样的提示： Delete subvolume (no-commit)，表示 Subvolume 被删除了，但没有提交。意思是在内存里面生效了，但磁盘上的内容还没删，意味着如果这个时候系统 Crash 掉，这个 Subvolume 有可能还会回来。Btrfs 这样做的好处是删除速度很快，不会影响使用，缺点是有可能在后台 Commit 的过程中系统挂掉，导致 Commit 失败。</p><p>为了确保 Subvolume 里的数据被真正的从磁盘上移除掉，可以在删除 Subvolume 的时候指定 -c 参数，这样 btrfs命令会等提交完成之后再返回。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del -c sub2</span><br><span class="line">Delete subvolume (commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;sub2&#39;</span><br></pre></td></tr></table></figure><h3 id="挂载-subvolume">挂载 Subvolume</h3><p>Subvolume 可以直接通过 mount 命令进行挂载，和挂载其它设备没什么区别，具体的挂载参数请查看参考官方文档。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个用于挂载点的目录</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo mkdir &#x2F;mnt&#x2F;sub1</span><br><span class="line"></span><br><span class="line"># 先查看待挂载的 Subvolume 的 id</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list &#x2F;mnt&#x2F;btrfs&#x2F;</span><br><span class="line">ID 256 gen 9 top level 5 path sub1</span><br><span class="line"></span><br><span class="line"># 通过 -o 参数来指定要挂载的 Subvolume 的 ID</span><br><span class="line"># 通过路径来挂载也是一样的效果：sudo mount -o subvol&#x3D;&#x2F;sub1 &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo mount -o subvolid&#x3D;256 &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree &#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">&#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">└── sub1-01.txt</span><br></pre></td></tr></table></figure><h3 id="设置-subvolume-只读">设置 Subvolume 只读</h3><p>Subvolume 可以被设置成只读状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 通过 btrfs property 可以查看和修改 Subvolume 的只读状态</span><br><span class="line"># 默认情况下，Subvolume 的只读属性为 false，即允许写</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property get -ts .&#x2F;sub1&#x2F;</span><br><span class="line">ro&#x3D;false</span><br><span class="line"></span><br><span class="line"># 将 sub1 的只读属性设置成 true</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property set -ts .&#x2F;sub1&#x2F; ro true</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property get -ts .&#x2F;sub1</span><br><span class="line">ro&#x3D;true</span><br><span class="line"></span><br><span class="line"># 写文件失败，提示文件系统只读</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch .&#x2F;sub1&#x2F;sub1-02.txt</span><br><span class="line">touch: cannot touch &#39;.&#x2F;sub1&#x2F;sub1-02.txt&#39;: Read-only file system</span><br><span class="line"></span><br><span class="line"># 将sub1的状态改回去，以免影响后续测试</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property set -ts .&#x2F;sub1&#x2F; ro false</span><br></pre></td></tr></table></figure><h2 id="snapshot">Snapshot</h2><p>可以在 Subvolume 的基础上制作快照，几点需要注意：</p><ul><li><p>默认情况下 Subvolume 的快照是可写的</p></li><li><p>快照是特殊的 Subvolume，具有 Subvolume 的属性。所以快照也可以通过 mount 挂载，也可以通过 btrfs property 命令设置只读属性</p></li><li><p>由于快照的本质就是一个 Subvolume ，所以可以在快照上面再做快照</p></li></ul><p>在 Subvolume 上做了快照后，Subvolume 和快照就会共享所有的文件。只有当文件更新的时候，才会触发 COW（copy on write），所以创建快照很快，基本不花时间。并且 Btrfs 的 COW 机制很高效，就算多个快照共享一个文件，更新这个文件也和更新一个普通文件差不多的速度。</p><p>如果用过 Git 的话，就能很容易理解 Btrfs 里的快照，可以把 Subvolume 理解为 Git 里面的 master 分支，而快照就是从 master checkout 出来的新分支，于是快照跟 Git 里的分支有类似的特点：</p><ul><li><p>创建快照几乎没有开销</p></li><li><p>可以在快照的基础上再创建快照</p></li><li><p>当前快照里面的修改不会影响其它快照</p></li><li><p>快照可以被删除</p></li></ul><p>当然 Subvolume 也可以像 Git 里的 master 一样被删除。</p><h3 id="创建快照">创建快照</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 在 Root Subvolume 的基础上创建一个快照</span><br><span class="line"># 默认情况下快照是可写的，如果要创建只读快照，需要加上 -r 参数</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume snapshot .&#x2F; .&#x2F;snap-root</span><br><span class="line">Create a snapshot of &#39;.&#x2F;&#39; in &#39;.&#x2F;snap-root&#39;</span><br><span class="line"></span><br><span class="line"># 创建完成后，可以看到我们已经有了两个 Subvolume</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list .&#x2F;</span><br><span class="line">ID 256 gen 11 top level 5 path sub1</span><br><span class="line">ID 257 gen 13 top level 5 path snap-root</span><br><span class="line"></span><br><span class="line"># 我们可以通过指定 -s 参数来只列出快照</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list -s .&#x2F;</span><br><span class="line">ID 257 gen 10 cgen 10 top level 5 otime 2017-03-05 21:46:03 path snap-root</span><br><span class="line"></span><br><span class="line"># 再来看看快照 snap-root 中的文件，可以看到有 dir1 及下面的文件，但看不到 sub1 下的文件，那是因为 sub1 是一个subvolume。在做一个 Subvolume 的快照的时候，不会将它里面的 Subvolume 也做快照</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree .&#x2F;snap-root</span><br><span class="line">.&#x2F;snap-root</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line"></span><br><span class="line"># 创建 sub1 的一个快照，可以看到 sub1 里面的文件出现在了快照里面</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume snapshot .&#x2F;sub1&#x2F; .&#x2F;snap-sub1</span><br><span class="line">Create a snapshot of &#39;.&#x2F;sub1&#x2F;&#39; in &#39;.&#x2F;snap-sub1&#39;</span><br><span class="line"></span><br><span class="line"># 然后在 sub1 和它的快照 snap-sub1 下面各自创建一个文件，会发现它们之间不受影响</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ touch snap-sub1&#x2F;snap-sub1-01.txt</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ touch sub1&#x2F;sub1-02.txt</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">├── snap-root</span><br><span class="line">│   ├── dir1</span><br><span class="line">│   │   └── dir1-01.txt</span><br><span class="line">│   └── sub1</span><br><span class="line">├── snap-sub1</span><br><span class="line">│   ├── snap-sub1-01.txt</span><br><span class="line">│   └── sub1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line">    ├── sub1-01.txt</span><br><span class="line">    └── sub1-02.txt</span><br></pre></td></tr></table></figure><h3 id="删除快照">删除快照</h3><p>删除快照和删除 Subvolume 是一样的，没有区别。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del snap-root</span><br><span class="line">Delete subvolume (no-commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;snap-root&#39;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del snap-sub1</span><br><span class="line">Delete subvolume (no-commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;snap-sub1&#39;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line">    ├── sub1-01.txt</span><br><span class="line">    └── sub1-02.txt</span><br></pre></td></tr></table></figure><h2 id="default-subvolume">Default Subvolume</h2><p>可以设置 Btrfs 分区的默认 Subvolume，即在挂载磁盘的时候，可以只让分区中的指定 Subvolume 对用户可见。看下面的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 查看 sub1 的ID</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list .&#x2F;</span><br><span class="line">ID 256 gen 14 top level 5 path sub1</span><br><span class="line"></span><br><span class="line"># 将 sub1 设置为当前 Btrfs 文件系统的默认 Subvolume</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume set-default 256 &#x2F;mnt&#x2F;btrfs&#x2F;</span><br><span class="line"></span><br><span class="line"># 重新将虚拟硬盘挂载到一个新目录</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo mkdir &#x2F;mnt&#x2F;btrfs1</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo mount &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;btrfs1&#x2F;</span><br><span class="line"></span><br><span class="line"># 这里将只能看到 sub1 下的文件</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree &#x2F;mnt&#x2F;btrfs1</span><br><span class="line">&#x2F;mnt&#x2F;btrfs1</span><br><span class="line">├── sub1-01.txt</span><br><span class="line">└── sub1-02.txt</span><br><span class="line"></span><br><span class="line"># 由于 Btrfs 原来的默认 Subvolume 是 Root Subvolume，其 ID 是5（也可以通过 0 来标识），所以我们可以通过同样的命令将默认 Subvolume 再改回去</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume set-default 0 &#x2F;mnt&#x2F;btrfs&#x2F;</span><br></pre></td></tr></table></figure><h3 id="default-subvolume-有什么用呢">Default Subvolume 有什么用呢？</h3><p>利用 Snapshot 和 Default Subvolume，可以很方便的实现不同系统版本的切换。比如将系统安装在一个 Subvolume 下面，当要做什么危险操作的时候，先在 Subvolume 的基础上做一个快照 A。如果操作成功，那么什么都不用做（或者把 A 删掉），继续用原来的 Subvolume，A 不被删掉也没关系，多一个快照在那里也不占空间。如果操作失败，那么可以将 A 设置成 Default Subvolume，并将原来的 Subvolume 删除，这样就相当于系统回滚。</p><p>有了这样的功能后，Linux 的每次操作都能回滚，养成在修改操作前做 Snapshot 的习惯，就再也不用担心 rm 误删文件了。</p><p>现在有些发行版已经有了类似的功能，如 Ubuntu，将安装工具 Apt 和 Btrfs 结合，自动的在安装软件之前打一个 Snapshot。然后安装软件，如果成功，删除新的 Snapshot，如果失败，修改 Default Subvolume 为新的 Snapshot，删除掉原来的 Snapshot，这样对系统没有任何影响，并且所有操作对用户是透明的。</p><p>随着 Btrfs 的成熟和普及，相信会改变一些我们使用 Linux 的习惯。</p><h2 id="延伸阅读">延伸阅读</h2><h3 id="btrfs-相关命令">btrfs 相关命令</h3><p>管理 btrfs 使用 btrfs 命令，该命令包含诸多子命令已完成不同的功能管理，常用命令如下：</p><ul><li><p>btrfs 文件系统属性查看： <code>btrfs filesystem show</code></p></li><li><p>调整文件系统大小： <code>btrfs filesystem resize +10g MOUNT_POINT</code></p></li><li><p>添加硬件设备： <code>btrfs filesystem add DEVICE MOUNT_POINT</code></p></li><li><p>均衡文件负载： <code>btrfs blance status|start|pause|resume|cancel MOUNT_POINT</code></p></li><li><p>移除物理卷(联机、自动移动)： <code>btrfs device delete DEVICE MOUNT_POINT</code></p></li><li><p>动态调整数据存放机制： <code>btrfs balance start -dconvert=RAID MOUNT_POINT</code></p></li><li><p>动态调整元数据存放机制： <code>btrfs balance start -mconvert=RAID MOUNT_POINT</code></p></li><li><p>动态调整文件系统数据数据存放机制： <code>btrfs balance start -sconvert=RAID MOUNT_POINT</code></p></li><li><p>创建子卷： <code>btrfs subvolume create MOUNT_POINT/DIR</code></p></li><li><p>列出所有子卷： <code>btrfs subvolume list MOUNT_POINT</code></p></li><li><p>显示子卷详细信息： <code>btrfs subvolume show MOUNT_POINT</code></p></li><li><p>删除子卷： <code>btrfs subvolume delete MOUNT_POIN/DIR</code></p></li><li><p>创建子卷快照(子卷快照必须存放与当前子卷的同一父卷中)： <code>btrfs subvolume snapshot SUBVOL PARVOL</code></p></li><li><p>删除快照同删除子卷一样： <code>btrfs subvolume delete MOUNT_POIN/DIR</code></p></li></ul><h2 id="相关阅读链接">相关阅读链接</h2><ol><li><p>Btrfs 官方文档：<a href="https://btrfs.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener">https://btrfs.wiki.kernel.org/index.php/Main_Page</a></p></li><li><p>Linux 下常见文件系统对比 ：<a href="https://segmentfault.com/a/1190000008481493" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008481493</a></p></li><li><p>Btrfs 官方挂载硬盘文档：<a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs(5)#MOUNT_OPTIONS" target="_blank" rel="noopener">https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs(5)#MOUNT_OPTIONS</a></p></li></ol><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://segmentfault.com/a/1190000008605135" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008605135</a></p></li><li><p><a href="https://mritd.me/2017/03/20/btrfs-note/" target="_blank" rel="noopener">https://mritd.me/2017/03/20/btrfs-note/</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于大部分文件系统来说，在磁盘上创建好文件系统，然后再挂载到系统中去就完事了。但对于 Btrfs 来说，除了在格式化和挂载的时候指定不同的参数外，还支持很多其他的功能。比如：管理多块硬盘、支持 LVM 和 RAID 等，具体的可以参考它的「官方文档」或者「Linux 下常见文件系统对比」。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Btrfs 是 Oracle 07 年基于 GPL 协议开源的 Linux 文件系统，其目的是替换传统的 Ext3、Ext4 系列文件系统。Ext 系列文件系统存在着诸多问题，比如反删除能力有限等；而 Btrfs 在解决问题同时提供了更加强大的高级特性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Btrfs 特性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Btrfs 在文件系统级别支持写时复制 (COW) 机制，并且支持快照 (增量快照)、支持对单个文件快照；同时支持单个超大文件、文件检查、内建 RAID；支持 B 树子卷 (组合多个物理卷，多卷支持) 等。具体如下：&lt;/p&gt;
&lt;p&gt;Btrfs 核心特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;多物理卷支持：Btrfs 可有多个物理卷组成 (类似 LVM)；支持 RAID 以及联机 添加、删除、修改&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;写时复制更新机制 (COW)：复制、更新、替换指针，而非传统意义上的覆盖&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持数据及元数据校验码：Checksum 机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持创建子卷：Subvolume 机制，同时可多层创建&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持快照：基于 COW 实现快照，并且相对于 LVM 可以实现快照的快照 (增量快照)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持透明压缩：后台自动压缩文件(消耗一定 CPU)，对前端程序透明&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Btrfs" scheme="https://www.hi-linux.com/tags/Btrfs/"/>
    
  </entry>
  
  <entry>
    <title>微软出品 Kubernetes 最新学习指南 v3.0，需要的赶紧下载吧！</title>
    <link href="https://www.hi-linux.com/posts/61882.html"/>
    <id>https://www.hi-linux.com/posts/61882.html</id>
    <published>2020-05-19T01:00:00.000Z</published>
    <updated>2020-05-19T08:49:55.567Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Kubernetes</code> 正在席卷应用开发世界，这是一个不争的事实。预计到 <code>2022</code> 年，全球有超过 <code>75％</code> 的组织将在生产环境中运行容器化应用程序。</p><p><code>Kubernetes</code> 正在塑造应用程序开发和管理的未来，微软希望今天帮助您开始使用它。为了你能更快的掌握 <code>Kubernetes</code>，微软出品了一个 <code>Kubernetes</code> 的学习路径指南。</p><p><img src="https://www.hi-linux.com/img/linux/ms-kubernetes-01.png" alt=""></p><p>该指南适用于有兴趣进一步了解 <code>Kubernetes</code> 的任何人。通过本指南你可以在短短 <code>50</code> 天内，了解 <code>Kubernetes</code> 的基础知识，并获得有关其各种组件，功能和解决方案。</p><p><img src="https://www.hi-linux.com/img/linux/ms-kubernetes-02.png" alt=""></p><a id="more"></a><p>「50 days from zero to hero with Kubernetes」大纲如下：</p><ul><li>为什么你需要关心容器</li><li>理解 Kubernetes 中的 Serverless</li><li>Kubernetes 的使用场景</li><li>Kubernetes 是如何工作的</li><li>Kubernetes 是如何调度任务的</li><li>Kubernetes 内的 Volume</li><li>Kubernetes 是如何部署服务的</li><li>Kubernetes CI/CD</li><li>Kubernetes 上有状态服务管理</li><li>Kubernetes Secret</li><li>准备把服务放在生产环境</li><li>监控与告警</li><li>Kubernetes 内的配置管理</li><li>Kubernetes 内的微服务是如何工作的</li><li>Kubernetes 中 Pod 与 Pod 的生命周期</li><li>理解基于角色的访问控制</li><li>通过 Operator 管理应用程序</li><li>…</li></ul><p>看上去，是不是很不错呢？<strong>只需在公众号对话框内回复 「<code>ms-kubernetes</code>」，即可获取「微软最新版 Kubernetes 学习指南 v3.0」PDF 版。</strong> PDF 能做得如此精美，交互也能做得如此好还是头一次见呢！</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt; 正在席卷应用开发世界，这是一个不争的事实。预计到 &lt;code&gt;2022&lt;/code&gt; 年，全球有超过 &lt;code&gt;75％&lt;/code&gt; 的组织将在生产环境中运行容器化应用程序。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt; 正在塑造应用程序开发和管理的未来，微软希望今天帮助您开始使用它。为了你能更快的掌握 &lt;code&gt;Kubernetes&lt;/code&gt;，微软出品了一个 &lt;code&gt;Kubernetes&lt;/code&gt; 的学习路径指南。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/ms-kubernetes-01.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;该指南适用于有兴趣进一步了解 &lt;code&gt;Kubernetes&lt;/code&gt; 的任何人。通过本指南你可以在短短 &lt;code&gt;50&lt;/code&gt; 天内，了解 &lt;code&gt;Kubernetes&lt;/code&gt; 的基础知识，并获得有关其各种组件，功能和解决方案。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/ms-kubernetes-02.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款支持 微信/QQ/TIM 消息防撤回神器 RevokeMsgPatcher</title>
    <link href="https://www.hi-linux.com/posts/30034.html"/>
    <id>https://www.hi-linux.com/posts/30034.html</id>
    <published>2020-05-19T01:00:00.000Z</published>
    <updated>2020-05-20T05:10:57.908Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>现在的社交软件都有一种 「后悔药」，学名叫 「消息撤回功能」。我们用的最多的应该是微信。在微信当中，不管你是消息发错了还是后悔了，只要长按消息内容点击 「撤回」，对方没看到的话，就永远看不到了！</p><p>当你看到别人撤回了一堆消息后，是不是很好奇 <code>Ta</code> 说了啥？但是当你再问 <code>Ta</code> 到底撤回了什么时候，基本上 <code>Ta</code> 是不会告诉你的，要不然也不会撤回了，对不对呀？既然消息已经发送过来一次了，难道我们不能做点什么让它撤回不了嘛？</p><p>今天我们就给大家推荐一个神器来解决这个千年难题。不论对方怎么骚操作，都可以让 <code>Ta</code> 发送过的消息留在聊天记录里，永远无法撤回！</p><p><img src="http://www.immidu.com/usr/uploads/2019/08/2390070843.jpg" alt=""></p><p>说了这么多，到底这神器是什么呢？是时候揭开它的神秘面纱了，它就是 <code>RevokeMsgPatcher</code>。<code>RevokeMsgPatcher</code> 是一款 <code>Windows</code> 下 PC 版的微信防撤回补丁。它除了支持微信，而且还支持 <code>QQ</code> 和 <code>TIM</code> 哟！</p><blockquote><p>项目地址：<a href="https://github.com/huiyadanli/RevokeMsgPatcher" target="_blank" rel="noopener">https://github.com/huiyadanli/RevokeMsgPatcher</a></p></blockquote><a id="more"></a><h2 id="安装-revokemsgpatcher">安装 RevokeMsgPatcher</h2><p><code>RevokeMsgPatcher</code> 的安装非常简单，只需在官方仓库 <code>Releases</code> 页面直接下载各平台对应的版本，解压后即可使用。</p><blockquote><p>注意：你的系统必须是 <code>Windows 7</code> 或更高版本，另外系统必须安装 <code>.NET Framework 4.5</code> 或更高版本。</p></blockquote><p><strong>RevokeMsgPatcher 目前支持的版本</strong></p><ul><li>支持的最新版本</li></ul><p><img src="https://i.loli.net/2019/11/13/LXw3lvqpftRokx2.png" alt=""></p><ul><li>支持的历史版本</li></ul><p><img src="https://i.loli.net/2019/11/13/FDO1cCJKIwB6beR.png" alt=""></p><p><strong>RevokeMsgPatcher 安装方法</strong></p><p><img src="https://raw.githubusercontent.com/huiyadanli/RevokeMsgPatcher/master/Images/screenshot.png" alt=""></p><ol><li><p><code>RevokeMsgPatcher</code> 使用和大多补丁程序类似，你肯定需要先关闭 <code>微信/QQ/TIM</code>。</p></li><li><p>以管理员权限运行程序，并点击工具界面上的「<code>...</code>」按钮后选择 <code>微信/QQ/TIM</code> 的安装路径。</p></li><li><p>点击工具界面上的「<code>点我防撤回</code>」按钮后，即可安装成功。</p></li></ol><blockquote><p>注意：</p><ol><li><p>缺省情况下会自动从注册表中获取安装路径，如果你使用的是绿色版可能需要手动选择一下安装路径。</p></li><li><p>工具界面此时可能会出现短暂的无响应，请耐心等待。另：因为补丁修改了微信的 <code>WeChatWin.dll</code> 文件、<code>QQ/TIM</code> 的 <code>IM.dll</code> 文件，如果杀毒软件弹出警告，你需要放行一下哟！</p></li></ol></blockquote><h2 id="使用-revokemsgpatcher">使用 RevokeMsgPatcher</h2><p>无论是 <code>微信/QQ/TIM</code> 上，对方进行撤回消息操作后，你在聊天界面仍旧能看到对方撤回的消息。下面是一个演示效果图：</p><p><img src="https://www.hi-linux.com/img/linux/unnamed-file-18.gif" alt=""></p><p>是不是，很惊喜，很意外呢。哈哈!</p><blockquote><p><code>RevokeMsgPatcher</code> 实现原理非常简单，其本质就是一个十六进制编辑器，可以对指定文件指定位置的字节进行编辑，把原先需要人工操作的地方自动化。</p></blockquote><p>赶紧用起来吧，从今以后你再也不会不知道你女朋友的小秘密了，哈哈！</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://xiaoma.me/778.html" target="_blank" rel="noopener">https://xiaoma.me/778.html</a></p></li><li><p><a href="http://www.immidu.com/index.php/archives/22/" target="_blank" rel="noopener">http://www.immidu.com/index.php/archives/22/</a></p></li><li><p><a href="https://mp.weixin.qq.com/s/pFl8fflWQYThwWAejR9G-g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/pFl8fflWQYThwWAejR9G-g</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在的社交软件都有一种 「后悔药」，学名叫 「消息撤回功能」。我们用的最多的应该是微信。在微信当中，不管你是消息发错了还是后悔了，只要长按消息内容点击 「撤回」，对方没看到的话，就永远看不到了！&lt;/p&gt;
&lt;p&gt;当你看到别人撤回了一堆消息后，是不是很好奇 &lt;code&gt;Ta&lt;/code&gt; 说了啥？但是当你再问 &lt;code&gt;Ta&lt;/code&gt; 到底撤回了什么时候，基本上 &lt;code&gt;Ta&lt;/code&gt; 是不会告诉你的，要不然也不会撤回了，对不对呀？既然消息已经发送过来一次了，难道我们不能做点什么让它撤回不了嘛？&lt;/p&gt;
&lt;p&gt;今天我们就给大家推荐一个神器来解决这个千年难题。不论对方怎么骚操作，都可以让 &lt;code&gt;Ta&lt;/code&gt; 发送过的消息留在聊天记录里，永远无法撤回！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.immidu.com/usr/uploads/2019/08/2390070843.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;说了这么多，到底这神器是什么呢？是时候揭开它的神秘面纱了，它就是 &lt;code&gt;RevokeMsgPatcher&lt;/code&gt;。&lt;code&gt;RevokeMsgPatcher&lt;/code&gt; 是一款 &lt;code&gt;Windows&lt;/code&gt; 下 PC 版的微信防撤回补丁。它除了支持微信，而且还支持 &lt;code&gt;QQ&lt;/code&gt; 和 &lt;code&gt;TIM&lt;/code&gt; 哟！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/huiyadanli/RevokeMsgPatcher&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/huiyadanli/RevokeMsgPatcher&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="工具" scheme="https://www.hi-linux.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="微信" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>U 盘多系统安装盘制作神器 YUMI 使用教程</title>
    <link href="https://www.hi-linux.com/posts/23035.html"/>
    <id>https://www.hi-linux.com/posts/23035.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.539Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>通常我们一个 U 盘只能制作成一个系统安装盘，比如制作好一个 <code>Windows 10</code> 安装盘，日后想要用到 <code>Linux</code>、<code>WinPE</code> 等安装盘时，只能重新制作一遍，非常浪费时间。而且现在 U 盘容量都很大，如果只放一个系统，同样就会白白浪费 U 盘剩余的空间。</p><p>今天，我们就给大家推荐一个可以让你的 U 盘制作成多系统安装盘的神器 <code>YUMI</code>。</p><p><code>YUMI</code> (<code>Your Universal Multiboot Integrator</code>) 是一款免费便携的 <code>USB</code> 多合一启动盘制作工具！它可以让你轻松将多款不同操作系统 <code>ISO</code> 镜像装到一个 U 盘里，制作出支持 <code>Multiboot</code> (多系统引导启动) 的多合一系统引导安装盘。</p><p><code>YUMI</code> 几乎支持全系列的 <code>Windows</code> 和 <code>Linux</code> 操作系统。比如 <code>Windows 10</code>、<code>Windows 7</code>、<code>WinPE</code>、<code>Windows To Go</code> 以及 <code>Linux</code> 的各种发行版。</p><blockquote><p>官网：<a href="https://www.pendrivelinux.com/yumi-multiboot-usb-creator/" target="_blank" rel="noopener">https://www.pendrivelinux.com/yumi-multiboot-usb-creator/</a></p></blockquote><a id="more"></a><h2 id="安装-yumi">安装 YUMI</h2><p><code>YUMI</code> 目前只支持 <code>Windows</code> 和 <code>Linux</code> 平台，共分为 <code>Legacy</code> 和 <code>UEFI</code> 两个版本，请根据自己 <code>BIOS</code> 实际引导情况选择下载。</p><ol><li>Windows 平台</li></ol><p><code>Windows</code> 安装非常简单，基本开箱即用，这里就不多赘述了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Legacy 版本下载地址</span><br><span class="line">https:&#x2F;&#x2F;www.pendrivelinux.com&#x2F;downloads&#x2F;YUMI&#x2F;YUMI-2.0.6.9.exe</span><br><span class="line"></span><br><span class="line"># UEFI 版本下载地址</span><br><span class="line">https:&#x2F;&#x2F;www.pendrivelinux.com&#x2F;downloads&#x2F;YUMI&#x2F;YUMI-UEFI-0.0.1.9.exe</span><br></pre></td></tr></table></figure><ol start="2"><li>Linux 平台</li></ol><p><code>Linux</code> 下安装相对就比较麻烦了，具体可以参考下官方文档。如果没什么必要，还是建议直接在 <code>Windows</code> 平台上使用。怎么简单怎么来嘛，反正平时用得也不多，哈哈！。</p><blockquote><p><a href="https://www.pendrivelinux.com/yumi-multiboot-usb-creator#HowTo" target="_blank" rel="noopener">https://www.pendrivelinux.com/yumi-multiboot-usb-creator#HowTo</a></p></blockquote><h2 id="使用-yumi-制作多系统启动盘">使用 YUMI 制作多系统启动盘</h2><p>使用 <code>YUMI</code> 制作多合一系统安装盘非常简单。插上 U  盘，运行 <code>YUMI</code> 软件后。制作系统安装盘一共只要以下 4 步：</p><ul><li><p>第一步：选择需要制作 U 盘的盘符。</p></li><li><p>第二步：选择你将要制作安装盘系统的名称。</p></li><li><p>第三步：选择你事先下载好的该系统对应的 <code>ISO</code> 镜像的安装文件。</p></li><li><p>第四步：最后，按下 「<code>Create</code>」后即开始制作。</p></li></ul><p><img src="https://i.loli.net/2019/10/25/cxpo3CA8ETsDRKw.png" alt=""></p><blockquote><p>注意: <code>YUMI</code> 每次只能制作一个系统的安装盘，如果你要制作多个系统，只需重复执行多次上述的步骤来增加其它操作系统即可。</p></blockquote><h2 id="使用-yumi-引导多系统">使用 YUMI 引导多系统</h2><p>系统安装盘制作完成后，在电脑 <code>BIOS</code> 设置 U 盘为开机启动后，就能直接进入 <code>YUMI</code> 的 <code>Miltiboot</code> 引导界面。</p><p><img src="https://www.pendrivelinux.com/wp-content/uploads/YUMI-Boot-Menu.png" alt=""></p><p>然后，你只需要选择自己需要的系统就可以开始安装。</p><h2 id="删除已制作好的操作系统">删除已制作好的操作系统</h2><p>按上述的步骤制作好多重启动盘之后，如果你需要删除其中的一个或者多个系统，那么你只需重新运行 <code>YUMI</code>，然后勾选右上方的「<code>You're in Uninstaller Model</code>」即可在下方列表中看到当前 U 盘里的系统。</p><p><img src="https://i.loli.net/2019/10/25/yPiRChIwKEoaQcs.png" alt=""></p><p>接下来，你只需在列表中选择不想要的操作系统后，点击「Remove」就可以删除它了。如需删除多个系统，重复多遍以上操作即可。</p><h2 id="总结">总结</h2><p>对于经常需要装机、制作系统安装盘的同学来说，<code>YUMI</code> 无疑是一个相当强大好用的工具。如果你想要制作一个集 <code>Windows 10</code>、<code>WinPE</code> 和 <code>Linux</code> 系统于一身、方便用于维护和装机的多合一系统安装盘，那么操作如此简单的 <code>YUMI</code> 值得你拥有！</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://www.iplaysoft.com/yumi.html" target="_blank" rel="noopener">https://www.iplaysoft.com/yumi.html</a></p></li><li><p><a href="https://blog.shiyunhong.com/3012.html" target="_blank" rel="noopener">https://blog.shiyunhong.com/3012.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通常我们一个 U 盘只能制作成一个系统安装盘，比如制作好一个 &lt;code&gt;Windows 10&lt;/code&gt; 安装盘，日后想要用到 &lt;code&gt;Linux&lt;/code&gt;、&lt;code&gt;WinPE&lt;/code&gt; 等安装盘时，只能重新制作一遍，非常浪费时间。而且现在 U 盘容量都很大，如果只放一个系统，同样就会白白浪费 U 盘剩余的空间。&lt;/p&gt;
&lt;p&gt;今天，我们就给大家推荐一个可以让你的 U 盘制作成多系统安装盘的神器 &lt;code&gt;YUMI&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YUMI&lt;/code&gt; (&lt;code&gt;Your Universal Multiboot Integrator&lt;/code&gt;) 是一款免费便携的 &lt;code&gt;USB&lt;/code&gt; 多合一启动盘制作工具！它可以让你轻松将多款不同操作系统 &lt;code&gt;ISO&lt;/code&gt; 镜像装到一个 U 盘里，制作出支持 &lt;code&gt;Multiboot&lt;/code&gt; (多系统引导启动) 的多合一系统引导安装盘。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YUMI&lt;/code&gt; 几乎支持全系列的 &lt;code&gt;Windows&lt;/code&gt; 和 &lt;code&gt;Linux&lt;/code&gt; 操作系统。比如 &lt;code&gt;Windows 10&lt;/code&gt;、&lt;code&gt;Windows 7&lt;/code&gt;、&lt;code&gt;WinPE&lt;/code&gt;、&lt;code&gt;Windows To Go&lt;/code&gt; 以及 &lt;code&gt;Linux&lt;/code&gt; 的各种发行版。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;官网：&lt;a href=&quot;https://www.pendrivelinux.com/yumi-multiboot-usb-creator/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.pendrivelinux.com/yumi-multiboot-usb-creator/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="YUMI" scheme="https://www.hi-linux.com/tags/YUMI/"/>
    
  </entry>
  
  <entry>
    <title>史上最全的高性能代理服务器 Envoy 中文实战教程</title>
    <link href="https://www.hi-linux.com/posts/57326.html"/>
    <id>https://www.hi-linux.com/posts/57326.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.543Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-envoy">什么是 Envoy</h2><p><code>Envoy</code> 是一款 <code>CNCF</code> 旗下的开源项目，由 <code>Lyft</code> 开源。<code>Envoy</code> 采用 C++ 实现，是面向 <code>Service Mesh</code> 的高性能网络代理服务。它与应用程序并行运行，通过以平台无关的方式提供通用功能来抽象网络。当基础架构中的所有服务流量都通过 Envoy 网格时，通过一致的可观测性，很容易地查看问题区域，调整整体性能。</p><p><code>Envoy</code> 也是 <code>Istio Service Mesh</code> 中默认的 <code>Data Plane</code>，本文我们将讲解 <code>Envoy</code> 的一些基本概念，并采用一些实例来介绍如何在本地环境中快速使用 <code>Envoy</code> 作为 <code>Service Mesh</code> 的数据平面，以帮助读者理解 <code>Istio</code> 的 <code>Data Panel</code> 层实现。</p><blockquote><p>官网：<a href="https://www.envoyproxy.io" target="_blank" rel="noopener">https://www.envoyproxy.io</a></p></blockquote><h3 id="envoy-特性">Envoy 特性</h3><ol><li>整体架构</li></ol><p><img src="https://ws1.sinaimg.cn/large/4483e99egy1ftn7wet57fj233f1utag1.jpg" alt=""></p><ol start="2"><li>进程无关架构</li></ol><p><code>Envoy</code> 是一个自组织的模块，与应用 <code>Server</code> 并无直接依赖。所有的 <code>Envoy</code> 构建了一个透明的服务网格 <code>Service Mesh</code>，处于其中的应用只需要简单的与本地的 <code>Envoy</code> 进行收发信息，并不需要关注整个网络拓扑。这种架构对于应用通信有两大好处：</p><ul><li><p><code>Envoy</code> 可以让任何的编程语言编写的服务通信，协同工作，<code>Envoy</code> 帮你屏蔽了服务之间的沟壑。</p></li><li><p>任何曾经在大型微服务开发中工作过的人都知道发布一个库更新是多么的痛苦。<code>Envoy</code> 可以以一种透明的方式快速的发布更新整个基础架构中的版本。</p></li></ul><a id="more"></a><ol start="3"><li>高级负载均衡</li></ol><p>分布式系统中不同模块间的负载均衡是一个复杂的问题。因为 <code>Envoy</code> 是一个自组织的代理，所以它能在一个地方实现高级负载均衡技术并使他们可被访问。当前 <code>Envoy</code> 支持自动重试、断路器、全局限速、阻隔请求、异常检测，将来还会支持按计划进行请求速率控制。</p><ol start="4"><li>动态配置</li></ol><p><code>Envoy</code> 提供了可选的一系列的分层的动态配置 <code>API</code>，使用这些 <code>API</code> 可以构建出复杂的集中式部署管理。</p><ol start="5"><li>正向代理支持</li></ol><p>虽然 <code>Envoy</code> 设计初衷是服务和服务之间通信系统，得益于其监视、管理、服务发现和负载均衡算法的实现，<code>Enovy</code> 包含了足够多的特性为绝大多数 <code>Web</code> 服务做正向代理。</p><p>除了这些之外还有对 <code>HTTP/2</code> 的支持，<code>L3</code>、<code>L4</code>、<code>L7</code> 代理，可以实现 <code>TCP Proxy</code>、<code>HTTP Proxy</code> 等功能。</p><ol start="6"><li>线程模型</li></ol><p><code>Envoy</code> 使用单进程多线程架构，其中一个扮演主线程的控制各种协调任务，而一些工作线程负责监听、过滤和转发。一旦某个链接被监听器 <code>Listener</code> 接受，那么这个链接将会剩余的生命周期绑定在这个 <code>Woker</code> 线程。这种架构会使得大部分工作工作在单线程的情况下，只有少量的工作会涉及到线程间通信，<code>Envoy</code> 代码是 100% 非阻塞的。</p><ol start="7"><li>Listener 监听器</li></ol><ul><li><p>一个 <code>Envoy</code> 进程可以设置多个不同的 <code>Listener</code>，建议一台机器只使用一个 <code>Envoy</code> 实例。</p></li><li><p>每一个 <code>Listener</code> 的网络层 <code>L3/L4</code> 过滤器是独立配置的。并且一个 <code>Listener</code> 是可以通过配置来完成多种任务的，比如：访问限制、TLS 客户端校验、HTTP 链接管理等。</p></li><li><p><code>Listener</code> 也有自己的非网络层过滤器，它可以修改链接的 <code>Metadata</code> 信息，通常用来影响接下来链接是如何被网络层过滤器处理的。</p></li><li><p>无论网络层过滤器还是 <code>Listener</code> 过滤器都可以提前终止后续的过滤器链的执行。</p></li></ul><ol start="8"><li>HTTP 连接管理器</li></ol><ul><li><p><code>Envoy</code> 是完整支持 <code>HTTP/1.1</code>、<code>Websockets</code> 和 <code>HTTP/2</code>，不支持 <code>SPDY</code>。</p></li><li><p>这层过滤器主要是将原始的传递数据转变成 <code>HTTP</code> 层级的信息和事件，如收到 <code>Headers</code>、收到 <code>Body</code> 数据，同样它也可以做接入日志、<code>Request ID</code> 生成和追踪、<code>Req/Res</code> 头部修改工作、路由表管理、统计分析。</p></li><li><p>每一个 <code>HTTP</code> 链接管理器有一个相匹配的路由表，路由表可以静态指定，也可以动态地通过 <code>RDS API</code> 来设置 <code>route-dynamic</code>。</p></li><li><p>其内部还有 <code>HTTP</code> 过滤器，可以支持在 <code>HTTP</code> 层级。在无需关注使用什么协议 (<code>HTTP/1.1</code> 或 <code>HTTP/2</code>) 实现的情况下进行操作 <code>HTTP</code> 内容，支持 <code>Encode</code>、<code>Decode</code>、<code>Encode/Decode</code> 三种不同类型过滤器。</p></li></ul><ol start="9"><li>HTTP 路由器</li></ol><ul><li><p>经常用在做边缘/反向代理和构建内部 <code>Envoy Mesh</code> 发挥巨大作用。</p></li><li><p><code>HTTP</code> 路由器可以支持请求重试配置：最大重试次数和设置重试条件，比如某些 <code>5XX</code> 错误和具有幂等性操作的 <code>4XX</code> 错误。</p></li><li><p><code>Envoy</code> 自己使用 <code>HTTP/2</code> 链接管理器实现了 <code>gRPC</code> 协议，将原来官方的 <code>Google gRPC</code> 内置的很多功能，比如重试、超时、<code>Endpoint</code> 发现、负载均衡、负载报告、健康检查等功能都实现了。将来除非特殊特性必须，都可以使用 <code>Envoy gRPC</code> 来实现。</p></li></ul><ol start="10"><li>Cluster 管理器</li></ol><p><code>Cluster</code> 管理器暴露 <code>API</code> 给过滤器，并允许过滤器可以得到链接到上游集群的 <code>L3/L4</code> 链接或者维持一个抽象的 <code>HTTP</code> 连接池用来链接上游集群（上游主机支持 <code>HTTP 1.1</code> 还是 <code>HTTP 2</code> 都是被隐藏的）。过滤器决定是使用 <code>L3/L4</code> 链接还是 <code>HTTP Stream</code> 来链接上游集群。而对于集群管理器来说，它负责所有集群内主机的可用性、负载均衡、健康度、线程安全的上游链接数据，上游链接类型 <code>TCP/UP</code>、<code>UDS</code>，上游可接受的协议 <code>HTTP 1.1/2</code>。</p><p><code>Cluster</code> 管理器既可以静态配置，也可以使用 <code>CDS-Cluster-Discovery-Service API</code> 来动态配置。 集群在正式使用之前有一个 “加热” <code>Warming</code> 的过程：先做服务发现必要的初始化，比如 <code>DNS</code> 记录更新、<code>EDS</code> 更新，然后进行健康检查，当进行完上述的过程，会进入<code>Becoming available</code> 状态，这个阶段 <code>Envoy</code> 不会把流量指向它们; 在更新集群时，也不会把正在处理流量的集群处理掉，而是用新的去替换老的那些还未进行任何流量的集群。</p><ol start="11"><li>与 Nginx 的区别</li></ol><ul><li><p><code>Envoy</code> 对 <code>HTTP/2</code> 的支持比 <code>Nginx</code> 更好，支持包括 <code>upstream</code> 和 <code>downstream</code> 在内的双向通信，而 <code>Nginx</code> 只支持 <code>downstream</code> 的连接。</p></li><li><p>高级负载均衡功能是免费的，<code>Nginx</code> 的高级负载均衡功能则需要付费的 <code>Nginx Plus</code> 支持。</p></li><li><p><code>Envoy</code> 支持热更新，<code>Nginx</code> 配置更新之后需要 <code>Reload</code>。</p></li><li><p><code>Envoy</code> 更贴近 <code>Service Mesh</code> 的使用习惯，<code>Nginx</code> 更贴近传统服务的使用习惯。</p></li></ul><h3 id="envoy-术语">Envoy 术语</h3><p>要深入理解 <code>Envoy</code>，首先需要先了解一下 <code>Envoy</code> 中的一些术语。</p><p><img src="https://ws1.sinaimg.cn/large/4483e99egy1fto85kdq0wj20lo0b2wej.jpg" alt=""></p><ul><li><p><code>Host</code>：能够进行网络通信的实体（如服务器上的应用程序）。</p></li><li><p><code>Downstream</code>：下游主机连接到 <code>Envoy</code>，发送请求并接收响应。</p></li><li><p><code>Upstream</code>：上游主机接收来自 <code>Envoy</code> 连接和请求并返回响应。</p></li><li><p><code>Listener</code>：可以被下游客户端连接的命名网络（如端口、<code>Unix</code> 套接字）。一般是每台主机运行一个 <code>Envoy</code>，使用单进程运行，但是每个进程中可以启动任意数量的 <code>Listener</code>（监听器），每个监听器都独立配置一定数量的（ <code>L3/L4</code> ）网络过滤器。</p></li><li><p><code>Cluster</code>：<code>Envoy</code> 连接到的一组逻辑上相似的上游主机。</p></li><li><p><code>Mesh</code>：以提供一致的网络拓扑的一组主机。</p></li><li><p><code>Runtime Configuration</code>：与 <code>Envoy</code> 一起部署的外置实时配置系统。</p></li><li><p><code>Listener Filter</code>：<code>Listener</code> 使用 <code>Listener Filter</code>（监听器过滤器）来操作链接的元数据，它的作用是在不更改 <code>Envoy</code> 的核心功能的情况下添加更多的集成功能。</p></li><li><p><code>Http Route Table</code>：<code>HTTP</code> 的路由规则，例如请求的域名，<code>Path</code> 符合什么规则，转发给哪个 <code>Cluster</code>。</p></li></ul><h2 id="部署-envoy">部署 Envoy</h2><p>官方提供了 <code>Envoy</code> 的 <code>Docker</code> 镜像，直接下载对应镜像即可使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull envoyproxy&#x2F;envoy:latest</span><br></pre></td></tr></table></figure><p>镜像中已经将 Envoy 安装到 <code>/usr/local/bin</code> 目录下，可以先看看 <code>Envoy</code> 进程的帮助信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --help</span><br><span class="line">USAGE: </span><br><span class="line">   &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy  [--disable-hot-restart] [--max-obj-name-len</span><br><span class="line">                         &lt;uint64_t&gt;] [--max-stats &lt;uint64_t&gt;] [--mode</span><br><span class="line">                         &lt;string&gt;] [--parent-shutdown-time-s &lt;uint32_t&gt;]</span><br><span class="line">                         [--drain-time-s &lt;uint32_t&gt;]</span><br><span class="line">                         [--file-flush-interval-msec &lt;uint32_t&gt;]</span><br><span class="line">                         [--service-zone &lt;string&gt;] [--service-node</span><br><span class="line">                         &lt;string&gt;] [--service-cluster &lt;string&gt;]</span><br><span class="line">                         [--hot-restart-version] [--restart-epoch</span><br><span class="line">                         &lt;uint32_t&gt;] [--log-path &lt;string&gt;] [--log-format</span><br><span class="line">                         &lt;string&gt;] [-l &lt;string&gt;]</span><br><span class="line">                         [--local-address-ip-version &lt;string&gt;]</span><br><span class="line">                         [--admin-address-path &lt;string&gt;] [--v2-config-only]</span><br><span class="line">                         [--config-yaml &lt;string&gt;] [-c &lt;string&gt;]</span><br><span class="line">                         [--concurrency &lt;uint32_t&gt;] [--base-id &lt;uint32_t&gt;]</span><br><span class="line">                         [--] [--version] [-h]</span><br></pre></td></tr></table></figure><p><code>Envoy</code> 进程启动的时候需要指定一些参数，其中最重要的是 <code>--config-yaml</code> 参数，用于指定 <code>Envoy</code> 进程启动的时候需要读取的配置文件地址。<code>Docker</code> 中配置文件默认是放在 <code>/etc/envoy</code> 目录下，配置文件的文件名是 <code>envoy.yaml</code>。所以我们在启动容器的时候需要将自定义的 <code>envoy.yaml</code> 配置文件挂载到指定目录下替换掉默认的配置文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy -c &lt;path to config&gt;.&#123;json,yaml,pb,pb_text&#125; --v2-config-only</span><br></pre></td></tr></table></figure><blockquote><p>注意：<code>Envoy</code> 默认的日志级别是 <code>info</code>，对于开发阶段需要进行调试的话，调整日志级别到 <code>Debug</code> 是非常有用的。你可以在启动参数中添加 <code>-l debug</code> 来将日志级别进行切换。</p></blockquote><h2 id="编写-envoy-配置文件">编写 Envoy 配置文件</h2><p>在介绍 <code>Envoy</code> 的配置文件之前，先介绍一下 <code>Envoy</code> 的 <code>API</code>。<code>Envoy</code> 提供了两个版本的 <code>API</code>，<code>V1</code> 和 <code>V2</code> 版本 <code>API</code>。现阶段 <code>V1</code> 版本已经不建议使用了，通常都是使用 <code>V2</code> 的 <code>API</code>。</p><p><code>V2</code> 的 <code>API</code> 提供了两种方式的访问，一种是 <code>HTTP Rest</code> 的方式访问，还有一种 <code>GRPC</code> 的访问方式。关于 <code>GRPC</code> 的介绍可以参考官方文档，在后面的文章中只实现了 <code>GRPC</code> 的 <code>API</code>。</p><p><code>Envoy</code> 的启动配置文件分为两种方式：静态配置和动态配置。</p><p>静态配置是将所有信息都放在配置文件中，启动的时候直接加载。</p><p>动态配置需要提供一个 <code>Envoy</code> 的服务端，用于动态生成 <code>Envoy</code> 需要的服务发现接口，这里叫 <code>XDS</code> ，通过发现服务来动态的调整配置信息，<code>Istio</code> 就是实现了 <code>V2</code> 的 <code>API</code>。</p><h3 id="静态配置">静态配置</h3><p>以一个最简化的静态配置来做示例，体验一下 <code>Envoy</code>。</p><p>下面是 <code>envoy.yaml</code>配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 127.0.0.1, port_value: 9901 &#125;</span><br><span class="line"></span><br><span class="line">static_resources:</span><br><span class="line">  listeners:</span><br><span class="line">  - name: listener_0</span><br><span class="line">    address:</span><br><span class="line">      socket_address: &#123; address: 0.0.0.0, port_value: 10000 &#125;</span><br><span class="line">    filter_chains:</span><br><span class="line">    - filters:</span><br><span class="line">      - name: envoy.http_connection_manager</span><br><span class="line">        config:</span><br><span class="line">          stat_prefix: ingress_http</span><br><span class="line">          codec_type: AUTO</span><br><span class="line">          route_config:</span><br><span class="line">            name: local_route</span><br><span class="line">            virtual_hosts:</span><br><span class="line">            - name: local_service</span><br><span class="line">              domains: [&quot;*&quot;]</span><br><span class="line">              routes:</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;&quot; &#125;</span><br><span class="line">                route: &#123; cluster: some_service &#125;</span><br><span class="line">          http_filters:</span><br><span class="line">          - name: envoy.router</span><br><span class="line">  clusters:</span><br><span class="line">  - name: some_service</span><br><span class="line">    connect_timeout: 0.25s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts: [&#123; socket_address: &#123; address: 127.0.0.1, port_value: 80 &#125;&#125;]</span><br></pre></td></tr></table></figure><p>在此基础上启动两个容器，<code>envoyproxy</code> 容器和 <code>nginx</code> 容器，<code>nginx</code> 容器共享 <code>envoyproxy</code> 容器的网络，以此来模拟 <code>Sidecar</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d -p 10000:10000 -v &#96;pwd&#96;&#x2F;envoy.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy envoyproxy&#x2F;envoy:latest</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy --name nginx nginx</span><br></pre></td></tr></table></figure><p>根据配置文件的规则，<code>Envoy</code> 监听在 <code>10000</code> 端口，同时该端口也在宿主机的 <code>10000</code> 端口上暴露出来。当有请求到达监听上后，<code>Envoy</code> 会对所有请求路由到 <code>some_service</code> 这个 <code>Cluster</code> 上，而该 <code>Cluster</code> 的 <code>Upstream</code> 指向本地的 <code>80</code> 端口，也就是 <code>Nginx</code> 服务上。</p><p><img src="https://upload-images.jianshu.io/upload_images/12196676-5550ffdbe14a2d0c.png" alt=""></p><h3 id="动态配置">动态配置</h3><p>动态配置可以实现全动态，即实现 <code>LDS</code> (<code>Listener Discovery Service</code>)、<code>CDS</code> (<code>Cluster Discovery Service</code>)、<code>RDS</code> (<code>Route Discovery Service</code>)、<code>EDS</code> (<code>Endpoint Discovery Service</code>)，以及 <code>ADS</code> (<code>Aggregated Discovery Service</code>)。</p><p><code>ADS</code> 不是一个实际意义上的 <code>XDS</code>，它提供了一个汇聚的功能，以实现需要多个同步 <code>XDS</code> 访问的时候可以在一个 <code>Stream</code> 中完成的作用。</p><p>下面的图通过在静态配置的基础上，比较直观的表示出各个发现服务所提供的信息。</p><p><img src="https://upload-images.jianshu.io/upload_images/12196676-1927da1e7ee7bb65.png" alt=""></p><p>由此，典型的动态配置文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 127.0.0.1, port_value: 9901 &#125;</span><br><span class="line"></span><br><span class="line">dynamic_resources:</span><br><span class="line">  cds_config:</span><br><span class="line">    ads: &#123;&#125;</span><br><span class="line">  lds_config:</span><br><span class="line">    ads: &#123;&#125;</span><br><span class="line">  ads_config:</span><br><span class="line">    api_type: GRPC</span><br><span class="line">    cluster_names: [xds_cluster]</span><br><span class="line"></span><br><span class="line">static_resources:</span><br><span class="line">  clusters:</span><br><span class="line">  - name: xds_cluster</span><br><span class="line">    connect_timeout: 0.25s</span><br><span class="line">    type: STRICT_DNS</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    http2_protocol_options: &#123;&#125;</span><br><span class="line">    hosts: [&#123; socket_address: &#123; address: envoy-server, port_value: 50051 &#125;&#125;]</span><br></pre></td></tr></table></figure><blockquote><p>注意：动态配置和静态配置最大的区别在于，启动的时候一定要指定 <code>cluster</code> 和 <code>id</code>，这两个参数表示该 Envoy 进程属于哪个 <code>Cluster</code>，<code>id</code> 要求在相同的 <code>Cluster</code> 下唯一，以表示不同的指向发现服务的连接信息。这两个参数可以在 <code>Envoy</code> 的启动命令中添加<code>--service-cluster</code> 和 <code>--service-node</code> 来指定，也可以在 <code>envoy.yaml</code> 配置文件中指定 <code>node.cluster</code> 和 <code>node.id</code>。</p></blockquote><h2 id="envoy-使用实例">Envoy 使用实例</h2><h3 id="入门实例">入门实例</h3><p>了解一个开源软件，从官方实例入手再好不过了，因此下面的例子将会围绕官方仓库中的实例展开。所以在开始之前，你需要安装并配置以下工具：</p><ul><li><code>Docker</code></li><li><code>Docker Compose</code></li><li><code>Git</code></li><li><code>Curl</code></li></ul><p>我们将会使用 <code>Docker</code> 和 <code>Docker Compose</code> 来构建和运行几个 <code>Envoy</code> 示例服务，并用 <code>Curl</code> 来检测 <code>Envoy</code> 示例服务是否在运行。</p><h4 id="运行-envoy">运行 Envoy</h4><p>首先克隆 <code>Envoy</code> 官方仓库到本地,并定位到 <code>envoy/examples/front-proxy</code> 文件夹。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;envoyproxy&#x2F;envoy</span><br><span class="line">$ cd envoy&#x2F;examples&#x2F;front-proxy</span><br></pre></td></tr></table></figure><p><code>front-proxy</code> 文件夹中的服务是一个用 <code>Flask</code> 实现的后端服务，入口文件在 <code>service.py</code> 文件里面。<code>Envoy</code> 作为一个 <code>Sidecar</code> 部件，将与 <code>service.py</code> 在同一个容器中运行，并由 <code>docker-compose,.yaml</code> 文件配置。</p><p>前端代理比后端服务更简单，它使用配置文件 <code>front-envoy.yaml</code> 来运行 <code>Envoy</code>。<code>Dockerfile-frontenvoy</code> 文件则是 <code>front-envoy</code> 的 <code>Dockerfile</code>。</p><p>如果你之前没有接触过 <code>Docker</code> 的话，你可以使用以下命令在本地构建并运行 <code>front-proxy</code> 的 <code>Docker</code> 镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;path&#x2F;to&#x2F;envoy&#x2F;examples&#x2F;front-proxy</span><br><span class="line">$ docker-compose up --build -d</span><br></pre></td></tr></table></figure><p>其中的 <code>--build</code> 表示构建镜像， <code>-d</code> 表示在后台运行所有 <code>docker-compose</code> 配置文件中定义的镜像，具体可参考 <code>Docker</code> 相关文档。</p><p>命令运行成功后，将会启动一个前端代理和两个服务实例：<code>service1</code> 和 <code>service2</code>。你可以通过以下命令来验证容器是否正常运行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose ps</span><br></pre></td></tr></table></figure><p>正常的话会返回以下内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ front-proxy git:(master) docker-compose ps</span><br><span class="line">          Name                         Command               State                            Ports</span><br><span class="line">----------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">front-proxy_front-envoy_1   &#x2F;usr&#x2F;bin&#x2F;dumb-init -- &#x2F;bin ...   Up      10000&#x2F;tcp, 0.0.0.0:8000-&gt;80&#x2F;tcp, 0.0.0.0:8001-&gt;8001&#x2F;tcp</span><br><span class="line">front-proxy_service1_1      &#x2F;bin&#x2F;sh -c &#x2F;usr&#x2F;local&#x2F;bin&#x2F; ...   Up      10000&#x2F;tcp, 80&#x2F;tcp</span><br><span class="line">front-proxy_service2_1      &#x2F;bin&#x2F;sh -c &#x2F;usr&#x2F;local&#x2F;bin&#x2F; ...   Up      10000&#x2F;tcp, 80&#x2F;tcp</span><br></pre></td></tr></table></figure><h4 id="测试服务是否连通">测试服务是否连通</h4><p>你可以使用 <code>curl</code> 或者浏览器来测试服务是否在正常运行</p><p>浏览器中输入 <code>http://localhost:8000/service/1</code> 或者使用以下命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl http:&#x2F;&#x2F;localhost:8000&#x2F;service&#x2F;1</span><br></pre></td></tr></table></figure><p>如果返回结果是像下面这样，则表示 <code>service1</code> 的 <code>Envoy</code> 服务正常运行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello from behind Envoy (service 1)! hostname: a841ffceafd0 resolvedhostname: 172.18.0.4</span><br></pre></td></tr></table></figure><p>你也可以用同样的方法测试 <code>service 2</code> 的服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl http:&#x2F;&#x2F;localhost:8000&#x2F;service&#x2F;2</span><br></pre></td></tr></table></figure><p>返回的结果和 <code>service 1</code> 类似。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello from behind Envoy (service 2)! hostname: e83b35c6f4fe resolvedhostname: 172.18.0.3 。</span><br></pre></td></tr></table></figure><h4 id="envoy-配置">Envoy 配置</h4><p>下面我们先简单看一下 <code>Envoy</code> 的静态配置信息，之后再继续看 <code>Demo</code> 中的动态配置信息。</p><p>我们先从 <code>front-envoy.yml</code> 入手。打开文件之后，我们会发现这个 <code>yaml</code> 有两个最高的层级，分别是 <code>static_resources</code> 和 <code>admin</code> 。<code>admin</code> 的内容相对比较简单，总共只有六行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">   access_log_path: &quot;&#x2F;dev&#x2F;null&quot;</span><br><span class="line">   address:</span><br><span class="line">     socket_address:</span><br><span class="line">       address: 0.0.0.0</span><br><span class="line">       port_value: 8001</span><br></pre></td></tr></table></figure><p>其中 <code>access_log_path</code> 字段值是 <code>/dev/null</code>，其含义是 <code>admin</code> 服务的请求日志将不会被保存。生产环境中可自行将目标目录指定到需要的地方。<code>address</code> 和 <code>port_value</code> 字段分别表示 <code>admin server</code> 运行的 <code>IP</code> 端口。</p><p><code>static_resource</code> 的内容定义了非动态管理的集群（<code>Cluster</code>）和监听器（<code>Listener</code>）相关配置。集群是 <code>Envoy</code> 连接到的一组逻辑上相似的上游主机，一个集群是一组被定义的 <code>ip/port</code> 集合，<code>Envoy</code> 将借此实现负载均衡。监听器是一组被定义的网络地址，它是可以由下游客户端连接的命名网络位置（例如，端口、<code>Unix</code> 域套接字等）。监听器是服务(程序)监听者，就是真正干活的，客户端可借此连接至服务。</p><p><code>front proxy</code> 中只有一个监听器，监听器中除了 <code>socket_address</code> 之外还有一个字段是 <code>filter_chains</code>，<code>Envoy</code> 通过此字段来管理 <code>HTTP</code> 的连接和过滤。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">listeners:</span><br><span class="line">- address:</span><br><span class="line">    socket_address:</span><br><span class="line">      address: 0.0.0.0</span><br><span class="line">      port_value: 80</span><br><span class="line">  filter_chains:</span><br><span class="line">  - filters:</span><br><span class="line">    - name: envoy.http_connection_manager</span><br><span class="line">      config:</span><br><span class="line">        codec_type: auto</span><br><span class="line">        stat_prefix: ingress_http</span><br><span class="line">        route_config:</span><br><span class="line">          name: local_route</span><br></pre></td></tr></table></figure><p>其中有个配置选项是 <code>virtual_hosts</code>，该选项在 <code>HTTP</code> 连接管理过滤器中用作定义虚拟主机，并通过正则过滤允许访问服务的域名。路由也在其中配置，例子中将 <code>/service/1</code> 和 <code>/service/2</code> 的请求分别转发到了其相应的集群中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">virtual_hosts:</span><br><span class="line">- name: backend</span><br><span class="line">  domains:</span><br><span class="line">  - &quot;*&quot;</span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      prefix: &quot;&#x2F;service&#x2F;1&quot;</span><br><span class="line">    route:</span><br><span class="line">      cluster: service1</span><br><span class="line">  - match:</span><br><span class="line">      prefix: &quot;&#x2F;service&#x2F;2&quot;</span><br><span class="line">    route:</span><br><span class="line">      cluster: service2</span><br></pre></td></tr></table></figure><p>接下来我们继续看静态集群的配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">clusters:</span><br><span class="line">- name: service1</span><br><span class="line">  connect_timeout: 0.25s</span><br><span class="line">  type: strict_dns</span><br><span class="line">  lb_policy: round_robin</span><br><span class="line">  http2_protocol_options: &#123;&#125;</span><br><span class="line">  hosts:</span><br><span class="line">  - socket_address:</span><br><span class="line">      address: service1</span><br><span class="line">      port_value: 80</span><br><span class="line">- name: service2</span><br><span class="line">  connect_timeout: 0.25s</span><br><span class="line">  type: strict_dns</span><br><span class="line">  lb_policy: round_robin</span><br><span class="line">  http2_protocol_options: &#123;&#125;</span><br><span class="line">  hosts:</span><br><span class="line">  - socket_address:</span><br><span class="line">      address: service2</span><br><span class="line">      port_value: 80</span><br></pre></td></tr></table></figure><p>在静态集群的配置内容中，我们可以配置超时时间、熔断器、服务发现等等内容。集群由一系列端点 (<code>Endpoints</code>) 组成，端点就是一组服务集群中可以响应访问请求的网络地址。在上面的例子中，端点标准定义成 <code>DNS</code> ，除此之外，端点可以直接被定义成 <code>Socket</code> 地址，或者是可动态读取的服务发现机制。</p><p><strong>尝试动手修改配置</strong></p><p>我们可以在本地尝试自己修改配置，重建镜像，测试修改后的配置。监听过滤器是 <code>Envoy</code> 为监听器提供的附加功能。比方说，想要增加访问日志到我们的 <code>HTTP</code> 过滤器中，只要增加 <code>access_log</code> 字段到配置文件中即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- filters:</span><br><span class="line">  - name: envoy.http_connection_manager</span><br><span class="line">    config:</span><br><span class="line">      codec_type: auto</span><br><span class="line">      stat_prefix: ingress_http</span><br><span class="line">      access_log:</span><br><span class="line">        - name: envoy.file_access_log</span><br><span class="line">          config:</span><br><span class="line">            path: &quot;&#x2F;var&#x2F;log&#x2F;access.log&quot;</span><br><span class="line">      route_config:</span><br></pre></td></tr></table></figure><p>修改之后，先通过 <code>docker-compose down</code> 命令关闭 <code>docker-compose</code> 容器组，然后使用 <code>docker-compose up --build -d</code> 命令重新构建镜像并运行容器组即可。</p><p>为了验证我们新增的 <code>access_log</code> 字段是否生效，我们可以模拟几次请求。然后通过命令 <code>docker-compose exec front-envoy /bin/bash</code> 手动进入容器内部查看访问日志是否在相应的目录中，你会看到 <code>/var/log/access.log</code> 文件记录着你的请求结果。</p><h4 id="管理页面">管理页面</h4><p>Envoy 的一大特色是内置了管理页面，你可以通过 <code>http://localhost:8001</code> 访问。管理页面中 <code>/cluster</code> 菜单展示了上游 (<code>Upstream</code>) 集群端口的统计内容，<code>stats</code> 菜单则显示了更多端口的统计内容。</p><p><img src="https://i.loli.net/2019/10/23/TowFauBL4Ae6Yz8.png" alt=""></p><p>更多管理页面的内容你可以直接访问帮助页面 <code>http://localhost:8001/help</code> 来查看。</p><h3 id="请求处理流程">请求处理流程</h3><p><code>Envoy</code> 中对访问请求的处理流程大致如下，先将请求数据预处理，转成 <code>Envoy</code> 中的 <code>Filter</code>， 读写请求的 <code>filter</code> 分别是 <code>ReadFilter</code> 和 <code>WriteFiler</code>，对每个网络层也有各自的 <code>filter</code> ，<code>TCP</code> 的是 <code>TcpProxyFilter</code>, <code>HTTP</code> 的是 <code>ConnectionManager</code>，都由读 <code>filter ReadFilter</code> 继承而来。各个 <code>filter</code> 预处理完成之后就会组织成上面示例配置文件中有提到的 <code>FilterChain</code>， 收到 <code>FilterChain</code> 之后会将其路由到指定的集群中，并根据负载均衡获取到相应的地址，然后将请求转发出去。</p><h3 id="进阶实例">进阶实例</h3><p>接下来的实验主要以动态配置的方式来实现一个简单的需求，首先描述一下需求场景：有两个微服务，一个是 <code>envoy-web</code>，一个 <code>envoy-server</code>。</p><ul><li><p><code>envoy-web</code> 相当于下图中的 <code>front-envoy</code> 作为对外访问的入口。</p></li><li><p><code>envoy-server</code> 相当于下图中的 <code>service_1</code> 和 <code>service_2</code>，是内部的一个微服务，部署 <code>2</code> 个实例。</p></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/12196676-2a45b1388924b33a.png" alt=""></p><p><code>envoy-server</code> 有 3 个 <code>API</code>，分别是 <code>/envoy-server/hello</code>、<code>/envoy-server/hi</code>、<code>/envoy-server/self</code>，目的是测试 <code>Envoy</code> 对于流入 <code>envoy-server</code> 的流量控制，对外只允许访问 <code>/envoy-server/hello</code> 和 <code>/envoy-server/hi</code> 两个 <code>API</code>，<code>/envoy-server/self</code> 不对外暴露服务。</p><p><code>envoy-web</code> 也有 3 个 <code>API</code>，分别是 <code>/envoy-web/hello</code>、<code>/envoy-web/hi</code>、<code>/envoy-web/self</code>，目的是测试 <code>Envoy</code> 对于流出 <code>envoy-web</code> 的流量控制，出口流量只允许 <code>/envoy-web/hello</code> 和 <code>/envoy-web/self</code> 两个访问出去。</p><p>最终的实验：外部只能访问 <code>envoy-web</code> 暴露的接口</p><ul><li><p>当访问 <code>/envoy-web/hello</code> 接口时返回 <code>envoy-server</code> 的 <code>/hello</code> 接口的数据，表示 <code>envoy-web</code> 作为客户端访问 <code>envoy-server</code> 返回服务响应的结果。</p></li><li><p>当访问 <code>/envoy-web/hi</code> 接口时，<code>envoy-web</code> 的 <code>envoy</code> 拦截住出口流量，限制 <code>envoy-web</code> 向 <code>envoy-server</code> 发送请求，对于前端用户返回 <code>mock</code> 数据。</p></li><li><p>当访问 <code>/envoy-web/self</code> 接口时，<code>envoy-web</code> 出口流量可以到达 <code>envoy-server</code> 容器，但是 <code>envoy-server</code> 在入口流量处控制住了此次请求，拒绝访问 <code>envoy-server</code>服务，对于前端用户返回 <code>mock</code> 数据。</p></li></ul><h3 id="静态配置">静态配置</h3><p>首先，以静态配置的方式先实现功能。</p><h4 id="编写服务代码">编写服务代码</h4><p>服务代码分为 <code>envoy-web</code> 和 <code>envoy-server</code> 两个服务，采用 <code>SpringBoot</code> 的方式，下面记录一些重要的代码片段。</p><ul><li>envoy-server</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class HelloRest &#123;</span><br><span class="line">    private static final Logger LOGGER &#x3D; LoggerFactory.getLogger(HelloRest.class);</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-server&#x2F;hello&quot;)</span><br><span class="line">    public String hello() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request from remote, send response, say hello&quot;);</span><br><span class="line">        return &quot;hello&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-server&#x2F;hi&quot;)</span><br><span class="line">    public String hi() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request from remote, send response, say hi&quot;);</span><br><span class="line">        return &quot;hi&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-server&#x2F;self&quot;)</span><br><span class="line">    public String self() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request from remote, send response, say self&quot;);</span><br><span class="line">        return &quot;self&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>envoy-web</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    private static final Logger LOGGER &#x3D; LoggerFactory.getLogger(HelloController.class);</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private RestTemplate template;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;local&quot;)</span><br><span class="line">    public String sayLocal() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request, send response&quot;);</span><br><span class="line">        return &quot;local&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;hello&quot;)</span><br><span class="line">    public String sayHello() &#123;</span><br><span class="line">        String url &#x3D; &quot;http:&#x2F;&#x2F;127.0.0.1:10000&#x2F;envoy-server&#x2F;hello&quot;;</span><br><span class="line">        LOGGER.info(&quot;get request, send rest template to &#123;&#125;&quot;, url);</span><br><span class="line">        return getRemote(url, &quot;mock value for hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;hi&quot;)</span><br><span class="line">    public String sayHi() &#123;</span><br><span class="line">        String url &#x3D; &quot;http:&#x2F;&#x2F;127.0.0.1:10000&#x2F;envoy-server&#x2F;hi&quot;;</span><br><span class="line">        LOGGER.info(&quot;get request, send rest template to &#123;&#125;&quot;, url);</span><br><span class="line">        return getRemote(url, &quot;mock value for hi&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;self&quot;)</span><br><span class="line">    public String saySelf() &#123;</span><br><span class="line">        String url &#x3D; &quot;http:&#x2F;&#x2F;127.0.0.1:10000&#x2F;envoy-server&#x2F;self&quot;;</span><br><span class="line">        LOGGER.info(&quot;get request, send rest template to &#123;&#125;&quot;, url);</span><br><span class="line">        return getRemote(url, &quot;mock value for self&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private String getRemote(String url, String mock) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            ResponseEntity&lt;String&gt; response &#x3D; template.getForEntity(url, String.class);</span><br><span class="line">            return response.getBody();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            LOGGER.error(&quot;error happens: &#123;&#125;&quot;, e);</span><br><span class="line">            return mock;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注：为简化起见，代码只是介绍对出入流量的控制，直接在 <code>envoy-web</code> 上访问了本地的 <code>Envoy</code> 端口进行转发流量，实际代码中可以用服务名:服务端口号访问，而此时为了使得 <code>Envoy</code> 仍然可以拦截入和出的流量，可以配置 <code>Iptables</code>（<code>Istio</code> 的实现中也是使用了 <code>Iptables</code>）。</p></blockquote><h4 id="编写配置文件">编写配置文件</h4><p>针对不同的服务，也配置了两份 <code>envoy.yaml</code> 配置文件。</p><ul><li>envoy-server</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 0.0.0.0, port_value: 9900 &#125;</span><br><span class="line">static_resources:</span><br><span class="line">  listeners:</span><br><span class="line">  - name: listener_ingress</span><br><span class="line">    address:</span><br><span class="line">      socket_address: &#123; address: 0.0.0.0, port_value: 10000 &#125;</span><br><span class="line">    filter_chains:</span><br><span class="line">    - filters:</span><br><span class="line">      - name: envoy.http_connection_manager</span><br><span class="line">        config:</span><br><span class="line">          stat_prefix: ingress_http</span><br><span class="line">          codec_type: AUTO</span><br><span class="line">          route_config:</span><br><span class="line">            name: local_route</span><br><span class="line">            virtual_hosts:</span><br><span class="line">            - name: local_service</span><br><span class="line">              domains: [&quot;*&quot;]</span><br><span class="line">              routes:</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;hello&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_server &#125;</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;hi&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_server &#125;</span><br><span class="line">          http_filters:</span><br><span class="line">          - name: envoy.router</span><br><span class="line">  clusters:</span><br><span class="line">  - name: cluster_server</span><br><span class="line">    connect_timeout: 0.5s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts: </span><br><span class="line">    - &#123; socket_address: &#123; address: 127.0.0.1, port_value: 8081 &#125;&#125;</span><br></pre></td></tr></table></figure><ul><li>envoy-web</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 0.0.0.0, port_value: 9900 &#125;</span><br><span class="line">static_resources:</span><br><span class="line">  listeners:</span><br><span class="line">  - name: listener_ingress</span><br><span class="line">    address:</span><br><span class="line">      socket_address: &#123; address: 0.0.0.0, port_value: 10000 &#125;</span><br><span class="line">    filter_chains:</span><br><span class="line">    - filters:</span><br><span class="line">      - name: envoy.http_connection_manager</span><br><span class="line">        config:</span><br><span class="line">          stat_prefix: ingress_http</span><br><span class="line">          codec_type: AUTO</span><br><span class="line">          route_config:</span><br><span class="line">            name: local_route</span><br><span class="line">            virtual_hosts:</span><br><span class="line">            - name: local_service</span><br><span class="line">              domains: [&quot;*&quot;]</span><br><span class="line">              routes:</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-web&#x2F;&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_ingress &#125;</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;hello&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_egress &#125;</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;self&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_egress &#125;</span><br><span class="line">          http_filters:</span><br><span class="line">          - name: envoy.router</span><br><span class="line">  clusters:</span><br><span class="line">  - name: cluster_ingress</span><br><span class="line">    connect_timeout: 0.5s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts:</span><br><span class="line">    - &#123; socket_address: &#123; address: 127.0.0.1, port_value: 8080 &#125;&#125;</span><br><span class="line">  - name: cluster_egress</span><br><span class="line">    connect_timeout: 0.5s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts:</span><br><span class="line">    - &#123; socket_address: &#123; address: 172.17.0.2, port_value: 10000 &#125;&#125;</span><br><span class="line">    - &#123; socket_address: &#123; address: 172.17.0.3, port_value: 10000 &#125;&#125;</span><br></pre></td></tr></table></figure><h4 id="启动测试">启动测试</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># envoy-server1</span><br><span class="line">$ docker run -d -v &#96;pwd&#96;&#x2F;envoy-server.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy-server1 envoyproxy&#x2F;envoy:latest &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --service-cluster envoy-server --service-node 1 -c &#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --v2-config-only</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy-server1 --name envoy-server1 envoy-server:1.1</span><br><span class="line"></span><br><span class="line"># envoy-server2</span><br><span class="line">$ docker run -d -v &#96;pwd&#96;&#x2F;envoy-server.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy-server2 envoyproxy&#x2F;envoy:latest &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --service-cluster envoy-server --service-node 2 -c &#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --v2-config-only</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy-server2 --name envoy-server2 envoy-server:1.1</span><br><span class="line"></span><br><span class="line"># envoy-web</span><br><span class="line">$ docker run -d -p 10000:10000 -v &#96;pwd&#96;&#x2F;envoy-web.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy-web envoyproxy&#x2F;envoy:latest &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --service-cluster envoy-web --service-node 1 -c &#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --v2-config-only</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy-web --name envoy-web envoy-web:1.1</span><br></pre></td></tr></table></figure><p>当容器部署完毕之后，可以直接访问以下 3 个 URL ，其中 hi 和 self 的访问返回的是 mock 数据，虽然同为 mock 数据，但是这两个 <code>URL</code> 其实是不相同的，一个是在 <code>Envoy</code> 出口流量处做的控制，一个是在 <code>Envoy</code> 入口流量处做的控制，其中的细节可以再去品味品味。</p><p><img src="https://upload-images.jianshu.io/upload_images/12196676-83ac7de7c28ad6a1.png" alt=""></p><h3 id="动态配置">动态配置</h3><p>动态配置需要实现发现服务，通过 <code>GRPC</code> 的方式获取相应。</p><p>动态的配置文件在前面的内容中已经有过介绍，最重要的是需要提供一个发现服务，对外提供 <code>XDS</code> 服务，下面以其中的一个 <code>LDS</code> 作为介绍，其他 <code>XDS</code> 实现类似。</p><p>服务端：既然作为服务，就需要对外提供接口服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">public class GrpcService &#123;</span><br><span class="line">    private Server server;</span><br><span class="line">    private static final int PORT &#x3D; 50051;</span><br><span class="line"></span><br><span class="line">    private void start() throws IOException &#123;</span><br><span class="line">        server &#x3D; ServerBuilder.forPort(PORT)</span><br><span class="line">                .addService(new LdsService())</span><br><span class="line">                .addService(new CdsService())</span><br><span class="line">                .addService(new RdsService())</span><br><span class="line">                .addService(new EdsService())</span><br><span class="line">                .addService(new AdsService())</span><br><span class="line">                .build()</span><br><span class="line">                .start();</span><br><span class="line">        System.err.println(&quot;Server started, listening on &quot; + PORT);</span><br><span class="line">        Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123;</span><br><span class="line">            System.err.println(&quot;*** shutting down gRPC server since JVM is shutting down&quot;);</span><br><span class="line">            GrpcService.this.stop();</span><br><span class="line">            System.err.println(&quot;*** server shut down&quot;);</span><br><span class="line">        &#125;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private void stop() &#123;</span><br><span class="line">        if (server !&#x3D; null) &#123;</span><br><span class="line">            server.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private void blockUntilShutdown() throws InterruptedException &#123;</span><br><span class="line">        if (server !&#x3D; null) &#123;</span><br><span class="line">            server.awaitTermination();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws IOException, InterruptedException &#123;</span><br><span class="line">        final GrpcService server &#x3D; new GrpcService();</span><br><span class="line">        server.start();</span><br><span class="line">        server.blockUntilShutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>XDS</code> 通过 <code>GRPC</code> 生成服务端的 <code>stub</code> 文件，实现 <code>LdsServer</code> 继承自 <code>ListenerDiscoveryServiceGrpc.ListenerDiscoveryServiceImplBase</code>，需要实现 <code>streamListeners</code> 方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public class LdsService extends ListenerDiscoveryServiceGrpc.ListenerDiscoveryServiceImplBase &#123;</span><br><span class="line">    private static final Logger LOGGER &#x3D; LogManager.getLogger();</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public StreamObserver&lt;Discovery.DiscoveryRequest&gt; streamListeners(StreamObserver&lt;Discovery.DiscoveryResponse&gt; responseObserver) &#123;</span><br><span class="line">        return new StreamObserver&lt;Discovery.DiscoveryRequest&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void onNext(Discovery.DiscoveryRequest request) &#123;</span><br><span class="line">                XdsHelper.getInstance().buildAndSendResult(request, responseObserver);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onError(Throwable throwable) &#123;</span><br><span class="line">                LOGGER.warn(&quot;Error happens&quot;, throwable);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onCompleted() &#123;</span><br><span class="line">                LOGGER.info(&quot;LdsService completed&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>至此，我们就基本介绍完 <code>Envoy</code> 使用的一些常见的使用方法，在实现的时候也会有其他一些细节需要注意。比如，<code>Envoy</code> 作为一个服务之间网络请求的代理，如何拦截全部的入和出流量？</p><p><code>Istio</code> 给了一个很好的解决方案，就是通过 <code>Iptables</code>。它会使用一个特定的 <code>uid</code>（默认 1337）用户运行 <code>Envoy</code> 进程，<code>Iptables</code> 对于 <code>1337</code> 用户的流量不做拦截。下面就是参考 <code>Istio</code> 的 <code>iptables.sh</code> 做的一个实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">uname&#x3D;envoy</span><br><span class="line">uid&#x3D;1337</span><br><span class="line">iptalbes -t nat -F</span><br><span class="line">iptables -t nat -I PREROUTING -p tcp -j REDIRECT --to-ports 10000</span><br><span class="line">iptables -t nat -N ENVOY_OUTPUT</span><br><span class="line">iptables -t nat -A OUTPUT -p tcp -j ENVOY_OUTPUT</span><br><span class="line">iptables -t nat -A ENVOY_OUTPUT -p tcp -d 127.0.0.1&#x2F;32 -j RETURN</span><br><span class="line">iptables -t nat -A ENVOY_OUTPUT -m owner --uid-owner $&#123;uid&#125; -j RETURN</span><br><span class="line">iptables -t nat -A ENVOY_OUTPUT -p tcp -j REDIRECT --to-ports 10000</span><br></pre></td></tr></table></figure><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://holajiawei.com/envoy/" target="_blank" rel="noopener">https://holajiawei.com/envoy/</a></p></li><li><p><a href="https://www.lijiaocn.com/soft/envoy/" target="_blank" rel="noopener">https://www.lijiaocn.com/soft/envoy/</a></p></li><li><p><a href="https://www.jianshu.com/p/90f9ee98ce70" target="_blank" rel="noopener">https://www.jianshu.com/p/90f9ee98ce70</a></p></li><li><p><a href="https://github.com/wellls/blog/issues/47" target="_blank" rel="noopener">https://github.com/wellls/blog/issues/47</a></p></li><li><p><a href="https://jimmysong.io/posts/envoy-as-front-proxy/" target="_blank" rel="noopener">https://jimmysong.io/posts/envoy-as-front-proxy/</a></p></li><li><p><a href="https://www.yangcs.net/posts/run-envoy-on-your-laptop/" target="_blank" rel="noopener">https://www.yangcs.net/posts/run-envoy-on-your-laptop/</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Envoy&quot;&gt;什么是 Envoy&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 是一款 &lt;code&gt;CNCF&lt;/code&gt; 旗下的开源项目，由 &lt;code&gt;Lyft&lt;/code&gt; 开源。&lt;code&gt;Envoy&lt;/code&gt; 采用 C++ 实现，是面向 &lt;code&gt;Service Mesh&lt;/code&gt; 的高性能网络代理服务。它与应用程序并行运行，通过以平台无关的方式提供通用功能来抽象网络。当基础架构中的所有服务流量都通过 Envoy 网格时，通过一致的可观测性，很容易地查看问题区域，调整整体性能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 也是 &lt;code&gt;Istio Service Mesh&lt;/code&gt; 中默认的 &lt;code&gt;Data Plane&lt;/code&gt;，本文我们将讲解 &lt;code&gt;Envoy&lt;/code&gt; 的一些基本概念，并采用一些实例来介绍如何在本地环境中快速使用 &lt;code&gt;Envoy&lt;/code&gt; 作为 &lt;code&gt;Service Mesh&lt;/code&gt; 的数据平面，以帮助读者理解 &lt;code&gt;Istio&lt;/code&gt; 的 &lt;code&gt;Data Panel&lt;/code&gt; 层实现。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;官网：&lt;a href=&quot;https://www.envoyproxy.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.envoyproxy.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Envoy-特性&quot;&gt;Envoy 特性&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;整体架构&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/4483e99egy1ftn7wet57fj233f1utag1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;进程无关架构&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 是一个自组织的模块，与应用 &lt;code&gt;Server&lt;/code&gt; 并无直接依赖。所有的 &lt;code&gt;Envoy&lt;/code&gt; 构建了一个透明的服务网格 &lt;code&gt;Service Mesh&lt;/code&gt;，处于其中的应用只需要简单的与本地的 &lt;code&gt;Envoy&lt;/code&gt; 进行收发信息，并不需要关注整个网络拓扑。这种架构对于应用通信有两大好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 可以让任何的编程语言编写的服务通信，协同工作，&lt;code&gt;Envoy&lt;/code&gt; 帮你屏蔽了服务之间的沟壑。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任何曾经在大型微服务开发中工作过的人都知道发布一个库更新是多么的痛苦。&lt;code&gt;Envoy&lt;/code&gt; 可以以一种透明的方式快速的发布更新整个基础架构中的版本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Envoy" scheme="https://www.hi-linux.com/tags/Envoy/"/>
    
  </entry>
  
  <entry>
    <title>如何通过 Alertmanager 有效的给 Prometheus 添加一个警报系统</title>
    <link href="https://www.hi-linux.com/posts/23179.html"/>
    <id>https://www.hi-linux.com/posts/23179.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.545Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>警报是监控系统中必不可少的一块, 当然了, 也是最难搞的一块. 我们乍一想, 警报似乎很简单一件事:</p><blockquote><p>假如发生了异常情况, 发送或邮件/消息通知给某人或某频道</p></blockquote><p>一把梭搞起来之后, 就不免有一些小麻烦:</p><ul><li><p>这个啊…一天中总有那么几次波动, 也难修难查了, 算了算了不看了</p></li><li><p>警报太多了, 实在看不过来, 屏蔽/归档/放生吧…</p></li><li><p>有毒吧, 这个阈值也太低了</p></li><li><p>卧槽, 这些警报啥意思啊, 发给我干嘛啊?</p></li><li><p>卧槽卧槽卧槽, 怎么一下子几十百来条警报, 哦…原来网络出问题了全崩了</p></li></ul><p>到最后我们还能总结出一个奇怪的规律:</p><blockquote><p>这世界上只有两种警报，一种是疯狂报警但是没有卵用完全没人看的警报，一种是非常有效大家都想看但在用户反馈前从来都报不出来的警报。—— 鲁迅(</p></blockquote><p>玩笑归玩笑，但至少我们能看出，警报不是一个简单的计算+通知系统。只是，”做好警报”这件事本身是个综合问题，代码能解决的也只是其中的一小部分，更多的事情要在组织、人事和管理上去做。我掰不出那么有深度的文章，这篇文章就专注一点，只讲代码部分里的通知，也就是 Prometheus 生态中的 Alertmanager 这个组件。</p><a id="more"></a><h2 id="为什么要-alertmanager">为什么要 Alertmanager？</h2><p>我们先介绍一点背景知识，Prometheus 生态中的警报是在 Prometheus Server 中计算警报规则(Alert Rule)并产生的，而所谓计算警报规则，其实就是周期性地执行一段 PromQL，得到的查询结果就是警报，比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node_load5 &gt; 20</span><br></pre></td></tr></table></figure><p>这个 PromQL 会查出所有”在最近一次采样中，5分钟平均 Load 大于 20”的时间序列。这些序列带上它们的标签就被转化为警报。</p><p>只是，当 Prometheus Server 计算出一些警报后，它自己并没有能力将这些警报通知出去，只能将警报推给 Alertmanager，由 Alertmanager 进行发送。</p><p>这个切分，一方面是出于单一职责的考虑，让 Prometheus “do one thing and do it well”, 另一方面则是因为警报发送确实不是一件”简单”的事，需要一个专门的系统来做好它。可以这么说，Alertmanager 的目标不是简单地”发出警报”，而是”发出高质量的警报”。它提供的高级功能包括但不限于：</p><ul><li><p>Go Template 渲染警报内容；</p></li><li><p>管理警报的重复提醒时机与消除后消除通知的发送；</p></li><li><p>根据标签定义警报路由，实现警报的优先级、接收人划分，并针对不同的优先级和接收人定制不同的发送策略；</p></li><li><p>将同类型警报打包成一条通知发送出去，降低警报通知的频率；</p></li><li><p>支持静默规则: 用户可以定义一条静默规则，在一段时间内停止发送部分特定的警报，比如已经确认是搜索集群问题，在修复搜索集群时，先静默掉搜索集群相关警报；</p></li><li><p>支持”抑制”规则(Inhibition Rule): 用户可以定义一条”抑制”规则，规定在某种警报发生时，不发送另一种警报，比如在”A 机房网络故障”这条警报发生时，不发送所有”A 机房中的警报”；</p></li></ul><p>假如你很忙，那么读到这里就完全 OK 了，反正这类文章最大的作用就是让我们”知道有 X 这回事，大概了解有啥特性，当有需求匹配时，能想到试试看 X 合不合适“，其中 X = Alertmanager。当然，假如你是个好奇宝宝，那么还可以看看下面的解析。</p><h2 id="alertmanager-内部架构">Alertmanager 内部架构</h2><p>先看官方文档中的架构图：</p><p><img src="https://aleiwu.com/img/alertmanager/alertmanager.png" alt=""></p><ol><li><p>从左上开始，Prometheus 发送的警报到 Alertmanager;</p></li><li><p>警报会被存储到 AlertProvider 中，Alertmanager 的内置实现就是包了一个 map，也就是存放在本机内存中，这里可以很容易地扩展其它 Provider;</p></li><li><p>Dispatcher 是一个单独的 goroutine，它会不断到 AlertProvider 拉新的警报，并且根据 YAML 配置的 Routing Tree 将警报路由到一个分组中;</p></li><li><p>分组会定时进行 flush (间隔为配置参数中的 group_interval), flush 后这组警报会走一个 Notification Pipeline 链式处理;</p></li><li><p>Notification Pipeline 为这组警报确定发送目标，并执行抑制逻辑，静默逻辑，去重逻辑，发送与重试逻辑，实现警报的最终投递;</p></li></ol><p>下面就分开讲一讲核心的两块：</p><ol><li><p>Dispatcher 中的 Routing Tree 的实现与设计意图</p></li><li><p>Notification Pipeline 的实现与设计意图</p></li></ol><h3 id="routing-tree">Routing Tree</h3><p>Routing Tree 的是一颗多叉树，节点的数据结构定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 节点包含警报的路由逻辑</span><br><span class="line">type Route struct &#123;</span><br><span class="line">    &#x2F;&#x2F; 父节点</span><br><span class="line">    parent *Route</span><br><span class="line">    &#x2F;&#x2F; 节点的配置，下文详解</span><br><span class="line">    RouteOpts RouteOpts</span><br><span class="line">    &#x2F;&#x2F; Matchers 是一组匹配规则，用于判断 Alert 与当前节点是否匹配</span><br><span class="line">    Matchers types.Matchers</span><br><span class="line">    &#x2F;&#x2F; 假如为 true, 那么 Alert 在匹配到一个节点后，还会继续往下匹配</span><br><span class="line">    Continue bool</span><br><span class="line">    &#x2F;&#x2F; 子节点</span><br><span class="line">    Routes []*Route</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体的处理代码很简单，深度优先搜索：警报从 root 开始匹配（root 默认匹配所有警报），然后根据节点中定义的 Matchers 检测警报与节点是否匹配，匹配则继续往下搜索，默认情况下第一个”最深”的 match (也就是 DFS 回溯之前的最后一个节点)会被返回。特殊情况就是节点配置了 Continue=true，这时假如这个节点匹配上了，那不会立即返回，而是继续搜索，用于支持警报发送给多方这种场景（比如”抄送”)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 深度优先搜索</span><br><span class="line">func (r *Route) Match(lset model.LabelSet) []*Route &#123;</span><br><span class="line">    if !r.Matchers.Match(lset) &#123;</span><br><span class="line">    return nil</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    var all []*Route</span><br><span class="line">    for _, cr :&#x3D; range r.Routes &#123;</span><br><span class="line">        &#x2F;&#x2F; 递归调用子节点的 Match 方法</span><br><span class="line">        matches :&#x3D; cr.Match(lset)</span><br><span class="line"></span><br><span class="line">        all &#x3D; append(all, matches...)</span><br><span class="line"></span><br><span class="line">        if matches !&#x3D; nil &amp;&amp; !cr.Continue &#123;</span><br><span class="line">          break</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 假如没有任何节点匹配上，那就匹配根节点</span><br><span class="line">    if len(all) &#x3D;&#x3D;0 &#123;</span><br><span class="line">        all &#x3D; append(all, r)</span><br><span class="line">    &#125;</span><br><span class="line">    return all</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么要设计一个复杂的 Routing Tree 逻辑呢？我们看看 Prometheus 官方的配置例子： 为了简化编写，Alertmanager 的设计是根节点的所有参数都会被子节点继承（除非子节点重写了这个参数）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">route:</span><br><span class="line">  # 根节点的警报会发送给默认的接收组</span><br><span class="line">  # 该节点中的警报会按’cluster’和’alertname’做 Group，每个分组中最多每5分钟发送一条警报，同样的警报最多4小时发送一次</span><br><span class="line">  receiver:’default-receiver’</span><br><span class="line">  group_wait: 30s</span><br><span class="line">  group_interval: 5m</span><br><span class="line">  repeat_interval: 4h</span><br><span class="line">  group_by: [cluster, alertname]</span><br><span class="line">  # 没有匹配到子节点的警报，会默认匹配到根节点上</span><br><span class="line">  # 接下来是子节点的配置：</span><br><span class="line">  routes:</span><br><span class="line">    # 所有 service 字段为 mysql 或 cassandra 的警报，会发送到’database-pager’这个接收组</span><br><span class="line">    # 由于继承逻辑，这个节点中的警报仍然是按’cluster’和’alertname’做 Group 的</span><br><span class="line">  - receiver:’database-pager’</span><br><span class="line">    group_wait: 10s</span><br><span class="line">    match_re:</span><br><span class="line">    service: mysql|cassandra</span><br><span class="line">    # 所有 team 字段为 fronted 的警报，会发送到’frontend-pager’这个接收组</span><br><span class="line">    # 很重要的一点是，这个组中的警报是按’product’和’environment’做分组的，因为’frontend’面向用户，更关心哪个’产品’的什么’环境’出问题了</span><br><span class="line">  - receiver:’frontend-pager’</span><br><span class="line">    group_by: [product, environment]</span><br><span class="line">    match:</span><br><span class="line">    team: frontend</span><br></pre></td></tr></table></figure><p>总结一下，Routing Tree 的设计意图是让用户能够非常自由地给警报归类，然后根据归类后的类别来配置要发送给谁以及怎么发送：</p><ul><li><p>发送给谁？上面已经做了很好的示例，’数据库警报’和’前端警报’都有特定的接收组，都没有匹配上那么就是’默认警报’, 发送给默认接收组</p></li><li><p>怎么发送？对于一类警报，有个多个字段来配置发送行为：</p><ul><li><p>group_by：决定了警报怎么分组，每个 group 只会定时产生一次通知，这就达到了降噪的效果，而不同的警报类别分组方式显然是不一样的，举个例子：</p><ul><li><p>配置中的 ‘数据库警报’ 是按 ‘集群’ 和 ‘规则名’ 分组的，这表明对于数据库警报，我们关心的是“哪个集群的哪个规则出问题了”，比如一个时间段内，’华东’集群产生了10条 ‘API响应时间过长’ 警报，这些警报就会聚合在一个通知里发出来；</p></li><li><p>配置中的 ‘前端警报’ 是按 ‘产品’ 和 ‘环境’ 分组的， 这表明对于前端警报，我们关心的是“哪个产品的哪个环境出问题了”</p></li></ul></li><li><p>group_interval 和 group_wait: 控制分组的细节，不细谈，其中 group_interval 控制了这个分组最快多久执行一次 Notification Pipeline</p></li><li><p>repeat_interval: 假如一个相同的警报一直 FIRING，Alertmanager 并不会一直发送警报，而会等待一段时间，这个等待时间就是 repeat_interval，显然，不同类型警报的发送频率也是不一样的</p></li></ul></li></ul><p>group_interval 和 repeat_interval 的区别会在下文中详述</p><h3 id="notification-pipeline">Notification Pipeline</h3><p>由 Routing Tree 分组后的警报会触发 Notification Pipeline:</p><ul><li><p>当一个 AlertGroup 新建后，它会等待一段时间（group_wait 参数)，再触发第一次 Notification Pipeline</p></li><li><p>假如这个 AlertGroup 持续存在，那么之后每隔一段时间（group_interval 参数)，都会触发一次 Notification Pipeline</p></li></ul><p>每次触发 Notification Pipeline，AlertGroup 都会将组内所有的 Alert 作为一个列表传进 Pipeline, Notification Pipeline 本身是一个按照责任链模式设计的接口，MultiStage 这个实现会链式执行所有的 Stage：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; A Stage processes alerts under the constraints of the given context.</span><br><span class="line">type Stage interface &#123;</span><br><span class="line">    Exec(ctx context.Context, l log.Logger, alerts …*types.Alert) (context.Context, []*types.Alert, error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; A MultiStage executes a series of stages sequencially.</span><br><span class="line">type MultiStage []Stage</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Exec implements the Stage interface.</span><br><span class="line">func (ms MultiStage) Exec(ctx context.Context, l log.Logger, alerts …*types.Alert) (context.Context, []*types.Alert, error) &#123;</span><br><span class="line">    var err error</span><br><span class="line">    for _, s :&#x3D; range ms &#123;</span><br><span class="line">        if len(alerts) &#x3D;&#x3D;0&#123;</span><br><span class="line">            return ctx, nil, nil</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ctx, alerts, err &#x3D; s.Exec(ctx, l, alerts…)</span><br><span class="line">        if err !&#x3D; nil &#123;</span><br><span class="line">            return ctx, nil, err</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return ctx, alerts, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MultiStage 里塞的就是开头架构图里画的 InhibitStage、SilenceStage…这么一条链式处理的流程，这里要提一下，官方的架构图画错了，RoutingStage 其实处在整个 Pipeline 的首位，不过这个顺序并不影响逻辑。 要重点说的是DedupStage和NotifySetStage它俩协同负责去重工作，具体做法是：</p><ul><li><p>NotifySetStage 会为发送成功的警报记录一条发送通知，key 是’接收组名字’+’GroupKey 的 key 值’，value 是当前 Stage 收到的 []Alert (这个列表和最开始进入 Notification Pipeline 的警报列表有可能是不同的，因为其中有些 Alert 可能在前置 Stage 中已经被过滤掉了)</p></li><li><p>DedupStage 中会以’接收组名字’+’GroupKey 的 key 值’为 key 查询通知记录，假如：</p><ul><li><p>查询无结果，那么这条通知没发过，为这组警报发送一条通知；</p></li><li><p>查询有结果，那么查询得到已经发送过的一组警报 S，判断当前的这组警报 A 是否为 S 的子集：</p><ul><li><p>假如 A 是 S 的子集，那么表明 A 和 S 重复，这时候要根据 repeat_interval 来决定是否再次发送：</p><ul><li><p>距离 S 的发送时间已经过去了足够久（repeat_interval)，那么我们要再发送一遍；</p></li><li><p>距离 S 的发送时间还没有达到 repeat_interval，那么为了降低警报频率，触发去重逻辑，这次我们就不发了；</p></li></ul></li><li><p>假如 A 不是 S 的子集，那么 A 和 S 不重复，需要再发送一次； 上面的表述可能有些抽象，最后表现出来的结果是：</p></li></ul></li></ul></li><li><p>假如一个 AlertGroup 里的警报一直发生变化，那么虽然每次都是新警报，不会被去重，但是由于 group_interval （假设是5分钟）存在，这个 AlertGroup 最多 5 分钟触发一次 Notification Pipeline，因此最多也只会 5 分钟发送一条通知；</p></li><li><p>假如一个 AlertGroup 里的警报一直不变化，就是那么几条一直 FIRING 着，那么虽然每个 group_interval 都会触发 Notification Pipeline，但是由于 repeate_interval（假设是1小时）存在，因此最多也只会每 1 小时为这个重复的警报发送一条通知； 再说一下 Silence 和 Inhibit，两者都是基于用户主动定义的规则的：</p></li><li><p>Silence Rule：静默规则用来关闭掉部分警报的通知，比如某个性能问题已经修复了，但需要排期上线，那么在上线前就可以把对应的警报静默掉来减少噪音；</p></li><li><p>Inhibit Rule：抑制规则用于在某类警报发生时，抑制掉另一类警报，比如某个机房宕机了，那么会影响所有上层服务，产生级联的警报洪流，反而会掩盖掉根本原因，这时候抑制规则就有用了； 因此 Notification Pipeline 的设计意图就很明确了：通过一系列逻辑（如抑制、静默、去重）来获得更高的警报质量，由于警报质量的维度很多（剔除重复、类似的警报，静默暂时无用的警报，抑制级联警报），因此 Notification Pipeline 设计成了责任链模式，以便于随时添加新的环节来优化警报质量</p></li></ul><h2 id="一个-prometheus-报警处理实例">一个 Prometheus 报警处理实例</h2><p>最近又被问到了 Prometheus 为啥不报警，恰好回忆起之前经常解答相关问题，不妨写一篇文章来解决下面两个问题：</p><ul><li><p>我的 Prometheus 为啥报警？</p></li><li><p>我的 Prometheus 为啥不报警？</p></li></ul><h3 id="从-for-参数开始">从 for 参数开始</h3><p>我们首先需要一些背景知识：Prometheus 是如何计算并产生警报的？</p><p>看一条简单的警报规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- alert: KubeAPILatencyHigh</span><br><span class="line">  annotations:</span><br><span class="line">    message: The API server has a 99th percentile latency of &#123;&#123; $value &#125;&#125; seconds</span><br><span class="line">      for &#123;&#123; $labels.verb &#125;&#125; &#123;&#123; $labels.resource &#125;&#125;.</span><br><span class="line">  expr: |</span><br><span class="line">    cluster_quantile:apiserver_request_latencies:histogram_quantile&#123;job&#x3D;&quot;apiserver&quot;,quantile&#x3D;&quot;0.99&quot;,subresource!&#x3D;&quot;log&quot;&#125; &gt; 4</span><br><span class="line">  for: 10m</span><br><span class="line">  labels:</span><br><span class="line">    severity: critical</span><br></pre></td></tr></table></figure><p>这条警报的<em>大致</em>含义是，假如 kube-apiserver 的 P99 响应时间大于 4 秒，并持续 10 分钟以上，就产生报警。</p><p>首先要注意的是由 <code>for</code> 指定的 Pending Duration。这个参数主要用于降噪，很多类似响应时间这样的指标都是有抖动的，通过指定 Pending Duration，我们可以 过滤掉这些瞬时抖动，让 on-call 人员能够把注意力放在真正有持续影响的问题上。</p><p>那么显然，下面这样的状况是不会触发这条警报规则的，因为虽然指标已经达到了警报阈值，但持续时间并不够长：</p><p><img src="https://aleiwu.com/prometheus-peaks.png" alt=""></p><p>但偶尔我们也会碰到更奇怪的事情。</p><h3 id="为什么不报警">为什么不报警？</h3><p><img src="https://aleiwu.com/no-alert.jpg" alt=""></p><p>类似上面这样持续超出阈值的场景，为什么有时候会不报警呢？</p><h3 id="为什么报警">为什么报警？</h3><p><img src="https://aleiwu.com/why-alert.jpg" alt=""></p><p>类似上面这样并未持续超出阈值的场景，为什么有时又会报警呢？</p><h3 id="采样间隔">采样间隔</h3><p>这其实都源自于 Prometheus 的数据存储方式与计算方式。</p><p>首先，Prometheus 按照配置的抓取间隔(<code>scrape_interval</code>)定时抓取指标数据，因此存储的是形如 (timestamp, value) 这样的采样点。</p><p>对于警报， Prometheus 会按固定的时间间隔重复计算每条警报规则，因此警报规则计算得到的只是稀疏的采样点，而警报持续时间是否大于 <code>for</code> 指定的 Pending Duration 则是由这些稀疏的采样点决定的。</p><p>而在 Grafana 渲染图表时，Grafana 发送给 Prometheus 的是一个 Range Query，其执行机制是从时间区间的起始点开始，每隔一定的时间点（由 Range Query 的 <code>step</code> 请求参数决定） 进行一次计算采样。</p><p>这些结合在一起，就会导致警报规则计算时“看到的内容”和我们在 Grafana 图表上观察到的内容不一致，比如下面这张示意图：</p><p><img src="https://aleiwu.com/alert-firing.jpg" alt=""></p><p>上面图中，圆点代表原始采样点：</p><ul><li><p>40s 时，第一次计算，低于阈值</p></li><li><p>80s 时，第二次计算，高于阈值，进入 Pending 状态</p></li><li><p>120s 时，第三次计算，仍然高于阈值，90s 处的原始采样点虽然低于阈值，但是警报规则计算时并没有”看到它“</p></li><li><p>160s 时，第四次计算，高于阈值，Pending 达到 2 分钟，进入 firing 状态</p></li><li><p>持续高于阈值</p></li><li><p>直到 360s 时，计算得到低于阈值，警报消除</p></li></ul><p>由于采样是稀疏的，部分采样点会出现被跳过的状况，而当 Grafana 渲染图表时，取决于 Range Query 中采样点的分布，图表则有可能捕捉到 被警报规则忽略掉的”低谷“（图三)或者也可能无法捕捉到警报规则碰到的”低谷“（图二）。如此这般，我们就被”图表“给蒙骗过去，质疑起警报来了。</p><h3 id="如何应对">如何应对</h3><p>首先嘛， Prometheus 作为一个指标系统天生就不是精确的——由于指标本身就是稀疏采样的，事实上所有的图表和警报都是”估算”，我们也就不必 太纠结于图表和警报的对应性，能够帮助我们发现问题解决问题就是一个好监控系统。当然，有时候我们也得证明这个警报确实没问题，那可以看一眼 <code>ALERTS</code> 指标。<code>ALERTS</code> 是 Prometheus 在警报计算过程中维护的内建指标，它记录每个警报从 Pending 到 Firing 的整个历史过程，拉出来一看也就清楚了。</p><p>但有时候 ALERTS 的说服力可能还不够，因为它本身并没有记录每次计算出来的值到底是啥，而在我们回头去考证警报时，又无法选取出和警报计算过程中一模一样的计算时间点， 因此也就无法还原警报计算时看到的计算值究竟是啥。这时候终极解决方案就是把警报所要计算的指标定义成一条 Recording Rule，计算出一个新指标来记录计算值，然后针对这个 新指标做阈值报警。kube-prometheus 的警报规则中就大量采用了这种技术。</p><h3 id="到此为止了吗">到此为止了吗？</h3><p>Prometheus 警报不仅包含 Prometheus 本身，还包含用于警报治理的 Alertmanager，我们可以看一看上面那张指标计算示意图的全图：</p><p><img src="https://aleiwu.com/alert-overview.jpg" alt=""></p><p>在警报产生后，还要经过 Alertmanager 的分组、抑制处理、静默处理、去重处理和降噪处理最后再发送给接收者。而这个过程也有大量的因素可能会导致警报产生了却最终没有进行通知。</p><h2 id="结语">结语</h2><p>Alertmanager 整体的设计意图就是奔着治理警报（通知）去的，首先它用 Routing Tree 来帮助用户定义警报的归类与发送逻辑，然后再用 Notification Pipeline 来做抑制、静默、去重以提升警报质量。这些功能虽然不能解决”警报”这件事中所有令人头疼的问题，但确实为我们着手去解决”警报质量”相关问题提供了趁手的工具。</p><blockquote><p>本文转载自：「Aylei’s Blog」，原文：1.<a href="https://url.cn/5Gp0VLq%E3%80%812.https://url.cn/5MEMY8K%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5Gp0VLq、2.https://url.cn/5MEMY8K，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;警报是监控系统中必不可少的一块, 当然了, 也是最难搞的一块. 我们乍一想, 警报似乎很简单一件事:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假如发生了异常情况, 发送或邮件/消息通知给某人或某频道&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一把梭搞起来之后, 就不免有一些小麻烦:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;这个啊…一天中总有那么几次波动, 也难修难查了, 算了算了不看了&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;警报太多了, 实在看不过来, 屏蔽/归档/放生吧…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有毒吧, 这个阈值也太低了&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;卧槽, 这些警报啥意思啊, 发给我干嘛啊?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;卧槽卧槽卧槽, 怎么一下子几十百来条警报, 哦…原来网络出问题了全崩了&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;到最后我们还能总结出一个奇怪的规律:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这世界上只有两种警报，一种是疯狂报警但是没有卵用完全没人看的警报，一种是非常有效大家都想看但在用户反馈前从来都报不出来的警报。—— 鲁迅(&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;玩笑归玩笑，但至少我们能看出，警报不是一个简单的计算+通知系统。只是，”做好警报”这件事本身是个综合问题，代码能解决的也只是其中的一小部分，更多的事情要在组织、人事和管理上去做。我掰不出那么有深度的文章，这篇文章就专注一点，只讲代码部分里的通知，也就是 Prometheus 生态中的 Alertmanager 这个组件。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/categories/Prometheus/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/tags/Prometheus/"/>
    
  </entry>
  
</feed>
