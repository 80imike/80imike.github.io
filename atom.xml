<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>奇妙的 Linux 世界</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2022-06-01T08:29:56.618Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何使用 Skopeo 做一个优雅的镜像搬运工</title>
    <link href="https://www.hi-linux.com/posts/55385.html"/>
    <id>https://www.hi-linux.com/posts/55385.html</id>
    <published>2022-06-01T01:00:00.000Z</published>
    <updated>2022-06-01T08:29:56.618Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="1-基础介绍">1. 基础介绍</span></h2><p>描述: 作为公司内部 PaaS toB 产品的打包发布人员，容器镜像对我们打工人而言就像是工地上的砖头 🧱，而我的一部分工作就是将这些砖头在各个仓库之间搬来搬去，最终将这些砖头打包放在产品的安装包中，形成一个完整的 PaaS 产品安装包。</p><ul><li>Q: 在 PaaS (平台即服务)中的大家常说的 ToB 与 ToC 到底是什么?</li></ul><blockquote><p>ToC 面向普通用户服务, 主要是让用户体验感好，解决用户使用方面的问题记录，并返回给前后端开发。<br>ToB 是面向企业用户服务, 产品可用、其中最关键是让Boss使用Happly!</p></blockquote><ul><li>Q: 假如有如下场景，我们从 dockerhub 公共仓库中下载一个 GB 以上的镜像，到本地的私有仓库中，我想通常你会这样做先 <code>docker pull</code> 到本地，然后使用 <code>docker tag</code> 更改为私有仓库地址加上镜像名称版本，最后再使用<code>docker push</code> 上传镜像到私有仓库中，以供其它内网机器拉取并使用。虽然该方法是可行，但是如果有多个大于 GB 以上的镜像需要上传到私有仓库，每次都要先解压 layer 到本地，然后再压缩 layer 上传到私有仓库中，你能想象此过程花费的时间有多久吗? 对于我们运维工程师来说时间就是金钱，所以需想尽一切方法来节约时间成本，那有没有一种办法可以直接将 registry 上的 blob 复制到另一个 registry，中间过程不涉及对镜像 layer 的解压缩，这岂不美哉。</li></ul><blockquote><p>解决方案当然是存在的，如果你不想使用docker进行images镜像拉取上传，我们完成可以使用skope工具来完全替代 docker-cli 来搬运镜像，skopeo是一个命令行实用程序，可对容器映像和映像存储库执行各种操作。</p></blockquote><a id="more"></a><p><strong>什么是 Skopeo ?</strong></p><p>skopeo 使用 API V2 Registry，例如 Docker Registry、Atomic Registry、私有Registry、本地目录和本地 OCI 镜像目录。skopeo 不需要运行守护进程，它可以执行的操作包括：</p><ul><li>通过各种存储机制复制镜像，例如，可以在不需要特权的情况下将镜像从一个 Registry 复制到另一个 Registry</li><li>检测远程镜像并查看其属性，包括其图层，无需将镜像拉到本地</li><li>从镜像库中删除镜像</li><li>当存储库需要时，skopeo 可以传递适当的凭据和证书进行身份验证</li></ul><p><strong>镜像存储特点</strong></p><p>根据 Robin 大佬在 《镜像仓库中镜像存储的原理解析》文章里得出的结论：</p><ul><li><p>通过 Registry API 获得的两个镜像仓库中相同镜像的 manifest 信息完全相同。</p></li><li><p>两个镜像仓库中相同镜像的 manifest 信息的存储路径和内容完全相同。</p></li><li><p>两个镜像仓库中相同镜像的 blob 信息的存储路径和内容完全相同</p></li></ul><p><strong>项目信息</strong></p><ul><li>Github 官方地址: <a href="https://github.com/containers/skopeo" target="_blank" rel="noopener">https://github.com/containers/skopeo</a></li><li>Gitee mirror: <a href="https://gitee.com/mirrors/skopeo" target="_blank" rel="noopener">https://gitee.com/mirrors/skopeo</a></li></ul><h2><span id="2-安装编译">2. 安装编译</span></h2><p>描述: Skopeo 官方安装&amp;编译方式参考文档: <a href="https://github.com/containers/skopeo/blob/main/install.md" target="_blank" rel="noopener">https://github.com/containers/skopeo/blob/main/install.md</a></p><p>本节安装实践环境将在 Ubuntu 20.04 LTS 以及 docker 20.10.12 中进行实践源码编译以及 apt 仓库源下载安装实践。</p><h3><span id="21-源码编译静态">2.1 源码编译（静态）</span></h3><p>描述: 要构建 skopeo 二进制文件您至少需要 Go 1.12 版本以上, 其次构建 skopeo 有两种方法，即<code>在容器中</code>或者在本地环境中构建(安装环境较为复杂), 此处为了方便演示将采用容器方式进行编译构建。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 1.拉取skopeo源码到本地</span><br><span class="line">$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;containers&#x2F;skopeo.git  # https:&#x2F;&#x2F;github.com&#x2F;containers&#x2F;skopeo.git</span><br><span class="line">$ cd skopeo</span><br><span class="line">$ sed -i &#39;s#proxy.golang.org#https:&#x2F;&#x2F;goproxy.cn#g&#39; skopeo&#x2F;Makefile</span><br><span class="line"></span><br><span class="line"># 2.下载镜像构建依赖</span><br><span class="line">$ sudo apt-get install go-md2man  # 构建手册依赖于 go-md2man。</span><br><span class="line">$ whereis go-md2man  # 获得本机中go-md2man路径。</span><br><span class="line"></span><br><span class="line"># 3.构建静态二进制文件</span><br><span class="line">$ BUILD_IMAGE&#x3D;&quot;golang:latest&quot;</span><br><span class="line">$ docker run --name skopeo-build -v $PWD:&#x2F;src -v &#x2F;usr&#x2F;bin&#x2F;go-md2man:&#x2F;go&#x2F;bin&#x2F;go-md2man -w &#x2F;src -e CGO_ENABLED&#x3D;0 -e GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn,direct $&#123;BUILD_IMAGE&#125; \</span><br><span class="line">sh -c &#39;make BUILDTAGS&#x3D;containers_image_openpgp GO_DYN_FLAGS&#x3D;&#39;</span><br><span class="line">  # CGO_CFLAGS&#x3D;&quot;&quot; CGO_LDFLAGS&#x3D;&quot;&quot; GO111MODULE&#x3D;on go build -mod&#x3D;vendor  -ldflags &#39;-X main.gitCommit&#x3D;df4d82b960572c19e9333381a203c0ac475766d7 &#39; -gcflags &quot;&quot; -tags  &quot;containers_image_openpgp&quot; -o bin&#x2F;skopeo .&#x2F;cmd&#x2F;skopeo</span><br><span class="line"></span><br><span class="line"># 4.运行编译生成的skopeo可执行文件</span><br><span class="line">$ cd .&#x2F;bin # &#x2F;opt&#x2F;software&#x2F;skopeo&#x2F;bin</span><br><span class="line">$ .&#x2F;skopeo --help</span><br><span class="line">  # Various operations with container images and container image registries</span><br><span class="line">  # .......</span><br><span class="line">  # Use &quot;skopeo [command] --help&quot; for more information about a command.</span><br></pre></td></tr></table></figure><p><strong>构建关键参数解析:</strong></p><ul><li>CGO_ENABLED=0 : 设置该环境变量, 禁用 CGO 会导致 Go 在可能的情况下更喜欢静态连接库，而不是动态链接到系统库 (解决可以在Ubuntu或者其它linux发行版中执行编译后二进制文件)。</li><li>GOPROXY=https://goproxy.cn,direct : Golong 依赖下载镜像站,加快go get依赖拉拉取。</li><li>BUILDTAGS=containers_image_openpgp : 设置该make参数消除了对libgpgme 及其配套库的依赖, Skopeo 的一些特性依赖于非 Go 库，例如 libgpgme 和 libdevmapper。</li><li>GO_DYN_FLAGS= : 清空该make参数 (否则会强制创建动态可执行文件)</li></ul><h3><span id="22-分发包安装">2.2 分发包安装</span></h3><p>描述: skopeo 可能已经打包在您的发行版中，此处以 ubuntu 20.04 为例进行安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 1.只支持 Ubuntu 20.10 and newer 发行版 </span><br><span class="line">$ sudo apt-get -y update</span><br><span class="line">$ sudo apt-get -y install skopeo</span><br><span class="line"></span><br><span class="line"># 2.但 Kubic 项目为 Ubuntu 20.04 提供了软件包，我们可以通过如下方式在我们及其上进行安装。</span><br><span class="line">$ . &#x2F;etc&#x2F;os-release</span><br><span class="line">$ echo &quot;deb https:&#x2F;&#x2F;download.opensuse.org&#x2F;repositories&#x2F;devel:&#x2F;kubic:&#x2F;libcontainers:&#x2F;stable&#x2F;xUbuntu_$&#123;VERSION_ID&#125;&#x2F; &#x2F;&quot; | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;devel:kubic:libcontainers:stable.list</span><br><span class="line">$ curl -L https:&#x2F;&#x2F;download.opensuse.org&#x2F;repositories&#x2F;devel:&#x2F;kubic:&#x2F;libcontainers:&#x2F;stable&#x2F;xUbuntu_$&#123;VERSION_ID&#125;&#x2F;Release.key | sudo apt-key add -</span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get -y upgrade</span><br><span class="line">$ sudo apt-get -y install skopeo</span><br></pre></td></tr></table></figure><h3><span id="23-容器安装运行">2.3 容器安装运行</span></h3><p>Skopeo 容器镜像可在 <a href="http://quay.io/skopeo/stable:latest" target="_blank" rel="noopener">quay.io/skopeo/stable:latest</a> 获得, 例如我们采用podman命令进行如下操作:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ podman run docker:&#x2F;&#x2F;quay.io&#x2F;skopeo&#x2F;stable:latest copy --help</span><br></pre></td></tr></table></figure><h2><span id="3-快速上手">3. 快速上手</span></h2><h3><span id="31-命令浅析">3.1 命令浅析</span></h3><p>描述: skopen 是操作各种容器映像和容器映像仓库的工具，其使用方法及其可用命令如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;skopeo --help    # 子命令可采用如下命令 skopeo [command] --help 命令</span><br><span class="line">Usage:</span><br><span class="line">  skopeo [flags]</span><br><span class="line">  skopeo [command]</span><br><span class="line">Available Commands: </span><br><span class="line">  copy          # 复制一个镜像从 A 到 B，这里的 A 和 B 可以为本地 docker 镜像或者 registry 上的镜像；</span><br><span class="line">  delete        # 删除一个镜像 tag，可以是本地 docker 镜像或者 registry 上的镜像；</span><br><span class="line">  help          # 帮助查看</span><br><span class="line">  inspect       # 查看一个镜像的 manifest 或者 image config 详细信息；</span><br><span class="line">  list-tags     # 列出存储库名称指定的镜像的tag</span><br><span class="line">  login           # 登陆某个镜像仓库,类似于 docker login 命令</span><br><span class="line">  logout          # 退出某个已认证的镜像仓库, 类似于 docker logout 命令</span><br><span class="line">  manifest-digest # 计算文件的清单摘要是一个sha256sum 值</span><br><span class="line">  standalone-sign   # 使用本地文件创建签名</span><br><span class="line">  standalone-verify # 验证本地文件的签名</span><br><span class="line">  sync              # 将一个或多个图像从一个位置同步到另一个位置 (该功能非常Nice)</span><br><span class="line">Flags:</span><br><span class="line">    --command-timeout duration   # 命令超时时间(单位秒)</span><br><span class="line">    --debug                      # 启用debug模式</span><br><span class="line">    --insecure-policy            # 在不进行任何策略检查的情况下运行该工具（如果没有配置 policy 的话需要加上该参数）</span><br><span class="line">    --override-arch ARCH         # 处理镜像时覆盖客户端 CPU 体系架构，如在 amd64 的机器上用 skopeo 处理 arm64 的镜像</span><br><span class="line">    --override-os OS             # 处理镜像时覆盖客户端 OS</span><br><span class="line">    --override-variant VARIANT   # 处理镜像时使用VARIANT而不是运行架构变量</span><br><span class="line">    --policy string              # 信任策略文件的路径 (为镜像配置安全策略情况下使用)</span><br><span class="line">    --registries.d DIR           # 在目录中使用Registry配置文件（例如，用于容器签名存储）</span><br><span class="line">    --tmpdir string              # 用于存储临时文件的目录</span><br><span class="line">-h, --help                       help for skopeo </span><br><span class="line">-v, --version                    Version for Skopeo</span><br></pre></td></tr></table></figure><h3><span id="32-skopeo-初体验">3.2 Skopeo 初体验</span></h3><p>描述: 在使用体验skopeo之前，我们需要了解一哈 Skopeo 可以在那些图像和存储库类型上执行镜像操作(官网文档走一波)：</p><table><thead><tr><th style="text-align:center">Repository types</th><th>Describe</th><th>Example</th></tr></thead><tbody><tr><td style="text-align:center"><code>containers-storage:docker-reference</code></td><td>适用于后端是 Podman, CRI-O, Buildah 的情况</td><td><code>containers-storage:</code></td></tr><tr><td style="text-align:center"><code>dir:path</code></td><td>适用于将manifest, layer tarballs 和 signatures 存储为单独文件的现有本地目录路径的情况</td><td><code>dir:/tmp/alpine:latest</code></td></tr><tr><td style="text-align:center"><code>docker://docker-reference</code></td><td>适用于Registry中实现&quot;Docker Registry HTTP API V2&quot;的镜像的情况</td><td><code>docker://harbor.weiyigeek.top/myblog:v2.8</code></td></tr><tr><td style="text-align:center"><code>docker-archive:path[:docker-reference]</code></td><td>适用于采用<code>docker save</code>命令导出镜像以tar格式存储的文件的情况</td><td><code>docker-archive:alpine.tar</code></td></tr><tr><td style="text-align:center"><code>docker-daemon:docker-reference</code></td><td>适用于存储在 docker 守护进程内部存储中的图像的情况</td><td><code>docker-daemon:alpine:latest</code></td></tr><tr><td style="text-align:center"><code>oci:path:tag</code></td><td>适用于符合&quot;Open Container Image Layout Specification&quot;的目录中的图像标记</td><td><code>oci:alpine:latest</code></td></tr></tbody></table><blockquote><p>温馨提示: 同一个镜像存在的方式有可能不同，不同类型方式存储对镜像的 layer 处理的方式也不一样,。</p></blockquote><p><strong>测试环境说明</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Docker 官方 hub 仓库 -&gt; docker.io             # 官网地址: https:&#x2F;&#x2F;hub.docker.com&#x2F;</span><br><span class="line">私有 Harbor 仓库     -&gt; harbor.weiyigeek.top</span><br><span class="line">临时创建的本地仓库    -&gt; 192.168.12.111:5000   # 一梭子解决: docker run -d -p 5000:5000 --name registry -v &#x2F;opt&#x2F;data&#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry registry:2</span><br></pre></td></tr></table></figure><blockquote><p>说明: 上述仓库都是在Registry中支持Docker Registry HTTP API V2版本的。</p></blockquote><h4><span id="321-skopeo-loginloout-远程仓库-auth">3.2.1 Skopeo login/loout - 远程仓库 Auth</span></h4><p>描述: 在使用 skopeo 前如果 src 或 dest 镜像是在 registry 仓库中的并且配置了非 public 的镜像需要相应的 auth 认证, 此时我们可以使用 <code>docker login</code> 或者 <code>skopeo login</code> 的方式登录到 registry 仓库，然后默认会在<code>~/.docker</code>目录下生成 registry 登录配置文件 config.json ,该文件里保存了登录需要的验证信息，skopeo 拿到该验证信息才有权限往 registry push 镜像。</p><ul><li><strong>登陆认证</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># (1) skopeo login 登陆示例 (两种方式)</span><br><span class="line">$ skopeo login -u WeiyiGeek -p testpassword harbor.weiyigeek.top</span><br><span class="line">  # Login Succeeded!</span><br><span class="line"></span><br><span class="line"># (2) docker login 登陆示例</span><br><span class="line">$ docker login -u WeiyiGeek docker.io</span><br><span class="line">$ docker login -u WeiyiGeek harbor.weiyigeek.top</span><br><span class="line">$ docker login -u anonymous -p anonymous 192.168.12.111:5000  # 实际上临时仓库没有配置认证, 账号密码随意即可。</span><br><span class="line">  # WARNING! Using --password via the CLI is insecure. Use --password-stdin.</span><br><span class="line">  # WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class="line">  # Configure a credential helper to remove this warning. See</span><br><span class="line">  # https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class="line">  # Login Succeeded</span><br><span class="line"></span><br><span class="line"># (3) docker login 生成的 registry 登录配置文件（base64编码安全性不多说）</span><br><span class="line">$ cat ~&#x2F;.docker&#x2F;config.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;auths&quot;: &#123;</span><br><span class="line">    &quot;192.168.12.111:5000&quot;: &#123;</span><br><span class="line">        &quot;auth&quot;: &quot;YW5v*******Q&#x3D;&#x3D;&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">    &quot;harbor.weiyigeek.top&quot;: &#123;</span><br><span class="line">        &quot;auth&quot;: &quot;YWR*******LkA&#x3D;&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">    &quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;: &#123;</span><br><span class="line">        &quot;auth&quot;: &quot;d2Vp**************kyZA&#x3D;&#x3D;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>注销认证</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo logout myregistrydomain.com:5000</span><br></pre></td></tr></table></figure><blockquote><p>温馨提示: 如果企业自建harbor仓库(一般都会设置自签证书)或者其它私有仓库配置证书,为了防止出错建议进行以下操作(正式环境请根据需要进行配置)。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># (1) 在 &#x2F;etc&#x2F;docker&#x2F;daemon.json 中配置 insecure-registries 字段,表示允许不安全的仓库。</span><br><span class="line">&quot;insecure-registries&quot;: [&quot;harbor.weiyigeek.top&quot;,&quot;192.168.12.111:5000&quot;]</span><br><span class="line"> </span><br><span class="line"># (2) 从官方文档可知客户端要使用tls与Harbor通信使用的还是&#96;自签证书&#96;，那么必须建立一个目录：&#96;&#x2F;etc&#x2F;docker&#x2F;certs.d&#96;</span><br><span class="line"># 如果配置可能会出现 x509: certificate signed by unknown authority 错误提示。</span><br><span class="line">$ mkdir -vp &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top</span><br><span class="line">$ cp -a &#x2F;deployapp&#x2F;harbor&#x2F;harbor.pem  &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top&#x2F;harbor.crt</span><br></pre></td></tr></table></figure><blockquote><p>温馨提示: 为了防止后续执行 skopeo 命令操作镜像时出错, 建议忽略 policy 策略和证书校验参数如下:</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--insecure-policy \</span><br><span class="line">--src-tls-verify&#x3D;false \ </span><br><span class="line">--dest-tls-verify&#x3D;false \</span><br></pre></td></tr></table></figure><h4><span id="322-skopeo-inspect-检查存储库中的镜像">3.2.2 Skopeo inspect - 检查存储库中的镜像</span></h4><p>描述: skopeo 能够检查容器 Registry 上的存储库并获取图像层。检查命令获取存储库的清单，它能够向您显示有关整个存储库或标签的类似 <code>docker inspect</code> 的 json 输出。与 docker inspect 相比,此工具可帮助您在拉取存储库或标签之前收集有用的信息(使用磁盘空间), 检查命令可以向您显示给定存储库可用的标签、映像具有的标签、映像的创建日期和操作系统等。</p><p>支持传输的类型 : <code>containers-storage, dir, docker, docker-archive, docker-daemon, oci, oci-archive, ostree, tarball</code></p><ul><li>步骤 01. 显示 busybox:latest 镜像的属性相关信息。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo inspect docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest</span><br><span class="line">&#123;</span><br><span class="line">  &quot;Name&quot;: &quot;docker.io&#x2F;library&#x2F;busybox&quot;,</span><br><span class="line">  &quot;Digest&quot;: &quot;sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678&quot;,</span><br><span class="line">  &quot;RepoTags&quot;: [</span><br><span class="line">      &quot;1&quot;,</span><br><span class="line">      &quot;1-glibc&quot;,</span><br><span class="line">      &quot;1-musl&quot;,</span><br><span class="line">      &quot;1-ubuntu&quot;,</span><br><span class="line">      &quot;1-uclibc&quot;,</span><br><span class="line">      &quot;1.21-ubuntu&quot;,</span><br><span class="line">      &quot;1.21.0-ubuntu&quot;,</span><br><span class="line">        .......          # 镜像历史tags</span><br><span class="line">      &quot;unstable-uclibc&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;Created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">  &quot;DockerVersion&quot;: &quot;20.10.7&quot;,</span><br><span class="line">  &quot;Labels&quot;: null,</span><br><span class="line">  &quot;Architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;Os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;Layers&quot;: [</span><br><span class="line">      &quot;sha256:5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>步骤 02. 显示 busybox:latest 镜像的容器配置相关信息。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo inspect --config docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest  | jq</span><br><span class="line">&#123;</span><br><span class="line">  &quot;created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">  &quot;architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;config&quot;: &#123;</span><br><span class="line">    &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Cmd&quot;: [</span><br><span class="line">      &quot;sh&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;rootfs&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;layers&quot;,</span><br><span class="line">    &quot;diff_ids&quot;: [</span><br><span class="line">      &quot;sha256:01fd6df81c8ec7dd24bbbd72342671f41813f992999a3471b9d9cbc44ad88374&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;history&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:40.833034683Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop) ADD file:6db446a57cbd2b7f4cfde1f280177b458390ed5a6d1b54c6169522bc2c4d838e in &#x2F; &quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop)  CMD [\&quot;sh\&quot;]&quot;,</span><br><span class="line">      &quot;empty_layer&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>步骤 03. 显示未经验证的图像 Digest（摘要）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo inspect --format &quot;Name: &#123;&#123;.Name&#125;&#125; Digest: &#123;&#123;.Digest&#125;&#125;&quot; docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest</span><br></pre></td></tr></table></figure><h4><span id="323-skopeo-copy-仓库镜像拷贝">3.2.3 Skopeo copy - 仓库镜像拷贝</span></h4><p>描述: skopeo 可以在各种存储机制之间复制容器镜像，支持包括容器仓库(<code>The Quay, Docker Hub, OpenShift, GCR, ，Artifactory ...</code>)以及容器存储后端 (<code>Podman, CRI-O, Docker</code>) 等、本地目录、本地 OCI-layout 目录。</p><p>例如，此处我从 hub 仓库复制 <code>busybox:latest</code> 镜像到私有 harbor 仓库中,在从私有 harbor 仓库中拷贝到本地指定目录中。</p><ul><li>步骤 01. 从 regsitry A 到 registry B 复制 busybox:latest 镜像。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo copy --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false --dest-authfile &#x2F;root&#x2F;.docker&#x2F;config.json docker:&#x2F;&#x2F;docker.io&#x2F;busybox:latest docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa done</span><br><span class="line">  # Copying config beae173cca done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br></pre></td></tr></table></figure><blockquote><p>Tips: 由上述日志可以看到 skopeo 是直接从 registry 中 copy 镜像 layer 的 blob 文件，传输是镜像在 registry 中存储的原始格式。</p></blockquote><ul><li>步骤 02. 从 registry B 复制 busybox:latest 镜像到本地 busybox:latest 目录中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo copy --insecure-policy --src-tls-verify&#x3D;false docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest dir:busybox:latest</span><br><span class="line"># Getting image source signatures</span><br><span class="line"># Copying blob 5cc84ad355aa done</span><br><span class="line"># Copying config beae173cca done</span><br><span class="line"># Writing manifest to image destination</span><br><span class="line"># Storing signatures</span><br><span class="line"></span><br><span class="line">$ ls &amp;&amp; tree busybox\:latest&#x2F;</span><br><span class="line">busybox:latest&#x2F;</span><br><span class="line">├── 5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa   # blob 块文件 -&gt; vnd.docker.image.rootfs.diff.tar.gzip</span><br><span class="line">├── beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a   # 镜像配置信息文件 -&gt; vnd.docker.container.image.v1+json </span><br><span class="line">├── manifest.json</span><br><span class="line">└── version</span><br><span class="line">0 directories, 4 files</span><br><span class="line"></span><br><span class="line"># 查看镜像的 manifest 文件</span><br><span class="line">$ cat busybox\:latest&#x2F;manifest.json</span><br><span class="line">&#123;</span><br><span class="line">   &quot;schemaVersion&quot;: 2,</span><br><span class="line">   &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.distribution.manifest.v2+json&quot;,</span><br><span class="line">   &quot;config&quot;: &#123;</span><br><span class="line">      &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.container.image.v1+json&quot;,</span><br><span class="line">      &quot;size&quot;: 1456,</span><br><span class="line">      &quot;digest&quot;: &quot;sha256:beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;layers&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 772788,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa&quot;</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 根据 manifest 文件查看镜像的 image config 文件 (存放镜像Build指令与镜像相关配置信息)</span><br><span class="line">$ jq &#39;.&#39; busybox\:latest&#x2F;beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">&#123;</span><br><span class="line">  &quot;architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;config&quot;: &#123;</span><br><span class="line">    &quot;Hostname&quot;: &quot;&quot;,</span><br><span class="line">    &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">    &quot;User&quot;: &quot;&quot;,</span><br><span class="line">    &quot;AttachStdin&quot;: false,</span><br><span class="line">    &quot;AttachStdout&quot;: false,</span><br><span class="line">    &quot;AttachStderr&quot;: false,</span><br><span class="line">    &quot;Tty&quot;: false,</span><br><span class="line">    &quot;OpenStdin&quot;: false,</span><br><span class="line">    &quot;StdinOnce&quot;: false,</span><br><span class="line">    &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Cmd&quot;: [</span><br><span class="line">      &quot;sh&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Image&quot;: &quot;sha256:da658412c37aa24e561eb7e16c61bc82a9711340d8fb5cf1a8f39d8e96d7f723&quot;,</span><br><span class="line">    &quot;Volumes&quot;: null,</span><br><span class="line">    &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">    &quot;Entrypoint&quot;: null,</span><br><span class="line">    &quot;OnBuild&quot;: null,</span><br><span class="line">    &quot;Labels&quot;: null</span><br><span class="line">  &#125;,</span><br><span class="line">........</span><br><span class="line">  &quot;history&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:40.833034683Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop) ADD file:6db446a57cbd2b7f4cfde1f280177b458390ed5a6d1b54c6169522bc2c4d838e in &#x2F; &quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2021-12-30T19:19:41.006954958Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;&#x2F;bin&#x2F;sh -c #(nop)  CMD [\&quot;sh\&quot;]&quot;,</span><br><span class="line">      &quot;empty_layer&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;rootfs&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;layers&quot;,</span><br><span class="line">    &quot;diff_ids&quot;: [</span><br><span class="line">      &quot;sha256:01fd6df81c8ec7dd24bbbd72342671f41813f992999a3471b9d9cbc44ad88374&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>步骤 03. 将 busybox:latest 镜像从 registry B 复制到本地目录，并以 OCI 格式保存</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo copy --insecure-policy --src-tls-verify&#x3D;false docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest oci:busybox-latest</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa done</span><br><span class="line">  # Copying config 48edd9298a done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br><span class="line"></span><br><span class="line">$ tree -h busybox-latest&#x2F;</span><br><span class="line">  # busybox-latest&#x2F;</span><br><span class="line">  # ├── [4.0K]  blobs</span><br><span class="line">  # │   └── [4.0K]  sha256</span><br><span class="line">  # │       ├── [ 347]  1612e16ff3f6b0d09eefdc4e9d5c5c0624f63032743e016585b095b958778016</span><br><span class="line">  # │       ├── [ 575]  48edd9298a25de2c97cd574a5523026f87576c6b7202330a2b60ce7d304ec307</span><br><span class="line">  # │       └── [755K]  5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa  # Blob 块 -</span><br><span class="line">  # ├── [ 186]  index.json</span><br><span class="line">  # └── [  31]  oci-layout</span><br><span class="line">  # 2 directories, 5 files</span><br></pre></td></tr></table></figure><ul><li>步骤 04. 将 <code>alpine:3.13.1</code> 镜像从 docker 本地存储（ /var/lib/docker/image） push 到 registry B中(实际上替代 docker push 功能)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 在  &#x2F;var&#x2F;lib&#x2F;docker&#x2F; 目录中此处主要关心 image (主要存放镜像中layer层的元数据) 和 overlay2 (各层的具体信息)</span><br><span class="line">$ docker images alpine:3.13.1</span><br><span class="line">  # REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">  # alpine       3.13.1    e50c909a8df2   11 months ago   5.61MB</span><br><span class="line"></span><br><span class="line">$ skopeo copy --insecure-policy --dest-tls-verify&#x3D;false --dest-authfile &#x2F;root&#x2F;.docker&#x2F;config.json docker-daemon:alpine:3.13.1 docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;alpine:3.13.1</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 1119ff37d4a9 done</span><br><span class="line">  # Copying config e50c909a8d done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/640-20220520095506113-2022-05-20-jxlRy3.png" alt></p><h4><span id="324-skopeo-sync-镜像同步命令">3.2.4 Skopeo sync - 镜像同步命令</span></h4><p>描述: Skopeo sync可以在容器仓库和本地目录之间同步镜像，其功能类似于阿里云的 image-syncer (<a href="https://github.com/AliyunContainerService/image-syncer" target="_blank" rel="noopener">https://github.com/AliyunContainerService/image-syncer</a>) 工具, 实际上其比 image-syncer 更强大、灵活性更强一些，废话不多说实践为王。</p><p>skopeo sync 镜像同步文件示例:</p><ul><li>步骤 01. 将仓库中所有 busybox 镜像版本同步到本地目录。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo sync --insecure-policy --src-tls-verify&#x3D;false --src docker --dest dir harbor.weiyigeek.top&#x2F;devops&#x2F;busybox &#x2F;tmp</span><br><span class="line">  # INFO[0000] Tag presence check                            imagename&#x3D;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox tagged&#x3D;false</span><br><span class="line">  # INFO[0000] Getting tags                                  image&#x3D;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox</span><br><span class="line">  # INFO[0000] Copying image ref 1&#x2F;1                         from&#x3D;&quot;docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest&quot; to&#x3D;&quot;dir:&#x2F;tmp&#x2F;busybox:latest&quot;</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa done</span><br><span class="line">  # Copying config beae173cca done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br><span class="line">  # INFO[0000] Synced 1 images from 1 sources</span><br><span class="line"></span><br><span class="line">$ tree -h &#x2F;tmp&#x2F;busybox:latest</span><br><span class="line">&#x2F;tmp&#x2F;busybox:latest</span><br><span class="line">├── [755K]  5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa</span><br><span class="line">├── [1.4K]  beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">├── [ 527]  manifest.json</span><br><span class="line">└── [  33]  version</span><br><span class="line">0 directories, 4 files</span><br></pre></td></tr></table></figure><ul><li>步骤 02. 从本地目录 <code>/tmp/</code> 同步到 docker 的 hub 容器仓库中，此外我们可以通过浏览器看到 <code>weiyigeek</code> 用户下的 <code>busybox</code> 镜像 (<a href="https://hub.docker.com/u/weiyigeek" target="_blank" rel="noopener">https://hub.docker.com/u/weiyigeek</a>)。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo sync --insecure-policy --dest-tls-verify&#x3D;false --src dir --dest docker &#x2F;tmp weiyigeek</span><br><span class="line">  # INFO[0000] Copying image ref 1&#x2F;1                         from&#x3D;&quot;dir:&#x2F;tmp&#x2F;busybox:latest&quot; to&#x3D;&quot;docker:&#x2F;&#x2F;weiyigeek&#x2F;busybox:latest&quot;</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 5cc84ad355aa skipped: already exists</span><br><span class="line">  # Copying config beae173cca done</span><br><span class="line">  # Writing manifest to image destination</span><br><span class="line">  # Storing signatures</span><br><span class="line">  # INFO[0021] Synced 1 images from 1 sources</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/640-20220520095506152-2022-05-20-wOfOkf.png" alt></p><ul><li>步骤 03. 从 hub 容器仓库中同步 alpine-jenkins-jnlp:v2.285 镜像到本地临时容器仓库中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo sync --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false --src docker --dest docker weiyigeek&#x2F;alpine-jenkins-jnlp:v2.285 192.168.12.111:5000&#x2F;</span><br><span class="line">  # INFO[0000] Tag presence check imagename&#x3D;&quot;weiyigeek&#x2F;alpine-jenkins-jnlp:v2.285&quot; tagged&#x3D;true</span><br><span class="line">  # INFO[0000] Copying image ref 1&#x2F;1 from&#x3D;&quot;docker:&#x2F;&#x2F;weiyigeek&#x2F;alpine-jenkins-jnlp:v2.285&quot; to&#x3D;&quot;docker:&#x2F;&#x2F;192.168.12.111:5000&#x2F;alpine-jenkins-jnlp:v2.285&quot;</span><br><span class="line">  # Getting image source signatures</span><br><span class="line">  # Copying blob 68517a8c32d3 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;-------------------------------] 45.0MiB &#x2F; 255.7MiB</span><br><span class="line">  # Copying blob 4c0d98bf9879 done</span><br></pre></td></tr></table></figure><ul><li>步骤 04. 以配置文件方式进行同步, 首先我们需要准备一个需要同步的资源清单。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># YAML 文件内容（用于 **--src yaml** 的源）</span><br><span class="line">$ cat &lt;&lt;&#39;EOF&#39; &gt; skopeo-sync.yml</span><br><span class="line">registry.example.com:</span><br><span class="line">  images:</span><br><span class="line">    busybox: []</span><br><span class="line">    redis:</span><br><span class="line">      - &quot;1.0&quot;</span><br><span class="line">      - &quot;2.0&quot;</span><br><span class="line">      - &quot;sha256:111111&quot;</span><br><span class="line">  images-by-tag-regex:</span><br><span class="line">      nginx: ^1\.13\.[12]-alpine-perl$</span><br><span class="line">  credentials:</span><br><span class="line">      username: john</span><br><span class="line">      password: this is a secret</span><br><span class="line">  tls-verify: true</span><br><span class="line">  cert-dir: &#x2F;home&#x2F;john&#x2F;certs</span><br><span class="line">quay.io:</span><br><span class="line">  tls-verify: false</span><br><span class="line">  images:</span><br><span class="line">    coreos&#x2F;etcd:</span><br><span class="line">      - latest</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 以yaml文件方式进行同步镜像到 my-registry.local.lan&#x2F;repo&#x2F; 仓库中</span><br><span class="line">$ skopeo sync --src yaml --dest docker skopeo-sync.yml my-registry.local.lan&#x2F;repo&#x2F;</span><br></pre></td></tr></table></figure><p>skopeo-sync.yml 文件中镜像匹配复制镜像说明:</p><ul><li><a href="http://registry.example.com/busybox" target="_blank" rel="noopener">registry.example.com/busybox</a> : 所有版本的镜像.</li><li><a href="http://registry.example.com/redis" target="_blank" rel="noopener">registry.example.com/redis</a> : 标记为“1.0”和“2.0”的图像以及带有摘要的图像&quot;sha256:0000000000000000000000000000000011111111111111111111111111111111&quot;.</li><li><a href="http://registry.example.com/nginx" target="_blank" rel="noopener">registry.example.com/nginx</a> : 图片标记为“1.13.1-alpine-perl”和“1.13.2-alpine-perl”.</li><li><a href="http://quay.io/coreos/etcd" target="_blank" rel="noopener">quay.io/coreos/etcd</a> : 拉取最新版本的镜像。</li></ul><h4><span id="325-skopeo-list-tags-仓库中镜像-tag-查看">3.2.5 Skopeo list-tags - 仓库中镜像 Tag 查看</span></h4><p>描述: 利用该命令我们可以列出 registry 上的某个镜像的所有 tag ，它是使用标准的 registry API 来获取镜像 tag。</p><p>简单示例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo list-tags docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest</span><br></pre></td></tr></table></figure><h4><span id="326-skopeo-delete-删除仓库中镜像-tag">3.2.6 Skopeo delete - 删除仓库中镜像 Tag</span></h4><p>描述: 使用该命令我们可以删除镜像 Tag,注意此处仅仅只是通过 registry API 来删除镜像的 tag（即删除了 tag 对 manifests 文件的引用）并非真正将镜像删除掉，如果想要删除镜像的 layer 还是需要通过 registry GC 的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 方式1. 利用 skopeo delete</span><br><span class="line">$ skopeo delete docker:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest --debug</span><br><span class="line">  # DEBU[0000] Loading registries configuration &quot;&#x2F;etc&#x2F;containers&#x2F;registries.conf&quot;</span><br><span class="line">  # DEBU[0000] Found credentials for harbor.weiyigeek.top in credential helper containers-auth.json in file &#x2F;home&#x2F;weiyigeek&#x2F;.docker&#x2F;config.json</span><br><span class="line">  # DEBU[0000] Using registries.d directory &#x2F;etc&#x2F;containers&#x2F;registries.d for sigstore configuration</span><br><span class="line">  # DEBU[0000]  No signature storage configuration found for harbor.weiyigeek.top&#x2F;devops&#x2F;busybox:latest, using built-in default file:&#x2F;&#x2F;&#x2F;home&#x2F;weiyigeek&#x2F;.local&#x2F;share&#x2F;containers&#x2F;sigstore</span><br><span class="line">  # DEBU[0000] Looking for TLS certificates and private keys in &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top</span><br><span class="line">  # DEBU[0000]  crt: &#x2F;etc&#x2F;docker&#x2F;certs.d&#x2F;harbor.weiyigeek.top&#x2F;harbor.crt</span><br><span class="line">  # DEBU[0000] GET https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F;</span><br><span class="line">  # DEBU[0000] Ping https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F; status 401</span><br><span class="line">  # DEBU[0000] GET https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;service&#x2F;token?account&#x3D;WeiyiGeek&amp;scope&#x3D;repository%3Adevops%2Fbusybox%3A%2A&amp;service&#x3D;harbor-registry</span><br><span class="line">  # DEBU[0000] GET https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F;devops&#x2F;busybox&#x2F;manifests&#x2F;latest</span><br><span class="line">  # DEBU[0000] DELETE https:&#x2F;&#x2F;harbor.weiyigeek.top&#x2F;v2&#x2F;devops&#x2F;busybox&#x2F;manifests&#x2F;sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  # DEBU[0000] Deleting &#x2F;home&#x2F;weiyigeek&#x2F;.local&#x2F;share&#x2F;containers&#x2F;sigstore&#x2F;devops&#x2F;busybox@sha256&#x3D;62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee&#x2F;signature-1</span><br><span class="line"></span><br><span class="line"># 方式2.利用 curl 命令进行 registery 进行删除 Tag。</span><br><span class="line">$ curl --header &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -I -X GET http:&#x2F;&#x2F;192.168.12.111:5000&#x2F;v2&#x2F;busybox&#x2F;manifests&#x2F;latest</span><br><span class="line">  # HTTP&#x2F;1.1 200 OK</span><br><span class="line">  # Content-Length: 527</span><br><span class="line">  # Content-Type: application&#x2F;vnd.docker.distribution.manifest.v2+json</span><br><span class="line">  # Docker-Content-Digest: sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  # Docker-Distribution-Api-Version: registry&#x2F;2.0</span><br><span class="line">  # Etag: &quot;sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee&quot;</span><br><span class="line">  # X-Content-Type-Options: nosniff</span><br><span class="line">  # Date: Thu, 20 Jan 2022 13:18:28 GMT</span><br><span class="line"></span><br><span class="line"># 一把梭织搞定</span><br><span class="line">$ Docker-Content-Digest&#x3D;$(curl -s --header &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -I -X GET http:&#x2F;&#x2F;192.168.12.111:5000&#x2F;v2&#x2F;busybox&#x2F;manifests&#x2F;latest | grep &quot;Docker-Content-Digest&quot; | cut -d &#39; &#39; -f 2)</span><br><span class="line">$ curl -I -X DELETE http:&#x2F;&#x2F;192.168.12.111:5000&#x2F;v2&#x2F;busybox&#x2F;manifests&#x2F;$&#123;Docker-Content-Digest&#125;</span><br></pre></td></tr></table></figure><h2><span id="4-镜像同步最佳实践">4. 镜像同步最佳实践</span></h2><p>本节，主要参考我前同事木子.其博客地址(<a href="https://blog.k8s.li" target="_blank" rel="noopener">https://blog.k8s.li</a>)。</p><h3><span id="41-指定文本中镜像同步">4.1 指定文本中镜像同步</span></h3><p>假如,给你一个镜像列表 images-list.txt, 其格式如下, 我们可以直接采用 shell 脚本调用 skopeo 进行执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># images-list.txt</span><br><span class="line">cat &lt;&lt;&#39;EOF&#39; &gt; images-list.txt</span><br><span class="line">kubesphere&#x2F;kube-apiserver:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-scheduler:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-proxy:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-controller-manager:v1.20.6</span><br><span class="line">kubesphere&#x2F;kube-apiserver:v1.19.8</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><strong>同步的 shell 脚本 <a href="http://skopeo-copy.sh" target="_blank" rel="noopener">skopeo-copy.sh</a></strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">GREEN_COL&#x3D;&quot;\\033[32;1m&quot;</span><br><span class="line">RED_COL&#x3D;&quot;\\033[1;31m&quot;</span><br><span class="line">NORMAL_COL&#x3D;&quot;\\033[0;39m&quot;</span><br><span class="line"></span><br><span class="line">SOURCE_REGISTRY&#x3D;$1</span><br><span class="line">TARGET_REGISTRY&#x3D;$2</span><br><span class="line"></span><br><span class="line"># shell 变量赋值，当没有从命令行中传递值给SOURCE_REGISTRY和TARGET_REGISTRY变量时，便采用下述值进行覆盖。</span><br><span class="line">: $&#123;IMAGES_LIST_FILE:&#x3D;&quot;images-list.txt&quot;&#125;</span><br><span class="line">: $&#123;TARGET_REGISTRY:&#x3D;&quot;hub.k8s.li&quot;&#125;</span><br><span class="line">: $&#123;SOURCE_REGISTRY:&#x3D;&quot;docker.io&quot;&#125;</span><br><span class="line"></span><br><span class="line">BLOBS_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">REPO_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line"></span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">CURRENT_NUM&#x3D;0</span><br><span class="line">ALL_IMAGES&#x3D;&quot;$(sed -n &#39;&#x2F;#&#x2F;d;s&#x2F;:&#x2F;:&#x2F;p&#39; $&#123;IMAGES_LIST_FILE&#125; | sort -u)&quot;</span><br><span class="line">TOTAL_NUMS&#x3D;$(echo &quot;$&#123;ALL_IMAGES&#125;&quot; | wc -l)</span><br><span class="line"></span><br><span class="line"># shopeo 拷贝函数，注意其传递的参数，此处值得学习记录。</span><br><span class="line">skopeo_copy() &#123;</span><br><span class="line"> if skopeo copy --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false \</span><br><span class="line"> --override-arch amd64 --override-os linux -q docker:&#x2F;&#x2F;$1 docker:&#x2F;&#x2F;$2; then</span><br><span class="line">  echo -e &quot;$GREEN_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 successful $NORMAL_COL&quot;</span><br><span class="line"> else</span><br><span class="line">  echo -e &quot;$RED_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 failed $NORMAL_COL&quot;</span><br><span class="line">  exit 2</span><br><span class="line"> fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 调用拷贝函数并记录当前执行序号。</span><br><span class="line">for image in $&#123;ALL_IMAGES&#125;; do</span><br><span class="line"> let CURRENT_NUM&#x3D;$&#123;CURRENT_NUM&#125;+1</span><br><span class="line"> skopeo_copy $&#123;SOURCE_REGISTRY&#125;&#x2F;$&#123;image&#125; $&#123;TARGET_REGISTRY&#125;&#x2F;$&#123;image&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ul><li><strong>执行命令和结果:</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ bash sync.sh docker.io localhost:5000</span><br><span class="line">Progress: 1&#x2F;143 sync docker.io&#x2F;alpine:3.14 to localhost:5000&#x2F;alpine:3.14 successful</span><br><span class="line">Progress: 2&#x2F;143 sync docker.io&#x2F;busybox:1.31.1 to localhost:5000&#x2F;busybox:1.31.1 successful</span><br><span class="line">....</span><br><span class="line">Progress: 142&#x2F;143 sync docker.io&#x2F;weaveworks&#x2F;scope:1.13.0 to localhost:5000&#x2F;weaveworks&#x2F;scope:1.13.0 successful</span><br><span class="line">Progress: 143&#x2F;143 sync docker.io&#x2F;wordpress:4.8-apache to localhost:5000&#x2F;wordpress:4.8-apache successful</span><br></pre></td></tr></table></figure><h3><span id="42-使用-registry-存储特性同步">4.2 使用 registry 存储特性同步</span></h3><p>描述: 将镜像从 registry 中同步到本地目录，使用 registry 存储的特性，将本地目录中的镜像转换成 registry 存储的格式, 这样的好处就是可以去除一些 skopeo dir 中重复的 layers，减少镜像的总大小。</p><ul><li><a href="http://convert-images.sh" target="_blank" rel="noopener">convert-images.sh</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eo pipefail</span><br><span class="line"></span><br><span class="line">GREEN_COL&#x3D;&quot;\\033[32;1m&quot;</span><br><span class="line">RED_COL&#x3D;&quot;\\033[1;31m&quot;</span><br><span class="line">NORMAL_COL&#x3D;&quot;\\033[0;39m&quot;</span><br><span class="line"></span><br><span class="line"># 命令行参数</span><br><span class="line">SOURCE_REGISTRY&#x3D;$1</span><br><span class="line">TARGET_REGISTRY&#x3D;$2</span><br><span class="line">IMAGES_DIR&#x3D;$2</span><br><span class="line"></span><br><span class="line">: $&#123;IMAGES_DIR:&#x3D;&quot;images&quot;&#125;</span><br><span class="line">: $&#123;IMAGES_LIST_FILE:&#x3D;&quot;images-list.txt&quot;&#125;</span><br><span class="line">: $&#123;SOURCE_REGISTRY:&#x3D;&quot;docker.io&quot;&#125;</span><br><span class="line">: $&#123;TARGET_REGISTRY:&#x3D;&quot;hub.k8s.li&quot;&#125;</span><br><span class="line"></span><br><span class="line"># hub.k8s.li 仓库服务器中的目录</span><br><span class="line">BLOBS_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">REPO_PATH&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line"></span><br><span class="line"># 记录当前数和总镜像数</span><br><span class="line">CURRENT_NUM&#x3D;0</span><br><span class="line">ALL_IMAGES&#x3D;&quot;$(sed -n &#39;&#x2F;#&#x2F;d;s&#x2F;:&#x2F;:&#x2F;p&#39; $&#123;IMAGES_LIST_FILE&#125; | sort -u)&quot;</span><br><span class="line">TOTAL_NUMS&#x3D;$(echo &quot;$&#123;ALL_IMAGES&#125;&quot; | wc -l)</span><br><span class="line"></span><br><span class="line"># 从远程仓库同步指定镜像到本地目录中。</span><br><span class="line">skopeo_sync() &#123;</span><br><span class="line"> if skopeo sync --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false \</span><br><span class="line"> --override-arch amd64 --override-os linux --src docker --dest dir $1 $2 &gt; &#x2F;dev&#x2F;null; then</span><br><span class="line">  echo -e &quot;$GREEN_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 successful $NORMAL_COL&quot;</span><br><span class="line"> else</span><br><span class="line">  echo -e &quot;$RED_COL Progress: $&#123;CURRENT_NUM&#125;&#x2F;$&#123;TOTAL_NUMS&#125; sync $1 to $2 failed $NORMAL_COL&quot;</span><br><span class="line">  exit 2</span><br><span class="line"> fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">convert_images() &#123;</span><br><span class="line"> rm -rf $&#123;IMAGES_DIR&#125;; mkdir -p $&#123;IMAGES_DIR&#125;</span><br><span class="line"> for image in $&#123;ALL_IMAGES&#125;; do</span><br><span class="line">  let CURRENT_NUM&#x3D;$&#123;CURRENT_NUM&#125;+1</span><br><span class="line">  </span><br><span class="line">  # 取 images-list.txt 文本中的每一行，并分隔存储。</span><br><span class="line">  image_name&#x3D;$&#123;image%%:*&#125;</span><br><span class="line">  image_tag&#x3D;$&#123;image##*:&#125;</span><br><span class="line">  image_repo&#x3D;$&#123;image%%&#x2F;*&#125;</span><br><span class="line"></span><br><span class="line">  # 函数调用 从仓库同步镜像到本地images目录</span><br><span class="line">  skopeo_sync $&#123;SOURCE_REGISTRY&#125;&#x2F;$&#123;image&#125; $&#123;IMAGES_DIR&#125;&#x2F;$&#123;image_repo&#125;</span><br><span class="line"></span><br><span class="line">  # 在本地images目录中，取得get image manifest sha256sum 信息</span><br><span class="line">  manifest&#x3D;&quot;$&#123;IMAGES_DIR&#125;&#x2F;$&#123;image&#125;&#x2F;manifest.json&quot;</span><br><span class="line">  manifest_sha256&#x3D;$(sha256sum $&#123;manifest&#125; | awk &#39;&#123;print $1&#125;&#39;)      # 62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  mkdir -p $&#123;BLOBS_PATH&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125; # docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&#x2F;62&#x2F;62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee</span><br><span class="line">  ln -f $&#123;manifest&#125; $&#123;BLOBS_PATH&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;&#x2F;data  #  该 data 文件实际上是镜像的 manifest.json 文件。</span><br><span class="line"></span><br><span class="line">  # make image repositories dir</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;&#123;_uploads,_layers,_manifests&#125;</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;&#123;current,index&#x2F;sha256&#125;</span><br><span class="line">  mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line"></span><br><span class="line">  # create image tag manifest link file</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link  # sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732deer</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;current&#x2F;link</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link</span><br><span class="line"></span><br><span class="line">  # link image layers file to registry blobs dir</span><br><span class="line">  for layer in $(sed &#39;&#x2F;v1Compatibility&#x2F;d&#39; $&#123;manifest&#125; | grep -Eo &quot;\b[a-f0-9]&#123;64&#125;\b&quot;); do  # 匹配 manifest.json 中&quot;digest&quot;两个不带sha256的值</span><br><span class="line">    mkdir -p $&#123;BLOBS_PATH&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;                 # 5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa 、 beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">    mkdir -p $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;  # 5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa 、 beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a</span><br><span class="line">    echo -n &quot;sha256:$&#123;layer&#125;&quot; &gt; $&#123;REPO_PATH&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;&#x2F;link  # sha256:5cc84ad355aaa64f46ea9c7bbcc319a9d808ab15088a27209c9e70ef86e5a2aa</span><br><span class="line">    ln -f $&#123;IMAGES_DIR&#125;&#x2F;$&#123;image&#125;&#x2F;$&#123;layer&#125; $&#123;BLOBS_PATH&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data     # 复制images目录中 &quot;application&#x2F;vnd.docker.container.image.v1+json&quot; 容器配置 config 与 多个 &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot; layer </span><br><span class="line">  done</span><br><span class="line"> done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">convert_images</span><br></pre></td></tr></table></figure><ul><li><a href="http://install.sh" target="_blank" rel="noopener">install.sh</a> : 使用这个脚本将 registry 存储中的镜像转换成 skopeo dir 的方式，然后再将镜像同步到 registry 中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">REGISTRY_DOMAIN&#x3D;&quot;harbor.k8s.li&quot;</span><br><span class="line">REGISTRY_PATH&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;registry&quot;</span><br><span class="line"></span><br><span class="line"># 切换到 registry 存储主目录下</span><br><span class="line">cd $&#123;REGISTRY_PATH&#125;</span><br><span class="line">gen_skopeo_dir() &#123;</span><br><span class="line">   # 定义 registry 存储的 blob 目录 和 repositories 目录，方便后面使用</span><br><span class="line">    BLOB_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">    REPO_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line">    # 定义生成 skopeo 目录</span><br><span class="line">    SKOPEO_DIR&#x3D;&quot;docker&#x2F;skopeo&quot;</span><br><span class="line">    # 通过 find 出 current 文件夹可以得到所有带 tag 的镜像，因为一个 tag 对应一个 current 目录</span><br><span class="line">    for image in $(find $&#123;REPO_DIR&#125; -type d -name &quot;current&quot;); do</span><br><span class="line">        # 根据镜像的 tag 提取镜像的名字</span><br><span class="line">        name&#x3D;$(echo $&#123;image&#125; | awk -F &#39;&#x2F;&#39; &#39;&#123;print $5&quot;&#x2F;&quot;$6&quot;:&quot;$9&#125;&#39;)</span><br><span class="line">        link&#x3D;$(cat $&#123;image&#125;&#x2F;link | sed &#39;s&#x2F;sha256:&#x2F;&#x2F;&#39;)</span><br><span class="line">        mfs&#x3D;&quot;$&#123;BLOB_DIR&#125;&#x2F;$&#123;link:0:2&#125;&#x2F;$&#123;link&#125;&#x2F;data&quot;</span><br><span class="line">        # 创建镜像的硬链接需要的目录</span><br><span class="line">        mkdir -p &quot;$&#123;SKOPEO_DIR&#125;&#x2F;$&#123;name&#125;&quot;</span><br><span class="line">        # 硬链接镜像的 manifests 文件到目录的 manifest 文件</span><br><span class="line">        ln $&#123;mfs&#125; $&#123;SKOPEO_DIR&#125;&#x2F;$&#123;name&#125;&#x2F;manifest.json</span><br><span class="line">        # 使用正则匹配出所有的 sha256 值，然后排序去重</span><br><span class="line">        layers&#x3D;$(grep -Eo &quot;\b[a-f0-9]&#123;64&#125;\b&quot; $&#123;mfs&#125; | sort -n | uniq)</span><br><span class="line">        for layer in $&#123;layers&#125;; do</span><br><span class="line">          # 硬链接 registry 存储目录里的镜像 layer 和 images config 到镜像的 dir 目录</span><br><span class="line">            ln $&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data $&#123;SKOPEO_DIR&#125;&#x2F;$&#123;name&#125;&#x2F;$&#123;layer&#125;</span><br><span class="line">        done</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line">sync_image() &#123;</span><br><span class="line">    # 使用 skopeo sync 将 dir 格式的镜像同步到 harbor</span><br><span class="line">    for project in $(ls $&#123;SKOPEO_DIR&#125;); do</span><br><span class="line">        skopeo sync --insecure-policy --src-tls-verify&#x3D;false --dest-tls-verify&#x3D;false \</span><br><span class="line">        --src dir --dest docker $&#123;SKOPEO_DIR&#125;&#x2F;$&#123;project&#125; $&#123;REGISTRY_DOMAIN&#125;&#x2F;$&#123;project&#125;</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line">gen_skopeo_dir</span><br></pre></td></tr></table></figure><blockquote><p>温馨提示: 此种方式是有些复杂对于大镜像的复制是推荐的, 而对于一些小镜像且显得多余。</p></blockquote><h3><span id="43-从-registry-存储中-select-出镜像进行同步">4.3 从 registry 存储中 select 出镜像进行同步</span></h3><p>描述: 先将镜像同步到一个 registry 中，再将镜像从 registry 存储中捞出来，该 registry 可以当作一个镜像存储的池子，我们使用 Linux 中硬链接的特性将镜像&quot;复制&quot;一份出来，然后再打一个 tar 包, 这样做的好处就是每次打包镜像的时候都能复用历史的镜像数据，而且性能极快。</p><ul><li>步骤 01. 先将镜像同步到一个固定的 registry 中。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bash skopeo-copy.sh docker.io localhost:5000</span><br></pre></td></tr></table></figure><ul><li>步骤 02. 使用该脚本将镜像从 registry 存储中捞出来</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eo pipefail</span><br><span class="line"># 命令行变量</span><br><span class="line">IMAGES_LIST&#x3D;&quot;$1&quot;</span><br><span class="line">REGISTRY_PATH&#x3D;&quot;$2&quot;</span><br><span class="line">OUTPUT_DIR&#x3D;&quot;$3&quot;</span><br><span class="line"></span><br><span class="line"># Registry 仓库数据目录</span><br><span class="line">BLOB_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F;sha256&quot;</span><br><span class="line">REPO_DIR&#x3D;&quot;docker&#x2F;registry&#x2F;v2&#x2F;repositories&quot;</span><br><span class="line"></span><br><span class="line"># 判断输出目录是否存在如不存在则移除。</span><br><span class="line">if [ -d $&#123;OUTPUT_DIR&#125; ];then</span><br><span class="line">  rm -rf $&#123;OUTPUT_DIR&#125;;</span><br><span class="line">fi</span><br><span class="line">mkdir -p $&#123;OUTPUT_DIR&#125;</span><br><span class="line"></span><br><span class="line">for image in $(find $&#123;IMAGES_LIST&#125; -type f -name &quot;*.list&quot; | xargs grep -Ev &#39;^#|^&#x2F;&#39; | grep &#39;:&#39;); do</span><br><span class="line">  # 镜像名称和Tag</span><br><span class="line">  image_name&#x3D;$&#123;image%%:*&#125;</span><br><span class="line">  image_tag&#x3D;$&#123;image##*:&#125;</span><br><span class="line"></span><br><span class="line">  # link 路径获取</span><br><span class="line">  tag_link&#x3D;$&#123;REGISTRY_PATH&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;current&#x2F;link</span><br><span class="line">  manifest_sha256&#x3D;$(sed &#39;s&#x2F;sha256:&#x2F;&#x2F;&#39; $&#123;tag_link&#125;)</span><br><span class="line">  manifest&#x3D;$&#123;REGISTRY_PATH&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;&#x2F;data</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line"></span><br><span class="line">  # 强制硬链接到指定目录</span><br><span class="line">  ln -f $&#123;manifest&#125; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;manifest_sha256:0:2&#125;&#x2F;$&#123;manifest_sha256&#125;&#x2F;data</span><br><span class="line"></span><br><span class="line">  # make image repositories dir</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;&#123;_uploads,_layers,_manifests&#125;</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;&#123;current,index&#x2F;sha256&#125;</span><br><span class="line">  mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;</span><br><span class="line"></span><br><span class="line">  # create image tag manifest link file  </span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;current&#x2F;link</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;revisions&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link</span><br><span class="line">  echo -n &quot;sha256:$&#123;manifest_sha256&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_manifests&#x2F;tags&#x2F;$&#123;image_tag&#125;&#x2F;index&#x2F;sha256&#x2F;$&#123;manifest_sha256&#125;&#x2F;link</span><br><span class="line"></span><br><span class="line">  # 强制创建 &#x2F;docker&#x2F;registry&#x2F;v2&#x2F;blobs&#x2F; 各 layer data 文件到指定目录之中</span><br><span class="line">  for layer in $(sed &#39;&#x2F;v1Compatibility&#x2F;d&#39; $&#123;manifest&#125; | grep -Eo &#39;\b[a-f0-9]&#123;64&#125;\b&#39; | sort -u); do</span><br><span class="line">      mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;</span><br><span class="line">      mkdir -p $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;</span><br><span class="line">      ln -f $&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;BLOB_DIR&#125;&#x2F;$&#123;layer:0:2&#125;&#x2F;$&#123;layer&#125;&#x2F;data</span><br><span class="line">      echo -n &quot;sha256:$&#123;layer&#125;&quot; &gt; $&#123;OUTPUT_DIR&#125;&#x2F;$&#123;REPO_DIR&#125;&#x2F;$&#123;image_name&#125;&#x2F;_layers&#x2F;sha256&#x2F;$&#123;layer&#125;&#x2F;link</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>至此完毕！</p><blockquote><p>本文转载自：「 WeiyiGeek 」，原文：<a href="https://url.hi-linux.com/xCmXo/" target="_blank" rel="noopener">https://url.hi-linux.com/xCmXo/</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-基础介绍&quot;&gt;1. 基础介绍&lt;/h2&gt;
&lt;p&gt;描述: 作为公司内部 PaaS toB 产品的打包发布人员，容器镜像对我们打工人而言就像是工地上的砖头 🧱，而我的一部分工作就是将这些砖头在各个仓库之间搬来搬去，最终将这些砖头打包放在产品的安装包中，形成一个完整的 PaaS 产品安装包。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q: 在 PaaS (平台即服务)中的大家常说的 ToB 与 ToC 到底是什么?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;ToC 面向普通用户服务, 主要是让用户体验感好，解决用户使用方面的问题记录，并返回给前后端开发。&lt;br&gt;
ToB 是面向企业用户服务, 产品可用、其中最关键是让Boss使用Happly!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Q: 假如有如下场景，我们从 dockerhub 公共仓库中下载一个 GB 以上的镜像，到本地的私有仓库中，我想通常你会这样做先 &lt;code&gt;docker pull&lt;/code&gt; 到本地，然后使用 &lt;code&gt;docker tag&lt;/code&gt; 更改为私有仓库地址加上镜像名称版本，最后再使用&lt;code&gt;docker push&lt;/code&gt; 上传镜像到私有仓库中，以供其它内网机器拉取并使用。虽然该方法是可行，但是如果有多个大于 GB 以上的镜像需要上传到私有仓库，每次都要先解压 layer 到本地，然后再压缩 layer 上传到私有仓库中，你能想象此过程花费的时间有多久吗? 对于我们运维工程师来说时间就是金钱，所以需想尽一切方法来节约时间成本，那有没有一种办法可以直接将 registry 上的 blob 复制到另一个 registry，中间过程不涉及对镜像 layer 的解压缩，这岂不美哉。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;解决方案当然是存在的，如果你不想使用docker进行images镜像拉取上传，我们完成可以使用skope工具来完全替代 docker-cli 来搬运镜像，skopeo是一个命令行实用程序，可对容器映像和映像存储库执行各种操作。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="Skopeo" scheme="https://www.hi-linux.com/tags/Skopeo/"/>
    
  </entry>
  
  <entry>
    <title>轻量级 Kubernetes 集群发行版 K3s 完全进阶指南</title>
    <link href="https://www.hi-linux.com/posts/907.html"/>
    <id>https://www.hi-linux.com/posts/907.html</id>
    <published>2022-05-20T01:00:00.000Z</published>
    <updated>2022-05-20T01:22:25.012Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>深入理解官方文档，轻松学会使用 K3S 工具！</strong></p></blockquote><p><code>K3s</code> 是一个轻量级的 <code>Kubernetes</code> 发行版，它针对边缘计算、物联网等场景进行了高度优化。</p><ul><li><code>CNCF</code> 认证的 <code>Kubernetes</code> 发行版</li><li>支持 <code>X86_64</code>, <code>ARM64</code>, <code>ARMv7</code> 平台</li><li>单一进程包含 <code>Kubernetes master</code>，<code>kubelet</code> 和 <code>containerd</code></li></ul><a id="more"></a><h2><span id="1-k3s-工具介绍">1. K3S 工具介绍</span></h2><blockquote><p><strong>为你提供 k3s 的产品介绍</strong></p></blockquote><p><code>K3s</code> 有以下增强功能：</p><ul><li>打包为单个二进制文件<ul><li>把 <code>K8S</code> 相关的组件，比如 <code>kube-api</code>/ <code>kube-manager</code> 都打包到同一个二进制文件里面，这样的话，只需要启动这个文件就可以快速的启动对应的组件。</li></ul></li><li>使用基于 sqlite3 的默认存储机制<ul><li>同时支持使用 <code>etcd3</code>、<code>MySQL</code> 和 <code>PostgreSQL</code> 作为存储机制。</li></ul></li><li>默认情况下是安全的<ul><li>在 <code>K3s</code> 中有一个默认的证书管理机制(默认一年有效期)，也有一个可以轮转证书的功能(就是在小于九十天之内重启 <code>K3s</code> 的话，就会自动续一年)。</li></ul></li><li>功能强大的 <code>batteries-included</code> 功能<ul><li>就是虽然有些服务本身这个二进制文件并没有提供，但是可以通过内置的服务，将配置文件放到指定的目录下面，就可以在启动的时候一并将该服务启动或替换默认组件。</li></ul></li><li>所有 <code>K8S control-plane</code> 组件都封装在单个二进制文件和进程中<ul><li>因为封装在二进制文件中，所以启动的时候只有一个进程。好处在于只需要管理这个单一进程就可以了，同时也具备操作复杂集群的能力。</li></ul></li><li>最大程度减轻了外部依赖性<ul><li>即稍新一点的 <code>Linux</code> 内核就可以了(需要 <code>kernel</code> 和 <code>cgroup</code> 挂载)。</li></ul></li></ul><p>之所以叫做 <code>K3S</code> 是因为希望安装的 <code>K8S</code> 在内存占用方面只是一半的大小，而一半大的东西就是一个 <code>5</code> 个字母的单词，简写为 <code>K3S</code>。</p><ul><li>生命周期<ul><li>同时支持 <code>3</code> 个 <code>K8s</code> 版本，支持的生命周期与 <code>K8s</code> 相同</li><li>可以参考: <a href="https://kubernetes.io/zh/docs/setup/release/version-skew-policy/" target="_blank" rel="noopener">Kubernetes 版本及版本偏差支持策略</a> 进行学习</li></ul></li><li>更新周期<ul><li>当 <code>K8s</code> 更新新版本后，一般 <code>K3s</code> 在一周内同步更新</li><li>可以通过 <a href="https://update.k3s.io/v1-release/channels" target="_blank" rel="noopener">这个链接</a> 获取 <strong><code>latest</code>/<code>stable</code>/<code>testing</code></strong> 版本</li><li>我们默认安装的是 <code>stable</code> 版本，可以运行通过命令进行查看</li></ul></li><li>命名规范<ul><li><strong>v1.20.4+k3s1</strong>: <code>v1.20.4</code> 为 <code>K8s</code> 版本，<code>k3s1</code> 为补丁版本</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># K3s软件包需要的依赖项</span></span><br><span class="line">containerd  <span class="comment"># 容器运行时(可以使用docker替代)</span></span><br><span class="line">Flannel     <span class="comment"># 网络</span></span><br><span class="line">CoreDNS     <span class="comment"># DNS</span></span><br><span class="line">CNI         <span class="comment"># CNI</span></span><br><span class="line">Traefik     <span class="comment"># 默认的controller服务(apisix/ingress-controller)</span></span><br><span class="line">iptables    <span class="comment"># 主机实用程序</span></span><br><span class="line">service load balancer     <span class="comment"># 嵌入式服务负载均衡器</span></span><br><span class="line">network policy controller <span class="comment"># 嵌入式网络策略控制器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># K3s适用于以下场景</span></span><br><span class="line">CI</span><br><span class="line">Development</span><br><span class="line">ARM</span><br><span class="line">嵌入 K8s</span><br><span class="line">物联网-IoT</span><br><span class="line">边缘计算-Edge</span><br></pre></td></tr></table></figure><p>与此同时，<code>Rancher</code> 中国团队推出了一款针对 <code>K3s</code> 的效率提升工具：<strong>AutoK3s</strong>。只需要输入一行命令，即可快速创建 <code>K3s</code> 集群并添加指定数量的 <code>master</code> 节点和 <code>worker</code> 节点。</p><h2><span id="2-k3s-快速入门">2. K3S 快速入门</span></h2><blockquote><p><strong>原理就是，将 K8S 的相关组件封装到 K3S 的二进制文件中去！</strong></p></blockquote><p>原理就是，将 <code>K8S</code> 的相关组件封装到 <code>K3S</code> 的二进制文件中去，然后启动这二进制文件就可以启动一个成熟的 <code>K8S</code> 集群。我们可以看到 <code>K3S</code> 和 <code>K8S</code> 的架构基本差不多，其中 <code>k3s-server</code> 对应这个 <code>control-plane</code>，而 <code>k3s-agent</code> 对应着 <code>node</code> 节点。</p><p>可以看到 <code>k3s</code> 中使用的默认存储是 <code>SQLite</code>(自带)，且默认的网络使用的是 <code>Flannel</code>(自带)。当服务端和客户端都启动之后，通过 <code>Tunnel-Proxy</code> 这个组件进行通信，通过这个通道去管理网络流量。在 <code>agent</code> 节点中，通过 <code>kubelet</code> 操作 <code>contaninerd</code> 来创建对应 <code>Pod</code>。</p><ul><li>K3s 架构</li></ul><p><img src="https://img.hi-linux.com/staticfile/advance-k3s-tool-01-2022-05-19-1NJdKE.jpg" alt="K3S工具进阶指南"></p><ul><li>K8s 架构</li></ul><p><img src="https://img.hi-linux.com/staticfile/advance-k3s-tool-02-20220519092405817-2022-05-19-tva27I.png" alt="K3S工具进阶指南"></p><p>国内的话，建议使用官方提供的 <a href="https://mirror.rancher.cn/" target="_blank" rel="noopener">镜像地址</a>，这样不但可以加速本地 <code>K3s</code> 的时候，而且方便部署和更新服务。这也是为什么建议国内使用 <code>k3s-install.sh</code> 部署服务的原因，因为其内部使用的地址都是从国内去获取的。</p><h2><span id="3-k3s-安装事项">3. K3S 安装事项</span></h2><h3><span id="31-安装指南">3.1 安装指南</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><p>虽然可以通过下载二进制文件进行服务端和工作节点的运行(<code>./k3s server</code>)，但是一旦我们退出进程，之前创建的节点也就立即销毁了，所以还是建议使用脚本进行安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主节点</span></span><br><span class="line">$ ./k3s server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 工作节点</span></span><br><span class="line">$ ./k3s agent K3S_URL=xxx K3S_TOKEN=xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清除垃圾文件</span></span><br><span class="line">$ rm -rf /etc/rancher /var/lib/rancher</span><br></pre></td></tr></table></figure><ul><li>镜像加速</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加配置</span></span><br><span class="line">$ cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt;EOF</span><br><span class="line">mirrors:</span><br><span class="line">  <span class="string">"docker.io"</span>:</span><br><span class="line">    endpoint:</span><br><span class="line">      - <span class="string">"https://fogjl973.mirror.aliyuncs.com"</span></span><br><span class="line">      - <span class="string">"https://registry-1.docker.io"</span></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">$ sudo systemctl restart k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否生效</span></span><br><span class="line">$ sudo crictl info | grep -A 2 <span class="string">"endpoint"</span></span><br></pre></td></tr></table></figure><p><code>K3s</code> 提供了一个安装脚本，可以方便的在 <code>systemd</code> 或 <code>openrc</code> 的系统上将其作为服务安装。运行此安装后，<code>K3s</code> 服务将被配置为在节点重启后或进程崩溃或被杀死时自动重启。</p><ul><li><p>安装内容</p><ul><li><code>kubectl</code>、<code>crictl</code>、<code>ctr</code></li><li><code>k3s-killall.sh</code>、<code>k3s-uninstall.sh</code></li></ul></li><li><p>执行操作</p><ul><li>将 <code>kubeconfig</code> 文件写入到 <code>/etc/rancher/k3s/k3s.yaml</code> 里面</li><li>由 <code>K3s</code> 安装的 <code>kubectl</code> 工具将自动使用该文件的配置来运行</li><li>其他机器可以通过复制这个配置文件并修改 <code>server</code> 地址来操作 <code>K3s</code> 集群</li></ul></li><li><p>主节点 - 192.168.100.100</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装脚本</span></span><br><span class="line"><span class="comment"># https://get.k3s.io</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建议使用这个安装脚本(国内化了)</span></span><br><span class="line">$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_NODE_NAME=k3s1 \</span><br><span class="line">    K3S_KUBECONFIG_OUTPUT=/home/escape/.kube/config \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--docker"</span> sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找stable分支版本信息</span></span><br><span class="line">[INFO]  Finding release <span class="keyword">for</span> channel stable</span><br><span class="line">[INFO]  Using v1.23.6+k3s1 as release</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取国内镜像版本地址</span></span><br><span class="line">[INFO]  Downloading <span class="built_in">hash</span> https://rancher-mirror.rancher.cn/k3s/v1.23.6-k3s1/sha256sum-amd64.txt</span><br><span class="line">[INFO]  Downloading binary https://rancher-mirror.rancher.cn/k3s/v1.23.6-k3s1/k3s</span><br><span class="line">[INFO]  Verifying binary download</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装k3s二进制工具并链接相关工具(内置)</span></span><br><span class="line">[INFO]  Installing k3s to /usr/<span class="built_in">local</span>/bin/k3s</span><br><span class="line">[INFO]  Skipping installation of SELinux RPM</span><br><span class="line">[INFO]  Creating /usr/<span class="built_in">local</span>/bin/kubectl symlink to k3s</span><br><span class="line">[INFO]  Creating /usr/<span class="built_in">local</span>/bin/crictl symlink to k3s</span><br><span class="line">[INFO]  Skipping /usr/<span class="built_in">local</span>/bin/ctr symlink to k3s, <span class="built_in">command</span> exists <span class="keyword">in</span> PATH at /usr/bin/ctr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装清除和卸载k3s生成的配置和工具</span></span><br><span class="line">[INFO]  Creating killall script /usr/<span class="built_in">local</span>/bin/k3s-killall.sh</span><br><span class="line">[INFO]  Creating uninstall script /usr/<span class="built_in">local</span>/bin/k3s-uninstall.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见了两个systemd的配置</span></span><br><span class="line">[INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env</span><br><span class="line">[INFO]  systemd: Creating service file /etc/systemd/system/k3s.service</span><br><span class="line">[INFO]  systemd: Enabling k3s unit</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service → /etc/systemd/system/k3s.service.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动k3s服务</span></span><br><span class="line">[INFO]  systemd: Starting k3s</span><br></pre></td></tr></table></figure><ul><li>工作节点 - 192.168.100.101</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 工作节点上安装并将它们添加到集群</span></span><br><span class="line"><span class="comment"># https://docs.rancher.cn/docs/k3s/architecture/_index#注册-agent-节点</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | \</span><br><span class="line">    K3S_URL=https://myserver:6443 \</span><br><span class="line">    K3S_TOKEN=mynodetoken sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建议使用这个安装命令(国内化了)</span></span><br><span class="line"><span class="comment"># K3S_URL: 会使K3s以worker模式运行</span></span><br><span class="line"><span class="comment"># K3S_TOKEN: 使用的值存储在你的服务器节点上</span></span><br><span class="line"><span class="comment"># K3S_NODE_NAME: 为每个节点提供一个有效且唯一的主机名</span></span><br><span class="line">$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_NODE_NAME=k3s2 \</span><br><span class="line">    K3S_KUBECONFIG_OUTPUT=/home/escape/.kube/config \</span><br><span class="line">    K3S_URL=https://192.168.100.100:6443 \</span><br><span class="line">    K3S_TOKEN=mynodetoken sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># mynodetoken</span></span><br><span class="line">$ sudo cat /var/lib/rancher/k3s/server/token</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找stable分支版本信息</span></span><br><span class="line">[INFO]  Finding release <span class="keyword">for</span> channel stable</span><br><span class="line">[INFO]  Using v1.23.6+k3s1 as release</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取国内镜像版本地址</span></span><br><span class="line">[INFO]  Downloading <span class="built_in">hash</span> https://rancher-mirror.rancher.cn/k3s/v1.23.6-k3s1/sha256sum-amd64.txt</span><br><span class="line">[INFO]  Downloading binary https://rancher-mirror.rancher.cn/k3s/v1.23.6-k3s1/k3s</span><br><span class="line">[INFO]  Verifying binary download</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装k3s二进制工具并链接相关工具(内置)</span></span><br><span class="line">[INFO]  Installing k3s to /usr/<span class="built_in">local</span>/bin/k3s</span><br><span class="line">[INFO]  Creating /usr/<span class="built_in">local</span>/bin/kubectl symlink to k3s</span><br><span class="line">[INFO]  Creating /usr/<span class="built_in">local</span>/bin/crictl symlink to k3s</span><br><span class="line">[INFO]  Skipping /usr/<span class="built_in">local</span>/bin/ctr symlink to k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装清除和卸载k3s生成的配置和工具</span></span><br><span class="line">[INFO]  Creating killall script /usr/<span class="built_in">local</span>/bin/k3s-agent-killall.sh</span><br><span class="line">[INFO]  Creating uninstall script /usr/<span class="built_in">local</span>/bin/k3s-agent-uninstall.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见了两个systemd的配置</span></span><br><span class="line">[INFO]  env: Creating environment file /etc/systemd/system/k3s-agent.service.env</span><br><span class="line">[INFO]  systemd: Creating service file /etc/systemd/system/k3s-agent.service</span><br><span class="line">[INFO]  systemd: Enabling k3s-agent unit</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/k3s-agent.service → /etc/systemd/system/k3s-agent.service.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动k3s服务</span></span><br><span class="line">[INFO]  systemd: Starting k3s-agent</span><br></pre></td></tr></table></figure><h3><span id="32-配置要求">3.2 配置要求</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><ul><li>[1] 先决条件<ul><li>选择上，两个节点不能有相同的主机名</li><li>不修改主机名可以通过添加随机后缀或指定主机名</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为每个节点添加随机后缀</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.100.100:6443 \</span><br><span class="line">    K3S_TOKEN=xxx sh -s - --with-node-id</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个节点指定主机名</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    K3S_NODE_NAME=<span class="string">"k3s2"</span> INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    K3S_URL=https://192.168.64.3:6443 K3S_TOKEN=xxx sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个节点指定主机名</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.64.3:6443 \</span><br><span class="line">    K3S_TOKEN=xxx sh -s - --node-name k3s2</span><br></pre></td></tr></table></figure><ul><li>[2] 硬件信息<ul><li>操作系统：可以在大多数现代 <code>Linux</code> 系统上运行</li><li>磁盘设备：<code>K3s</code> 的性能取决于数据库的性能(建议使用 <code>SSD</code> 硬盘)</li><li>网络相关：<code>K3s Server</code> 节点的入站规则，所有出站流量都是允许的</li></ul></li></ul><table><thead><tr><th style="text-align:left">协议</th><th style="text-align:left">端口</th><th style="text-align:left">源</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">TCP</td><td style="text-align:left">6443</td><td style="text-align:left">K3s agent 节点</td><td style="text-align:left">Kubernetes API Server</td></tr><tr><td style="text-align:left">UDP</td><td style="text-align:left">8472</td><td style="text-align:left">K3s server 和 agent 节点</td><td style="text-align:left">仅对 Flannel VXLAN 需要</td></tr><tr><td style="text-align:left">TCP</td><td style="text-align:left">10250</td><td style="text-align:left">K3s server 和 agent 节点</td><td style="text-align:left">Kubelet metrics</td></tr><tr><td style="text-align:left">TCP</td><td style="text-align:left">2379-2380</td><td style="text-align:left">K3s server 节点</td><td style="text-align:left">只有嵌入式 etcd 高可用才需要</td></tr></tbody></table><ul><li>[3] 安装选项<ul><li><a href="https://docs.rancher.cn/docs/k3s/autok3s/_index" target="_blank" rel="noopener">官方安装参数文档</a></li><li><a href="https://github.com/kingsd041/k3s-tutorial/blob/main/03-%E5%AE%89%E8%A3%85-%E8%A6%81%E6%B1%82%E5%8F%8A%E9%80%89%E9%A1%B9/README.md" target="_blank" rel="noopener">安装选项示例演示</a></li></ul></li></ul><table><thead><tr><th style="text-align:left">Environment Variable</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left"><code>INSTALL_K3S_EXEC</code></td><td style="text-align:left">用于在服务中启动 <code>K3s</code> 的后续子命令</td></tr><tr><td style="text-align:left"><code>K3S_CONFIG_FILE</code></td><td style="text-align:left">指定配置文件的位置</td></tr><tr><td style="text-align:left"><code>K3S_TOKEN</code></td><td style="text-align:left">用于将 <code>server/agent</code> 加入集群的共享 <code>secret</code> 值</td></tr><tr><td style="text-align:left"><code>K3S_TOKEN_FILE</code></td><td style="text-align:left">用于将 <code>server/agent</code> 加入集群的共享 <code>secret</code> 文件</td></tr><tr><td style="text-align:left"><code>INSTALL_K3S_VERSION</code></td><td style="text-align:left">指定下载 <code>K3s</code> 的版本</td></tr><tr><td style="text-align:left"><code>K3S_TOKEN_FILE</code></td><td style="text-align:left">指定  <code>cluster-secret</code>/<code>token</code> 的文件目录</td></tr><tr><td style="text-align:left"><code>INSTALL_K3S_SKIP_START</code></td><td style="text-align:left">将不会启动 <code>K3s</code> 服务</td></tr><tr><td style="text-align:left"><code>INSTALL_K3S_SKIP_DOWNLOAD</code></td><td style="text-align:left">用于离线安装；设置之后不会下载远程工具</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 其实就把对应参数加到systemd配置文件里面去了</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--docker"</span> sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动化部署(不用获取token值了)</span></span><br><span class="line"><span class="comment"># 主节点和工作节点使用我们指定的key来通信</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    K3S_TOKEN=rancher-k3s sh -</span><br><span class="line">$ sudo cat /var/lib/rancher/k3s/server/token</span><br></pre></td></tr></table></figure><ul><li>[4] 其他说明<ul><li>运行 <code>agent</code> 时还必须设置 <code>K3S_TOKEN</code></li><li>以 <code>K3S_</code> 开头的环境变量将被保留，供 <code>systemd/openrc</code> 使用</li><li>没有明确设置 <code>exec</code> 并设置 <code>K3S_URL</code> 的话会将命令默认为工作节点</li></ul></li></ul><h3><span id="33-命令参数">3.3 命令参数</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><p>在整个 K3s 文档中，你会看到一些选项可以作为命令标志和环境变量传递进来，那该如何使用标志和环境变量呢？</p><ul><li>[1] 使用标志和环境变量</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用标志</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE=<span class="string">"644"</span> sh -s -</span><br><span class="line">$ curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644</span><br><span class="line"></span><br><span class="line"><span class="comment"># 环境变量</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--flannel-backend none"</span> sh -s -</span><br><span class="line">$ curl -sfL https://get.k3s.io | \</span><br><span class="line">    sh -s - server --flannel-backend none</span><br></pre></td></tr></table></figure><ul><li>[2] K3s Server/Agent - 常用配置</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># write-kubeconfig</span></span><br><span class="line"><span class="comment"># 将管理客户端的kubeconfig写入这个文件</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    K3S_KUBECONFIG_OUTPUT=/root/.kube/config \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用docker作为容器运行时</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--docker"</span> sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定运行时工具</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--container-runtime-endpoint containerd"</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置私有镜像仓库配置文件</span></span><br><span class="line"><span class="comment"># 默认配置文件: /etc/rancher/k3s/registries.yaml</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--private-registry xxx"</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 针对多网卡主机安装K3s集群</span></span><br><span class="line"><span class="comment"># 默认多网卡会使用默认网关的那个卡</span></span><br><span class="line">$ rout -n</span><br><span class="line"></span><br><span class="line"><span class="comment"># K3s server</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--node-ip=192.168.100.100"</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># K3s agent</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    K3S_URL=https://192.168.99.211:6443 K3S_TOKEN=xxx \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--node-ip=192.168.100.100"</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --tls-san</span></span><br><span class="line"><span class="comment"># 在TLS证书中添加其他主机名或IP作为主机备用名称</span></span><br><span class="line"><span class="comment"># 即在公网环境下允许通过公网IP访问控制、操作远程集群</span></span><br><span class="line"><span class="comment"># 或者部署多个Server并使用LB进行负责，就需要保留公网地址</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">"--tls-san 1.1.1.1"</span>  \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取配置</span></span><br><span class="line">$ kubectl get secret k3s-serving -n kube-system -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后本机复制公网主节点对应的yaml文件即可本地操作了</span></span><br><span class="line">$ scp ci@1.1.1.1:/etc/rancher/k3s/k3s.yaml ~/.kube/config</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改启动的服务对应配置(调整节点的启动的最大Pod数量)</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--kubelet-arg=max-pods=200'</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改启动的服务对应配置(使用ipvs作为服务调度工具)</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--kube-proxy-arg=proxy-mode=ipvs'</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改启动的服务对应配置(调整服务启动的端口范围)</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--kube-apiserver-arg=service-node-port-range=40000-50000'</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubelet-arg     --kubelet-arg</span></span><br><span class="line"><span class="comment"># kube-apiserver  --kube-apiserver-arg</span></span><br><span class="line"><span class="comment"># kube-proxy-arg  --kube-proxy-arg</span></span><br><span class="line"><span class="comment"># kube-proxy-arg  --kube-proxy-arg=proxy-mode=ipvs</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --data-dir</span></span><br><span class="line"><span class="comment"># 修改K3s数据存储目录</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--data-dir=/opt/k3s-data'</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 禁用组件</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--disable traefik'</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自己加自己需要的服务</span></span><br><span class="line">$ ls /var/lib/rancher/k3s/server/manifests</span><br><span class="line">$ kubectl get pods -A | grep traefik</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加label和taint标识</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--node-label foo=bar,hello=world \</span></span><br><span class="line"><span class="string">        --node-taint key1=value1:NoExecute'</span></span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看一下</span></span><br><span class="line">$ kubectl describe nodes</span><br></pre></td></tr></table></figure><ul><li>[3] K3s Server/Agent - 数据库选项</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定数据源名称</span></span><br><span class="line"><span class="comment"># 标志位: --datastore-endpoint&amp;nbsp;value</span></span><br><span class="line"><span class="comment"># 环境变量: K3S_DATASTORE_ENDPOINT</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--datastore-endpoint&amp;nbsp;etcd'</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cron规范中的快照间隔时间</span></span><br><span class="line"><span class="comment"># --etcd-snapshot-schedule-cron&amp;nbsp;value</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--etcd-snapshot-schedule-cron *&amp;nbsp;*/5&amp;nbsp;*&amp;nbsp;*&amp;nbsp;*'</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><h3><span id="34-网络选项">3.4 网络选项</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><p>默认情况下，<code>K3s</code> 将以 <code>flannel</code> 作为 <code>CNI</code> 运行，使用 <code>VXLAN</code> 作为默认后端，<code>CNI</code> 和默认后端都可以通过参数修改。要启用加密，请使用下面的 <code>IPSec</code> 或 <code>WireGuard</code> 选项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认安装K3s之后的网络配置</span></span><br><span class="line">$ sudo cat /var/lib/rancher/k3s/agent/etc/flannel/net-conf.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"Network"</span>: <span class="string">"10.42.0.0/16"</span>,</span><br><span class="line">    <span class="string">"EnableIPv6"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"EnableIPv4"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"IPv6Network"</span>: <span class="string">"::/0"</span>,</span><br><span class="line">    <span class="string">"Backend"</span>: &#123;</span><br><span class="line">        <span class="string">"Type"</span>: <span class="string">"vxlan"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">CLI Flag 和 Value</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>--flannel-backend=vxlan</code></td><td style="text-align:left">使用 <code>VXLAN</code> 后端(默认)</td></tr><tr><td style="text-align:left"><code>--flannel-backend=host-gw</code></td><td style="text-align:left">使用 <code>host-gw</code> 后端</td></tr><tr><td style="text-align:left"><code>--flannel-backend=ipsec</code></td><td style="text-align:left">使用 <code>IPSEC</code> 后端；对网络流量进行加密</td></tr><tr><td style="text-align:left"><code>--flannel-backend=wireguard</code></td><td style="text-align:left">使用 <code>WireGuard</code> 后端；对网络流量进行加密</td></tr></tbody></table><ul><li>配置 Flannel 选项</li></ul><p>这样，我就可以在安装 <code>K3s</code> 或者之后修改对应配置文件，来修改 <code>Flannel</code> 默认的后端网络配置选项(重启会覆盖不生效)了。下面，我们演示下，如何修改为 <code>host-gw</code> 模式。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主节点</span></span><br><span class="line"><span class="comment"># flannel-backend使用host-gw</span></span><br><span class="line"><span class="comment"># 该模式会把对端主机的IP当做默认网管(多Server情况)</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--flannel-backend=host-gw'</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 工作节点</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.100.100:6443 \</span><br><span class="line">    K3S_TOKEN=xxx sh -</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认的路由信息</span></span><br><span class="line">$ route -n</span><br><span class="line">0.0.0.0         172.16.64.1     0.0.0.0         UG    100    0        0 enp0s2</span><br><span class="line">10.42.1.0       172.16.64.9     255.255.255.0   UG    0      0        0 enp0s2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看配置之后的网络配置</span></span><br><span class="line">$ sudo cat /var/lib/rancher/k3s/agent/etc/flannel/net-conf.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"Network"</span>: <span class="string">"10.42.0.0/16"</span>,</span><br><span class="line">    <span class="string">"Backend"</span>: &#123;</span><br><span class="line">        <span class="string">"Type"</span>: <span class="string">"host-gw"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>启用 Directrouting 特性</li></ul><p><strong>Flannel 自身的特性</strong>：当主机在同一子网时，启用 <code>direct routes</code>(如 <code>host-gw</code>)。<code>vxlan</code> 只用于将数据包封装到不同子网的主机上，同子网的主机之间使用  <code>host-gw</code>，默认值为  <code>false</code>。</p><p>要添加我们就不能修改其对应的网络配置文件，因为重新安装或者重启都会把这个配置冲掉(变成默认配置)，所以需要折中下。我们自建一个网络配置文件，然后在启动的时候执行从哪个配置文件里面加载对应配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k3s的master和agent</span></span><br><span class="line">$ sudo cat /etc/flannel/net-conf.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"Network"</span>: <span class="string">"10.42.0.0/16"</span>,</span><br><span class="line">    <span class="string">"Backend"</span>: &#123;</span><br><span class="line">        <span class="string">"Type"</span>: <span class="string">"vxlan"</span>,</span><br><span class="line">        <span class="string">"Directrouting"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># k3s master</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--flannel-backend=host-gw'</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><ul><li>自定义 CNI</li></ul><p>使用  <code>--flannel-backend=none</code>(禁用) 运行 <code>K3s</code>，然后在安装你选择的 <code>CNI</code>。按照 <a href="https://docs.projectcalico.org/master/reference/cni-plugin/configuration" target="_blank" rel="noopener">Calico CNI 插件指南</a> 来修改 <code>Calico</code> 的 <code>YAML</code> 配置文件，在 <code>container_settings</code> 部分中允许 <code>IP</code> 转发。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加到Calico的YAML文件中</span></span><br><span class="line"><span class="comment"># 允许IP转发(这个是K3s的一个限制；需要开启)</span></span><br><span class="line"><span class="string">"container_settings"</span>: &#123;</span><br><span class="line">    <span class="string">"allow_ip_forwarding"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">- name: CALICO_IPV4POOL_CIDR</span><br><span class="line">  value: <span class="string">"192.168.200.0/24"</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过在主机上运行以下命令，确保设置已被应用(true)</span></span><br><span class="line">$ sudo cat /etc/cni/net.d/10-canal.conflist</span><br><span class="line"></span><br><span class="line"><span class="comment"># calico</span></span><br><span class="line"><span class="comment"># 其中--cluster-cidr可不设置</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--flannel-backend=none \</span></span><br><span class="line"><span class="string">        --cluster-cidr=192.168.200.0/24"'</span> \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动网络服务</span></span><br><span class="line">$ kubectl apply -f ./calico.yaml</span><br></pre></td></tr></table></figure><h3><span id="35-外部数据库">3.5 外部数据库</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><ul><li>[1] 使用外部数据库实现高可用安装<ul><li>两个或多个<code>server</code> 节点</li><li>零个或多个<code>agent</code> 节点</li><li>外部数据存储(<code>Etcd/MySQL/PostgRES</code>)</li><li>固定的注册地址(<code>LB</code>)</li><li><a href="https://mp.weixin.qq.com/s/0Wk2MzfWqMqt8DfUK_2ICA" target="_blank" rel="noopener">这应该是最适合国内用户的 K3s HA 方案</a></li></ul></li></ul><p>虽然单节点 <code>k3s server</code> 集群可以满足各种用例，但是对于需要稳定运行的重要环境，可以在 <code>HA</code> 配置中运行 <code>K3s</code>，如何使用外部数据库安装一个高可用的 <code>K3s</code> 集群？</p><p><img src="https://img.hi-linux.com/staticfile/advance-k3s-tool-03-20220519092423240-2022-05-19-amkNto.png" alt="K3S安装事项 - 外部数据库"></p><table><thead><tr><th style="text-align:left">主机名</th><th style="text-align:left">角色</th><th style="text-align:left">IP</th></tr></thead><tbody><tr><td style="text-align:left">k3s-server-1</td><td style="text-align:left">k3s master</td><td style="text-align:left">172.31.2.134</td></tr><tr><td style="text-align:left">k3s-server-2</td><td style="text-align:left">k3s master</td><td style="text-align:left">172.31.2.42</td></tr><tr><td style="text-align:left">k3s-db</td><td style="text-align:left">DB</td><td style="text-align:left">172.31.10.251</td></tr><tr><td style="text-align:left">k3s-lb</td><td style="text-align:left">LB</td><td style="text-align:left">172.31.13.97</td></tr><tr><td style="text-align:left">k3s-agent</td><td style="text-align:left">k3s agent</td><td style="text-align:left">172.31.15.130</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.创建一个外部数据存储</span></span><br><span class="line">$ docker run --name some-mysql \</span><br><span class="line">    --restart=unless-stopped -p 3306:3306 \</span><br><span class="line">    -e MYSQL_ROOT_PASSWORD=password -d mysql:5.7</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.启动k3s-server节点(有读写权限不用加库名)</span></span><br><span class="line"><span class="comment"># mysql://username:password@tcp(hostname:3306)/database-name</span></span><br><span class="line"><span class="comment"># 可加污点 --node-taint CriticalAddonsOnly=true:NoExecute</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn sh - server \</span><br><span class="line">    --datastore-endpoint=<span class="string">"mysql://root:password@ip:3306/k3s"</span> \</span><br><span class="line">    --tls-san 172.31.13.97</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.配置固定的注册地址(k3s-lb节点)</span></span><br><span class="line"><span class="comment"># Agent节点需要一个URL来注册(LB)</span></span><br><span class="line">$ cat &gt;&gt; /etc/nginx.conf &lt;&lt;EOF</span><br><span class="line">worker_processes 4;</span><br><span class="line">worker_rlimit_nofile 40000;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 8192;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line">    upstream k3s_api &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 172.31.2.134:6443 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 172.31.2.42:6443 max_fails=3 fail_timeout=5s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen     6443;</span><br><span class="line">        proxy_pass k3s_api;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">$ docker run -d --restart=unless-stopped \</span><br><span class="line">  -p 6443:6443 \</span><br><span class="line">  -v /etc/nginx.conf:/etc/nginx/nginx.conf \</span><br><span class="line">  nginx:1.14</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.加入Agent节点</span></span><br><span class="line"><span class="comment"># Agent会保存LB节点和每个Server节点的IP信息</span></span><br><span class="line"><span class="comment"># cat /var/lib/rancher/k3s/agent/etc/k3s-agent-load-balancer.json</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn</span><br><span class="line">    K3S_URL=https://172.31.13.97:6443 K3S_TOKEN=mynodetoken \</span><br><span class="line">    sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.通过kubeconfig访问K3s集群</span></span><br><span class="line">$ kubectl get nodes</span><br><span class="line">NAME           STATUS   ROLES                  AGE   VERSION</span><br><span class="line">k3s-server-1   Ready    control-plane,master   68s   v1.20.7+k3s1</span><br><span class="line">k3s-server-2   Ready    control-plane,master   66s   v1.20.7+k3s1</span><br></pre></td></tr></table></figure><ul><li>[2] 嵌入式 DB 的高可用</li></ul><p>要在这种模式下运行 <code>K3s</code>，你必须有奇数的服务器节点，建议从三个节点开始。在嵌入式中，默认使用 <code>Etcd</code> 作为高可用的数据库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 服务器节点(启动etcd集群)</span></span><br><span class="line"><span class="comment"># SECRET我们预定一个key值</span></span><br><span class="line"><span class="comment"># 使用cluster-init标志来启用集群</span></span><br><span class="line"><span class="comment"># 并使用一个标记作为共享的密钥来加入其他服务器到集群中</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_TOKEN=SECRET \</span><br><span class="line">    sh -s - --cluster-init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看类型</span></span><br><span class="line">$ sudo  kubectl get nodes</span><br><span class="line">NAME    STATUS  ROLES                      AGE  VERSION</span><br><span class="line">ip-xxx  Ready   control-plane,etcd,master  19h  v1.23.6+k3s1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他服务器节点(2/3)</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn K3S_TOKEN=SECRET \</span><br><span class="line">    sh -s - --server https://&lt;ip-or-host-server&gt;:6443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询ETCD集群状态</span></span><br><span class="line"><span class="comment"># etcd证书默认目录：/var/lib/rancher/k3s/server/tls/etcd</span></span><br><span class="line"><span class="comment"># etcd数据默认目录：/var/lib/rancher/k3s/server/db/etcd</span></span><br><span class="line">$ ETCDCTL_ENDPOINTS=<span class="string">'https://172.31.12.136:2379,\</span></span><br><span class="line"><span class="string">    https://172.31.4.43:2379,\</span></span><br><span class="line"><span class="string">    https://172.31.4.190:2379'</span> \</span><br><span class="line">ETCDCTL_CACERT=<span class="string">'/var/lib/rancher/k3s/server/tls/etcd/server-ca.crt'</span> \</span><br><span class="line">ETCDCTL_CERT=<span class="string">'/var/lib/rancher/k3s/server/tls/etcd/server-client.crt'</span>\</span><br><span class="line">ETCDCTL_KEY=<span class="string">'/var/lib/rancher/k3s/server/tls/etcd/server-client.key'</span> \</span><br><span class="line">ETCDCTL_API=3 etcdctl endpoint status --write-out=table</span><br></pre></td></tr></table></figure><ul><li>[3] 集群数据存储选项</li></ul><p>使用 <code>etcd</code> 以外的数据存储运行 <code>K8S</code> 的能力使 <code>K3s</code> 区别于其他 <code>K8S</code> 发行版。该功能为 <code>K8S</code> 操作者提供了灵活性，可用的数据存储选项允许你选择一个最适合用例的数据存储。</p><p>如果你的团队没有操作 <code>etcd</code> 的专业知识，可以选择 <code>MySQL</code> 或 <code>PostgreSQL</code> 等企业级 <code>SQL</code> 数据库。如果您需要在 <code>CI/CD</code> 环境中运行一个简单的、短暂的集群，可以使用嵌入式 <code>SQLite</code> 数据库</p><p>如果你想使用外部数据存储，如 <code>PostgreSQL</code>、<code>MySQL</code> 或 <code>etcd</code>，你必须设置 <code>datastore-endpoint</code> 参数，以便 <code>K3s</code> 知道如何连接到它，也可以指定参数来配置连接的认证和加密。下表总结了这些参数，它们可以作为 <code>CLI</code> 标志或环境变量传递。</p><table><thead><tr><th style="text-align:left">CLI Flag</th><th style="text-align:left">环境变量</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>--datastore-endpoint</code></td><td style="text-align:left"><code>K3S_DATASTORE_ENDPOINT</code></td><td style="text-align:left">指定一个 PostgresSQL、MySQL 或 etcd 连接字符串。用于描述与数据存储的连接。这个字符串的结构是特定于每个后端的，详情如下。</td></tr><tr><td style="text-align:left"><code>--datastore-cafile</code></td><td style="text-align:left"><code>K3S_DATASTORE_CAFILE</code></td><td style="text-align:left">TLS 证书颁发机构（CA）文件，用于帮助确保与数据存储的通信安全。如果你的数据存储通过 TLS 服务请求，使用由自定义证书颁发机构签署的证书，你可以使用这个参数指定该 CA，这样 K3s 客户端就可以正确验证证书。</td></tr><tr><td style="text-align:left"><code>--datastore-certfile</code></td><td style="text-align:left"><code>K3S_DATASTORE_CERTFILE</code></td><td style="text-align:left">TLS 证书文件，用于对数据存储进行基于客户端证书的验证。要使用这个功能，你的数据存储必须被配置为支持基于客户端证书的认证。如果你指定了这个参数，你还必须指定<code>datastore-keyfile</code>参数。</td></tr><tr><td style="text-align:left"><code>--datastore-keyfile</code></td><td style="text-align:left"><code>K3S_DATASTORE_KEYFILE</code></td><td style="text-align:left">TLS 密钥文件，用于对数据存储进行基于客户端证书的认证。更多细节请参见前面的<code>datastore-certfile</code>参数。</td></tr></tbody></table><p>作为最佳实践，我们建议将这些参数设置为环境变量，而不是命令行参数，这样你的数据库证书或其他敏感信息就不会作为进程信息的一部分暴露出来。</p><h3><span id="36-私有镜像仓库">3.6 私有镜像仓库</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><p><code>K3s</code> 默认使用 <code>containerd</code> 作为容器运行时，所以在 <code>docker</code> 上配置镜像仓库是不生效的。<code>K3s</code> 镜像仓库配置文件由两大部分组成：<code>mirrors</code> 和  <code>configs</code>。</p><ul><li><code>Mirrors</code> 是一个用于定义专用镜像仓库的名称和 <code>endpoint</code> 的指令</li><li><code>Configs</code> 部分定义了每个 <code>mirror</code> 的 <code>TLS</code> 和证书配置</li><li>对于每个 <code>mirror</code>，你可以定义 <code>auth</code> 和 <code>/</code> 或 <code>tls</code></li></ul><p><code>K3s registry</code> 配置目录为： <code>/etc/rancher/k3s/registries.yaml</code>。<code>K3s</code> 启动时会检查  <code>/etc/rancher/k3s/</code> 中是否存在  <code>registries.yaml</code> 文件，并指示 <code>containerd</code> 使用文件中定义的镜像仓库。如果你想使用一个私有的镜像仓库，那么你需要在每个使用镜像仓库的节点上以 <code>root</code> 身份创建这个文件。</p><p>请注意，<code>server</code> 节点默认是可以调度的。如果你没有在 <code>server</code> 节点上设置污点，那么将在它们上运行工作负载，请确保在每个 <code>server</code> 节点上创建  <code>registries.yaml</code> 文件。</p><p><code>containerd</code> 使用了类似 <code>K8S</code> 中 <code>svc</code> 与 <code>endpoint</code> 的概念，<code>svc</code> 可以理解为访问名称，这个名称会解析到对应的 <code>endpoint</code> 上。也可以理解 <code>mirror</code> 配置就是一个反向代理，它把客户端的请求代理到 <code>endpoint</code> 配置的后端镜像仓库。<code>mirror</code> 名称可以随意填写，但是必须符合 <code>IP</code> 或域名的定义规则。并且可以配置多个 <code>endpoint</code>，默认解析到第一个 <code>endpoint</code>，如果第一个 <code>endpoint</code> 没有返回数据，则自动切换到第二个 <code>endpoint</code>，以此类推。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/rancher/k3s/registries.yaml</span></span><br><span class="line"><span class="comment"># 同时可以设置多个mirrors地址</span></span><br><span class="line"><span class="comment"># 可以对mirrors设置权限和证书</span></span><br><span class="line"><span class="attr">mirrors:</span></span><br><span class="line">  <span class="attr">"172.31.6.200:5000":</span></span><br><span class="line">    <span class="attr">endpoint:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"http://172.31.6.200:5000"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"http://x.x.x.x:5000"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"http://y.y.y.y:5000"</span></span><br><span class="line">  <span class="attr">"rancher.ksd.top:5000":</span></span><br><span class="line">    <span class="attr">endpoint:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"http://172.31.6.200:5000"</span></span><br><span class="line">  <span class="attr">"docker.io":</span></span><br><span class="line">    <span class="attr">endpoint:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"https://fogjl973.mirror.aliyuncs.com"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"https://registry-1.docker.io"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">configs:</span></span><br><span class="line">  <span class="attr">"172.31.6.200:5000":</span></span><br><span class="line">    <span class="attr">auth:</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">admin</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">Harbor@12345</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">cert_file:</span> <span class="string">/home/ubuntu/harbor2.escapelife.site.cert</span></span><br><span class="line">      <span class="attr">key_file:</span> <span class="string">/home/ubuntu/harbor2.escapelife.site.key</span></span><br><span class="line">      <span class="attr">ca_file:</span> <span class="string">/home/ubuntu/ca.crt</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 镜像都是从同一个仓库获取到的</span></span><br><span class="line">$ sudo systemctl restart k3s.service</span><br><span class="line">$ sudo crictl pull 172.31.6.200:5000/library/alpine</span><br><span class="line">$ sudo crictl pull rancher.ksd.top:5000/library/alpine</span><br></pre></td></tr></table></figure><p>这里我们介绍下，如何使用 <code>TLS</code> 配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 证书颁发机构颁发的证书</span></span><br><span class="line">$ cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt;EOF</span><br><span class="line">mirrors:</span><br><span class="line">  <span class="string">"harbor.escapelife.site"</span>:</span><br><span class="line">    endpoint:</span><br><span class="line">      - <span class="string">"https://harbor.escapelife.site"</span></span><br><span class="line">configs:</span><br><span class="line">  <span class="string">"harbor.escapelife.site"</span>:</span><br><span class="line">    auth:</span><br><span class="line">      username: admin</span><br><span class="line">      password: Harbor@12345</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">$ sudo systemctl restart k3s</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自签名证书</span></span><br><span class="line">$ cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt;EOF</span><br><span class="line">mirrors:</span><br><span class="line">  <span class="string">"harbor2.escapelife.site"</span>:</span><br><span class="line">    endpoint:</span><br><span class="line">      - <span class="string">"https://harbor2.escapelife.site"</span></span><br><span class="line">configs:</span><br><span class="line">  <span class="string">"harbor2.escapelife.site"</span>:</span><br><span class="line">    auth:</span><br><span class="line">      username: admin</span><br><span class="line">      password: Harbor@12345</span><br><span class="line">    tls:</span><br><span class="line">      cert_file: /home/ubuntu/harbor2.escapelife.site.cert</span><br><span class="line">      key_file:  /home/ubuntu/harbor2.escapelife.site.key</span><br><span class="line">      ca_file:   /home/ubuntu/ca.crt</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">$ sudo systemctl restart k3s</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不使用TLS证书</span></span><br><span class="line">$ cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt;EOF</span><br><span class="line">mirrors:</span><br><span class="line">  <span class="string">"docker.io"</span>:</span><br><span class="line">    endpoint:</span><br><span class="line">      - <span class="string">"https://fogjl973.mirror.aliyuncs.com"</span></span><br><span class="line">      - <span class="string">"https://registry-1.docker.io"</span></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">$ sudo systemctl restart k3s</span><br></pre></td></tr></table></figure><p><code>K3s</code> 将会在 <code>/var/lib/rancher/k3s/agent/etc/containerd/config.toml</code> 中为 <code>containerd</code> 生成  <code>config.toml</code>。如果要对这个文件进行高级设置，你可以在同一目录中创建另一个名为  <code>config.toml.tmpl</code> 的文件，此文件将会代替默认设置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 完整示例</span></span><br><span class="line">$ cat &gt;&gt; /etc/rancher/k3s/registries.yaml</span><br><span class="line">mirrors:</span><br><span class="line">  <span class="string">"harbor.escapelife.site"</span>:</span><br><span class="line">     endpoint:</span><br><span class="line">     - <span class="string">"https://harbor.escapelife.site"</span></span><br><span class="line">  <span class="string">"harbor2.escapelife.site"</span>:</span><br><span class="line">     endpoint:</span><br><span class="line">     - <span class="string">"https://harbor2.escapelife.site"</span></span><br><span class="line">  <span class="string">"172.31.19.227:5000"</span>:</span><br><span class="line">     endpoint:</span><br><span class="line">     - <span class="string">"http://172.31.19.227:5000"</span></span><br><span class="line">  <span class="string">"docker.io"</span>:</span><br><span class="line">     endpoint:</span><br><span class="line">     - <span class="string">"https://fogjl973.mirror.aliyuncs.com"</span></span><br><span class="line">     - <span class="string">"https://registry-1.docker.io"</span></span><br><span class="line"></span><br><span class="line">configs:</span><br><span class="line">  <span class="string">"harbor.escapelife.site"</span>:</span><br><span class="line">     auth:</span><br><span class="line">       username: admin</span><br><span class="line">       password: Harbor@12345</span><br><span class="line"></span><br><span class="line">  <span class="string">"harbor2.escapelife.site"</span>:</span><br><span class="line">     auth:</span><br><span class="line">       username: admin</span><br><span class="line">       password: Harbor@12345</span><br><span class="line">     tls:</span><br><span class="line">       cert_file: /home/ubuntu/harbor2.escapelife.site.cert</span><br><span class="line">       key_file:  /home/ubuntu/harbor2.escapelife.site.key</span><br><span class="line">       ca_file:   /home/ubuntu/ca.crt</span><br></pre></td></tr></table></figure><h3><span id="37-离线安装">3.7 离线安装</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><p>离线安装的过程主要分为以下两个步骤：</p><ul><li><p>步骤 1：部署镜像</p><ul><li><strong>部署私有镜像仓库</strong></li><li><strong>手动部署镜像</strong></li></ul></li><li><p>步骤 2：安装 <code>K3s</code> 工具</p><ul><li><strong>单节点安装</strong></li><li><strong>高可用安装</strong></li></ul></li><li><p>通过私有镜像仓库安装 K3s</p><ul><li><code>k3s-images.txt</code> 包含对于版本依赖的镜像文件</li><li><code>k3s-airgap-images-amd64.tar</code> 包含对于版本的镜像文件</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所需镜像上传到私有镜像仓库</span></span><br><span class="line"><span class="comment"># https://github.com/k3s-io/k3s/releases</span></span><br><span class="line">可以从K3s镜像列表获取到版本，下载上传到私有镜像仓库</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建镜像仓库(YAML)</span></span><br><span class="line"><span class="comment"># 按照私有镜像仓库配置指南创建并配置registry.yaml文件</span></span><br><span class="line">$ mkdir -p /etc/rancher/k3s/</span><br><span class="line">cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt;EOF</span><br><span class="line">mirrors:</span><br><span class="line">  <span class="string">"docker.io"</span>:</span><br><span class="line">    endpoint:</span><br><span class="line">      - <span class="string">"https://harbor.escapelife.site"</span></span><br><span class="line">configs:</span><br><span class="line">  <span class="string">"docker.io"</span>:</span><br><span class="line">    auth:</span><br><span class="line">      username: admin</span><br><span class="line">      password: Harbor@12345</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装单节点K3s集群</span></span><br><span class="line"><span class="comment"># https://github.com/k3s-io/k3s/releases</span></span><br><span class="line">可以从K3s仓库获取到版本(二进制文件)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取K3s安装脚本</span></span><br><span class="line">$ wget https://get.k3s.io -o ./install.sh</span><br><span class="line">$ wget http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装K3s-server</span></span><br><span class="line">$ INSTALL_K3S_SKIP_DOWNLOAD=<span class="literal">true</span> ./install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将agent加入到K3s集群</span></span><br><span class="line">$ INSTALL_K3S_SKIP_DOWNLOAD=<span class="literal">true</span> \</span><br><span class="line">    K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken \</span><br><span class="line">    ./install.sh</span><br></pre></td></tr></table></figure><ul><li>通过手动部署镜像安装 K3s</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从Github页面获取你所运行的K3s版本及文件</span></span><br><span class="line"><span class="comment"># https://github.com/rancher/k3s/releases</span></span><br><span class="line">k3s二进制文件+镜像tar文件</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将tar文件放在images目录下</span></span><br><span class="line">$ sudo mkdir -p /var/lib/rancher/k3s/agent/images/</span><br><span class="line">$ sudo cp ./k3s-airgap-images-<span class="variable">$ARCH</span>.tar /var/lib/rancher/k3s/agent/images/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将k3s二进制文件放在/usr/local/bin/k3s路径上</span></span><br><span class="line">$ mv ./k3s /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">$ chmod 755 /usr/<span class="built_in">local</span>/bin/k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装K3s-server</span></span><br><span class="line">$ INSTALL_K3S_SKIP_DOWNLOAD=<span class="literal">true</span> ./install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将agent加入到K3s集群</span></span><br><span class="line">$ INSTALL_K3S_SKIP_DOWNLOAD=<span class="literal">true</span> \</span><br><span class="line">    K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken \</span><br><span class="line">    ./install.sh</span><br></pre></td></tr></table></figure><p>离线升级 <code>K3s</code> 版本，完成离线安装 <code>K3s</code> 后，还可以通过脚本升级 <code>K3s</code> 版本，或启用自动升级功能，以保持离线环境中的 <code>K3s</code> 版本与最新的 <code>K3s</code> 版本同步。</p><ul><li>升级 K3s 版本</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过脚本升级</span></span><br><span class="line"><span class="comment"># https://github.com/rancher/k3s/releases</span></span><br><span class="line">从Github页面下载要升级到的K3s版本</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换</span></span><br><span class="line"><span class="comment"># 复制并替换每个节点上/usr/local/bin中的旧K3s二进制文件</span></span><br><span class="line">$ mv ./k3s /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">$ chmod 755 /usr/<span class="built_in">local</span>/bin/k3s</span><br><span class="line">$ wget http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启K3s服务</span></span><br><span class="line">$ sudo systemctl restart k3s.service</span><br></pre></td></tr></table></figure><h3><span id="38-仪表盘及卸载">3.8 仪表盘及卸载</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><p>推荐使用三种仪表盘工具，分别是对应是 <code>Kubernetes Dashboard</code>、<code>kube-explorer</code> 和 <code>Rancher UI</code>，其各自各有优劣。</p><ul><li>[1] Kubernetes Dashboard</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 部署Kubernetes仪表盘</span></span><br><span class="line">$ GITHUB_URL=https://github.com/kubernetes/dashboard/releases</span><br><span class="line">$ VERSION_KUBE_DASHBOARD=$(curl -w <span class="string">'%&#123;url_effective&#125;'</span> -I -L -s -S \</span><br><span class="line">    <span class="variable">$&#123;GITHUB_URL&#125;</span>/latest -o /dev/null | sed -e <span class="string">'s|.*/||'</span>)</span><br><span class="line">$ sudo k3s kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/<span class="variable">$&#123;VERSION_KUBE_DASHBOARD&#125;</span>/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 仪表盘RBAC配置</span></span><br><span class="line"><span class="comment"># 本指南中创建的admin-user将在仪表盘中拥有管理权限</span></span><br><span class="line">$ sudo k3s kubectl create \</span><br><span class="line">    -f dashboard.admin-user.yml \</span><br><span class="line">    -f dashboard.admin-user-role.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># dashboard.admin-user.yml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"><span class="comment"># dashboard.admin-user-role.yml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: admin-user</span><br><span class="line">    namespace: kubernetes-dashboard</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获得Bearer-Token</span></span><br><span class="line">$ sudo k3s kubectl -n kubernetes-dashboard \</span><br><span class="line">    describe secret admin-user-token | grep <span class="string">'^token'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地访问仪表盘</span></span><br><span class="line"><span class="comment"># https://192.168.100.100:8443</span></span><br><span class="line"><span class="comment"># https://www.escapelife.site/posts/180e93f1.html</span></span><br><span class="line"><span class="comment"># https://www.escapelife.site/posts/538ec6b1.html</span></span><br><span class="line">$ sudo k3s kubectl proxy</span><br><span class="line">$ sudo kubectl -n kubernetes-dashboard port-forward \</span><br><span class="line">    --address 0.0.0.0 svc/kubernets-dashboard 8443:443</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 升级仪表盘</span></span><br><span class="line">$ sudo k3s kubectl delete ns kubernetes-dashboard</span><br><span class="line">$ GITHUB_URL=https://github.com/kubernetes/dashboard/releases</span><br><span class="line">$ VERSION_KUBE_DASHBOARD=$(curl -w <span class="string">'%&#123;url_effective&#125;'</span> -I -L -s -S <span class="variable">$&#123;GITHUB_URL&#125;</span>/latest -o /dev/null | sed -e <span class="string">'s|.*/||'</span>)</span><br><span class="line">$ sudo k3s kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/<span class="variable">$&#123;VERSION_KUBE_DASHBOARD&#125;</span>/aio/deploy/recommended.yaml -f dashboard.admin-user.yml -f dashboard.admin-user-role.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># ## 删除仪表盘和admin-user配置</span></span><br><span class="line">$ sudo k3s kubectl delete ns kubernetes-dashboard</span><br><span class="line">$ sudo k3s kubectl delete clusterrolebinding kubernetes-dashboard</span><br><span class="line">$ sudo k3s kubectl delete clusterrole kubernetes-dashboard</span><br></pre></td></tr></table></figure><ul><li>[2] kube-explorer<ul><li><code>kube-explorer</code> 是 <code>K8S</code> 的便携式资源管理器，没有任何依赖</li><li>并提供了一个几乎完全无状态的 <code>K8S</code> 资源管理器</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从发布页面下载二进制文件</span></span><br><span class="line"><span class="comment"># https://github.com/cnrancher/kube-explorer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line"><span class="comment"># --kubeconfig 可以不配置(自己可以找到)</span></span><br><span class="line">$ ./kube-explorer --kubeconfig=/etc/rancher/k3s/kube.yaml \</span><br><span class="line">    --http-listen-port=9898 \</span><br><span class="line">    --https-listen-port=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开浏览器访问</span></span><br><span class="line">http://192.168.100.100:9898</span><br></pre></td></tr></table></figure><ul><li>[3] Rancher UI<ul><li>可以将 <code>K3s</code> 导入到 <code>Rancher UI</code> 中去管理</li><li>官网 <a href="http://docs.rancher.cn/docs/rancher2/cluster-provisioning/imported-clusters/_index/#%E5%AF%BC%E5%85%A5-k3s-%E9%9B%86%E7%BE%A4" target="_blank" rel="noopener">导入 K3s 集群</a> 指导文档</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入K3s集群时，Rancher会将其识别为K3s类型，并且附件额外功能</span></span><br><span class="line"><span class="comment"># 1.能够升级K3s版本</span></span><br><span class="line"><span class="comment"># 2.可配置升级集群时升级的最大节点数</span></span><br><span class="line"><span class="comment"># 3.在主机详情页能够查看启动K3s集群时每个节点的配置参数和环境变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置K3s集群以允许导入到Rancher</span></span><br><span class="line">$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn sh -s - \</span><br><span class="line">    --write-kubeconfig-mode 644</span><br></pre></td></tr></table></figure><ul><li>[4] 卸载 K3s 服务</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主节点</span></span><br><span class="line">$ /usr/<span class="built_in">local</span>/bin/k3s-uninstall.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 工作节点</span></span><br><span class="line">$ /usr/<span class="built_in">local</span>/bin/k3s-agent-uninstall.sh</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 包括docker等信息一并清理</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">KUBE_SVC=<span class="string">'</span></span><br><span class="line"><span class="string">kubelet</span></span><br><span class="line"><span class="string">kube-scheduler</span></span><br><span class="line"><span class="string">kube-proxy</span></span><br><span class="line"><span class="string">kube-controller-manager</span></span><br><span class="line"><span class="string">kube-apiserver</span></span><br><span class="line"><span class="string">'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> kube_svc <span class="keyword">in</span> <span class="variable">$&#123;KUBE_SVC&#125;</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="comment"># 停止服务</span></span><br><span class="line">  <span class="keyword">if</span> [[ `systemctl is-active <span class="variable">$&#123;kube_svc&#125;</span>` == <span class="string">'active'</span> ]]; <span class="keyword">then</span></span><br><span class="line">    systemctl stop <span class="variable">$&#123;kube_svc&#125;</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  <span class="comment"># 禁止服务开机启动</span></span><br><span class="line">  <span class="keyword">if</span> [[ `systemctl is-enabled <span class="variable">$&#123;kube_svc&#125;</span>` == <span class="string">'enabled'</span> ]]; <span class="keyword">then</span></span><br><span class="line">    systemctl <span class="built_in">disable</span> <span class="variable">$&#123;kube_svc&#125;</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止所有容器</span></span><br><span class="line">docker stop $(docker ps -aq)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除所有容器</span></span><br><span class="line">docker rm -f $(docker ps -qa)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除所有容器卷</span></span><br><span class="line">docker volume rm $(docker volume ls -q)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载mount目录</span></span><br><span class="line"><span class="keyword">for</span> mount <span class="keyword">in</span> $(mount | grep tmpfs | grep <span class="string">'/var/lib/kubelet'</span> | awk <span class="string">'&#123; print $3 &#125;'</span>) /var/lib/kubelet /var/lib/rancher;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  umount <span class="variable">$mount</span>;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份目录</span></span><br><span class="line">mv /etc/kubernetes /etc/kubernetes-bak-$(date +<span class="string">"%Y%m%d%H%M"</span>)</span><br><span class="line">mv /var/lib/etcd /var/lib/etcd-bak-$(date +<span class="string">"%Y%m%d%H%M"</span>)</span><br><span class="line">mv /var/lib/rancher /var/lib/rancher-bak-$(date +<span class="string">"%Y%m%d%H%M"</span>)</span><br><span class="line">mv /opt/rke /opt/rke-bak-$(date +<span class="string">"%Y%m%d%H%M"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除残留路径</span></span><br><span class="line">rm -rf /etc/ceph \</span><br><span class="line">    /etc/cni \</span><br><span class="line">    /opt/cni \</span><br><span class="line">    /run/secrets/kubernetes.io \</span><br><span class="line">    /run/calico \</span><br><span class="line">    /run/flannel \</span><br><span class="line">    /var/lib/calico \</span><br><span class="line">    /var/lib/cni \</span><br><span class="line">    /var/lib/kubelet \</span><br><span class="line">    /var/<span class="built_in">log</span>/containers \</span><br><span class="line">    /var/<span class="built_in">log</span>/kube-audit \</span><br><span class="line">    /var/<span class="built_in">log</span>/pods \</span><br><span class="line">    /var/run/calico \</span><br><span class="line">    /usr/libexec/kubernetes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理网络接口</span></span><br><span class="line">no_del_net_inter=<span class="string">'</span></span><br><span class="line"><span class="string">lo</span></span><br><span class="line"><span class="string">docker0</span></span><br><span class="line"><span class="string">eth</span></span><br><span class="line"><span class="string">ens</span></span><br><span class="line"><span class="string">bond</span></span><br><span class="line"><span class="string">'</span></span><br><span class="line"></span><br><span class="line">network_interface=`ls /sys/class/net`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> net_inter <span class="keyword">in</span> <span class="variable">$network_interface</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> ! <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;no_del_net_inter&#125;</span>"</span> | grep -qE <span class="variable">$&#123;net_inter:0:3&#125;</span>; <span class="keyword">then</span></span><br><span class="line">    ip link delete <span class="variable">$net_inter</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理残留进程</span></span><br><span class="line">port_list=<span class="string">'</span></span><br><span class="line"><span class="string">80</span></span><br><span class="line"><span class="string">443</span></span><br><span class="line"><span class="string">6443</span></span><br><span class="line"><span class="string">2376</span></span><br><span class="line"><span class="string">2379</span></span><br><span class="line"><span class="string">2380</span></span><br><span class="line"><span class="string">8472</span></span><br><span class="line"><span class="string">9099</span></span><br><span class="line"><span class="string">10250</span></span><br><span class="line"><span class="string">10254</span></span><br><span class="line"><span class="string">'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> port <span class="keyword">in</span> <span class="variable">$port_list</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  pid=`netstat -atlnup | grep <span class="variable">$port</span> | awk <span class="string">'&#123;print $7&#125;'</span> | awk -F <span class="string">'/'</span> <span class="string">'&#123;print $1&#125;'</span> | grep -v - | sort -rnk2 | uniq`</span><br><span class="line">  <span class="keyword">if</span> [[ -n <span class="variable">$pid</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">kill</span> -9 <span class="variable">$pid</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">kube_pid=`ps -ef | grep -v grep | grep kube | awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="variable">$kube_pid</span> ]]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">kill</span> -9 <span class="variable">$kube_pid</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理Iptables表</span></span><br><span class="line"><span class="comment">## 注意：如果节点Iptables有特殊配置，以下命令请谨慎操作</span></span><br><span class="line">sudo iptables --flush</span><br><span class="line">sudo iptables --flush --table nat</span><br><span class="line">sudo iptables --flush --table filter</span><br><span class="line">sudo iptables --table nat --delete-chain</span><br><span class="line">sudo iptables --table filter --delete-chain</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h3><span id="39-注意事项">3.9 注意事项</span></h3><blockquote><p><strong>理解 Server 节点的安装，以及注册 Agent 节点的步骤！</strong></p></blockquote><ul><li><strong>Helm</strong><ul><li>如果需要使用 <code>helm</code> 操作 <code>K3s</code> 集群，需要创建 <code>~/.kube/conf</code> 目录</li><li>需要执行 <code>cp /etc/rancher/k3s/k3s.yaml ~/.kube/config</code> 命令</li></ul></li><li><strong>自动部署的清单</strong><ul><li>将由 <code>rancher/helm-controller</code> 在运行时安装</li><li>目录路径：<code>/var/lib/rancher/k3s/server/manifests</code></li><li>目录下面的每个 <code>yaml</code> 就代表这个一个需要启动的服务</li></ul></li></ul><p>对于我们希望使用的组件，可以在启动的时候禁用默认组件，在手动部署你需要的一些组件(通常是放到一个指定目录下面，随着服务启动自动拉起)，从而达到灵活使用的目的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有Pod服务</span></span><br><span class="line"><span class="comment"># 比如helm/coredns也不是自带的就是通过这个方式创建的</span></span><br><span class="line">$ sudo kubectl get pods -A</span><br></pre></td></tr></table></figure><ul><li>注册 Agent 节点<ul><li>工作节点密码存储：<code>/etc/rancher/node/password</code></li><li>主节点的密码存储：<code>/var/lib/rancher/k3s/server/cred/node-passwd</code></li></ul></li></ul><p>在 <code>agent</code> 节点运行注册命令，会和 <code>server</code> 节点发起 <code>websocket</code> 连接，然后会在工作节点上面创建一个随机的密码。然后会拿着这个密码和工作节点的主机名，发送给主节点。然后主节点会将这个信息在保存(<code>k8s secrets</code>)起来，随后的任何尝试都必须使用相同的密码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 工作节点的密码信息(password+hostname)</span></span><br><span class="line">$ sudo cat /etc/rancher/node/password</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看主节点的密码信息</span></span><br><span class="line"><span class="comment"># https://docs.rancher.cn/docs/k3s/architecture/_index#注册-agent-节点</span></span><br><span class="line">$ sudo kubectl get secret k3s2.node-password.k3s -o yaml -n kube-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以查看日志信息验证这个信息的存在</span></span><br><span class="line">$ sudo tail -f 200 /var/<span class="built_in">log</span>/syslog | grep k3s</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发现节点信息提示NotReady状态</span></span><br><span class="line"><span class="comment"># 可以尝试删除节点的密码存储信息，之后会自动获取新的</span></span><br><span class="line">$ sudo kubectl delete secret k3s2.node-password.k3s -n kube-system</span><br></pre></td></tr></table></figure><ul><li>自定义存储类型</li></ul><p>集群启动之后，默认会启动一个 <code>local-path</code> 的组件，用于提供服务挂载存储使用，其默认以 <code>PVC</code> 的形式。之后，将其存储在 <code>/var/lib/rancher/k3s/server/storageclass</code> 目录下面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看组件</span></span><br><span class="line">$ sudo kubectl get pods -A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看对应存储</span></span><br><span class="line">$ sudo kubectl get storageclass</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以使用参数修改默认存储地址</span></span><br><span class="line"><span class="comment"># --default-local-storage-path&amp;nbsp;value</span></span><br><span class="line">$ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \</span><br><span class="line">    INSTALL_K3S_MIRROR=cn \</span><br><span class="line">    INSTALL_K3S_EXEC=<span class="string">'--etcd-snapshot-schedule-cron *&amp;nbsp;*/5&amp;nbsp;*&amp;nbsp;*&amp;nbsp;*'</span> \</span><br><span class="line">    sh -</span><br></pre></td></tr></table></figure><h2><span id="4-k3s-集群升级">4. K3S 集群升级</span></h2><blockquote><p><strong>手动升级 + 自动升级</strong></p></blockquote><p>当升级 <code>K3s</code> 时，<code>K3s</code> 服务会重启或停止，但 <code>K3s</code> 容器会继续运行。 要停止所有的 <code>K3s</code> 容器并重置容器的状态，可以使用  <code>k3s-killall.sh</code> 脚本。 <code>killall</code> 脚本清理容器、<code>K3s</code> 目录和网络组件，同时也删除了 <code>iptables</code> 链和所有相关规则。集群数据不会被删除。</p><ul><li>[1] 手动升级 - 使用安装脚本升级 K3s</li></ul><p>你可以通过使用安装脚本升级 <code>K3s</code>，或者手动安装所需版本的二进制文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 升级到最新stable版本</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级到latest版本</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL=latest sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级到v1.20的最新版本</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL=<span class="string">"v1.20"</span> sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级到指定版本</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=vX.Y.Z-rc1 sh -</span><br></pre></td></tr></table></figure><ul><li>[2] 手动升级 - 使用二进制文件手动升级 K3s</li></ul><p>你可以通过使用安装脚本升级 <code>K3s</code>，或者手动安装所需版本的二进制文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从发布下载所需版本的K3s二进制文件</span></span><br><span class="line">https://github.com/rancher/k3s/releases</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将下载的二进制文件复制到/usr/local/bin/k3s</span></span><br><span class="line">$ mv ./k3s /usr/<span class="built_in">local</span>/bin/k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止旧的K3s二进制文件</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL=<span class="string">"v1.20"</span> sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动新的K3s二进制文件</span></span><br><span class="line">$ curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=vX.Y.Z-rc1 sh -</span><br></pre></td></tr></table></figure><p>你可以使用 <code>Rancher</code> 的 <code>system-upgrad-controller</code> 来管理 <code>K3s</code> 集群升级。这是一种 <code>Kubernetes</code> 原生的集群升级方法。它利用自定义资源定义(<code>CRD</code>)、计划和控制器，根据配置的计划安排升级。</p><p>控制器通过监控计划和选择要在其上运行升级 <code>job</code> 的节点来调度升级，计划通过标签选择器定义哪些节点应该升级。当一个 <code>job</code> 成功运行完成后，控制器会给它运行的节点打上相应的标签。</p><ul><li>[3] 自动升级 - 使用二进制文件手动升级 K3s<ul><li><a href="https://github.com/rancher/k3s-upgrade" target="_blank" rel="noopener">k3s-upgrade</a></li><li><a href="https://github.com/rancher/system-upgrade-controller" target="_blank" rel="noopener">system-upgrade-controller</a></li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将system-upgrade-controller安装到您的集群中</span></span><br><span class="line">$ kubectl apply -f https://github.com/rancher/system-upgrade-controller/releases/download/v0.6.2/system-upgrade-controller.yaml</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置计划</span></span><br><span class="line"><span class="comment"># 建议您最少创建两个计划</span></span><br><span class="line"><span class="comment"># 升级server节点的计划和升级agent节点的计划</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Server plan</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">upgrade.cattle.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Plan</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">server-plan</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">system-upgrade</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">concurrency:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">cordon:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">matchExpressions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span> <span class="comment"># 选择主节点</span></span><br><span class="line">      <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">      <span class="attr">values:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"true"</span></span><br><span class="line">  <span class="attr">serviceAccountName:</span> <span class="string">system-upgrade</span></span><br><span class="line">  <span class="attr">upgrade:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rancher/k3s-upgrade</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1.20.4+k3s1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Agent plan</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">upgrade.cattle.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Plan</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">agent-plan</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">system-upgrade</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">concurrency:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">cordon:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">matchExpressions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span> <span class="comment"># 选择工作节点</span></span><br><span class="line">      <span class="attr">operator:</span> <span class="string">DoesNotExist</span></span><br><span class="line">  <span class="attr">prepare:</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prepare</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">server-plan</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rancher/k3s-upgrade</span></span><br><span class="line">  <span class="attr">serviceAccountName:</span> <span class="string">system-upgrade</span></span><br><span class="line">  <span class="attr">upgrade:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rancher/k3s-upgrade</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1.20.4+k3s1</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自动升级到最新版本(不指定版本)</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">upgrade.cattle.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Plan</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">upgrade:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rancher/k3s-upgrade</span></span><br><span class="line">  <span class="attr">channel:</span> <span class="string">https://update.k3s.io/v1-release/channels/stable</span></span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/advance-k3s-tool-04-20220519092442639-2022-05-19-XowxJZ.png" alt="K3S集群升级"></p><h2><span id="5-k3s-备份恢复">5. K3S 备份恢复</span></h2><blockquote><p><strong>SQLite + etcd + 外部数据存储</strong></p></blockquote><ul><li>[1] 使用嵌入式 SQLite 数据存储进行备份和恢复</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式1：备份/恢复数据目录</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份</span></span><br><span class="line">$ cp -rf /var/lib/rancher/k3s/server/db /opt/db</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复</span></span><br><span class="line">$ systemctl stop k3s</span><br><span class="line">$ rm -rf /var/lib/rancher/k3s/server/db</span><br><span class="line">$ cp -rf /opt/db /var/lib/rancher/k3s/server/db</span><br><span class="line">$ systemctl start k3s</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式2：通过 SQLite cli</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份</span></span><br><span class="line">sqlite3 /var/lib/rancher/k3s/server/db/state.db</span><br><span class="line">SQLite version 3.22.0 2018-01-22 18:45:57</span><br><span class="line">Enter <span class="string">".help"</span> <span class="keyword">for</span> usage hints.</span><br><span class="line">sqlite&gt; .backup <span class="string">"/opt/kine.db"</span></span><br><span class="line">sqlite&gt; .<span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复</span></span><br><span class="line">$ sudo systemctl stop k3s</span><br><span class="line"></span><br><span class="line">sqlite3 /var/lib/rancher/k3s/server/db/state.db</span><br><span class="line">SQLite version 3.22.0 2018-01-22 18:45:57</span><br><span class="line">Enter <span class="string">".help"</span> <span class="keyword">for</span> usage hints.</span><br><span class="line">sqlite&gt; .restore <span class="string">'/opt/kine.db'</span></span><br><span class="line">sqlite&gt; .<span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line">$ sudo systemctl start k3s</span><br></pre></td></tr></table></figure><p>当使用外部数据存储时，备份和恢复操作是在 <code>K3s</code> 之外处理的。数据库管理员需要对外部数据库进行备份，或者从快照或转储中进行恢复。我们建议将数据库配置为执行定期快照。</p><ul><li>[2] 使用外部数据存储进行备份和恢复</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份</span></span><br><span class="line">$ mysqldump -uroot -p --all-databases --master-data &gt; k3s-dbdump.db</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复</span></span><br><span class="line">$ systemctl stop k3s</span><br><span class="line">$ mysql -uroot -p  &lt; k3s-dbdump.db</span><br><span class="line">$ systemctl start k3s</span><br></pre></td></tr></table></figure><ul><li>[3] 使用嵌入式 etcd 数据存储进行备份和恢复</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建快照(K3s默认启用快照)</span></span><br><span class="line"><span class="comment"># 快照目录默认: /var/lib/rancher/k3s/server/db/snapshots</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 要配置快照间隔或保留的快照数量</span></span><br><span class="line">--etcd-disable-snapshots       禁用自动etcd快照</span><br><span class="line">--etcd-snapshot-schedule-cron  定时快照的时间点；认值为每12小时触发一次</span><br><span class="line">--etcd-snapshot-retention      保留的快照数量；默认值为5</span><br><span class="line">--etcd-snapshot-dir            保存数据库快照的目录路径</span><br><span class="line">--cluster-reset                忘记所有的对等体；成为新集群的唯一成员</span><br><span class="line">--cluster-reset-restore-path   要恢复的快照文件的路径</span><br></pre></td></tr></table></figure><p>当 <code>K3s</code> 从备份中恢复时，旧的数据目录将被移动到<code>/var/lib/rancher/k3s/server/db/etcd-old/</code>。然后 <code>K3s</code> 会尝试通过创建一个新的数据目录来恢复快照，然后从一个带有一个 <code>etcd</code> 成员的新 <code>K3s</code> 集群启动 <code>etcd</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从快照恢复集群</span></span><br><span class="line"><span class="comment"># 使用--cluster-reset选项运行K3s</span></span><br><span class="line"><span class="comment"># 同时给出--cluster-reset-restore-path</span></span><br><span class="line">$ ./k3s server \</span><br><span class="line">    --cluster-reset \</span><br><span class="line">    --cluster-reset-restore-path=&lt;PATH-TO-SNAPSHOT&gt;</span><br></pre></td></tr></table></figure><h2><span id="6-k3s-卷和存储">6. K3S 卷和存储</span></h2><blockquote><p><strong>介绍了如何通过 local storage provider 或 Longhorn 来设置持久存储。</strong></p></blockquote><p>当部署一个需要保留数据的应用程序时，你需要创建持久存储。持久存储允许您从运行应用程序的 <code>pod</code> 外部存储应用程序数据。即使应用程序的 <code>pod</code> 发生故障，这种存储方式也可以使您维护应用程序数据。</p><ul><li>[1] 设置 Local Storage Provider 支持</li></ul><p><code>K3s</code> 自带 <code>Rancher</code> 的 <code>Local Path Provisioner</code>(<code>LPP</code>)，这使得能够使用各自节点上的本地存储来开箱即用地创建 <code>pvc</code>。根据用户配置，<code>LPP</code> 将自动在节点上创建基于 <code>hostPath</code> 的持久卷。它利用了 <code>K8s</code> 的 <code>Local Persistent Volume</code> 特性引入的特性，但它比 <code>K8s</code> 中内置的  <code>local pv</code> 特性更简单的解决方案。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pvc.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">local-path-pvc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">local-path</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">2Gi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pod.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-test</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-test</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:stable-alpine</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volv</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volv</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">local-path-pvc</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 应用yaml服务</span></span><br><span class="line">$ kubectl create -f pvc.yaml pod.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确认PV和PVC已创建</span></span><br><span class="line">$ kubectl get pv</span><br><span class="line">$ kubectl get pvc</span><br></pre></td></tr></table></figure><ul><li>[2] 设置 Longhorn 支持</li></ul><p><code>K3s</code> 支持 <code>Longhorn</code>(是 <code>K8s</code> 的一个开源分布式块存储系统)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装Longhorn</span></span><br><span class="line"><span class="comment"># 将被安装在命名空间longhorn-system中</span></span><br><span class="line">$ kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/master/deploy/longhorn.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># pvc.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: longhorn-volv-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  storageClassName: longhorn</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 2Gi</span><br><span class="line"></span><br><span class="line"><span class="comment"># pod.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: volume-test</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: volume-test</span><br><span class="line">    image: nginx:stable-alpine</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: volv</span><br><span class="line">      mountPath: /data</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">  volumes:</span><br><span class="line">  - name: volv</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: longhorn-volv-pvc</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 应用yaml服务</span></span><br><span class="line">$ kubectl create -f pvc.yaml pod.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确认PV和PVC已创建</span></span><br><span class="line">$ kubectl get pv</span><br><span class="line">$ kubectl get pvc</span><br></pre></td></tr></table></figure><h2><span id="7-k3s-网络相关">7. K3S 网络相关</span></h2><blockquote><p><strong>简单介绍下 K3s 相关的网络配置组件！</strong></p></blockquote><ul><li><strong>CoreDNS</strong></li></ul><p><code>CoreDNS</code> 是在 <code>agent</code> 节点启动时部署的。要禁用，请在每台服务器上运行 <code>--disable coredns</code> 选项。如果你不安装 <code>CoreDNS</code>，你将需要自己安装一个集群 <code>DNS</code> 提供商。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如何修改coredns参数</span></span><br><span class="line"><span class="comment"># /var/lib/rancher/k3s/server/manifests/coredns.yaml</span></span><br><span class="line"><span class="comment"># 该文件重启K3s服务的话会导致coredns配置重新初始化</span></span><br><span class="line">1.将coredns.yaml保存到其他目录</span><br><span class="line">2.通过 --<span class="built_in">disable</span> coredns 禁用coredns</span><br><span class="line">3.复制coredns.yaml到/var/lib/rancher/k3s/server/manifests/目录并修改参数</span><br></pre></td></tr></table></figure><ul><li><strong>Traefik Ingress Controller</strong></li></ul><p>启动 <code>server</code> 时，默认情况下会部署 <code>Traefik</code>，对该文件的任何修改都会以类似 <code>kubectl apply</code> 的方式自动部署到 <code>Kubernetes</code> 中，将使用主机上的 <code>80</code> 和 <code>443</code> 端口。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 操作和上面基本是一致的</span></span><br><span class="line"><span class="comment"># 请使用 --disable traefik 选项启动每个server</span></span><br><span class="line"><span class="comment"># /var/lib/rancher/k3s/server/manifests/traefik.yaml</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如何启用 treafik2 dashboard</span></span><br><span class="line"><span class="comment"># http://traefik.example.com/dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">Note:</span> in a kubernetes secret the string (e.g. generated by htpasswd) must be base64-encoded first.</span></span><br><span class="line"><span class="comment"># To create an encoded user:password pair, the following command can be used:</span></span><br><span class="line"><span class="comment"># htpasswd -nb admin admin | openssl base64</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authsecret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">users:</span> <span class="string">|2</span></span><br><span class="line">    <span class="string">YWRtaW46JGFwcjEkLkUweHd1Z0EkUjBmLi85WndJNXZWRFMyR2F2LmtELwoK</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">traefik.containo.us/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">IngressRoute</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">routes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">match:</span> <span class="string">Host(`traefik.example.com`)</span> <span class="string">&amp;&amp;</span> <span class="string">(PathPrefix(`/api`)</span> <span class="string">||</span> <span class="string">PathPrefix(`/dashboard`))</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">Rule</span></span><br><span class="line">      <span class="attr">services:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">api@internal</span></span><br><span class="line">          <span class="attr">kind:</span> <span class="string">TraefikService</span></span><br><span class="line">      <span class="attr">middlewares:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">auth</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">traefik.containo.us/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Middleware</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">auth</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">basicAuth:</span></span><br><span class="line">    <span class="attr">secret:</span> <span class="string">authsecret</span> <span class="comment"># Kubernetes secret named "secretName"</span></span><br></pre></td></tr></table></figure><ul><li>Service Load Balancer</li></ul><p><code>K3s</code> 提供了一个名为 <code>Klipper Load Balancer</code> 的负载均衡器，它可以使用可用的主机端口。 允许创建 <code>LoadBalancer</code> 类型的 <code>Service</code>，但不包括 <code>LB</code> 的实现。某些 <code>LB</code> 服务需要云提供商，例如 <code>Amazon EC2</code>。相比之下，<code>K3s service LB</code> 使得可以在没有云提供商的情况下使用 <code>LB</code> 服务。</p><h2><span id="8-k3s-与-helm">8. K3S 与 Helm</span></h2><p><code>Helm</code> 是 <code>Kubernetes</code> 的包管理工具。<code>Helm Chart</code> 为 <code>Kubernetes YAML</code> 清单文件提供了模板化语法，可以通过 <code>Helm</code> 安装对应的 <code>chart</code>。<code>K3s</code> 不需要任何特殊的配置就可以使用 <code>Helm</code> 命令行工具。</p><ul><li>自动部署 Helm charts</li></ul><p>在 <code>/var/lib/rancher/k3s/server/manifests</code> 中找到的任何 <code>Kubernetes</code> 清单将以类似 <code>kubectl apply</code> 的方式自动部署到 <code>K3s</code>。以这种方式部署的 <code>manifests</code> 是作为 <code>AddOn</code> 自定义资源来管理的。你会发现打包组件的 <code>AddOns</code>，如 <code>CoreDNS</code>、<code>Local-Storage</code> 等。<code>AddOns</code> 是由部署控制器自动创建的，并根据它们在 <code>manifests</code> 目录下的文件名命名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看运行AddOn资源</span></span><br><span class="line">$ kubectl get addon -A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以将Helm-Chart作为AddOns部署</span></span><br><span class="line">https://github.com/rancher/helm-controller/</span><br></pre></td></tr></table></figure><ul><li>使用 Helm CRD</li></ul><p><code>HelmChart CRD</code> 捕获了大多数你通常会传递给 <code>helm</code> 命令行工具的选项。下面是一个例子，说明如何从默认的 <code>Chart</code> 资源库中部署 <code>Grafana</code>，覆盖一些默认的 <code>Chart</code> 值。请注意，<code>HelmChart</code> 资源本身在 <code>kube-system</code> 命名空间，但 <code>Chart</code> 资源将被部署到 <code>monitoring</code> 命名空间。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">helm.cattle.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HelmChart</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">grafana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">chart:</span> <span class="string">stable/grafana</span></span><br><span class="line">  <span class="attr">targetNamespace:</span> <span class="string">monitoring</span></span><br><span class="line">  <span class="attr">set:</span></span><br><span class="line">    <span class="attr">adminPassword:</span> <span class="string">"NotVerySafePassword"</span></span><br><span class="line">  <span class="attr">valuesContent:</span> <span class="string">|-</span></span><br><span class="line">    <span class="attr">image:</span></span><br><span class="line">      <span class="attr">tag:</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">env:</span></span><br><span class="line">      <span class="attr">GF_EXPLORE_ENABLED:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">adminUser:</span> <span class="string">admin</span></span><br><span class="line">    <span class="attr">sidecar:</span></span><br><span class="line">      <span class="attr">datasources:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2><span id="9-k3s-高级选项">9. K3S 高级选项</span></h2><blockquote><p><strong><a href="https://github.com/kingsd041/k3s-tutorial/blob/main/17-%E9%AB%98%E7%BA%A7%E9%80%89%E9%A1%B9%E5%92%8C%E9%85%8D%E7%BD%AE/README.md" target="_blank" rel="noopener">包含高级选项和配置</a></strong></p></blockquote><ul><li>证书轮换</li></ul><p>默认情况下，<code>K3s</code> 的证书在 <code>12</code> 个月内过期。如果证书已经过期或剩余的时间不足 <code>90</code> 天，则在 <code>K3s</code> 重启时轮换证书。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询K3s证书过期时间</span></span><br><span class="line">$ <span class="keyword">for</span> i <span class="keyword">in</span> `ls /var/lib/rancher/k3s/server/tls/*.crt`; \</span><br><span class="line">  <span class="keyword">do</span> \</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$i</span>;\</span><br><span class="line">    openssl x509 -enddate -noout -<span class="keyword">in</span> <span class="variable">$i</span>; \</span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改系统时间为证书过期前90天或证书过期后</span></span><br><span class="line">$ timedatectl <span class="built_in">set</span>-ntp no</span><br><span class="line">$ date -s 20220807</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启K3s服务</span></span><br><span class="line">$ service k3s restart</span><br></pre></td></tr></table></figure><ul><li>Red Hat 和 CentOS 的额外准备</li></ul><p>建议运行以下命令，关闭 <code>firewalld</code> 防火墙。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">disable</span> firewalld --now</span><br></pre></td></tr></table></figure><h2><span id="10-参考链接">10. 参考链接</span></h2><blockquote><p><strong>送人玫瑰，手有余香！</strong></p></blockquote><ul><li><strong>[1] 文档教程</strong><ul><li><a href="http://mirror.cnrancher.com/" target="_blank" rel="noopener">K3s 中文文档 - 国外</a></li><li><a href="https://docs.rancher.cn/k3s" target="_blank" rel="noopener">K3s 中文文档 - 国内</a></li><li><a href="https://mirror.rancher.cn/" target="_blank" rel="noopener">K3s 国内镜像站 - 加速</a></li><li><a href="https://github.com/kingsd041/k3s-tutorial" target="_blank" rel="noopener">K3s 系列教程 - 官方制作</a></li></ul></li><li><strong>[2] 代码地址</strong><ul><li><a href="https://github.com/k3s-io" target="_blank" rel="noopener">K3s 仓库地址 - Github</a></li></ul></li><li><strong>[3] 周边项目</strong><ul><li>K3s 周边项目 - k3os<ul><li>完全基于 <code>K8S</code> 管理的轻量级操作系统</li></ul></li><li>K3s 周边项目 - autok3s<ul><li>用于简化 <code>K3s</code> 集群部署和管理的轻量级工具</li><li>即在阿里云和 <code>aws</code> 等云服务器上面部署 <code>k3s</code></li></ul></li><li>K3s 周边项目 - k3d<ul><li>可以在 <code>k3d</code> 创建容器化的 <code>k3s</code> 集群</li><li>可以使用容器在单台计算机上启动多节点 <code>k3s</code> 集群</li></ul></li><li>K3s 周边项目 - harvester<ul><li>基于 <code>K8S</code> 构建的开源超融合基础架构(<code>HCI</code>)软件</li><li>旨在替换 <code>vSphere</code> 和 <code>Nutanix</code> 的开源替代方案</li></ul></li><li>K3s 周边项目 - octopus<ul><li>主要用于边缘计算相关</li><li>用于 <code>K8S</code> 和 <code>k3s</code> 的轻量级云原生设备管理系统</li><li>集群可以将边缘设备作为自定义 <code>k8s</code> 资源进行管理</li></ul></li></ul></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://url.hi-linux.com/ytP71" target="_blank" rel="noopener">https://url.hi-linux.com/ytP71</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;深入理解官方文档，轻松学会使用 K3S 工具！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;K3s&lt;/code&gt; 是一个轻量级的 &lt;code&gt;Kubernetes&lt;/code&gt; 发行版，它针对边缘计算、物联网等场景进行了高度优化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CNCF&lt;/code&gt; 认证的 &lt;code&gt;Kubernetes&lt;/code&gt; 发行版&lt;/li&gt;
&lt;li&gt;支持 &lt;code&gt;X86_64&lt;/code&gt;, &lt;code&gt;ARM64&lt;/code&gt;, &lt;code&gt;ARMv7&lt;/code&gt; 平台&lt;/li&gt;
&lt;li&gt;单一进程包含 &lt;code&gt;Kubernetes master&lt;/code&gt;，&lt;code&gt;kubelet&lt;/code&gt; 和 &lt;code&gt;containerd&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="K3s" scheme="https://www.hi-linux.com/tags/K3s/"/>
    
  </entry>
  
  <entry>
    <title>再见 Alfred，是时候拥抱下一代快捷启动神器 Raycast 了</title>
    <link href="https://www.hi-linux.com/posts/21309.html"/>
    <id>https://www.hi-linux.com/posts/21309.html</id>
    <published>2022-04-28T01:00:00.000Z</published>
    <updated>2022-04-28T04:21:29.798Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>一款速度极快、完全可扩展的启动器。</strong></p></blockquote><p>今天给大家介绍一款可以帮助我们提升生产力或者改善效率的工具，那就是 <code>Raycast</code>。它的功能和我们知道的 <code>Spotlight</code> 和 <code>Alfred</code> 很类似，但是其 <code>UI</code> 涉及完全可以能够驾驭 <code>macOS</code> 的全新的视觉风格(如下图所示)。</p><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-2022-04-28-WkhBCv.jpg" alt="Raycast 下一代快捷启动器"></p><h2><span id="1-工具介绍">1. 工具介绍</span></h2><blockquote><p><strong>你的新一代快捷启动器</strong></p></blockquote><p><code>Raycast</code> 是直到 <code>10</code> 月 <code>29</code> 日才放出这第一个公测版本，其开发者介绍 <code>Raycast</code> 正是受命令行的启发，作为软件工程师，他们注意到自己真正写代码的时间越来越少，反而需要更多的时间来管理软件开发，例如跟踪 <code>bug</code> 反馈、管理 <code>sprint</code>、发布新版本等等，这些都需要借助网页端或者其它的不同工具来完成。</p><p>于是，<code>Raycast</code> 正是为了解决他们的困扰而创建，尽可能将常用的管理开发、内部会议、任务规划等内容集成在一起，腾出更多地时间放在编写代码上。简单过一下 <code>Raycast</code> 目前所能实现的核心功能：</p><ul><li>在 <code>macOS</code> 上启动程序或者搜索文件，相当于聚焦；</li><li>在 <code>GitHub</code>、<code>Jira</code> 中创建、搜索和关闭 <code>issues</code>；</li><li>批准、合并和关闭 <code>GitHub</code> 的拉取请求；</li><li>调用 <code>Zoom</code> 管理日常会议；</li><li>支持快捷设置日程、待办事项以及其它诸多系统设置；</li><li>支持脚本扩展；</li><li>……</li></ul><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-01-20220428092254655-2022-04-28-iV3UcV.png" alt="Raycast 下一代快捷启动器"></p><a id="more"></a><h2><span id="2-配置说明">2. 配置说明</span></h2><blockquote><p><strong>可完全取代聚焦</strong></p></blockquote><p>既然 <code>Raycast</code> 包含了 <code>Spotlight</code> 的功能，意味着你完全可以用 <code>Raycast</code> 替换掉它。默认快捷键为 <strong>「option + 空格」</strong> ，可以启动该工具，我们可以通过在输入框中输入信息来得到我们想要的东西或启动对应的应用服务。</p><ul><li>显示一个搜索框<ul><li>推荐项目(根据使用频率)</li><li>手动收藏项目以及快捷操作</li><li>下滑则能看到所有的项目</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-02-2022-04-28-9jsJYr.png" alt="Raycast 下一代快捷启动器"></p><p>软件右下角有快捷菜单，除了打开应用/文件之外，还可以快速定位文件位置或者执行其它操作，而且这些所有的一系列操作都可以使用快捷键完成。文件搜索功能支持部分图片、文档预览，且能显示文件详细信息，这个比聚焦实用性更高。</p><h2><span id="3-高级特性">3. 高级特性</span></h2><blockquote><p><strong>支持管理日程、待办事项、剪贴板历史</strong></p></blockquote><p><code>Raycast</code> 对接了不少第三方应用的功能服务，也包括 <code>macOS</code> 系统自带的日程查看以及待办事项管理，这些所能实现的操作在设置中都可以直接看到，可手动选择关闭。不过同样是系统应用，通过 <code>Raycast</code> 可以查看、创建待办事项，而日历日程却只能查看，无法通过 <code>Raycast</code> 新建。</p><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-03-20220428092302624-2022-04-28-TOPIrj.jpg" alt="Raycast 下一代快捷启动器"></p><p>剪贴板历史记录算是 <code>Raycast</code> 给我的一个小小惊喜，这是 <code>Raycast</code> 本身自带的小功能。而通过 <code>Raycast</code> 搜索「<code>Clipboard History</code>」，能够直接查看近期的剪贴板记录。</p><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-04-20220428092310098-2022-04-28-kXgJZZ.jpg" alt="Raycast 下一代快捷启动器"></p><p>接入第三方服务高效协作，已经接入了 <code>GitHub</code>、<code>Jira</code>、<code>Zoom</code> 等服务，能够快速完成特定操作。用户需要通过 <code>OAuth</code> 协议登录指定服务，已完成自有账号内容的双向同步。</p><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-05-2022-04-28-qMZDRk.jpg" alt="Raycast 下一代快捷启动器"></p><p>日常使用电脑，可能经常会需要调整一些系统设置项，例如音量调节、休眠、锁屏或者深色模式切换等等。不少用户会通过第三方工具来完成，例如  <code>One Switch</code>。<code>Raycast</code> 本身内置了一些系统功能调节，同时支持加载命令脚本，意味着能够将很多较为隐秘的系统设置融入 <code>Raycast</code> 实现快捷操作。</p><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-06-2022-04-28-k0gQv8.jpg" alt="Raycast 下一代快捷启动器"></p><h2><span id="4-插件">4. 插件</span></h2><p>Raycast 官方有着相当丰富的插件生态，包括 <code>Vscode</code>、<code>Github</code>、<code>Google</code>、<code>Docker</code>、<code>Kubernetes</code> 等常用插件。</p><p><img src="https://img.hi-linux.com/staticfile/image-20220428093840589-2022-04-28-uLVFIV.png" alt="Raycast 下一代快捷启动器"></p><p><img src="https://img.hi-linux.com/staticfile/image-20220428093923976-2022-04-28-k9bfl4.png" alt="Raycast 下一代快捷启动器"></p><p>下面以 <a href="http://Ray.so" target="_blank" rel="noopener">Ray.so</a> 为例，来看看其强大的插件功能：</p><blockquote><p><strong>主要是介绍相关的一些配置集合我们应该怎么使用</strong></p></blockquote><ul><li>[1] 生成漂亮的分享代码 - <a href="http://Raycast+Ray.so" target="_blank" rel="noopener">Raycast+Ray.so</a><ul><li>安装：<code>Raycast</code> -&gt; <code>store</code> - <code>ray.so</code></li><li>使用：选中代码 -&gt; 打开搜索 <code>CI</code>(<code>Copy Image</code>) -&gt; 生成</li><li>定制：打开搜索 <code>Create Image from Code</code> 进行设置</li></ul></li></ul><p><code>Ray.so</code> 是一款提供代码图片分享的 <code>Web</code> 服务，可以将代码文本转化为美观的图片进行分享，类似的 Web 服务还有  <a href="https://carbon.now.sh/" target="_blank" rel="noopener">Carbon</a> 等。</p><p><img src="https://img.hi-linux.com/staticfile/raycast-terminal-tool-07-20220428092319067-2022-04-28-xISHXC.png" alt="Raycast 下一代快捷启动器"></p><p>更多好用的插件可到 Raycast Store 探索。</p><blockquote><p>Raycast Store 官方地址: <a href="https://www.raycast.com/store" target="_blank" rel="noopener">https://www.raycast.com/store</a></p></blockquote><p>如果官方 Raycast Store 提供的插件也不能满足你更多狂野的需求，你还可到开源社区获取更多的脚本插件。</p><p><img src="https://img.hi-linux.com/staticfile/dPV66e-2022-04-28-Ri7jvF.jpg" alt="Raycast 下一代快捷启动器"></p><p><img src="https://img.hi-linux.com/staticfile/add-directory-2022-04-28-2Wqr2O.png" alt="Raycast 下一代快捷启动器"></p><p>除此之外，你还可以按自身需求定制专用的脚本，支持的脚本语言有：<code>Bash</code>，<code>Python</code>，<code>Apple Script</code>，<code>Swift</code>，<code>Ruby</code>，<code>Node.js</code>。</p><p><img src="https://img.hi-linux.com/staticfile/Create-Script-Command-20220428114937278-2022-04-28-e1Y4Jy.png" alt="Raycast 下一代快捷启动器"></p><blockquote><p>Raycast Script 官方地址: <a href="https://github.com/raycast/script-commands" target="_blank" rel="noopener">https://github.com/raycast/script-commands</a></p></blockquote><h2><span id="5-参考链接">5. 参考链接</span></h2><ul><li><a href="https://sspai.com/post/63521" target="_blank" rel="noopener">Raycast 快捷启动器中的「潜力股」</a></li><li><a href="https://sspai.com/post/72627" target="_blank" rel="noopener">Raycast 分享让人眼前一亮的代码</a></li><li><a href="https://github.com/raycast/script-commands" target="_blank" rel="noopener">Raycast 脚本大集合 - 可参考和使用</a></li><li><a href="https://www.notion.so/Raycast-Manual-d5c85a7694dc4e4088b8b93557ea6d2d" target="_blank" rel="noopener">Raycast 官方使用手册 - 新手指南</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://url.hi-linux.com/8wXQL" target="_blank" rel="noopener">https://url.hi-linux.com/8wXQL</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;一款速度极快、完全可扩展的启动器。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天给大家介绍一款可以帮助我们提升生产力或者改善效率的工具，那就是 &lt;code&gt;Raycast&lt;/code&gt;。它的功能和我们知道的 &lt;code&gt;Spotlight&lt;/code&gt; 和 &lt;code&gt;Alfred&lt;/code&gt; 很类似，但是其 &lt;code&gt;UI&lt;/code&gt; 涉及完全可以能够驾驭 &lt;code&gt;macOS&lt;/code&gt; 的全新的视觉风格(如下图所示)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/raycast-terminal-tool-2022-04-28-WkhBCv.jpg&quot; alt=&quot;Raycast 下一代快捷启动器&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-工具介绍&quot;&gt;1. 工具介绍&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;你的新一代快捷启动器&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Raycast&lt;/code&gt; 是直到 &lt;code&gt;10&lt;/code&gt; 月 &lt;code&gt;29&lt;/code&gt; 日才放出这第一个公测版本，其开发者介绍 &lt;code&gt;Raycast&lt;/code&gt; 正是受命令行的启发，作为软件工程师，他们注意到自己真正写代码的时间越来越少，反而需要更多的时间来管理软件开发，例如跟踪 &lt;code&gt;bug&lt;/code&gt; 反馈、管理 &lt;code&gt;sprint&lt;/code&gt;、发布新版本等等，这些都需要借助网页端或者其它的不同工具来完成。&lt;/p&gt;
&lt;p&gt;于是，&lt;code&gt;Raycast&lt;/code&gt; 正是为了解决他们的困扰而创建，尽可能将常用的管理开发、内部会议、任务规划等内容集成在一起，腾出更多地时间放在编写代码上。简单过一下 &lt;code&gt;Raycast&lt;/code&gt; 目前所能实现的核心功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 &lt;code&gt;macOS&lt;/code&gt; 上启动程序或者搜索文件，相当于聚焦；&lt;/li&gt;
&lt;li&gt;在 &lt;code&gt;GitHub&lt;/code&gt;、&lt;code&gt;Jira&lt;/code&gt; 中创建、搜索和关闭 &lt;code&gt;issues&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;批准、合并和关闭 &lt;code&gt;GitHub&lt;/code&gt; 的拉取请求；&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;Zoom&lt;/code&gt; 管理日常会议；&lt;/li&gt;
&lt;li&gt;支持快捷设置日程、待办事项以及其它诸多系统设置；&lt;/li&gt;
&lt;li&gt;支持脚本扩展；&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/raycast-terminal-tool-01-20220428092254655-2022-04-28-iV3UcV.png&quot; alt=&quot;Raycast 下一代快捷启动器&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Alfred" scheme="https://www.hi-linux.com/tags/Alfred/"/>
    
      <category term="Raycast" scheme="https://www.hi-linux.com/tags/Raycast/"/>
    
  </entry>
  
  <entry>
    <title>如何快速的自建 DoH ( DNS over HTTPS) 服务</title>
    <link href="https://www.hi-linux.com/posts/34709.html"/>
    <id>https://www.hi-linux.com/posts/34709.html</id>
    <published>2022-04-19T01:00:00.000Z</published>
    <updated>2022-04-19T04:29:49.665Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="1-前言">1. 前言</span></h2><p>DoH（DNS over HTTPS），顾名思义，使用HTTPS协议执行DNS查询，除了最常用的UDP外，还有DoT（DNS over TLS），DNS over HTTP（服务提供商自定义）等方案，对比如下：</p><table><thead><tr><th style="text-align:left">协议</th><th style="text-align:left">标准</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">DNS over HTTPS</td><td style="text-align:left"><a href="https://datatracker.ietf.org/doc/html/rfc8484" target="_blank" rel="noopener">RFC8484</a></td><td style="text-align:left">使用TLS加密的HTTP/2执行DNS查询</td></tr><tr><td style="text-align:left">DNS over TLS</td><td style="text-align:left"><a href="https://datatracker.ietf.org/doc/html/rfc7858" target="_blank" rel="noopener">RFC7858</a></td><td style="text-align:left">使用TLS加密的TCP执行DNS查询</td></tr><tr><td style="text-align:left">DNS over HTTP</td><td style="text-align:left">服务提供商自定义</td><td style="text-align:left">使用自定义加密的HTTP/1.1执行DNS查询</td></tr></tbody></table><p>移动端的DNS优化已经有很多实践，最常见的是DNS over HTTP，通过加密的HTTP请求规避运营商对DNS的UDP包劫持，从而优化App访问服务器的延迟。但这个方案并没有形成统一的标准，通常需要内嵌DNS服务提供商的SDK，通过访问固定的BGP或任播IP获取DNS响应。</p><a id="more"></a><p>大概是意识到DNS在移动互联网中的扮演越来越重要的角色，在DoT和DoH的规范相继推出后，许多DNS服务提供商都跟进了部署，国内的阿里云、DNSPod，国外的谷歌、Cloudflare等目前已经推出了免费的DoT和DoH服务。</p><p>客户端方面，常用的Chrome、FireFox已经支持了自定义DoH服务器，macOS、iOS也可通过配置文件设置系统范围的默认DoH服务器。</p><p>笔者也正好有一个自定义DNS的需求：</p><ol><li>需要针对一些域名的DNS查询仅返回IPv4记录</li><li>使用的某某路由器系统的自定义DNS服务仅支持设置UDP和DoH</li><li>UDP模式默认使用53端口，不可修改，UDP包容易遭受干扰</li><li>DoH可自定义域名、端口且使用HTTP2作为传输协议，稳定性更强</li></ol><p>综上，只有自建DoH服务了，于是就有了下面的折腾，最后测试时发现这个傻瓜路由器系统只支持一些特定的DoH服务商如阿里云DNS、DNSPod等，不支持自建的DoH服务。</p><h2><span id="2-部署方案">2. 部署方案</span></h2><p>DoH本质上就是一个HTTP请求，只是目前协议定义要求启用TLS与HTTP/2。最初没有跑通coredns的DoH时，使用了nginx作为前端转发DoH请求到doh-server，然后doh-server使用本地的coredns服务作为上游。</p><p>最近再仔细研究了下文档，发现coredns已经支持了DoH服务，可直接对外暴露服务，或者通过nginx转发来复用已经部署好的web服务。</p><h3><span id="21-nginx-doh-server-coredns">2.1 nginx + doh-server + coredns</span></h3><p><a href="https://github.com/m13253/dns-over-https" target="_blank" rel="noopener">https://github.com/m13253/dns-over-https</a> 是一个提供 DNS over HTTP 的服务，需要一个web前端和一个DNS后端，可用的docker镜像地址为：<a href="https://hub.docker.com/r/satishweb/doh-server" target="_blank" rel="noopener">satishweb/doh-server</a>，使用doh-server时，DNS请求流转如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTP Service -&gt; doh-server -&gt; DNS Server</span><br></pre></td></tr></table></figure><p>RFC8484中指定使用/dns-query路径作为默认查询路径，因此只需要将该路径前缀的请求转发到doh-server即可，如下：</p><p><strong>nginx配置（已配置好TLS与HTTP2）</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl http2 fastopen&#x3D;256 reuseport;</span><br><span class="line">    listen [::]:443 ssl http2 fastopen&#x3D;256 reuseport;</span><br><span class="line">    server_name doh.wbuntu.com</span><br><span class="line">    ...</span><br><span class="line">    location &#x2F;dns-query &#123;</span><br><span class="line">    proxy_redirect off;</span><br><span class="line">    proxy_http_version 1.1;</span><br><span class="line">    proxy_set_header Host $http_host;</span><br><span class="line">    # show real IP</span><br><span class="line">    proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    proxy_pass http:&#x2F;&#x2F;127.0.0.1:8053;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>doh-server</strong></p><p>使用hostNetwork模式启动服务，监听8053端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart unless-stopped --network host --name doh-server \</span><br><span class="line">  -e UPSTREAM_DNS_SERVER&#x3D;&quot;udp:127.0.0.1:53&quot; \</span><br><span class="line">  -e DOH_HTTP_PREFIX&#x3D;&quot;&#x2F;dns-query&quot; \</span><br><span class="line">  -e DOH_SERVER_LISTEN&#x3D;&quot;127.0.0.1:8053&quot; \</span><br><span class="line">  -e DOH_SERVER_TIMEOUT&#x3D;&quot;10&quot; \</span><br><span class="line">  -e DOH_SERVER_TRIES&#x3D;&quot;3&quot; \</span><br><span class="line">  -e DOH_SERVER_VERBOSE&#x3D;&quot;true&quot; \</span><br><span class="line">  satishweb&#x2F;doh-server</span><br></pre></td></tr></table></figure><p><strong>coredns</strong></p><p>coredns配置文件如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ tree &#x2F;etc&#x2F;coredns&#x2F;</span><br><span class="line">&#x2F;etc&#x2F;coredns&#x2F;</span><br><span class="line">└── Corefile</span><br><span class="line"></span><br><span class="line">0 directories, 1 files</span><br><span class="line">➜  cat &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br><span class="line">.:53 &#123;</span><br><span class="line">    bind 127.0.0.1</span><br><span class="line">    forward . 1.1.1.1 1.0.0.1</span><br><span class="line">    log</span><br><span class="line">    errors</span><br><span class="line">    cache</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用hostNetwork模式启动服务，监听53端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart unless-stopped --network host --name coredns \</span><br><span class="line">  -v &#x2F;etc&#x2F;coredns:&#x2F;etc&#x2F;coredns \</span><br><span class="line">  coredns&#x2F;coredns \</span><br><span class="line">  -conf &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br></pre></td></tr></table></figure><p>服务启动后，我们可以得到一个自定义的DoH服务：<a href="https://doh.wbuntu.com/dns-query" target="_blank" rel="noopener">https://doh.wbuntu.com/dns-query</a></p><h3><span id="22-coredns">2.2 coredns</span></h3><p>目前coredns支持作为DoH服务端，不支持连接上游DoH服务器，上游服务器可使用UDP和DoT。</p><p>直接对外暴露服务需要使用有效的TLS证书，coredns配置文件及证书位置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ tree &#x2F;etc&#x2F;coredns&#x2F;</span><br><span class="line">&#x2F;etc&#x2F;coredns&#x2F;</span><br><span class="line">├── Corefile</span><br><span class="line">├── tls.crt</span><br><span class="line">└── tls.key</span><br><span class="line"></span><br><span class="line">0 directories, 3 files</span><br><span class="line">➜  cat &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br><span class="line">https:&#x2F;&#x2F;.:443 &#123;</span><br><span class="line">    tls &#x2F;etc&#x2F;coredns&#x2F;tls.crt &#x2F;etc&#x2F;coredns&#x2F;tls.key</span><br><span class="line">    bind 0.0.0.0</span><br><span class="line">    forward . 1.1.1.1 1.0.0.1</span><br><span class="line">    log</span><br><span class="line">    errors</span><br><span class="line">    cache</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用hostNetwork模式启动服务，监听443端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart unless-stopped --network host --name coredns \</span><br><span class="line">  -v &#x2F;etc&#x2F;coredns:&#x2F;etc&#x2F;coredns \</span><br><span class="line">  coredns&#x2F;coredns \</span><br><span class="line">  -conf &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br></pre></td></tr></table></figure><p>服务启动后，我们可以得到一个自定义的DoH服务：<a href="https://doh.wbuntu.com/dns-query" target="_blank" rel="noopener">https://doh.wbuntu.com/dns-query</a></p><h3><span id="23-nginx-coredns">2.3 nginx + coredns</span></h3><p>直接暴露coredns服务到公网需要占用端口，coredns在未配置TLS证书时，可使用nginx作为前端来复用web服务，如下：</p><p><strong>nginx配置（已配置好TLS与HTTP2）</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl http2 fastopen&#x3D;256 reuseport;</span><br><span class="line">    listen [::]:443 ssl http2 fastopen&#x3D;256 reuseport;</span><br><span class="line">    server_name doh.wbuntu.com</span><br><span class="line">    ...</span><br><span class="line">    location &#x2F;dns-query &#123;</span><br><span class="line">    proxy_redirect off;</span><br><span class="line">    proxy_http_version 1.1;</span><br><span class="line">    proxy_set_header Host $http_host;</span><br><span class="line">    # show real IP</span><br><span class="line">    proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    proxy_pass http:&#x2F;&#x2F;127.0.0.1:8053;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>coredns</strong></p><p>coredns配置文件如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ tree &#x2F;etc&#x2F;coredns&#x2F;</span><br><span class="line">&#x2F;etc&#x2F;coredns&#x2F;</span><br><span class="line">└── Corefile</span><br><span class="line"></span><br><span class="line">0 directories, 1 files</span><br><span class="line">➜  cat &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br><span class="line">https:&#x2F;&#x2F;.:8053 &#123;</span><br><span class="line">    bind 127.0.0.1</span><br><span class="line">    forward . 1.1.1.1 1.0.0.1</span><br><span class="line">    log</span><br><span class="line">    errors</span><br><span class="line">    cache</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用hostNetwork模式启动服务，监听8053端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart unless-stopped --network host --name coredns \</span><br><span class="line">  -v &#x2F;etc&#x2F;coredns:&#x2F;etc&#x2F;coredns \</span><br><span class="line">  coredns&#x2F;coredns \</span><br><span class="line">  -conf &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br></pre></td></tr></table></figure><p>服务启动后，我们可以得到一个自定义的DoH服务：<a href="https://doh.wbuntu.com/dns-query" target="_blank" rel="noopener">https://doh.wbuntu.com/dns-query</a></p><h2><span id="3-测试">3. 测试</span></h2><p>使用谷歌浏览器配置DoH服务：Settings -&gt; Secutiry and Privacy -&gt; Secutiry -&gt; Advanced -&gt; Use secure DNS</p><p><img src="https://img.hi-linux.com/staticfile/chrome-doh-settings-20220412111328635-2022-04-12-e3XoP6.png" alt></p><p>使用Go代码测试：<a href="https://github.com/mikumaycry/example/blob/main/2021/doh/main.go" target="_blank" rel="noopener">github.com/mikumaycry/example/blob/main/2021/doh/main.go</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">        &quot;encoding&#x2F;base64&quot;</span><br><span class="line">        &quot;fmt&quot;</span><br><span class="line">        &quot;github.com&#x2F;miekg&#x2F;dns&quot;</span><br><span class="line">        &quot;io&#x2F;ioutil&quot;</span><br><span class="line">        &quot;net&#x2F;http&quot;</span><br><span class="line">        &quot;os&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">       query :&#x3D; dns.Msg&#123;&#125;</span><br><span class="line">       query.SetQuestion(&quot;www.google.com.&quot;, dns.TypeA)</span><br><span class="line">       msg, _ :&#x3D; query.Pack()</span><br><span class="line">       b64 :&#x3D; base64.RawURLEncoding.EncodeToString(msg)</span><br><span class="line">       resp, err :&#x3D; http.Get(&quot;https:&#x2F;&#x2F;doh.wbuntu.com&#x2F;dns-query?dns&#x3D;&quot; + b64)</span><br><span class="line">       if err !&#x3D; nil &#123;</span><br><span class="line">            fmt.Printf(&quot;Send query error, err:%v\n&quot;, err)</span><br><span class="line">            os.Exit(1)</span><br><span class="line">       &#125;</span><br><span class="line">       defer resp.Body.Close()</span><br><span class="line">       bodyBytes, _ :&#x3D; ioutil.ReadAll(resp.Body)</span><br><span class="line">       response :&#x3D; dns.Msg&#123;&#125;</span><br><span class="line">       response.Unpack(bodyBytes)</span><br><span class="line">       fmt.Printf(&quot;Dns answer is :%v\n&quot;, response.String())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 Wbuntu 的博客 」，原文：<a href="https://wbuntu.com/deploy-a-doh-service/" target="_blank" rel="noopener">https://wbuntu.com/deploy-a-doh-service/</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-前言&quot;&gt;1. 前言&lt;/h2&gt;
&lt;p&gt;DoH（DNS over HTTPS），顾名思义，使用HTTPS协议执行DNS查询，除了最常用的UDP外，还有DoT（DNS over TLS），DNS over HTTP（服务提供商自定义）等方案，对比如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:left&quot;&gt;协议&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;标准&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;DNS over HTTPS&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc8484&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RFC8484&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;使用TLS加密的HTTP/2执行DNS查询&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;DNS over TLS&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc7858&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RFC7858&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;使用TLS加密的TCP执行DNS查询&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;DNS over HTTP&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;服务提供商自定义&lt;/td&gt;
&lt;td style=&quot;text-align:left&quot;&gt;使用自定义加密的HTTP/1.1执行DNS查询&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;移动端的DNS优化已经有很多实践，最常见的是DNS over HTTP，通过加密的HTTP请求规避运营商对DNS的UDP包劫持，从而优化App访问服务器的延迟。但这个方案并没有形成统一的标准，通常需要内嵌DNS服务提供商的SDK，通过访问固定的BGP或任播IP获取DNS响应。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="DNS" scheme="https://www.hi-linux.com/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>24 个 常见的 Docker 疑难杂症处理技巧</title>
    <link href="https://www.hi-linux.com/posts/42601.html"/>
    <id>https://www.hi-linux.com/posts/42601.html</id>
    <published>2022-04-06T01:00:00.000Z</published>
    <updated>2022-04-06T02:24:56.310Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>这里主要是为了记录在使用 Docker 的时候遇到的问题及其处理解决方法。</strong></p></blockquote><h2><span id="docker-迁移存储目录">Docker 迁移存储目录</span></h2><blockquote><p><strong>默认情况系统会将 Docker 容器存放在 /var/lib/docker 目录下</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 今天通过监控系统，发现公司其中一台服务器的磁盘快慢，随即上去看了下，发现 <code>/var/lib/docker</code> 这个目录特别大。由上述原因，我们都知道，在 <code>/var/lib/docker</code> 中存储的都是相关于容器的存储，所以也不能随便的将其删除掉。</li><li>那就准备迁移 <code>docker</code> 的存储目录吧，或者对 <code>/var</code> 设备进行扩容来达到相同的目的。更多关于 <code>dockerd</code> 的详细参数，请点击查看 <a href="https://docs.docker.com/engine/reference/commandline/dockerd/" target="_blank" rel="noopener"><strong>官方文档</strong></a> 地址。</li><li>但是需要注意的一点就是，尽量不要用软链， 因为一些 <code>docker</code> 容器编排系统不支持这样做，比如我们所熟知的 <code>k8s</code> 就在内。</li></ul><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发现容器启动不了了</span></span><br><span class="line">ERROR：cannot  create temporary directory!</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统存储情况</span></span><br><span class="line">$ du -h --max-depth=1</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法 1] 添加软链接</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.停止docker服务</span></span><br><span class="line">$ sudo systemctl stop docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.开始迁移目录</span></span><br><span class="line">$ sudo mv /var/lib/docker /data/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.添加软链接</span></span><br><span class="line">$ sudo ln -s /data/docker /var/lib/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.启动docker服务</span></span><br><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法 2] 改动 docker 配置文件</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [方式一] 改动docker启动配置文件</span></span><br><span class="line">$ sudo vim /lib/systemd/system/docker.service</span><br><span class="line">ExecStart=/usr/bin/dockerd --graph=/data/docker/</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [方式二] 改动docker启动配置文件</span></span><br><span class="line">$ sudo vim /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"live-restore"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"graph"</span>: [ <span class="string">"/data/docker/"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[操作注意事项]</strong> 在迁移 <code>docker</code> 目录的时候注意使用的命令，要么使用 <code>mv</code> 命令直接移动，要么使用 <code>cp</code> 命令复制文件，但是需要注意同时复制文件权限和对应属性，不然在使用的时候可能会存在权限问题。如果容器中，也是使用 <code>root</code> 用户，则不会存在该问题，但是也是需要按照正确的操作来迁移目录。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用mv命令</span></span><br><span class="line">$ sudo mv /var/lib/docker /data/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用cp命令</span></span><br><span class="line">$ sudo cp -arv /data/docker /data2/docker</span><br></pre></td></tr></table></figure><ul><li>下图中，就是因为启动的容器使用的是普通用户运行进程的，且在运行当中需要使用 <code>/tmp</code> 目录，结果提示没有权限。在我们导入容器镜像的时候，其实是会将容器启动时需要的各个目录的权限和属性都赋予了。如果我们直接是 <code>cp</code> 命令单纯复制文件内容的话，就会出现属性不一致的情况，同时还会有一定的安全问题。</li></ul><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-3-20220329161818563-2022-03-29-j0jRk4.png" alt="Docker迁移存储目录"></p><h2><span id="docker-设备空间不足">Docker 设备空间不足</span></h2><blockquote><p><a href="https://stackoverflow.com/questions/50140939/increase-docker-container-size-from-default-10gb-on-rhel7/52971594#52971594" target="_blank" rel="noopener"><strong>Increase Docker container size from default 10GB on rhel7.</strong></a></p></blockquote><ul><li><strong>[问题起因一]</strong> 容器在导入或者启动的时候，如果提示磁盘空间不足的，那么多半是真的因为物理磁盘空间真的有问题导致的。如下所示，我们可以看到 <code>/</code> 分区确实满了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看物理磁盘空间</span></span><br><span class="line">$ df -Th</span><br><span class="line">Filesystem    Size    Used    Avail    Use%    Mounted on</span><br><span class="line">/dev/vda1      40G     40G       0G    100%    /</span><br><span class="line">tmpfs         7.8G       0     7.8G      0%    /dev/shm</span><br><span class="line">/dev/vdb1     493G    289G     179G     62%    /mnt</span><br></pre></td></tr></table></figure><ul><li>如果发现真的是物理磁盘空间满了的话，就需要查看到底是什么占据了如此大的空间，导致因为容器没有空间无法启动。其中，<code>docker</code> 自带的命令就是一个很好的能够帮助我们发现问题的工具。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看基本信息</span></span><br><span class="line"><span class="comment"># 硬件驱动使用的是devicemapper，空间池为docker-252</span></span><br><span class="line"><span class="comment"># 磁盘可用容量仅剩16.78MB，可用供我们使用</span></span><br><span class="line">$ docker info</span><br><span class="line">Containers: 1</span><br><span class="line">Images: 28</span><br><span class="line">Storage Driver: devicemapper</span><br><span class="line"> Pool Name: docker-252:1-787932-pool</span><br><span class="line"> Pool Blocksize: 65.54 kB</span><br><span class="line"> Backing Filesystem: extfs</span><br><span class="line"> Data file: /dev/loop0</span><br><span class="line"> Metadata file: /dev/loop1</span><br><span class="line"> Data Space Used: 1.225 GB</span><br><span class="line"> Data Space Total: 107.4 GB</span><br><span class="line"> Data Space Available: 16.78 MB</span><br><span class="line"> Metadata Space Used: 2.073 MB</span><br><span class="line"> Metadata Space Total: 2.147 GB</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 通过查看信息，我们知道正是因为 <code>docker</code> 可用的磁盘空间不足，所以导致启动的时候没有足够的空间进行加载启动镜像。解决的方法也很简单，第一就是清理无效数据文件释放磁盘空间(<strong>清除日志</strong>)，第二就是修改 <code>docker</code> 数据的存放路径(<strong>大分区</strong>)。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示哪些容器目录具有最大的日志文件</span></span><br><span class="line">$ du -d1 -h /var/lib/docker/containers | sort -h</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清除您选择的容器日志文件的内容</span></span><br><span class="line">$ cat /dev/null &gt; /var/lib/docker/containers/container_id/container_log_name</span><br></pre></td></tr></table></figure><ul><li><strong>[问题起因二]</strong> 显然我遇到的不是上一种情况，而是在启动容器的时候，容器启动之后不久就显示是 <code>unhealthy</code> 的状态，通过如下日志发现，原来是复制配置文件启动的时候，提示磁盘空间不足。</li><li>后面发现是因为 <code>CentOS7</code> 的系统使用的 <code>docker</code> 容器默认的创建大小就是 <code>10G</code> 而已，然而我们使用的容器却超过了这个限制，导致无法启动时提示空间不足。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2019-08-16 11:11:15,816 INFO spawned: <span class="string">'app-demo'</span> with pid 835</span><br><span class="line">2019-08-16 11:11:16,268 INFO exited: app (<span class="built_in">exit</span> status 1; not expected)</span><br><span class="line">2019-08-16 11:11:17,270 INFO gave up: app entered FATAL state, too many start retries too quickly</span><br><span class="line">cp: cannot create regular file <span class="string">'/etc/supervisor/conf.d/grpc-app-demo.conf'</span>: No space left on device</span><br><span class="line">cp: cannot create regular file <span class="string">'/etc/supervisor/conf.d/grpc-app-demo.conf'</span>: No space left on device</span><br><span class="line">cp: cannot create regular file <span class="string">'/etc/supervisor/conf.d/grpc-app-demo.conf'</span>: No space left on device</span><br><span class="line">cp: cannot create regular file <span class="string">'/etc/supervisor/conf.d/grpc-app-demo.conf'</span>: No space left on device</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法 1] 改动 docker 启动配置文件</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/docker/daemon.json</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"live-restore"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"storage-opt"</span>: [ <span class="string">"dm.basesize=20G"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法 2] 改动 systemctl 的 docker 启动文件</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.stop the docker service</span></span><br><span class="line">$ sudo systemctl stop docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.rm exised container</span></span><br><span class="line">$ sudo rm -rf /var/lib/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.edit your docker service file</span></span><br><span class="line">$ sudo vim /usr/lib/systemd/system/docker.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.find the execution line</span></span><br><span class="line">ExecStart=/usr/bin/dockerd</span><br><span class="line">and change it to:</span><br><span class="line">ExecStart=/usr/bin/dockerd --storage-opt dm.basesize=20G</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.start docker service again</span></span><br><span class="line">$ sudo systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.reload daemon</span></span><br><span class="line">$ sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure><ul><li><strong>[问题起因三]</strong> 还有一种情况也会让容器无法启动，并提示磁盘空间不足，但是使用命令查看发现并不是因为物理磁盘真的不足导致的。而是，因为对于分区的 <code>inode</code> 节点数满了导致的。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 报错信息</span></span><br><span class="line">No space left on device</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 因为 <code>ext3</code> 文件系统使用 <code>inode table</code> 存储 <code>inode</code> 信息，而 <code>xfs</code> 文件系统使用 <code>B+ tree</code> 来进行存储。考虑到性能问题，默认情况下这个 <code>B+ tree</code> 只会使用前 <code>1TB</code> 空间，当这 <code>1TB</code> 空间被写满后，就会导致无法写入 <code>inode</code> 信息，报磁盘空间不足的错误。我们可以在 <code>mount</code> 时，指定 <code>inode64</code> 即可将这个 <code>B+ tree</code> 使用的空间扩展到整个文件系统。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看系统的inode节点使用情况</span></span><br><span class="line">$ sudo df -i</span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试重新挂载</span></span><br><span class="line">$ sudo mount -o remount -o noatime,nodiratime,inode64,nobarrier /dev/vda1</span><br></pre></td></tr></table></figure><ul><li><strong>[补充知识]</strong> 文件储存在硬盘上，硬盘的最小存储单位叫做 <strong>扇区</strong>(<code>Sector</code>)。每个扇区储存 <code>512</code> 字节(相当于<code>0.5KB</code>)。操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个<strong>块</strong>(<code>block</code>)。这种由多个扇区组成的<strong>块</strong>，是文件存取的最小单位。<strong>块</strong>的大小，最常见的是<code>4KB</code>，即连续八个 <code>sector</code> 组成一个 <code>block</code> 块。文件数据都储存在<strong>块</strong>中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做<strong>索引节点</strong>(<code>inode</code>)。每一个文件都有对应的 <code>inode</code>，里面包含了除了文件名以外的所有文件信息。</li><li><code>inode</code> 也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是 <code>inode</code> 区(<code>inode table</code>)，存放 <code>inode</code> 所包含的信息。每个 <code>inode</code> 节点的大小，一般是 <code>128</code> 字节或 <code>256</code> 字节。<code>inode</code> 节点的总数，在格式化时就给定，一般是每<code>1KB</code>或每<code>2KB</code>就设置一个 <code>inode</code> 节点。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个节点信息的内容</span></span><br><span class="line">$ <span class="built_in">stat</span> check_port_live.sh</span><br><span class="line">  File: check_port_live.sh</span><br><span class="line">  Size: 225           Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 822h/2082d    Inode: 99621663    Links: 1</span><br><span class="line">Access: (0755/-rwxr-xr-x)  Uid: ( 1006/  escape)   Gid: ( 1006/  escape)</span><br><span class="line">Access: 2019-07-29 14:59:59.498076903 +0800</span><br><span class="line">Modify: 2019-07-29 14:59:59.498076903 +0800</span><br><span class="line">Change: 2019-07-29 23:20:27.834866649 +0800</span><br><span class="line"> Birth: -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 磁盘的inode使用情况</span></span><br><span class="line">$ df -i</span><br><span class="line">Filesystem                 Inodes   IUsed     IFree IUse% Mounted on</span><br><span class="line">udev                     16478355     801  16477554    1% /dev</span><br><span class="line">tmpfs                    16487639    2521  16485118    1% /run</span><br><span class="line">/dev/sdc2               244162560 4788436 239374124    2% /</span><br><span class="line">tmpfs                    16487639       5  16487634    1% /dev/shm</span><br></pre></td></tr></table></figure><h2><span id="docker-缺共享链接库">Docker 缺共享链接库</span></h2><blockquote><p><strong>Docker 命令需要对/tmp 目录下面有访问权限</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 给系统安装完 <code>compose</code> 之后，查看版本的时候，提示缺少一个名为 <code>libz.so.1</code> 的共享链接库。第一反应就是，是不是系统少安装那个软件包导致的。随即，搜索了一下，将相关的依赖包都给安装了，却还是提示同样的问题。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提示错误信息</span></span><br><span class="line">$ docker-compose --version</span><br><span class="line">error <span class="keyword">while</span> loading shared libraries: libz.so.1: failed to map segment from shared object: Operation not permitted</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 后来发现，是因为系统中 <code>docker</code> 没有对 <code>/tmp</code> 目录的访问权限导致，需要重新将其挂载一次，就可以解决了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新挂载</span></span><br><span class="line">$ sudo mount /tmp -o remount,<span class="built_in">exec</span></span><br></pre></td></tr></table></figure><h2><span id="docker-容器文件损坏">Docker 容器文件损坏</span></h2><blockquote><p><strong>对 dockerd 的配置有可能会影响到系统稳定</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 容器文件损坏，经常会导致容器无法操作。正常的 <code>docker</code> 命令已经无法操控这台容器了，无法关闭、重启、删除。正巧，前天就需要这个的问题，主要的原因是因为重新对 <code>docker</code> 的默认容器进行了重新的分配限制导致的。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 操作容器遇到类似的错误</span></span><br><span class="line">b<span class="string">'devicemapper: Error running deviceCreate (CreateSnapDeviceRaw) dm_task_run failed'</span></span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 可以通过以下操作将容器删除/重建。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.关闭docker</span></span><br><span class="line">$ sudo systemctl stop docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.删除容器文件</span></span><br><span class="line">$ sudo rm -rf /var/lib/docker/containers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.重新整理容器元数据</span></span><br><span class="line">$ sudo thin_check /var/lib/docker/devicemapper/devicemapper/metadata</span><br><span class="line">$ sudo thin_check --clear-needs-check-flag /var/lib/docker/devicemapper/devicemapper/metadata</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.重启docker</span></span><br><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><h2><span id="docker-容器优雅重启">Docker 容器优雅重启</span></h2><blockquote><p><strong>不停止服务器上面运行的容器，重启 dockerd 服务是多么好的一件事</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 默认情况下，当 <code>Docker</code> 守护程序终止时，它会关闭正在运行的容器。从 <code>Docker-ce 1.12</code> 开始，可以在配置文件中添加 <code>live-restore</code> 参数，以便在守护程序变得不可用时容器保持运行。需要注意的是 <code>Windows</code> 平台暂时还是不支持该参数的配置。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Keep containers alive during daemon downtime</span></span><br><span class="line">$ sudo vim /etc/docker/daemon.yaml</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"live-restore"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在守护进程停机期间保持容器存活</span></span><br><span class="line">$ sudo dockerd --live-restore</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只能使用reload重载</span></span><br><span class="line"><span class="comment"># 相当于发送SIGHUP信号量给dockerd守护进程</span></span><br><span class="line">$ sudo systemctl reload docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是对应网络的设置需要restart才能生效</span></span><br><span class="line">$ sudo systemctl restart docker</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 可以通过以下操作将容器删除/重建。</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># /etc/docker/daemon.yaml</span><br><span class="line">&#123;</span><br><span class="line">    "registry-mirrors": ["https://vec0xydj.mirror.aliyuncs.com"],  # 配置获取官方镜像的仓库地址</span><br><span class="line">    "experimental": true,  # 启用实验功能</span><br><span class="line">    "default-runtime": "nvidia",  # 容器的默认OCI运行时(默认为runc)</span><br><span class="line">    "live-restore": true,  # 重启dockerd服务的时候容易不终止</span><br><span class="line">    "runtimes": &#123;  # 配置容器运行时</span><br><span class="line">        "nvidia": &#123;</span><br><span class="line">            "path": "/usr/bin/nvidia-container-runtime",</span><br><span class="line">            "runtimeArgs": []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    "default-address-pools": [  # 配置容器使用的子网地址池</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"scope"</span>: <span class="string">"local"</span>,</span><br><span class="line">            <span class="attr">"base"</span>:<span class="string">"172.17.0.0/12"</span>,</span><br><span class="line">            <span class="attr">"size"</span>:<span class="number">24</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"default-address-pools"</span> : [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"base"</span> : <span class="string">"172.240.0.0/16"</span>,</span><br><span class="line">      <span class="string">"size"</span> : 24</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="docker-容器无法删除">Docker 容器无法删除</span></h2><blockquote><p><strong>找不到对应容器进程是最吓人的</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 今天遇到 <code>docker</code> 容器无法停止/终止/删除，以为这个容器可能又出现了 <code>dockerd</code> 守护进程托管的情况，但是通过 <code>ps -ef &lt;container id&gt;</code> 无法查到对应的运行进程。哎，后来开始开始查 <code>supervisor</code> 以及 <code>Dockerfile</code> 中的进程，都没有。这种情况的可能原因是容器启动之后，主机因任何原因重新启动并且没有优雅地终止容器。剩下的文件现在阻止你重新生成旧名称的新容器，因为系统认为旧容器仍然存在。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除容器</span></span><br><span class="line">$ sudo docker rm -f f8e8c3..</span><br><span class="line">Error response from daemon: Conflict, cannot remove the default name of the container</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 找到 <code>/var/lib/docker/containers/</code> 下的对应容器的文件夹，将其删除，然后重启一下 <code>dockerd</code> 即可。我们会发现，之前无法删除的容器没有了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除容器文件</span></span><br><span class="line">$ sudo rm -rf /var/lib/docker/containers/f8e8c3...65720</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">$ sudo systemctl restart docker.service</span><br></pre></td></tr></table></figure><h2><span id="docker-容器中文异常">Docker 容器中文异常</span></h2><blockquote><p><strong>容器存在问题话，记得优先在官网查询</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 今天登陆之前部署的 <code>MySQL</code> 数据库查询，发现使用 <code>SQL</code> 语句无法查询中文字段，即使直接输入中文都没有办法显示。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看容器支持的字符集</span></span><br><span class="line">root@b18f56aa1e15:<span class="comment"># locale -a</span></span><br><span class="line">C</span><br><span class="line">C.UTF-8</span><br><span class="line">POSIX</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> <code>Docker</code> 部署的 <code>MySQL</code> 系统使用的是 <code>POSIX</code> 字符集。然而 <code>POSIX</code> 字符集是不支持中文的，而 <code>C.UTF-8</code> 是支持中文的只要把系统中的环境 <code>LANG</code> 改为 <code>&quot;C.UTF-8&quot;</code> 格式即可解决问题。同理，在 <code>K8S</code> 进入 <code>pod</code> 不能输入中文也可用此方法解决。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时解决</span></span><br><span class="line">docker <span class="built_in">exec</span> -it some-mysql env LANG=C.UTF-8 /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 永久解决</span></span><br><span class="line">docker run --name some-mysql \</span><br><span class="line">    -e MYSQL_ROOT_PASSWORD=my-secret-pw \</span><br><span class="line">    -d mysql:tag --character-set-server=utf8mb4 \</span><br><span class="line">    --collation-server=utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure><h2><span id="docker-容器网络互通">Docker 容器网络互通</span></h2><blockquote><p><strong>了解 Docker 的四种网络模型</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 在本机部署 <code>Nginx</code> 容器想代理本机启动的 <code>Python</code> 后端服务程序，但是对代码服务如下的配置，结果访问的时候一直提示 <code>502</code> 错误。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Nginx服务</span></span><br><span class="line">$ docker run -d -p 80:80 <span class="variable">$PWD</span>:/etc/nginx nginx</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    ...</span><br><span class="line">    location &#x2F;api &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;localhost:8080</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 后面发现是因为 <code>nginx.conf</code> 配置文件中的 <code>localhost</code> 配置的有问题，由于 <code>Nginx</code> 是在容器中运行，所以 <code>localhost</code> 为容器中的 <code>localhost</code>，而非本机的 <code>localhost</code>，所以导致无法访问。</li><li>可以将 <code>nginx.conf</code> 中的 <code>localhost</code> 改为宿主机的 <code>IP</code> 地址，就可以解决 <code>502</code> 的错误。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询宿主机IP地址 =&gt; 172.17.0.1</span></span><br><span class="line">$ ip addr show docker0</span><br><span class="line">docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:d5:4c:f2:1e brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:d5ff:fe4c:f21e/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    ...</span><br><span class="line">    location &#x2F;api &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;172.17.0.1:8080</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>当容器使用 <code>host</code> 网络时，容器与宿主共用网络，这样就能在容器中访问宿主机网络，那么容器的 <code>localhost</code> 就是宿主机的 <code>localhost</code> 了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 服务的启动方式有所改变(没有映射出来端口)</span></span><br><span class="line"><span class="comment"># 因为本身与宿主机共用了网络，宿主机暴露端口等同于容器中暴露端口</span></span><br><span class="line">$ docker run -d -p 80:80 --network=host <span class="variable">$PWD</span>:/etc/nginx nginxx</span><br></pre></td></tr></table></figure><h2><span id="docker-容器总线错误">Docker 容器总线错误</span></h2><blockquote><p><strong>总线错误看到的时候还是挺吓人了</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 在 <code>docker</code> 容器中运行程序的时候，提示 <code>bus error</code> 错误。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 总线报错</span></span><br><span class="line">$ inv app.user_op --name=zhangsan</span><br><span class="line">Bus error (core dumped)</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 原因是在 <code>docker</code> 运行的时候，<code>shm</code> 分区设置太小导致 <code>share memory</code> 不够。不设置 <code>--shm-size</code> 参数时，<code>docker</code> 给容器默认分配的 <code>shm</code> 大小为 <code>64M</code>，导致程序启动时不足。具体原因还是因为安装 <code>pytorch</code> 包导致了，多进程跑任务的时候，<code>docker</code> 容器分配的共享内存太小，导致 <code>torch</code> 要在 <code>tmpfs</code> 上面放模型数据用于子线程的 <a href="https://github.com/pytorch/pytorch/issues/2244" target="_blank" rel="noopener">共享不足</a>，就出现报错了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 问题原因</span></span><br><span class="line">root@18...35:/opt/app<span class="comment"># df -TH</span></span><br><span class="line">Filesystem     Type     Size  Used Avail Use% Mounted on</span><br><span class="line">overlay        overlay  2.0T  221G  1.4T   3% /</span><br><span class="line">tmpfs          tmpfs     68M     0   68M   0% /dev</span><br><span class="line">shm            tmpfs     68M   41k   68M   1% /dev/shm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动docker的时候加上--shm-size参数(单位为b,k,m或g)</span></span><br><span class="line">$ docker run -it --rm --shm-size=200m pytorch/pytorch:latest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在docker-compose添加对应配置</span></span><br><span class="line">$ shm_size: <span class="string">'2gb'</span></span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 还有一种情况就是容器内的磁盘空间不足，也会导致 <code>bus error</code> 这样的报错，所以如果出现了，清除多余文件和目录或者分配一个大的磁盘空间，就可以解决了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 磁盘空间不足</span></span><br><span class="line">$ df -Th</span><br><span class="line">Filesystem     Type     Size  Used Avail Use% Mounted on</span><br><span class="line">overlay        overlay    1T    1T    0G 100% /</span><br><span class="line">shm            tmpfs     64M   24K   64M   1% /dev/shm</span><br></pre></td></tr></table></figure><h2><span id="docker-nfs-挂载报错">Docker NFS 挂载报错</span></h2><blockquote><p><strong>NFS 挂载之后容器程序使用异常为内核版本太低导致的</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 我们将服务部署到 <code>openshift</code> 集群中，启动服务调用资源文件的时候，报错信息如下所示。从报错信息中，得知是在 <code>Python3</code> 程序执行 <code>read_file()</code> 读取文件的内容，给文件加锁的时候报错了。但是奇怪的是，本地调试的时候发现服务都是可以正常运行的，文件加锁也是没问题的。后来发现，在 <code>openshift</code> 集群中使用的是 <code>NFS</code> 挂载的共享磁盘。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 报错信息</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">    ......</span><br><span class="line">    File <span class="string">"xxx/utils/storage.py"</span>, line 34, <span class="keyword">in</span> xxx.utils.storage.LocalStorage.read_file</span><br><span class="line">OSError: [Errno 9] Bad file descriptor</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 文件加锁代码</span><br><span class="line">...</span><br><span class="line">    with open(self.mount(path), &#39;rb&#39;) as fileobj:</span><br><span class="line">        fcntl.flock(fileobj, fcntl.LOCK_EX)</span><br><span class="line">        data &#x3D; fileobj.read()</span><br><span class="line">    return data</span><br><span class="line">...</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 从下面的信息得知，要在 <code>Linux</code> 中使用 <code>flock()</code> 的话，就需要升级内核版本到 <code>2.6.11+</code> 才行。后来才发现，这实际上是由 <code>RedHat</code> 內核中的一个错误引起的，并在 <code>kernel-3.10.0-693.18.1.el7</code> 版本中得到修复。 所以对于 <code>NFSv3</code> 和 <code>NFSv4</code> 服务而已，就需要升级 <code>Linux</code> 内核版本才能够解决这个问题。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://t.codebug.vip/questions-930901.htm</span></span><br><span class="line">$ In Linux kernels up to 2.6.11, flock() does not lock files over NFS (i.e.,</span><br><span class="line">the scope of locks was limited to the <span class="built_in">local</span> system). [...] Since Linux 2.6.12,</span><br><span class="line">NFS clients support flock() locks by emulating them as byte-range locks on the entire file.</span><br></pre></td></tr></table></figure><h2><span id="docker-使用默认网段">Docker 使用默认网段</span></h2><blockquote><p><strong>启动的容器网络无法相互通信，很是奇怪！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 我们在使用 <code>Docker</code> 启动服务的时候，发现有时候服务之前可以相互连通，而有时启动的多个服务之前却出现了无法访问的情况。究其原因，发现原来是因为使用的内部私有地址网段不一致导致的。有的服务启动到了 <code>172.17 - 172.31</code> 的网段，有的服务跑到了 <code>192.169.0 - 192.168.224</code> 的网段，这样导致服务启动之后出现无法访问的情况(默认情况下，有下面这个两个网段可供其使用)。</li></ul><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-2-2022-03-29-DlFT7v.png" alt="Docker默认使用网段"></p><ul><li><strong>[解决方法]</strong> 上述问题的处理方式，就是手动指定 <code>Docker</code> 服务的启动网段，二选一就可以了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看docker容器配置</span></span><br><span class="line">$ cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"registry-mirrors"</span>: [<span class="string">"https://vec0xydj.mirror.aliyuncs.com"</span>],</span><br><span class="line">    <span class="string">"default-address-pools"</span>:[&#123;<span class="string">"base"</span>:<span class="string">"172.17.0.0/12"</span>, <span class="string">"size"</span>:24&#125;],</span><br><span class="line">    <span class="string">"experimental"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"default-runtime"</span>: <span class="string">"nvidia"</span>,</span><br><span class="line">    <span class="string">"live-restore"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"runtimes"</span>: &#123;</span><br><span class="line">        <span class="string">"nvidia"</span>: &#123;</span><br><span class="line">            <span class="string">"path"</span>: <span class="string">"/usr/bin/nvidia-container-runtime"</span>,</span><br><span class="line">            <span class="string">"runtimeArgs"</span>: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="docker-服务启动串台">Docker 服务启动串台</span></h2><blockquote><p><strong>使用 docker-compose 命令各自启动两组服务，发现服务会串台！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 在两个不同名称的目录目录下面，使用 <code>docker-compose</code> 来启动服务，发现当 <code>A</code> 组服务启动完毕之后，再启动 <code>B</code> 组服务的时候，发现 <code>A</code> 组当中对应的一部分服务又重新启动了一次，这就非常奇怪了！因为这个问题的存在会导致，<code>A</code> 组服务和 <code>B</code> 组服务无法同时启动。之前还以为是工具的 <code>Bug</code>，后来请教了 <strong>“上峰”</strong>，才知道了原因，恍然大悟。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 服务目录结构如下所示</span></span><br><span class="line">A: /data1/app/docker-compose.yml</span><br><span class="line">B: /data2/app/docker-compose.yml</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 发现 <code>A</code> 和 <code>B</code> 两组服务会串台的原因，原来是 <code>docker-compose</code> 会给启动的容器加 <code>label</code> 标签，然后根据这些 <code>label</code> 标签来识别和判断对应的容器服务是由谁启动的、谁来管理的，等等。而这里，我们需要关注的 <code>label</code> 变量是 <code>com.docker.compose.project</code>，其对应的值是使用启动配置文件的目录的最底层子目录名称，即上面的 <code>app</code> 就是对应的值。我们可以发现， <code>A</code> 和 <code>B</code> 两组服务对应的值都是 <code>app</code>，所以启动的时候被认为是同一个，这就出现了上述的问题。如果需要深入了解的话，可以去看对应源代码。</li></ul><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-4-20220329161418940-2022-03-29-Aqsd14.png" alt="Docker服务启动串台"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以将目录结构调整为如下所示</span></span><br><span class="line">A: /data/app1/docker-compose.yml</span><br><span class="line">B: /data/app2/docker-compose.yml</span><br><span class="line"></span><br><span class="line">A: /data1/app-old/docker-compose.yml</span><br><span class="line">B: /data2/app-new/docker-compose.yml</span><br></pre></td></tr></table></figure><ul><li>或者使用 <code>docker-compose</code> 命令提供的参数 <code>-p</code> 手动指定标签，来规避该问题的发生。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定项目项目名称</span></span><br><span class="line">$ docker-compose -f ./docker-compose.yml -p app1 up -d</span><br></pre></td></tr></table></figure><h2><span id="docker-命令调用报错">Docker 命令调用报错</span></h2><blockquote><p><strong>在编写脚本的时候常常会执行 docker 相关的命令，但是需要注意使用细节！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> <code>CI</code> 更新环境执行了一个脚本，但是脚本执行过程中报错了，如下所示。通过对应的输出信息，可以看到提示说正在执行的设备不是一个 <code>tty</code>。</li></ul><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-5-2022-03-29-3hwPWX.png" alt="Docker命令调用报错"></p><ul><li>随即，查看了脚本发现报错地方是执行了一个 <code>exec</code> 的 <code>docker</code> 命令，大致如下所示。很奇怪的是，手动执行或直接调脚本的时候，怎么都是没有问题的，但是等到 <code>CI</code> 调用的时候怎么都是有问题。后来好好看下，下面这个命令，注意到 <code>-it</code> 这个参数了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 脚本调用docker命令</span></span><br><span class="line">docker <span class="built_in">exec</span> -it &lt;container_name&gt; psql -Upostgres ......</span><br></pre></td></tr></table></figure><ul><li>我们可以一起看下 <code>exec</code> 命令的这两个参数，自然就差不多理解了。</li></ul><table><thead><tr><th style="text-align:left">编号</th><th style="text-align:left">参数</th><th style="text-align:left">解释说明</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><code>-i</code>/<code>-interactive</code></td><td style="text-align:left">即使没有附加也保持 STDIN 打开；如果你需要执行命令则需要开启这个选项</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><code>-t</code>/<code>–tty</code></td><td style="text-align:left">分配一个伪终端进行执行；一个连接用户的终端与容器 stdin 和 stdout 的桥梁</td></tr></tbody></table><ul><li><strong>[解决方法]</strong> <code>docker exec</code> 的参数 <code>-t</code> 是指 <code>Allocate a pseudo-TTY</code> 的意思，而 <code>CI</code> 在执行 <code>job</code> 的时候并不是在 <code>TTY</code> 终端中执行，所以 <code>-t</code> 这个参数会报错。同时在 『<a href="https://stackoverflow.com/questions/43099116/error-the-input-device-is-not-a-tty" target="_blank" rel="noopener">stackoverflow</a>』也有人给出原因，可以自行查看。</li></ul><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-6-20220329162948314-2022-03-29-ECCkYH.png" alt="Docker命令调用报错"></p><h2><span id="docker-定时任务异常">Docker 定时任务异常</span></h2><blockquote><p><strong>在 Crontab 定时任务中也存在 Docker 命令执行异常的情况！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 今天发现了一个问题，就是在备份 <code>Mysql</code> 数据库的时候，使用 <code>docker</code> 容器进行备份，然后使用 <code>Crontab</code> 定时任务来触发备份。但是发现备份的 <code>MySQL</code> 数据库居然是空的，但是手动执行对应命令切是好的，很奇怪。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Crontab定时任务</span></span><br><span class="line">0 */6 * * * \</span><br><span class="line">    docker <span class="built_in">exec</span> -it &lt;container_name&gt; sh -c \</span><br><span class="line">        <span class="string">'exec mysqldump --all-databases -uroot -ppassword ......'</span></span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 后来发现是因为执行的 <code>docker</code> 命令多个 <code>-i</code> 导致的。因为 <code>Crontab</code> 命令执行的时候，并不是交互式的，所以需要把这个去掉才可以。总结就是，如果你需要回显的话则需要 <code>-t</code> 选项，如果需要交互式会话则需要 <code>-i</code> 选项。</li></ul><table><thead><tr><th style="text-align:left">编号</th><th style="text-align:left">参数</th><th style="text-align:left">解释说明</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><code>-i</code>/<code>-interactive</code></td><td style="text-align:left">即使没有附加也保持 STDIN 打开；如果你需要执行命令则需要开启这个选项</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><code>-t</code>/<code>–tty</code></td><td style="text-align:left">分配一个伪终端进行执行；一个连接用户的终端与容器 stdin 和 stdout 的桥梁</td></tr></tbody></table><h2><span id="docker-变量使用引号">Docker 变量使用引号</span></h2><blockquote><p><strong>compose 里边环境变量带不带引号的问题！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 使用过 <code>compose</code> 的朋友可能都遇到过，在编写启服务启动配置文件的时候，添加环境变量时到底是使用单引号、双引号还是不使用引号的问题？时间长了，我们可能会将三者混用，认为其效果是一样的。但是后来，发现的坑越来越多，才发现其越来越隐晦。</li><li>反正我是遇到过很多问题，都是因为添加引号导致的服务启动异常的，后来得出的结论就是一律不使引号。裸奔，体验前所未有的爽快！直到现在看到了 <code>Github</code> 中对应的 <a href="https://github.com/docker/compose/issues/2854" target="_blank" rel="noopener">issus</a> 之后，才终于破案了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Compose中进行引用TEST_VAR变量，无法找到</span></span><br><span class="line">TEST_VAR=<span class="string">"test"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在Compose中进行引用TEST_VAR变量，可以找到</span></span><br><span class="line">TEST_VAR=<span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 后来发现docker本身其实已经正确地处理了引号的使用</span></span><br><span class="line">docker run -it --rm -e TEST_VAR=<span class="string">"test"</span> <span class="built_in">test</span>:latest</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 得到的结论就是，因为 <code>Compose</code> 解析 <code>yaml</code> 配置文件，发现引号也进行了解释包装。这就导致原本的 <code>TEST_VAR=&quot;test&quot;</code> 被解析成了 <code>'TEST_VAR=&quot;test&quot;'</code>，所以我们在引用的时候就无法获取到对应的值。现在解决方法就是，不管是我们直接在配置文件添加环境变量或者使用 <code>env_file</code> 配置文件，能不使用引号就不适用引号。</li><li>需要注意的是环境变量配置的是日志格式的话(<code>2022-01-01</code>)，如果使用的是 <code>Python</code> 的 <code>yaml.load</code> 模块的话，会被当做是 <code>date</code> 类型的，这是如果希望保持原样信息的话，可以使用 <code>'</code>/<code>&quot;</code> 引起来将其变成字符串格式的。</li></ul><h2><span id="docker-删除镜像报错">Docker 删除镜像报错</span></h2><blockquote><p><strong>无法删除镜像，归根到底还是有地方用到了！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 清理服器磁盘空间的时候，删除某个镜像的时候提示如下信息。提示需要强制删除，但是发现及时执行了强制删除依旧没有效果。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除镜像</span></span><br><span class="line">$ docker rmi 3ccxxxx2e862</span><br><span class="line">Error response from daemon: conflict: unable to delete 3ccxxxx2e862 (cannot be forced) - image has dependent child images</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制删除</span></span><br><span class="line">$ dcoker rmi -f 3ccxxxx2e862</span><br><span class="line">Error response from daemon: conflict: unable to delete 3ccxxxx2e862 (cannot be forced) - image has dependent child images</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 后来才发现，出现这个原因主要是因为 <code>TAG</code>，即存在其他镜像引用了这个镜像。这里我们可以使用如下命令查看对应镜像文件的依赖关系，然后根据对应 <code>TAG</code> 来删除镜像。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询依赖 - image_id表示镜像名称</span></span><br><span class="line">$ docker image inspect --format=<span class="string">'&#123;&#123;.RepoTags&#125;&#125; &#123;&#123;.Id&#125;&#125; &#123;&#123;.Parent&#125;&#125;'</span> $(docker image ls -q --filter since=&lt;image_id&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据TAG删除镜像</span></span><br><span class="line">$ docker rmi -f c565xxxxc87f</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除悬空镜像</span></span><br><span class="line">$ docker rmi $(docker images --filter <span class="string">"dangling=true"</span> -q --no-trunc)</span><br></pre></td></tr></table></figure><h2><span id="docker-普通用户切换">Docker 普通用户切换</span></h2><blockquote><p><strong>切换 Docker 启动用户的话，还是需要注意下权限问题的！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 我们知道在 <code>Docker</code> 容器里面使用 <code>root</code> 用户的话，是不安全的，很容易出现越权的安全问题，所以一般情况下，我们都会使用普通用户来代替 <code>root</code> 进行服务的启动和管理的。今天给一个服务切换用户的时候，发现 <code>Nginx</code> 服务一直无法启动，提示如下权限问题。因为对应的配置文件也没有配置 <code>var</code> 相关的目录，无奈 🤷‍♀ ！️</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Nginx报错信息</span></span><br><span class="line">nginx: [alert] could not open error <span class="built_in">log</span> file: open() <span class="string">"/var/log/nginx/error.log"</span> failed (13: Permission denied)</span><br><span class="line">2020/11/12 15:25:47 [emerg] 23<span class="comment">#23: mkdir() "/var/cache/nginx/client_temp" failed (13: Permission denied)</span></span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 后来发现还是 <code>nginx.conf</code> 配置文件，配置的有问题，需要将 <code>Nginx</code> 服务启动时候需要的文件都配置到一个无权限的目录，即可解决。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">user  www-data;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">error_log  &#x2F;data&#x2F;logs&#x2F;master_error.log warn;</span><br><span class="line">pid        &#x2F;dev&#x2F;shm&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       &#x2F;etc&#x2F;nginx&#x2F;mime.types;</span><br><span class="line">    default_type  application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">    gzip               on;</span><br><span class="line">    sendfile           on;</span><br><span class="line">    tcp_nopush         on;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    client_body_temp_path  &#x2F;tmp&#x2F;client_body;</span><br><span class="line">    fastcgi_temp_path      &#x2F;tmp&#x2F;fastcgi_temp;</span><br><span class="line">    proxy_temp_path        &#x2F;tmp&#x2F;proxy_temp;</span><br><span class="line">    scgi_temp_path         &#x2F;tmp&#x2F;scgi_temp;</span><br><span class="line">    uwsgi_temp_path        &#x2F;tmp&#x2F;uwsgi_temp;</span><br><span class="line"></span><br><span class="line">    include &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;*.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="docker-绑定到-ipv6-上">Docker 绑定到 IPv6 上</span></h2><blockquote><p><strong>Docker 服务在启动的时候，将地址绑定到 IPv6 地址上面了，提示报错信息！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 物理机器更新了对应补丁之后，重启了服务，导致原本可以正常启动的 <code>docker-compose</code> 服务提示如下报错信息。不清楚是否修改了操作系统的相关配置，还是对应 <code>docker</code> 进行的其他方面的配置，比如修改 <code>/etc/docker/daemon.json</code> 或者 <code>docker</code> 的 <code>service</code> 启动文件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Docker的报错信息</span></span><br><span class="line">docker run -p 80:80 nginx:alpine succeeds. Previously, this was failing with Error \</span><br><span class="line">starting userland proxy: listen tcp6 [::]:80: socket: address family not supported by protocol.</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 通过如上所示的报错信息，可以看到服务的启动端口绑定到了 <code>tcp6</code> 上面了，但是对应的 <code>socket</code> 发现系统本身并不支持。这时，我们一看下对应的操作系统 <code>ipv6</code> 的设置，发现系统禁用了，所有的 <code>ipv6</code> 地址。需要了解的朋友，可以参考 <a href="https://github.com/moby/moby/pull/42322" target="_blank" rel="noopener">fix port forwarding with ipv6.disable=1</a> 和 <a href="https://github.com/moby/moby/issues/42288" target="_blank" rel="noopener">cannot start if ipv6 is disabled on host</a> 这两个 <code>issus</code> 来获取更多信息。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 操作系统配置</span></span><br><span class="line">$ cat /etc/sysctl.conf | grep ipv6</span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br></pre></td></tr></table></figure><ul><li><strong>[方法一]</strong> 最为简单的解决方法，就是在 <code>docker-compose.yml</code> 文件中，手动指定将对应服务的端口绑定到 <code>ipv4</code> 上面，如下所示。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">version: &quot;3&quot;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    restart: on-failure</span><br><span class="line">    container_name: app_web</span><br><span class="line">    image: app:latest</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;0.0.0.0:80:80&#x2F;tcp&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - &quot;.&#x2F;app_web:&#x2F;data&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - app_network</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  app_network:</span><br></pre></td></tr></table></figure><ul><li><strong>[方法二]</strong> 或者修改 <code>/etc/docker/daemon.json</code> 文件，在配置中，阻止 <code>Docker</code> 错误的将端口映射到 <code>IPv6</code> 上，即可达到同样的效果，且不用再次修改多个服务的启动配置文件了。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 修改配置</span><br><span class="line">$ vim &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;ipv6&quot;: false,</span><br><span class="line">  &quot;fixed-cidr-v6&quot;: &quot;2001:db8:1::&#x2F;64&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 重启服务</span><br><span class="line">$ systemctl reload docker</span><br></pre></td></tr></table></figure><ul><li><strong>[方法三]</strong> <code>Docker</code> 默认情况下会同时将端口映射于 <code>IPv4</code> 与 <code>IPv6</code> 两者上，而且有的时候会出现只绑定到了 <code>IPv6</code>，导致服务无法正常访问的情况。现在通用的始终还是 <code>IPv4</code> 地址，因此最简单的做法就是关闭 <code>IPv6</code> 地址。详细的配置，可以参考 <a href="https://github.com/moby/moby/issues/2174" target="_blank" rel="noopener">Port redirecting binding to IPv6 but not IPv4 interfaces</a> 这个 <code>issus</code> 地址。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改系统配置</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'1'</span> &gt; /proc/sys/net/ipv6/conf/lo/disable_ipv6</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'1'</span> &gt; /proc/sys/net/ipv6/conf/lo/disable_ipv6</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'1'</span> &gt; /proc/sys/net/ipv6/conf/all/disable_ipv6</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'1'</span> &gt; /proc/sys/net/ipv6/conf/default/disable_ipv6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启网络</span></span><br><span class="line">$ /etc/init.d/networking restart</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后检测是否已关闭IPv6</span></span><br><span class="line">ip addr show | grep net6</span><br></pre></td></tr></table></figure><h2><span id="docker-容器启动超时">Docker 容器启动超时</span></h2><blockquote><p><strong>Docker 服务在启动的时候，提示超时，被直接终止了！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 使用 <code>docker-compose</code> 启动容器的时候，等待了很久的时候(大约 <code>2-3</code> 分钟左右)，之后提示如下信息。通过阅读信息内容，可以看到是因为超时导致的，提示可以通过设置环境变量，加大超时的时间。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose up -d</span><br><span class="line">ERROR: <span class="keyword">for</span> xxx  UnixHTTPConnectionPool(host=<span class="string">'localhost'</span>, port=None): Read timed out. (<span class="built_in">read</span> timeout=70)</span><br><span class="line">ERROR: An HTTP request took too long to complete. Retry with --verbose to obtain debug information.</span><br><span class="line">If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 按照提示设置的环境变量之后，再次启动发现确实可以正常启动了，但是还是能够感觉到有些慢。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> COMPOSE_HTTP_TIMEOUT=500</span><br><span class="line"><span class="built_in">export</span> DOCKER_CLIENT_TIMEOUT=500</span><br></pre></td></tr></table></figure><ul><li>排除了下启动流程，因为容器启动有映射目录到容器里面且目录大小比较大，所以怀疑是因为 <code>i/o</code> 导致的。随即使用 <code>iotop</code> 命令查看服务器目前的 <code>i/o</code> 情况，发现存在很多个 <code>rg</code> 命令，且都处于 <code>100%</code> 左右。查了下，发现是 <code>vscode</code> 远程服务器启动的搜索目录结构的进程，西八，有些坑呀！</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo iotop</span><br><span class="line"> 4269 be/4 escape     15.64 K/s    0.00 B/s  0.00 % 98.36 % rg --files --hidden</span><br><span class="line"> 4270 be/4 escape     28.15 K/s    0.00 B/s  0.00 % 97.46 % rg --files --hidden</span><br><span class="line"> 4272 be/4 escape     31.27 K/s    0.00 B/s  0.00 % 97.39 % rg --files --hidden</span><br><span class="line"> 4276 be/4 escape     34.40 K/s    0.00 B/s  0.00 % 96.98 % rg --files --hidden</span><br></pre></td></tr></table></figure><h2><span id="docker-端口网络限制">Docker 端口网络限制</span></h2><blockquote><p><strong>如果发现服务都一切正常，但是无法无法访问的话，则多为网络问题！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 启用服务之后，登录跳转发现直接 <code>502</code> 报错了。排除了配置等相关原因都没有任何问题(做过相关测试)，这就非常奇怪了！</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 部署服务架构</span></span><br><span class="line">nginx(80) -&gt; web1(8080)</span><br><span class="line">          -&gt; web2(8081)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 报错信息如下所示</span></span><br><span class="line">nginx connect() failed (113: No route to host) <span class="keyword">while</span> connecting to upstream</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 根据错误信息可知，是因为没有路由到指定的 <code>host</code> 导致了，随即看了下防火墙是开着的，看了日志发现被过滤掉了，西八！问题找到了，现在需要做的就是，要么添加防火墙规则，要么关闭防火墙。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查开放的端口</span></span><br><span class="line">$ sudo firewall-cmd --permanent --zone=public --list-ports</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启需要路由的端口</span></span><br><span class="line">$ sudo firewall-cmd --permanent --zone=public --add-port=8080/tcp</span><br><span class="line">$ sudo firewall-cmd --permanent --zone=public --add-port=8081/tcp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置立即生效</span></span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭防火墙</span></span><br><span class="line">$ sudo systemctl stop firewalld.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用自启动</span></span><br><span class="line">$ sudo systemctl <span class="built_in">disable</span> firewalld.service</span><br></pre></td></tr></table></figure><h2><span id="docker-无法获取镜像">Docker 无法获取镜像</span></h2><blockquote><p><strong>新初始化的机器，无法获取私有仓库的镜像文件！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 机器初始化之后，使用如下命令登录私有 <code>docker</code> 仓库，发现提示无法获取对应镜像，但是在其他机器上面获取该镜像就可以执行成功，这就非常奇怪了！</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录私有仓库</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'123456'</span> | docker login -u escape --password-stdin docker.escapelife.site</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异常信息提示</span></span><br><span class="line">$ sudo docker pull docker.escapelife.site/app:0.10</span><br><span class="line">Error response from daemon: manifest <span class="keyword">for</span> docker.escapelife.site/app:0.10 not found: manifest unknown: manifest unknown</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 太坑了，我还以为我发现某个隐藏的 <code>bug</code> 了，可劲的排查，最后发现，原来是自己镜像包名字写错了，应该写成 <code>0.0.10</code> 的，自己却写成了 <code>0.10</code>。这里，纪念一下，以后碰到上述报错，那肯定是镜像不存在的。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录私有仓库之后会在用户家目录下生成一个docker配置</span></span><br><span class="line"><span class="comment"># 其用来记录docker私有仓库的登录认证信息(是加密过的信息但不安全) =&gt; base64</span></span><br><span class="line">$ cat .docker/config.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"auths"</span>: &#123;</span><br><span class="line">        <span class="string">"docker.escapelife.site"</span>: &#123;</span><br><span class="line">            <span class="string">"auth"</span>: <span class="string">"d00u11Fu22B3355VG2xasE12w=="</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="docker-使容器不退出">Docker 使容器不退出</span></h2><blockquote><p><strong>如何使使用 docker-compose 启动的容器服务 hang 住而不退出</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 有时候我们启动的服务，因为某些问题(<code>bug</code>)导致服务无法正常启动，就会出现容器无限重启(<code>restart: on-failure</code>)的情况，这时就很不利于排除问题。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ docker ps -a</span><br><span class="line">4e6xxx9a4   app:latest   <span class="string">"/xxx/…"</span>   26 seconds ago   Restarting (1) 2 seconds ago</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 这时我们就需要根据，服务构建使用命令来决定是用什么命令来 <code>hang</code> 住服务。卡住的原理，就类似于使用 <code>/bin/bash</code> 进入容器是一样的，这里我就不过多解释了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 类似原理</span></span><br><span class="line">docker run -it --rm --entrypoint=/bin/bash xxx/app:latest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Command命令</span></span><br><span class="line">tty: <span class="literal">true</span></span><br><span class="line"><span class="built_in">command</span>: tail -f /dev/null</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Entrypoint命令</span></span><br><span class="line">tty: <span class="literal">true</span></span><br><span class="line">entrypoint: tail -f /dev/null</span><br></pre></td></tr></table></figure><ul><li>同理，我们在使用 <code>docker-compose</code> 或者 <code>k8s</code> 平台部署服务的时候，也有时会因为启动问题需要，使启动的服务不直接退出，来手动调试和排查问题原因。所以，我这里记录下其不同部署方式的，暂停方式。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Compose</span><br><span class="line"></span><br><span class="line">version: &quot;3&quot;</span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    image: ubuntu:latest</span><br><span class="line">    tty: true</span><br><span class="line">    entrypoint: &#x2F;usr&#x2F;bin&#x2F;tail</span><br><span class="line">    command: &quot;-f &#x2F;dev&#x2F;null&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># K8S</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: ubuntu</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: ubuntu</span><br><span class="line">      image: ubuntu:latest</span><br><span class="line">      command: [&quot;&#x2F;bin&#x2F;bash&quot;, &quot;-c&quot;, &quot;--&quot;]</span><br><span class="line">      args: [&quot;while true; do sleep 30; done;&quot;]</span><br><span class="line">      # command: [&quot;sleep&quot;]</span><br><span class="line">      # args: [&quot;infinity&quot;]</span><br></pre></td></tr></table></figure><h2><span id="docker-不使用默认网段">Docker 不使用默认网段</span></h2><blockquote><p><strong>有些情况，内部规划的网段和可能和 Dockerd 默认的网段有冲突，导致异常出现！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 今天在新机器上面，部署了一整套服务(多台机器)，服务部署完毕之后，通过前置 <code>Nginx</code> 服务发现并不能访问，后置机器开放的端口，发现发到对应端口的请求都没有转发出去。这就比较奇怪了，因为端口控制是已经开通了的，不应该出现不通的情况。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ nc -v 172.16.100.12 8000</span><br><span class="line">nc: connect to 172.16.100.12 port 8000 (tcp) failed: Connection refused</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 发现服务器端口不通，我这里怀疑可能是 <code>dockerd</code> 服务启动导致的，所以我先将服务都停掉，直接在机器上面启动了 <code>Python</code> 的服务端程序(<code>Linux</code> 机器自带 <code>Python2.7.x</code> 的版本)，然后在前置 <code>Nginx</code> 服务发现，端口确实是通的。后来，排除发现是内部服务默认网段和 <code>dockerd</code> 服务启动的默认网段是冲突的，导致重写了机器的防火墙规则，导致出现上述异常的。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ python -m SimpleHTTPServer 8000</span><br><span class="line">Serving HTTP on 0.0.0.0 port 8000 ...</span><br><span class="line"></span><br><span class="line">➜ nc -v 172.16.100.12 8000</span><br><span class="line">Connection to 172.16.100.12 8000 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure><ul><li>既然问题已经知道了，现在需要做的就是非常简单了：不适用默认网段！通过 <a href="https://docs.mirantis.com/mke/3.4/install/plan-deployment/mcr-considerations/default-address-pools.html" target="_blank" rel="noopener">『mirantis』</a> 里面，我们可以选择进行设置，然后重启服务 <code>dockerd</code> 服务，即可。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改配置</span></span><br><span class="line">$ sudo cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"default-address-pools"</span>:[&#123;<span class="string">"base"</span>:<span class="string">"192.168.100.0/20"</span>,<span class="string">"size"</span>:24&#125;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">$ sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务验证是否生效</span></span><br><span class="line">$ ip a</span><br><span class="line">$ docker network inspect app | grep Subnet</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-7-2022-03-29-Ddg8C6.png" alt="Docker 不使用默认网段"></p><ul><li>这时，就到了考验我们网络的子网划分的能力了：如何在给定的网段下面合理且高效的进行划分呢？咳咳，确实难倒我了，这时我们可以再这个在线网站上面 <a href="https://www.sojson.com/convert/subnetmask.html" target="_blank" rel="noopener">JSON 在线解析</a> 进行划分，然后选定合理的 <code>base</code> 和 <code>size</code> 就可以了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 报错信息</span></span><br><span class="line">Error response from daemon: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照下图我们可以对 pool 进行合理划分</span></span><br><span class="line"><span class="comment"># 给定 10.210.200.0 + 255.255.255.0 的网段来划分子网</span></span><br><span class="line">$ sudo cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"default-address-pools"</span>:[&#123;<span class="string">"base"</span>:<span class="string">"10.210.200.0/24"</span>,<span class="string">"size"</span>:28&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>其中，<code>base</code> 告诉我们划分子网的网段是什么(从来开始)，是从前两位(<code>/16</code>)开始，还是第三位开始(<code>/24</code>)呢？而 <code>size</code> 则告诉我们划分的每个子网有多少 <code>IP</code> 地址可以使用呢？从 <code>&quot;10.210.200.0/24&quot;</code> 我们可以知道，该网络下面只有 <code>254</code> 个可用的 <code>IP</code> 地址(直接使用肯定不够)，然后我们需要给 <code>docker</code> 使用，划分每个子网可用 <code>16</code> 个 <code>IP</code> 地址，所以子网就应该写成 <code>28</code> 了。</li></ul><p><img src="https://img.hi-linux.com/staticfile/docker-have-some-trouble-8-2022-03-29-tYKsQu.png" alt="Docker 不使用默认网段"></p><h2><span id="docker-添加私有仓库">Docker 添加私有仓库</span></h2><blockquote><p><strong>有些情况，我们服务器上面需要使用内部私有的容器镜像地址！</strong></p></blockquote><ul><li><strong>[问题起因]</strong> 如果新机器上面需要使用私有仓库的话，但是又没有配置，再获取镜像的时候就会出现如下报错信息。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取/登陆私库时提示</span></span><br><span class="line">$ docker pull 192.168.31.191:5000/nginx:latest</span><br><span class="line">x509: certificate signed by unknown authority</span><br></pre></td></tr></table></figure><ul><li><strong>[解决方法]</strong> 该问题的处理方式很简单，如下所示，配置一下仓库地址，重启服务并登陆私有仓库就可以了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加配置</span></span><br><span class="line">$ sudo cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"insecure-registries"</span>: [<span class="string">"192.168.31.191:5000"</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">$ sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新登录即可</span></span><br><span class="line">$ docker login 私库地址 -u 用户名 -p 密码</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 escapelife 的博客 」，原文：<a href="https://tinyurl.com/2p89skum" target="_blank" rel="noopener">https://tinyurl.com/2p89skum</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;这里主要是为了记录在使用 Docker 的时候遇到的问题及其处理解决方法。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Docker-迁移存储目录&quot;&gt;Docker 迁移存储目录&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;默认情况系统会将 Docker 容器存放在 /var/lib/docker 目录下&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;[问题起因]&lt;/strong&gt; 今天通过监控系统，发现公司其中一台服务器的磁盘快慢，随即上去看了下，发现 &lt;code&gt;/var/lib/docker&lt;/code&gt; 这个目录特别大。由上述原因，我们都知道，在 &lt;code&gt;/var/lib/docker&lt;/code&gt; 中存储的都是相关于容器的存储，所以也不能随便的将其删除掉。&lt;/li&gt;
&lt;li&gt;那就准备迁移 &lt;code&gt;docker&lt;/code&gt; 的存储目录吧，或者对 &lt;code&gt;/var&lt;/code&gt; 设备进行扩容来达到相同的目的。更多关于 &lt;code&gt;dockerd&lt;/code&gt; 的详细参数，请点击查看 &lt;a href=&quot;https://docs.docker.com/engine/reference/commandline/dockerd/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;strong&gt;官方文档&lt;/strong&gt;&lt;/a&gt; 地址。&lt;/li&gt;
&lt;li&gt;但是需要注意的一点就是，尽量不要用软链， 因为一些 &lt;code&gt;docker&lt;/code&gt; 容器编排系统不支持这样做，比如我们所熟知的 &lt;code&gt;k8s&lt;/code&gt; 就在内。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Tailscale 开源版中文部署指南（支持无限设备数、自定义多网段 、自建中继等高级特性）</title>
    <link href="https://www.hi-linux.com/posts/15561.html"/>
    <id>https://www.hi-linux.com/posts/15561.html</id>
    <published>2022-03-30T01:00:00.000Z</published>
    <updated>2022-03-30T02:18:16.728Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><img src="https://img.hi-linux.com/staticfile/2022-03-21-11-13-q1TRI3-2022-03-30-ooh4UE.png" alt></p><p>目前国家工信部在大力推动三大运营商发展 IPv6，对家用宽带而言，可以使用的 IPv4 公网 IP 会越来越少。有部分地区即使拿到了公网 IPv4 地址，也是个大内网地址，根本不是真正的公网 IP，访问家庭内网的资源将会变得越来越困难。</p><p>部分小伙伴可能会选择使用 frp 等针对特定协议和端口的内网穿透方案，但这种方案还是不够酸爽，无法访问家庭内网任意设备的任意端口。更佳的选择还是通过 VPN 来组建大内网。至于该选择哪种 VPN，毫无疑问肯定是 WireGuard，WireGuard 就是 VPN 的未来。<strong>我已经不止一次向大家推荐使用 WireGuard 了，我累了，不想再讲了，你爱 JB 用辣鸡 OpenVPN 之类的就用吧，你开心就好。</strong></p><p>WireGuard 相比于传统 VPN 的核心优势是没有 VPN 网关，所有节点之间都可以点对点（P2P）连接，也就是我之前提到的<a href="https://fuckcloudnative.io/posts/wireguard-full-mesh/#1-%E5%85%A8%E4%BA%92%E8%81%94%E6%A8%A1%E5%BC%8F%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%85%8D%E7%BD%AE" target="_blank" rel="noopener">全互联模式（full mesh）</a>，效率更高，速度更快，成本更低。</p><p>WireGuard 目前最大的痛点就是上层应用的功能不够健全，因为 WireGuard 推崇的是 Unix 的哲学，WireGuard 本身只是一个内核级别的模块，只是一个数据平面，至于上层的更高级的功能（比如秘钥交换机制，UDP 打洞，ACL 等），需要通过用户空间的应用来实现。</p><a id="more"></a><p>所以为了基于 WireGuard 实现更完美的 VPN 工具，现在已经涌现出了很多项目在互相厮杀。笔者前段时间一直在推崇 <a href="https://fuckcloudnative.io/posts/configure-a-mesh-network-with-netmaker/" target="_blank" rel="noopener">Netmaker</a>，它通过可视化界面来配置 WireGuard 的全互联模式，它支持 UDP 打洞、多租户等各种高端功能，几乎适配所有平台，非常强大。然而现实世界是复杂的，无法保证所有的 NAT 都能打洞成功，且 Netmaker 目前还没有 fallback 机制，如果打洞失败，无法 fallback 改成走中继节点。Tailscale 在这一点上比 Netmaker 高明许多，它支持 fallback 机制，可以尽最大努力实现全互联模式，部分节点即使打洞不成功，也能通过中继节点在这个虚拟网络中畅通无阻。</p><p>没错，我移情别恋了，从 Netmaker 阵营转向了 Tailscale，是渣男没错了。</p><h2><span id="tailscale-是什么">Tailscale 是什么</span></h2><p>Tailscale 是一种基于 WireGuard 的虚拟组网工具，和 Netmaker 类似，<strong>最大的区别在于 Tailscale 是在用户态实现了 WireGuard 协议，而 Netmaker 直接使用了内核态的 WireGuard</strong>。所以 Tailscale 相比于内核态 WireGuard 性能会有所损失，但与 OpenVPN 之流相比还是能甩好几十条街的，Tailscale 虽然在性能上做了些许取舍，但在功能和易用性上绝对是完爆其他工具：</p><ol><li>开箱即用</li></ol><ul><li>无需配置防火墙</li><li>没有额外的配置</li></ul><ol><li>高安全性/私密性</li></ol><ul><li>自动密钥轮换</li><li>点对点连接</li><li>支持用户审查端到端的访问记录</li></ul><ol><li>在原有的 ICE、STUN 等 UDP 协议外，实现了 DERP TCP 协议来实现 NAT 穿透</li><li>基于公网的控制服务器下发 ACL 和配置，实现节点动态更新</li><li>通过第三方（如 Google） SSO 服务生成用户和私钥，实现身份认证</li></ol><p>简而言之，我们可以将 Tailscale 看成是更为易用、功能更完善的 WireGuard。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-14-50-Q4bWmK-2022-03-30-HyPo1B.png" alt></p><p>光有这些还不够，作为一个白嫖党，咱更关心的是<strong>免费</strong>与<strong>开源</strong>。</p><p>Tailscale 是一款商业产品，但个人用户是可以白嫖的，个人用户在接入设备不超过 20 台的情况下是可以免费使用的（虽然有一些限制，比如子网网段无法自定义，且无法设置多个子网）。除 Windows 和 macOS 的图形应用程序外，其他 Tailscale 客户端的组件（包含 Android 客户端）是在 BSD 许可下以开源项目的形式开发的，你可以在他们的 <a href="https://github.com/tailscale/" target="_blank" rel="noopener">GitHub 仓库</a>找到各个操作系统的客户端源码。</p><p>对于大部份用户来说，白嫖 Tailscale 已经足够了，如果你有更高的需求，比如自定义网段，可以选择付费。</p><p><strong>我就不想付费行不行？行，不过得往下看。</strong></p><h2><span id="headscale-是什么">Headscale 是什么</span></h2><p>Tailscale 的控制服务器是不开源的，而且对免费用户有诸多限制，这是人家的摇钱树，可以理解。好在目前有一款开源的实现叫 <a href="https://github.com/juanfont/headscale" target="_blank" rel="noopener">Headscale</a>，这也是唯一的一款，希望能发展壮大。</p><p>Headscale 由欧洲航天局的 Juan Font 使用 Go 语言开发，在 BSD 许可下发布，实现了 Tailscale 控制服务器的所有主要功能，可以部署在企业内部，没有任何设备数量的限制，且所有的网络流量都由自己控制。</p><p>目前 Headscale 还没有可视化界面，期待后续更新吧。</p><h2><span id="headscale-部署">Headscale 部署</span></h2><p>Headscale 部署很简单，推荐直接在 Linux 主机上安装。</p><blockquote><p>理论上来说只要你的 Headscale 服务可以暴露到公网出口就行，但最好不要有 NAT，所以推荐将 Headscale 部署在有公网 IP 的云主机上。</p></blockquote><p>首先需要到其 GitHub 仓库的 Release 页面下载最新版的二进制文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget --output-document=/usr/<span class="built_in">local</span>/bin/headscale \</span><br><span class="line">   https://github.com/juanfont/headscale/releases/download/v&lt;HEADSCALE VERSION&gt;/headscale_&lt;HEADSCALE VERSION&gt;_linux_&lt;ARCH&gt;</span><br><span class="line"></span><br><span class="line">$ chmod +x /usr/<span class="built_in">local</span>/bin/headscale</span><br></pre></td></tr></table></figure><p>创建配置目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /etc/headscale</span><br></pre></td></tr></table></figure><p>创建目录用来存储数据与证书：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /var/lib/headscale</span><br></pre></td></tr></table></figure><p>创建空的 SQLite 数据库文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ touch /var/lib/headscale/db.sqlite</span><br></pre></td></tr></table></figure><p>创建 Headscale 配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://github.com/juanfont/headscale/raw/main/config-example.yaml -O /etc/headscale/config.yaml</span><br></pre></td></tr></table></figure><ul><li><p>修改配置文件，将 <code>server_url</code> 改为公网 IP 或域名。<strong>如果是国内服务器，域名必须要备案</strong>。我的域名无法备案，所以我就直接用公网 IP 了。</p></li><li><p>如果暂时用不到 DNS 功能，可以先将 <code>magic_dns</code> 设为 false。</p></li><li><p><code>server_url</code> 设置为 <code>http://&lt;PUBLIC_IP&gt;:8080</code>，将 <code>&lt;PUBLIC_IP&gt;</code> 替换为公网 IP 或者域名。</p></li><li><p>可自定义私有网段，也可同时开启 IPv4 和 IPv6：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ip_prefixes:</span></span><br><span class="line">  <span class="comment"># - fd7a:115c:a1e0::/48</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">10.1</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br></pre></td></tr></table></figure></li></ul><p>创建 SystemD service 配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/systemd/system/headscale.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=headscale controller</span><br><span class="line">After=syslog.target</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=headscale</span><br><span class="line">Group=headscale</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/headscale serve</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional security enhancements</span></span><br><span class="line">NoNewPrivileges=yes</span><br><span class="line">PrivateTmp=yes</span><br><span class="line">ProtectSystem=strict</span><br><span class="line">ProtectHome=yes</span><br><span class="line">ReadWritePaths=/var/lib/headscale /var/run/headscale</span><br><span class="line">AmbientCapabilities=CAP_NET_BIND_SERVICE</span><br><span class="line">RuntimeDirectory=headscale</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>创建 headscale 用户：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ useradd headscale -d /home/headscale -m</span><br></pre></td></tr></table></figure><p>修改 /var/lib/headscale 目录的 owner：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chown -R headscale:headscale /var/lib/headscale</span><br></pre></td></tr></table></figure><p>修改配置文件中的 <code>unix_socket</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">unix_socket:</span> <span class="string">/var/run/headscale/headscale.sock</span></span><br></pre></td></tr></table></figure><p>Reload SystemD 以加载新的配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br></pre></td></tr></table></figure><p>启动 Headscale 服务并设置开机自启：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl <span class="built_in">enable</span> --now headscale</span><br></pre></td></tr></table></figure><p>查看运行状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl status headscale</span><br></pre></td></tr></table></figure><p>查看占用端口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ss -tulnp|grep headscale</span><br><span class="line"></span><br><span class="line">tcp LISTEN 0 1024 [::]:9090 [::]:* users:((<span class="string">"headscale"</span>,pi</span><br><span class="line"></span><br><span class="line">d=10899,fd=13))</span><br><span class="line"></span><br><span class="line">tcp LISTEN 0 1024 [::]:50443 [::]:* users:((<span class="string">"headscale"</span>,pi</span><br><span class="line"></span><br><span class="line">d=10899,fd=10))</span><br><span class="line"></span><br><span class="line">tcp LISTEN 0 1024 [::]:8080 [::]:* users:((<span class="string">"headscale"</span>,pi</span><br><span class="line"></span><br><span class="line">d=10899,fd=12))</span><br></pre></td></tr></table></figure><p>Tailscale 中有一个概念叫 tailnet，你可以理解成租户，租户与租户之间是相互隔离的，具体看参考 Tailscale 的官方文档：<a href="https://tailscale.com/kb/1136/tailnet/" target="_blank" rel="noopener">What is a tailnet</a>。Headscale 也有类似的实现叫 namespace，即命名空间。我们需要先创建一个 namespace，以便后续客户端接入，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ headscale namespaces create default</span><br></pre></td></tr></table></figure><p>查看命名空间：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ headscale namespaces list</span><br><span class="line"></span><br><span class="line">ID | Name | Created</span><br><span class="line"></span><br><span class="line">1 | default | 2022-03-09 06:12:06</span><br></pre></td></tr></table></figure><h2><span id="tailscale-客户端接入">Tailscale 客户端接入</span></h2><p>目前除了 iOS 客户端，其他平台的客户端都有办法自定义 Tailscale 的控制服务器。</p><table><thead><tr><th style="text-align:left">OS</th><th style="text-align:left">是否支持 Headscale</th></tr></thead><tbody><tr><td style="text-align:left">Linux</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">OpenBSD</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">FreeBSD</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">macOS</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">Windows</td><td style="text-align:left">Yes 参考 <a href="https://github.com/juanfont/headscale/blob/main/docs/windows-client.md" target="_blank" rel="noopener">Windows 客户端文档</a></td></tr><tr><td style="text-align:left">Android</td><td style="text-align:left"><a href="https://github.com/juanfont/headscale/issues/58#issuecomment-950386833" target="_blank" rel="noopener">需要自己编译客户端</a></td></tr><tr><td style="text-align:left">iOS</td><td style="text-align:left">暂不支持</td></tr></tbody></table><p>我们先来看下 Linux 平台的接入。</p><h3><span id="linux">Linux</span></h3><p>Tailscale 官方提供了各种 Linux 发行版的软件包，但国内的网络你懂得，软件源根本用不了。好在官方还提供了<a href="https://tailscale.com/download/linux/static" target="_blank" rel="noopener">静态编译的二进制文件</a>，我们可以直接下载。例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://pkgs.tailscale.com/stable/tailscale_1.22.2_amd64.tgz</span><br></pre></td></tr></table></figure><p>解压：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ tar zxvf tailscale_1.22.2_amd64.tgz</span><br><span class="line">x tailscale_1.22.2_amd64/</span><br><span class="line">x tailscale_1.22.2_amd64/tailscale</span><br><span class="line">x tailscale_1.22.2_amd64/tailscaled</span><br><span class="line">x tailscale_1.22.2_amd64/systemd/</span><br><span class="line">x tailscale_1.22.2_amd64/systemd/tailscaled.defaults</span><br><span class="line">x tailscale_1.22.2_amd64/systemd/tailscaled.service</span><br></pre></td></tr></table></figure><p>将二进制文件复制到官方软件包默认的路径下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp tailscale_1.22.2_amd64/tailscaled /usr/sbin/tailscaled</span><br><span class="line">$ cp tailscale_1.22.2_amd64/tailscale /usr/bin/tailscale</span><br></pre></td></tr></table></figure><p>将 systemD service 配置文件复制到系统路径下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp tailscale_1.22.2_amd64/systemd/tailscaled.service /lib/systemd/system/tailscaled.service</span><br></pre></td></tr></table></figure><p>将环境变量配置文件复制到系统路径下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp tailscale_1.22.2_amd64/systemd/tailscaled.defaults /etc/default/tailscaled</span><br></pre></td></tr></table></figure><p>启动 tailscaled.service 并设置开机自启：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl <span class="built_in">enable</span> --now tailscaled</span><br></pre></td></tr></table></figure><p>查看服务状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl status tailscaled</span><br></pre></td></tr></table></figure><p>Tailscale 接入 Headscale：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 &lt;HEADSCALE_PUB_IP&gt; 换成你的 Headscale 公网 IP 或域名</span></span><br><span class="line">$ tailscale up --login-server=http://&lt;HEADSCALE_PUB_IP&gt;:8080 --accept-routes=<span class="literal">true</span> --accept-dns=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>这里推荐将 DNS 功能关闭，因为它会覆盖系统的默认 DNS。如果你对 DNS 有需求，可自己研究官方文档，这里不再赘述。</p><p>执行完上面的命令后，会出现下面的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">To authenticate, visit:</span><br><span class="line"></span><br><span class="line">http://xxxxxx:8080/register?key=905cf165204800247fbd33989dbc22be95c987286c45aac303393704</span><br><span class="line"></span><br><span class="line">1150d846</span><br></pre></td></tr></table></figure><p>在浏览器中打开该链接，就会出现如下的界面：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-17-06-08qWbz-2022-03-30-omWdbc.png" alt></p><p>将其中的命令复制粘贴到 headscale 所在机器的终端中，并将 NAMESPACE 替换为前面所创建的 namespace。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ headscale -n default nodes register --key 905cf165204800247fbd33989dbc22be95c987286c45aac3033937041150d846</span><br><span class="line">Machine register</span><br></pre></td></tr></table></figure><p>注册成功，查看注册的节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ headscale nodes list</span><br><span class="line"></span><br><span class="line">ID | Name | NodeKey | Namespace | IP addresses | Ephemeral | Last seen | Onlin</span><br><span class="line"></span><br><span class="line">e | Expired</span><br><span class="line"></span><br><span class="line">1 | coredns | [Ew3RB] | default | 10.1.0.1 | <span class="literal">false</span> | 2022-03-20 09:08:58 | onlin</span><br><span class="line"></span><br><span class="line">e | no</span><br></pre></td></tr></table></figure><p>回到 Tailscale 客户端所在的 Linux 主机，可以看到 Tailscale 会自动创建相关的路由表和 iptables 规则。路由表可通过以下命令查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip route show table 52</span><br></pre></td></tr></table></figure><p>查看 iptables 规则：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -S</span><br><span class="line">-P INPUT DROP</span><br><span class="line">-P FORWARD ACCEPT</span><br><span class="line">-P OUTPUT ACCEPT</span><br><span class="line">-N ts-forward</span><br><span class="line">-N ts-input</span><br><span class="line">-A INPUT -j ts-input</span><br><span class="line">-A FORWARD -j ts-forward</span><br><span class="line">-A ts-forward -i tailscale0 -j MARK --<span class="built_in">set</span>-xmark 0x40000/0xffffffff</span><br><span class="line">-A ts-forward -m mark --mark 0x40000 -j ACCEPT</span><br><span class="line">-A ts-forward -s 100.64.0.0/10 -o tailscale0 -j DROP</span><br><span class="line">-A ts-forward -o tailscale0 -j ACCEPT</span><br><span class="line">-A ts-input -s 10.1.0.5/32 -i lo -j ACCEPT</span><br><span class="line">-A ts-input -s 100.115.92.0/23 ! -i tailscale0 -j RETURN</span><br><span class="line">-A ts-input -s 100.64.0.0/10 ! -i tailscale0 -j DROP</span><br><span class="line"></span><br><span class="line">$ iptables -S -t nat</span><br><span class="line">-P PREROUTING ACCEPT</span><br><span class="line">-P INPUT ACCEPT</span><br><span class="line">-P OUTPUT ACCEPT</span><br><span class="line">-P POSTROUTING ACCEPT</span><br><span class="line">-A ts-postrouting -m mark --mark 0x40000 -j MASQUERADE</span><br></pre></td></tr></table></figure><h3><span id="macos">macOS</span></h3><p>macOS 客户端的安装相对来说就简单多了，只需要在应用商店安装 APP 即可，前提是你<strong>需要一个美区 ID</strong>。。。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-17-33-3uRFwF-20220330100846245-2022-03-30-UU0DC4.png" alt></p><p>安装完成后还需要做一些骚操作，才能让 Tailscale 使用 Headscale 作为控制服务器。当然，Headscale 已经给我们提供了详细的操作步骤，你只需要在浏览器中打开 URL：<code>http://&lt;HEADSCALE_PUB_IP&gt;:8080/apple</code>，便会出现如下的界面：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-17-39-arYdfv-20220330100854600-2022-03-30-QA5zoK.png" alt></p><p>你只需要按照图中所述的步骤操作即可，本文就不再赘述了。</p><p>修改完成后重启 Tailscale 客户端，在 macOS 顶部状态栏中找到 Tailscale 并点击，然后再点击 <code>Log in</code>。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-17-43-pTW3r7-2022-03-30-lici7s.png" alt></p><p>然后立马就会跳转到浏览器并打开一个页面。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-17-46-AbzngB-2022-03-30-I0Dftb.png" alt></p><p>接下来与之前 Linux 客户端相同，回到 Headscale 所在的机器执行浏览器中的命令即可，注册成功：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-17-51-Gcjcmy-2022-03-30-kfN06l.png" alt></p><p>回到 Headscale 所在主机，查看注册的节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ headscale nodes list</span><br><span class="line"></span><br><span class="line">ID | Name | NodeKey | Namespace | IP addresses | Ephemeral | Last seen | Onlin</span><br><span class="line"></span><br><span class="line">e | Expired</span><br><span class="line"></span><br><span class="line">1 | coredns | [Ew3RB] | default | 10.1.0.1 | <span class="literal">false</span> | 2022-03-20 09:08:58 | onlin</span><br><span class="line"></span><br><span class="line">e | no</span><br><span class="line">2 | carsondemacbook-pro | [k7bzX] | default   | 10.1.0.2     | <span class="literal">false</span>     | 2022-03-20 09:48:30 | online  | no</span><br></pre></td></tr></table></figure><p>回到 macOS，测试是否能 ping 通对端节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ ping -c 2 10.1.0.1</span><br><span class="line">PING 10.1.0.1 (10.1.0.1): 56 data bytes</span><br><span class="line">64 bytes from 10.1.0.1: icmp_seq=0 ttl=64 time=37.025 ms</span><br><span class="line">64 bytes from 10.1.0.1: icmp_seq=1 ttl=64 time=38.181 ms</span><br><span class="line"></span><br><span class="line">--- 10.1.0.1 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0.0% packet loss</span><br><span class="line">round-trip min/avg/max/stddev = 37.025/37.603/38.181/0.578 ms</span><br></pre></td></tr></table></figure><p>也可以使用 Tailscale CLI 来测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /Applications/Tailscale.app/Contents/MacOS/Tailscale ping 10.1.0.1</span><br><span class="line">pong from coredns (10.1.0.1) via xxxx:41641 <span class="keyword">in</span> 36ms</span><br></pre></td></tr></table></figure><p>如果你没有美区 ID，无法安装 App，可以直接使用命令行版本，通过 Homebrew 安装即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install tailscale</span><br></pre></td></tr></table></figure><h3><span id="android">Android</span></h3><p>Android 客户端就比较麻烦了，需要自己修改源代码编译 App，具体可参考<a href="https://github.com/juanfont/headscale/issues/58#issuecomment-950386833" target="_blank" rel="noopener">这个 issue</a>。编译过程还是比较麻烦的，需要先修改源码，然后构建一个包含编译环境的 Docker 镜像，最后在通过该镜像启动容器编译 apk。</p><p>我知道很多人一看麻烦就不想搞了，这个问题不大，我送佛送到西，提供了一条龙服务，你只需 fork 我的 GitHub 仓库 <a href="https://github.com/yangchuansheng/tailscale-android" target="_blank" rel="noopener">tailscale-android</a>：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-21-25-utX9zr-20220330100913552-2022-03-30-oLXzfj.png" alt></p><p>然后在你的仓库中点击 <strong>Settings</strong> 标签，找到 <strong>Secrets</strong> 下拉框中的 Actions 选项：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-21-32-OQT9m7-2022-03-30-X3WXc1.jpg" alt></p><p>选择 <strong>New repository secret</strong> 添加一个 secret 叫 <code>HEADSCALE_URL</code>，将你的 Headscale 服务公网地址填入其中：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-21-35-ep7qXR-20220330100925768-2022-03-30-wX3Vxc.png" alt></p><p><strong>添加在这里的配置，将只对你可见，不用担心会泄露给他人。</strong></p><p>然后点击 <strong>Actions</strong> 标签，选择 <strong>Release</strong> Workflow。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-21-53-CXAfAl-20220330100934764-2022-03-30-N045W9.png" alt></p><p>你会看到一个 <strong>Run workflow</strong> 按钮，点击它，然后在下拉框中点击 <strong>Run workflow</strong>。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-02-SaxiiT-20220330100941082-2022-03-30-jMUwEO.png" alt></p><p>流水线就会开始执行，执行成功后就会在 Release 页面看到编译好的 apk。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-05-wxjatP-20220330100947763-2022-03-30-XNDPE9.png" alt></p><p>接下来的事情就简单了，下载这个 apk 到你的 Android 手机上安装就好了。安装完成后打开 Tailscale App，选择 <strong>Sign in with other</strong>。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-14-34ZnDn-20220330100954238-2022-03-30-OgX2LV.jpeg" alt></p><p>然后就会跳出这个页面：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-21-11-10-jbk5KL-2022-03-30-s7wFak-2022-03-30-MhBzl0.jpeg" alt></p><p>将其中的命令粘贴到 Headscale 所在主机的终端，将 <strong>NAMESPACE</strong> 替换为之前创建的 namespace，然后执行命令即可。注册成功后可将该页面关闭，回到 App 主页，效果如图：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-19-GET2os-20220330101008543-2022-03-30-1Wfo84.jpeg" alt></p><p>回到之前的 GitHub 仓库，刚才我们是通过手动触发 Workflow 来编译 apk 的，有没有办法自动编译呢？<strong>只要 Tailscale 官方仓库有更新，就立即触发 Workflow 开始编译。</strong></p><p>那当然是可以实现的，而且我已经实现了，仔细看 GitHub Actions 的编排文件：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-29-QJvXwt-20220330101015867-2022-03-30-0Sh9T7.png" alt></p><p>红框圈出来的部分表示只要仓库的 <code>main</code> 分支有更新，便会触发 Workflow。<strong>现在的问题是如何让 main 分支和上游官方仓库一致，一直保持在最新状态。</strong></p><p>这个问题使用第三方 Github App 就可以解决，这个 App 名字简单粗暴，就叫 <a href="https://github.com/apps/pull" target="_blank" rel="noopener">Pull</a>，它的作用非也很简单粗暴：保持你的 Fork 在最新状态。</p><p>Pull 的使用方法很简单：</p><ol><li>打开 <a href="https://github.com/apps/pull" target="_blank" rel="noopener">Pull App</a> 页面</li><li>点击右上角绿色的 install 按钮</li></ol><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-44-fRwr6j-20220330101027005-2022-03-30-FKoCBW.png" alt></p><ol><li>在选项页面，使用默认的 <strong>All repositories</strong> 即可（你也可以选择指定的仓库，比如 tailscale-android），然后点击绿色的 <strong>install</strong> 按钮：</li></ol><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-22-46-flOKJW-2022-03-30-LfAe4V-2022-03-30-m2esZD.png" alt></p><p>简单三步，Pull App 就安装好了。接下来 Pull App 会每天定时帮你更新代码库，使你 fork 的代码始终是最新版的。</p><h3><span id="windows">Windows</span></h3><p>Windows Tailscale 客户端想要使用 Headscale 作为控制服务器，只需在浏览器中打开 URL：<code>http://&lt;HEADSCALE_PUB_IP&gt;:8080/windows</code>，便会出现如下的界面：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-20-23-30-zcQX3F-2022-03-30-OUQVcT.png" alt></p><p>按照其中的步骤操作即可。</p><h3><span id="其他-linux-发行版">其他 Linux 发行版</span></h3><p>除了常规的 Linux 发行版之外，还有一些特殊场景的 Linux 发行版，比如 OpenWrt、威联通（QNAP）、群晖等，这些发行版的安装方法已经有人写好了，这里就不详细描述了，我只给出相关的 GitHub 仓库，大家如果自己有需求，直接去看相关仓库的文档即可。</p><ul><li>OpenWrt：<a href="https://github.com/adyanth/openwrt-tailscale-enabler" target="_blank" rel="noopener">https://github.com/adyanth/openwrt-tailscale-enabler</a></li><li>群晖：<a href="https://github.com/tailscale/tailscale-synology" target="_blank" rel="noopener">https://github.com/tailscale/tailscale-synology</a></li><li>威联通：<a href="https://github.com/ivokub/tailscale-qpkg" target="_blank" rel="noopener">https://github.com/ivokub/tailscale-qpkg</a></li></ul><h3><span id="ios">iOS</span></h3><p>Tailscale iOS 客户端源代码没有开源，目前还无法破解使其使用第三方控制服务器，遗憾~~</p><h2><span id="打通局域网">打通局域网</span></h2><p>到目前为止我们只是打造了一个点对点的 Mesh 网络，各个节点之间都可以通过 WireGuard 的私有网络 IP 进行直连。但我们可以更大胆一点，还记得我在文章开头提到的访问家庭内网的资源吗？我们可以通过适当的配置让每个节点都能访问其他节点的局域网 IP。这个使用场景就比较多了，你可以直接访问家庭内网的 NAS，或者内网的任何一个服务，<strong>更高级的玩家可以使用这个方法来访问云上 Kubernetes 集群的 Pod IP 和 Service IP。</strong></p><p>假设你的家庭内网有一台 Linux 主机（比如 OpenWrt）安装了 Tailscale 客户端，我们希望其他 Tailscale 客户端可以直接通过家中的局域网 IP（例如 <strong>192.168.100.0/24</strong>） 访问家庭内网的任何一台设备。</p><p>配置方法很简单，首先需要设置 IPv4 与 IPv6 路由转发：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">'net.ipv4.ip_forward = 1'</span> | tee /etc/sysctl.d/ipforwarding.conf</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'net.ipv6.conf.all.forwarding = 1'</span> | tee -a /etc/sysctl.d/ipforwarding.conf</span><br><span class="line">$ sysctl -p /etc/sysctl.d/ipforwarding.conf</span><br></pre></td></tr></table></figure><p>客户端修改注册节点的命令，在原来命令的基础上加上参数 <code>--advertise-routes=192.168.100.0/24</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale up --login-server=http://&lt;HEADSCALE_PUB_IP&gt;:8080 --accept-routes=<span class="literal">true</span> --accept-dns=<span class="literal">false</span> --advertise-routes=192.168.100.0/24</span><br></pre></td></tr></table></figure><p>在 Headscale 端查看路由，可以看到相关路由是关闭的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ headscale nodes list|grep openwrt</span><br><span class="line"></span><br><span class="line">6 | openwrt | [7LdVc] | default | 10.1.0.6 | <span class="literal">false</span> | 2022-03-20 15:50:46 | onlin</span><br><span class="line"></span><br><span class="line">e | no</span><br><span class="line"></span><br><span class="line">$ headscale routes list -i 6</span><br><span class="line"></span><br><span class="line">Route | Enabled</span><br><span class="line"></span><br><span class="line">192.168.100.0/24 | <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>开启路由：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ headscale routes <span class="built_in">enable</span> -i 6 -r <span class="string">"192.168.100.0/24"</span></span><br><span class="line"></span><br><span class="line">Route | Enabled</span><br><span class="line"></span><br><span class="line">192.168.100.0/24 | <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>其他节点查看路由结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ip route show table 52|grep <span class="string">"192.168.100.0/24"</span></span><br><span class="line">192.168.100.0/24 dev tailscale0</span><br></pre></td></tr></table></figure><p>现在你在任何一个 Tailscale 客户端所在的节点都可以 ping 通家庭内网的机器了，你在公司或者星巴克也可以像在家里一样用同样的 IP 随意访问家中的任何一个设备，就问你香不香？</p><h2><span id="总结">总结</span></h2><p>目前从稳定性来看，Tailscale 比 Netmaker 略胜一筹，基本上不会像 Netmaker 一样时不时出现 ping 不通的情况，这取决于 Tailscale 在用户态对 NAT 穿透所做的种种优化，他们还专门写了一篇文章介绍 <a href="https://tailscale.com/blog/how-nat-traversal-works/" target="_blank" rel="noopener">NAT 穿透的原理</a>，<a href="https://arthurchiao.art/blog/how-nat-traversal-works-zh/" target="_blank" rel="noopener">中文版</a>翻译自国内的 eBPF 大佬赵亚楠，墙裂推荐大家阅读。放一张图给大家感受一下：</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-21-10-52-TzXGEZ-20220330101049526-2022-03-30-9Eqg5N.png" alt></p><p>本文给大家介绍了 Tailscale 和 Headscale，包括 Headscale 的安装部署和各个平台客户端的接入，以及如何打通各个节点所在的局域网。下篇文章将会给大家介绍如何让 Tailscale 使用自定义的 DERP Servers（也就是中继服务器），See you~~</p><p>上面我们介绍了如何使用 <code>Headscale</code> 替代 Tailscale 官方的控制服务器，并接入各个平台的客户端。本文将会介绍如何让 Tailscale 使用自定义的 DERP Servers。可能很多人都不知道 <code>DERP</code> 是个啥玩意儿，没关系，我先从<strong>中继服务器</strong>开始讲起。</p><h2><span id="stun-是什么">STUN 是什么</span></h2><p>Tailscale 的终极目标是让两台<strong>处于网络上的任何位置</strong>的机器建立<strong>点对点连接</strong>（直连），但现实世界是复杂的，大部份情况下机器都位于 NAT 和防火墙后面，这时候就需要通过打洞来实现直连，也就是 NAT 穿透。</p><p>NAT 按照 <strong>NAT 映射行为</strong>和<strong>有状态防火墙行为</strong>可以分为多种类型，但对于 NAT 穿透来说根本不需要关心这么多类型，只需要看 <strong>NAT 或者有状态防火墙是否会严格检查目标 Endpoint</strong>，根据这个因素，可以将 NAT 分为 <strong>Easy NAT</strong> 和 <strong>Hard NAT</strong>。</p><ul><li><strong>Easy NAT</strong> 及其变种称为 “Endpoint-Independent Mapping” (<strong>EIM，终点无关的映射</strong>)<br>这里的 Endpoint 指的是目标 Endpoint，也就是说，有状态防火墙只要看到有客户端自己发起的出向包，就会允许相应的入向包进入，<strong>不管这个入向包是谁发进来的都可以</strong>。</li><li><strong>hard NAT</strong> 以及变种称为 “Endpoint-Dependent Mapping”（<strong>EDM，终点相关的映射</strong>）<br>这种 NAT 会针对每个目标 Endpoint 来生成一条相应的映射关系。 在这样的设备上，如果客户端向某个目标 Endpoint 发起了出向包，假设客户端的公网 IP 是 2.2.2.2，那么有状态防火墙就会打开一个端口，假设是 4242。那么只有来自该目标 Endpoint 的入向包才允许通过 <code>2.2.2.2:4242</code>，其他客户端一律不允许。这种 NAT 更加严格，所以叫 Hard NAT。</li></ul><p>对于 Easy NAT，我们只需要提供一个第三方的服务，它能够告诉客户端“它看到的客户端的公网 ip:port 是什么”，然后将这个信息以某种方式告诉通信对端（peer），后者就知道该和哪个地址建连了！这种服务就叫 <strong>STUN</strong> (Session Traversal Utilities for NAT，NAT会话穿越应用程序)。它的工作流程如下图所示：</p><ul><li>笔记本向 STUN 服务器发送一个请求：“从你的角度看，我的地址什么？”</li><li>STUN 服务器返回一个响应：“我看到你的 UDP 包是从这个地址来的：<code>ip:port</code>”。</li></ul><p><img src="https://img.hi-linux.com/staticfile/2022-03-26-17-27-yqHlMG-20220330101057816-2022-03-30-PeORYt.jpg" alt></p><h2><span id="中继是什么">中继是什么</span></h2><p>对于 <strong>Hard NAT</strong> 来说，STUN 就不好使了，即使 STUN 拿到了客户端的公网 <code>ip:port</code> 告诉通信对端也于事无补，因为防火墙是和 STUN 通信才打开的缺口，这个缺口只允许 STUN 的入向包进入，其他通信对端知道了这个缺口也进不来。通常企业级 NAT 都属于 Hard NAT。</p><p>这种情况下打洞是不可能了，但也不能就此放弃，可以选择一种折衷的方式：创建一个中继服务器（relay server），客户端与中继服务器进行通信，中继服务器再将包中继（relay）给通信对端。</p><p>至于中继的性能，那要看具体情况了：</p><ul><li>如果能直连，那显然没必要用中继方式；</li><li>但如果无法直连，而中继路径又非常接近双方直连的真实路径，并且带宽足够大，那中继方式并不会明显降低通信质量。延迟肯定会增加一点，带宽会占用一些，但<strong>相比完全连接不上，还是可以接受的</strong>。</li></ul><p>事实上对于大部分网络而言，Tailscale 都可以通过各种黑科技打洞成功，只有极少数情况下才会选择中继，中继只是一种 fallback 机制。</p><h2><span id="中继协议简介">中继协议简介</span></h2><p>中继协议有多种实现方式。</p><h3><span id="turn">TURN</span></h3><p>TURN 即 Traversal Using Relays around NAT，这是一种经典的中继实现方式，核心理念是：</p><ul><li><strong>用户</strong>（人）先去公网上的 TURN 服务器认证，成功后后者会告诉你：“我已经为你分配了 ip:port，接下来将为你中继流量”，</li><li>然后将这个 ip:port 地址告诉对方，让它去连接这个地址，接下去就是非常简单的客户端/服务器通信模型了。</li></ul><p>与 STUN 不同，这种协议没有真正的交互性，不是很好用，因此 Tailscale 并没有采用 TURN 作为中继协议。</p><h3><span id="derp">DERP</span></h3><p>DERP 即 Detoured Encrypted Routing Protocol，这是 Tailscale 自研的一个协议：</p><ul><li>它是一个<strong>通用目的包中继协议，运行在 HTTP 之上</strong>，而大部分网络都是允许 HTTP 通信的。</li><li>它根据目的公钥（destination’s public key）来中继加密的流量（encrypted payloads）。</li></ul><p><img src="https://img.hi-linux.com/staticfile/2022-03-26-19-02-zLDv51-2022-03-30-KTRx7G.svg" alt="Tailscale 会自动选择离目标节点最近的 DERP server 来中继流量"></p><p>Tailscale 使用的算法很有趣，<strong>所有客户端之间的连接都是先选择 DERP 模式（中继模式），这意味着连接立即就能建立（优先级最低但 100% 能成功的模式），用户不用任何等待</strong>。然后开始并行地进行路径发现，通常几秒钟之后，我们就能发现一条更优路径，然后将现有连接透明升级（upgrade）过去，变成点对点连接（直连）。</p><p>因此，DERP 既是 Tailscale 在 NAT 穿透失败时的保底通信方式（此时的角色与 TURN 类似），也是在其他一些场景下帮助我们完成 NAT 穿透的旁路信道。 换句话说，它既是我们的保底方式，也是有更好的穿透链路时，帮助我们进行连接升级（upgrade to a peer-to-peer connection）的基础设施。</p><h2><span id="自建私有-derp-server">自建私有 DERP server</span></h2><p>Tailscale 的私钥只会保存在当前节点，因此 DERP server 无法解密流量，它只能和互联网上的其他路由器一样，呆呆地将加密的流量从一个节点转发到另一个节点，只不过 DERP 使用了一个稍微高级一点的协议来防止滥用。</p><p>Tailscale 开源了 DERP 服务器的代码，如果你感兴趣，可以阅读 <a href="https://github.com/tailscale/tailscale/tree/main/derp" target="_blank" rel="noopener">DERP 的源代码</a>。</p><p>Tailscale 官方内置了很多 DERP 服务器，分步在全球各地，<strong>惟独不包含中国大陆</strong>，原因你懂得。这就导致了一旦流量通过 DERP 服务器进行中继，延时就会非常高。而且官方提供的 DERP 服务器是万人骑，存在安全隐患。</p><p>为了实现低延迟、高安全性，我们可以参考 <a href="https://tailscale.com/kb/1118/custom-derp-servers/" target="_blank" rel="noopener">Tailscale 官方文档</a>自建私有的 DERP 服务器。有两种部署模式，一种是基于域名，另外一种不需要域名，可以直接使用 IP，不过需要一点黑科技。我们先来看最简单的使用域名的方案。</p><h3><span id="使用域名">使用域名</span></h3><p>这种方案需要满足以下几个条件：</p><ul><li>要有自己的域名，并且申请了 SSL 证书</li><li>需要准备一台或多台云主机</li><li>如果服务器在国内，域名需要备案</li><li>如果服务器在国外，则不需要备案</li></ul><p>如果以上条件都俱备，就可以按照下面的步骤开始部署了。</p><p>推荐直接使用 Docker 来部署，我已经构建好了 Docker 镜像，直接部署就可以了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">🐳  → docker run --restart always \</span><br><span class="line">  --name derper -p 12345:12345 -p 3478:3478/udp \</span><br><span class="line">  -v /root/.acme.sh/xxxx/:/app/certs \</span><br><span class="line">  -e DERP_CERT_MODE=manual \</span><br><span class="line">  -e DERP_ADDR=:12345 \</span><br><span class="line">  -e DERP_DOMAIN=xxxx \</span><br><span class="line">  -d ghcr.io/yangchuansheng/derper:latest</span><br></pre></td></tr></table></figure><p>有几点需要注意：</p><ul><li>能用 443 端口尽量用 443 端口，实在不行再用别的端口；</li><li>默认情况下也会开启 STUN 服务，UDP 端口是 <code>3478</code>；</li><li>防火墙需要放行端口 12345 和 3478；</li><li>准备好 SSL 证书；</li><li>域名部分我打了码，请换成你自己的域名。</li></ul><p>关于证书部分需要重点说明：<strong>假设你的域名是 <code>xxx.com</code>，那么证书的名称必须是 <code>xxx.com.crt</code>，一个字符都不能错！同理，私钥名称必须是 <code>xxx.com.key</code>，一个字符都不能错！</strong></p><p>查看容器日志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">🐳  → docker logs -f derper</span><br><span class="line">2022/03/26 11:36:28 no config path specified; using /var/lib/derper/derper.key</span><br><span class="line">2022/03/26 11:36:28 derper: serving on :12345 with TLS</span><br><span class="line">2022/03/26 11:36:28 running STUN server on [::]:3478</span><br></pre></td></tr></table></figure><p>目前 derper 运行一段时间就会崩溃，暂时还没有更好的解决方案，只能通过定时重启来解决，比如通过 crontab 来设置每两小时重启一次容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 */2 * * * docker restart derper &amp;&gt; /dev/null</span><br></pre></td></tr></table></figure><p>具体可参考这个 issue：<a href="https://github.com/tailscale/tailscale/issues/4082" target="_blank" rel="noopener">Derper TLS handshake error: remote error: tls: internal error</a></p><p>部署好 derper 之后，就可以修改 Headscale 的配置来使用自定义的 DERP 服务器了。Headscale 可以通过两种形式的配置来使用自定义 DERP：</p><ul><li>一种是在线 URL，格式是 <code>JSON</code>，与 Tailscale 官方控制服务器使用的格式和语法相同。</li><li>另一种是本地文件，格式是 <code>YAML</code>。</li></ul><p>我们可以直接使用本地的 YAML 配置文件，内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/headscale/derp.yaml</span></span><br><span class="line"><span class="attr">regions:</span></span><br><span class="line">  <span class="attr">900:</span></span><br><span class="line">    <span class="attr">regionid:</span> <span class="number">900</span></span><br><span class="line">    <span class="attr">regioncode:</span> <span class="string">thk</span> </span><br><span class="line">    <span class="attr">regionname:</span> <span class="string">Tencent</span> <span class="string">Hongkong</span> </span><br><span class="line">    <span class="attr">nodes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">900a</span></span><br><span class="line">        <span class="attr">regionid:</span> <span class="number">900</span></span><br><span class="line">        <span class="attr">hostname:</span> <span class="string">xxxx</span></span><br><span class="line">        <span class="attr">ipv4:</span> <span class="string">xxxx</span></span><br><span class="line">        <span class="attr">stunport:</span> <span class="number">3478</span></span><br><span class="line">        <span class="attr">stunonly:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">derpport:</span> <span class="number">12345</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">900b</span></span><br><span class="line">        <span class="attr">regionid:</span> <span class="number">900</span></span><br><span class="line">        <span class="attr">hostname:</span> <span class="string">xxxx</span></span><br><span class="line">        <span class="attr">ipv4:</span> <span class="string">xxxx</span></span><br><span class="line">        <span class="attr">stunport:</span> <span class="number">3478</span></span><br><span class="line">        <span class="attr">stunonly:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">derpport:</span> <span class="number">12345</span></span><br><span class="line">  <span class="attr">901:</span></span><br><span class="line">    <span class="attr">regionid:</span> <span class="number">901</span></span><br><span class="line">    <span class="attr">regioncode:</span> <span class="string">hs</span> </span><br><span class="line">    <span class="attr">regionname:</span> <span class="string">Huawei</span> <span class="string">Shanghai</span> </span><br><span class="line">    <span class="attr">nodes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">901a</span></span><br><span class="line">        <span class="attr">regionid:</span> <span class="number">901</span></span><br><span class="line">        <span class="attr">hostname:</span> <span class="string">xxxx</span></span><br><span class="line">        <span class="attr">ipv4:</span> <span class="string">xxxx</span></span><br><span class="line">        <span class="attr">stunport:</span> <span class="number">3478</span></span><br><span class="line">        <span class="attr">stunonly:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">derpport:</span> <span class="number">12345</span></span><br></pre></td></tr></table></figure><p>配置说明：</p><ul><li><code>regions</code> 是 YAML 中的<strong>对象</strong>，下面的每一个对象表示一个<strong>可用区</strong>，每个<strong>可用区</strong>里面可设置多个 DERP 节点，即 <code>nodes</code>。</li><li>每个可用区的 <code>regionid</code> 不能重复。</li><li>每个 <code>node</code> 的 <code>name</code> 不能重复。</li><li><code>regionname</code> 一般用来描述可用区，<code>regioncode</code> 一般设置成可用区的缩写。</li><li><code>ipv4</code> 字段不是必须的，如果你的域名可以通过公网解析到你的 DERP 服务器地址，这里可以不填。如果你使用了一个二级域名，而这个域名你并没有在公共 DNS server 中添加相关的解析记录，那么这里就需要指定 IP（前提是你的证书包含了这个二级域名，这个很好支持，搞个泛域名证书就行了）。</li><li><code>stunonly: false</code> 表示除了使用 STUN 服务，还可以使用 DERP 服务。</li><li>上面的配置中域名和 IP 部分我都打码了，你需要根据你的实际情况填写。</li></ul><p>接下来还需要修改 Headscale 的配置文件，引用上面的自定义 DERP 配置文件。需要修改的配置项如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/headscale/config.yaml</span></span><br><span class="line"><span class="attr">derp:</span></span><br><span class="line">  <span class="comment"># List of externally available DERP maps encoded in JSON</span></span><br><span class="line">  <span class="attr">urls:</span></span><br><span class="line">  <span class="comment">#  - https://controlplane.tailscale.com/derpmap/default</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Locally available DERP map files encoded in YAML</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># This option is mostly interesting for people hosting</span></span><br><span class="line">  <span class="comment"># their own DERP servers:</span></span><br><span class="line">  <span class="comment"># https://tailscale.com/kb/1118/custom-derp-servers/</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># paths:</span></span><br><span class="line">  <span class="comment">#   - /etc/headscale/derp-example.yaml</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/etc/headscale/derp.yaml</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># If enabled, a worker will be set up to periodically</span></span><br><span class="line">  <span class="comment"># refresh the given sources and update the derpmap</span></span><br><span class="line">  <span class="comment"># will be set up.</span></span><br><span class="line">  <span class="attr">auto_update_enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># How often should we check for DERP updates?</span></span><br><span class="line">  <span class="attr">update_frequency:</span> <span class="string">24h</span></span><br></pre></td></tr></table></figure><p>可以把 Tailscale 官方的 DERP 服务器禁用，来测试自建的 DERP 服务器是否能正常工作。</p><p>修改完配置后，重启 headscale 服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart headscale</span><br></pre></td></tr></table></figure><p>在 Tailscale 客户端上使用以下命令查看目前可以使用的 DERP 服务器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale netcheck</span><br><span class="line"></span><br><span class="line">Report:</span><br><span class="line">        * UDP: <span class="literal">true</span></span><br><span class="line">        * IPv4: yes, xxxxx:57068</span><br><span class="line">        * IPv6: no</span><br><span class="line">        * MappingVariesByDestIP: <span class="literal">false</span></span><br><span class="line">        * HairPinning: <span class="literal">false</span></span><br><span class="line">        * PortMapping: </span><br><span class="line">        * Nearest DERP: Tencent Hongkong</span><br><span class="line">        * DERP latency:</span><br><span class="line">                - thk: 39.7ms (Tencent Hongkong)</span><br></pre></td></tr></table></figure><p><code>tailscale netcheck</code> 实际上只检测 <code>3478/udp</code> 的端口， 就算 netcheck 显示能连，也不一定代表 12345 端口可以转发流量。最简单的办法是直接打开 DERP 服务器的 URL：<a href="https://xxxx:12345" target="_blank" rel="noopener">https://xxxx:12345</a>，如果看到如下页面，且地址栏的 SSL 证书标签显示正常可用，那才是真没问题了。</p><p><img src="https://img.hi-linux.com/staticfile/2022-03-27-11-21-dZ5dtZ-2022-03-30-jkEw4r.png" alt></p><p>查看与通信对端的连接方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale status</span><br><span class="line">10.1.0.5        coredns              default      linux   -</span><br><span class="line">                carsondemacbook-pro  default      macOS   active; direct xxxx:2756; offline, tx 50424 rx 34056</span><br><span class="line">                oneplus-8t           default      android active; relay <span class="string">"thk"</span>; offline, tx 1608 rx 1552</span><br><span class="line">                openwrt              default      linux   active; direct xxxx:2834; offline, tx 1403688 rx 1217620</span><br></pre></td></tr></table></figure><p>这个客户端是一台云主机，有 3 个通信对端，分别是 macOS、OpenWRT 与 Android 手机，macOS 和 OpenWRT 都处于电信家庭内网中，Android 手机使用的是电信流量。可以看到只有 Android 手机是通过自定义的 DERP 服务器来中继流量的，打洞成功率相当高。使用 ping 来测试连通性：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ ping 10.1.0.8</span><br><span class="line">PING 10.1.0.8 (10.1.0.8) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.0.8: icmp_seq=1 ttl=64 time=150 ms</span><br><span class="line">64 bytes from 10.1.0.8: icmp_seq=2 ttl=64 time=131 ms</span><br><span class="line">64 bytes from 10.1.0.8: icmp_seq=3 ttl=64 time=161 ms</span><br><span class="line">64 bytes from 10.1.0.8: icmp_seq=4 ttl=64 time=137 ms</span><br><span class="line">64 bytes from 10.1.0.8: icmp_seq=5 ttl=64 time=156 ms</span><br><span class="line">64 bytes from 10.1.0.8: icmp_seq=6 ttl=64 time=169 ms</span><br><span class="line">^C</span><br><span class="line">--- 10.1.0.8 ping statistics ---</span><br><span class="line">6 packets transmitted, 6 received, 0% packet loss, time 5005ms</span><br><span class="line">rtt min/avg/max/mdev = 131.728/151.154/169.627/13.193 ms</span><br></pre></td></tr></table></figure><p>也可以使用 Tailscale 命令行工具来测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale ping 10.1.0.8</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via DERP(thk) <span class="keyword">in</span> 104ms</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via DERP(thk) <span class="keyword">in</span> 111ms</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via DERP(thk) <span class="keyword">in</span> 105ms</span><br></pre></td></tr></table></figure><p>这个更加友好一点，会直接告诉你是通过 DERP 中继服务器来和对方通信的。</p><p>如果当前 Tailscale 客户端所在主机开启了 IPv6，那么与手机便可以直接通过 IPv6 点对点连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ /Applications/Tailscale.app/Contents/MacOS/Tailscale status</span><br><span class="line">                coredns              default      linux   active; direct xxxx:45986; offline, tx 124352 rx 185736</span><br><span class="line">                oneplus-8t           default      android active; direct [240e:472:da0:24a2:a07f:2a67:2a1e:4475]:37237; offline, tx 125216 rx 20052</span><br><span class="line">                openwrt              default      linux   active; direct [240e:390:caf:1870:c02c:e8ff:feb9:b0b]:41641; offline, tx 181992 rx 3910120</span><br><span class="line"></span><br><span class="line">$ /Applications/Tailscale.app/Contents/MacOS/Tailscale ping 10.1.0.8</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via [240e:472:da0:24a2:a07f:2a67:2a1e:4475]:37237 <span class="keyword">in</span> 62ms</span><br></pre></td></tr></table></figure><p>所以如果你开启了 IPv6，可以大大增加<strong>点对点连接</strong>的成功率。</p><h3><span id="使用纯-ip">使用纯 IP</span></h3><p>我知道，大部分人是没有自己的域名的。再退一步，就算有自己的域名，如果没有备案，也是没办法部署在国内服务器上使用的。</p><p>这个时候我们就只能从 derper 源码上动手脚了，找到 tailscale 仓库中的 <code>cmd/derper/cert.go</code> 文件，将与域名验证相关的内容删除或注释：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *manualCertManager)</span> <span class="title">getCertificate</span><span class="params">(hi *tls.ClientHelloInfo)</span> <span class="params">(*tls.Certificate, error)</span></span> &#123;</span><br><span class="line"><span class="comment">//if hi.ServerName != m.hostname &#123;</span></span><br><span class="line"><span class="comment">//return nil, fmt.Errorf("cert mismatch with hostname: %q", hi.ServerName)</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"><span class="keyword">return</span> m.cert, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还需要创建自签名证书，可以通过脚本来创建：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build_cert.sh</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">CERT_HOST=<span class="variable">$1</span></span><br><span class="line">CERT_DIR=<span class="variable">$2</span></span><br><span class="line">CONF_FILE=<span class="variable">$3</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"[req]</span></span><br><span class="line"><span class="string">default_bits  = 2048</span></span><br><span class="line"><span class="string">distinguished_name = req_distinguished_name</span></span><br><span class="line"><span class="string">req_extensions = req_ext</span></span><br><span class="line"><span class="string">x509_extensions = v3_req</span></span><br><span class="line"><span class="string">prompt = no</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[req_distinguished_name]</span></span><br><span class="line"><span class="string">countryName = XX</span></span><br><span class="line"><span class="string">stateOrProvinceName = N/A</span></span><br><span class="line"><span class="string">localityName = N/A</span></span><br><span class="line"><span class="string">organizationName = Self-signed certificate</span></span><br><span class="line"><span class="string">commonName = <span class="variable">$CERT_HOST</span>: Self-signed certificate</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[req_ext]</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[v3_req]</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[alt_names]</span></span><br><span class="line"><span class="string">IP.1 = <span class="variable">$CERT_HOST</span></span></span><br><span class="line"><span class="string">"</span> &gt; <span class="string">"<span class="variable">$CONF_FILE</span>"</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="string">"<span class="variable">$CERT_DIR</span>"</span></span><br><span class="line">openssl req -x509 -nodes -days 730 -newkey rsa:2048 -keyout <span class="string">"<span class="variable">$CERT_DIR</span>/<span class="variable">$CERT_HOST</span>.key"</span> -out <span class="string">"<span class="variable">$CERT_DIR</span>/<span class="variable">$CERT_HOST</span>.crt"</span> -config <span class="string">"<span class="variable">$CONF_FILE</span>"</span></span><br></pre></td></tr></table></figure><p>重新编写 Dockerfile，将 derper 的域名设置为 <code>127.0.0.1</code>：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:latest AS builder</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ========= CONFIG =========</span></span><br><span class="line"><span class="comment"># - download links</span></span><br><span class="line"><span class="keyword">ENV</span> MODIFIED_DERPER_GIT=https://github.com/yangchuansheng/ip_derper.git</span><br><span class="line"><span class="keyword">ENV</span> BRANCH=ip_derper</span><br><span class="line"><span class="comment"># ==========================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build modified derper</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> git <span class="built_in">clone</span> -b <span class="variable">$BRANCH</span> <span class="variable">$MODIFIED_DERPER_GIT</span> tailscale --depth 1 &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> /app/tailscale/cmd/derper &amp;&amp; \</span></span><br><span class="line"><span class="bash">    /usr/<span class="built_in">local</span>/go/bin/go build -ldflags <span class="string">"-s -w"</span> -o /app/derper &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> /app &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm -rf /app/tailscale</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">20.04</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ========= CONFIG =========</span></span><br><span class="line"><span class="comment"># - derper args</span></span><br><span class="line"><span class="keyword">ENV</span> DERP_HOST=<span class="number">127.0</span>.<span class="number">0.1</span></span><br><span class="line"><span class="keyword">ENV</span> DERP_CERTS=/app/certs/</span><br><span class="line"><span class="keyword">ENV</span> DERP_STUN true</span><br><span class="line"><span class="keyword">ENV</span> DERP_VERIFY_CLIENTS false</span><br><span class="line"><span class="comment"># ==========================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># apt</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get install -y openssl curl</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> build_cert.sh /app/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /app/derper /app/derper</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build self-signed certs &amp;&amp; start derper</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> bash /app/build_cert.sh <span class="variable">$DERP_HOST</span> <span class="variable">$DERP_CERTS</span> /app/san.conf &amp;&amp; \</span></span><br><span class="line"><span class="bash">    /app/derper --hostname=<span class="variable">$DERP_HOST</span> \</span></span><br><span class="line"><span class="bash">    --certmode=manual \</span></span><br><span class="line"><span class="bash">    --certdir=<span class="variable">$DERP_CERTS</span> \</span></span><br><span class="line"><span class="bash">    --stun=<span class="variable">$DERP_STUN</span>  \</span></span><br><span class="line"><span class="bash">    --verify-clients=<span class="variable">$DERP_VERIFY_CLIENTS</span></span></span><br></pre></td></tr></table></figure><p>构建好镜像后，就可以在你想部署 derper 的主机上直接通过该镜像启动 derper 容器了，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">🐳  → docker run --restart always --net host --name derper -d ghcr.io/yangchuansheng/ip_derper</span><br></pre></td></tr></table></figure><p>和使用域名的方案一样，防火墙需要放行相应端口（12345 与 3478）。</p><p>查看容器日志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">🐳  → docker logs -f derper</span><br><span class="line">Generating a RSA private key</span><br><span class="line">.......................................+++++</span><br><span class="line">..............+++++</span><br><span class="line">writing new private key to <span class="string">'/app/certs//127.0.0.1.key'</span></span><br><span class="line">-----</span><br><span class="line">2022/03/26 14:30:31 no config path specified; using /var/lib/derper/derper.key</span><br><span class="line">2022/03/26 14:30:31 derper: serving on :443 with TLS</span><br><span class="line">2022/03/26 14:30:31 running STUN server on [::]:3478</span><br></pre></td></tr></table></figure><p>如果你想自己构建 derper 镜像，可以参考<a href="https://github.com/yangchuansheng/ip_derper" target="_blank" rel="noopener">我的 GitHub 仓库</a>。</p><p>下面就是骚操作了，我们在 Headscale 的配置中需要<strong>将 DERP 的域名设置为 IP</strong>！不理解的可以再消化一下，然后继续往下看哈哈~~</p><p>除了 derper 之外，Tailscale 客户端还需要<strong>跳过域名验证</strong>，这个需要在 DERP 的配置中设置。而 Headscale 的本地 YAML 文件目前还不支持这个配置项，所以没办法，咱只能使用在线 URL 了。JSON 配置内容如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"Regions"</span>: &#123;</span><br><span class="line">    <span class="attr">"901"</span>: &#123;</span><br><span class="line">      <span class="attr">"RegionID"</span>: <span class="number">901</span>,</span><br><span class="line">      <span class="attr">"RegionCode"</span>: <span class="string">"ali-sh"</span>,</span><br><span class="line">      <span class="attr">"RegionName"</span>: <span class="string">"Aliyun Shanghai"</span>,</span><br><span class="line">      <span class="attr">"Nodes"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"Name"</span>: <span class="string">"901a"</span>,</span><br><span class="line">          <span class="attr">"RegionID"</span>: <span class="number">901</span>,</span><br><span class="line">          <span class="attr">"DERPPort"</span>: <span class="number">443</span>,</span><br><span class="line">          <span class="attr">"HostName"</span>: <span class="string">"xxxx"</span>,</span><br><span class="line">          <span class="attr">"IPv4"</span>: <span class="string">"xxxx"</span>,</span><br><span class="line">          <span class="attr">"InsecureForTests"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置解析：</p><ul><li><code>HostName</code> 直接填 derper 的公网 IP，即和 <code>IPv4</code> 的值相同。</li><li><code>InsecureForTests</code> 一定要设置为 true，以跳过域名验证。</li></ul><p>你需要把这个 JSON 文件变成 Headscale 服务器可以访问的 URL，比如在 Headscale 主机上搭个 Nginx，或者上传到对象存储（比如阿里云 OSS）。</p><p>接下来还需要修改 Headscale 的配置文件，引用上面的自定义 DERP 的 URL。需要修改的配置项如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/headscale/config.yaml</span></span><br><span class="line"><span class="attr">derp:</span></span><br><span class="line">  <span class="comment"># List of externally available DERP maps encoded in JSON</span></span><br><span class="line">  <span class="attr">urls:</span></span><br><span class="line">  <span class="comment">#  - https://controlplane.tailscale.com/derpmap/default</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">https://xxxxx/derp.json</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Locally available DERP map files encoded in YAML</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># This option is mostly interesting for people hosting</span></span><br><span class="line">  <span class="comment"># their own DERP servers:</span></span><br><span class="line">  <span class="comment"># https://tailscale.com/kb/1118/custom-derp-servers/</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># paths:</span></span><br><span class="line">  <span class="comment">#   - /etc/headscale/derp-example.yaml</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/etc/headscale/derp.yaml</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># If enabled, a worker will be set up to periodically</span></span><br><span class="line">  <span class="comment"># refresh the given sources and update the derpmap</span></span><br><span class="line">  <span class="comment"># will be set up.</span></span><br><span class="line">  <span class="attr">auto_update_enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># How often should we check for DERP updates?</span></span><br><span class="line">  <span class="attr">update_frequency:</span> <span class="string">24h</span></span><br></pre></td></tr></table></figure><p>修改完配置后，重启 headscale 服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart headscale</span><br></pre></td></tr></table></figure><p>在 Tailscale 客户端上使用以下命令查看目前可以使用的 DERP 服务器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale netcheck</span><br><span class="line"></span><br><span class="line">Report:</span><br><span class="line">* UDP: <span class="literal">true</span></span><br><span class="line">* IPv4: yes, 192.168.100.1:49656</span><br><span class="line">* IPv6: no</span><br><span class="line">* MappingVariesByDestIP: <span class="literal">true</span></span><br><span class="line">* HairPinning: <span class="literal">false</span></span><br><span class="line">* PortMapping: UPnP</span><br><span class="line">* Nearest DERP: Home Hangzhou</span><br><span class="line">* DERP latency:</span><br><span class="line">- home: 9.7ms   (Home Hangzhou)</span><br><span class="line">-  hs: 25.2ms  (Huawei Shanghai)</span><br><span class="line">- thk: 43.5ms  (Tencent Hongkong)</span><br></pre></td></tr></table></figure><p>再次查看与通信对端的连接方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale status</span><br><span class="line">                coredns              default      linux   active; direct xxxx:45986; offline, tx 131012 rx 196020</span><br><span class="line">                oneplus-8t           default      android active; relay <span class="string">"home"</span>; offline, tx 211900 rx 22780</span><br><span class="line">                openwrt              default      linux   active; direct 192.168.100.254:41641; offline, tx 189868 rx 4074772</span><br></pre></td></tr></table></figure><p>可以看到这一次 Tailscale 自动选择了一个线路最优的<strong>国内的</strong> DERP 服务器作为中继，可以测试一下延迟：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ tailscale ping 10.1.0.8</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via DERP(home) <span class="keyword">in</span> 30ms</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via DERP(home) <span class="keyword">in</span> 45ms</span><br><span class="line">pong from oneplus-8t (10.1.0.8) via DERP(home) <span class="keyword">in</span> 30ms</span><br></pre></td></tr></table></figure><p>完美！这里的 home 当然是我的家庭宽带，部署方式与上面所说的国内云主机类似，你需要额外开启公网的端口映射（12345/tcp, 3478/udp）。还有一点需要注意的是配置内容：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"Regions"</span>: &#123;</span><br><span class="line">    <span class="attr">"901"</span>: &#123;</span><br><span class="line">      <span class="attr">"RegionID"</span>: <span class="number">901</span>,</span><br><span class="line">      <span class="attr">"RegionCode"</span>: <span class="string">"ali-sh"</span>,</span><br><span class="line">      <span class="attr">"RegionName"</span>: <span class="string">"Aliyun Shanghai"</span>,</span><br><span class="line">      <span class="attr">"Nodes"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"Name"</span>: <span class="string">"901a"</span>,</span><br><span class="line">          <span class="attr">"RegionID"</span>: <span class="number">901</span>,</span><br><span class="line">          <span class="attr">"DERPPort"</span>: <span class="number">443</span>,</span><br><span class="line">          <span class="attr">"HostName"</span>: <span class="string">"xxxx"</span>,</span><br><span class="line">          <span class="attr">"IPv4"</span>: <span class="string">"xxxx"</span>,</span><br><span class="line">          <span class="attr">"InsecureForTests"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"902"</span>: &#123;</span><br><span class="line">      <span class="attr">"RegionID"</span>: <span class="number">902</span>,</span><br><span class="line">      <span class="attr">"RegionCode"</span>: <span class="string">"home"</span>,</span><br><span class="line">      <span class="attr">"RegionName"</span>: <span class="string">"Home Hangzhou"</span>,</span><br><span class="line">      <span class="attr">"Nodes"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"Name"</span>: <span class="string">"902a"</span>,</span><br><span class="line">          <span class="attr">"RegionID"</span>: <span class="number">902</span>,</span><br><span class="line">          <span class="attr">"DERPPort"</span>: <span class="number">12345</span>,</span><br><span class="line">          <span class="attr">"HostName"</span>: <span class="string">"xxxx"</span>,</span><br><span class="line">          <span class="attr">"InsecureForTests"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与国内云主机相比，家庭宽带的配置有两点不同：</p><ul><li>需要删除 <code>IPv4</code> 配置项。因为家用宽带的公网 IP 是动态变化的，所以你需要使用 <strong>DDNS</strong> 来动态解析公网 IP。</li><li><code>HostName</code> 最好填域名，因为你的公网 IP 是动态变化的，没法填写 IP，除非你不停地修改配置文件。填域名也没关系啦，反正不会验证域名的，也不用关心证书的事情，<strong>只要域名能解析到你的公网 IP 即可。</strong></li></ul><h2><span id="防止-derp-被白嫖">防止 DERP 被白嫖</span></h2><p>默认情况下 DERP 服务器是可以被白嫖的，只要别人知道了你的 DERP 服务器的地址和端口，就可以为他所用。如果你的服务器是个小水管，用的人多了可能会把你撑爆，因此我们需要修改配置来防止被白嫖。</p><blockquote><p>特别声明：只有使用域名的方式才可以通过认证防止被白嫖，使用纯 IP 的方式无法防白嫖，你只能小心翼翼地隐藏好你的 IP 和端口，不能让别人知道。</p></blockquote><p>只需要做两件事情：</p><p><strong>1、在 DERP 服务器上安装 Tailscale。</strong></p><p>第一步需要在 DERP 服务所在的主机上安装 Tailscale 客户端，<strong>启动 tailscaled 进程</strong>。</p><p><strong>2、derper 启动时加上参数 <code>--verify-clients</code>。</strong></p><p>本文推荐的是通过容器启动，<a href="https://github.com/yangchuansheng/docker-image/blob/master/derper/Dockerfile" target="_blank" rel="noopener">Dockerfile 内容</a>如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:latest AS builder</span><br><span class="line"></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> org.opencontainers.image.source https://github.com/yangchuansheng/docker-image</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># https://tailscale.com/kb/1118/custom-derp-servers/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go install tailscale.com/cmd/derper@main</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> DEBIAN_FRONTEND=noninteractive</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get install -y --no-install-recommends apt-utils &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get install -y ca-certificates &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mkdir /app/certs</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> DERP_DOMAIN your-hostname.com</span><br><span class="line"><span class="keyword">ENV</span> DERP_CERT_MODE letsencrypt</span><br><span class="line"><span class="keyword">ENV</span> DERP_CERT_DIR /app/certs</span><br><span class="line"><span class="keyword">ENV</span> DERP_ADDR :<span class="number">443</span></span><br><span class="line"><span class="keyword">ENV</span> DERP_STUN true</span><br><span class="line"><span class="keyword">ENV</span> DERP_HTTP_PORT <span class="number">80</span></span><br><span class="line"><span class="keyword">ENV</span> DERP_VERIFY_CLIENTS false</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /go/bin/derper .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> /app/derper --hostname=<span class="variable">$DERP_DOMAIN</span> \</span></span><br><span class="line"><span class="bash">    --certmode=<span class="variable">$DERP_CERT_MODE</span> \</span></span><br><span class="line"><span class="bash">    --certdir=<span class="variable">$DERP_CERT_DIR</span> \</span></span><br><span class="line"><span class="bash">    --a=<span class="variable">$DERP_ADDR</span> \</span></span><br><span class="line"><span class="bash">    --stun=<span class="variable">$DERP_STUN</span>  \</span></span><br><span class="line"><span class="bash">    --http-port=<span class="variable">$DERP_HTTP_PORT</span> \</span></span><br><span class="line"><span class="bash">    --verify-clients=<span class="variable">$DERP_VERIFY_CLIENTS</span></span></span><br></pre></td></tr></table></figure><p>默认情况下 <code>--verify-clients</code> 参数设置的是 <code>false</code>。我们不需要对 Dockerfile 内容做任何改动，只需在容器启动时加上环境变量即可，将之前的启动命令修改一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">🐳  → docker run --restart always \</span><br><span class="line">  --name derper -p 12345:12345 -p 3478:3478/udp \</span><br><span class="line">  -v /root/.acme.sh/xxxx/:/app/certs \</span><br><span class="line">  -e DERP_CERT_MODE=manual \</span><br><span class="line">  -e DERP_ADDR=:12345 \</span><br><span class="line">  -e DERP_DOMAIN=xxxx \</span><br><span class="line">  -e DERP_VERIFY_CLIENTS=<span class="literal">true</span> \</span><br><span class="line">  -d ghcr.io/yangchuansheng/derper:latest</span><br></pre></td></tr></table></figure><p>这样就大功告成了，别人即使知道了你的 DERP 服务器地址也无法使用，但还是要说明一点，即便如此，你也应该尽量不让别人知道你的服务器地址，防止别人有可趁之机。</p><h2><span id="总结">总结</span></h2><p>本文给大家介绍了 STUN 对于辅助 NAT 穿透的意义，科普了几种常见的中继协议，包含 Tailscale 自研的 DERP 协议。最后手把手教大家如何自建私有的 DERP 服务器，并让 Tailscale 使用我们自建的 DERP 服务器。</p><h2><span id="参考资料">参考资料</span></h2><ul><li><a href="https://arthurchiao.art/blog/how-nat-traversal-works-zh/" target="_blank" rel="noopener">NAT 穿透是如何工作的：技术原理及企业级实践</a></li><li><a href="https://tailscale.com/kb/1118/custom-derp-servers/" target="_blank" rel="noopener">Custom DERP Servers</a></li><li><a href="https://tailscale.com/blog/how-tailscale-works/#encrypted-tcp-relays-derp" target="_blank" rel="noopener">Encrypted TCP relays (DERP)</a></li></ul><blockquote><p>本文转载自：「 云原生实验室 」，原文：<a href="https://tinyurl.com/588mv65u" target="_blank" rel="noopener">https://tinyurl.com/588mv65u</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/2022-03-21-11-13-q1TRI3-2022-03-30-ooh4UE.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;目前国家工信部在大力推动三大运营商发展 IPv6，对家用宽带而言，可以使用的 IPv4 公网 IP 会越来越少。有部分地区即使拿到了公网 IPv4 地址，也是个大内网地址，根本不是真正的公网 IP，访问家庭内网的资源将会变得越来越困难。&lt;/p&gt;
&lt;p&gt;部分小伙伴可能会选择使用 frp 等针对特定协议和端口的内网穿透方案，但这种方案还是不够酸爽，无法访问家庭内网任意设备的任意端口。更佳的选择还是通过 VPN 来组建大内网。至于该选择哪种 VPN，毫无疑问肯定是 WireGuard，WireGuard 就是 VPN 的未来。&lt;strong&gt;我已经不止一次向大家推荐使用 WireGuard 了，我累了，不想再讲了，你爱 JB 用辣鸡 OpenVPN 之类的就用吧，你开心就好。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;WireGuard 相比于传统 VPN 的核心优势是没有 VPN 网关，所有节点之间都可以点对点（P2P）连接，也就是我之前提到的&lt;a href=&quot;https://fuckcloudnative.io/posts/wireguard-full-mesh/#1-%E5%85%A8%E4%BA%92%E8%81%94%E6%A8%A1%E5%BC%8F%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%85%8D%E7%BD%AE&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;全互联模式（full mesh）&lt;/a&gt;，效率更高，速度更快，成本更低。&lt;/p&gt;
&lt;p&gt;WireGuard 目前最大的痛点就是上层应用的功能不够健全，因为 WireGuard 推崇的是 Unix 的哲学，WireGuard 本身只是一个内核级别的模块，只是一个数据平面，至于上层的更高级的功能（比如秘钥交换机制，UDP 打洞，ACL 等），需要通过用户空间的应用来实现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Tailscale" scheme="https://www.hi-linux.com/tags/Tailscale/"/>
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/tags/WireGuard/"/>
    
  </entry>
  
  <entry>
    <title>零代码变更，巧用 Reloader 快速实现 Kubernetes 的 Configmap 和 Secret 热更新</title>
    <link href="https://www.hi-linux.com/posts/24272.html"/>
    <id>https://www.hi-linux.com/posts/24272.html</id>
    <published>2022-03-15T01:00:00.000Z</published>
    <updated>2022-03-25T07:06:58.507Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="背景">背景</span></h2><h3><span id="11-配置中心问题">1.1 配置中心问题</span></h3><p>在云原生中配置中心，例如：<code>Configmap</code>和<code>Secret</code>对象，虽然可以进行直接更新资源对象</p><ul><li>对于引用这些有些不变的配置是可以打包到镜像中的，那可变的配置呢？</li><li>信息泄漏，很容易引发安全风险，尤其是一些敏感信息，比如密码、密钥等。</li><li>每次配置更新后，都要重新打包一次，升级应用。镜像版本过多，也给镜像管理和镜像中心存储带来很大的负担。</li><li>定制化太严重，可扩展能力差，且不容易复用。</li></ul><a id="more"></a><h3><span id="12-使用方式">1.2 使用方式</span></h3><p><code>Configmap</code>或<code>Secret</code>使用有两种方式，一种是<code>env</code>系统变量赋值，一种是<code>volume</code>挂载赋值，env写入系统的configmap是不会热更新的，而volume写入的方式支持热更新！</p><ul><li>对于env环境的，必须要滚动更新pod才能生效，也就是删除老的pod，重新使用镜像拉起新pod加载环境变量才能生效。</li><li>对于volume的方式，虽然内容变了，但是需要我们的应用直接监控configmap的变动，或者一直去更新环境变量才能在这种情况下达到热更新的目的。</li></ul><p>应用不支持热更新，可以在业务容器中启动一个sidercar容器，监控configmap的变动，更新配置文件，或者也滚动更新pod达到更新配置的效果。</p><h2><span id="解决方案">解决方案</span></h2><p>ConfigMap 和 Secret 是 Kubernetes 常用的保存配置数据的对象，你可以根据需要选择合适的对象存储数据。通过 Volume 方式挂载到 Pod 内的，kubelet 都会定期进行更新。但是通过环境变量注入到容器中，这样无法感知到 ConfigMap 或 Secret 的内容更新。</p><p>目前如何让 Pod 内的业务感知到 ConfigMap 或 Secret 的变化，还是一个待解决的问题。但是我们还是有一些 Workaround 的。</p><p>如果业务自身支持 reload 配置的话，比如nginx -s reload，可以通过 inotify 感知到文件更新，或者直接定期进行 reload（这里可以配合我们的 readinessProbe 一起使用）。</p><p>如果我们的业务没有这个能力，考虑到不可变基础设施的思想，我们是不是可以采用滚动升级的方式进行？没错，这是一个非常好的方法。目前有个开源工具Reloader，它就是采用这种方式，通过 watch ConfigMap 和 Secret，一旦发现对象更新，就自动触发对 Deployment 或 StatefulSet 等工作负载对象进行滚动升级。</p><h2><span id="reloader简介">reloader简介</span></h2><h3><span id="31-reloader简介">3.1 reloader简介</span></h3><p><code>Reloader</code> 可以观察 ConfigMap 和 Secret 中的变化，并通过相关的 deploymentconfiggs、 deploymentconfiggs、 deploymonset 和 statefulset 对 Pods 进行滚动升级。</p><h3><span id="32-reloader安装">3.2 reloader安装</span></h3><ul><li>helm安装</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add stakater https:&#x2F;&#x2F;stakater.github.io&#x2F;stakater-charts</span><br><span class="line">$ helm repo update</span><br><span class="line">$ helm install stakater&#x2F;reloader</span><br></pre></td></tr></table></figure><ul><li>Kustomize</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -k https:&#x2F;&#x2F;github.com&#x2F;stakater&#x2F;Reloader&#x2F;deployments&#x2F;kubernetes</span><br></pre></td></tr></table></figure><ul><li>资源清单安装</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;stakater&#x2F;Reloader&#x2F;master&#x2F;deployments&#x2F;kubernetes&#x2F;reloader.yaml</span><br><span class="line"></span><br><span class="line"># 在此安装在common-service 名称空间下，</span><br><span class="line">[root@master reloader]# kubectl apply -f reloader.yaml </span><br><span class="line">clusterrole.rbac.authorization.k8s.io&#x2F;reloader-reloader-role created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;reloader-reloader-role-binding created</span><br><span class="line">deployment.apps&#x2F;reloader-reloader created</span><br><span class="line">serviceaccount&#x2F;reloader-reloader created</span><br><span class="line">[root@master reloader]# kubectl get all -n common-service </span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod&#x2F;reloader-reloader-66d46d5885-nx64t   1&#x2F;1     Running   0          15s</span><br><span class="line"></span><br><span class="line">NAME                                READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps&#x2F;reloader-reloader   1&#x2F;1     1            1           16s</span><br><span class="line"></span><br><span class="line">NAME                                           DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps&#x2F;reloader-reloader-66d46d5885   1         1         1       16s</span><br></pre></td></tr></table></figure><ul><li>配置忽略</li></ul><p><code>reloader</code> 能够配置忽略cm或者secrets资源，可以通过配置在reader deploy中的spec.template.spec.containers.args，如果两个都忽略，那就缩小deploy为0，或者不部署reoader。</p><table><thead><tr><th style="text-align:left">Args</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left">–resources-to-ignore=configMaps</td><td style="text-align:left">To ignore configMaps</td></tr><tr><td style="text-align:left">–resources-to-ignore=secrets</td><td style="text-align:left">To ignore secrets</td></tr></tbody></table><h3><span id="33-配置">3.3 配置</span></h3><h4><span id="331-自动更新">3.3.1 自动更新</span></h4><p><code>reloader.stakater.com/search</code> 和 <code>reloader.stakater.com/auto</code> 并不在一起工作。如果你在你的部署上有一个 <a href="http://reloader.stakater.com/auto" target="_blank" rel="noopener">reloader.stakater.com/auto</a> : &quot;true&quot;的注释，该资源对象引用的所有configmap或这secret的改变都会重启该资源，不管他们是否有 <a href="http://reloader.stakater.com/match" target="_blank" rel="noopener">reloader.stakater.com/match</a> : &quot;true&quot;的注释。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    reloader.stakater.com&#x2F;auto: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  template: metadata:</span><br></pre></td></tr></table></figure><h4><span id="332-指定更新">3.3.2 指定更新</span></h4><p>指定一个特定的configmap或者secret，只有在我们指定的配置图或秘密被改变时才会触发滚动升级，这样，它不会触发滚动升级所有配置图或秘密在部署，后台登录或状态设置中使用。</p><p>一个指定deployment资源对象，在引用的configmap或者secret种，只有<code>reloader.stakater.com/match: &quot;true&quot;</code>为true才会出发更新，为false或者不进行标记，该资源对象都不会监视配置的变化而重启。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    reloader.stakater.com&#x2F;search: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br></pre></td></tr></table></figure><p>cm 配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    reloader.stakater.com&#x2F;match: &quot;true&quot;</span><br><span class="line">data:</span><br><span class="line">  key: value</span><br></pre></td></tr></table></figure><h4><span id="333-指定cm">3.3.3 指定cm</span></h4><p>如果一个deployment挂载有多个cm或者的场景下，我们只希望更新特定一个cm后，deploy发生滚动更新，更新其他的cm，deploy不更新，这种场景可以将cm在deploy中指定为单个或着列表实现。</p><p>例如：一个deploy有挂载nginx-cm1和nginx-cm2两个configmap，只想nginx-cm1更新的时候deploy才发生滚动更新，此时无需在两个cm中配置注解，只需要在deploy中写入<code>configmap.reloader.stakater.com/reload:nginx-cm1</code>，其中nginx-cm1如果发生更新，deploy就会触发滚动更新。</p><p>如果多个cm直接用逗号隔开</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># configmap对象</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    configmap.reloader.stakater.com&#x2F;reload: &quot;nginx-cm1&quot;</span><br><span class="line">spec:</span><br><span class="line">  template: metadata:</span><br><span class="line"></span><br><span class="line"># secret对象</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    secret.reloader.stakater.com&#x2F;reload: &quot;foo-secret&quot;</span><br><span class="line">spec:</span><br><span class="line">  template: metadata:</span><br></pre></td></tr></table></figure><blockquote><p>无需在cm或secret中添加注解，只需要在引用资源对象中添加注解即可。</p></blockquote><h2><span id="测试">测试</span></h2><h3><span id="41-deploy">4.1 deploy</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">   # reloader.stakater.com&#x2F;auto: &quot;true&quot;</span><br><span class="line">    reloader.stakater.com&#x2F;search: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    run: nginx</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">        volumeMounts:</span><br><span class="line">        # 必须匹配volumes的名称,定义configmap</span><br><span class="line">        - name: nginx-cm</span><br><span class="line">          mountPath: &#x2F;data&#x2F;cfg</span><br><span class="line">          readOnly: true</span><br><span class="line">      volumes:</span><br><span class="line">      # 定义逻辑卷的名称</span><br><span class="line">      - name: nginx-cm</span><br><span class="line">        configMap:</span><br><span class="line">          # 使用configmap资源的名称</span><br><span class="line">          name: nginx-cm</span><br><span class="line">          items:</span><br><span class="line">          # 使用configmap中到那个key</span><br><span class="line">          - key: config.yaml</span><br><span class="line">            # 使用configmap中到key映射到容器中到文件名称</span><br><span class="line">            path: config.yaml</span><br><span class="line">            mode: 0644</span><br></pre></td></tr></table></figure><h3><span id="42-configmap">4.2 configmap</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  config.yaml: |</span><br><span class="line">    # project settings</span><br><span class="line"></span><br><span class="line">    # go2cloud_api service config</span><br><span class="line">    DEFAULT_CONF:</span><br><span class="line">      port: 8888</span><br><span class="line">    # data disk api</span><br><span class="line">    UNITTEST_TENCENT_ZONE: ap-chongqing-1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-cm</span><br><span class="line">  annotations:</span><br><span class="line">    reloader.stakater.com&#x2F;match: &quot;true&quot;</span><br></pre></td></tr></table></figure><h3><span id="43-测试">4.3 测试</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master ns-default]# kubectl  get po</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-68c9bf4ff7-9gmg6   1&#x2F;1     Running   0          10m</span><br><span class="line">[root@master ns-default]# kubectl  get cm</span><br><span class="line">NAME       DATA   AGE</span><br><span class="line">nginx-cm   1      28m</span><br><span class="line"># 更新cm内容</span><br><span class="line">[root@master ns-default]# kubectl edit cm nginx-cm </span><br><span class="line">configmap&#x2F;nginx-cm edited</span><br><span class="line"># 查看po发生了滚动更新，重新加载配置文件</span><br><span class="line">[root@master ns-default]# kubectl get po</span><br><span class="line">NAME                     READY   STATUS              RESTARTS   AGE</span><br><span class="line">nginx-66c758b548-9dllm   0&#x2F;1     ContainerCreating   0          4s</span><br><span class="line">nginx-68c9bf4ff7-9gmg6   1&#x2F;1     Running             0          10m</span><br></pre></td></tr></table></figure><h2><span id="reloader-使用注意事项">Reloader 使用注意事项</span></h2><ul><li>Reloader 为全局资源对象，建议部署在一个公共服务的ns下，然后其他ns也可以正常使用reloader特性。</li><li><a href="http://Reloader.stakater.com/auto" target="_blank" rel="noopener">Reloader.stakater.com/auto</a> : 如果配置configmap或者secret在 deploymentconfigmap/deployment/daemonsets/Statefulsets</li><li><a href="http://secret.reloader.stakater.com/reload" target="_blank" rel="noopener">secret.reloader.stakater.com/reload</a> 或者 <a href="http://configmap.reloader.stakater.com/reload" target="_blank" rel="noopener">configmap.reloader.stakater.com/reload</a> 注释中被使用，那么 true 只会重新加载 pod，不管使用的是 configmap 还是 secret。</li><li><a href="http://reloader.stakater.com/search" target="_blank" rel="noopener">reloader.stakater.com/search</a> 和 <a href="http://reloader.stakater.com/auto" target="_blank" rel="noopener">reloader.stakater.com/auto</a> 不能同时使用。如果你在你的部署上有一个 <a href="http://reloader.stakater.com/auto" target="_blank" rel="noopener">reloader.stakater.com/auto</a> : &quot;true&quot;的注释，那么它总是会在你修改了 configmaps 或者使用了机密之后重新启动，不管他们是否有 <a href="http://reloader.stakater.com/match" target="_blank" rel="noopener">reloader.stakater.com/match</a> : &quot;true&quot;的注释。</li></ul><h2><span id="反思">反思</span></h2><p>Reloader通过 watch ConfigMap 和 Secret，一旦发现对象更新，就自动触发对 Deployment 或 StatefulSet 等工作负载对象进行滚动升级。</p><p>如果我们的应用内部没有去实时监控配置文件，利用该方式可以非常方便的实现配置的热更新。</p><h2><span id="参考链接">参考链接</span></h2><ul><li><a href="https://github.com/stakater/Reloader" target="_blank" rel="noopener">https://github.com/stakater/Reloader</a></li></ul><blockquote><p>本文转载自：「 掘金 」，原文：<a href="https://tinyurl.com/6w4ukjrb" target="_blank" rel="noopener">https://tinyurl.com/6w4ukjrb</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;h3 id=&quot;1-1-配置中心问题&quot;&gt;1.1 配置中心问题&lt;/h3&gt;
&lt;p&gt;在云原生中配置中心，例如：&lt;code&gt;Configmap&lt;/code&gt;和&lt;code&gt;Secret&lt;/code&gt;对象，虽然可以进行直接更新资源对象&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于引用这些有些不变的配置是可以打包到镜像中的，那可变的配置呢？&lt;/li&gt;
&lt;li&gt;信息泄漏，很容易引发安全风险，尤其是一些敏感信息，比如密码、密钥等。&lt;/li&gt;
&lt;li&gt;每次配置更新后，都要重新打包一次，升级应用。镜像版本过多，也给镜像管理和镜像中心存储带来很大的负担。&lt;/li&gt;
&lt;li&gt;定制化太严重，可扩展能力差，且不容易复用。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何在命令行快速获取公网动态 IP 地址</title>
    <link href="https://www.hi-linux.com/posts/39230.html"/>
    <id>https://www.hi-linux.com/posts/39230.html</id>
    <published>2022-03-04T01:00:00.000Z</published>
    <updated>2022-03-25T06:57:04.579Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>如何确定公网IP地址是一个让很多家用宽带朋友们经常遇到的问题，毕竟固定IP地址总是价格不菲因而不适用于家庭宽带，而我们的电信宽带运营商（ISP）往往给我们分配的是动态IP地址，之所以称作为动态IP地址，是因为每次拨号得到的IP地址可能会不一样，还有更骚的操作就是有的运营商每天或不定期在某个时间刷新IP地址池，这样已经获得的IP地址将会被强制释放并分配新的IP地址。</p><p>这对于我们一些运行在家用带宽下的服务带来了影响——需要重新设置服务端 IP 地址，比如监控、网络存储等等，这时候 DDNS 就发挥作用的，现在大部分路由器内置了 DDNS 客户端，比如花生壳等服务客户端，但是这些客户端存在收费、不稳定以及刷新间隔小等问题，对于自己有域名的朋友可以使用 DNS 服务商的 API 自己实现 IP 更新操作，比如阿里云（Aliyun）、Cloudflare 均可以实现。</p><p>对于 DDNS 如何使用 API 更新不在本文叙述范围内，但调用 API 有个关键参数那就是公网IP地址，如何获取当前运营商分配的公网 IP地址呢？除了问路由器外（打开路由器管理界面找到 WAN 口信息）我们还可以通过一些网络服务进行检测。</p><a id="more"></a><h2><span id="使用-shell-命令获取公网-ip-地址">使用 Shell 命令获取公网 IP 地址</span></h2><h3><span id="浏览器方式">浏览器方式</span></h3><p>如果我们使用浏览器打开这个地址<a href="https://checkip.amazonaws.com/" target="_blank" rel="noopener">checkip.amazonaws.com</a>你就会发现你的公网IP地址赫然在目，互联网上的服务器总是能够知道是什么 IP地址的客户端发起了连接，当然就可以通过这种方式获取公网 IP，同样功能的网站有很多，这里列举部分我收集到的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;checkip.amazonaws.com</span><br><span class="line">https:&#x2F;&#x2F;api.ipify.org</span><br><span class="line">https:&#x2F;&#x2F;ifconfig.me&#x2F;ip</span><br><span class="line">https:&#x2F;&#x2F;icanhazip.com</span><br><span class="line">https:&#x2F;&#x2F;ipinfo.io&#x2F;ip</span><br><span class="line">https:&#x2F;&#x2F;ipecho.net&#x2F;plain</span><br><span class="line">https:&#x2F;&#x2F;checkipv4.dedyn.io</span><br></pre></td></tr></table></figure><h3><span id="curl-方式">cURL 方式</span></h3><p>在命令行下我们当然不能为这点小事随便启动浏览器，我们可以请出另外一个功能强大的工具，那就是<a href="https://curl.se/" target="_blank" rel="noopener">curl</a>，cURL 是一个利用URL语法在命令行下工作的文件传输工具，关于cURL的快速用法可以参考阮一峰的网络日志<a href="https://www.ruanyifeng.com/blog/2019/09/curl-reference.html" target="_blank" rel="noopener">《curl 的用法指南》</a>，这里不再详述，最简单的用法就是<code>curl 你要请求的网址</code>，比如<code>curl checkip.amazonaws.com</code>。</p><h3><span id="使用-dig-命令">使用 dig 命令</span></h3><p>首次在别人脚本中看到这个方式获取公网IP觉得比较新奇，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dig +short myip.opendns.com @resolver1.opendns.com</span><br></pre></td></tr></table></figure><p>这个是由OpenDNS提供的服务，如果你的主机上没有安装dig命令，对于Debian系列系统可以通过<code>apt-get install dnsutils</code>安装，这个命令的原理是指定<code>resolver1.opendns.com</code>为域名<code>myip.opendns.com</code>的解析服务器，为什么要指定，主要是避免 DNS 下游服务器缓存，另外这个指定的解析服务器被 OpenDNS 进行了特殊配置，其始终将域名<code>myip.opendns.com</code>解析为发起 DNS 请求的客户端 IP 地址，这样也就实现了查找公网 IP的功能。</p><p>这个和 cURL 方式比有什么优势呢？当然是数据量更小传输更快，毕竟使用 cURL 发起 HTTP 请求必然会导致协议头等无关信息的交换，如果启用了 HTTPS/TLS 那么还要进行加密协商，效率会比较低，当然这种方式的缺点就是 DNS 查询容易被运营商审计和过滤，稳定性略差，不过我测试下来除了偶尔查询失败外其余情况是完全 OK 的。</p><h2><span id="使用-shell-脚本获取公网-ip-地址">使用 Shell 脚本获取公网 IP 地址</span></h2><p>至此我有个新的主意，那就是首先采用 dig 命令快速检索公网 IP 地址，如果失败则切换到 cURL 的方式，为了避免 cURL 单一服务器失败，采用轮询或者随机的方式，尽可能提高成功率。</p><p>使用 Bash Shell 脚本 do it，比如获取公网 IPv4 的脚本如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This script try to ensure gets the current IP address (as assigned by the ISP) from</span></span><br><span class="line"><span class="comment"># OpenDNS and other online services as fallbacks</span></span><br><span class="line"></span><br><span class="line">hosts=(<span class="string">"checkip.amazonaws.com"</span> <span class="string">"api.ipify.org"</span> <span class="string">"ifconfig.me/ip"</span> <span class="string">"icanhazip.com"</span> <span class="string">"ipinfo.io/ip"</span> <span class="string">"ipecho.net/plain"</span> <span class="string">"checkipv4.dedyn.io"</span>)</span><br><span class="line"></span><br><span class="line">CURL=`<span class="built_in">which</span> curl`</span><br><span class="line">DIG=`<span class="built_in">which</span> dig`</span><br><span class="line"></span><br><span class="line">check=$(<span class="variable">$DIG</span> +short myip.opendns.com @resolver1.opendns.com A) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! $? -eq 0 ] || [ -z <span class="string">"<span class="variable">$check</span>"</span> ] || [[ ! <span class="variable">$check</span> =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Unable to get your public IP address by OpenDNS service, try to another way."</span></span><br><span class="line">    count=<span class="variable">$&#123;#hosts[@]&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> [ -z <span class="string">"<span class="variable">$check</span>"</span> ] &amp;&amp; [[ <span class="variable">$count</span> -ne 0 ]]; <span class="keyword">do</span></span><br><span class="line">        selectedhost=<span class="variable">$&#123;hosts[ $RANDOM % $&#123;#hosts[@]&#125;</span> ]&#125;</span><br><span class="line">        check=$(<span class="variable">$CURL</span> -4s https://<span class="variable">$selectedhost</span> | grep <span class="string">'[^[:blank:]]'</span>) &amp;&amp; &#123;</span><br><span class="line">            <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$check</span>"</span> ] &amp;&amp; [[ <span class="variable">$check</span> =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; <span class="keyword">then</span></span><br><span class="line">                <span class="built_in">break</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                check=<span class="string">""</span></span><br><span class="line">                count=$(expr <span class="variable">$count</span> - 1)</span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"The host <span class="variable">$selectedhost</span> returned an invalid IP address."</span></span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">        &#125; || &#123;</span><br><span class="line">            check=<span class="string">""</span></span><br><span class="line">            count=$(expr <span class="variable">$count</span> - 1)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"The host <span class="variable">$selectedhost</span> did not respond."</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$check</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Unable to get your public IP address. Please check your internet connection."</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Your public IP address is <span class="variable">$check</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure><p>上述脚本可以看出首先我使用 dig 方式查询 OpenDNS，如果查询失败或者返回为空或者不是 IP 地址，那么进入cURL模式，这里将可用服务器添加到 hosts 列表，并且随机抽取一个进行cURL，这里使用了<code>curl -4s</code>参数<code>-4s</code>分别表示仅使用 IPv4 方式连接（确保获取 IPv4 地址）和抑制进度条和错误信息，如果抽取的服务发生错误，那么进入循环再抽取一个，直到循环满最大 hosts 数停止。</p><h2><span id="总结">总结</span></h2><p>大部分脚本甚至一些程序仅使用了一种方式获取公网 IP，但是互联网上这些服务往往是不可靠的，如果你所选用的服务出现故障，那么将会影响到你后续业务的开展，所以本文的核心思想还是多个备份，另外对于 cURL 方式采用随机确保所谓的“负载平衡”，避免 fallback 时过度请求某个服务导致 IP 被 Ban。</p><blockquote><p>本文转载自：「 王晔的博客 」，原文：<a href="https://tinyurl.com/2p95wpue" target="_blank" rel="noopener">https://tinyurl.com/2p95wpue</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何确定公网IP地址是一个让很多家用宽带朋友们经常遇到的问题，毕竟固定IP地址总是价格不菲因而不适用于家庭宽带，而我们的电信宽带运营商（ISP）往往给我们分配的是动态IP地址，之所以称作为动态IP地址，是因为每次拨号得到的IP地址可能会不一样，还有更骚的操作就是有的运营商每天或不定期在某个时间刷新IP地址池，这样已经获得的IP地址将会被强制释放并分配新的IP地址。&lt;/p&gt;
&lt;p&gt;这对于我们一些运行在家用带宽下的服务带来了影响——需要重新设置服务端 IP 地址，比如监控、网络存储等等，这时候 DDNS 就发挥作用的，现在大部分路由器内置了 DDNS 客户端，比如花生壳等服务客户端，但是这些客户端存在收费、不稳定以及刷新间隔小等问题，对于自己有域名的朋友可以使用 DNS 服务商的 API 自己实现 IP 更新操作，比如阿里云（Aliyun）、Cloudflare 均可以实现。&lt;/p&gt;
&lt;p&gt;对于 DDNS 如何使用 API 更新不在本文叙述范围内，但调用 API 有个关键参数那就是公网IP地址，如何获取当前运营商分配的公网 IP地址呢？除了问路由器外（打开路由器管理界面找到 WAN 口信息）我们还可以通过一些网络服务进行检测。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Shell" scheme="https://www.hi-linux.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>如何让一个创业公司优雅的进行云原生之旅</title>
    <link href="https://www.hi-linux.com/posts/7852.html"/>
    <id>https://www.hi-linux.com/posts/7852.html</id>
    <published>2022-02-27T01:00:00.000Z</published>
    <updated>2022-03-25T06:57:04.581Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="前言">前言</span></h2><p>IT是一座道场！</p><p><img src="https://img.hi-linux.com/staticfile/1617155792725-55dca530-a3c3-4d4a-9ae6-3fad2df5755e-2021-09-26-eAvwbl.png" alt></p><p>2020年5月中旬本科毕业后，进入严格意义上的第一家公司。当时带我的是阿里云的MVP，也是公司的CTO，跟着他(石老大)学到了很多很多，带领我经过了入道(机会，不是人人都有，请感恩，给你机会和帮助的人）。三个月后他离职了，感谢石老大，正是他的离职给了我独自闯道的机会。</p><p>2020年9月开始进入了闯道(孤独，痛苦和煎熬会时常与你共舞)、修道(别忘了，给风雨中的自己一个鼓励)、悟道(认知和思想，是拉开人与人之间的重要差距)阶段。可以说自石老大走后，我的任务都是自我安排，技术都是自我驱动实现的。</p><p>2019年7月离开学校时，告诉自己：我的路是一条追逐云原生的路。自2018年8月接触Kubernetes时就深深爱上了这条路。</p><p>2020年6月初进入公司后，实实在在感受到了创业公司的集群环境之乱(只有前端业务Kubernetes化且测试和生产通过namespace区分、生产Kubernetes资源特别低且服务副本数只有2个、gitlab代码仓库是部署在Kubernetes环境上的、权限混乱等)。提出了一些自己的解决方案：<a href="https://www.cnblogs.com/zisefeizhu/p/13692782.html" target="_blank" rel="noopener">https://www.cnblogs.com/zisefeizhu/p/13692782.html</a></p><a id="more"></a><p>2020年6月构建以ELFK为技术核心的日志系统(只收集网关日志即nginx-ingress日志为唯一收集源)。</p><p>2020年7月围绕业务全面Kubernetes化展开，主导了业务从一到零再到一的过程。</p><p>2020年8月和9月忙于集群和CI|CD重构。新增了测试环境、预发环境，将网关由nginx-ingress改为kong-ingress，将gitlab从Kubernetes环境中剥离出来，借助cert-manager实现证书的自动申请和续签，增加堡垒机更正权限混乱问题，使用gitlab-runner实现多Kubernetes集群的自动化部署等。</p><p>2020年10月专攻于&quot;监控预警系统&quot;，实现三个纬度的监控，期间第一次参与并主导私有化项目的部署。</p><p>2020年11月以&quot;ISTIO服务治理&quot;为重心，在测试环境验证了连接、安全、流控、可视，期间开发了envoyfilter插件对接鉴权服务。</p><p>2020年12月和1月围绕&quot;kubernetes下微服务的日志系统&quot;展开，实现了多Kubernetes集群服务和裸机服务的日志统一到一个管理平台。</p><p>2021年1月和2月实现了将预发环境的kong-ingress过度到istio。并对接了证书服务、监控预警系统和日志系统。</p><p>2021年3月忙于私有化部署和istio准备上生产环境的验证。</p><p>2021年4月忙于旧服务器治理、私有化部署、聚石塔方面的有关工作。</p><p>2021年5月忙于istio生产启用、聚石塔和私有化部署的工作。</p><p>在公司近1年中创建了13个代码仓库，写了130余篇技术文档，</p><p>2020年6月初经过规划了一张&quot;基于KUBERNETES的企业级集群架构&quot;，经过和CTO及向有关人员的阐述，准备实施此架构</p><p><img src="https://img.hi-linux.com/staticfile/1617176613827-8f78dfb2-78b9-411e-9879-6461df0a20f7-2021-09-26-Yqe8Vf.png" alt></p><p>此架构规划了三个集群环境：生产环境、预发环境、测试环境</p><p>此架构除业务和项目外还增加了边界服务：统一日志管理平台、监控预警系统、链路追踪、统一管理平台、证书自动续签、流控等，下面将重点围绕此展开</p><h2><span id="基于-kubernetes-的企业级集群架构重点部分浅解">基于 KUBERNETES 的企业级集群架构重点部分浅解</span></h2><h3><span id="重构集群架构-业务全面容器化">重构集群架构、业务全面容器化</span></h3><p>这是一个从一到零再到一的过程，刚毕业即接触此类项目，实属幸运</p><p>大致重构步骤如下：</p><blockquote><ul><li>根据原有业务设计容器化架构方案；</li><li>新增堡垒机Jumpserver；</li><li>制作前后端业务镜像；</li><li>新增测试环境Kubernetes集群、预发环境Kubernetes集群、改造原生产环境Kubernetes集群；</li><li>借助Gitlab-Runner、Gitlab、Kustomize等实现多集群的CI|CD；</li><li>和有关同事一起定义前后端日志字段和输出形式；</li><li>协助后端团队微调原裸机业务源码；</li><li>借助Rancher实现对多Kubernetes集群的统一管理；</li><li>用Cert-Manager实现域名证书的自动申请和续期；</li><li>写Shell脚本对Gitlab备份进行检查、裸机服务备份进行检查、对域名有效期进行检查。</li></ul></blockquote><h3><span id="统一日志管理平台">统一日志管理平台</span></h3><p>此项目应是我近一年的最大收获了，思想上。</p><p>大致实现思路：多kubernetes集群的namespace绝对不能重复，elasticsearch、kibana、logstash、kafka独立于集群环境外且共用一套，filebeat、metricbeat、kube-state-metrics需要在每个kubernetes集群中都存在一套、metricbeat和tag需要标准清晰明了、日志以json格式输出且不允许多行日志出现</p><p>一提之举在：</p><blockquote><ul><li>实现了多集群、多环境日志的统一化管理</li></ul></blockquote><h3><span id="cicd">CI|CD</span></h3><p>基于我司目前的研发现状，选择的自动化部署工具为<code>gitlab-runner</code>。代码仓库创建规范可以参考：<a href="https://www.cnblogs.com/zisefeizhu/p/13621797.html%E3%80%82" target="_blank" rel="noopener">https://www.cnblogs.com/zisefeizhu/p/13621797.html。</a></p><p>大致实现思路：研发提交代码代码到特定分支(分支区分环境，生产分支需要项目总监merge) --&gt; 镜像打包(由预发Kubernetes集群的一台特定节点执行) --&gt; 根据<code>.gitlab-ci.yml</code> 规则进行业务pod化。</p><p>一提之举在：</p><blockquote><ul><li>通过分支区分环境</li><li>镜像打包只在一台预发环境的特定节点执行，减少因打包镜像而对生产环境带来的波动，且可以存在镜像利用</li><li>大量借助内置变量通过提前写的脚本提高Kubernetes 部署部分的资源清单的重复可用性</li></ul></blockquote><h3><span id="监控预警系统">监控预警系统</span></h3><p>实现三个纬度(业务监控、应用监控、操作系统)的监控预警系统。</p><p>其中业务监控主要是研发提供一些业务指标、业务数据。对其增上率、错误率等进行告警或展示，需要提前定义规范甚至埋点。</p><p>应用程序的监控主要有探针和内省。其中探针主要是从外部探测应用程序的特征，比如监听端口是否有响应。内省主要是查看应用程序内部的内容，应用程序通过检测并返回其内部的状态、内部的组件，事务和性能等度量，它可以直接将事件、日志和指标直接发送给监控工具。</p><p>操作系统主要是监控主要组件的使用率、饱和度以及错误，比如CPU的使用率、CPU的负载等。</p><p>一提之举在：</p><blockquote><ul><li>三个纬度</li><li>裸机也进行监控</li><li>windows也进行监控</li></ul></blockquote><h3><span id="服务治理">服务治理</span></h3><p>随着业务的不断微服务化、对于服务的运行的失控感越来越强、且对东西向流量的管理成为了急需解决的痛点、而Kong网关的ab test是付费版的开箱即用功能，而我司恰恰开始需要此功能。基于上服务治理开始进行视野。</p><p>我司对于服务治理的使用应算中度依赖，主要使用到如下点：</p><blockquote><ul><li>负载均衡：基础服务使用最少连接策略，业务层服务使用一致性哈希负载均衡。</li><li>健康检测：输出健康检测具体配置方案。（如：基础移出时间30秒，10秒内出现3次错误移出，检测时间间隔为10秒…）</li><li>连接池：创建连接池，每个实例最大处理请求数为10，每个连接处理2个请求后关闭，重试次数为3次，连接超时时间为500ms。</li><li>熔断策略：根据健康检测和连接池策略实现熔断策略</li><li>重试策略：最多重试3次，每次调用超时为2秒。</li><li>限流策略：后期用户数提高后再实行。</li><li>链路追踪</li></ul></blockquote><p>一提之举在：</p><blockquote><ul><li>基于envoyfilter 和lua开发对接鉴权服务和istio</li></ul></blockquote><h3><span id="私有化部署">私有化部署</span></h3><p>因我司主打产品为3D编辑器，数据保密性要求极高，大型企业更在意数据由自己掌握，所以在这近一年中做了好几个私有化部署项目。</p><p>在做私有化部署项目中学到了很多：</p><blockquote><ul><li>业务：需要知道客户需求牵扯到的服务有那些，作出路由规划表。</li><li>集群：根据客户的需求，估算出资源需求。</li><li>沟通：需要和客户(基本是非技术类)、我司运营等人于啊进行技术上的沟通，需要将繁琐的技术通俗化。</li><li>时间：根据客户的规定时间和我司的实际现状规划出准备、部署、测试、交付的时间段，考验项目时间把握度。</li><li>协调：在项目部署中难免会出现一些配置类的问题，需要后端人员介入。</li></ul></blockquote><p>一提之举在：</p><blockquote><ul><li>私有化部署严重考验对业务、集群的熟悉度，是考验一个运维人员的技能修养的。</li></ul></blockquote><h2><span id="总结">总结</span></h2><p>始终认为IT是一座道场，修道，修道，修一座自己的道场。在毕业的近1年中，经历了入道、闯道、修道阶段，到目前的悟道阶段。</p><p>需要提升和掌握的知识还有很多，技术没有止境，依然在路上。云原生是一条充满机遇的路，坚持与不断追求才能翻过一座又一座高山。</p><h2><span id="展望">展望</span></h2><p>悟道(认知和思想，是拉开人与人之间的重要差距)</p><p>试道(出道下山、世界这么大)</p><p>围绕 Kubernetes 展开云原生的涉猎，更快的参与二开和社区。</p><p>过手如登山，一步一重天</p><blockquote><p>本文转载自：「 博客园 」，原文：<a href="https://tinyurl.com/hc9vn8hf" target="_blank" rel="noopener">https://tinyurl.com/hc9vn8hf</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;IT是一座道场！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/1617155792725-55dca530-a3c3-4d4a-9ae6-3fad2df5755e-2021-09-26-eAvwbl.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2020年5月中旬本科毕业后，进入严格意义上的第一家公司。当时带我的是阿里云的MVP，也是公司的CTO，跟着他(石老大)学到了很多很多，带领我经过了入道(机会，不是人人都有，请感恩，给你机会和帮助的人）。三个月后他离职了，感谢石老大，正是他的离职给了我独自闯道的机会。&lt;/p&gt;
&lt;p&gt;2020年9月开始进入了闯道(孤独，痛苦和煎熬会时常与你共舞)、修道(别忘了，给风雨中的自己一个鼓励)、悟道(认知和思想，是拉开人与人之间的重要差距)阶段。可以说自石老大走后，我的任务都是自我安排，技术都是自我驱动实现的。&lt;/p&gt;
&lt;p&gt;2019年7月离开学校时，告诉自己：我的路是一条追逐云原生的路。自2018年8月接触Kubernetes时就深深爱上了这条路。&lt;/p&gt;
&lt;p&gt;2020年6月初进入公司后，实实在在感受到了创业公司的集群环境之乱(只有前端业务Kubernetes化且测试和生产通过namespace区分、生产Kubernetes资源特别低且服务副本数只有2个、gitlab代码仓库是部署在Kubernetes环境上的、权限混乱等)。提出了一些自己的解决方案：&lt;a href=&quot;https://www.cnblogs.com/zisefeizhu/p/13692782.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/zisefeizhu/p/13692782.html&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="云原生" scheme="https://www.hi-linux.com/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>使用 Nginx 三方扩展 ngx_waf 快速实现一个高性能的 Web 应用防火墙</title>
    <link href="https://www.hi-linux.com/posts/36520.html"/>
    <id>https://www.hi-linux.com/posts/36520.html</id>
    <published>2022-02-23T01:00:00.000Z</published>
    <updated>2022-02-23T05:13:47.620Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>ngx_waf：方便且高性能的 Nginx 防火墙模块</strong></p></blockquote><p>缓存策略为 <code>LRU</code>，<code>IP</code> 检查和 <code>CC</code> 防御花费常数时间，其它的检查花费 <code>O(nm)</code> 的时间，其中 <code>n</code> 是相关规则的条数，<code>m</code> 为执行正则匹配的时间复杂度，但是每次检查过后会自动缓存本次检查的结果，下次检查相同的目标时就可以使用缓存而不是检查全部的规则。不会缓存 <code>POST</code> 请求体的检查结果。</p><a id="more"></a><h2><span id="工具特点">工具特点</span></h2><blockquote><p><strong>介绍了该工具的主要特点以及核心功能！</strong></p></blockquote><p>该 <code>Nginx</code> 的第三方扩展工具，可以防御 <code>CC</code> 攻击(超出限制后自动拉黑对应 <code>IP</code> 一段时间或者使用验证码做人机识别)，可以支持多种黑白名单(<code>IP</code>/<code>POST</code>/<code>URL</code>/<code>UA</code>等等)，还可以提供防护 <code>SQL</code> 注入和 <code>XSS</code> 工具。</p><ul><li>使用简单<ul><li>配置文件和规则文件书写简单，可读性强</li></ul></li><li>基础防护<ul><li>如 <code>IP</code> 或 <code>IP</code> 网段的黑白名单、<code>URI</code> 黑白名单和请求体黑名单等</li></ul></li><li>高性能<ul><li>使用高效的 <code>IP</code> 检查算法和缓存机制，支持 <code>IPV4</code> 和 <code>IPV6</code></li></ul></li><li>高级防护<ul><li>兼容 <a href="https://github.com/SpiderLabs/ModSecurity" target="_blank" rel="noopener"><code>ModSecurity</code></a> 的规则，你可以使用 <code>OWASP</code> 的核心规则库</li></ul></li><li>友好爬虫验证<ul><li>支持验证 <code>Google</code>、<code>Bing</code>、<code>Baidu</code> 和 <code>Yandex</code> 的爬虫并自动放行，避免错误拦截，主要是基于 <code>User-Agent</code> 和 <code>IP</code> 的识别规则</li></ul></li><li>验证码<ul><li>支持三种验证码：<code>hCaptcha</code>、<code>reCAPTCHAv2</code> 和 <code>reCAPTCHAv3</code></li></ul></li></ul><h2><span id="模块安装">模块安装</span></h2><blockquote><p><strong>第三方模块我们应该怎么安装呢？</strong></p></blockquote><p><code>Nginx</code> 提供两种安装模块的方式，即「静态链接」和「动态加载」，通过两种方式安装的模块也分别称为「静态模块」和「动态模块」，可以通过运行脚本 <code>assets/guide.sh</code> 来选择使用静态模块还是动态模块。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行如下命令</span></span><br><span class="line">$ sh assets/guide.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果输出下面这行，则建议使用动态模块</span></span><br><span class="line"><span class="comment"># It is recommended that you use dynamic modules.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果输出下面这行，则建议使用静态模块</span></span><br><span class="line"><span class="comment"># It is recommended that you use static modules.</span></span><br></pre></td></tr></table></figure><ul><li><strong>[1] 静态模块</strong></li></ul><p>编译安装一个新的模块需要知道当前的 <code>Nginx</code> 的 <code>configure</code> 脚本的参数，您可以通过运行 <code>nginx -V</code> 来获取，务必记住 <code>configure arguments:</code> 后面的内容。安装静态模块需要重新编译整个 <code>Nginx</code>，花费的时间相对于安装动态模块比较长。如果不想在替换二进制文件时，关闭 <code>Nginx</code> 服务的话，可以参考<a href="https://nginx.org/en/docs/control.html" target="_blank" rel="noopener">官方文档的热部署方案</a>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载对应的Nginx版本</span></span><br><span class="line"><span class="comment"># http://nginx.org/en/download.html</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line">$ wget https://nginx.org/download/nginx-1.20.1.tar.gz</span><br><span class="line">$ tar -zxf nginx-1.20.1.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用稳定版的源码</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line">$ git <span class="built_in">clone</span> -b lts https://github.com/ADD-SP/ngx_waf.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行配置脚本</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/nginx-1.20.1</span><br><span class="line">$ ./configure ARG --add-module=/usr/<span class="built_in">local</span>/src/ngx_waf</span><br><span class="line">$ sed -i <span class="string">'s/^\(CFLAGS.*\)/\1 \</span></span><br><span class="line"><span class="string">    -fstack-protector-strong -Wno-sign-compare/'</span> \</span><br><span class="line">    objs/Makefile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译(非并行/并行)</span></span><br><span class="line">$ make</span><br><span class="line">$ make -j$(nproc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换Nginx二进制文件(假设已经安装过)</span></span><br><span class="line">$ cp objs/nginx /usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 动态模块 - 下载预构建的模块</strong></li></ul><p>通过执行脚本 <code>assets/download.sh</code> 来下载动态模块。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于nginx-1.20.1的LTS版的模块</span></span><br><span class="line">$ sh assets/download.sh 1.20.1 lts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于nginx-1.20.1的最新版的模块</span></span><br><span class="line">$ sh assets/download.sh 1.20.1 current</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行成功后会有如下输出</span></span><br><span class="line">checking <span class="keyword">for</span> <span class="built_in">command</span> ... yes</span><br><span class="line">checking <span class="keyword">for</span> libc implementation ... yes</span><br><span class="line"> + GNU C libary</span><br><span class="line">Pulling remote image addsp/ngx_waf-prebuild:ngx-1.20.1-module-beta-glibc</span><br><span class="line">......</span><br><span class="line">Download complete!</span><br></pre></td></tr></table></figure><p>如果看到 <code>Download complete!</code> 的话，则说明下载成功，模块会被保存在当前目录下。你可以将其拷贝到一个目录下，然后在 <code>nginx.conf</code> 的顶部添加一行。然后关闭 <code>Nginx</code> 服务并运行 <code>nginx -t</code>。如果没有出错则说明模块被正常加载，反之则说明您的 <code>Nginx</code> 不支持预构建的模块，请编译安装模块。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_module &quot;&#x2F;path&#x2F;to&#x2F;ngx_http_waf_module.so&quot;;</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 动态模块 - 编译动态模块</strong></li></ul><p>编译安装动态模块并不需要重新编译整个 <code>Nginx</code>，只需要重新编译所有的模块，所以速度相对静态模块快一些，这也是本文档推荐的方式。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载对应的Nginx版本</span></span><br><span class="line"><span class="comment"># http://nginx.org/en/download.html</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line">$ wget https://nginx.org/download/nginx-1.20.1.tar.gz</span><br><span class="line">$ tar -zxf nginx-1.20.1.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用稳定版的源码</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line">$ git <span class="built_in">clone</span> -b lts https://github.com/ADD-SP/ngx_waf.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行配置脚本</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/nginx-1.20.1</span><br><span class="line">$ ./configure --add-dynamic-module=/usr/<span class="built_in">local</span>/src/ngx_waf --with-compat</span><br><span class="line">$ sed -i <span class="string">'s/^\(CFLAGS.*\)/\1 \</span></span><br><span class="line"><span class="string">    -fstack-protector-strong -Wno-sign-compare/'</span> \</span><br><span class="line">    objs/Makefile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始编译动态模块</span></span><br><span class="line">$ make modules</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将动态模块拷贝到模块目录(关闭服务)</span></span><br><span class="line">$ cp objs/*.so /usr/<span class="built_in">local</span>/nginx/modules</span><br></pre></td></tr></table></figure><p>最后，在 <code>Nginx</code> 的配置文件顶部添加一行，表示加载这个编译好的模块。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_module &quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules&#x2F;ngx_http_waf_module.so&quot;;</span><br></pre></td></tr></table></figure><h2><span id="模块使用">模块使用</span></h2><blockquote><p><strong>第三方模块我们应该怎么使用呢？更多参数参考 <a href="https://docs.addesp.com/ngx_waf/zh-cn/advance/directive.html" target="_blank" rel="noopener">配置语法</a></strong></p></blockquote><p>现在就可以在 <code>nginx.conf</code> 内的一个 <code>server</code> 块中添加配置来开启 <code>ngx_waf</code> 模块来配置服务的防火墙了，下面是一个例子。</p><ul><li><strong>[1] LTS 版本</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    ...</span><br><span class="line">    server &#123;</span><br><span class="line">        ...</span><br><span class="line">        # on&#x2F;off 表示启用和关闭</span><br><span class="line">        waf on;</span><br><span class="line"></span><br><span class="line">        # 规则文件所在目录的绝对路径，必须以&#x2F;结尾</span><br><span class="line">        waf_rule_path &#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_waf&#x2F;assets&#x2F;rules&#x2F;;</span><br><span class="line"></span><br><span class="line">        # 防火墙工作模式，STD表示标准模式</span><br><span class="line">        waf_mode STD;</span><br><span class="line"></span><br><span class="line">        # CC防御参数</span><br><span class="line">        # 1000表示每分钟请求次数上限，超出上限后封禁对应ip地址60分钟</span><br><span class="line">        waf_cc_deny rate&#x3D;1000r&#x2F;m duration&#x3D;60m;</span><br><span class="line"></span><br><span class="line">        # 最多缓存50个检测目标的检测结果</span><br><span class="line">        # 对除了IP黑白名单检测、CC防护和POST检测以外的所有检测生效</span><br><span class="line">        waf_cache capacity&#x3D;50;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[2] Current 版本</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    # 声明一块共享内存</span><br><span class="line">    waf_zone name&#x3D;waf size&#x3D;20m;</span><br><span class="line">    ...</span><br><span class="line">    server &#123;</span><br><span class="line">        ...</span><br><span class="line">        # on&#x2F;off 表示启用和关闭</span><br><span class="line">        waf on;</span><br><span class="line"></span><br><span class="line">        # 规则文件所在目录的绝对路径，必须以&#x2F;结尾</span><br><span class="line">        waf_rule_path &#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_waf&#x2F;assets&#x2F;rules&#x2F;;</span><br><span class="line"></span><br><span class="line">        # 防火墙工作模式，STD表示标准模式</span><br><span class="line">        waf_mode STD;</span><br><span class="line"></span><br><span class="line">        # CC防御参数</span><br><span class="line">        # 1000表示每分钟请求次数上限，超出上限后封禁对应ip地址60分钟</span><br><span class="line">        waf_cc_deny on rate&#x3D;1000r&#x2F;m duration&#x3D;60m zone&#x3D;waf:cc;</span><br><span class="line"></span><br><span class="line">        # 对除了IP黑白名单检测、CC防护和POST检测以外的所有检测生效</span><br><span class="line">        waf_cache on capacity&#x3D;50;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="常用设置">常用设置</span></h2><blockquote><p><strong>列出一些 <a href="https://docs.addesp.com/ngx_waf/zh-cn/practice/overview.html" target="_blank" rel="noopener">常用的设置</a>，拿来直接就可以使用！</strong></p></blockquote><p>因为模块的配置比较复杂，为了降低使用难度，在这里列出了一些常见用法。</p><ul><li><strong>[1] 针对路径或文件限流</strong></li></ul><p>有时你可能想要限制不同的路径或文件的请求速率，比如静态资源和动态资源使用不同的速率限制。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># LTS</span><br><span class="line"></span><br><span class="line"># 将静态资源的请求速率限制到10,000次&#x2F;分钟</span><br><span class="line">location &#x2F;static&#x2F; &#123;</span><br><span class="line">    waf_cc_deny rate&#x3D;10000r&#x2F;m duration&#x3D;1h;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 将动态资源的请求速率限制到2,000次&#x2F;分钟</span><br><span class="line">location &#x2F;dynamic&#x2F; &#123;</span><br><span class="line">    waf_cc_deny rate&#x3D;2000r&#x2F;m duration&#x3D;1h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Current</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    waf_zone name&#x3D;waf size&#x3D;20m;</span><br><span class="line">    server &#123;</span><br><span class="line">        # 将静态资源的请求速率限制到10,000次&#x2F;分钟</span><br><span class="line">        location &#x2F;static&#x2F; &#123;</span><br><span class="line">            waf_cc_deny rate&#x3D;10000r&#x2F;m duration&#x3D;1h zone&#x3D;waf:cc_static;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # 将动态资源的请求速率限制到2,000次&#x2F;分钟</span><br><span class="line">        location &#x2F;dynamic&#x2F; &#123;</span><br><span class="line">            waf_cc_deny rate&#x3D;2000r&#x2F;m duration&#x3D;1h zone&#x3D;waf:cc_dynamic;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>[2] 开启验证码<ul><li><a href="https://www.hcaptcha.com/" target="_blank" rel="noopener">hCaptcha</a></li><li><a href="https://developers.google.com/recaptcha" target="_blank" rel="noopener">reCAPTCHAv2</a></li><li><a href="https://developers.google.com/recaptcha" target="_blank" rel="noopener">reCAPTCHAv3</a></li></ul></li></ul><p>当你的站点受到 <code>CC</code> 攻击时开启验证码是不错的选择，因为验证码可以帮助你进行人机识别。本模块目前支持三种验证码，你应该选择一个并从其网站上申请到 <code>Sitekey</code> 和 <code>Secret</code>。配置完成之后，重启 <code>nginx</code> 服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 整个站点开启验证码</span><br><span class="line">server &#123;</span><br><span class="line">    waf_captcha on prov&#x3D;hCaptcha secret&#x3D;your_secret sitekey&#x3D;your_sitekey;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 为某个路径开启验证码</span><br><span class="line">location &#123;</span><br><span class="line">    waf_captcha on prov&#x3D;hCaptcha secret&#x3D;your_secret sitekey&#x3D;your_sitekey;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 当访问频率过高时开启验证码</span><br><span class="line">http &#123;</span><br><span class="line">    waf_zone name&#x3D;waf size&#x3D;20m;</span><br><span class="line">    server &#123;</span><br><span class="line">        waf_cc_deny on rate&#x3D;1000r&#x2F;m duration&#x3D;1h zone&#x3D;waf:cc;</span><br><span class="line">        waf_captcha off prov&#x3D;hCaptcha secret&#x3D;your_secret sitekey&#x3D;your_sitekey;</span><br><span class="line">        waf_action cc_deny&#x3D;CAPTCHA zone&#x3D;waf:action;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 拦截请求时启用验证码</strong></li></ul><p>如今，许多攻击者都会使用自动工具攻击服务器，这些自动工具会尝试每一个漏洞，有的会被安全措施所拦截，有的则可以躲避检测。 如果攻击者觉得你的价值比较高，可能会手动攻击你的服务。我们并不能完美地防御这些攻击，但却能很简单地提高攻击的成本。</p><p>当一个请求被拦截时，<code>ngx_waf</code> 会对该 <code>IP</code> 启用验证码，此时该 <code>IP</code> 想要继续访问就必须完成验证码。这基本可以废掉多数的自动攻击工具，因为这些工具会尝试每一个漏洞，而我们总能识别一些明显的攻击请求并启用验证码，而自动工具时难以通过验证的。对于手动攻击者，这也能提高他们的时间成本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    waf_zone name&#x3D;waf size&#x3D;20m;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        waf_captcha off prov&#x3D;xxx sitekey&#x3D;xxx secret&#x3D;xxx;</span><br><span class="line">        waf_action blacklist&#x3D;CAPTCHA zone&#x3D;waf:action;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>[4] 被攻击时降低带宽占用</strong></li></ul><p>当你受到 <code>CC</code> 攻击时，攻击者的 <code>IP</code> 已经被 <code>CC</code> 防护拉黑，但是你的上下行带宽依然很高， 这是因为 <code>CC</code> 防护会返回一个 <code>503</code> 状态码，因此占用了你的带宽，你可以使用下面的配置来降低带宽占用。</p><p><code>444</code> 状态码是 <code>nginx </code>定义的一个非标准的 <code>HTTP</code> 状态码，其作用就是直接关闭连接，不再发送任何数据。如果你使用了 <code>444</code> 状态码，那么在用户看来你的网站就像是不存在一样。这是因为网站出错一般都会有 <code>HTTP</code> 状态码用来提示错误， 如果访问一个网站连错误提示都没有，那么大概率是这个网站不存在。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># LTS</span><br><span class="line">waf_http_status cc_deny&#x3D;444;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Current</span><br><span class="line">waf_action cc_deny&#x3D;444;</span><br></pre></td></tr></table></figure><ul><li><strong>[5] 抵御分布式 CC 攻击</strong></li></ul><p><code>CC</code> 攻击(<code>HTTP</code> 洪水)是指发送大量的 <code>HTTP</code> 请求来耗尽服务器的资源。如果攻击者使用的 <code>IP</code> 较少则防御较为简单，因为只需要限制 <code>IP</code> 的请求频率，但是如果攻击者使用大量的 <code>IP</code> 进行攻击，仅仅限制 <code>IP</code> 的请求频率是无济于事的。这种使用大量 <code>IP</code> 进行 <code>CC</code> 攻击的方式称为分布式 <code>CC</code> 攻击或分布式 <code>HTTP</code> 洪水。</p><p>本模块提供了一些缓解方式，第一种开启验证码来缓解，第二种使用降低带宽占用，第三种使用五秒盾来缓解。你可能听说过 <code>Cloudflare</code> 的五秒盾，本模块的五秒盾和 <code>Cloudflare</code> 的完全不同。它的功能是检测客户端是否能够正确地支持 <code>Cookie</code>，比如发送 <code>Cookie</code> 和正确地处理 <code>Set-Cookie</code> 响应头。你可以从本项目的 <code>assets/</code> 目录下找到 <code>under-attack.html</code> 并将其拷贝到某个路径下，然后通过修改 <code>nginx</code> 的配置文件来开启五秒盾。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># LTS</span><br><span class="line"></span><br><span class="line"># 为整个网站开启五秒盾</span><br><span class="line">server &#123;</span><br><span class="line">    waf_under_attack on file&#x3D;&#x2F;path&#x2F;to&#x2F;under_attack.html;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 为某个路径开启五秒盾</span><br><span class="line">location &#x2F;path &#123;</span><br><span class="line">    waf_under_attack on file&#x3D;&#x2F;path&#x2F;to&#x2F;under_attack.html;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Current</span><br><span class="line"></span><br><span class="line"># 为整个网站开启五秒盾</span><br><span class="line">server &#123;</span><br><span class="line">    waf_under_attack on;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 为某个路径开启五秒盾</span><br><span class="line">location &#x2F;path &#123;</span><br><span class="line">    waf_under_attack on;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="效果测试">效果测试</span></h2><blockquote><p><strong>如需更多帮助，可以参考 <a href="https://docs.addesp.com/ngx_waf/zh-cn/guide/test.html#%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95" target="_blank" rel="noopener">如何测试</a>！</strong></p></blockquote><p>当我们部署和配置服务完成之后，需要测试下防火墙是否正常起作用了，可以通过如下方式进行简单的测试来判断规则是否正常运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 测试时的配置</span><br><span class="line">master_process on;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        access_log off;</span><br><span class="line"></span><br><span class="line">        waf on;</span><br><span class="line">        waf_mode DYNAMIC !CC !POST;</span><br><span class="line">        waf_rule_path &#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_waf&#x2F;rules&#x2F;;</span><br><span class="line">        waf_cache capacity&#x3D;6000 interval&#x3D;1h percent&#x3D;50;</span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">            default_type text&#x2F;html;</span><br><span class="line">            return 200 &#39;hello&#39;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>[1] 简易测试<ul><li>运行下列命令，如果输出 <code>403</code> 则表示模块正常工作</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -I -o /dev/null --user-agent bench \</span><br><span class="line">    -s -w <span class="string">"%&#123;http_code&#125;\\n"</span> https://example.com</span><br></pre></td></tr></table></figure><ul><li>[2] 自动测试<ul><li>项目附带了许多测试用例，你可以通过下面的指令来运行全部的用例</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这行命令的执行时间比较长</span></span><br><span class="line">$ cpan Test::Nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果目录已经存在则会先删除再创建</span></span><br><span class="line">$ <span class="built_in">export</span> MODULE_TEST_PATH=/path/to/temp/dir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果你安装了动态模块则需要指定动态模块的绝对路径，反之则无需执行这行命令</span></span><br><span class="line">$ <span class="built_in">export</span> MODULE_PATH=/path/to/ngx_http_waf_module.so</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动化测试</span></span><br><span class="line">$ <span class="built_in">cd</span> ./<span class="built_in">test</span>/<span class="built_in">test</span>-nginx</span><br><span class="line">$ sh ./init.sh</span><br><span class="line">$ sh ./start.sh ./t/*.t</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以使用WRK工具测试</span></span><br><span class="line">$ wrk -c 100 -d 30m -t 1 -s <span class="built_in">test</span>/wrk/rand.lua --latency \</span><br><span class="line">    http://localhost/ -- /path/to/rand-str.txt</span><br></pre></td></tr></table></figure><h2><span id="注意事项">注意事项</span></h2><blockquote><p><strong>如需更多帮助，可以参考 <a href="https://docs.addesp.com/ngx_waf/zh-cn/guide/faq.html" target="_blank" rel="noopener">常见问题与解答</a>！</strong></p></blockquote><p>本模块只保证对 <code>nginx-1.18.0</code> 或更新的版本的兼容性，且不保证与 <code>Linux</code> 以外的操作系统的兼容性。这里需要注意的是，模块与 <a href="https://nginx.org/en/docs/http/ngx_http_rewrite_module.html" target="_blank" rel="noopener">ngx_http_rewrite_module</a> 存在兼容性问题。</p><ul><li>当 <code>return</code> 指令生效时，该模块不会生效</li><li>当 <code>rewrite</code> 指令造成了返回(如 <code>302</code> 重定向)时，该模块不会生效</li><li>所以可以使用 <a href="https://nginx.org/en/docs/http/ngx_http_core_module.html#try_files" target="_blank" rel="noopener"><code>try_files</code></a> 代替 <a href="https://nginx.org/en/docs/http/ngx_http_rewrite_module.html#rewrite" target="_blank" rel="noopener"><code>rewrite</code></a> 指令，避免上述问题的出现</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># rewrite</span><br><span class="line">if (!-e $request_filename) &#123;</span><br><span class="line">    rewrite (.*) &#x2F;index.php</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># try_files</span><br><span class="line">try_files $uri $uri&#x2F; &#x2F;index.php;</span><br></pre></td></tr></table></figure><h2><span id="参考链接">参考链接</span></h2><ul><li><a href="https://github.com/ADD-SP/ngx_waf" target="_blank" rel="noopener">Github 代码仓库</a></li><li><a href="https://docs.addesp.com/ngx_waf/zh-cn/advance/rule.html" target="_blank" rel="noopener">黑白名单规则说明</a></li><li><a href="https://docs.addesp.com/ngx_waf/zh-cn/advance/priority.html" target="_blank" rel="noopener">检测项目规则优先级</a></li><li><a href="https://docs.addesp.com/ngx_waf/zh-cn/advance/variable.html" target="_blank" rel="noopener">模块的内置变量</a></li><li><a href="https://docs.addesp.com/ngx_waf/zh-cn/advance/log.html" target="_blank" rel="noopener">日志相关的配置说明</a></li></ul><blockquote><p>本文转载自：「 Escape 的博客 」，原文：<a href="https://tinyurl.com/2p979waj" target="_blank" rel="noopener">https://tinyurl.com/2p979waj</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ngx_waf：方便且高性能的 Nginx 防火墙模块&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;缓存策略为 &lt;code&gt;LRU&lt;/code&gt;，&lt;code&gt;IP&lt;/code&gt; 检查和 &lt;code&gt;CC&lt;/code&gt; 防御花费常数时间，其它的检查花费 &lt;code&gt;O(nm)&lt;/code&gt; 的时间，其中 &lt;code&gt;n&lt;/code&gt; 是相关规则的条数，&lt;code&gt;m&lt;/code&gt; 为执行正则匹配的时间复杂度，但是每次检查过后会自动缓存本次检查的结果，下次检查相同的目标时就可以使用缓存而不是检查全部的规则。不会缓存 &lt;code&gt;POST&lt;/code&gt; 请求体的检查结果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="https://www.hi-linux.com/categories/nginx/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Nginx" scheme="https://www.hi-linux.com/tags/Nginx/"/>
    
      <category term="安全" scheme="https://www.hi-linux.com/tags/%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>超给力，100+ 互联网大厂产品开源代码合集！</title>
    <link href="https://www.hi-linux.com/posts/56314.html"/>
    <id>https://www.hi-linux.com/posts/56314.html</id>
    <published>2022-01-28T01:00:00.000Z</published>
    <updated>2022-02-09T03:03:37.728Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>学习互联网大厂产品的源码是非常好提高自身技术水平的方法，但是问题来了，源码不一定开源啊，想学也没办法。但是就是有这样一些技术大牛，通过研究大厂的产品，开源出来了各种克隆的实现。</p><p>今天要推荐的开源项目是 <code>Clone-Wars</code>，收集了 100+ 互联网大厂产品的开源实现，包括 <code>Airbnb</code>、<code>Amazon</code>、<code>Instagram</code>、<code>Netflix</code>、<code>Tiktok</code>、<code>Spotify</code>、<code>Whatsapp</code>、<code>Youtube</code> 等非常多，其中内容包含了源码、Demo 链接、技术栈介绍等。有一说一，这个真的太全了，部分产品还自带教学视频。</p><p><img src="https://img.hi-linux.com/staticfile/og-2021-07-15-3ikq76.png" alt></p><a id="more"></a><p>以下是部分比较著名的网站实现：</p><p><img src="https://img.hi-linux.com/staticfile/image-20210715160217277-2021-07-15-rSLbMK.png" alt></p><p>很多产品还不只一个开源的克隆实现呢。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210715160423005-2021-07-15-OqJHWD.png" alt></p><p>我们来看下其中一个 HackerNews 的开源克隆实现，作者还做了部分的重新设计，看上去要比原版视觉效果要好一点。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210715160536681-2021-07-15-js5y1j.png" alt></p><p>更多项目详情请查看项目地址：<a href="https://github.com/GorvGoyl/Clone-Wars" target="_blank" rel="noopener">https://github.com/GorvGoyl/Clone-Wars</a></p><blockquote><p>本文转载自：「 GitHub 精选 」，原文：<a href="https://tinyurl.com/4f7crwf4" target="_blank" rel="noopener">https://tinyurl.com/4f7crwf4</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习互联网大厂产品的源码是非常好提高自身技术水平的方法，但是问题来了，源码不一定开源啊，想学也没办法。但是就是有这样一些技术大牛，通过研究大厂的产品，开源出来了各种克隆的实现。&lt;/p&gt;
&lt;p&gt;今天要推荐的开源项目是 &lt;code&gt;Clone-Wars&lt;/code&gt;，收集了 100+ 互联网大厂产品的开源实现，包括 &lt;code&gt;Airbnb&lt;/code&gt;、&lt;code&gt;Amazon&lt;/code&gt;、&lt;code&gt;Instagram&lt;/code&gt;、&lt;code&gt;Netflix&lt;/code&gt;、&lt;code&gt;Tiktok&lt;/code&gt;、&lt;code&gt;Spotify&lt;/code&gt;、&lt;code&gt;Whatsapp&lt;/code&gt;、&lt;code&gt;Youtube&lt;/code&gt; 等非常多，其中内容包含了源码、Demo 链接、技术栈介绍等。有一说一，这个真的太全了，部分产品还自带教学视频。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/og-2021-07-15-3ikq76.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="开源" scheme="https://www.hi-linux.com/categories/%E5%BC%80%E6%BA%90/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
      <category term="程序员" scheme="https://www.hi-linux.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
  </entry>
  
  <entry>
    <title>WireGuard 中文教程：使用 Netmaker 快速组建 WireGuard 全互联 (Full Mesh) 网络</title>
    <link href="https://www.hi-linux.com/posts/40657.html"/>
    <id>https://www.hi-linux.com/posts/40657.html</id>
    <published>2022-01-14T01:00:00.000Z</published>
    <updated>2022-01-14T01:27:32.617Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2><span id="什么是-netmaker">什么是 Netmaker</span></h2><p><a href="https://github.com/gravitl/netmaker" target="_blank" rel="noopener">Netmaker</a> 是一个开源的、基于 [[WireGuard]] 的网络（overlay network) 控制工具，可以非常快速的用来组建 WireGuard 网络。</p><p>如果你有两台连接互联网的设备，那么 Netmaker 可以组建一个安全的网络，并打通一个安全的隧道提供给两台机器通信。而如果你有数千台机器分布在不同的地区，不同的数据中心，不同的网络中，那么 Netmaker 也可以组建一个网络来提供给这些不同的节点通信。</p><p>如果熟悉 AWS，那么 Netmaker 就像 VPC 一样，不过 Netmaker 可以应用在任意的机器中。从 Netmaker 网络中的机器来看，同一个网络中的机器尽管在世界各地，但其相互通信就像是在同一个局域网中一样。</p><a id="more"></a><p>Netmaker 和其他一些产品非常相似，比如 [[Tailscale]], [[ZeroTier]]，[[Nebula]] 但不同于这些产品的是，Netmaker 连接更快，更加灵活。Netmaker 使用 [[WireGuard]] 所以更快，Netmaker 中的节点不管是服务端还是Agent都完全可配置，所以提供了更大的灵活性。</p><p>Netmaker 优于 [[Tailscale]] 的地方还在于 ，Netmaker 不需要 Google, Microsoft 或者 GitHub 账号。Netmaker 可以认为是一个可以自行托管的 Tailscale。</p><h2><span id="netmaker-工作原理">Netmaker 工作原理</span></h2><p>Netmaker 依赖于 WireGuard 来在机器间创建隧道（tunnel), Netmaker 通过管理不同机器的 WireGuard 来创建网络。简单来说，Netmaker 实现 Client/Server 架构：</p><ul><li>the admin server 管理端，称为 Netmaker，管理网络的界面</li><li>the agent，客户端，称为 Netclient，客户端通过 gRPC 与服务端通信</li></ul><p>作为 Network 管理端，你可以通过管理端来创建网络，管理连接的设备。服务端会保存所有网络和设备的配置信息，这些信息会被 netclient (agent) 来获取使用。</p><p>客户端（netclient) 是一个二进制文件，netclient 会在节点被添加到网络中的时候安装到不同的机器中，netclient 可以在大多数系统中运行，不管是虚拟机，物理机，或者 IoT 设备都可以运行 netclient。netclient 会连接服务端，通过服务端的配置来自动管理 WireGuard，动态更新 Peers。通过不断向网络中添加节点的方式，可以创建一个动态的，完全可以配置的虚拟网络。</p><p>Netmaker server 不会路由网络流量，否则这个网络就变成了一个中心辐射模型（hub-and-spoke model），这会使得中心服务器变成瓶颈，并且拖慢网络。相反，Network 会告诉网络中的节点他们之间可以相互直接通信，这被称为 full mesh network（网状网络），这会让节点和节点的连接更快。即使管理端宕机，只要现存的节点没有变化，那么这个网络依然可以正常工作。</p><h2><span id="应用场景-use-cases">应用场景 Use Cases</span></h2><p>Netmaker 有非常多的应用场景，事实上，现在可能就已经在使用了。</p><p>用例：</p><ul><li>自动创建 WireGuard mesh network</li><li>在云环境和数据中心之间创建 flat, secure 网络</li><li>给 IoT 设备提供更安全的网络访问</li><li>增强家庭，或办公网络的安全性</li><li>在现存网络上增加一层加密</li><li>安全的 site-to-site 连接</li><li>管理 cryptocurrency proof-of-stake 机器</li><li>创建动态的安全的 Kubernetes underlay network</li></ul><p>更多的用例也可以参考<a href="https://docs.netmaker.org/usage.html" target="_blank" rel="noopener">官网</a>。</p><h2><span id="架构">架构</span></h2><p><img src="https://img.hi-linux.com/staticfile/netmaker-architecture-20211212101049-2022-01-13-uWAKsc.png" alt="Netmaker 的架构图"></p><h2><span id="概念">概念</span></h2><p>熟悉一下 Netmaker 中常常被提到的概念，有助于理解。</p><h3><span id="wireguard">WireGuard</span></h3><p>[[WireGuard]] 相对比较新，但非常强大，WireGuard 被加入到了 Linux kernel。WireGuard 可以非常简单快速地在设备之间创建加密通道。从 <a href="https://www.wireguard.com/" target="_blank" rel="noopener">WireGuard</a> 官网的介绍中可以看到，“WireGuard 可以被认为是工业界最安全，最方便使用，最简单的 VPN 解决方案”。</p><p>之前的解决方案，比如 OpenVPN，或者 IPSec 都被认为又重又复杂，并且性能也不是很好。所有现存的 VPN tunneling 方案都会导致网络延迟增大。WireGuard 是第一个实现了几乎接近有线连接网络速度的 VPN，可以看到 WireGuard 对现有网络连接几乎没有影响。随着 WireGuard 的发布，没有任何理由去使用其他隧道加密技术了。</p><h3><span id="mesh-network">Mesh Network</span></h3><p>当提到 mesh network （网状网络）的时候通常也会说 「full mesh」。一个 full <a href="https://www.bbc.co.uk/bitesize/guides/zr3yb82/revision/2" target="_blank" rel="noopener">mesh network</a> 指的是网络中的任何节点都可以相互直接连接。</p><p><img src="https://img.hi-linux.com/staticfile/full-mesh-network-20211212102133-2022-01-13-2gL9FB.png" alt></p><p>比如在路由器后面的家庭网络，所有的电脑都会通过私有局域网地址相互连接。</p><p>Mesh network 通常会和 hub-and-spoke (中心辐射) 网络放到一起对比，中心辐射的网络中，一个节点必须通过 relay server 才能和另外一个节点进行通信。</p><p>在一些场景中，你可以需要部分的 mesh network，网络中只有部分设备需要相互直接通信，而其他设备都需要将流量转发给一个 relay/gateway 。Netmaker 在某些时候也可以实现这类模型。在第一张图片中，这个设置就是一个部分的 mesh network，因为节点A-D 是网状网络，而其他的客户端通过 gateway 连接。</p><p>Mesh networks 通常比其他拓扑的网络更快，但通常设置也会更加复杂。WireGuard 提供了在设备之间创建加密隧道的方法，但是它不提供设置完整网络的方法。这是 Netmaker 诞生的理由。</p><h3><span id="netmaker">Netmaker</span></h3><p>Netmaker 是一个建立在 WireGuard 上的平台，允许用户在设备之间构建 mesh networks。Netmaker 可以根据需要创建完全的、或部分的 mesh network。</p><p>当我们提及 Netmaker 整体的时候，通常指的是 Netmaker 以及 netclient, 以及其他辅助的服务，比如 CoreDNS，rqlite 和 UI 服务。</p><p>从终端用户来看，通常会和 Netmaker UI 交互，或会直接在终端节点中直接运行脚本。而其他部分都会在后台默默地执行。</p><p>Netmaker 做了非常多的配置相关的工作，简化了用户的配置。包括了 WireGuard 的端口，endpoints( 终端) , public IPs（公网IP），keys(密钥) 和 peers(节点)。Netmaker 尽可能多地抽象了网络管理，只需简单的在界面点击创建网络，然后点击将计算机添加到网络。也就是说，每一个机器都是不同的，可能需要不同的配置。这就是为什么，Netmaker 使用一套默认设置，则网格内的所有内容都是完全可配置的。</p><h3><span id="systemd">SystemD</span></h3><p>SystemD 是一个被 Linux 广泛使用的系统服务器管理器。尽管没有被所有发行版采用，但是不管如何，它已经成为了 Linux 世界的事实标准。非 Linux 可能没有 systemd，而 Linux/Unix 发行版有可代替的 system service managers。</p><p>Netmaker 的 netclient (客户端) 会控制节点上的网络，可以通过命令行运行，或者通过作为 system 守护进程（daemon），在 Linux 上会默认以 daemon 运行（依赖于 systemd)。</p><p>从 0.8 版本开始，支持了 macOS 和 Windows，在这些操作系统中，netclient 使用 LaunchD 来启动 netclient 守护进程。</p><h3><span id="ingress-gateways">Ingress Gateways</span></h3><p>在 Netmaker 网络中的任何节点都可以成为 Ingress Gateway，Ingress Gateway 可以接受 Netmaker（WireGuard）网络外部的流量。</p><h3><span id="egress-gateways">Egress Gateways</span></h3><p>Egress Gateway 出口网关，允许将内部网络流量转发到外部指定 IP。</p><h2><span id="netmaker-安装">Netmaker 安装</span></h2><h3><span id="硬件要求">硬件要求</span></h3><p>服务器：</p><ul><li>一台可用的 VPS（最好比较干净，没有占用端口，否则需要根据自己的需要自行调整）。</li><li>公开的 IP 地址</li><li>至少 1GB RAM，1CPU（4GB RAM，2 CPU 生产环境）</li><li>2GB+ 存储</li><li>Ubuntu 20.04</li></ul><h3><span id="软件要求">软件要求</span></h3><p>域名：</p><ul><li>一个可用的域名（可选）</li><li>可以操作管理 DNS 服务(53端口)</li><li>保证 443(tcp)， 53(tcp udp), 51821-518XX(udp) 端口可用<ul><li>443 端口，Dashboard，REST API 和 gRPC</li><li>53 端口，CoreDNS</li><li>51821-518XX，WireGuard，每一个网络需要一个端口，起始端口会使用 51821，可以根据自己的网络端数量需要设定端口范围</li><li>允许防火墙 <code>sudo ufw allow proto tcp from any to any port 443 &amp;&amp; sudo ufw allow 53/udp &amp;&amp; sudo ufw allow 53/tcp &amp;&amp; sudo ufw allow 51821:51830/udp</code></li></ul></li></ul><h3><span id="一键安装">一键安装</span></h3><p>如果想使用自己的域名，比如 <code>dashboard.netmaker.example.com</code> 这样，可以参考<a href="https://docs.netmaker.org/quick-start.html" target="_blank" rel="noopener">官网</a>。这里为了演示方便，就使用一键脚本。</p><p>Netmaker 官方已经提供了一个 Docker 镜像，并且也提供了安装脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo wget -qO - https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;gravitl&#x2F;netmaker&#x2F;master&#x2F;scripts&#x2F;nm-quick.sh | bash</span><br></pre></td></tr></table></figure><p>如果没有使用自己的域名，一键脚本会使用一个 <a href="http://nip.io" target="_blank" rel="noopener">nip.io</a> 的泛域名解析映射工具根据 IP 自动获取一个域名，用来访问后台地址。</p><p>首次登录后台会要求设定用户名和密码。登录后台之后，左侧的 Networks、 Nodes、 Access Keys 是比较重要的菜单。</p><p><img src="https://img.hi-linux.com/staticfile/netmaker-dashboard-20211212154245-2022-01-13-E1wl5F.png" alt></p><p>在 Network 选项中选择创建 Network，设定 IP 段范围，然后在其他机器上依次安装客户端，添加节点到网络中即可。</p><p>在添加到之后网络之后，可以运行 <code>sudo wg show</code> 查看信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">❯ sudo wg show</span><br><span class="line">interface: nm-k3s</span><br><span class="line">  public key: PGeGQKOlJt4zZJX2axf15dRsWvs6QaFRF&#x2F;j&#x2F;fJUfnjw&#x3D;</span><br><span class="line">  private key: (hidden)</span><br><span class="line">  listening port: 51821</span><br><span class="line"></span><br><span class="line">peer: Cjbp&#x2F;IeTEFgPEJpOldjkaleUvlNjqg+y75hiI&#x2F;Sq61Q&#x3D;</span><br><span class="line">  endpoint: 140.XXX.XXX.XXX:51821</span><br><span class="line">  allowed ips: 10.10.11.8&#x2F;32</span><br><span class="line">  latest handshake: 2 seconds ago</span><br><span class="line">  transfer: 6.74 KiB received, 1.88 KiB sent</span><br><span class="line">  persistent keepalive: every 20 seconds</span><br></pre></td></tr></table></figure><p>通常会看到 interface 和 peer 信息。</p><h3><span id="手动安装">手动安装</span></h3><p>如果需要手动安装，也不是特别麻烦，从官网下载 docker-compose.yml 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget -O docker-compose.yml https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;gravitl&#x2F;netmaker&#x2F;master&#x2F;compose&#x2F;docker-compose.contained.yml</span><br><span class="line">$ sed -i &#39;s&#x2F;NETMAKER_BASE_DOMAIN&#x2F;&lt;your base domain&gt;&#x2F;g&#39; docker-compose.yml</span><br><span class="line">$ sed -i &#39;s&#x2F;SERVER_PUBLIC_IP&#x2F;&lt;your server ip&gt;&#x2F;g&#39; docker-compose.yml</span><br><span class="line">$ sed -i &#39;s&#x2F;COREDNS_IP&#x2F;&lt;default interface ip&gt;&#x2F;g&#39; docker-compose.yml</span><br></pre></td></tr></table></figure><ul><li>生成唯一的 master key:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ tr -dc A-Za-z0-9 &lt;&#x2F;dev&#x2F;urandom | head -c 30 ; echo &#39;&#39;</span><br><span class="line">$ sed -i &#39;s&#x2F;REPLACE_MASTER_KEY&#x2F;&lt;your generated key&gt;&#x2F;g&#39; docker-compose.yml</span><br></pre></td></tr></table></figure><ul><li>配置 Caddy</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget -O &#x2F;root&#x2F;Caddyfile https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;gravitl&#x2F;netmaker&#x2F;master&#x2F;docker&#x2F;Caddyfile</span><br><span class="line">$ sed -i &#39;s&#x2F;NETMAKER_BASE_DOMAIN&#x2F;&lt;your base domain&gt;&#x2F;g&#39; &#x2F;root&#x2F;Caddyfile</span><br><span class="line">$ sed -i &#39;s&#x2F;YOUR_EMAIL&#x2F;&lt;your email&gt;&#x2F;g&#39; &#x2F;root&#x2F;Caddyfile</span><br></pre></td></tr></table></figure><ul><li>然后启动：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker-compose up -d</span><br></pre></td></tr></table></figure><p>然后可以访问 <code>dashboard.nm.example.com</code> 后台。</p><p>需要注意的是，如果使用自己的域名需要添加一个泛域名 A 记录（wildcard A record)，比如想要后台访问地址是 <code>dashboard.nm.example.com</code> 那么需要添加 <code>*.nm.example.com</code>。</p><p>Caddy 会创建三个子域名：</p><ul><li><a href="http://dashboard.nm.example.com" target="_blank" rel="noopener">dashboard.nm.example.com</a></li><li><a href="http://api.nm.example.com" target="_blank" rel="noopener">api.nm.example.com</a></li><li><a href="http://grpc.nm.example.com" target="_blank" rel="noopener">grpc.nm.example.com</a></li></ul><h2><span id="netclient-使用">netclient 使用</span></h2><p><code>netclient</code> 是一个简单的 CLI，用于创建 WireGuard 配置和接口。netclient 可以管理任意私有网络。</p><h3><span id="安装-netclient-依赖">安装 netclient 依赖</span></h3><p>以 macOS 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install wireguard-tools</span><br></pre></td></tr></table></figure><h3><span id="安装-netclient">安装 netclient</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;gravitl&#x2F;netmaker&#x2F;releases&#x2F;download&#x2F;v0.9.3&#x2F;netclient-darwin</span><br><span class="line">$ mv netclient-darwin netclient</span><br><span class="line">$ chmod +x netclient</span><br></pre></td></tr></table></figure><h3><span id="使用-netclient-将节点加入网络">使用 netclient 将节点加入网络</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;netclient join --dnson no --name &lt;HOSTNAME&gt; --network demo --apiserver &lt;Netmaker_IP&gt;:8081 --grpcserver &lt;Netmaker_IP&gt;:50051</span><br></pre></td></tr></table></figure><h2><span id="外延">外延</span></h2><p>Nebula 是另外一个选择，同样基于 WireGuard。</p><p>更多资料可以查看 Gravitl 官网：<a href="https://gravitl.com/resources" target="_blank" rel="noopener">https://gravitl.com/resources</a></p><h2><span id="reference">reference</span></h2><ul><li><a href="https://docs.netmaker.org/" target="_blank" rel="noopener">官方文档</a></li><li><a href="https://afeiszli.medium.com/how-to-enable-secure-access-to-your-hosted-services-using-netmaker-and-wireguard-1b3282d4b7aa" target="_blank" rel="noopener">使用 Netmaker 和 WireGuard 访问内网服务</a></li><li><a href="https://netmaker.readthedocs.io/en/master/getting-started.html" target="_blank" rel="noopener">Netmaker Getting Started</a></li><li><a href="https://itnext.io/getting-started-with-netmaker-a-wireguard-virtual-networking-platform-3d563fbd87f0" target="_blank" rel="noopener">Getting started with netmaker</a></li></ul><blockquote><p>本文转载自：「 Verne in GitHub 」，原文：<a href="https://tinyurl.com/5yuj4xbu" target="_blank" rel="noopener">https://tinyurl.com/5yuj4xbu</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Netmaker&quot;&gt;什么是 Netmaker&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/gravitl/netmaker&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Netmaker&lt;/a&gt; 是一个开源的、基于 [[WireGuard]] 的网络（overlay network) 控制工具，可以非常快速的用来组建 WireGuard 网络。&lt;/p&gt;
&lt;p&gt;如果你有两台连接互联网的设备，那么 Netmaker 可以组建一个安全的网络，并打通一个安全的隧道提供给两台机器通信。而如果你有数千台机器分布在不同的地区，不同的数据中心，不同的网络中，那么 Netmaker 也可以组建一个网络来提供给这些不同的节点通信。&lt;/p&gt;
&lt;p&gt;如果熟悉 AWS，那么 Netmaker 就像 VPC 一样，不过 Netmaker 可以应用在任意的机器中。从 Netmaker 网络中的机器来看，同一个网络中的机器尽管在世界各地，但其相互通信就像是在同一个局域网中一样。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="WireGuard" scheme="https://www.hi-linux.com/tags/WireGuard/"/>
    
      <category term="Netmaker" scheme="https://www.hi-linux.com/tags/Netmaker/"/>
    
  </entry>
  
  <entry>
    <title>世界是 Container 的，也是 Microservice 的，但最终还是 Serverless 的</title>
    <link href="https://www.hi-linux.com/posts/32279.html"/>
    <id>https://www.hi-linux.com/posts/32279.html</id>
    <published>2022-01-03T01:00:00.000Z</published>
    <updated>2022-01-13T05:34:07.912Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>世界上有两种基础设施，一种是拿来主义，另一种是自主可控。</p><p>原谅我也蹭个已经被浇灭的、没怎么火起来的热点。不过我们喜欢的是拿来主义，<strong>够用就行，不想也不需要过多的控制，也不想惹过多的麻烦</strong>，也就是 fully managed。</p><p>之所以想到写这篇文章，源于前几天看到的这篇来自微软 Azure 的博客内容： <a href="https://thenewstack.io/the-future-of-Kubernetes-is-serverless/" target="_blank" rel="noopener">The Future of Kubernetes Is Serverless</a> ，然后又顺手温习了一遍 AWS CTO 所撰写的 <a href="https://www.allthingsdistributed.com/2018/04/changing-calculus-containers-cloud.html" target="_blank" rel="noopener">Changing the calculus of containers in the cloud</a> 这篇文章。这两篇文章你觉得有可能有广告的嫌疑，都是在推销自家的共有云服务，但是仔细品味每一句话，我却觉得几乎没有几句废话，都很说到点子上，你可以点击进去看下原文。</p><p>有个前提需要说明的是，这里的 Serverless 指的是 Serverless infrastructure，而不是我们常听到的 AWS Lambda，Microsoft Azure Functions 或 Google Cloud Functions 等函数（功能）即服务（FaaS）技术，为了便于区分，我们将这些 FaaS 称为无服务器计算，和我们本文要介绍的无服务器基础设施还是不一样的。</p><a id="more"></a><h2><span id="iaas变革的开始">IaaS：变革的开始</span></h2><p>说到基础设施，首先来介绍下最先出现的 IaaS，即基础设施即服务。IaaS 免除了大部分硬件的 provision 工作，没人再关心机架、电源和服务器问题，使得运维工作更快捷，更轻松，感觉解放了很多人，让大家走上了富裕之路。</p><p>当然这一代的云计算服务，可不只是可以几分钟启动一台虚拟机那么简单。</p><p>除了 VM 之外， IaaS 厂商还提供了很多其他基础设施和中间件服务，这些组件被称为 building block ，比如网络和防火墙、数据库、缓存等老三样，最近还出现了非常多非常多的业务场景服务，大数据、机器学习和算法，以及IoT等，看起来就像个百货商店，使用云计算就像购物，架构设计就是购物清单，架构里的组件都可以在商店里买到。</p><p>基础设施则使用 IaaS 服务商所提供的各种服务，编写应用程序可以更专注于业务。这能带来很多好处：</p><ul><li>将精力集中投入到核心业务</li><li>加快上线速度</li><li>提高可用性</li><li>快速扩缩容</li><li>不必关心中间件的底层基础设施</li><li>免去繁杂的安装、配置、备份和安全管理等运维工作</li></ul><p>在 AWS 成为业界标准之后，各大软件公司，不管是新兴的还是老牌的，都开始着手打造自己的云，国外有微软、谷歌、IBM等，国内的 BAT 也都有自己的云，以及京东和美团这样的电商类公司也有自己的云产品，独立的厂商类似 UCloud 和青云等公司也发展的不错，甚至有开饭馆的也要出来凑热闹。而开源软件 OpenStack 和基于 OS 的创业公司和产品也层出不穷。</p><p>全民皆云。</p><h2><span id="容器云计算的深入人心">容器：云计算的深入人心</span></h2><p>之后在 2013 年，容器技术开始面向大众普及了。在 LXC 之前，容器对普通开发人员甚至 IT 业者来说几乎不是同一个维度的术语，那是些专业人员才能掌控的晦涩的术语和繁杂的命令集，大部分人都没有用过容器技术；但是随着 Docker 的出现，容器技术的门槛降低，也在软件行业变得普及。随着几年的发展，基本可以说容器技术已经非常成熟，已成为了开发的标配。</p><p>随着容器技术的成熟和普及，应用程序架构也出现了新的变化，可以说软件和基础设施的进化相辅相成。人们越来越多的认识到对技术栈的分层和解耦更加重要，不同层之间的技术和责任、所有权等界限清晰明了，这也和软件设计中的模块松耦合原则很相像。</p><p>在有了责权明晰的分层结构之后，每个人可以更容易集中在自己所关注的重点上。开发人员更关注应用程序本身了，在 Docker 火了的同时，也出现了 app-centric 的概念。甚至 CoreOS 还将自己对抗 OCI/runc 的标准称为 appc 。当然现在的 Docker 也不是原来的 Docker ，也是一个组件化的东西，很多组件，尤其是 runtime ，都可以替换为其他运行时。</p><p>和以应用程序为重心相对应的是传统的以基础设施为中心，即先有基础设施，围绕基础设施做架构设计和开发、部署，受基础设施的限制较多。而随着 IaaS 等服务的兴起，基础设施越来越简单，越来越多容易入手，而且还提供了编程化的接口，开发人员也可以非常方便的对基础设施进行管理，可以说云计算的出现也使得开发人员抢了一部分运维人员的饭碗（遗憾的是这种趋势太 high 了停不下来。。。）。</p><p>当然，现在以应用为中心这一概念也已经深入人心。特别是进化到极致的 FaaS ，自己只需要写几行代码，其他平台全给搞定了。</p><h2><span id="编排兵家必争之地">编排：兵家必争之地</span></h2><p>容器解决了代码的可移植性的问题，也使得在云计算中出现新的基础设施应用模式成为可能。使用一个一致的、不可变的部署制品，比如镜像，可以让我们从复杂的服务器部署中解脱出来，也可以非常方便的部署到不同的运行环境中（可移植性）。</p><p>但是容器的出现也增加了新的工作内容，要想使用容器运行我们的代码，就需要一套容器管理系统，在我们编写完代码，打包到容器之后，需要选择合适的运行环境，设置好正确的扩容配置，相关的网络连接，安全策略和访问控制，以及监控、日志和分布式追踪系统。</p><p>之所以出现编排系统，就是因为一台机器已经不够用了，我们要准备很多机器，在上面跑容器，而且我不关心容器跑在哪台机器上，这个交给调度系统就行了。可以说，从一定层面上，编排系统逐渐淡化了主机这一概念，我们面对的是一个资源池，是一组机器，有多少个 CPU 和多少的内存等计算资源可用。</p><p>rkt vs Docker 的战争从开始其实就可以预料到结局，但在编排系统/集群管理上，这场“战争”则有着更多的不确定性。</p><p>Mesos（DC/OS）出来的最早，还有 Twitter 等公司做案例，也是早期容器调度系统的标配；Swarm 借助其根正苗红以及简单性、和 Docker 的亲和性，也要争一分地盘；不过现在看来赢家应该是 K8s，K8s 有 Google 做靠山，有 Google 多年调度的经验，加上 RedHat/CoreOS 这些反 Docker 公司的站队，社区又做得红红火火，总之是赢了。</p><p>据说今年在哥本哈根举办的 Kubecon 有 4300 人参加。不过当初 Dockercon 也是这声势，而现在影响力已经没那么大了，有种昨日黄花、人老色衰的感觉，不知道几年之后的 Kubernetes 将来会如何，是否会出现新的产品或服务来撼动 Kubernetes 现在的地位？虽然不一定，但是我们期待啊。</p><h2><span id="serverless-infrastructure进化的结果">Serverless infrastructure：进化的结果</span></h2><p>但是呢，淡化主机的存在性也只是淡化而已，并没有完全消除主机的概念，只是我们直接面向主机的机会降低了，不再直接面向主机进行部署，也不会为某些部门分配独占的主机等。主机出了问题还得重启，资源不够了还得添加新的主机，管理工作并没有完全消失。</p><p>但是管理一套集群带来了很大的复杂性，这也和使用云计算的初衷相反，更称不上云原生。</p><p>从用户的角度再次审视一下，可以发现一个长时间被我们忽略的问题：为什么只是想运行容器，非得先买一台 VM 装好 Docker，或者自己搭建一套 Kubernetes 集群，或者使用类似 EKS 这样的服务，乐此不疲的进行各种配置和调试，不仅花费固定的资产费，还增加了很多并没有任何价值的运维管理工作。</p><p>既然我们嫌弃手动在多台主机中部署容器过于麻烦，将其交给集群管理和调度系统去做，那么维护调度系统同样繁杂的工作，是不是也可以交给别人来做，外包出去呢？</p><p>按照精益思想，这些和核心业务目标无关，不能带来任何用户价值的过程，都属于浪费行为，都需要提出。</p><p>这时候，出现了 Serverless infrastructure 服务，最早的比如国内的 <a href="https://hyper.sh/" target="_blank" rel="noopener">hyper.sh</a> （2016.8 GA），以及去年发布的 AWS 的 Fargate（2017.12），微软的 ACI（Azure Container Instance，2017.7） 等。</p><p>以 <a href="http://hyper.sh" target="_blank" rel="noopener">hyper.sh</a> 为例，使用起来和 Docker 非常类似，可以将本地的 Docker 体验原封不动的搬到云端：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ brew install hyper  </span><br><span class="line">$ hyper pull mysql  </span><br><span class="line">$ hyper run mysql  </span><br><span class="line">MySQL is running...  </span><br><span class="line">$ hyper run --link mysql wordpress  </span><br><span class="line">WordPress is running...  </span><br><span class="line">$ hyper fip attach 22.33.44.55 wordpress  </span><br><span class="line">22.33.44.55 </span><br><span class="line">$ open 22.33.44.55</span><br></pre></td></tr></table></figure><p>大部分命令从 <code>docker</code> 换成 <code>hyper</code> 就可以了，体验如同使用 Docker 一模一样，第一次看到这样的应用给人的新奇感，并不亚于当初的 Docker 。</p><p>使用 Serverless infrastructure，我们可以再不必为如下事情烦恼：</p><ul><li>不必再去费心选择 VM 实例的类型，需要多少 CPU 和内存</li><li>不必再担心使用什么版本的 Docker 和集群管理软件</li><li>不必担心 VM 内中间件的安全漏洞</li><li>不必担心集群资源利用率太低</li><li>从为资源池付费变为为运行中的容器付费</li><li>完全不可变基础设施</li><li>不用因为 ps 时看到各种无聊的 agent 而心理膈应</li></ul><p>我们需要做的就是安心写自己的业务应用，构建自己的镜像，选择合适的容器大小，付钱给 cloud 厂商，让他们把系统做好，股票涨高高。</p><h2><span id="fargate此处也可以换做-aci-大厂表态">Fargate（此处也可以换做 ACI ）：大厂表态</span></h2><p>尽管 AWS 不像 GCP 那样“热衷”于容器，但是 AWS 也还是早就提供了 ECS（Elastic Container Service）服务。</p><p>去年发布的 AWS Fargate 则是个无服务器的容器服务，Fargate 是为了实现 AWS 的容器服务，比如 ECS（Elastic Container Service） 和 EKS（Elastic Kubernetes Service） 等，将容器运行所需要的基础设施进行抽象化的技术，并且现在 ECS 已经可以直接使用 Fargate。</p><p>和提供虚拟机的 EC2 不同，Fargate 提供的是容器运行实例，用户以容器作为基本的运算单位，而不必担心底层主机实例的管理，用户只需建立容器镜像，指定所需要的 CPU 和内存大小，设置相应的网络和IAM（身分管理）策略即可。</p><p>对于前面我们的疑问，AWS 的答案是基础设施的坑我们来填，你们只需要专心写好自己的应用程序就行了，你不必担心启动多少资源，我们来帮你进行容量管理，你只需要为你的使用付费就行了。</p><p>可以说 Fargate 和 Lambda 等产品都诞生于此哲学之下。</p><p>终于可以专心编写自己最擅长的 CRUD 了，happy，happy。</p><h2><span id="serverless-infrastructure-vs-serverless-compute">Serverless infrastructure vs Serverless compute</span></h2><p>再多说几句，主要是为了帮助大家辨别两种不同的无服务器架构：无服务器计算和无服务器基础设施。</p><p>说实话一下子从 EC2 迁移到 Lambda ，这步子确实有点大。</p><p>Lambda 等 FaaS 产品虽然更加简单，但是存在有如下很多缺点：</p><ul><li>使用场景：Lambda 更适合用户操作或事件驱动，不适合做守护服务、批处理等业务</li><li>灵活性：固定的内核、AMI等，无法定制</li><li>资源限制：文件系统、内存、进程线程数、请求 body 大小以及执行时间等很多限制</li><li>编程语言限制</li><li>很难做服务治理</li><li>不方便调试和测试</li></ul><p>Lambda 和容器相比最大的优势就是运维工作更少，基本没有，而且计费更精确，不需要为浪费的计算资源买单，而且 Lambda 响应更快，扩容效率会高一些。</p><p>可以认为 Fargate 等容器实例，就是结合了 EC2 实例和 Lambda 优点的产品，既像 Lambda 一样轻量，更关注核心的应用程序，还能像 EC2 一样带来很大的灵活性和可控性。</p><p>云原生会给用户更多的控制，但是需要用户更少的投入和负担。</p><p>Serverless infrastructure 可以让容器更加 cloud native。</p><h2><span id="fully-managed大势所趋">fully managed：大势所趋</span></h2><p>所谓的 fully managed，可以理解为用户花费很少的成本，就可以获得想要的产品、服务并可以进行相应的控制。</p><p>这两天，阿里云发布了 Serverless Kubernetes ，Serverless Kubernetes 与原生的 Kubernetes 完全兼容，可以采用标准的 API、CLI 来部署和管理应用，还可以继续使用各种传统资产，并且还能获得企业级的高可用和安全性保障。难道以后我们连 Kubernetes 也不用自己装了，大部分人只需要掌握 kubectl 命令就好了。</p><p>IaaS 的出现，让我们丢弃了各种 provision 工具，同时，各种 configuration management 工具如雨后春笋般的出现和普及；容器的出现，又让我们扔掉了刚买还没看几页的各种 Chef/Puppet 入门/圣经，匆忙学起 Kubernetes；有了 Serverless infrastructure，也差不多可以和各种编排工具说拜拜了。</p><p>不管你们是在单体转微服务，还是在传统上云、转容器，估计大家都会喜欢上 fully managed 的服务，人人都做 Ops，很多运维工作都可以共同分担。当然，也会有一部分运维工程师掩面而逃。</p><blockquote><p>本文转载自：「 人间指南 」，原文：<a href="https://tinyurl.com/exvzu9tb" target="_blank" rel="noopener">https://tinyurl.com/exvzu9tb</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;世界上有两种基础设施，一种是拿来主义，另一种是自主可控。&lt;/p&gt;
&lt;p&gt;原谅我也蹭个已经被浇灭的、没怎么火起来的热点。不过我们喜欢的是拿来主义，&lt;strong&gt;够用就行，不想也不需要过多的控制，也不想惹过多的麻烦&lt;/strong&gt;，也就是 fully managed。&lt;/p&gt;
&lt;p&gt;之所以想到写这篇文章，源于前几天看到的这篇来自微软 Azure 的博客内容： &lt;a href=&quot;https://thenewstack.io/the-future-of-Kubernetes-is-serverless/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Future of Kubernetes Is Serverless&lt;/a&gt; ，然后又顺手温习了一遍 AWS CTO 所撰写的 &lt;a href=&quot;https://www.allthingsdistributed.com/2018/04/changing-calculus-containers-cloud.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Changing the calculus of containers in the cloud&lt;/a&gt; 这篇文章。这两篇文章你觉得有可能有广告的嫌疑，都是在推销自家的共有云服务，但是仔细品味每一句话，我却觉得几乎没有几句废话，都很说到点子上，你可以点击进去看下原文。&lt;/p&gt;
&lt;p&gt;有个前提需要说明的是，这里的 Serverless 指的是 Serverless infrastructure，而不是我们常听到的 AWS Lambda，Microsoft Azure Functions 或 Google Cloud Functions 等函数（功能）即服务（FaaS）技术，为了便于区分，我们将这些 FaaS 称为无服务器计算，和我们本文要介绍的无服务器基础设施还是不一样的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>GitHub 星标 2.1 K，可能是最简单好用的纯文本流程图制作工具</title>
    <link href="https://www.hi-linux.com/posts/16328.html"/>
    <id>https://www.hi-linux.com/posts/16328.html</id>
    <published>2022-01-02T01:00:00.000Z</published>
    <updated>2022-01-13T05:34:07.910Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天要推荐一个可能是最简单的流程图制作工具了，小编第一次使用就有点上头，爱不释手，必须要推荐给大家。</p><p>这款工具叫 <code>flowchart-fun</code>，绝对是我见过最简单的流程图制作工具，任何人都可以简单的上手。我们看一下操作界面如下：</p><p><img src="https://img.hi-linux.com/staticfile/image-20210813122631680-2021-08-13-Xxy5KF.png" alt></p><a id="more"></a><p>流程图的制作原理很简单，图表依次从左到右画，每一行为一个方块，缩进就代表向右移动，同时会带有方向的箭头。所以使用的规则很简单，就跟正常写作一样，缩进即可。这个工具不管是用来做思维导图，或者是做流程图都很简单，对于我这种不喜欢去拖拽方块的人来说，简直就是神器。</p><p>文字描述使用方式可能比较苍白，我们来看下示例，毕竟流程图一般是一些指向性的结构。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210813123002512-2021-08-13-OPu5Bf.png" alt></p><p>以上示例是不是还挺简单的。</p><p>另外一个好处，用文字表示流程图的话，可以很方便的追溯更改的历史。同时只要按规则也可以很方便自动去生成对应的文字表示。</p><blockquote><p>试用网址：<a href="https://flowchart.fun/" target="_blank" rel="noopener">https://flowchart.fun/</a></p></blockquote><p>更多项目详情请查看开源项目地址：<a href="https://github.com/tone-row/flowchart-fun" target="_blank" rel="noopener">https://github.com/tone-row/flowchart-fun</a></p><blockquote><p>本文转载自：「 GitHub精选 」，原文：<a href="https://tinyurl.com/25htjd93" target="_blank" rel="noopener">https://tinyurl.com/25htjd93</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天要推荐一个可能是最简单的流程图制作工具了，小编第一次使用就有点上头，爱不释手，必须要推荐给大家。&lt;/p&gt;
&lt;p&gt;这款工具叫 &lt;code&gt;flowchart-fun&lt;/code&gt;，绝对是我见过最简单的流程图制作工具，任何人都可以简单的上手。我们看一下操作界面如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.hi-linux.com/staticfile/image-20210813122631680-2021-08-13-Xxy5KF.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款 GitHub 星标 15.6K 的神器，可一键将 MySQL、PostgreSQL、SQL Server 等数据库转换为智能电子表格！</title>
    <link href="https://www.hi-linux.com/posts/15719.html"/>
    <id>https://www.hi-linux.com/posts/15719.html</id>
    <published>2022-01-02T01:00:00.000Z</published>
    <updated>2022-01-13T05:34:07.914Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>不知道大家了解 Airtable 么？Airtable 是海外大名鼎鼎的在线表格应用工具，Airtable 建立在这样一个信念上：软件不应该决定你的工作方式，而应该由你决定软件的工作方式。我们的使命是使任何人都能构建出满足自己需求的工具，从而使软件充分个性化。</p><a id="more"></a><p>今天推荐一个对标 Airtable 的开源产品 NocoDB，目前支持将 MySQL、PostgreSQL、SQL Server、SQLite 和 MariaDB 转换为一个智能的在线电子表格。它不仅可以把数据库和图片等数据转化成表格的方式展现，还提供了团队协作、工作流接入以及更加开放 API 服务。让团队在数据上工作，数据就在手边 “即视即用”。</p><p><img src="https://img.hi-linux.com/staticfile/OpenSourceAirtableAlternative-2021-07-30-9Ag2f4.png" alt></p><p>NocoDB 目前支持丰富的电子表格接口，简单易用。比如搜索、排序、创建/分享视图等功能都支持。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210730154904436-2021-07-30-4i4Q9Q.png" alt></p><p>另外还支持与其他的第三方应用进行自动化的流程联动，比如聊天软件、邮件等。同时支持丰富的 API 用于与你现有的系统对接，以此也能看出 NocoDB 是完全以开放的生态来建设的。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210730154959452-2021-07-30-XACrDF.png" alt></p><p>下图是 NocoDB 为什么开发以及作者希望达成的愿景。大概意思是现在使用电子表格的用户太多了，每天有超过 10 亿，但是个人电脑安装的电子表格计算能力有限，而这些人并不会使用像数据库一样的工具，而现状一些 SaaS 工具在使用体验上并不是很友好。nocodb 希望提供一个开放的无代码的平台，以在线电子表格的易操作为基础，帮助这些在商业上有类似数据计算需求的用户，人人都可使用。</p><p><img src="https://img.hi-linux.com/staticfile/image-20210730155031980-2021-07-30-cpjuKB.png" alt></p><p>更多项目详情请查看项目地址：<a href="https://github.com/nocodb/nocodb" target="_blank" rel="noopener">https://github.com/nocodb/nocodb</a></p><blockquote><p>本文转载自：「 GitHub精选 」，原文：<a href="https://tinyurl.com/2h4t5sn3" target="_blank" rel="noopener">https://tinyurl.com/2h4t5sn3</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不知道大家了解 Airtable 么？Airtable 是海外大名鼎鼎的在线表格应用工具，Airtable 建立在这样一个信念上：软件不应该决定你的工作方式，而应该由你决定软件的工作方式。我们的使命是使任何人都能构建出满足自己需求的工具，从而使软件充分个性化。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
      <category term="NocoDB" scheme="https://www.hi-linux.com/tags/NocoDB/"/>
    
  </entry>
  
  <entry>
    <title>15 个实用的 Kubernetes 集群资源清理命令</title>
    <link href="https://www.hi-linux.com/posts/2396.html"/>
    <id>https://www.hi-linux.com/posts/2396.html</id>
    <published>2021-12-20T01:00:00.000Z</published>
    <updated>2021-12-20T06:21:52.466Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>长时间运行的集群，常会面临各种资源耗尽的问题，另外磁盘不足时 Kubelet 还会主动清理镜像增加不确定因素，本文提供了一些命令片段用于清理工作。</p></blockquote><h2><span id="kubernetes-基础对象清理">Kubernetes 基础对象清理</span></h2><ul><li>清理 Evicted 状态的 Pod</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide | grep Evicted | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pod -n</span><br></pre></td></tr></table></figure><ul><li>清理 Error 状态的 Pod</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide | grep Error | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pod -n</span><br></pre></td></tr></table></figure><ul><li>清理 Completed 状态的 Pod</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide | grep Completed | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pod -n</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>清理没有被使用的 PV</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe -A pvc | grep -E &quot;^Name:.*$|^Namespace:.*$|^Used By:.*$&quot; | grep -B 2 &quot;&lt;none&gt;&quot; | grep -E &quot;^Name:.*$|^Namespace:.*$&quot; | cut -f2 -d: | paste -d &quot; &quot; - - | xargs -n2 bash -c &#39;kubectl -n $&#123;1&#125; delete pvc $&#123;0&#125;&#39;</span><br></pre></td></tr></table></figure><ul><li>清理没有被绑定的 PVC</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pvc --all-namespaces | tail -n +2 | grep -v Bound | awk &#39;&#123;print $1,$2&#125;&#39; | xargs -L1 kubectl delete pvc -n</span><br></pre></td></tr></table></figure><ul><li>清理没有被绑定的 PV</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pv | tail -n +2 | grep -v Bound | awk &#39;&#123;print $1&#125;&#39; | xargs -L1 kubectl delete pv</span><br></pre></td></tr></table></figure><h2><span id="linux-清理">Linux 清理</span></h2><ul><li>查看磁盘全部空间</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ df -hl &#x2F;</span><br><span class="line"></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">&#x2F;dev&#x2F;sda2       100G   47G   54G  47% &#x2F;</span><br></pre></td></tr></table></figure><ul><li>查看指定目录占用</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ du -sh .</span><br><span class="line"></span><br><span class="line">24G.</span><br></pre></td></tr></table></figure><ul><li>删除指定前缀的文件夹</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;nfsdata</span><br><span class="line">$ ls | grep archived- |xargs -L1 rm -r</span><br></pre></td></tr></table></figure><ul><li>清理僵尸进程</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps -A -ostat,ppid | grep -e &#39;^[Zz]&#39; | awk &#39;&#123;print &#125;&#39; | xargs kill -HUP &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h2><span id="docker-清理">Docker 清理</span></h2><ul><li>查看磁盘使用情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker system df</span><br><span class="line"></span><br><span class="line">TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE</span><br><span class="line">Images              361                 23                  178.5GB             173.8GB (97%)</span><br><span class="line">Containers          29                  9                   6.682GB             6.212GB (92%)</span><br><span class="line">Local Volumes       4                   0                   3.139MB             3.139MB (100%)</span><br><span class="line">Build Cache         0                   0                   0B                  0B</span><br></pre></td></tr></table></figure><ul><li>清理 none 镜像</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker images | grep none | awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi</span><br></pre></td></tr></table></figure><ul><li>清理不再使用的数据卷</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume rm $(docker volume ls -q)</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume prune</span><br></pre></td></tr></table></figure><ul><li>清理缓存</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker builder prune</span><br></pre></td></tr></table></figure><ul><li>全面清理</li></ul><p>删除关闭的容器、无用的存储卷、无用的网络、dangling 镜像（无 tag 镜像）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker system prune -f</span><br></pre></td></tr></table></figure><ul><li>清理正则匹配上的镜像</li></ul><p>这里清理的是 <code>master-8bcf8d7-20211206-111155163</code> 格式的镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker images |grep -E &quot;([0-9a-z]*[-])&#123;3,&#125;[0-9]&#123;9&#125;&quot; |awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi</span><br></pre></td></tr></table></figure><h2><span id="设置定时">设置定时</span></h2><ul><li>查看定时任务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -l</span><br></pre></td></tr></table></figure><ul><li>设置定时任务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br></pre></td></tr></table></figure><p>文本新增定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*&#x2F;35 *&#x2F;6 * * *  docker images | grep none | awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi</span><br><span class="line">45 1 * * * docker system prune -f</span><br></pre></td></tr></table></figure><p>这里第一个任务是每隔六个小时的第 35 分钟执行，第二个任务每天的 1 时 45 分执行。</p><ul><li>定时任务的格式</li></ul><p>设置定时格式: <code>* * * * * shell</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">第一个星号，minute，分钟，值为 0-59</span><br><span class="line">第二个星号，hour，小时，值从 0-23</span><br><span class="line">第三个星号，day，天，值为从 1-31</span><br><span class="line">第四个星号，month，月，值为从 1-12 月，或者简写的英文，比如 Nov、Feb 等</span><br><span class="line">第五个星号，week 周，值为从 0-6 或者简写的英文，Wen、Tur 等，代表周几，其中 0 代表周末</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 陈少文的网站 」，原文：<a href="https://tinyurl.com/yckjyedn" target="_blank" rel="noopener">https://tinyurl.com/yckjyedn</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;长时间运行的集群，常会面临各种资源耗尽的问题，另外磁盘不足时 Kubelet 还会主动清理镜像增加不确定因素，本文提供了一些命令片段用于清理工作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Kubernetes-基础对象清理&quot;&gt;Kubernetes 基础对象清理&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;清理 Evicted 状态的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get pods --all-namespaces -o wide | grep Evicted | awk &amp;#39;&amp;#123;print $1,$2&amp;#125;&amp;#39; | xargs -L1 kubectl delete pod -n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;清理 Error 状态的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get pods --all-namespaces -o wide | grep Error | awk &amp;#39;&amp;#123;print $1,$2&amp;#125;&amp;#39; | xargs -L1 kubectl delete pod -n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;清理 Completed 状态的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ kubectl get pods --all-namespaces -o wide | grep Completed | awk &amp;#39;&amp;#123;print $1,$2&amp;#125;&amp;#39; | xargs -L1 kubectl delete pod -n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>云原生分布式文件存储 MinIO 保姆级中文教程</title>
    <link href="https://www.hi-linux.com/posts/43710.html"/>
    <id>https://www.hi-linux.com/posts/43710.html</id>
    <published>2021-12-07T01:00:00.000Z</published>
    <updated>2021-12-08T03:11:30.366Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p><strong>MinIO - 构建高性能的云原生数据的多云对象存储</strong></p></blockquote><p><code>MinIO</code> 提供开源、高性能、兼容 <code>s3</code> 的对象存储，为每个公共云、每个 <code>Kubernetes</code> 发行版、私有云和边缘云中无缝运行，使其成为混合云和多云对象存储的领导者。</p><ul><li><a href="https://min.io/" target="_blank" rel="noopener">MinIO 英文官网地址</a></li><li><a href="http://www.minio.org.cn/" target="_blank" rel="noopener">MinIO 中文官网地址</a></li></ul><h2><span id="1-minio-的应用场景">1. MinIO 的应用场景</span></h2><blockquote><p><strong>MinIO 是一个非常轻量的服务，可以很简单的和其他应用的结合。</strong></p></blockquote><p><code>MinIO</code> 是一个基于 <code>Apache License v2.0</code> 开源协议的对象存储服务。它兼容亚马逊 <code>S3</code> 云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从 <code>KB</code> 到最大 <code>TB</code> 不等。</p><ul><li>网盘 : 海量文件</li><li>社交网站：海量图片</li><li>电商网站：海量商品图片</li><li>视频网站：海量视频文件</li></ul><p>对于中小型企业，如果不选择存储上云，那么 <code>MinIO</code> 是个不错的选择，麻雀虽小，五脏俱全。当然 <code>MinIO</code> 除了直接作为对象存储使用，还可以作为云上对象存储服务的网关层，无缝对接到 <code>Amazon S3</code> 等。</p><a id="more"></a><h2><span id="2-minio-的系统特点">2. MinIO 的系统特点</span></h2><blockquote><p><strong>介绍 MinIO 服务的主要特点和特性</strong></p></blockquote><ul><li>[1] 高性能<ul><li><code>MinIO</code> 是全球领先的对象存储先锋，在标准硬件上，读/写速度上高达 <code>183GB/s</code> 和<code> 171GB/s</code>，已经成为 <code>Hadoop HDFS</code> 的替代品。</li><li><code>MinIO</code> 用作云原生应用程序的主要存储，与传统对象存储相比，云原生应用程序需要更高的吞吐量和更低的延迟。而这些都是 <code>MinIO</code> 能够达成的性能指标。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-01-2021-12-06-g5KIqw.png" alt="MinIO分布式文件存储 - 高性能"></p><ul><li>[2] 可扩展性<ul><li><code>MinIO</code> 一直秉承着 “简单可扩展” 的理念，为对象存储带来了一个简单的缩放模型。借助在此基础之上，可以实现 <code>MinIO</code> 从单个群集到其他 <code>MinIO</code> 群集联合使用的情况，并且在需要时可以跨越多个不同的数据中心。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-02-2021-12-06-SDx7Q3.png" alt="MinIO分布式文件存储 - 可扩展性"></p><ul><li>[3] 开放全部源代码 + 企业级支持<ul><li><code>MinIO</code> 基于 <code>Apache V2 license</code> 的 <code>100%</code> 开放源代码的产品。</li><li>客户能够自动的、无限制、自由免费使用和集成 MinIO、自由的创新和创造、 自由的去修改、自由的再次发行新的版本和软件。其部署的多样性使软件变得更加坚固，这是专有软件无法提供的。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-03-20211206173811532-2021-12-06-kKFztU.png" alt="MinIO分布式文件存储 - 开放全部源代码+企业级支持"></p><ul><li>[4] 混合云和多云<ul><li>亚马逊云的 <code>S3 API</code> 是在全球范围内达到共识的对象存储的协议。</li><li>当添加到数以百万计的私有云实例和广泛的边缘部署时，MinIO 是混合云的领导者。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-04-2021-12-06-Z6G0QE.png" alt="MinIO分布式文件存储 - 混合云和多云"></p><p><strong>MinIO分布式文件存储 - 混合云和多云</strong></p><ul><li>[5] 简单而强大<ul><li>极简主义是 <code>MinIO</code> 的指导性设计原则。简单性减少了出错的机会，提高了正常运行时间，提供了可靠性，同时简单性又是性能的基础。</li><li>只需下载一个二进制文件然后执行，即可在几分钟内安装和配置 <code>MinIO</code>。<code>MinIO</code> 升级是通过一个简单命令完成的，这个命令可以无中断的完成 <code>MinIO</code> 的升级，并且不需要停机即可完成升级操作。</li></ul></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-05-20211206173756926-2021-12-06-dKfVuA.gif" alt="MinIO分布式文件存储 - 简单而强大"></p><h2><span id="3-minio-的基础概念">3. MinIO 的基础概念</span></h2><blockquote><p><strong>了解如下基础概念，可以方便的理解其使用方式。</strong></p></blockquote><ul><li>存储相关的概念<ul><li>一个对象存储在一个 <code>Set</code></li><li>一个集群划分为多个 <code>Set</code></li><li>一个 <code>Set</code> 中的 <code>Drive</code> 尽可能分布在不同的节点上</li><li>一个 <code>Set</code> 包含的 <code>Drive</code> 数量是固定的，默认由系统根据集群规模自动计算</li></ul></li></ul><table><thead><tr><th style="text-align:left">概念名称</th><th style="text-align:left">对应含义解释</th></tr></thead><tbody><tr><td style="text-align:left"><code>Object</code></td><td style="text-align:left">存储的基本对象；比如文件、图片等等</td></tr><tr><td style="text-align:left"><code>Bucket</code></td><td style="text-align:left">用于存储 <code>Object</code> 的逻辑空间；相互之间互相隔离；类似于系统中的顶层文件夹</td></tr><tr><td style="text-align:left"><code>Drive</code></td><td style="text-align:left">即存储数据的磁盘；所有的对象数据都会存储在 <code>Drive</code> 里面</td></tr><tr><td style="text-align:left"><code>Set</code></td><td style="text-align:left">即一组 <code>Drive</code> 的集合；分布式部署根据集群规模自动划分一个或多个 <code>Set</code></td></tr></tbody></table><ul><li><strong>纠删码 - EC - Erasure Code</strong></li></ul><p><code>MinIO</code> 使用 <strong>纠删码和校验和</strong> 机制来保证高可靠性，即便丢失一半数量(<code>N/2</code>)的硬盘，仍然可以恢复数据。纠删码是一种恢复丢失和损坏数据的数学算法，<code>MinIO</code> 采用 <code>Reed-Solomon code</code> 将对象拆分成 <code>N/2</code> 数据和 <code>N/2</code> 奇偶校验块。这就意味着如果是 <code>12</code> 块盘，一个对象会被分成 <code>6</code> 个数据块、<code>6</code> 个奇偶校验块，你可以丢失任意 <code>6</code> 块盘，仍可以从剩下的盘中的数据进行恢复。</p><p>纠删码的工作原理和 <code>RAID</code> 或者复制不同，像 <code>RAID6</code> 可以在损失两块盘的情况下不丢数据，而 <code>MinIO</code> 纠删码可以在丢失一半的盘的情况下，仍可以保证数据安全。而且 <code>MinIO</code> 纠删码是作用在对象级别，可以一次恢复一个对象，而 <code>RAID</code> 是作用在卷级别，数据恢复时间很长。<code>MinIO</code> 对每个对象单独编码，存储服务一经部署，通常情况下是不需要更换硬盘或者修复。<code>MinIO</code> 纠删码的设计目标是为了性能和尽可能的使用硬件加速。</p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-06-2021-12-06-ytxrnO.jpg" alt="MinIO分布式文件存储 - 对象的存储形式"></p><ul><li><strong>对象的存储形式</strong></li></ul><p>文件对象上传到 <code>MinIO</code> 上面，会在对应的磁盘当中，以 <code>Bucket</code> 名称为目录，文件名称为下一级目录，文件名下是 <code>part.1</code> 和 <code>xl.meta</code>，前者是编码数据块及检验块，后者是元数据文件。</p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-07-20211206173827530-2021-12-06-p2Otij.png" alt="MinIO分布式文件存储 - 对象的存储形式(网络采集的图片)"></p><ul><li><strong>常见的使用方案</strong></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-08-2021-12-06-QGpa3P.png" alt="MinIO分布式文件存储 - 常见的使用方案(网络采集的图片)"></p><h2><span id="4-minio-的安装部署-单机">4. MinIO 的安装部署 - 单机</span></h2><blockquote><p><strong>建议使用容器化安装和部署方式 - 简单和好用</strong></p></blockquote><p>需要注意的是，单机版本无法使用，版本控制、对象锁定和存储桶复制等功能。如果需要使用，是需要部署 <strong>带有纠删码的分布式 MinIO</strong>。</p><ul><li>单机版 - 容器安装 - 没有纠错码版本<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 内嵌了一个MinIO的对象服务</span><br><span class="line"># http:&#x2F;&#x2F;127.0.0.1:9000 (minioadmin:minioadmin)</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">    -p 9000:9000 -p 9001:9001 \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data --console-address &quot;:9001&quot;</span><br><span class="line"></span><br><span class="line"># 启动时自定义用户和密码</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">    -p 9000:9000 -p 9001:9001 \</span><br><span class="line">    -e &quot;MINIO_ROOT_USER&#x3D;admin&quot; \</span><br><span class="line">    -e &quot;MINIO_ROOT_PASSWORD&#x3D;123456&quot; \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data --console-address &quot;:9001&quot;</span><br><span class="line"></span><br><span class="line"># Windows系统启动</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">    -p 9000:9000 -p 9001:9001 \</span><br><span class="line">    -v D:\data:&#x2F;data \</span><br><span class="line">    -e &quot;MINIO_ROOT_USER&#x3D;admin&quot; \</span><br><span class="line">    -e &quot;MINIO_ROOT_PASSWORD&#x3D;123456&quot; \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data --console-address &quot;:9001&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 设置安全秘钥启动</span><br><span class="line">$ echo &quot;admin&quot; | docker secret create access_key -</span><br><span class="line">$ echo &quot;123456&quot; | docker secret create secret_key -</span><br><span class="line"></span><br><span class="line"># 使用docker-service的安全秘钥启动</span><br><span class="line">$ docker service create --name&#x3D;&quot;minio-service&quot; \</span><br><span class="line">    --secret&#x3D;&quot;access_key&quot; --secret&#x3D;&quot;secret_key&quot; \</span><br><span class="line">    --env&#x3D;&quot;MINIO_ROOT_USER_FILE&#x3D;my_access_key&quot; \</span><br><span class="line">    --env&#x3D;&quot;MINIO_ROOT_PASSWORD_FILE&#x3D;my_secret_key&quot; \</span><br><span class="line">    quay.io&#x2F;minio&#x2F;minio server &#x2F;data</span><br></pre></td></tr></table></figure><ul><li>单机版 - 容器安装 - 带有纠错码版本<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 命令行启动</span><br><span class="line">$ minio server \</span><br><span class="line">    &#x2F;data1 &#x2F;data2 &#x2F;data3 &#x2F;data4 \</span><br><span class="line">    &#x2F;data5 &#x2F;data6 &#x2F;data7 &#x2F;data8</span><br><span class="line"></span><br><span class="line"># 容器启动</span><br><span class="line">$ docker run --name&#x3D;minio-test \</span><br><span class="line">  -p 9000:9000 -p 9001:9001 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data1:&#x2F;data1 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data2:&#x2F;data2 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data3:&#x2F;data3 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data4:&#x2F;data4 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data5:&#x2F;data5 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data6:&#x2F;data6 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data7:&#x2F;data7 \</span><br><span class="line">  -v &#x2F;mnt&#x2F;data8:&#x2F;data8 \</span><br><span class="line">  quay.io&#x2F;minio&#x2F;minio server &#x2F;data&#123;1...8&#125; --console-address &quot;:9001&quot;</span><br></pre></td></tr></table></figure><ul><li>单机版 - 命令安装<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># MacOS</span><br><span class="line">$ brew install minio&#x2F;stable&#x2F;minio</span><br><span class="line">$ minio server &#x2F;data</span><br><span class="line"></span><br><span class="line"># linux</span><br><span class="line">$ apt install minio</span><br><span class="line">$ minio server &#x2F;data</span><br></pre></td></tr></table></figure><ul><li>单机版 - 二进制安装<ul><li><code>9000</code> 端口为自带的 <code>Web</code> 网页入库</li><li><code>9001</code> 端口为使用 <code>API</code> 和客户端的连接口</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># MacOS</span><br><span class="line">$ wget https:&#x2F;&#x2F;dl.min.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;darwin-amd64&#x2F;minio</span><br><span class="line">$ chmod +x minio</span><br><span class="line">$ .&#x2F;minio server &#x2F;data</span><br><span class="line"></span><br><span class="line"># Windows</span><br><span class="line">$ wget https:&#x2F;&#x2F;dl.min.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;windows-amd64&#x2F;minio.exe</span><br><span class="line">$ minio.exe server D:\</span><br><span class="line"></span><br><span class="line"># Linux</span><br><span class="line">$ wget https:&#x2F;&#x2F;dl.min.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;linux-amd64&#x2F;minio</span><br><span class="line">$ chmod +x minio</span><br><span class="line">$ .&#x2F;minio server &#x2F;data</span><br><span class="line"></span><br><span class="line">$ ufw allow 9000:9010&#x2F;tcp</span><br><span class="line">$ firewall-cmd --get-active-zones</span><br><span class="line">$ firewall-cmd --zone&#x3D;public --add-port&#x3D;9000&#x2F;tcp --permanent</span><br><span class="line">$ firewall-cmd --reload</span><br></pre></td></tr></table></figure><h2><span id="5-minio-的安装部署-分布式">5. MinIO 的安装部署 - 分布式</span></h2><blockquote><p><strong>建议使用容器化安装和部署方式 - 简单和好用</strong></p></blockquote><p>在大数据领域，通常的设计理念都是无中心和分布式。<code>MinIO</code> 也提供了分布式部署的方式，其好处在于，可以提供一个高可用的对象存储服务，确保数据不会丢失和一致。<code>MinIO</code> 在分布式和单机模式下，所有读写操作都严格遵守 <code>read-after-write</code> 一致性模型。</p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-09-2021-12-06-WIfj1H.png" alt="MinIO分布式文件存储 - 分布式架构图"></p><ul><li><strong>命令行方式启动 - client</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 设置变量</span><br><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;SECRET_KEY&gt;</span><br><span class="line"></span><br><span class="line"># 命令行启动方式格式</span><br><span class="line">$ minio server http:&#x2F;&#x2F;host&#123;1...n&#125;&#x2F;export&#123;1...m&#125;</span><br><span class="line">$ minio server http:&#x2F;&#x2F;host&#123;1...n&#125;&#x2F;export&#123;1...m&#125; http:&#x2F;&#x2F;host&#123;o...z&#125;&#x2F;export&#123;1...m&#125;</span><br><span class="line"></span><br><span class="line"># 命令行启动方式示例</span><br><span class="line">minio server http:&#x2F;&#x2F;192.168.1.11&#x2F;export1 http:&#x2F;&#x2F;192.168.1.12&#x2F;export2 \</span><br><span class="line">             http:&#x2F;&#x2F;192.168.1.13&#x2F;export3 http:&#x2F;&#x2F;192.168.1.14&#x2F;export4 \</span><br><span class="line">             http:&#x2F;&#x2F;192.168.1.15&#x2F;export5 http:&#x2F;&#x2F;192.168.1.16&#x2F;export6 \</span><br><span class="line">             http:&#x2F;&#x2F;192.168.1.17&#x2F;export7 http:&#x2F;&#x2F;192.168.1.18&#x2F;export8</span><br></pre></td></tr></table></figure><ul><li><strong>容器方式启动 - docker</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.7&#39;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  minio:</span><br><span class="line">    restart: on-failure</span><br><span class="line">    container_name: app_minio</span><br><span class="line">    image: quay.io&#x2F;minio&#x2F;minio:RELEASE.2021-11-09T03-21-45Z</span><br><span class="line">    command: server &#x2F;data --console-address &quot;:9001&quot;</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;80:9000&quot;</span><br><span class="line">      - &quot;81:9001&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - &quot;&#x2F;app_minio&#x2F;data:&#x2F;data&quot;</span><br><span class="line">    environment:</span><br><span class="line">      MINIO_ROOT_USER: admin</span><br><span class="line">      MINIO_ROOT_PASSWORD: 123456</span><br><span class="line">    healthcheck:</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http:&#x2F;&#x2F;localhost:9000&#x2F;minio&#x2F;health&#x2F;live&quot;]</span><br><span class="line">      interval: 30s</span><br><span class="line">      timeout: 20s</span><br><span class="line">      retries: 3</span><br><span class="line">    networks:</span><br><span class="line">      - app_minio_network</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  app_minio_network:</span><br></pre></td></tr></table></figure><ul><li>容器方式启动 - kubernetes<ul><li><a href="https://github.com/minio/charts" target="_blank" rel="noopener">helm minio charts</a></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 安装MinIO的chart</span><br><span class="line">$ helm install stable&#x2F;minio</span><br><span class="line"></span><br><span class="line"># 容器平台上面启动服务 - 单机</span><br><span class="line">$ helm install --name minio-release \</span><br><span class="line">    --namespace minio</span><br><span class="line">    --set rootUser&#x3D;rootuser,rootPassword&#x3D;rootpass123</span><br><span class="line">    --set persistence.size&#x3D;100Gi \</span><br><span class="line">    stable&#x2F;minio</span><br><span class="line"></span><br><span class="line">#  容器平台上面启动服务 - 分布式</span><br><span class="line">$ helm install --set mode&#x3D;distributed stable&#x2F;minio</span><br><span class="line">$ helm install --set mode&#x3D;distributed,numberOfNodes&#x3D;8 stable&#x2F;minio</span><br><span class="line">$ helm install --set mode&#x3D;shared,numberOfNodes&#x3D;8 stable&#x2F;minio</span><br><span class="line">$ helm install --set persistence.enabled&#x3D;false stable&#x2F;minio</span><br></pre></td></tr></table></figure><h2><span id="6-minio-的安装部署-多租户">6. MinIO 的安装部署 - 多租户</span></h2><blockquote><p><strong>建议使用容器化安装和部署方式 - 简单和好用</strong></p></blockquote><ul><li><strong>[1] 单主机 + 单磁盘</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ minio server --address :9001 &#x2F;data&#x2F;tenant1</span><br><span class="line">$ minio server --address :9002 &#x2F;data&#x2F;tenant2</span><br><span class="line">$ minio server --address :9003 &#x2F;data&#x2F;tenant3</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-10-2021-12-06-qGORMY.jpg" alt="MinIO分布式文件存储 - 多租户"></p><ul><li><strong>[2] 单主机 + 块磁盘 (有纠错码)</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ minio server --address :9001 &#x2F;disk&#123;1...4&#125;&#x2F;data&#x2F;tenant1</span><br><span class="line">$ minio server --address :9002 &#x2F;disk&#123;1...4&#125;&#x2F;data&#x2F;tenant2</span><br><span class="line">$ minio server --address :9003 &#x2F;disk&#123;1...4&#125;&#x2F;data&#x2F;tenant3</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-11-2021-12-06-j2cFg2.jpg" alt="MinIO分布式文件存储 - 多租户"></p><ul><li><strong>[3] 多主机 + 多块磁盘 (分布式+纠错码)</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;TENANT1_ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;TENANT1_SECRET_KEY&gt;</span><br><span class="line">$ minio server --address :9001 http:&#x2F;&#x2F;192.168.10.1&#123;1...4&#125;&#x2F;data&#x2F;tenant1</span><br><span class="line"></span><br><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;TENANT2_ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;TENANT2_SECRET_KEY&gt;</span><br><span class="line">$ minio server --address :9002 http:&#x2F;&#x2F;192.168.10.1&#123;1...4&#125;&#x2F;data&#x2F;tenant2</span><br><span class="line"></span><br><span class="line">$ export MINIO_ROOT_USER&#x3D;&lt;TENANT3_ACCESS_KEY&gt;</span><br><span class="line">$ export MINIO_ROOT_PASSWORD&#x3D;&lt;TENANT3_SECRET_KEY&gt;</span><br><span class="line">$ minio server --address :9003 http:&#x2F;&#x2F;192.168.10.1&#123;1...4&#125;&#x2F;data&#x2F;tenant3</span><br></pre></td></tr></table></figure><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-12-20211206174412358-2021-12-06-0zVHNj.jpg" alt="MinIO分布式文件存储 - 多租户"></p><h2><span id="7-minio-的网页使用">7. MinIO 的网页使用</span></h2><blockquote><p><strong>安装部署完成之后，建议使用界面操作，简单好用！</strong></p></blockquote><ul><li>[1] 运行服务 - docker-compose<ul><li><a href="https://raw.githubusercontent.com/minio/minio/master/docs/orchestration/docker-compose/docker-compose.yaml" target="_blank" rel="noopener"><code>docker-compose.yaml</code></a></li><li><a href="https://raw.githubusercontent.com/minio/minio/master/docs/orchestration/docker-compose/nginx.conf" target="_blank" rel="noopener"><code>nginx.conf</code></a></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">version: &quot;3.7&quot;</span><br><span class="line"></span><br><span class="line">x-minio-common: &amp;minio-common</span><br><span class="line">  image: quay.io&#x2F;minio&#x2F;minio:RELEASE.2021-11-24T23-19-33Z</span><br><span class="line">  command: server --console-address &quot;:9001&quot; http:&#x2F;&#x2F;minio&#123;1...4&#125;&#x2F;data&#123;1...2&#125;</span><br><span class="line">  expose:</span><br><span class="line">    - &quot;9000&quot;</span><br><span class="line">    - &quot;9001&quot;</span><br><span class="line">  environment:</span><br><span class="line">    MINIO_ROOT_USER: minio</span><br><span class="line">    MINIO_ROOT_PASSWORD: minio123</span><br><span class="line">  healthcheck:</span><br><span class="line">    test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http:&#x2F;&#x2F;localhost:9000&#x2F;minio&#x2F;health&#x2F;live&quot;]</span><br><span class="line">    interval: 30s</span><br><span class="line">    timeout: 20s</span><br><span class="line">    retries: 3</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  minio1:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio1</span><br><span class="line">    volumes:</span><br><span class="line">      - data1-1:&#x2F;data1</span><br><span class="line">      - data1-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  minio2:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio2</span><br><span class="line">    volumes:</span><br><span class="line">      - data2-1:&#x2F;data1</span><br><span class="line">      - data2-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  minio3:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio3</span><br><span class="line">    volumes:</span><br><span class="line">      - data3-1:&#x2F;data1</span><br><span class="line">      - data3-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  minio4:</span><br><span class="line">    &lt;&lt;: *minio-common</span><br><span class="line">    hostname: minio4</span><br><span class="line">    volumes:</span><br><span class="line">      - data4-1:&#x2F;data1</span><br><span class="line">      - data4-2:&#x2F;data2</span><br><span class="line"></span><br><span class="line">  nginx:</span><br><span class="line">    image: nginx:1.19.2-alpine</span><br><span class="line">    hostname: nginx</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9000:9000&quot;</span><br><span class="line">      - &quot;9001:9001&quot;</span><br><span class="line">    depends_on:</span><br><span class="line">      - minio1</span><br><span class="line">      - minio2</span><br><span class="line">      - minio3</span><br><span class="line">      - minio4</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  data1-1:</span><br><span class="line">  data1-2:</span><br><span class="line">  data2-1:</span><br><span class="line">  data2-2:</span><br><span class="line">  data3-1:</span><br><span class="line">  data3-2:</span><br><span class="line">  data4-1:</span><br><span class="line">  data4-2:</span><br></pre></td></tr></table></figure><ul><li><strong>[2] 启动服务</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># docker-compose</span><br><span class="line">$ docker stack deploy --compose-file docker-compose.yaml minio</span><br></pre></td></tr></table></figure><ul><li><strong>[3] 界面登录</strong></li></ul><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-13-20211206174432974-2021-12-06-k00IiE.png" alt="MinIO分布式文件存储 - 网页地址"></p><p><img src="https://img.hi-linux.com/staticfile/minio-file-storage-14-2021-12-06-2dPHBS.png" alt="MinIO分布式文件存储 - 网页地址"></p><h2><span id="8-minio-客户端使用">8. MinIO 客户端使用</span></h2><blockquote><p><strong>MinIO Client (mc) provides a modern alternative to UNIX commands</strong></p></blockquote><ul><li><strong>[1] MC 命令行工具安装</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 容器安装</span><br><span class="line">$ docker pull minio&#x2F;mc</span><br><span class="line">$ docker run minio&#x2F;mc ls play</span><br><span class="line">$ docker run -it --entrypoint&#x3D;&#x2F;bin&#x2F;sh minio&#x2F;mc</span><br><span class="line"></span><br><span class="line"># MacOS</span><br><span class="line">brew install minio&#x2F;stable&#x2F;mc</span><br><span class="line"></span><br><span class="line"># Linux</span><br><span class="line">$ wget http:&#x2F;&#x2F;dl.minio.org.cn&#x2F;client&#x2F;mc&#x2F;release&#x2F;linux-amd64&#x2F;mc</span><br><span class="line">chmod +x mc</span><br><span class="line"></span><br><span class="line"># 自动补全</span><br><span class="line">mc --autocompletion</span><br></pre></td></tr></table></figure><ul><li>[2] MC 命令行参数介绍<ul><li><code>mc xxx</code></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">alias        设置&#x2F;移除&#x2F;列出自定义的别名</span><br><span class="line">ls           列出文件和文件夹</span><br><span class="line">mb           创建一个存储桶或一个文件夹</span><br><span class="line">rb           移除一个桶</span><br><span class="line">cp           拷贝文件和对象</span><br><span class="line">mirror       给存储桶和文件夹做镜像</span><br><span class="line">cat          显示文件和对象内容</span><br><span class="line">head         显示对象的第n行</span><br><span class="line">pipe         将一个STDIN重定向到一个对象或者文件或者STDOUT</span><br><span class="line">share        生成用于共享的URL</span><br><span class="line">find         基于参数查找文件</span><br><span class="line">sql          在对象上运行SQL查询</span><br><span class="line">stat         显示对象元信息</span><br><span class="line">mv           移动文件和对象</span><br><span class="line">tree         以树的格式列出桶和对象</span><br><span class="line">du           统计磁盘使用情况</span><br><span class="line">retention    设置对象和桶的保留</span><br><span class="line">legalhold    设置对象的合法持有</span><br><span class="line">diff         对两个文件夹或者存储桶比较差异</span><br><span class="line">rm           删除文件和对象</span><br><span class="line">encrypt      管理桶加密配置</span><br><span class="line">events       管理对象通知</span><br><span class="line">watch        监听文件和对象的事件</span><br><span class="line">undo         取消PUT&#x2F;DELETE操作</span><br><span class="line">policy       管理访问策略</span><br><span class="line">tag          管理桶和对象的标签</span><br><span class="line">ilm          管理桶的生命周期</span><br><span class="line">version      输出版本信息</span><br><span class="line">replicate    配置服务器端桶复制</span><br><span class="line">admin        管理Minio服务器</span><br><span class="line">update       检查软件更新</span><br></pre></td></tr></table></figure><ul><li>[3] MC 服务端命令参数<ul><li><code>mc admin xxx</code></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">service     服务重启并停止所有MinIO服务器</span><br><span class="line">update      更新更新所有MinIO服务器</span><br><span class="line">info        信息显示MinIO服务器信息</span><br><span class="line">user        管理用户</span><br><span class="line">group       管理小组</span><br><span class="line">policy      MinIO服务器中定义的策略管理策略</span><br><span class="line">config      配置管理MinIO服务器配置</span><br><span class="line">heal        修复MinIO服务器上的磁盘，存储桶和对象</span><br><span class="line">profile     概要文件生成概要文件数据以进行调试</span><br><span class="line">top         顶部提供MinIO的顶部统计信息</span><br><span class="line">trace       跟踪显示MinIO服务器的http跟踪</span><br><span class="line">console     控制台显示MinIO服务器的控制台日志</span><br><span class="line">prometheus  Prometheus管理Prometheus配置</span><br><span class="line">kms         kms执行KMS管理操作</span><br><span class="line">bucket      管理MinIO服务器中定义的存储桶</span><br></pre></td></tr></table></figure><ul><li><strong>[4] 示例演示</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># MinIO云存储配置</span><br><span class="line">mc alias set minio http:&#x2F;&#x2F;192.168.1.51 admin 123456</span><br><span class="line">mc alias set s3 https:&#x2F;&#x2F;s3.amazonaws.com admin 123456</span><br><span class="line">mc alias set gcs  https:&#x2F;&#x2F;storage.googleapis.com admin 123456</span><br><span class="line"></span><br><span class="line"># 开始操作云存储 - 列出所有存储桶</span><br><span class="line">mc ls play</span><br><span class="line"></span><br><span class="line"># 创建一个桶</span><br><span class="line">mc mb play&#x2F;mybucket</span><br><span class="line"></span><br><span class="line"># 上传东西</span><br><span class="line">mc cp myobject.txt play&#x2F;mybucket</span><br></pre></td></tr></table></figure><h2><span id="9-minio-python-sdk">9. MinIO Python SDK</span></h2><blockquote><p><strong>Python 代码操作 MinIO 服务</strong></p></blockquote><ul><li><a href="https://docs.min.io/docs/python-client-quickstart-guide.html" target="_blank" rel="noopener">MinIO Python SDK for Amazon S3 Compatible Cloud Storage Slack</a></li><li><a href="https://docs.min.io/docs/python-client-api-reference" target="_blank" rel="noopener">Python Client API Reference</a></li><li><a href="https://github.com/minio/minio-py/tree/release/examples" target="_blank" rel="noopener">MinIO Python SDK Examples</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 安装pip包</span><br><span class="line">pip3 install minio</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># file_uploader.py</span><br><span class="line">from minio import Minio</span><br><span class="line">from minio.error import S3Error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # Create a client with the MinIO server playground, its access key</span><br><span class="line">    # and secret key.</span><br><span class="line">    client &#x3D; Minio(</span><br><span class="line">        &quot;play.min.io&quot;,</span><br><span class="line">        access_key&#x3D;&quot;Q3AM3UQ867SPQQA43P2F&quot;,</span><br><span class="line">        secret_key&#x3D;&quot;zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # Make &#39;asiatrip&#39; bucket if not exist.</span><br><span class="line">    found &#x3D; client.bucket_exists(&quot;asiatrip&quot;)</span><br><span class="line">    if not found:</span><br><span class="line">        client.make_bucket(&quot;asiatrip&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;Bucket &#39;asiatrip&#39; already exists&quot;)</span><br><span class="line">    </span><br><span class="line">    # Upload &#39;&#x2F;home&#x2F;user&#x2F;Photos&#x2F;asiaphotos.zip&#39; as object name</span><br><span class="line">    # &#39;asiaphotos-2015.zip&#39; to bucket &#39;asiatrip&#39;.</span><br><span class="line">    client.fput_object(</span><br><span class="line">        &quot;asiatrip&quot;, &quot;asiaphotos-2015.zip&quot;, &quot;&#x2F;home&#x2F;user&#x2F;Photos&#x2F;asiaphotos.zip&quot;,</span><br><span class="line">    )</span><br><span class="line">    print(</span><br><span class="line">        &quot;&#39;&#x2F;home&#x2F;user&#x2F;Photos&#x2F;asiaphotos.zip&#39; is successfully uploaded as &quot;</span><br><span class="line">        &quot;object &#39;asiaphotos-2015.zip&#39; to bucket &#39;asiatrip&#39;.&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    try:</span><br><span class="line">        main()</span><br><span class="line">    except S3Error as exc:</span><br><span class="line">        print(&quot;error occurred.&quot;, exc)</span><br></pre></td></tr></table></figure><blockquote><p>本文转载自：「 Escape 」，原文：<a href="https://tinyurl.com/yc3edfec" target="_blank" rel="noopener">https://tinyurl.com/yc3edfec</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;MinIO - 构建高性能的云原生数据的多云对象存储&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;MinIO&lt;/code&gt; 提供开源、高性能、兼容 &lt;code&gt;s3&lt;/code&gt; 的对象存储，为每个公共云、每个 &lt;code&gt;Kubernetes&lt;/code&gt; 发行版、私有云和边缘云中无缝运行，使其成为混合云和多云对象存储的领导者。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://min.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MinIO 英文官网地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.minio.org.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MinIO 中文官网地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1-MinIO-的应用场景&quot;&gt;1. MinIO 的应用场景&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;MinIO 是一个非常轻量的服务，可以很简单的和其他应用的结合。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;MinIO&lt;/code&gt; 是一个基于 &lt;code&gt;Apache License v2.0&lt;/code&gt; 开源协议的对象存储服务。它兼容亚马逊 &lt;code&gt;S3&lt;/code&gt; 云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从 &lt;code&gt;KB&lt;/code&gt; 到最大 &lt;code&gt;TB&lt;/code&gt; 不等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网盘 : 海量文件&lt;/li&gt;
&lt;li&gt;社交网站：海量图片&lt;/li&gt;
&lt;li&gt;电商网站：海量商品图片&lt;/li&gt;
&lt;li&gt;视频网站：海量视频文件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于中小型企业，如果不选择存储上云，那么 &lt;code&gt;MinIO&lt;/code&gt; 是个不错的选择，麻雀虽小，五脏俱全。当然 &lt;code&gt;MinIO&lt;/code&gt; 除了直接作为对象存储使用，还可以作为云上对象存储服务的网关层，无缝对接到 &lt;code&gt;Amazon S3&lt;/code&gt; 等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="教程" scheme="https://www.hi-linux.com/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="MinIO" scheme="https://www.hi-linux.com/tags/MinIO/"/>
    
  </entry>
  
  <entry>
    <title>关于 Kubernetes 的 Secret 并不安全这件事</title>
    <link href="https://www.hi-linux.com/posts/45918.html"/>
    <id>https://www.hi-linux.com/posts/45918.html</id>
    <published>2021-11-25T01:00:00.000Z</published>
    <updated>2021-12-18T08:41:42.651Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>K8s 提供了 Secret 资源供我们来保存、设置一些敏感信息，比如 API endpoint 地址，各种用户密码或 token 之类的信息。在没有使用 K8s 的时候，这些信息可能是通过配置文件或者环境变量在部署的时候设置的。</p><p>不过，Secret 其实并不安全，稍微用 kubectl 查看过 Secret 的人都知道，我们可以非常方便的看到 Secret 的原文，只要有相关的权限即可，尽管它的内容是 base64 编码的，这基本上等同于明文。</p><p>所以说，K8s 原生的 Secret 是非常简单的，不是特别适合在大型公司里直接使用，对 RBAC 的挑战也比较大，很多不该看到明文信息的人可能都能看到。</p><p>尤其是现在很多公司采用了所谓的 GitOps 理念，很多东西都需要放到 VCS，比如 git 中，这一问题就更日益突出，因为 VCS 也得需要设置必要的权限。</p><a id="more"></a><h2><span id="问题">问题</span></h2><p>简单来说，大概有几个地方都可以让不应该看到 Secret 内容的人获得 Secret 内容：</p><ul><li>etcd 存储</li><li>通过 API server</li><li>在 node 上直接查看文件</li></ul><p>这里我们以这个例子来看一下 Secret 在 K8s 中的使用情况。</p><p>Secret 定义， 用户名和密码分别为 <code>admin</code> 和 <code>hello-secret</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: mysecret</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  username: YWRtaW4&#x3D;</span><br><span class="line">  password: aGVsbG8tc2VjcmV0Cg&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>Pod 定义，这里我们将 Secret 作为 volume mount 到容器中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: mypod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: mypod</span><br><span class="line">    image: docker.io&#x2F;containerstack&#x2F;alpine-stress</span><br><span class="line">    command:</span><br><span class="line">      - top</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: foo</span><br><span class="line">      mountPath: &quot;&#x2F;etc&#x2F;foo&quot;</span><br><span class="line">      readOnly: true</span><br><span class="line">  volumes:</span><br><span class="line">  - name: foo</span><br><span class="line">    secret:</span><br><span class="line">      secretName: mysecret</span><br></pre></td></tr></table></figure><p>Pod 启动后，我们可以到容器中来查看 Secret 作为 volume mount 到容器后的文件内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -it mypod sh</span><br><span class="line">&#x2F; # cd &#x2F;etc&#x2F;foo&#x2F;</span><br><span class="line">&#x2F;etc&#x2F;foo # ls -tal</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x    1 root     root          4096 Apr 14 08:55 ..</span><br><span class="line">drwxrwxrwt    3 root     root           120 Apr 14 08:55 .</span><br><span class="line">drwxr-xr-x    2 root     root            80 Apr 14 08:55 ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx    1 root     root            31 Apr 14 08:55 ..data -&gt; ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx    1 root     root            15 Apr 14 08:55 password -&gt; ..data&#x2F;password</span><br><span class="line">lrwxrwxrwx    1 root     root            15 Apr 14 08:55 username -&gt; ..data&#x2F;username</span><br><span class="line">&#x2F;etc&#x2F;foo # ls -tal ..2021_04_14_08_55_54.401661151</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x    2 root     root            80 Apr 14 08:55 .</span><br><span class="line">drwxrwxrwt    3 root     root           120 Apr 14 08:55 ..</span><br><span class="line">-rw-r--r--    1 root     root            13 Apr 14 08:55 password</span><br><span class="line">-rw-r--r--    1 root     root             5 Apr 14 08:55 username</span><br><span class="line">&#x2F;etc&#x2F;foo # cat password</span><br><span class="line">hello-secret</span><br><span class="line">&#x2F;etc&#x2F;foo #</span><br></pre></td></tr></table></figure><h3><span id="etcd-存储">etcd 存储</span></h3><p>API server 中的资源都保存在 etcd 中，我们可以直接从文件看到相关内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># hexdump -C &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;member&#x2F;snap&#x2F;db | grep -A 5 -B 5 hello</span><br><span class="line">00043640  12 00 1a 07 64 65 66 61  75 6c 74 22 00 2a 24 32  |....default&quot;.*$2|</span><br><span class="line">00043650  35 66 37 35 38 30 38 2d  37 33 31 33 2d 34 38 64  |5f75808-7313-48d|</span><br><span class="line">00043660  39 2d 39 61 38 65 2d 38  61 35 66 66 32 32 63 64  |9-9a8e-8a5ff22cd|</span><br><span class="line">00043670  64 35 39 32 00 38 00 42  08 08 98 dc da 83 06 10  |d592.8.B........|</span><br><span class="line">00043680  00 7a 00 12 19 0a 08 70  61 73 73 77 6f 72 64 12  |.z.....password.|</span><br><span class="line">00043690  0d 68 65 6c 6c 6f 2d 73  65 63 72 65 74 0a 12 11  |.hello-secret...|</span><br><span class="line">000436a0  0a 08 75 73 65 72 6e 61  6d 65 12 05 61 64 6d 69  |..username..admi|</span><br><span class="line">000436b0  6e 1a 06 4f 70 61 71 75  65 1a 00 22 00 00 00 00  |n..Opaque..&quot;....|</span><br><span class="line">000436c0  00 00 00 08 95 5f 00 00  00 00 00 00 00 00 0a 37  |....._.........7|</span><br><span class="line">000436d0  2f 72 65 67 69 73 74 72  79 2f 73 65 72 76 69 63  |&#x2F;registry&#x2F;servic|</span><br><span class="line">000436e0  65 73 2f 65 6e 64 70 6f  69 6e 74 73 2f 6b 75 62  |es&#x2F;endpoints&#x2F;kub|</span><br></pre></td></tr></table></figure><p>可以看到，基本 yaml 中的内容都是明文存放的，而且是进行 base64 解码之后的内容。</p><p>使用下面的命令也可以获得类似的结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ETCDCTL_API&#x3D;3 etcdctl get --prefix &#x2F;registry&#x2F;secrets&#x2F;default&#x2F;mysecret | hexdump -C</span><br></pre></td></tr></table></figure><p>etcd 本来存储的是明文数据，这个好像已经从 1.7 开始支持 <a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/" target="_blank" rel="noopener">加密存储</a> 了，而且直接访问 etcd 从物理上来说也不是那么容易。</p><h3><span id="api-server">API server</span></h3><p>通过 API server 则简单的多，只要有权限就可以从任何节点上通过访问 API server 来得到 secret 的明文内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get secret mysecret -o yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  password: aGVsbG8tc2VjcmV0Cg&#x3D;&#x3D;</span><br><span class="line">  username: YWRtaW4&#x3D;</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: &quot;2021-04-14T08:55:52Z&quot;</span><br><span class="line">  name: mysecret</span><br><span class="line">  namespace: default</span><br><span class="line">  resourceVersion: &quot;2196&quot;</span><br><span class="line">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;secrets&#x2F;mysecret</span><br><span class="line">  uid: 25f75808-7313-48d9-9a8e-8a5ff22cdd59</span><br><span class="line">type: Opaque</span><br></pre></td></tr></table></figure><h3><span id="节点上">节点上</span></h3><p>在节点上也可以看到 Secret 文件的内容。</p><p>查找 foo volume 的挂载点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># mount | grep foo </span><br><span class="line">tmpfs on &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;280451e8-512b-489c-b5dd-df2b1a3c9b29&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;foo type tmpfs (rw,relatime)</span><br></pre></td></tr></table></figure><p>查看这个 volume 下面的文件内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># ls -tal &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;280451e8-512b-489c-b5dd-df2b1a3c9b29&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;foo</span><br><span class="line">total 4</span><br><span class="line">drwxrwxrwt 3 root root  120 4月  14 16:55 .</span><br><span class="line">drwxr-xr-x 2 root root   80 4月  14 16:55 ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx 1 root root   31 4月  14 16:55 ..data -&gt; ..2021_04_14_08_55_54.401661151</span><br><span class="line">lrwxrwxrwx 1 root root   15 4月  14 16:55 password -&gt; ..data&#x2F;password</span><br><span class="line">lrwxrwxrwx 1 root root   15 4月  14 16:55 username -&gt; ..data&#x2F;username</span><br><span class="line">drwxr-xr-x 4 root root 4096 4月  14 16:55 ..</span><br><span class="line"></span><br><span class="line"># cat &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;280451e8-512b-489c-b5dd-df2b1a3c9b29&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;foo&#x2F;password</span><br><span class="line">hello-secret</span><br></pre></td></tr></table></figure><h2><span id="第三方方案">第三方方案</span></h2><p>针对上面提到的可能泄露 Secret 的几点，大概解决方案不难想到如下几种：</p><ul><li>etcd 加密</li><li>API server 严格进行权限设计</li><li>强化 node 节点用户权限管理和系统安全</li></ul><p>不过，要相关确保 Secret 的绝对安全，上面这几种方案都是必须，缺一不可，缺少了那一个都相当于在墙上留了一个洞。</p><p>社区和公有云提供商都有一些产品和方案，我们可以参考一下。</p><ul><li><a href="https://github.com/shyiko/kubesec" target="_blank" rel="noopener">shyiko/kubesec</a>: Secure Secret management for Kubernetes (with gpg, Google Cloud KMS and AWS KMS backends)</li><li><a href="https://github.com/bitnami-labs/sealed-secrets" target="_blank" rel="noopener">bitnami-labs/sealed-secrets</a>: A Kubernetes controller and tool for one-way encrypted Secrets</li><li><a href="https://www.vaultproject.io/docs/platform/k8s" target="_blank" rel="noopener">Vault by HashiCorp</a></li><li><a href="https://github.com/mozilla/sops" target="_blank" rel="noopener">mozilla/sops</a></li><li><a href="https://github.com/external-secrets/kubernetes-external-secrets" target="_blank" rel="noopener">Kubernetes External Secrets</a></li><li><a href="https://github.com/Soluto/kamus" target="_blank" rel="noopener">Kamus</a></li></ul><h3><span id="shyikokubesec">shyiko/kubesec</span></h3><p>kubesec 只对 Secret 中数据进行加密/解密，支持如下 key 管理服务或软件：</p><ul><li>AWS Key Management Service</li><li>Google Cloud KMS</li><li>GnuPG</li></ul><h3><span id="bitnami-labssealed-secrets">bitnami-labs/sealed-secrets</span></h3><p>Bitnami 在 K8s 领域也是一家人人知晓的公司，输出了很多技术和最佳实践。</p><p><img src="https://img.hi-linux.com/staticfile/sealed-secrets-20210520174450379-2021-05-20-foc4mT.png" alt></p><p><em>本图来自 <a href="https://engineering.bitnami.com/articles/sealed-secrets.html" target="_blank" rel="noopener">Sealed Secrets: Protecting your passwords before they reach Kubernetes</a></em></p><p>SealeSecret 将 secret 资源整个加密保存为 <code>SealedSecret</code> 资源，而解密只能由该集群中的 controller 进行。</p><p>SealeSecret 提供了一个 kubeseal 工具来对 secret 资源进行加密，这个过程需要一个公开 key（公钥），这个公开 key 就是从 SealeSecret controller 拿到的。</p><p>不过，只从从说明文档来看， SealeSecret controller 加密解密所依赖的 key，也是通过普通的 Secret 来保存的，这难道不是一个问题？同时也增加了 SealeSecret controller 的运维成本。</p><h3><span id="mozillasops">mozilla/sops</span></h3><p>严格来说， sops 跟 K8s 并没有什么必然关系，它只是一个支持 YAML/JSON/ENV/INI 等文件格式的加密文件编辑器，它支持 AWS KMS, GCP KMS, Azure Key Vault, age, 和 PGP 等服务与应用。</p><p>如果有有兴趣可以看它的<a href="https://github.com/mozilla/sops" target="_blank" rel="noopener">主页</a>。</p><h3><span id="kubernetes-external-secrets">Kubernetes External Secrets</span></h3><p>Kubernetes External Secrets 是知名域名服务提供商 godaddy 开发的开源软件，它可以直接将保存在外部 KMS 中的机密信息传给 K8s 。目前支持的 KSM 包括：</p><ul><li>AWS Secrets Manager</li><li>AWS System Manager</li><li>Hashicorp Vault</li><li>Azure Key Vault</li><li>GCP Secret Manager</li><li>Alibaba Cloud KMS Secret Manager</li></ul><p>它通过自定义 controller 和 CRD 来实现，具体架构图如下：</p><p><img src="https://img.hi-linux.com/staticfile/kubernetes-external-secrets-architecture-2021-05-20-iCQv1L.png" alt="img"></p><p>具体来说用户需要创建一个 ExternalSecret 类型的资源，来将外部 KMS 的数据映射到 K8s 的 Secret 上。</p><p>不过，这种方式大概只有两点好处：</p><ul><li>统一 key 的管理，或者沿用既有 key 资产</li><li>key 信息不想放到 VCS 等</li></ul><p>对于防止 Sercet 信息泄露，作用不大，因为其明文资源还是可以在 API server/etcd 上看到。</p><p>或者说，External Secrets 真正做的事情，也就是从外部 KMS 中的 key ，映射成 K8s 中的 Secret 资源而已，对保证在 K8s 集群中数据的安全性用处不大。</p><h3><span id="kamus">Kamus</span></h3><p>Kamus 同样提供了加密 key 的方法（一个命令行工具），同时只有通过 K8s 中的 controller 才能对这个 key 进行解密。不过它 保存在 K8s 中的 Secret 是加密的状态，用户不能像 External Secrets 那样直接获得 Secret 的明文内容。</p><p>Kamus 由 3 个组件组成，分别是：</p><ul><li>Encrypt API</li><li>Decrypt API</li><li>Key Management System (KMS)</li></ul><p>KMS 是一个外部加密服务的封装，目前支持如下服务： - AES - AWS KMS - Azure KeyVault - Google Cloud KMS</p><p>Kamus 以 service account 为单位对 secret 进行加密，之后 Pod 会通过 service account 来请求 Kamus 的解密服务来对该 secret 进行解密。</p><p>对 K8s 来说，解密 secret 可以通过 init container 来实现：定义一个 基于内存的 emptyDir ，业务容器和 init 容器使用同一个 volume， init 容器解密后，将数据存放到该 volume 下，之后业务容器就可以使用解密后的 secret 数据了。</p><p><img src="https://img.hi-linux.com/staticfile/kamus-pod-2021-05-20-5Z6xjw.png" alt="img"></p><h3><span id="vault-by-hashicorp">Vault by HashiCorp</span></h3><p>HashiCorp 公司就不多说，在云计算/DevOps领域也算是数一数二的公司了。</p><p>Vault 本身就是一个 KMS 类似的服务，用于管理机密数据。对于 K8s 的原生 secret ，大概提供了如下两种方式的支持：</p><ul><li><a href="https://www.vaultproject.io/docs/platform/k8s/injector" target="_blank" rel="noopener">Agent Sidecar Injector/vault-k8s</a></li><li><a href="https://www.vaultproject.io/docs/platform/k8s/csi" target="_blank" rel="noopener">Vault CSI Provider</a></li></ul><h4><span id="agent-sidecar-injector">Agent Sidecar Injector</span></h4><p>这种方式和上面的 Kamus 类似，也是需要两个组件：</p><ul><li>Mutation webhook：负责修改 pod 定义，注入init/sidecar</li><li>agent-sidecar：负责获取和解密数据，将数据保存到指定的 volume/路径下</li></ul><p>Vault agent sidecar injector 不仅提供了 init container 来初始化 secret ，还通过 sidecar 来定期更新 secret ，这样就非常接近原生 secret 的实现了。</p><p>应用程序则只需要在文件系统上读取指定的文件就可以了，而不必关系如何从外部获取加密信息。</p><p>这是官方 blog 中的一个示例：</p><p>Pod 信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        vault.hashicorp.com&#x2F;agent-inject: &quot;true&quot;</span><br><span class="line">        vault.hashicorp.com&#x2F;agent-inject-secret-helloworld: &quot;secrets&#x2F;helloworld&quot;</span><br><span class="line">        vault.hashicorp.com&#x2F;role: &quot;myapp&quot;</span><br></pre></td></tr></table></figure><p>这个定义中，<code>vault-k8s</code> 会对该 pod 注入 <code>vault agent</code>，并使用 <code>secrets/helloworld</code> 来初始化。Pod 运行后，可以在 <code>/vault/secrets</code> 下找到一个名为 <code>helloworld</code> 的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -ti app-XXXXXXXXX -c app -- cat &#x2F;vault&#x2F;secrets&#x2F;helloworld</span><br><span class="line">data: map[password:foobarbazpass username:foobaruser]</span><br><span class="line">metadata: map[created_time:2019-12-16T01:01:58.869828167Z deletion_time: destroyed:false version:1]</span><br></pre></td></tr></table></figure><p>当然这个数据是raw data，没有经过格式化。如果想指定输出到文件中的格式，可以使用 vault 的模板功能。</p><h4><span id="vault-csi-provider">Vault CSI Provider</span></h4><p>这部分可以参考下面的社区方案部分。</p><h2><span id="社区方案">社区方案</span></h2><p>当然，社区没有理由意识不到原生 secret 的问题，因此社区也有 <a href="https://github.com/kubernetes-sigs/secrets-store-csi-driver" target="_blank" rel="noopener">Kubernetes Secrets Store CSI Driver</a> ，一种通过 CSI 接口将 Secret 集成到 K8s 的方案。</p><p>Secrets Store CSI driver（<code>secrets-store.csi.k8s.io</code>）可以让 K8s mount 多个 secret 以 volume 的形式，从外部 KMS mount 到 Pod 里。</p><p>要想使用 Secrets Store CSI Driver ，大致过程如下:</p><ul><li>定义 SecretProviderClass</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: secrets-store.csi.x-k8s.io&#x2F;v1alpha1</span><br><span class="line">kind: SecretProviderClass</span><br><span class="line">metadata:</span><br><span class="line">  name: my-provider</span><br><span class="line">spec:</span><br><span class="line">  provider: vault   # accepted provider options: azure or vault or gcp</span><br><span class="line">  parameters:       # provider-specific parameters</span><br></pre></td></tr></table></figure><ul><li>为 Pod 配置 Volume</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: secrets-store-inline</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: k8s.gcr.io&#x2F;e2e-test-images&#x2F;busybox:1.29</span><br><span class="line">    name: busybox</span><br><span class="line">    command:</span><br><span class="line">    - &quot;&#x2F;bin&#x2F;sleep&quot;</span><br><span class="line">    - &quot;10000&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: secrets-store-inline</span><br><span class="line">      mountPath: &quot;&#x2F;mnt&#x2F;secrets-store&quot;</span><br><span class="line">      readOnly: true</span><br><span class="line">  volumes:</span><br><span class="line">    - name: secrets-store-inline</span><br><span class="line">      csi:</span><br><span class="line">        driver: secrets-store.csi.k8s.io</span><br><span class="line">        readOnly: true</span><br><span class="line">        volumeAttributes:</span><br><span class="line">          secretProviderClass: &quot;my-provider&quot;</span><br></pre></td></tr></table></figure><p>Pod 启动之后，就可以确认解密后的数据了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec secrets-store-inline -- ls &#x2F;mnt&#x2F;secrets-store&#x2F;</span><br><span class="line">foo</span><br></pre></td></tr></table></figure><h2><span id="总结">总结</span></h2><p>上面的总结都是基于互联网公开的资料而来，并没有经过亲身体验，因此有些地方可能理解有误，要想深入了解还需要自己亲手确认最好。</p><p>不过总体来说，社区这种方案可能最简单，部署也不是很麻烦，只是这就和原生的 secret 基本没什么关系了。。。</p><p>Vault 方案也很成熟，值得关注。</p><blockquote><p>本文转载自：「 人间指南 」，原文：<a href="https://tinyurl.com/y9warvpa" target="_blank" rel="noopener">https://tinyurl.com/y9warvpa</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;K8s 提供了 Secret 资源供我们来保存、设置一些敏感信息，比如 API endpoint 地址，各种用户密码或 token 之类的信息。在没有使用 K8s 的时候，这些信息可能是通过配置文件或者环境变量在部署的时候设置的。&lt;/p&gt;
&lt;p&gt;不过，Secret 其实并不安全，稍微用 kubectl 查看过 Secret 的人都知道，我们可以非常方便的看到 Secret 的原文，只要有相关的权限即可，尽管它的内容是 base64 编码的，这基本上等同于明文。&lt;/p&gt;
&lt;p&gt;所以说，K8s 原生的 Secret 是非常简单的，不是特别适合在大型公司里直接使用，对 RBAC 的挑战也比较大，很多不该看到明文信息的人可能都能看到。&lt;/p&gt;
&lt;p&gt;尤其是现在很多公司采用了所谓的 GitOps 理念，很多东西都需要放到 VCS，比如 git 中，这一问题就更日益突出，因为 VCS 也得需要设置必要的权限。&lt;/p&gt;
    
    </summary>
    
    
      <category term="微服务" scheme="https://www.hi-linux.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="微服务" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Linux 运维工程师必须知道的 6 类好习惯和 23 个教训</title>
    <link href="https://www.hi-linux.com/posts/17487.html"/>
    <id>https://www.hi-linux.com/posts/17487.html</id>
    <published>2021-11-19T01:00:00.000Z</published>
    <updated>2021-12-18T08:41:42.656Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>从事运维三年半，遇到过各式各样的问题，数据丢失，网站挂马，误删数据库文件，黑客攻击等各类问题。</p><p>今天简单整理一下，分享给各位小伙伴。</p><h2><span id="线上操作规范">线上操作规范</span></h2><p><strong>1、测试使用</strong></p><p>当初学习 Linux 的使用，从基础到服务到集群，都是在虚拟机做的，虽然老师告诉我们跟真机没有什么差别，可是对真实环境的渴望日渐上升，不过虚拟机的各种快照却让我们养成了各种手贱的习惯，以致于拿到服务器操作权限时候，就迫不及待的想去试试，记得上班第一天，老大把 root 密码交给我，由于只能使用 putty，我就想使用 xshell，于是悄悄登录服务器尝试改为 Xshell+密钥登录，因为没有测试，也没有留一个 SSH 连接，所有重启 SSHD 服务器之后，自己就被挡在服务器之外了，幸好当时我备份了 sshd_config 文件，后来让机房人员 cp 过去就可以了，幸亏这是一家小公司，不然直接就被干了……庆幸当年运气比较好。</p><p>第二个例子是关于文件同步的，大家都知道 sync 同步很快，可是他删除文件的速度大大超过了 rm -rf，在 rsync 中有一个命令是，以某目录为准同步某文件（如果第一个目录是空的，那么结果可想而知），源目录（有数据的）就会被删除，当初我就是因为误操作，以及缺乏测试，就目录写反了，关键是没有备份……生产环境数据被删了。</p><p>没备份，大家自己想后果吧，其重要性不言而喻。</p><a id="more"></a><p><strong>2、Enter 前再三确认</strong></p><p>关于 <code>rm -rf / var</code> 这种错误，我相信手快的人，或者网速比较慢的时候，出现的几率相当大，当你发现执行完之后，你的心至少是凉了半截。</p><p>大家可能会说，我按了这么多次都没出过错，不用怕，我只想说当出现一次你就明白了，不要以为那些运维事故都是在别人身上，如果你不注意，下一个就是你。</p><p><strong>3、切忌多人操作</strong></p><p>我在的上一家公司，运维管理相当混乱，举一个最典型的例子吧，离职好几任的运维都有服务器 root 密码。</p><p>通常我们运维接到任务，都会进行简单查看如果无法解决，就请求他人帮忙，可是当问题焦头烂额的时候，客服主管（懂点 Linux），网管，你上司一起调试一个服务器，当你各种百度,各种对照，完了发现，你的服务器配置文件，跟上次你修改不一样了，然后再改回来，然后再谷歌，兴冲冲发现问题，解决了，别人却告诉你，他也解决了，修改的是不同的参数……这个，我就真不知道哪个是问题真正的原因了，当然这还是好的，问题解决了，皆大欢喜，可是你遇到过你刚修改的文件，测试无效，再去修改发现文件又被修改的时候呢？真的很恼火，切忌多人操作。</p><p><strong>4、先备份后操作</strong></p><p>养成一个习惯，要修改数据时，先备份，比如 <code>.conf</code> 的配置文件。另外，修改配置文件时，建议注释原选项，然后再复制，修改。</p><p>再者说，如果第一个例子中，有数据库备份，那 rsync 的误操作不久没事了吧。所以说丢数据库非一朝一夕，随便备份一个就不用那么惨。</p><h2><span id="涉及数据">涉及数据</span></h2><p><strong>5、慎用rm -rf</strong></p><p>网上的例子很多，各种 <code>rm -rf /</code>，各种删除主数据库，各种运维事故……</p><p>一点小失误就会造成很大的损失。如果真需要删除，一定要谨慎。</p><p><strong>6、备份大于一切</strong></p><p>本来上面都有各种关于备份，但是我想把它划分在数据类再次强调，备份非常之重要哇。</p><p>我记得我的老师说过一句话，涉及到数据何种的谨慎都不为过。我就职的公司有做第三方支付网站和网贷平台的，第三方支付是每两个小时完全备份一次，网贷平台是每 20 分钟备份一次。</p><p>我不多说了，大家自己斟酌吧。</p><p><strong>7、稳定大于一切</strong></p><p>其实不止是数据，在整个服务器环境，都是稳定大于一切，不求最快，但求最稳定，求可用性，所以未经测试，不要在服务器使用新的软件，比如 Nginx+PHP-FPM，生产环境中 PHP 各种挂啊。</p><p>重启下就好了，或者换 apache 就好了。</p><p><strong>8、保密大于一切</strong></p><p>现在各种艳照门漫天飞，各种路由器后门，所以说，涉及到数据，不保密是不行的。</p><h2><span id="涉及安全">涉及安全</span></h2><p><strong>9、SSH</strong></p><ul><li>更改默认端口（当然如果专业要黑你，扫描下就出来了）</li><li>禁止 root 登录</li><li>使用普通用户+key认证+sudo规则+IP地址+用户限制</li><li>使用 hostdeny 类似的防爆里破解软件（超过几次尝试直接拉黑）</li></ul><p>筛选 <code>/etc/passwd</code> 中 login 的用户。</p><p><strong>10、防火墙</strong></p><p>防火墙生产环境一定要开，并且要遵循最小原则，drop所有，然后放行需要的服务端口。</p><p><strong>11、精细权限和控制粒度</strong></p><p>能使用普通用户启动的服务坚决不使用root，把各种服务权限控制到最低，控制粒度要精细。</p><p><strong>12、入侵检测和日志监控</strong></p><p>使用第三方软件，时刻检测系统关键文件以及各种服务配置文件的改动，比如：<code>/etc/passwd</code>，<code>/etc/my.cnf</code>，<code>/etc/httpd/con/httpd.conf</code>等。</p><p>使用集中化的日志监控体系，监控 <code>/var/log/secure</code>，<code>/etc/log/message</code>，ftp 上传下载文件等报警错误日志。</p><p>另外针对端口扫描，也可以使用一些第三方软件，发现被扫描就直接拉入 host.deny。这些信息对于系统被入侵后排错很有帮助。</p><p>有人说过，一个公司在安全投入的成本跟他被安全攻击损失的成本成正比，安全是一个很大的话题，也是一个很基础的工作，把基础做好了，就能相当的提高系统安全性，其他的就是安全高手做的了。</p><h2><span id="日常监控">日常监控</span></h2><p><strong>13、系统运行监控</strong></p><p>好多人踏入运维都是从监控做起，大的公司一般都有专业 24 小时监控运维。系统运行监控一般包括硬件占用率，常见的有，内存，硬盘，CPU，网卡，OS包括登录监控，系统关键文件监控。</p><p>定期的监控可以预测出硬件损坏的概率，并且给调优带来很实用的功能。</p><p><strong>14、服务运行监控</strong></p><p>服务监控一般就是各种应用，Web，DB，LVS等，这一般都是监控一些指标。</p><p>在系统出现性能瓶颈的时候就能很快发现并解决。</p><p><strong>15、日志监控</strong></p><p>这里的日志监控跟安全的日志监控类似，但这里一般都是硬件，OS，应用程序的报错和警报信息。</p><p>监控在系统稳定运行的时候确实没啥用，但是一旦出现问题，你又没做监控，就会很被动了。</p><h2><span id="性能调优">性能调优</span></h2><p><strong>16、深入了解运行机制</strong></p><p>其实按一年多的运维经验来说，谈调优根本就是纸上谈兵，但是我只是想简单总结下，如果有更深入的了解，我会更新。在对软件进行优化之前，比如要深入了解一个软件的运行机制，比如 Nginx 和 Apache，大家都说 Nginx 快，那就必须知道 Nginx 为什么快，利用什么原理，处理请求比 Apache，并且要能跟别人用浅显易懂的话说出来，必要的时候还要能看懂源代码，否则一切以参数为调优对象的文档都是瞎谈。</p><p><strong>17、调优框架以及先后</strong></p><p>熟悉了底层运行机制，就要有调优的框架和先后顺序，比如数据库出现瓶颈，好多人直接就去更改数据库的配置文件，我的建议是，先根据瓶颈去分析，查看日志，写出来调优方向，然后再入手，并且数据库服务器调优应该是最后一步，最先的应该是硬件和操作系统，现在的数据库服务器都是在各种测试之后才会发布的</p><p>适用于所有操作系统，不应该先从他入手。</p><p><strong>18、每次只调一个参数</strong></p><p>每次只调一个参数，这个相比大家都了解，调的多了，你就自己就迷糊了。</p><p><strong>19、基准测试</strong></p><p>判断调优是否有用，和测试一个新版本软件的稳定性和性能等方面，就必须要基准测试了，测试要涉及很多因素。</p><p>测试是否接近业务真实需求这要看测试人的经验了，相关资料大家可以参考《高性能MySQL》第三版相当的好。</p><p>我的老师曾说过，没有放之四海皆准的参数，任何参数更改任何调优都必须符合业务场景，所以不要再谷歌什么什么调优了，对你的提升和业务环境的改善没有长久作用。</p><h2><span id="运维心态">运维心态</span></h2><p><strong>20、控制心态</strong></p><p>很多 <code>rm -rf /data</code> 都在下班的前几分钟，都在烦躁的高峰，那么你还不打算控制下你的心态么？</p><p>有人说了，烦躁也要上班，可是你可以在烦躁的时候尽量避免处理关键数据环境，越是有压力，越要冷静，不然会损失更多。</p><p>大多人都有 <code>rm -rf /data/mysql</code> 的经历，发现删除之后，那种心情你可以想象一下，可是如果没有备份，你急又有什么用，一般这种情况下，你就要冷静想下最坏打算了，对于 MySQL 来说，删除了物理文件，一部分表还会存在内存中，所以断开业务，但是不要关闭MySQL数据库，这对恢复很有帮助，并使用dd复制硬盘，然后你再进行恢复。</p><p>当然了大多时候你就只能找数据恢复公司了。</p><p>试想一下，数据被删了，你各种操作，关闭数据库，然后修复，不但有可能覆盖文件，还找不到内存中的表了。</p><p><strong>21、对数据负责</strong></p><p>生产环境不是儿戏，数据库也不是儿戏，一定要对数据负责。不备份的后果是非常严重的。</p><p><strong>22、追根究底</strong></p><p>很多运维人员比较忙，遇到问题解决就不会再管了，记得去年一个客户的网站老是打不开，经过 PHP 代码报错，发现是 session 和 whos_online 损坏，前任运维是通过 repair 修复的，我就也这样修复了，但是过了几个小时，又出现了。反复三四次之后，我就去谷歌数据库表莫名损坏原因：一是 myisam 的 bug，二是 mysqlbug，三是 MySQL 在写入过程中被 kill，最后发现是内存不够用，导致 OOM kill 了 mysqld 进程，并且没有 swap 分区，后台监控内存是够用的，最后升级物理内存解决。</p><p><strong>23、测试和生产环境</strong></p><p>在重要操作之前一定要看自己所在的机器，尽量避免多开窗口。</p><blockquote><p>本文转载自：「 博客园 」，原文：<a href="https://tinyurl.com/jrh7nr2x" target="_blank" rel="noopener">https://tinyurl.com/jrh7nr2x</a> ，版权归原作者所有。欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a>。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从事运维三年半，遇到过各式各样的问题，数据丢失，网站挂马，误删数据库文件，黑客攻击等各类问题。&lt;/p&gt;
&lt;p&gt;今天简单整理一下，分享给各位小伙伴。&lt;/p&gt;
&lt;h2 id=&quot;线上操作规范&quot;&gt;线上操作规范&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1、测试使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当初学习 Linux 的使用，从基础到服务到集群，都是在虚拟机做的，虽然老师告诉我们跟真机没有什么差别，可是对真实环境的渴望日渐上升，不过虚拟机的各种快照却让我们养成了各种手贱的习惯，以致于拿到服务器操作权限时候，就迫不及待的想去试试，记得上班第一天，老大把 root 密码交给我，由于只能使用 putty，我就想使用 xshell，于是悄悄登录服务器尝试改为 Xshell+密钥登录，因为没有测试，也没有留一个 SSH 连接，所有重启 SSHD 服务器之后，自己就被挡在服务器之外了，幸好当时我备份了 sshd_config 文件，后来让机房人员 cp 过去就可以了，幸亏这是一家小公司，不然直接就被干了……庆幸当年运气比较好。&lt;/p&gt;
&lt;p&gt;第二个例子是关于文件同步的，大家都知道 sync 同步很快，可是他删除文件的速度大大超过了 rm -rf，在 rsync 中有一个命令是，以某目录为准同步某文件（如果第一个目录是空的，那么结果可想而知），源目录（有数据的）就会被删除，当初我就是因为误操作，以及缺乏测试，就目录写反了，关键是没有备份……生产环境数据被删了。&lt;/p&gt;
&lt;p&gt;没备份，大家自己想后果吧，其重要性不言而喻。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>阿里云发布全新开源操作系统『龙蜥』，支持 X86 64 和 ARM 64 架构及飞腾、海光、兆芯、鲲鹏等芯片</title>
    <link href="https://www.hi-linux.com/posts/20754.html"/>
    <id>https://www.hi-linux.com/posts/20754.html</id>
    <published>2021-10-19T01:00:00.000Z</published>
    <updated>2021-12-18T08:41:42.654Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>近日，2021 云栖大会上，阿里云发布了全新操作系统 <strong>“龙蜥”(Anolis OS)</strong>，并宣布开源。</p><p>据了解，龙蜥操作系统 <strong>定位于服务器市场</strong>，支持 x86、ARM 等多种硬件架构和计算场景。</p><p><strong>它特别针对云原生应用开发做了多重优化，云上典型场景的综合性能可提升 40％，同时故障率可降低 50％，还兼容 CentOS 生态，支持一键迁移，并提供全栈国密能力。</strong></p><p>龙蜥操作系统 <strong>完全开源</strong>，通过开源社区和操作系统厂商等形式提供服务，<strong>技术支持至少 10 年。</strong></p><a id="more"></a><p>未来，<strong>阿里云计划为龙蜥系统投入 20 亿元的专项资金</strong>，并联合 100 家生态合作伙伴推动生态建设。</p><p>事实上，龙蜥操作系统并非新鲜事物，只是首次对外公布而已，<strong>它已经在阿里巴巴内部打磨了 10 年之久，特别是有效支撑了历年来的天猫双 11 活动</strong>，性能和稳定性都经受住了严苛的考验。</p><p>另外，<strong>阿里达摩院操作系统实验室</strong> 同步宣告成立，未来将专注于操作系统的研发、推广。</p><blockquote><p>龙蜥操作系统(Anolis OS) 8.4 版本依然秉承与国际主流 Linux 厂商发行版 100% 兼容的原则，且提供配套的迁移工具，助力用户完美平滑地迁移至龙蜥操作系统(Anolis OS)，满足 CentOS 停服后的各领域、各行业用户的使用习惯和需求。在硬件生态方面通过和 Intel 及国内芯片厂商的合作，支持 Intel、海光、兆芯、飞腾、鲲鹏等一系列芯片平台，进行软、硬一体的优化，充分发挥硬件平台的性能。</p></blockquote><p>在基本库、应用生态上融入了适合云场景新组件，各组件经过云计算场景超大规模部署的打磨和完善，可满足各个行业领域对于不同生产环境下不同方案的实际需求。</p><h2><span id="亮点">亮点</span></h2><ul><li>100% 兼容<strong>国际主流 Linux</strong> 厂商发行版；</li><li>支持 x86_64 和 aarch64 架构及飞腾、海光、兆芯、鲲鹏等芯片，适配 x86 及 arm64 <strong>主流服务器</strong>硬件；</li><li>支持 Linux Kernel <strong>4.19 LTS</strong> 版本并同步上游社区<strong>最新成果</strong>，帮助用户及时获得开源社区创新红利；</li><li>支持开源分布式关系数据库<strong>OceanBase</strong>；</li><li>支持安全容器<strong>Kata Containers</strong>；</li><li>支持开源云原生关系型数据库<strong>PolarDB for PostgreSQL</strong>；</li><li><strong>基础应用组件</strong>升级；<br>Python 3.9/SWIG 4.0/Subversion 1.14/Redis 6/PostgreSQL 13/MariaDB 10.5；</li><li><strong>工具链</strong>升级；<br>GCC Toolset 10/LLVM Toolset 11.0.0/Rust Toolset 1.49.0/Go Toolset 1.15.7；</li><li>提供 CentOS 系统到 Anolis OS 迁移工具，帮助系统及应用的<strong>顺滑迁移</strong>；</li></ul><h2><span id="硬件支撑">硬件支撑</span></h2><h3><span id="支持架构">支持架构</span></h3><p>x86_64 和 aarch64</p><h3><span id="cloud-kernel-平台兼容性">Cloud Kernel 平台兼容性</span></h3><p>Cloud Kernel 内核 <strong>已验证支持的服务器</strong> 如下，后续将逐步增加对其他服务器的支持，也欢迎广大合作伙伴/开发者参与贡献和验证。</p><table><thead><tr><th>名称</th><th>架构</th><th>CPU</th></tr></thead><tbody><tr><td>飞腾</td><td>aarch64</td><td>Phytium FT-2000+/64,Phytium S2500/64</td></tr><tr><td>海光</td><td>x86_64</td><td>Hygon C86 7185 32-core Process</td></tr><tr><td>兆芯</td><td>x86_64</td><td>Zhaoxin KH-37800D</td></tr><tr><td>鲲鹏</td><td>aarch64</td><td>Kunpeng-920</td></tr></tbody></table><h2><span id="发布内容">发布内容</span></h2><p>目前龙蜥最新的稳定版是 7 月份发布的 Anolis OS 8.4，发布内容包括 <strong>ISO、虚拟机镜像和 REPO 源</strong>。</p><h3><span id="iso-列表">ISO 列表</span></h3><table><thead><tr><th><strong>名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>AnolisOS-8.4-x86_64-dvd.iso</td><td>x86_64架构的安装 ISO</td></tr><tr><td>AnolisOS-8.4-aarch64-dvd.iso</td><td>aarch64架构的安装 ISO</td></tr><tr><td>AnolisOS-8.4-src-dvd.iso</td><td>source 包ISO</td></tr></tbody></table><h3><span id="虚拟机镜像列表">虚拟机镜像列表</span></h3><table><thead><tr><th><strong>名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>AnolisOS-8.4-GA-x86_64-ANCK.qcow2</td><td>x86_64架构虚拟机镜像搭配ANCK内核</td></tr><tr><td>AnolisOS-8.4-GA-x86_64-RHCK.qcow2</td><td>x86_64架构虚拟机镜像搭配RHCK内核[注1]</td></tr><tr><td>AnolisOS-8.4-GA-aarch64-ANCK.qcow2</td><td>aarch64架构虚拟机镜像搭配ANCK内核</td></tr><tr><td>AnolisOS-8.4-GA-aarch64-RHCK.qcow2</td><td>aarch64架构虚拟机镜像搭配RHCK内核</td></tr></tbody></table><blockquote><p>注1：RHCK 内核兼容 CentOS 8.4 的内核，当前版本是 kernel-4.18.0-305.an8</p><p>注2：镜像缺省 sudo 用户 anuser，对应登录密码是 anolisos。</p></blockquote><h3><span id="repo-源列表">REPO 源列表</span></h3><table><thead><tr><th><strong>名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>BaseOS</td><td>BaseOS 软件包源，该源目的是提供安装基础的所有核心包。</td></tr><tr><td>AppStream</td><td>AppStream 软件包源，该源提供额外的多场景，多用途的用户态程序，数据库等。该部分引入了额外的 RPM Module 形态。</td></tr><tr><td>PowerTools</td><td>PowerTools 软件包源， 该源提供开发者需要的额外包。</td></tr><tr><td>Plus</td><td>Plus 软件包源，该源提供 OpenAnolis SIG 组专门研发包，如 ANCK 内核，Dragonwell8 JDK等。</td></tr><tr><td>DDE</td><td>DDE 桌面主包以及依赖包</td></tr></tbody></table><h3><span id="下载地址">下载地址</span></h3><ul><li>社区网站</li></ul><p><a href="https://mirrors.openanolis.cn/anolis/8.4/isos/" target="_blank" rel="noopener">https://mirrors.openanolis.cn/anolis/8.4/isos/</a></p><ul><li>阿里云镜像</li></ul><p><a href="https://mirrors.aliyun.com/anolis/8.4/" target="_blank" rel="noopener">https://mirrors.aliyun.com/anolis/8.4/</a></p><h2><span id="参考文档">参考文档</span></h2><ol><li><a href="https://news.mydrivers.com/1/790/790382.htm" target="_blank" rel="noopener">https://news.mydrivers.com/1/790/790382.htm</a></li><li><a href="https://segmentfault.com/a/1190000040419582" target="_blank" rel="noopener">https://segmentfault.com/a/1190000040419582</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日，2021 云栖大会上，阿里云发布了全新操作系统 &lt;strong&gt;“龙蜥”(Anolis OS)&lt;/strong&gt;，并宣布开源。&lt;/p&gt;
&lt;p&gt;据了解，龙蜥操作系统 &lt;strong&gt;定位于服务器市场&lt;/strong&gt;，支持 x86、ARM 等多种硬件架构和计算场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;它特别针对云原生应用开发做了多重优化，云上典型场景的综合性能可提升 40％，同时故障率可降低 50％，还兼容 CentOS 生态，支持一键迁移，并提供全栈国密能力。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;龙蜥操作系统 &lt;strong&gt;完全开源&lt;/strong&gt;，通过开源社区和操作系统厂商等形式提供服务，&lt;strong&gt;技术支持至少 10 年。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="开源" scheme="https://www.hi-linux.com/tags/%E5%BC%80%E6%BA%90/"/>
    
      <category term="阿里云" scheme="https://www.hi-linux.com/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"/>
    
  </entry>
  
</feed>
