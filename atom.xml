<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维之美</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2020-05-23T15:21:29.674Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用 Sysdig 进行监控和调试 Linux 机器</title>
    <link href="https://www.hi-linux.com/posts/9561.html"/>
    <id>https://www.hi-linux.com/posts/9561.html</id>
    <published>2020-05-23T02:26:00.000Z</published>
    <updated>2020-05-23T15:21:29.674Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h3 id="sysdig-简介">Sysdig 简介</h3><p><code>Sysdig</code> 官网 上对自己的介绍是：</p><blockquote><p>Open Source Universal System Visibility With Native Contaier Support.</p></blockquote><p>它的定位是系统监控、分析和排障的工具，其实在 <code>Linux</code> 平台上，已经有很多这方面的工具 <code>strace</code>、<code>tcpdump</code>、<code>htop</code>、<code>iftop</code>、<code>lsof</code>、<code>netstat</code>，它们都能用来分析 <code>Linux</code> 系统的运行情况，而且还有很多日志、监控工具。为什么还需要 <code>Sysdig</code> 呢？在我看来，<code>Sysdig</code> 的优点可以归纳为三个词语：整合、强大、灵活。</p><h4 id="整合">整合</h4><p>虽然 <code>Linux</code> 有很多系统分析和调优的工具，但是它们一般都负责某个特殊的功能，并且使用方式有很大的差异，如果要分析和定位问题，一般都需要熟练掌握需要命令的使用。而且这些工具的数据无法进行共享，只能相互独立工作。<code>Sysdig</code> 一个工具就能实现上述所有工具的功能，并且提供了统一的使用语法。</p><h4 id="强大">强大</h4><p><code>Sysdig</code> 能获取实时的系统数据，也能把信息保存到文件中以供后面分析。捕获的数据包含系统的个个方面：</p><ul><li>全方面的系统参数：CPU、Memory、Disk IO、网络 IO</li><li>支持各种 IO 活动：进程、文件、网络连接等</li></ul><p>除了帮你捕获信息之外，<code>Sysdig</code> 还预先还有有用的工具来分析这些数据，从大量的数据中找到有用的信息变得非常简单。比如你能还简单地做到下面这些事情：</p><ul><li>按照 CPU 的使用率对进程进行排序，找到 CPU 使用率最高的那个</li><li>按照发送网络数据报文的多少对进程进行排序</li><li>找到打开最多文件描述符的进程</li><li>查看哪些进程修改了指定的文件</li><li>打印出某个进程的 HTTP 请求报文</li><li>找到用时最久的系统调用</li><li>查看系统中所有的用户都执行了哪些命令</li><li>……</li></ul><p>基本上自带的工具就能满足大部分的分析需求。</p><a id="more"></a><h4 id="灵活">灵活</h4><p><code>Sysdig</code> 有着类似于 <code>tcpdump</code> 的过滤语法，用户可以随意组合自己的过滤逻辑，从茫茫的数据中找到关心的信息。除此之外，用户还可以自己编写 <code>Lua</code> 脚本来自定义分析逻辑，基本上不受任何限制。</p><h4 id="工作原理">工作原理</h4><p><code>Sysdig</code> 通过在内核的 driver 模块注册系统调用的 hook，这样当有系统调用发生和完成的时候，它会把系统调用信息拷贝到特定的 buffer，然后用户模块的组件对数据信息处理（解压、解析、过滤等），并最终通过 <code>Sysdig</code> 命令行和用户进行交互。</p><p><img src="https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2014/04/Blog2-pic3-1024x886.png" alt=""></p><p>更多的原理可以参考官方博客</p><p>除了 <code>Sysdig</code> 命令之外，还有一个基于终端的 UI 命令 <code>Csysdig</code>，它类似于 <code>top</code> 命令，定时对系统情况进行刷新，并且可以让用户交互。这篇文章我们只介绍 <code>Sysdig</code>，不会讲解 <code>Csysdig</code> 的使用。</p><h3 id="安装">安装</h3><p><code>Sysdig</code> 的安装在官方文档中有详细的说明，这里不再赘述。需要注意的是，<code>Sysdig</code> 对内核版本有一定的要求，请保证内核不要太旧。</p><p>另外，如果使用容器的方式安装，需要把主机的很多系统目录 mount 到容器中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -i -t --name sysdig --privileged -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;host&#x2F;var&#x2F;run&#x2F;docker.sock -v &#x2F;dev:&#x2F;host&#x2F;dev -v &#x2F;proc:&#x2F;host&#x2F;proc:ro -v &#x2F;boot:&#x2F;host&#x2F;boot:ro -v &#x2F;lib&#x2F;modules:&#x2F;host&#x2F;lib&#x2F;modules:ro -v &#x2F;usr:&#x2F;host&#x2F;usr:ro sysdig&#x2F;sysdig</span><br></pre></td></tr></table></figure><h3 id="sysdig-基本用法">Sysdig 基本用法</h3><h4 id="基本格式">基本格式</h4><p>直接在终端输入 <code>sysdig</code> 就能开始捕获系统信息，这个命令需要系统管理员权限，执行后你会看到终端有持续不断的输出流。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sysdig</span><br></pre></td></tr></table></figure><p>因为系统每时每刻都有大量的系统调用产生，这样是没办法看清更无法分析输出信息的，可以先使用 CTRL + c 来退出命令。</p><p>在讲解如何使用 <code>Sysdig</code> 的参数之前，我们先来解释一下它的输出格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">5352209 11:54:08.853479695 0 ssh-agent (13314) &lt; getrusage</span><br><span class="line">5352210 11:54:08.853481094 0 ssh-agent (13314) &gt; clock_gettime</span><br><span class="line">5352211 11:54:08.853482049 0 ssh-agent (13314) &lt; clock_gettime</span><br><span class="line">5352226 11:54:08.853510313 0 ssh-agent (13314) &gt; getrusage</span><br><span class="line">5352228 11:54:08.853511089 0 ssh-agent (13314) &lt; getrusage</span><br><span class="line">5352229 11:54:08.853511646 0 ssh-agent (13314) &gt; clock_gettime</span><br><span class="line">5352231 11:54:08.853512020 0 ssh-agent (13314) &lt; clock_gettime</span><br><span class="line">5352240 11:54:08.853530285 0 ssh-agent (13314) &gt; stat</span><br><span class="line">5352241 11:54:08.853532329 0 ssh-agent (13314) &lt; stat res&#x3D;0 path&#x3D;&#x2F;home&#x2F;cizixs&#x2F;.ssh</span><br><span class="line">5352242 11:54:08.853533065 0 ssh-agent (13314) &gt; stat</span><br><span class="line">5352243 11:54:08.853533990 0 ssh-agent (13314) &lt; stat res&#x3D;0 path&#x3D;&#x2F;home&#x2F;cizixs&#x2F;.ssh&#x2F;id_rsa.pub</span><br><span class="line">5353954 11:54:08.857382204 0 ssh-agent (13314) &gt; write fd&#x3D;16 size&#x3D;280</span><br></pre></td></tr></table></figure><p>所有的输入都是按照行来分割的，每行都是一条记录，由多个列组成，默认的格式是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%evt.num %evt.outputtime %evt.cpu %proc.name (%thread.tid) %evt.dir %evt.type %evt.info</span><br></pre></td></tr></table></figure><p>各个字段的含义如下：</p><ul><li>evt.num： 递增的事件号。</li><li>evt.time： 事件发生的时间。</li><li>evt.cpu： 事件被捕获时所在的 CPU，也就是系统调用是在哪个 CPU 执行的。比较上面的例子中，值 0 代表机器的第一个 CPU。</li><li><a href="http://proc.name" target="_blank" rel="noopener">proc.name</a>： 生成事件的进程名字，也就是哪个进程在运行。</li><li>thread.tid： 线程的 id，如果是单线程的程序，这也是进程的 pid。</li><li>evt.dir： 事件的方向（direction），&gt; 代表进入事件，&lt; 代表退出事件。</li><li>evt.type： 事件的名称，比如 open、stat等，一般是系统调用。</li><li>evt.args： 事件的参数。如果是系统调用，这些对应着系统调用的参数。</li></ul><h4 id="过滤">过滤</h4><p>完整的 <code>Sysdig</code> 使用方法是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysdig [option]...  [filter]</span><br></pre></td></tr></table></figure><p>因为 <code>Sysdig</code> 的输出内容很多，不管是监控还是查问题我们要关注的事件只是其中很小的一部分。这个时候就要用到过滤的功能，找到感兴趣的事件。<code>Sysdig</code> 的过滤功能很强大，不仅支持的过滤项很多，而且还能够自由地进行逻辑组合。</p><p><code>Sysdig</code> 的过滤器也是分成不同类别的，比如:</p><ul><li>fd: 对文件描述符（file descriptor）进行过滤，比如 fd 标号（fd.num）、fd 名字（<a href="http://fd.name" target="_blank" rel="noopener">fd.name</a>）。</li><li>process: 进程信息的过滤，比如进程 id（<a href="http://proc.id" target="_blank" rel="noopener">proc.id</a>）、进程名（<a href="http://proc.name" target="_blank" rel="noopener">proc.name</a>）。</li><li>evt: 事件信息的过滤，比如事件编号、事件名。</li><li>user: 用户信息的过滤，比如用户 id、用户名、用户 home 目录、用户的登录 shell（user.shell）。</li><li>syslog: 系统日志的过滤，比如日志的严重程度、日志的内容。</li><li>fdlist: poll event 的文件描述符的过滤。</li></ul><p>完整的过滤器列表可以使用 <code>sysdig -l</code> 来查看，比如可以查看建立 TCP 连接的事件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sysdig evt.type&#x3D;accept</span><br></pre></td></tr></table></figure><p>过滤器除了直接的相等比较之外，还有其他操作符，包括 =、!=、&gt;=、&gt;、&lt;、&lt;=、contains、in 和 exists，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig fd.name contains &#x2F;etc</span><br><span class="line">$ sysdig &quot;evt.type in ( &#39;select&#39;, &#39;poll&#39; )&quot;</span><br><span class="line">$ sysdig proc.name exists</span><br></pre></td></tr></table></figure><p>更酷的是，多个过滤条件还可以通过 and、or 和 not 进行逻辑组合，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig &quot;not (fd.name contains &#x2F;proc or fd.name contains &#x2F;dev)&quot;</span><br></pre></td></tr></table></figure><p>这些强大的功能综合到一起，就能让我们很容易定位到需要的事件，分析和监控更有目的性。</p><h4 id="自定义输出格式">自定义输出格式</h4><p>标准的输出已经打印出常用的信息，sysdig 还允许你自定义打印出的内容，参数 <code>-p</code> 可以加上类似于 C 语言 printf 字符串，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -p&quot;user:%user.name dir:%evt.arg.path&quot; evt.type&#x3D;chdir</span><br><span class="line">user:ubuntu dir:&#x2F;root</span><br><span class="line">user:ubuntu dir:&#x2F;root&#x2F;tmp</span><br><span class="line">user:ubuntu dir:&#x2F;root&#x2F;Download</span><br></pre></td></tr></table></figure><p>上面的信息，可以很容易看到用户更改当前目录的情况。从上面的例子也可以使用 <code>-p</code> 的使用方法：</p><ul><li>字段必须用 % 作为前缀，所有在 <code>sysdig -l</code> 中列出来的字段都可以使用</li><li>你可以在字符串中加入其他可读性的内容，它们会如实打印出来</li><li>如果某个字段在时间中不存在，默认这个事件会过滤掉，在这个字符串最前面加上 * 符号，会打印出所有的事件，不存在的字段会变成 <na>，比如:</na></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -p&quot;*%evt.type %evt.dir %evt.arg.name&quot; evt.type&#x3D;open</span><br><span class="line">open &gt; &lt;NA&gt;</span><br><span class="line">open &lt; &#x2F;proc&#x2F;1285&#x2F;task&#x2F;1399&#x2F;stat</span><br><span class="line">open &gt; &lt;NA&gt;</span><br><span class="line">open &lt; &#x2F;proc&#x2F;1285&#x2F;task&#x2F;1400&#x2F;io</span><br><span class="line">open &gt; &lt;NA&gt;</span><br><span class="line">open &lt; &#x2F;proc&#x2F;1285&#x2F;task&#x2F;1400&#x2F;statm</span><br><span class="line">open &gt; &lt;NA&gt;</span><br></pre></td></tr></table></figure><h4 id="保存到文件">保存到文件</h4><p>尽管可以用过滤器减少输出，直接在终端查看事件流还是没有办法让我们进行深入分析。和 <code>tcpdump</code> 工具类似，<code>Sysdig</code> 也允许你把捕获的时间保存到本地的文件，然后再读取文件的内容进行分析。</p><p>保存到文件可以通过 <code>-w</code> 实现，从文件中读取需要 <code>-r</code> 参数，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 捕获事件，并保存到文件中，这样在终端是看不到输出的。</span><br><span class="line">$ sudo sysdig -w sysdig-trace-file.scap</span><br><span class="line"></span><br><span class="line"># 从文件中读取 Sysdig 格式的事件进行分析。</span><br><span class="line">$ sudo sysdig -r sysdig-trace-file.scap</span><br></pre></td></tr></table></figure><p>另一个有用的功能是，你可以控制捕获到文件的内容。通常情况下，<code>Sysdig</code> 捕获了系统所有的活动，因此这些数据会很大，如果一直捕获的话，会造成磁盘空间的浪费，<code>Sysdig</code> 提供了类似于 <code>logrotate</code> 的方式，让你只保存最新捕获的文件。</p><p>控制捕获文件大小的一个办法是在捕获的使用使用过滤器，之外，你还可以通过 <code>-n 2000</code> 指定捕获 2000 条事件之后就退出，或者通过 <code>logrotate</code> 的方式来滚动文件：</p><ul><li><code>sysdig -C 5 -W 10 -w dump.pcap</code> ：保证每个文件不超过 5M 大小，并且只保存最近的 10 个文件</li><li><code>sysdig -G 60 -W 60 -w dump.pcap</code>：每个文件只保存一分钟内的系统活动（-G 60），并且只保存 60 个文件，也就是说捕获最近一个小时的系统活动，每分钟的数据一个文件</li><li><code>sysdig -e 1000 -W 5 -w dump.scap</code>：保存 5 个文件，每个文件只有 1000 个事件</li></ul><p>当使用 <code>-w</code> 保存文件的使用，还可以使用 <code>-z</code> 参数对保存的内容进行压缩，进一步减少占用的空间。</p><p>读取的时候也可以使用过滤器，如果我们只关心 write 系统调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -r sysdig-trace-nano.scap evt.type&#x3D;write</span><br></pre></td></tr></table></figure><p>而且读取的时候也可以进一步对文件进行分割，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -r dump.scap -G 300 -z -w segments.scap</span><br></pre></td></tr></table></figure><p>这个命令，就是读取 dump.scap 文件的内容，并且把它分割成五分钟（-G 300s）的多个文件。</p><h4 id="常用的参数">常用的参数</h4><p>除了上面介绍的过滤器参数，<code>Sysdig</code> 还有很多可用的参数，完整的列表和解释请参考 <code>man sysdig</code> 文档。这里介绍一下比较常用的：</p><ul><li>-A --print-ascii：把 buffer 中数据按照 ASCII 格式打印，方便用户阅读</li><li>-x --print-hex： 把 buffer 中数据按照十六进制格式打印</li><li>-X --print-hex-ascii： 把 buffer 中数据同时按照 ASCII 格式和十六进制格式打印</li><li>-s 1024：捕获 buffer 的数据大小，默认为 80，如果这个值设置的过大，会产生很大的文件</li><li>-N：不用把端口号转换成可读的名字，这个参数会提高处理的效率</li></ul><h3 id="chisels实用的工具箱">Chisels：实用的工具箱</h3><p>虽然有了过滤器和文件的输入输出，加上 <code>Sysdig</code> 其他的参数，我们可以按照需求去分析和监控系统了，但是很多场景需要更复杂的数据聚合。<code>Sysdig</code> 提供了另外一个强大的功能：<code>chisels</code>，它们是一组预定义的功能集合，通过 <code>Lua</code> 脚本实现，用来分析特定的场景。</p><p>可以通过 <code>sudo sysdig -cl</code> 列出支持的所有 <code>chisels</code>，我们来解释一些比较常用的 <code>chisels</code>：</p><ul><li>httplog：输出所有的 HTTP 请求。</li><li>topprocs_cpu：输出按照 CPU 使用率排序的进程列表。</li><li>echo_fds：输出进程读写的数据。</li><li>netstat：列出网络的连接情况。</li><li>spy_file：输出文件的读写数据，可以提供某个文件名作为参数，这样就只输出该文件的读写内容。</li></ul><p>有些 <code>chisel</code> 可能需要参数才能正常运行，如果要了解某个 <code>chisel</code> 的具体使用说明，可以用 <code>-i</code> 参数，比如要了解 <code>spy_file</code> 的用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sysdig -i spy_file</span><br><span class="line"></span><br><span class="line">Category: I&#x2F;O</span><br><span class="line">-------------</span><br><span class="line">spy_file        Echo any read&#x2F;write made by any process to all files. Optionall</span><br><span class="line">                y, you can provide the name of one file to only intercept reads</span><br><span class="line">                &#x2F;writes to that file.</span><br><span class="line"></span><br><span class="line">This chisel intercepts all reads and writes to all files. Instead of all files,</span><br><span class="line"> you can limit interception to one file.</span><br><span class="line">Args:</span><br><span class="line">[string] read_or_write - Specify &#39;R&#39; to capture only read event</span><br><span class="line">                s; &#39;W&#39; to capture only write events; &#39;RW&#39; to capture read and w</span><br><span class="line">                rite events. By default both read and write events are captured</span><br><span class="line">                .</span><br><span class="line">[string] spy_on_file_name - The name of the file which the chis</span><br><span class="line">                el should spy on for all read and write activity.</span><br></pre></td></tr></table></figure><p>文章最开始的时候，我提到过 <code>Sysdig</code> 可以满足大部分的日常分析，它们主要就是通过 <code>chisel</code> 完成的。比如：</p><p>按照网络的使用情况对进程进行排序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  sysdig -c topprocs_net</span><br></pre></td></tr></table></figure><p>按照建立连接数量对进程进行排序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -c fdcount_by fd.sport &quot;evt.type&#x3D;accept&quot;</span><br></pre></td></tr></table></figure><p>查看系统中用户执行的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -r sysdig.pcap -c spy_users</span><br></pre></td></tr></table></figure><p>更多的使用案例，可以参考 Sysdig Example 这篇 wiki。</p><p>在 <code>Linux</code> 机器上，这些 <code>chisel</code> 保存在 /usr/share/sysdig/chisels 文件夹中，每个 <code>chisel</code> 对应一个 <code>Lua</code> 脚本文件。如果提供的这些 <code>chisel</code> 还不能满足需求，用户也可以根据需求编写自己的 <code>chisel</code>。</p><h3 id="对容器的支持">对容器的支持</h3><p><code>Sysdig</code> 另外一个优势是它对容器（ <code>Docker</code> 和 <code>Kubernetes</code> ）的良好支持，这对于目前采用了容器化的系统管理员来说是很好的福利。</p><p>使用 <code>-pc</code> 参数就能自动在打印的事件中添加上容器的信息（容器名、容器 id 等），比如捕获 container 名字为 zen_knuth 的所有系统活动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -pc container.name&#x3D;zen_knuth</span><br></pre></td></tr></table></figure><p>对容器的分析和原来的一样，只要通过 container.name=apache 指定要分析的容器名字就行，比如查看某个容器的网络连接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysdig -pc -c topconns container.name&#x3D;wordpress1</span><br></pre></td></tr></table></figure><p>要集成 <code>Kubernetes</code> 系统监控的话，使用 <code>-k http://master_ip:8080</code> 参数，后面是 apiserver 的地址，如果 apiserver 需要认证的话，需要指定 <code>-K filename</code> 来说明 apiserver CA 证书的文件地址。关于 <code>Kubernetes</code> 的监控和分析不是这篇文章的重点，读者可以参数 <code>Sysdig</code> 的博客或者其他文档。</p><h3 id="csysdig图形化的-sysdig">Csysdig：图形化的 Sysdig</h3><p><code>Sysdig</code> 还提供了另外一个图形化的工具：<code>Csysdig</code>，它的界面和 top/htop 命令相似，并且可以接受用户的交互。</p><p><img src="https://assets.digitalocean.com/articles/sysdig_ubuntu_1604/LEhCwvI.jpg" alt=""></p><p>和 <code>Sysdig</code> 一样，<code>Csysdig</code> 可以实时捕获系统事件，也可以读取之前保存的文件。</p><h3 id="更多文档">更多文档</h3><p>这篇文章介绍的都出入门的、基础概念性的知识，如果读者希望进一步了解 sysdig，不妨继续阅读下面这些文章：</p><ul><li>sysdig 和传统的 strace、htop、lsof、tcpdump、iftop命令的比较</li><li>理解 sysdig 的输出</li><li>sysdig twitter 账号 #digoftheday</li></ul><h3 id="参考资料">参考资料</h3><p>这篇文章主要参考了一下的博客、文章和资料：</p><ul><li>Sysdig User Guide</li><li>Linux Troubleshooting Cheatsheet: strace, htop, lsof, tcpdump, iftop &amp; sysdig</li><li>DigitalOcean: How To Monitor Your Ubuntu 16.04 System with Sysdig</li><li>Sysdig vs DTrace vs Strace: a Technical Discussion</li><li>用 Sysdig 监控服务器和 Docker 容器</li></ul><blockquote><p>来源：Cizixs Blogs</p><p>原文：<a href="https://tinyurl.com/yc3tm4bf" target="_blank" rel="noopener">https://tinyurl.com/yc3tm4bf</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Sysdig-简介&quot;&gt;Sysdig 简介&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Sysdig&lt;/code&gt; 官网 上对自己的介绍是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Open Source Universal System Visibility With Native Contaier Support.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;它的定位是系统监控、分析和排障的工具，其实在 &lt;code&gt;Linux&lt;/code&gt; 平台上，已经有很多这方面的工具 &lt;code&gt;strace&lt;/code&gt;、&lt;code&gt;tcpdump&lt;/code&gt;、&lt;code&gt;htop&lt;/code&gt;、&lt;code&gt;iftop&lt;/code&gt;、&lt;code&gt;lsof&lt;/code&gt;、&lt;code&gt;netstat&lt;/code&gt;，它们都能用来分析 &lt;code&gt;Linux&lt;/code&gt; 系统的运行情况，而且还有很多日志、监控工具。为什么还需要 &lt;code&gt;Sysdig&lt;/code&gt; 呢？在我看来，&lt;code&gt;Sysdig&lt;/code&gt; 的优点可以归纳为三个词语：整合、强大、灵活。&lt;/p&gt;
&lt;h4 id=&quot;整合&quot;&gt;整合&lt;/h4&gt;
&lt;p&gt;虽然 &lt;code&gt;Linux&lt;/code&gt; 有很多系统分析和调优的工具，但是它们一般都负责某个特殊的功能，并且使用方式有很大的差异，如果要分析和定位问题，一般都需要熟练掌握需要命令的使用。而且这些工具的数据无法进行共享，只能相互独立工作。&lt;code&gt;Sysdig&lt;/code&gt; 一个工具就能实现上述所有工具的功能，并且提供了统一的使用语法。&lt;/p&gt;
&lt;h4 id=&quot;强大&quot;&gt;强大&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Sysdig&lt;/code&gt; 能获取实时的系统数据，也能把信息保存到文件中以供后面分析。捕获的数据包含系统的个个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全方面的系统参数：CPU、Memory、Disk IO、网络 IO&lt;/li&gt;
&lt;li&gt;支持各种 IO 活动：进程、文件、网络连接等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了帮你捕获信息之外，&lt;code&gt;Sysdig&lt;/code&gt; 还预先还有有用的工具来分析这些数据，从大量的数据中找到有用的信息变得非常简单。比如你能还简单地做到下面这些事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按照 CPU 的使用率对进程进行排序，找到 CPU 使用率最高的那个&lt;/li&gt;
&lt;li&gt;按照发送网络数据报文的多少对进程进行排序&lt;/li&gt;
&lt;li&gt;找到打开最多文件描述符的进程&lt;/li&gt;
&lt;li&gt;查看哪些进程修改了指定的文件&lt;/li&gt;
&lt;li&gt;打印出某个进程的 HTTP 请求报文&lt;/li&gt;
&lt;li&gt;找到用时最久的系统调用&lt;/li&gt;
&lt;li&gt;查看系统中所有的用户都执行了哪些命令&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基本上自带的工具就能满足大部分的分析需求。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Sysdig" scheme="https://www.hi-linux.com/tags/Sysdig/"/>
    
  </entry>
  
  <entry>
    <title>Linux 中 Pstree 命令使用指南</title>
    <link href="https://www.hi-linux.com/posts/35899.html"/>
    <id>https://www.hi-linux.com/posts/35899.html</id>
    <published>2020-05-23T02:25:00.000Z</published>
    <updated>2020-05-23T15:15:28.061Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在 Linux 机器上工作时，有时你可能需要找出当前正在运行的进程。你可以使用许多命令来查找有关正在运行的进程的信息，其中 <code>ps</code> 和 <code>top</code> 是最常用的命令。</p><p>在本文中，我们将讨论 <code>pstree</code> 命令。它类似于 <code>ps</code> ，但没有列出正在运行的进程，而是将它们显示在一个目录树中。树状格式是以一种更方便的方式来显示进程层次结构，并使输出在视觉上更具吸引力。</p><h2 id="如何使用-pstree-命令">如何使用 pstree 命令</h2><p><code>pstree</code> 命令的一般语法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps [OPTIONS] [USER or PID]</span><br></pre></td></tr></table></figure><p>以最简单的形式调用时没有任何选项或参数，<code>pstree</code> 命令将显示所有正在运行的进程的分层树结构。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ pstree</span><br><span class="line">systemd─┬─VBoxService───7*[&#123;VBoxService&#125;]</span><br><span class="line">        ├─accounts-daemon───2*[&#123;accounts-daemon&#125;]</span><br><span class="line">        ├─2*[agetty]</span><br><span class="line">        ├─atd</span><br><span class="line">        ├─cron</span><br><span class="line">        ├─dbus-daemon</span><br><span class="line">        ├─irqbalance───&#123;irqbalance&#125;</span><br><span class="line">        ├─2*[iscsid]</span><br><span class="line">        ├─lvmetad</span><br><span class="line">        ├─lxcfs───2*[&#123;lxcfs&#125;]</span><br><span class="line">        ├─networkd-dispat───&#123;networkd-dispat&#125;</span><br><span class="line">        ├─nginx───2*[nginx]</span><br><span class="line">...</span><br></pre></td></tr></table></figure><a id="more"></a><p>目录树中的 <code>top/root</code> 项目是所有系统进程的父进程。在此示例中为 <code>systemd</code>，这是系统启动时启动的第一个进程。</p><p><code>pstree</code> 通过将相同的分支放在方括号之间并为它们加上代表分支数的整数作为前缀来合并它们，这使得输出更具可读性和视觉吸引力。以下是显示如何使用方括号的示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pstree</span><br><span class="line">├─2*[agetty]</span><br></pre></td></tr></table></figure><p>要禁用相同分支的合并，请使用 <code>-c</code> 选项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -c</span><br><span class="line">├─agetty        </span><br><span class="line">├─agetty</span><br></pre></td></tr></table></figure><p>每个进程的线程显示在父进程下，并使用花括号内的进程名称显示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">├─lxcfs───2*[&#123;lxcfs&#125;]</span><br></pre></td></tr></table></figure><p>你可以使用 <code>-t</code> 选项显示完整的线程名称，如果要隐藏线程并仅显示进程，请使用 <code>-T</code> 选项。</p><p>通常，<code>pstree</code> 会在屏幕上显示多行输出。要一次查看输出一页，你可以将其结果通过管道传递到 <code>less</code> 命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pstree | less</span><br></pre></td></tr></table></figure><p>如果使用用户名作为参数，则 <code>pstree</code> 仅显示该用户拥有的进程。例如，以下命令将仅显示那些由名为 myfreax 的用户启动的进程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pstree myfreax</span><br></pre></td></tr></table></figure><p>如果将 <code>PID</code> 指定为参数，则 <code>pstree</code> 将显示一棵以给定进程为树根的目录树。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pstree 1943</span><br><span class="line">sshd───bash───pstree</span><br></pre></td></tr></table></figure><p>要显示给定进程的父进程，你可以使用 <code>-s</code> 选项，并在其后跟进程 <code>PID</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -s 1943</span><br><span class="line">systemd───sshd───sshd───bash───pstree</span><br></pre></td></tr></table></figure><h2 id="显示-pid-和-pgid">显示 PID 和 PGID</h2><p>通常，当运行 <code>pstree</code> 命令时，用户寻找的最重要的信息是进程 ID。例如，你知道 PID 即可让你杀死发生故障的进程。</p><p>我们可以通过 <code>-p</code> 选项让 <code>pstree</code> 显示进程的 <code>PID</code> 。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个进程或线程后的括号中均显示的是 PID。</span></span><br><span class="line">$ pstree -p</span><br><span class="line">systemd(1)─┬─VBoxService(955)─┬─&#123;VBoxService&#125;(956)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(957)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(958)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(959)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(960)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(961)</span><br><span class="line">           │                  └─&#123;VBoxService&#125;(962)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>默认情况下，<code>pstree</code> 按名称对具有相同父项的进程进行排序。 如果你想按 <code>PID</code> 排序，你则可以使用 <code>-n</code> 选项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -pn</span><br></pre></td></tr></table></figure><p>一个或多个进程组 ID 是进程组的第一个成员的进程 ID。如果你要查看 <code>PGID</code>，可以使用 <code>-g</code> 选项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个进程或线程之后的括号中也显示了 PID。</span></span><br><span class="line">$ pstree -g</span><br><span class="line">systemd(1)─┬─VBoxService(954)─┬─&#123;VBoxService&#125;(954)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(954)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(954)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(954)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(954)</span><br><span class="line">           │                  ├─&#123;VBoxService&#125;(954)</span><br><span class="line">           │                  └─&#123;VBoxService&#125;(954)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>注：显示 <code>PID</code> 或 <code>PGID</code> 时，将隐式禁用默认的进程合并。</p></blockquote><h2 id="显示命令行参数">显示命令行参数</h2><p>默认情况下，<code>pstree</code> 不会向你显示正在运行的进程的命令行参数。要查看进程是如何开始的，你可以使用 <code>-a</code> 选项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -a</span><br><span class="line">...</span><br><span class="line">  ├─agetty -o -p -- \\u --keep-baud 115200,38400,9600 ttyS0 vt220</span><br><span class="line">  ├─agetty -o -p -- \\u --noclear tty1 linux</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="高亮">高亮</h2><p><code>pstree</code> 还可以使你突出显示进程以更好地呈现视觉效果。-h 选项指示 <code>pstree</code> 高亮显示当前进程及其所有父进程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -h</span><br></pre></td></tr></table></figure><p>如果要高亮显示特定的进程，你可以使用 <code>-H</code> 选项，然后加上进程 ID。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -H PID_NUMBER</span><br></pre></td></tr></table></figure><h2 id="结论">结论</h2><p>至此，我们就讲完了以树结构的形式显示正在运行的进程的 <code>pstree</code> 命令。有关所有可用 <code>pstree</code> 选项的信息，你可以通过在终端中输入 <code>man pstree</code> 进行查看。</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://url.cn/5yQDYSA" target="_blank" rel="noopener">https://url.cn/5yQDYSA</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 Linux 机器上工作时，有时你可能需要找出当前正在运行的进程。你可以使用许多命令来查找有关正在运行的进程的信息，其中 &lt;code&gt;ps&lt;/code&gt; 和 &lt;code&gt;top&lt;/code&gt; 是最常用的命令。&lt;/p&gt;
&lt;p&gt;在本文中，我们将讨论 &lt;code&gt;pstree&lt;/code&gt; 命令。它类似于 &lt;code&gt;ps&lt;/code&gt; ，但没有列出正在运行的进程，而是将它们显示在一个目录树中。树状格式是以一种更方便的方式来显示进程层次结构，并使输出在视觉上更具吸引力。&lt;/p&gt;
&lt;h2 id=&quot;如何使用-pstree-命令&quot;&gt;如何使用 pstree 命令&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;pstree&lt;/code&gt; 命令的一般语法如下：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ps [OPTIONS] [USER or PID]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;以最简单的形式调用时没有任何选项或参数，&lt;code&gt;pstree&lt;/code&gt; 命令将显示所有正在运行的进程的分层树结构。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ pstree&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;systemd─┬─VBoxService───7*[&amp;#123;VBoxService&amp;#125;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─accounts-daemon───2*[&amp;#123;accounts-daemon&amp;#125;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─2*[agetty]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─atd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─cron&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─dbus-daemon&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─irqbalance───&amp;#123;irqbalance&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─2*[iscsid]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─lvmetad&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─lxcfs───2*[&amp;#123;lxcfs&amp;#125;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─networkd-dispat───&amp;#123;networkd-dispat&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ├─nginx───2*[nginx]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;...&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="终端" scheme="https://www.hi-linux.com/tags/%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>浅谈劳动合同法中赔偿金 N、N+1、2N 的区别</title>
    <link href="https://www.hi-linux.com/posts/16375.html"/>
    <id>https://www.hi-linux.com/posts/16375.html</id>
    <published>2020-05-23T02:24:00.000Z</published>
    <updated>2020-05-23T15:12:14.458Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="1-离职经济补偿金的法律依据是什么">1. 离职经济补偿金的法律依据是什么？</h2><p>首先需要注意的是，虽然我们遇到问题就会提到《劳动法》，但是离职经济补偿金的相关规定都在《劳动合同法》之中，两个法规并不是一回事。所以，再遇到相关问题的时候就不要拿《劳动法》说事了。</p><h2 id="2-n-是什么意思">2. N 是什么意思？</h2><p>参见第四十七条，经济补偿计算</p><p>经济补偿按劳动者在本单位工作的年限，每满一年支付一个月工资的标准向劳动者支付。六个月以上不满一年的，按一年计算；不满六个月的，向劳动者支付半个月工资的经济补偿。</p><p>这里大家俗称的 N 就是指劳动者在用人单位的工作年限。</p><h2 id="3-n1-是怎么回事">3. N+1 是怎么回事？</h2><p>参见第四十条 无过失性辞退</p><p>有下列情形之一的，用人单位提前三十日以书面形式通知劳动者本人或者额外支付劳动者一个月工资后，可以解除劳动合同：</p><p>（一）劳动者患病或者非因工负伤，在规定的医疗期满后不能从事原工作，也不能从事由用人单位另行安排的工作的；</p><p>（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；</p><p>（三）劳动合同订立时所依据的客观情况发生重大变化，致使劳动合同无法履行，经用人单位与劳动者协商，未能就变更劳动合同内容达成协议的。</p><p>也就是说如果用人单位按照以上情况主动辞退员工的时候，需要支付 N 个月的补偿金，但是必须提前三十天以书面形式通知劳动者，这实际上是为了让劳动者有一个缓冲期来找新的工作以及处理社保等内容。<strong>如果没有提前通知就要辞退的话，需要额外支付一个月的补偿金，也就是 N+1的来源。</strong></p><a id="more"></a><h2 id="4-为什么有的公司只需要赔偿-n">4. 为什么有的公司只需要赔偿 N ？</h2><p>参见第四十一条 经济性裁员</p><p>有下列情形之一，需要裁减人员二十人以上或者裁减不足二十人但占企业职工总数百分之十以上的，用人单位提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见后，裁减人员方案经向劳动行政部门报告，可以裁减人员：</p><p>（一）依照企业破产法规定进行重整的；</p><p>（二）生产经营发生严重困难的；</p><p>（三）企业转产、重大技术革新或者经营方式调整，经变更劳动合同后，仍需裁减人员的；</p><p>（四）其他因劳动合同订立时所依据的客观经济情况发生重大变化，致使劳动合同无法履行的。</p><p>满足这个前提条件的情况下，公司主动辞退员工的时候，不用提前一个月通知，也不用额外支付一个月的补偿金，所以只需要赔偿N就可以了。但是，为了避免公司投机取巧，还规定了优先留用人员以及优先招用规则：</p><p>裁减人员时，应当优先留用下列人员：</p><p>（一）与本单位订立较长期限的固定期限劳动合同的；</p><p>（二）与本单位订立无固定期限劳动合同的；</p><p>（三）家庭无其他就业人员，有需要扶养的老人或者未成年人的。用人单位依照本条第一款规定裁减人员，在六个月内重新招用人员的，应当通知被裁减的人员，并在同等条件下优先招用被裁减的人员。</p><h2 id="5-什么情况公司解雇员工不用赔偿">5. 什么情况公司解雇员工不用赔偿？</h2><p>参见第三十九条 用人单位单方解除劳动合同（过失性辞退）</p><p>劳动者有下列情形之一的，用人单位可以解除劳动合同：</p><p>（一）在试用期间被证明不符合录用条件的；</p><p>（二）严重违反用人单位的规章制度的；</p><p>（三）严重失职，营私舞弊，给用人单位造成重大损害的；</p><p>（四）劳动者同时与其他用人单位建立劳动关系，对完成本单位的工作任务造成严重影响，或者经用人单位提出，拒不改正的；</p><p>（五）因本法第二十六条第一款第一项规定的情形致使劳动合同无效的；</p><p>（六）被依法追究刑事责任的。</p><p>这里重点介绍一下！当员工有过错的前提下，公司确实可以开除员工而不用支付补偿金。</p><p><strong>但是！但是！但是！</strong></p><p><strong>公司很难依照此条文解雇员工，具体常见逼退手段下面再单独讲解！</strong></p><h2 id="6-为什么有人可以获得-2n-赔偿">6. 为什么有人可以获得 2N 赔偿？</h2><p>参见第八十七条 违反解除或者终止劳动合同的法律责任</p><p>用人单位违反本法规定解除或者终止劳动合同的，应当依照本法第四十七条规定的经济补偿标准的二倍向劳动者支付赔偿金。</p><p>这里例句一些常见的一些情况，方便大家保护自身利益：</p><p>（一）从事接触职业病危害作业的劳动者未进行离岗前职业健康检查，或者疑似职业病病人在诊断或者医学观察期间的；</p><p>（二）在本单位患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；</p><p>（三）患病或者非因工负伤，在规定的医疗期内的；</p><p>（四）女职工在孕期、产期、哺乳期的；</p><p>（五）在本单位连续工作满十五年，且距法定退休年龄不足五年的；</p><p>（六）法律、行政法规规定的其他情形。</p><p>法律上并没有 2N+1 的说法，毕竟违法裁员，根本不需要提前一个月通知，所以只有 2N，没有 2N+1。注意：2N 这个就应该叫做赔偿金了，是违法的赔偿。</p><h2 id="7-为什么有人可以获得-n6">7. 为什么有人可以获得 N+6？</h2><p>N+6 等补偿金更多的是一种操作策略，而不是出于劳动合同法上的需求。企业为了尽快解决裁员问题，减少麻烦，会提出各种补偿办法。比如今年的甲骨文裁员，5 月 22 日前签字是 N+6，6 月 7 日前签字是 N+1，6 月 7后签字走人就只有 N 了。</p><h2 id="8-员工主动离职可以提出补偿吗">8. 员工主动离职可以提出补偿吗？</h2><p>参见第三十七条 劳动者提前通知解除劳动合同</p><p>劳动者提前三十日以书面形式通知用人单位，可以解除劳动合同。劳动者在试用期内提前三日通知用人单位，可以解除劳动合同。</p><p>所以，自己提出辞职的人，就不要再想拿补偿金了。</p><h2 id="9-劳动合同到期了辞退员工如何补偿">9. 劳动合同到期了辞退员工如何补偿？</h2><p>劳动合同到期，如果公司不想续签也需要补偿 N。另外，如果员工可以签订<strong>无固定期限劳动合同</strong>的情况，公司需要支付 2N 的赔偿。</p><h2 id="10-什么是无固定期限劳动合同">10. 什么是无固定期限劳动合同？</h2><p>参见第十四条 无固定期限劳动合同</p><p>无固定期限劳动合同，是指用人单位与劳动者约定无确定终止时间的劳动合同。用人单位与劳动者协商一致，可以订立无固定期限劳动合同。有下列情形之一，劳动者提出或者同意续订、订立劳动合同的，除劳动者提出订立固定期限劳动合同外，应当订立无固定期限劳动合同：</p><p>（一）劳动者在该用人单位连续工作满十年的；</p><p>（二）用人单位初次实行劳动合同制度或者国有企业改制重新订立劳动合同时，劳动者在该用人单位连续工作满十年且距法定退休年龄不足十年的；</p><p>（三）连续订立二次固定期限劳动合同，且劳动者没有本法第三十九条和第四十条第一项、第二项规定的情形，续订劳动合同的。用人单位自用工之日起满一年不与劳动者订立书面劳动合同的，视为用人单位与劳动者已订立无固定期限劳动合同。</p><p>所以各位可以检查一下自己是否签订了无固定期限劳动合同？</p><h2 id="11-离职经济补偿金的基数怎么算">11. 离职经济补偿金的基数怎么算？</h2><p>1）合同解除前 12 个月内的货币性收入</p><p>2）应发工资（税前工资）</p><p>3）包含年终奖或年终双薪、包含津贴和补贴</p><p>4）包含加班费（据说上海规定不含，具体遇到问题的朋友请及时联系法律顾问）</p><h2 id="12-为什么我的补偿金少了">12. 为什么我的补偿金少了？</h2><p>参见第四十七条 经济补偿的计算</p><p>劳动者月工资高于用人单位所在直辖市、设区的市级人民政府公布的本地区上年度职工月平均工资三倍的，向其支付经济补偿的标准按职工月平均工资三倍的数额支付，向其支付经济补偿的年限最高不超过十二年。</p><p>所以，如果你的工资太高了，也不会给你补偿那么多的。以北京为例，2019 年平均工作为 6906，最高的离职补偿金就是：6909x3x12≈25万。</p><p>补偿金不用缴纳个税。</p><h2 id="13-劳动合同不同于劳务合同">13. 劳动合同不同于劳务合同</h2><p>劳务关系，是指不构成劳动关系的，一方提供劳务、一方支付报酬的民事关系，如家庭或个人与家政服务人员之间的关系，个体工匠与帮工、学徒之间的关系，农村承包经营户与受雇人之间的关系等。</p><p>劳务关系离职是没有补偿金说法的，所以签订协议时要明确是劳动合同还是劳务合同。</p><h2 id="14-劳动合同法是保护劳动者的">14. 劳动合同法是保护劳动者的！</h2><p>虽然我们在第 5 点里介绍了公司可以不支付补偿金的情况，<strong>但是绝大多数情况下，公司都很难以此来解除劳动合同，而在解除合同过程中任何一点瑕疵，都是违法的！</strong></p><p>所有解除的理由必须证据确凿并需要你亲自签字确认才可以，而且重大过失要有调查过程，还需要给你澄清的机会。总之，<strong>劳动者面对违法解约时，只要上诉劳动仲裁部门，基本都能赢，所以不要怕 HR 的威逼利诱！</strong></p><p>就比如严重违反用人单位的规章制度这一条，上班睡觉算不算违反，上班玩手机算不算违反？如果要按照仲裁流程的话，用人单位要提供清楚什么内容才算玩手机，玩了多久才算违规，另外还需要提供证据证明你在什么时间到什么时候玩了什么内容，对公司的生产造成了什么样的危害。总之，所有的举证责任都在公司，想要合法的开除一个人，是真的很难很难的。</p><p>再比很多 HR 会拿绩效不达标或者末尾淘汰为理由辞退员工。但是需要注意的是绩效不达标、末位淘汰≠不能胜任工作。另外，绩效考核标准必须合理，这一点就有大的解释空间和法律风险。都需要公司去举证。</p><p>另外常见的手段就是给你转岗到海外或者不发达地区，其实这个属于变动了劳动合同内容，需要与员工协商签字才可以，否则就是违法的！</p><p><strong>《中华人民共和国劳动合同法》 完整版本</strong>可参见这里：<a href="https://url.cn/5QSBTZj" target="_blank" rel="noopener">https://url.cn/5QSBTZj</a></p><blockquote><p>再提醒一点：哺乳期的同事不要同意签署延迟协议（HR 会让你哺乳期结束就滚蛋），务必直接签下一个合同，否则劳动局仲裁；</p></blockquote><p><strong>最后！和 HR 还有主管谈话时，</strong></p><p><strong>记得带好录音笔！</strong></p><p><strong>记得带好录音笔！</strong></p><p><strong>记得带好录音笔！</strong></p><p>希望这篇文章能给到广大朋友以帮助！</p><blockquote><p>本文转载自：「表哥有话讲」，原文：<a href="https://url.cn/5Ls0zGQ%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5Ls0zGQ，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-离职经济补偿金的法律依据是什么？&quot;&gt;1. 离职经济补偿金的法律依据是什么？&lt;/h2&gt;
&lt;p&gt;首先需要注意的是，虽然我们遇到问题就会提到《劳动法》，但是离职经济补偿金的相关规定都在《劳动合同法》之中，两个法规并不是一回事。所以，再遇到相关问题的时候就不要拿《劳动法》说事了。&lt;/p&gt;
&lt;h2 id=&quot;2-N-是什么意思？&quot;&gt;2. N 是什么意思？&lt;/h2&gt;
&lt;p&gt;参见第四十七条，经济补偿计算&lt;/p&gt;
&lt;p&gt;经济补偿按劳动者在本单位工作的年限，每满一年支付一个月工资的标准向劳动者支付。六个月以上不满一年的，按一年计算；不满六个月的，向劳动者支付半个月工资的经济补偿。&lt;/p&gt;
&lt;p&gt;这里大家俗称的 N 就是指劳动者在用人单位的工作年限。&lt;/p&gt;
&lt;h2 id=&quot;3-N-1-是怎么回事？&quot;&gt;3. N+1 是怎么回事？&lt;/h2&gt;
&lt;p&gt;参见第四十条 无过失性辞退&lt;/p&gt;
&lt;p&gt;有下列情形之一的，用人单位提前三十日以书面形式通知劳动者本人或者额外支付劳动者一个月工资后，可以解除劳动合同：&lt;/p&gt;
&lt;p&gt;（一）劳动者患病或者非因工负伤，在规定的医疗期满后不能从事原工作，也不能从事由用人单位另行安排的工作的；&lt;/p&gt;
&lt;p&gt;（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；&lt;/p&gt;
&lt;p&gt;（三）劳动合同订立时所依据的客观情况发生重大变化，致使劳动合同无法履行，经用人单位与劳动者协商，未能就变更劳动合同内容达成协议的。&lt;/p&gt;
&lt;p&gt;也就是说如果用人单位按照以上情况主动辞退员工的时候，需要支付 N 个月的补偿金，但是必须提前三十天以书面形式通知劳动者，这实际上是为了让劳动者有一个缓冲期来找新的工作以及处理社保等内容。&lt;strong&gt;如果没有提前通知就要辞退的话，需要额外支付一个月的补偿金，也就是 N+1的来源。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>30 个你应该知道的编程技巧</title>
    <link href="https://www.hi-linux.com/posts/39135.html"/>
    <id>https://www.hi-linux.com/posts/39135.html</id>
    <published>2020-05-23T02:23:00.000Z</published>
    <updated>2020-05-23T15:09:37.248Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><blockquote><p>本文作者 Jun Wu 有着编程和统计学背景，她在 15 年前就是一名程序员。近日，她分享了给程序员的 30 条心得建议。</p></blockquote><p>如果你想成为一名程序员，这个建议可以帮助你走上正确的道路。</p><p>程序员不是一个容易的职业，每年都有许多人从国内顶尖院校的计算机科学专业毕业，这是任何人都能从事的竞争最大的职业之一。同时，编程也是令人兴奋的。随着技术的进步，工业界每天都有创新。编程对于热爱它的人来说是一项充满激情的事业。</p><p>当我 15 年前开始做程序员的时候，我希望有人能告诉我下面清单上的一切建议。这个清单可以为所有新手程序员节省大量的时间和精力，并且，你可以在编程职业发展的整个过程中都参考这些建议。即使这里面有些观点现在可能与你无关，但总有一天你会看到其中的智慧。</p><p>作为一名程序员，你正处在伟大的顶点。</p><p>你只要对自己要走的道路稍有了解就可以开始冒险了。</p><h2 id="1-你不需要学位但你需要知识">1. 你不需要学位，但你需要知识</h2><p>我和许多没有计算机科学硕士学位或计算机科学本科学位的程序员一起工作。编程是少数不依赖学位的职业之一。然而，编程是一项知识密集型的职业。如果你想开始编程生涯，这十本基础书籍你必读的。这十本书将涵盖计算机科学的基本概念以及如何在项目团队中工作。它们可以为你的技术打下坚实的基础，让你对基本概念有一个深刻的理解，并且让你有能力去编写功能性的代码，顺利进行技术面试并与同事交流。</p><h2 id="2-创造性是提高解决编程问题能力的重要因素">2. 创造性是提高解决编程问题能力的重要因素</h2><p>大多数人都有这样的认知：编程都是关于分析和解决问题的技能。这个观点并不是完全正确的，编程也非常需要创造力。通常，你可以用很多方法编写给定的代码。当你拥有了创造力，就能设计出最简单、最有效的代码。</p><h2 id="3-不要什么都学精通一部分知识">3. 不要什么都学，精通一部分知识</h2><p>编程语言有数百种。有一些编程领域有着明确的职业道路：Web 开发人员、前端开发人员、后端开发人员、软件工程师、数据库开发人员等。你需要决定要成为哪种开发人员，然后学习该职位所需的所有技术和技能。</p><h2 id="4-你不需要活的像机器人">4. 你不需要活的像机器人</h2><p>记住，你首先是一个人，其次才是程序员。当您第一次开始编程时，很容易在代码中迷失方向。有时我在完成项目的所有任务之前都不离开电脑。但是你是一个人，你需要笑，哭，减压，和人交谈。管理好你的生活，最大限度地提高工作之外的兴趣爱好，这将为程序员的工作带来更多的创造力。</p><h2 id="5-编程就是应用知识而不是为了记忆">5. 编程就是应用知识而不是为了记忆</h2><p>与研究不同，在研究中，你会发明和创造新的知识领域，但编程就是应用现有的知识。书籍、研究论文、在线文章和学习视频成为您经常使用的资源。不需要记住任何东西。你总是可以搜索资源来找到答案。随着你处理的项目越来越多，这些记忆会自动自然地出现。</p><a id="more"></a><h2 id="6-你每天都要克服自己是冒牌货的心态">6. 你每天都要克服自己是「冒牌货」的心态</h2><p>编程似乎是所有「聪明」人都倾向于做的一种职业。除非你是个天才，否则你会像我一样，每天都会怀疑自己是个冒牌货。当你每天都经历这些的时候，你往往会想出一个办法来解决这个问题。对我来说，我一直把它当做学习新事物的动力。我已经学会了站在正确的角度看待这个问题，并且满足于每天都有的一点点进步。</p><h2 id="7-你必须有程序员以外的生活否则你只会沉迷于编程">7. 你必须有程序员以外的生活，否则你只会沉迷于编程</h2><p>有时你会宅在家里。然而，要成为一个快乐的程序员，你必须主动地在电脑屏幕之外寻找生活。你事业的成功往往取决于你遇到的人。当你是一个程序员时，社交网络是必不可少的。拥有程序员以外的生活对于防止自己沉溺于编程是至关重要的。当你编程是因为激情而不是被迫的时候，你就能做出最好的工作。</p><h2 id="8-如果你和其他人共同完成一个项目你会更快地学会编程">8. 如果你和其他人共同完成一个项目，你会更快地学会编程</h2><p>在你的职业生涯刚开始的时候，你会试图把自己封闭起来，阅读关于编程的书来建立你的计算机科学基础。你猜怎么着？如果你找到一个朋友一起合作，你会学习得更快。我在和其他小伙伴合作完成一个项目的过程中看完了编程书籍。当你和其他人一起合作时，你所有的程序缺点就会暴露出来，你的代码将受到批评。你将学会编写有效的代码，因为有人在监视你。你会想找出最好的方法去做事情，因为你的朋友也在学习。当你做程序员时，总有人在审查你的代码。你永远不会独自编程，所以你需要习惯这些。</p><h2 id="9-你不需要擅长数学和科学">9. 你不需要擅长数学和科学</h2><p>在科技行业，你会遇到各种超级程序员，他们在接受了一辈子的文科教育后发现编程的逻辑思维很有吸引力。有很多画家和作家在一边追求艺术，一边做着程序员。编程是一项艰苦的工作，做一个好的程序员所需要的只是坚持，任何人都可以通过编程书籍学习基础知识。很多人在这个行业工作了一段时间后就开始学数学了。最终，这些人甚至可以理解和实现复杂的算法，尽管他们并没有接受任何形式的正式数学教育。</p><h2 id="10-你需要成为一个全明星的学习者">10. 你需要成为一个全明星的「学习者」</h2><p>程序员是一个熟练的学习者。现在你可能不是一个大师级的学习者，但你会到达那一步的。有时候你的工作会要求你在六个月内学会三种编程语言，这就是技术创新的现状。作为程序员，我们每天都在学习。对我们来说，学习就像呼吸一样自然。如果你对每天的学习感到不耐烦，你必须强迫自己去习惯这一点。</p><h2 id="11-专注于完成你的项目">11. 专注于完成你的项目</h2><p>编码是真的会上瘾。在你的编程生涯中的某个时刻，你将经历一整晚的通宵编程。在完成目标之前，你不会想睡觉的。你会忘记吃饭、喝酒，甚至忘记从办公桌上起来，因为你的大脑处理了太多的信息。没关系，在做完后，到外面散散步，度个假吧。</p><h2 id="12-你会花费整天找一个小-bug">12. 你会花费整天找一个小 Bug</h2><p>大多数时候，在一个项目中，许多部分是相互依赖的。通常，你会发现除非你修复了一个潜伏在你系统中的小 Bug，否则你无法继续前进。作为一个程序员，除非你发现这个错误，否则你会对整个项目感到有压力，你将整天坐在电脑前寻找它，在找到它之前你将在晚上梦见代码。</p><h2 id="13-你将花大部分时间搜索没有人能告诉你的答案">13. 你将花大部分时间搜索没有人能告诉你的答案</h2><p>如果你用一种流行的语言编程，你将能够找到你在网上遇到的大多数问题的答案。但是，也有例外。有时，没有人遇到过你碰到的问题。在这种情况下，参考编程书籍和在四处询问通常会为您指明正确的方向。</p><h2 id="14-你会读一本设计模式书">14. 你会读一本设计模式书</h2><p>你是否毕业于最好的计算机院校关系不大。在每一个程序员的职业生涯中，总有一段时间你会坐下来，从头到尾地阅读「 Head First Design Patterns」。对于一个新手程序员来说，这可能是阅读得最多的书之一。那么，你还在等什么？把它捡起来，从头读到尾。</p><h2 id="15-你将学会专注于准确的拼写">15. 你将学会专注于准确的拼写</h2><p>在每一个程序员职业生涯中的某个时刻，您将用您最喜欢的语言编写了足够的代码，以便按照自己想要的方式来做事情。这包括变量、类甚至数据库中的表按照你自己的命名约定进行准确的编写。你将对此进行彻底的审查。你最不想看到的是一些因为你拼写错误而出现的 Bug。记住，如果理由足够，那么请专注于一件事情。但当你没有很好的理由而去做某件事，这可能只是重复性的行为。</p><h2 id="16-你会放弃">16. 你会放弃</h2><p>我放弃了多少次？我已经数不清了。有时你会碰到你无法解决的问题，有时候你会因为困难而想停止，有时候工作环境会让你想辞职。你的激情取决于你的坚持，这些正是考验你的时候。是留下还是离开？我每次都留下来了。有时，在几年没有写一行代码之后，我会作为一个准备好完成一个项目的新人回来。当你知道你热爱你的工作时，它会变成一个家，你会愿意为之冒险。</p><h2 id="17-重启你自己">17. 重启你自己</h2><p>如果你相信更高的力量，你可能会需要这个建议。我看到过很多人重新开始编程，通常他们都是因为热爱，与钱无关。当你看到一个人像你以前一样对编程乐在其中时，你是嫉妒的，你觉得你也不能放弃编码。然后，突然间，你又回到了一个项目中。你知道，在你的内心深处，你的生活和呼吸都离不开代码。这就是你知道自己是一个真正程序员的时刻。</p><h2 id="18-你将回到某种形式的学校学习正确的做事方式">18. 你将回到某种形式的「学校」学习「正确」的做事方式</h2><p>即使是从精英计算机科学专业硕士毕业的最好的程序员也会在工作后继续学习。事实上，在职培训是在大型科技公司工作的最佳福利之一。公司会给你提供「昂贵」的课程和研讨会，让你了解他们希望你使用的最新技术。如果可能，你在工作中学到的知识是不够的，你将参加许多在线编码学院，查看 YouTube 视频来提高你的技能。</p><h2 id="19-你将被一个你不想为之工作的人雇用">19. 你将被一个你不想为之工作的人雇用</h2><p>即使你是一个平庸的程序员，某些公司也会需要你的技能。当他们面试你时，请记住你也在面试他们。由于公司的文化，你可能会发现自己想对一个轻松的 offer 说「不」。作为一名程序员，你将工作很长时间，因此，找到一个文化和你契合的公司文化至关重要。愉快的心情能让你更好地工作。如果你的技能合适，其他公司也会来敲你的门，除非有必要，请不要随意跳槽。</p><h2 id="20-你会在技术面试中失败">20. 你会在技术面试中失败</h2><p>技术面试不是开玩笑。高级程序员经常为了好玩而编造技术面试问题。通常，由于某种原因，这些问题是非常困难的。如果你没有通过技术面试，那并不是世界末日，它并不能证明你没有编程能力，它只是在测试你的知识库，试着往好的方面看。如果你的人际交往能力出众，经理们会记住你的。如果他们喜欢你，而你不适合这个职位，他们可能还会打电话给你另一个职位。</p><h2 id="21-你会被告知你很棒">21. 你会被告知你很棒</h2><p>在你的职业生涯中，有时你会觉得自己是明星。依赖于你完成项目的经理会为了激励你，会告诉你特别伟大。你会觉得自己在世界的顶端。记住，保持脚踏实地。总是有新技术需要探索，总是有比你更好的新程序员。</p><h2 id="22-你会被告知你什么都不知道">22. 你会被告知你什么都不知道</h2><p>在你的职业生涯中，有时你会觉得自己什么都不知道。对某个项目感到沮丧的人会告诉你你什么都不知道。也许他们这样做是为了让你安顿下来。但是，你完全不应该否定自己。因为你知道的可能比你想象的要多得多。每过一天，你就会知道得比前一天多一点。一年后，人们会尊敬你的。请继续努力，一段时间之后，你甚至可能得到那个告诉你你什么都不知道的人的尊重。</p><h2 id="23-你会想和其他你钦佩的程序员竞争">23. 你会想和其他你钦佩的程序员竞争</h2><p>编程最棒的方面之一就是竞争。我喜欢和我崇拜的人一起编程。当你能编写一段让你欣赏的程序员肯定的代码时，你会像刚刚中了彩票一样开心。编程中的竞争是很有趣的，它并不是比谁最好，更多的是互相学习。</p><h2 id="24-你不明白你的同事刚刚说的话">24. 你不明白你的同事刚刚说的话</h2><p>在最开始，这可能每周或每月发生一次。在你的新编程工作中，你会不理解你的同事刚刚说的话。这可能有两个原因。一个可能的原因是，你就是无法理解他们的口音。在这种情况下，可以请另一个同事翻译。不能听懂别人的话并不羞耻，很可能其他同事也花了很多年才习惯这种口音。另一个原因是，你的同事刚刚说的话完全超出了你的想象。但这也没关系，毕竟，你的同事是专家。摆好椅子，请你的同事以图片的形式解释这一切。很可能，你需要一段时间去适应。</p><h2 id="25-看到去年写的乱七八糟的代码你会感到羞愧">25. 看到去年写的乱七八糟的代码你会感到羞愧</h2><p>这也是经常发生的。在最开始，我也因为代码不规范受到过批评。当时，设计很好且有着良好文档，但我是用一种难以阅读的语言写的。但直到现在，不管我多么努力，每年我仍然会找到一些乱七八糟的代码，这通常都是因为我想很快地完成工作。实际上这就是程序员的工作，我们不停地完善和修改各种代码。这并不羞耻。当你意识到它们是你写的的时候，后退一步，如果可以的话，好好地修改它。</p><h2 id="26-当你厌倦看代码时你将在你的数据库项目中躲避">26. 当你厌倦看代码时，你将在你的数据库项目中躲避</h2><p>当你在进行一次愉快的编程之旅时，可能会发生这种情况。你已经连续工作两个月了，你需要休息一下。但你喜欢这种当时的状态，所以你继续前进。然后您会发现 SQL 很有趣。你不明白为什么你看不进去一行代码。但不知何故，将数据放入数据库并将其取出，是一件令人愉快的事情。你陶醉于这种完全符合逻辑的简单语言。</p><h2 id="27-你对黑客又爱又恨">27. 你对黑客又爱又恨</h2><p>黑客攻击现在很常见。程序员在团队中互相竞争，在这个过程中，好几个小时你都在高度紧张地学习。此时的黑客攻击就像调味剂一样，你可能会非常喜欢。但有时，你会讨厌在高速敲键盘时被打断。你也会讨厌拥挤的办公室和喧嚣的活动。</p><h2 id="28-在阅读研究论文时你会认为你一个单词都看不懂">28. 在阅读研究论文时，你会认为你一个单词都看不懂</h2><p>你会说英语吗？好吧，大多数人的回答都是肯定的。但是，我向你保证，有时你会一遍又一遍地读一些研究论文，并意识到自己完全无法理解它们。对我来说，在我学会大学数学的课程之前，大多数关于算法的研究论文都像是没有意义的森林。然后，突然某一天，一切似乎都有了意义。</p><h2 id="29-你要买耳机">29. 你要买耳机</h2><p>在你的职业生涯中的某个时刻，当你全神贯注于你的代码时，你会意识到任何一种噪音都会阻碍你的感官。一个好的耳机可以消除外部噪音，这样在拥挤的办公室里你也会隔绝外部干扰。在某些时候，你也会发现听音乐可以帮助你编码。在我编码生涯的早期，我发现音乐的节奏有助于我流畅地编码。即使现在，我也会借助一些音乐来提高自己的生产力。</p><h2 id="30-你将去一个新的地方如果幸运的话它将是拉斯维加斯">30. 你将去一个新的地方，如果幸运的话，它将是拉斯维加斯</h2><p>在你职业生涯中的某个阶段，你会成为对公司非常重要的核心开发人员。这时，你可能会被邀请到异地和其它技术人员进行交流。高层管理人员可能会利用这个机会了解你。请别误会，这并不代表着你可以无忧无虑地喝醉酒了，而是你和你的同龄人交往和交流的好机会。如果你幸运的话，活动将会在拉斯维加斯。有时，还会有其他公司的技术专家来参加这些活动。</p><blockquote><p>来源：雷锋网</p><p>原文：<a href="http://t.cn/AiY7TQ9g" target="_blank" rel="noopener">http://t.cn/AiY7TQ9g</a></p><p>译文：<a href="http://t.cn/AiY7T3uX" target="_blank" rel="noopener">http://t.cn/AiY7T3uX</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文作者 Jun Wu 有着编程和统计学背景，她在 15 年前就是一名程序员。近日，她分享了给程序员的 30 条心得建议。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果你想成为一名程序员，这个建议可以帮助你走上正确的道路。&lt;/p&gt;
&lt;p&gt;程序员不是一个容易的职业，每年都有许多人从国内顶尖院校的计算机科学专业毕业，这是任何人都能从事的竞争最大的职业之一。同时，编程也是令人兴奋的。随着技术的进步，工业界每天都有创新。编程对于热爱它的人来说是一项充满激情的事业。&lt;/p&gt;
&lt;p&gt;当我 15 年前开始做程序员的时候，我希望有人能告诉我下面清单上的一切建议。这个清单可以为所有新手程序员节省大量的时间和精力，并且，你可以在编程职业发展的整个过程中都参考这些建议。即使这里面有些观点现在可能与你无关，但总有一天你会看到其中的智慧。&lt;/p&gt;
&lt;p&gt;作为一名程序员，你正处在伟大的顶点。&lt;/p&gt;
&lt;p&gt;你只要对自己要走的道路稍有了解就可以开始冒险了。&lt;/p&gt;
&lt;h2 id=&quot;1-你不需要学位，但你需要知识&quot;&gt;1. 你不需要学位，但你需要知识&lt;/h2&gt;
&lt;p&gt;我和许多没有计算机科学硕士学位或计算机科学本科学位的程序员一起工作。编程是少数不依赖学位的职业之一。然而，编程是一项知识密集型的职业。如果你想开始编程生涯，这十本基础书籍你必读的。这十本书将涵盖计算机科学的基本概念以及如何在项目团队中工作。它们可以为你的技术打下坚实的基础，让你对基本概念有一个深刻的理解，并且让你有能力去编写功能性的代码，顺利进行技术面试并与同事交流。&lt;/p&gt;
&lt;h2 id=&quot;2-创造性是提高解决编程问题能力的重要因素&quot;&gt;2. 创造性是提高解决编程问题能力的重要因素&lt;/h2&gt;
&lt;p&gt;大多数人都有这样的认知：编程都是关于分析和解决问题的技能。这个观点并不是完全正确的，编程也非常需要创造力。通常，你可以用很多方法编写给定的代码。当你拥有了创造力，就能设计出最简单、最有效的代码。&lt;/p&gt;
&lt;h2 id=&quot;3-不要什么都学，精通一部分知识&quot;&gt;3. 不要什么都学，精通一部分知识&lt;/h2&gt;
&lt;p&gt;编程语言有数百种。有一些编程领域有着明确的职业道路：Web 开发人员、前端开发人员、后端开发人员、软件工程师、数据库开发人员等。你需要决定要成为哪种开发人员，然后学习该职位所需的所有技术和技能。&lt;/p&gt;
&lt;h2 id=&quot;4-你不需要活的像机器人&quot;&gt;4. 你不需要活的像机器人&lt;/h2&gt;
&lt;p&gt;记住，你首先是一个人，其次才是程序员。当您第一次开始编程时，很容易在代码中迷失方向。有时我在完成项目的所有任务之前都不离开电脑。但是你是一个人，你需要笑，哭，减压，和人交谈。管理好你的生活，最大限度地提高工作之外的兴趣爱好，这将为程序员的工作带来更多的创造力。&lt;/p&gt;
&lt;h2 id=&quot;5-编程就是应用知识而不是为了记忆&quot;&gt;5. 编程就是应用知识而不是为了记忆&lt;/h2&gt;
&lt;p&gt;与研究不同，在研究中，你会发明和创造新的知识领域，但编程就是应用现有的知识。书籍、研究论文、在线文章和学习视频成为您经常使用的资源。不需要记住任何东西。你总是可以搜索资源来找到答案。随着你处理的项目越来越多，这些记忆会自动自然地出现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="编程" scheme="https://www.hi-linux.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>35 岁后的互联网人应该怎么办？</title>
    <link href="https://www.hi-linux.com/posts/1977.html"/>
    <id>https://www.hi-linux.com/posts/1977.html</id>
    <published>2020-05-23T02:22:00.000Z</published>
    <updated>2020-05-23T15:07:35.788Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>华为、腾讯、京东、阿里都曾被爆出类似「优化中年基层管理者」的新闻，面对「被倒挂」与「被优化」的危机，互联网行业从业者应该如何「自如的面对」？</p><p>这里给大家分享一个知乎上的高赞答案，共勉！</p><blockquote><p>几年前见到类似的说法，这个数字还是 30 岁。估计再过几年，这个数字会变成 40 岁。</p><p>其实长期来看，大家都会习惯，互联网和其他各个行业一样，所有行业存在的问题，互联网行业都会存在。</p><p>什么是危机？感觉周围的人都在危机，甚至包括一些财富、地位都已经很高的人，仍然逃不过焦虑。似乎焦虑就是自然而然的，伴随着每个人的成长。焦虑多了，就开始危机了。</p><p>我想在这里持续写一些感想，可能对各年龄段的朋友都有一些帮助。其实很多人真到这个年龄，见识和能力都已经很厉害了，我帮忙总结一下。</p><p>前段时间有好朋友和我说，感觉随着年龄增长，会有焦虑。因为年龄越大，会发现技能上面并没有比年轻人高太多，体力和精力可能还要差一些。这样的问题迟早大家都会遇到，无论是在职场中工作了很久，还是刚入职场，有些事实，业务应该早一些了解。</p></blockquote><a id="more"></a><p>分享一下我自己的观察和思考，对于所有年龄在增加的企业里的中层，以及未来要成为中层的大家。</p><p><strong>1. 永远贴近业务</strong></p><p>在工作中你会面临一些微妙的选择，是纯做管理，搭团队管人，还是更贴近业务。这两者往往不互斥，但是很多人会不自觉的偏向前者。所以经常看到一些朋友的焦虑，虽然纯做管理相对要轻松一点点（很多时候也未必有多轻松），但是自己的那把剑容易钝。贴近业务是很考验人的，也很累，但是能够让自己始终在一个好的节奏上。</p><p><strong>2. 注意警惕自己的体制耦合度</strong></p><p>所谓体制，在各种地方都存在。比如你在一家大公司里工作，你会发现很多时间其实在处理部门与部门之间的协调、沟通工作，这个比例不低。你在这里的时间越久，越是熟门熟路，知道该从哪些部门争取资源，如何搞定各种各样的关系。但是反过来，你也会让你的体制耦合度不断增加。等某一天你到了另一个地方，会发现自己原本得心应手的工作，对于新的工作价值不大。</p><p><strong>3. 平台能力不是个人能力</strong></p><p>在一个平台上，这个平台会让你具备很多力量。需要明白这些力量未必是自己的能力。你在一个好的平台上能够使用的资源，可能到了另一个相对小的平台上，就用不起来了，这时候自己真实的短板就出来了。我见过一些在大企业工作的朋友，在创业公司时很痛苦，因为感觉自己很多地方都是心有余而力不足。最简单的，招聘工作，你都会发现，原本大平台的品牌背书很强，而现在你的资源要少很多，但是还得做事情。需要持续提升自己的能力，不要被眼前被加成的能力蒙蔽。</p><p><strong>4. 扎扎实实积累资源</strong></p><p>很多人不理解资源的含义，以为认识一些人就是资源。其实你得成为一个网络里的节点，不能是单向的，得是双向的。我见过一些人动不动说和这个人熟那个人熟，什么叫熟呢？如果你请人帮忙，如果你需要找人合作，人家能否信任你？你做过什么事情、有什么积累值得对方信任？这是从内到外的积累，不取决于能说会道，长袖善舞。</p><p><strong>5. 成为网络中的节点</strong></p><p>专业技能是一方面，对于很多人的工作，到一定阶段会发现除了专业技能，年龄的优势在于你能「搞定事情」。这样搞定事情一方面是你能够带领团队搞定，另一方面是能够协调外部各种资源搞定。而且，这种力量不应该完全依赖于你在哪一家公司、哪个职位上工作。比如你们要做一个产品、一个项目，需要各种资源，或者某一天你想找工作，除了猎头外，是不是如果有其他朋友帮你介绍、背书，效果来的更好？你得成为一个网络中的一部分。狭义的说这个网络就是圈子，但是更广义的来说，各种各样的信息网络、协作网络，都是你需要的网络。你要成为这个网络中的节点。</p><p><strong>6. 熟人之间降低交易成</strong></p><p>本熟人可能是朋友，可能是合作伙伴等等，熟人之间做事情，可以降低交易成本（或者说合作成本等等）。长期来说，你需要尽可能降低交易交易成本，让大家能够快速达成共识。这需要你自己重视口碑，作为网络的节点，获得其他节点的背书。为什么别人会信任你？因为你靠谱，或者其他靠谱的人认为你靠谱，所以大家就信了。太侧重短期利益，往往会提升自己这个节点长期的交易成本。</p><p><strong>7. 注重复利型的积累机会</strong></p><p>「复利是指一笔资金除本金产生利息外，在下一个计息周期内，以前各计息周期内产生的利息也计算利息的计息方法。」也就是说，利能生利。有一些机会，你不断往下做的时候，以往的积累，能够成为未来新的资本基础，而不是过去就过去了。这样的机会可能是你的工作本身，也可能是一些小的工作，或者就是业余爱好。例如在网上分享知识和专业经验，往往都是我在各种碎片时间完成的，持续了很多年，这样的事情就产生了复利，做各种事情，都能用在这样的基础上，有更多的人愿意支持。当我做知群的时候，已经自然有一批朋友愿意支持，包括很多公司的高管都愿意提供资源。复利能够让我们做的事情不断增强，时间变成了朋友。</p><p><strong>8. 讲原则与结善缘</strong></p><p>首先在公司里工作，要做好事情，讲原则，这是基础。在这个基础之上，在行业里能够顺手帮忙的，尽量能够帮忙，这是结善缘。因为很多时候你也不知道未来会如何。可能今天别人是找你帮忙，过两年，就变成你要找别人帮忙了。有些人没有意识到这一点，认为自己今天的积累已经足够，但其实如前面所说，很多时候是公司和平台的能力，而不是个人的能力。在这种认识下，一些人甚至会有意为难、做一些损人未必利己的事情，现在可能还觉得挺好，某一天就会吃亏。当然这里有个最基本的点，就是要有原则，在为公司、产品做好事情的前提下去结善缘。</p><p><strong>9. 要获得帮助的时候，多想想如何对等</strong></p><p>以前有一位好友做的很好，他在和其他公司合作的时候，总会说，在这个合作里我们有很多好处，但是不能让对方吃亏，也得多想想如何能够帮到对方。这和前一点结善缘类似，需要强调的是不要短时，每次都只以自己为出点。总是自己有好处才上，总想让别人能帮到自己，给人感觉目的性太强，但是又是单向的。这样下来，很难有持续的积累。其实会发现类似的积累，在某一天都能够反过来帮到自己。</p><p><strong>10. 避免高估自己的专业或者职业</strong></p><p>需要清楚公司真正的核心是什么。很多人会说某某公司是技术驱动的、很多公司是产品驱动的，等等。往往做专业工作的人，容易陷入到一个固定的视角里，认为自己的专业非常重要。做技术的觉得技术最重要，做产品的觉得产品经理最重要，做设计的觉得设计师最重要，等等，其实大家都是整个公司的一个环节。驱动公司前进的，往往是一些更底层的商业驱动力。正确看待自己在公司里的作用和位置，积累在这个方面的能力和资源，并继续核心业务，提升自己。</p><p><strong>11. 分的清时和势对自己的影响</strong></p><p>很多人容易高估自己的能力，而低估时和势对自己的帮助，以至于做职业的决策时产生偏差。有一次和一个兄弟，拉勾的创始人马德龙一起反思，有一个很好的问题：到底是我们在成就这个时代，还是这个时代在成就我们？很多人认为自己做的好是因为自己能力强，但是这是全部原因么？其实很多人是因为在正确的时间点跟上了正确的趋势，或者进入了正确的公司。当然能力肯定不会差，但是要明白很多加成其实来自时和势。如果今天再重复一遍以往做的事，还会如之前一样顺利么？未必。所以有空正确认识这一点。一方面，寻找时和势，让自己顺流而上，另一方面，避免判断错误的时和势，认为参考以往，自己的能力已经足以驾驭。该保守估计的时候要保守，不要因为自己以前能做得好，就认为自己今天一定能做得好。</p><p><strong>12. 找到一些机会，往往是概率事件</strong></p><p>张颖有一次给我们分享了他的早期经历，挺值得借鉴。在投行工作时突然整个机构遇到问题，他被裁员了。面临着巨大的压力，在两个星期的时间，投出了两千份简历，最终他拿到了一个 Offer，后来一路成了投资圈的佼佼者。这里的重点，是两千份简历，拿到一个 Offer，这就足够了。这就是个概率事件，你不需要到处受欢迎，你又不是人民币，你只需要一个机会就足够了。</p><p><strong>13. 设定合理的期望值</strong></p><p>自己的下属现在比自己做的好？曾经认为不如自己的人现在成长速度更快？接受这一点，对自己更好。有朋友动辄就是谁谁谁以前是我的下属，我应该如何如何，言语中总觉得自己高人一等。其实，很多时候只是时间上比人家早一点而已，总有一些人成长速度非常快，把自己放的位置太高，一方面不利于外部的合作，毕竟大家都成长到一定程度了，干嘛要觉得自己比人高？另一方面也给自己太大压力，在后续的求职等等过程中，徒增困扰。</p><p><strong>14. 在核心业务的基础上扩展自己的能力边界</strong></p><p>我自己做过设计师、产品经理、用户增长和市场，所以有时会在不同的圈子里和一些朋友交流。比如一些设计圈里非常资深的朋友，基本上是在各大公司设计这个领域已经做到最高的位置上了，然后聊天的时候会聊些什么呢？不太会聊通常意义上的设计，这些已经默认你能够做好、搞定，或者你能做招到人去做好。大家经常感兴趣的，是听我聊聊线上的用户应该怎么获取、整个大的流量趋势是什么样的、流量的成本结构、如何低成本的推动增长等等。这些话题未必是这个职位的人现在直接负责的，但是为什么大家感兴趣？因为未来很可能用的到。围绕着核心业务，总是有很多机会可以挖掘，而这些机会往往需要的能力是复合型的，越是往前走，越是需要融会贯通。当然一门心思钻一个深的专业领域，同样也可以，只是存在的风险是有可能领域本身不存在了。这在做技术的人当中非常典型。对于大多数人，扩展自己的能力边界，是个好的选择。基于核心业务来有意识的扩展自己的能力边界，很可能今天的收益不是特别明显，但是到了未来某个时候，就会成为你新的竞争力。</p><p><strong>15.你的人未必是你的人</strong></p><p>一位在大公司做中层的朋友说，我出来可以带一个团队出来。其实大部分时候，很可能带不出来几个人。大家聚在一起，是因为有这个平台作为纽带。人可能是你招的、带的，但是当时人家看重的不仅仅是你，还有这个平台。明白这一点，不要产生错误的认识。如前面所说，大多数时候，我们的能力是建构在平台基础之上的。</p><p><strong>16. 保持危机感</strong></p><p>重点是针对 IT 和互联网行业的朋友，这个行业最大的特点就是变化。曾经在甲骨文工作是非常好的事，我有朋友聊起来，说他们在美国每次都感觉甲骨文是很舒服的公司，本身也很赚钱，员工的工作和生活也平衡的很好，听起来很理想，这样的公司是能够工作一辈子的地方。但是现实是残酷的，甲骨文也开始裁员，尽管有补偿，但是很多人都会面临巨大的挑战。其实从一开始就要有这个意识，在这个快速变化的领域，每个人都不可避免的会被这些变化裹挟其中。危机感是客观存在的，早点认识到这一点，在心态上做好准备，比有一天危机突然来临要好。正确认识了危机感，才能有动力让自己不断积累，有动力如这篇文章里其他各个点里提到的那样去做。</p><p><strong>互联网寒冬的当下，你还过得好吗？欢迎大家留言讨论！</strong></p><blockquote><p>本文转载自：「知乎」，原文：<a href="https://url.cn/5Edu7wT%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5Edu7wT，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;华为、腾讯、京东、阿里都曾被爆出类似「优化中年基层管理者」的新闻，面对「被倒挂」与「被优化」的危机，互联网行业从业者应该如何「自如的面对」？&lt;/p&gt;
&lt;p&gt;这里给大家分享一个知乎上的高赞答案，共勉！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;几年前见到类似的说法，这个数字还是 30 岁。估计再过几年，这个数字会变成 40 岁。&lt;/p&gt;
&lt;p&gt;其实长期来看，大家都会习惯，互联网和其他各个行业一样，所有行业存在的问题，互联网行业都会存在。&lt;/p&gt;
&lt;p&gt;什么是危机？感觉周围的人都在危机，甚至包括一些财富、地位都已经很高的人，仍然逃不过焦虑。似乎焦虑就是自然而然的，伴随着每个人的成长。焦虑多了，就开始危机了。&lt;/p&gt;
&lt;p&gt;我想在这里持续写一些感想，可能对各年龄段的朋友都有一些帮助。其实很多人真到这个年龄，见识和能力都已经很厉害了，我帮忙总结一下。&lt;/p&gt;
&lt;p&gt;前段时间有好朋友和我说，感觉随着年龄增长，会有焦虑。因为年龄越大，会发现技能上面并没有比年轻人高太多，体力和精力可能还要差一些。这样的问题迟早大家都会遇到，无论是在职场中工作了很久，还是刚入职场，有些事实，业务应该早一些了解。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="思想" scheme="https://www.hi-linux.com/tags/%E6%80%9D%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>技术驱动型公司是假命题吗？</title>
    <link href="https://www.hi-linux.com/posts/23923.html"/>
    <id>https://www.hi-linux.com/posts/23923.html</id>
    <published>2020-05-23T02:21:00.000Z</published>
    <updated>2020-05-23T15:02:04.589Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="世界上没有技术驱动型公司">世界上没有技术驱动型公司</h2><p>世界上没有技术驱动型公司，不论 Google、Facebook，还是腾讯、阿里，都不是技术驱动型公司。<strong>因为技术不是源头，需求才是。</strong></p><p>因此一切技术问题，都要服从产品交付和市场反馈。所以，任何公司都不可能以技术去驱动自身。人可以以技术驱动自己进步，但公司不行。</p><p><strong>一家公司可以以技术切入某个市场，但如果它想生存下去，就一定不能以技术为导向，坚持以技术为导向的公司的生命力为零，其下场有两个：破产或者在破产之前被收购。</strong></p><p>如果你真的很痴迷钻研技术，请读研读博最后留校，或者进研究院让国家用纳税人的钱养你。</p><h2 id="每个人都得加班">每个人都得加班</h2><p>资本富集的地方，人都得加班，加班的本质，是人跟着机器跑、人跟着钱跑。</p><p>更为本质地说，资本富集的地方，人作为劳动力，也是资本的一种。<strong>即人是资本而不是人本身。</strong></p><p>资本的运转是不能停的，因为停一下损失的钱太多了，中国和外国都一样。</p><p>知道发达国家为什么产业工人不加班吗？因为制造业已经不是这些国家主要创造财富的领域了。</p><p>发达国家资本富集的地方是金融行业，所以西方国家的金融狗一样加班。</p><p>劳动法？加班费？都不存在的。劳动法和加班费只有在资本离开这个市场后才能给你保证。</p><p>一般公司的策略是：付给你高于其他行业的薪水、换取你 “自愿” 加班。不想加班的同学们，你们可以去考公务员或者去欧洲做IT，我保证你不加班、不但不用加班，你甚至会很闲。</p><a id="more"></a><h2 id="先想后写">先想后写</h2><p>IT 是工科，不是理科，和 IT 行业相似度最高的行业是盖楼房。真的，相似度相当惊人。</p><p>IT 领域最重要的是经验，而不是你有多聪明，不聪明的人，或者更准确地说，不适合做这个行业的人，大学毕业后就改行了。</p><p>记住：你做得好不好，不取决于你是否聪明，而取决于你是否愿意不断读书、不断学习和不断积累。因此，如果你打算投身这个行业，还在学校的话就请抓紧一切时间多读书。</p><p>公司是你创造财富的地方，公司不是学校。你可以在工作中学习，但你不能放下工作然后去学习，除非你的工作已经做完了。</p><p><strong>能大规模商用的技术，都不需要智商，否则这种技术就不可能规模化。某些程序员们，请停止你们的蜜汁自信。</strong></p><p>技术栈，一旦确立了，就很难改了。一个技术人员是如此，一家公司也是如此。根本原因是：每一个栈的 Size 都太深了，就像是 <strong>ulimit -s unlimited</strong> 过一样。</p><p><strong>一个程序员，应该花 80% 的时间做代码设计、画 UML 图、画时序图，20% 的时间写 Code 和 Debug，菜鸟程序员的这个比例恰好是反的。</strong></p><p>一句话，不论这个需求有多紧急，你都一定要 “想好再动手”。“想好” 的标志就是设计文档写好了，文档一旦写好，写代码就是纯粹的无脑工作。</p><p>写文档的目的是让你在 Code 的时候，不需要停下来思考，更不需要推倒重来。如果没有文档也可以做到这一点，你当然可以不写文档，同时思考下自己水平这么高是不是可以要求升职加薪了。</p><p>或者，你是不是在做无聊的 if else 编码工作？</p><h2 id="关注软技能">关注软技能</h2><p>英语，很重要。能否使用英语查阅资料，是区分技术人员水平的重要指示之一。<strong>寄希望于 “有人迟早会翻译成中文” 的人是愚蠢的、是会被淘汰的。</strong></p><p><strong>要有分享精神，不要担心你知道的东西告诉别人后你就没价值了。你最大的价值在于你知道那些东西的过程，而不是那些东西本身。</strong></p><p>你愿意和别人分享，别人自然也会愿意和你分享，最终达到 1+1 大于 2 的效果。</p><p>不分享，就像一个失去了互联网的程序员，试问他还能创造多少价值？恐怕他连日常工作都无法展开了。</p><p>持有 “我把别人知道的都学会，把自己知道的都藏起来，别让别人学去” 想法的人，其实是默认全世界只有你聪明别人都是傻瓜，这样的人，在信息传输成本高的时代，可以活下去，但是在今天这个时代，他们的路会越走越窄，最后会自己走入死胡同。</p><p>当然，如果你真的知道了了不得的黑科技，那就请你保护好自己的知识产权，然后自己开公司玩吧。</p><h2 id="工作要有热情">工作要有热情</h2><p>智商决定你的起点，情商决定你能走多远爬多高。混职场，靠的是情商。</p><p>情商高就是：别人愿意和你一起工作、你有问题的时候别人愿意帮你。智商有时候可以稍微弥补一下情商，但不起决定性的作用。</p><p>现代管理学的精髓，就是让每个人（包括老板本人）都变得可替代。如果你觉得自己不可替代，要么是你的错觉，要么是你在一家管理非常原始的、摇摇欲坠马上要完蛋的公司。</p><h2 id="写好文档">写好文档</h2><p><strong>怎样让程序员变得可替代？三个字：写文档。</strong></p><p>不愿意写文档的程序员，应该立刻马上毫不犹豫地开掉。程序员工作创造的价值，至少一半是通过文档体现出来才对。</p><p>“一个项目换一个人就要让项目大地震一下”，“解决 Bug 换一个人就不行，因为只有老人知道要改哪一行的哪个关键字” 。这不说明这个项目所涉及的技术有多复杂、不说明这个老人是什么技术大牛，而只说明这个项目的项目经理很蠢，这个项目已经失控了。</p><p>文档不是事无巨细的流水账，写文档以及组织文档是需要智商的、是需要架构师去设计的。</p><p>美国的航天飞机那么复杂，但是在 Pilot 手里的手册也就那么多，而这个手册可以在航天飞机出问题的时候协助 Pilot 快速定位绝大多数问题。</p><p><strong>不可替代的打工者只有一种：以中高层领导的身份跟完了一个项目，而且这个项目正处于大红大紫的阶段，公司为了防止你跳槽到竞争对手那里，愿意付给你薪水，养着你天天在办公室喝茶。只要项目一直红着，公司就愿意一直养着你。</strong></p><h2 id="开发人员的文档的作用">开发人员的文档的作用</h2><p>给正在 Code 的自己看、给几个月后已经忘记这个模块当初是怎么开发的自己看、给要接手自己工作的新人看、给周边有关联开发任务的同事看、给领导等有关人员看，这是产品出 Bug 的时候用来和别人怼的武器。</p><p>如果没有文档，这些工作量都会成倍增长。</p><p>代码再精简再直观，也不可能有人类语言直观，谁觉得自己厉害到读代码和读人类语言写的文档速度一样快，那我给你一个我上大学时候写的小程序，麻烦你读一下代码，看看你多长时间可以看明白。</p><blockquote><p>项目地址：<a href="https://github.com/YvesZHI/FallingCode" target="_blank" rel="noopener">https://github.com/YvesZHI/FallingCode</a></p></blockquote><p>这段代码本身并不复杂，应该说非常简单，但是没有文档……读读看吧。</p><p>简而言之，文档，就像盖楼房的设计图，没有图纸，你是不能开始搬砖的。</p><p>领导有没有给你看需求分析文档？有没有拿着需求分析文档给你宣讲你要做什么？没有？不干活。</p><p>测试的同事有没有给你看测试用例文档？有没有给你宣讲？没有？不干活。</p><p>你自己明白领导的意图了吗？明白测试同事的意图了吗？想明白后，开始想自己要开发的模块里的各个功能模块之间的关系，可以画时序图。</p><p>时序图画完了，看看是否有（可能）频繁变化的模块/需求，如果有，请务必使用一些设计模式，如果要用设计模式，请务必画 UML 类图，如果没有频繁变化的模块/需求，请一定不要用设计模式。</p><p>最后，看看在一个功能模块中，有没有逻辑比较复杂的地方，如果有，请画流程图。</p><p>模块和模块之间有没有需要明确的协议？如果有，请把协议写出来。</p><p>上面这一段话，就是你要写的文档，这个文档的读者主要是你，在你的模块出问题之前，别人通常不会读这个文档（不排除你的领导会要求看你这个文档）。</p><p>如果你既不需要时序图又不需要类图又没什么协议需要明确，那么，你就可以不写这个文档。另外，如果这个文档写得好，你的代码是不需要任何注释的。</p><h2 id="技术驱动">技术驱动</h2><p><strong>如果一家公司打着 “我们是技术驱动型公司” 的名号在招人，我劝你一定要想好考察好，再决定是否去这家公司。</strong></p><p>为什么呢？因为我知道他的那句 “技术驱动” 很吸引你，<strong>你想学东西，但是对小公司来说，它最大的任务是活下去，然后才是其他。</strong></p><p>我不是说小公司学不到东西，我只是说小公司很难很难做到真正的技术驱动。</p><p>有人坚持认为微软这种公司是技术驱动，但微软从没大张旗鼓地说自己是 “技术驱动” 公司，并以此忽悠新人。</p><p>以华为为例：华为成功的内在原因，早就敲锣打鼓地告诉全世界了：<strong>以客户为中心，以奋斗者为本，长期艰苦奋斗，坚持自我批判。</strong></p><p>这四句话，没一句是直接和技术相关的。</p><p>这里我先特别声明一下，我不是说，技术人员在华为就不会搞技术、不会提升自己的技术水平、华为的技术水平差。我绝不是这个意思。</p><p>华为的技术，不需要我多说，全世界的人都是有目共睹的，华为公司的技术专利数就摆在那里，那是谁也抹杀不了的，华为公司里的技术大牛多了去了。</p><p>但在这里，我要说的还是第一段的意思：一个人可以以技术驱动，但一家公司不行。</p><p>华为公司的核心理念，本质就是 “成就客户”，你把客户成就了，你就把自己成就了，华为不是先成就自己再去成就客户的公司。</p><p>你去华为工作，你可以以技术驱动自己，但华为不能这样做。</p><p>这一点和微软与 IBM 的合作极其相似：IBM 说，你们微软现在搞的东西我愿意用，但是我需要你们给我搞个操作系统，这样我们才能继续合作。</p><p>然后微软怎么做的呢？它马上购买了另外一家公司搞的 DOS 操作系统，然后直接授权给 IBM 使用。</p><p>这里面有四个问题值得思考：</p><ol><li>为什么那家开发 DOS 的公司没能直接和 IBM 合作？</li><li>微软购买 DOS 系统的钱哪里来的？</li><li>微软为什么不自己开发操作系统？</li><li>技术在前三个问题中的角色和作用是什么？</li></ol><p>至于有人说 Intel 是技术驱动公司，我建议大家可以去了解一下 Intel 为什么放弃了手机市场：重点关注 Intel 决定放弃手机市场的原因，你就会发现，这个原因的本质，就是一种技术情节的产物。</p><p>Intel 放弃手机市场与华为决定进军手机市场是截然不同的。华为本来是做基站、路由器和交换机的，这是它的主营业务。</p><p>那么华为为什么决定进入手机市场？是什么原因驱使华为在没有任何技术积累的前提下进入手机市场？以至于最初华为的手机被华为员工戏称为 “暖手宝”，倒贴钱都没人愿意用，而现在却如此成功？</p><p><strong>所以，我还是那个观点：世界上没有技术驱动型公司。</strong></p><p>我本人就是程序员，我一直都以技术在驱动自己，努力提升自己的技术水平。但是我还是要说：世界上没有技术驱动型公司。</p><p>一个新的 Team  要开发一款软件，它首先要解决的问题，是在产品 1.0 开发出来并且赚到钱之前这个 Team 的经费。</p><p>其次，它要提前找好产品的客户群和可能存在的销售渠道，并且做完相应的工作。</p><p>再次，它要做产品规划，如什么时候出 1.0 版本的产品、哪个模块开发大概要多久、什么类型的问题可以暂时搁置、什么类型的问题不能搁置、要组织公关组公关等（全是项目管理相关内容，和技术没有直接关系）。</p><p>最后，进入产品开发阶段。一旦进入产品开发，就像工厂的流水线一样，是不可能出现什么导致产品开发进行不下去的技术难点的（否则技术 Leader 就是白痴，这种产品在头脑风暴阶段就应该被拍死才对）。</p><p><strong>所以，“期望出现决定产品生死的技术难点，然后自己 NB 闪闪地搞定”这种事情，是不可能发生的。</strong></p><p>同时，在开发过程中，难免出现各种意料之外的 Bug。比如：你负责的模块出现了三个 Bug，其中一个是必现问题，且直接影响功能实现，那这是一定要搞定的。如果你搞不定，Team 会找其他老手和你一起攻关。</p><p>攻关结果有两种，一种是 Bug 解决了，但是不知道为什么；另一种是 Bug 解决了也知道了是为什么。</p><p>对于第一种情况，Team 是不会为了找到原因而让你潜心研究几个月的，为什么？</p><p>因为你还有后续工作要完成，而这个 Bug 已经解决了，不影响用户使用了。</p><p>什么时候才有可能让你继续跟进这个问题呢？1.0 版本的产品市场反馈符合预期，且公司决定要继续投入 2.0 版本 ——只有这个条件满足，你才有可能继续跟进这个问题，为什么是有可能呢？</p><p>因为这个 Bug 已经不影响客户使用了，没必要投入人力去研究了，你如果花几个月的时间去找这个 Bug 的原因，那么请问：2.0版本的工作谁做？</p><p>在很多项目中，类似这种 “问题解决了但是不知道原因” 的bug，是比较常见的，很多时候，直到这个产品生命周期结束，这些 Bug 的原因都没有找到。</p><p>因此，“期望碰到神秘 Bug，然后自己潜心研究几个月，终于把原因找到” 这种事情，很多时候是不存在的。</p><p>接着上面的 “三个 Bug ”继续：另外两个 Bug，是概率发生且发生概率很低。</p><p>这个时候如果工期比较赶，公司会想办法绕过这两个 Bug，比如定时重启服务器、定时清理缓存等（这些方法通常可以绕开低概率 Bug），不会给你 “潜心研究三个月然后把 Bug 解决”的机会的。</p><p>什么时候才有可能让你继续研究这两个 Bug 呢？和第一个 Bug 一样，只有后续继续开发，才有可能让你继续跟进。</p><p>现在，请各位再重新品味一下 “技术驱动” 这个词。到底什么是技术驱动？</p><p><strong>其实这个词真正的含义就是：我们公司效益很好，能养活 NB 的技术团队，所以产品能不断迭代演进开发，随着产品的不断迭代，技术人员有可能会遇到一些其他公司遇不到的问题。</strong></p><p>所以，如果一家新成立的小公司说自己是技术驱动的……连 1.0 版本的产品都没有，就敢说自己是技术驱动？你信吗？不管你信不信，反正我不信。</p><p><strong>简而言之，“技术驱动” 的同义词就是 “我们公司很有钱” + “我们公司不是炒股炒房而是做产品的公司”。</strong></p><p>至于为什么不直接这么说呢？这是因为这种说法不容易被十年寒窗苦读、潜心研究技术的同学接受……</p><p>被 “技术驱动” 迷惑的同学，其实就是读书读傻了，什么叫 “读书读傻了” ？就是把社会和学校等同成同样的东西……</p><p>“很有钱的做 IT 产品的公司”，这个世界上当然是有的，但是这样的公司，根本不会用 “技术驱动” 这种词来忽悠新人。</p><p>最后，隔行如隔山，但隔行不隔理。如果你读完上面的东西，对自己所处的行业有了进一步的认识，我以为，是很正常的。</p><blockquote><p>作者介绍：智煜徽，洛林大学计算机专业研究生，现就职于华为，从事自动驾驶/机器学习相关研发工作。曾在卢森堡-Clearstream 参与分布式金融平台的开发；有创业经历。</p><p>这是来自知乎的一篇贴子，原文：<a href="https://url.cn/5DY4OfB%E3%80%82%E4%B8%BB%E8%A6%81%E7%9A%84%E8%A7%82%E7%82%B9%E6%98%AF%EF%BC%9A%E4%B8%96%E7%95%8C%E4%B8%8A%E6%B2%A1%E6%9C%89%E6%8A%80%E6%9C%AF%E9%A9%B1%E5%8A%A8%E5%9E%8B%E5%85%AC%E5%8F%B8%E3%80%82%E8%A7%82%E7%82%B9%E9%A2%87%E6%9C%89%E4%BA%89%E8%AE%AE%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%A4%A7%E5%AE%B6%E6%9C%89%E4%B8%8D%E5%90%8C%E7%9C%8B%E6%B3%95%EF%BC%8C%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E7%95%99%E8%A8%80%E4%BA%A4%E6%B5%81%EF%BC%81" target="_blank" rel="noopener">https://url.cn/5DY4OfB。主要的观点是：世界上没有技术驱动型公司。观点颇有争议，如果大家有不同看法，欢迎大家留言交流！</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;世界上没有技术驱动型公司&quot;&gt;世界上没有技术驱动型公司&lt;/h2&gt;
&lt;p&gt;世界上没有技术驱动型公司，不论 Google、Facebook，还是腾讯、阿里，都不是技术驱动型公司。&lt;strong&gt;因为技术不是源头，需求才是。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此一切技术问题，都要服从产品交付和市场反馈。所以，任何公司都不可能以技术去驱动自身。人可以以技术驱动自己进步，但公司不行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一家公司可以以技术切入某个市场，但如果它想生存下去，就一定不能以技术为导向，坚持以技术为导向的公司的生命力为零，其下场有两个：破产或者在破产之前被收购。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果你真的很痴迷钻研技术，请读研读博最后留校，或者进研究院让国家用纳税人的钱养你。&lt;/p&gt;
&lt;h2 id=&quot;每个人都得加班&quot;&gt;每个人都得加班&lt;/h2&gt;
&lt;p&gt;资本富集的地方，人都得加班，加班的本质，是人跟着机器跑、人跟着钱跑。&lt;/p&gt;
&lt;p&gt;更为本质地说，资本富集的地方，人作为劳动力，也是资本的一种。&lt;strong&gt;即人是资本而不是人本身。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;资本的运转是不能停的，因为停一下损失的钱太多了，中国和外国都一样。&lt;/p&gt;
&lt;p&gt;知道发达国家为什么产业工人不加班吗？因为制造业已经不是这些国家主要创造财富的领域了。&lt;/p&gt;
&lt;p&gt;发达国家资本富集的地方是金融行业，所以西方国家的金融狗一样加班。&lt;/p&gt;
&lt;p&gt;劳动法？加班费？都不存在的。劳动法和加班费只有在资本离开这个市场后才能给你保证。&lt;/p&gt;
&lt;p&gt;一般公司的策略是：付给你高于其他行业的薪水、换取你 “自愿” 加班。不想加班的同学们，你们可以去考公务员或者去欧洲做IT，我保证你不加班、不但不用加班，你甚至会很闲。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="思想" scheme="https://www.hi-linux.com/tags/%E6%80%9D%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>如何有效的清除 DNS 缓存</title>
    <link href="https://www.hi-linux.com/posts/56208.html"/>
    <id>https://www.hi-linux.com/posts/56208.html</id>
    <published>2020-05-23T02:20:00.000Z</published>
    <updated>2020-05-23T14:58:59.770Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>DNS 缓存是一个临时数据库，用于存储有关以前的 DNS 查找的信息。换句话说，每当你访问网站时，你的操作系统和网络浏览器都会保留该域和相应 IP 地址的记录。这消除了对远程 DNS 服务器重复查询的需要，并允许你的 OS 或浏览器快速解析网站的 URL。</p><p>但是在某些情况下，例如：对网络问题进行故障排除，或者在更改 DNS 解析器之后，你将需要刷新 DNS 缓存。这将清除缓存的 DNS 条目，并根据新配置的 DNS 设置执行后续查找以解析域。</p><p>本指南提供有关如何在不同的操作系统和 Web 浏览器上刷新 DNS 缓存的说明。</p><h2 id="在-windows-上清除刷新-dns-缓存">在 Windows 上清除/刷新 DNS 缓存</h2><p>对于所有 Windows 版本，清除 DNS 缓存的过程都是相同的。你需要使用管理员权限打开命令提示符并运行 <code>ipconfig /flushdns</code>。</p><h3 id="windows-10-和-windows-8">Windows 10 和 Windows 8</h3><p>要在 Windows 10 和 Windows 8 中清除 DNS 缓存，请执行以下步骤：</p><ol><li><p>在 Windows 搜索栏中键入 cmd 。</p></li><li><p>右键单击 “命令提示符”，然后右击 “以管理员身份运行”。这将打开 “命令提示符” 窗口。</p></li><li><p>在命令行上，键入以下行，然后按回车：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipconfig &#x2F;flushdns</span><br></pre></td></tr></table></figure><p>成功后，系统将返回以下消息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Windows IP Configuration</span><br><span class="line"></span><br><span class="line">Successfully flushed the DNS Resolver Cache.</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="windows-7">Windows 7</h3><p>要在 Windows 7 中清除 DNS 缓存，请执行以下步骤：</p><ol><li><p>单击开始按钮。</p></li><li><p>在开始菜单搜索文本框中键入 cmd。</p></li><li><p>右键单击 “命令提示符”，然后单击 “以管理员身份运行”。这将打开 “命令提示符” 窗口。</p></li><li><p>在命令行上，键入以下行，然后按回车：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipconfig &#x2F;flushdns</span><br></pre></td></tr></table></figure><p>成功后，系统将返回以下消息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Windows IP Configuration</span><br><span class="line"></span><br><span class="line">Successfully flushed the DNS Resolver Cache.</span><br></pre></td></tr></table></figure><h2 id="在-linux-上清除刷新-dns-缓存">在 Linux 上清除/刷新 DNS 缓存</h2><p>在 Linux 上，除非已安装并运行诸如 <code>Systemd-Resolved</code>，<code>DNSMasq</code> 或 <code>Nscd</code> 之类的缓存服务，否则没有操作系统级 <code>DNS</code> 缓存。根据 Linux 发行版和所使用的缓存服务，清除 DNS 缓存的过程有所不同。</p><h3 id="系统化解决">系统化解决</h3><p>大多数现代 Linux 发行版，例如 Ubuntu 18.04，都使用 systemd 解析的服务来缓存 DNS 条目。</p><p>要查找服务是否正在运行，请运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl is-active systemd-resolved.service</span><br></pre></td></tr></table></figure><p>如果该服务正在运行，则将打印命令 active，否则将看到 inactive。</p><p>要清除系统解析的 DNS 缓存，你需要键入以下命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemd-resolve --flush-caches</span><br></pre></td></tr></table></figure><p>成功后，该命令不会返回任何消息。</p><h3 id="dnsmasq">Dnsmasq</h3><p>Dnsmasq 是轻量级的 DHCP 和 DNS 缓存名称服务器。</p><p>如果你的系统使用 DNSMasq 作为缓存服务器，则要清除 DNS 缓存，需要重新启动 Dnsmasq 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart dnsmasq.service</span><br></pre></td></tr></table></figure><p>也可以使用以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo service dnsmasq restart</span><br></pre></td></tr></table></figure><h3 id="nscd">NSCD</h3><p><code>NSCD</code> 是一个缓存守护程序，它是大多数基于 RedHat 的发行版的首选 DNS 缓存系统。</p><p>如果系统使用 <code>NSCD</code> 来清除 DNS 缓存，则需要重新启动 <code>NSCD</code> 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart nscd.service</span><br><span class="line">或者</span><br><span class="line">$ sudo service nscd restart</span><br></pre></td></tr></table></figure><h2 id="在-macos-上清除刷新-dns-缓存">在 MacOS 上清除/刷新 DNS 缓存</h2><p>根据你所运行的版本，在 MacOS 中刷新缓存的命令略有不同。该命令必须以具有系统管理员特权的用户（sudo 用户）身份运行。</p><p>要清除 MacOS 中的 DNS 缓存，请执行以下步骤：</p><ol><li><p>打开查找器。</p></li><li><p>转到应用程序&gt;实用程序&gt;终端。这将打开终端窗口。</p></li><li><p>在命令行中，输入以下行，然后按回车：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo killall -HUP mDNSResponder</span><br></pre></td></tr></table></figure><p>输入你的 <code>sudo</code> 密码，然后再次按回车。成功后，系统不会返回任何消息。</p><p>对于早期版本的 MacOS，刷新缓存的命令不同。</p><ul><li>MacOS 版本 10.11 和 10.9</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dscacheutil -flushcache</span><br><span class="line">$ sudo killall -HUP mDNSResponder</span><br></pre></td></tr></table></figure><ul><li>MacOS 版本 10.10</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo discoveryutil mdnsflushcache</span><br><span class="line">$ sudo discoveryutil udnsflushcaches</span><br></pre></td></tr></table></figure><ul><li>MacOS 版本 10.6 和 10.5</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dscacheutil -flushcache</span><br></pre></td></tr></table></figure><h2 id="清除刷新浏览器-dns-缓存">清除/刷新浏览器 DNS 缓存</h2><p>大多数现代的 Web 浏览器都有一个内置的 DNS 客户端，以防止每次访问该网站时重复查询。</p><h3 id="谷歌浏览器-chrome">谷歌浏览器 Chrome</h3><p>要清除 Google Chrome 的 DNS 缓存，请执行以下步骤：</p><ol><li><p>打开一个新标签，然后在地址栏输入 <code>chrome://net-internals/#dnsChrome</code>。</p></li><li><p>点击 “清除主机缓存” 按钮。</p></li></ol><p>如果那对你不起作用，请尝试清除缓存和 Cookie。</p><ol><li><p>按下 <code>CTRL+Shift+Del</code> 以打开 “清除浏览数据” 对话框窗口。</p></li><li><p>选择一个时间范围。选择 “所有时间” 以删除所有内容。</p></li><li><p>选中 “Cookie 和其他站点数据” 和 “缓存的图像和文件” 框。</p></li><li><p>点击 “清除数据” 按钮。</p></li></ol><p>此方法适用于所有基于 Chrome 的浏览器，包括 Chromium，Vivaldi 和 Opera。</p><h3 id="火狐-firefox">火狐 Firefox</h3><p>要清除 Firefox 的 DNS 缓存，请执行以下步骤：</p><ol><li><p>在右上角，单击汉堡包图标 ☰ 以打开 Firefox 的菜单：</p></li><li><p>点击 ⚙ Options (Preferences) 链接。</p></li><li><p>单击左侧的 “隐私和安全性” 或 “隐私” 选项卡。</p></li><li><p>向下滚动到该 History 部分，然后单击 Clear History… 按钮。</p></li><li><p>选择要清除的时间范围。选择 “所有内容” 以删除所有内容。</p></li><li><p>选择所有框，然后单击 “立即清除” 。</p></li></ol><p>如果这对你不起作用，请尝试以下方法并暂时禁用 DNS 缓存。</p><ol><li><p>打开一个新标签，然后在 Firefox 的地址栏中输入 <code>about:config</code> 。</p></li><li><p>搜索 <code>network.dnsCacheExpiration</code>，将值暂时设置为 0，然后单击 “确定”。然后，改回默认值，然后单击 “确定” 。</p></li><li><p>搜索 <code>network.dnsCacheEntries</code>，将值暂时设置为 0，然后单击 “确定” 。然后，改回默认值，然后单击 “确定”。</p></li></ol><h2 id="结论">结论</h2><p>至此，你已经了解了如何在 Windows，Linux 和 MacOS 操作系统上清除或刷新 DNS 缓存。</p><p>如果还存在问题，Linux 和 MacOS 还可以使用 <code>dig</code> 命令来查询 DNS 并对 DNS 问题进行故障排除。</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://tinyurl.com/yyl2n44e" target="_blank" rel="noopener">https://tinyurl.com/yyl2n44e</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DNS 缓存是一个临时数据库，用于存储有关以前的 DNS 查找的信息。换句话说，每当你访问网站时，你的操作系统和网络浏览器都会保留该域和相应 IP 地址的记录。这消除了对远程 DNS 服务器重复查询的需要，并允许你的 OS 或浏览器快速解析网站的 URL。&lt;/p&gt;
&lt;p&gt;但是在某些情况下，例如：对网络问题进行故障排除，或者在更改 DNS 解析器之后，你将需要刷新 DNS 缓存。这将清除缓存的 DNS 条目，并根据新配置的 DNS 设置执行后续查找以解析域。&lt;/p&gt;
&lt;p&gt;本指南提供有关如何在不同的操作系统和 Web 浏览器上刷新 DNS 缓存的说明。&lt;/p&gt;
&lt;h2 id=&quot;在-Windows-上清除-刷新-DNS-缓存&quot;&gt;在 Windows 上清除/刷新 DNS 缓存&lt;/h2&gt;
&lt;p&gt;对于所有 Windows 版本，清除 DNS 缓存的过程都是相同的。你需要使用管理员权限打开命令提示符并运行 &lt;code&gt;ipconfig /flushdns&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;Windows-10-和-Windows-8&quot;&gt;Windows 10 和 Windows 8&lt;/h3&gt;
&lt;p&gt;要在 Windows 10 和 Windows 8 中清除 DNS 缓存，请执行以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在 Windows 搜索栏中键入 cmd 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;右键单击 “命令提示符”，然后右击 “以管理员身份运行”。这将打开 “命令提示符” 窗口。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在命令行上，键入以下行，然后按回车：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ipconfig &amp;#x2F;flushdns&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;成功后，系统将返回以下消息：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Windows IP Configuration&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Successfully flushed the DNS Resolver Cache.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="DNS" scheme="https://www.hi-linux.com/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>浅谈边缘计算</title>
    <link href="https://www.hi-linux.com/posts/22481.html"/>
    <id>https://www.hi-linux.com/posts/22481.html</id>
    <published>2020-05-23T02:19:00.000Z</published>
    <updated>2020-05-23T14:58:59.774Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是边缘计算">什么是边缘计算？</h2><p>云计算（Cloud Computing）从 2005 年进入我们的视线至今已经发展了 14 年，商业应用取得了巨大的成功，边缘计算（Edge Computing）则是云计算继续发酵的产物，目前还处于概念阶段。</p><p>那么到底什么是边缘计算呢？ 引用 Wikipedia 对 Edge Computing 的定义，边缘计算是指：</p><blockquote><p>Edge computing is a method of optimising cloud computing systems by performing data processing at the edge of the network, near the source of the data.</p></blockquote><p>与将数据传到远程的云端进行处理相对，边缘计算是一种分布式计算概念。边缘计算在靠近数据源头的网络边缘提供计算和存储资源，允许在数据收集源附近实时处理和分析数据。</p><p>通俗的说，边缘计算是去中心化或分布式的云计算，原始数据不传回云端，而是在本地完成分析。看好边缘计算的人认为计算能力正在从云端向边缘移动，因此边缘计算会成为下一个像云计算这样成功的技术爆发点。另一方面，边缘计算是驱动物联网的关键技术，因此边缘计算的推动者往往是从事物联网的人。</p><p>有了定义还不足以理解边缘计算，你可能会问到底什么是边缘呢？</p><p>边缘是一个很笼统的概念，它是指接近数据源的计算基础设施，不同的边缘计算提供商往往有不同的边缘。比如美国电信公司 AT&amp;T 的边缘就是离客户几英里的蜂窝网络基站；对于世界最大的 CDN 厂商阿卡麦，边缘则是指遍布全球的 CDN 设备；对于机场的监控设备，边缘就是覆盖整个机场无死角的高清摄像头。</p><p><img src="https://img.alicdn.com/tfs/TB1cJS2KhjaK1RjSZKzXXXVwXXa-3197-1854.png" alt=""></p><h2 id="云计算-边缘计算-雾计算">云计算、边缘计算、雾计算</h2><p>云计算发展至今还未到达顶峰，在一些营销的推波助澜下又冒出了个边缘计算，甚至雾计算（Fog Computing）。下面谈一谈他们的区别和联系。</p><a id="more"></a><h3 id="云计算与边缘计算">云计算与边缘计算</h3><p>云计算的概念应该是比较明确的了——一种按使用量付费、通过网络提供的虚拟资源，这些资源包括服务器、运行环境和软件，它们分别对应 IaaS、Paas 和 SaaS。</p><p>下面引用 IIOT EDGE COMPUTING VS. CLOUD COMPUTING 的观点来解释云计算和边缘计算的区别。</p><p>传统的云计算架构要求客户端将数据推送到中心服务器然后再拉回来，比如我们每天都在使用的 ICloud 帮助我们备份照片、短信等。然后这种集中式的云架构对时间敏感、带宽稀缺的工业物联网就不再适用，因此某些关键数据的处理任务最好是在数据源而不是云端，边缘计算应用而生。</p><p>云计算和边缘计算共同参与的物联网解决方案</p><p><img src="https://www.yanxurui.cc/posts/misc/2017-08-08-a-survey-of-edge-computing/edge-v-cloud-computing-graphic.png" alt=""></p><p>边缘计算并不会替代云计算，他们是相辅相成的，简单的说就是大量的计算任务在离用户最近的边缘计算节点上完成，只有少量的数据需要传到云计算中心。它们扮演的角色如下所示：</p><p><strong>CLOUD COMPUTING</strong></p><ul><li>Complex analytics</li><li>Big Data mining</li><li>Sources of business logic</li><li>Machine learning rules</li><li>Advanced visualizations</li><li>Long term data storage/warehousing</li></ul><p><strong>EDGE COMPUTING</strong></p><ul><li>Basic data visualization</li><li>Basic data analytics and short term data historian features</li><li>Data caching, buffering and streaming</li><li>Data pre-processing, cleansing, filtering and optimization</li><li>Some data aggregation</li><li>Device to Device communications/M2M</li></ul><h3 id="边缘计算与雾计算">边缘计算与雾计算</h3><p>思科最早使用雾计算这个术语来描述网络边缘的计算层，可以对数据进行预处理，使数据快速，安全地传输到云端。雾计算与边缘计算非常接近，但也是有区别的。</p><p>以下观点来自 Fog Computing vs. Edge Computing: What’s the Difference?，这篇文章采访了该行业内两位比较权威的从业人士：</p><ul><li>David King 是一家为工业和商业物联网开发边缘智能软件的公司 FogHorn Systems 的 CEO；</li><li>Matt Newton 是一家生产控制器、I/O 设备、中继器和连接边缘设备到网络的软件制造商 Opto 22 的技术市场主管；</li></ul><p>雾计算与边缘计算都是将智能和计算能力推向靠近数据来源的位置，因此他们常常被混用。他们的区别也正是计算能力（大脑）所处的位置：</p><ul><li>雾计算将计算能力推向局域网，在雾节点或物联网的网关处完成数据处理</li><li>边缘计算将边缘网关的智能，处理能力和通信能力直接推送到诸如可编程自动化控制器的设备</li></ul><p>三者的关系如下所示（图片来自Fog vs Edge Computing）：</p><p><img src="https://www.yanxurui.cc/posts/misc/2017-08-08-a-survey-of-edge-computing/cloud-edge-fog-computing.png" alt=""></p><h2 id="边缘计算的优势与问题">边缘计算的优势与问题</h2><h3 id="云计算面临的问题">云计算面临的问题</h3><p>现在的云计算都是集中式的，即把服务器集中在某一个地方，为了使用云计算的计算资源，数据需要先被传输到距离用户很远的数据中心然后集中处理。但是很多设备都无法接入云端，大致是以下两个原因：</p><ol><li><p>数据量大：对于巨大的数据量，这种传输带宽成本难以接受；比如通用电气很早就意识到工业机床上的传感器产生的大量的数据需要在设备边缘进行处理，只将有最有价值的数据移到云端进行机器学习并且在不同设备之间共享（Edge computing could push the cloud to the fringe）</p></li><li><p>速度：对于要求低延迟、密集型计算的智能设备，比如头戴式 VR，机器人，无人机等，受限于网络传输延迟而无法享受云计算的强大计算资源，这些设备还面临一个共同的问题，就是电池续航时间短；</p></li></ol><p>边缘计算概念的提出就是为了解决这样的问题。 在边缘计算中，传感器，控制器和其他连接的设备本身收集和分析物联网数据，或将其传输到附近的计算设备（如服务器或笔记本电脑）进行分析。当数据处理和分析发生在网络边缘（与数据中心或云相对）时，数据可以立即分析并投入运行。</p><h3 id="边缘计算的优势">边缘计算的优势</h3><p>Sprint 公司的物联网事业部经理 Mohamad Nasser 在 Four advantages of edge computing 一文中给出了边缘计算的应用实例，并阐述了边缘计算的四个优势。</p><p><a href="http://openedgecomputing.org" target="_blank" rel="noopener">openedgecomputing.org</a> 的首页上言简意赅的列出了边缘计算的两条优势。</p><p>结合维基百科的观点，将以上内容整理后总结如下：</p><ol><li>接近实时的数据处理：因为数据是在边缘结点进行分析，降低了延迟，提升应用的响应速度</li><li>减少数据传输：数据不需要推送到遥远的云端，减少智能设备和数据中心传输的数据量，节省带宽成本，同时还能减小核心网络的拥堵。比如 Facebook 等社交软件的用户上传的照片在边缘调整到合适的分辨率再上传到云端</li><li>数据安全：一些比较敏感的数据直接在边缘进行分析，不用当心数据泄漏</li><li>提高可用性：分担（offload）了中心服务器的计算任务，一定程度上消除了主要的瓶颈，并且降低了出现单点故障的可能，</li></ol><h3 id="边缘计算的问题">边缘计算的问题</h3><p>任何东西都是有缺点的，如果只看到优点说明理解的不够深入。边缘计算还处于概念阶段，同样存在很多问题，比如：</p><ol><li>使边缘设备具有处理能力意味着更高的成本和更容易被入侵的危险；</li><li>在大量的边缘设备上进行应用部署和服务监控会成为一个棘手的问题；</li><li>在边缘进行分布式计算并与云端协调任务会让应用编程变得更加复杂；</li></ol><h2 id="边缘计算与-cdn">边缘计算与 CDN</h2><p>CDN 的作用简单的说就是通过将图片、视频等静态文件缓存到接近用户的节点上，降低直接访问源站的延迟，从而实现加速。</p><p>CDN 公司拥有遍布各地、接近用户的庞大服务器集群自然成为了优势明显的边缘计算资源，因此结合 CDN 技术的优势，向客户提供边缘计算服务成为了传统 CDN 公司向创新型服务商转变的一个新的突破点。</p><p>以下是边缘计算在 CDN 的探索性应用：</p><ol><li><p>国内 CDN 行业的龙头老大网宿认为未来 CDN 的演进方向之一是形成边缘计算系统。因此，网宿科技对 MEC 有着清晰的规划。网宿科技将通过布局集中式数据中心+边缘计算节点，用中心云+边缘云的方式承载未来。此外，公司正在升级现有 CDN 节点为具备存储、计算、传输、安全功能的边缘计算节点，部署数量更多的边缘计算节点到距离用户更近的城域网（出处：深度报告：移动边缘计算，站在5G “中央”）。此外网宿基于边缘计算的方式，成功研发出边缘弹幕分发技术，所有的弹幕在网宿平台上直接进行分发，不用再回源，解救了直播平台弹幕压力大的一大痛点。（出处：CDN 掀起二次变革：从传输服务到边缘计算）</p></li><li><p>阿卡迈在全球节点上除了做传统 CDN 分发之外，还利用自身分布式运算的能力，帮助用户解决业务逻辑问题。举个简单例子，阿卡迈在云端部署方面，可以精确识别用户所在的位置和用户所使用的浏览器类型。还能精确识别这个客户所在的运营商所属的组织机构等。利用这些信息，我们就可以在云端帮助客户做一些逻辑判断，帮助用户完成在云端的一些通用型逻辑处理，例如把来自手机的访问自动重定向到M站（手机站），以及将浏览器语言自动定向到所属国家和地区。通过云端的逻辑智能处理，就大大节省客户在应用编码上的时间，上述的这些技术都已经产品化，并已经是经过很多客户验证过的解决方案，让客户通过简单的配置在几小时之内在云端实现，降低操作的难度以及缩短部署推向市场的时间（出处：阿卡迈梁世鹏：云计算与 CDN 是一对天生的孪生兄弟）。阿卡麦通过与 IBM 合作，使客户可以直接将 Java 应用部署到分布在全球的边缘设备上，实现就近计算，提升用户体验（出处：Akamai, IBM team for edge computing）。</p></li><li><p>英特尔提出了利用 CDN 节点直接进行视频转码、分发和存储的视频直播解决方案，数据不用回流到源站，大大节省了带宽资源，并且获得更好的用户体验（出处：边缘计算揽洪荒之力挺直播大潮 GPU 携深度学习助智能 CDN）。</p></li></ol><blockquote><p>来源：Xurui Yan Blog<br>原文：<a href="http://t.cn/AiWYM1f2" target="_blank" rel="noopener">http://t.cn/AiWYM1f2</a><br>题图：来自谷歌图片搜索<br>版权：本文版权归原作者所有<br>投稿：欢迎投稿，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是边缘计算？&quot;&gt;什么是边缘计算？&lt;/h2&gt;
&lt;p&gt;云计算（Cloud Computing）从 2005 年进入我们的视线至今已经发展了 14 年，商业应用取得了巨大的成功，边缘计算（Edge Computing）则是云计算继续发酵的产物，目前还处于概念阶段。&lt;/p&gt;
&lt;p&gt;那么到底什么是边缘计算呢？ 引用 Wikipedia 对 Edge Computing 的定义，边缘计算是指：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge computing is a method of optimising cloud computing systems by performing data processing at the edge of the network, near the source of the data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与将数据传到远程的云端进行处理相对，边缘计算是一种分布式计算概念。边缘计算在靠近数据源头的网络边缘提供计算和存储资源，允许在数据收集源附近实时处理和分析数据。&lt;/p&gt;
&lt;p&gt;通俗的说，边缘计算是去中心化或分布式的云计算，原始数据不传回云端，而是在本地完成分析。看好边缘计算的人认为计算能力正在从云端向边缘移动，因此边缘计算会成为下一个像云计算这样成功的技术爆发点。另一方面，边缘计算是驱动物联网的关键技术，因此边缘计算的推动者往往是从事物联网的人。&lt;/p&gt;
&lt;p&gt;有了定义还不足以理解边缘计算，你可能会问到底什么是边缘呢？&lt;/p&gt;
&lt;p&gt;边缘是一个很笼统的概念，它是指接近数据源的计算基础设施，不同的边缘计算提供商往往有不同的边缘。比如美国电信公司 AT&amp;amp;T 的边缘就是离客户几英里的蜂窝网络基站；对于世界最大的 CDN 厂商阿卡麦，边缘则是指遍布全球的 CDN 设备；对于机场的监控设备，边缘就是覆盖整个机场无死角的高清摄像头。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.alicdn.com/tfs/TB1cJS2KhjaK1RjSZKzXXXVwXXa-3197-1854.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;云计算、边缘计算、雾计算&quot;&gt;云计算、边缘计算、雾计算&lt;/h2&gt;
&lt;p&gt;云计算发展至今还未到达顶峰，在一些营销的推波助澜下又冒出了个边缘计算，甚至雾计算（Fog Computing）。下面谈一谈他们的区别和联系。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="边缘计算" scheme="https://www.hi-linux.com/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>如何平滑的变更单表超 100000000 条记录的数据库结构</title>
    <link href="https://www.hi-linux.com/posts/33485.html"/>
    <id>https://www.hi-linux.com/posts/33485.html</id>
    <published>2020-05-23T02:18:00.000Z</published>
    <updated>2020-05-23T14:58:59.775Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>众所周知，很多互联网业务都面临着无法停机，需要在线变更数据库结构的情况。但是在线修改数据量较大的表，可能对线上业务产生较大影响，比如：</p><ol><li><p>在线修改大表的表结构执行时间往往不可预估，一般时间较长。</p></li><li><p>由于修改表结构是表级锁，因此在修改表结构时，影响表写入操作。</p></li><li><p>如果长时间的修改表结构，中途修改失败，由于修改表结构是一个事务，因此失败后会还原表结构，在这个过程中表都是锁着不可写入。</p></li><li><p>修改大表结构容易导致数据库 CPU、IO 等性能消耗，使 MySQL 服务器性能降低。</p></li><li><p>在线修改大表结构容易导致主从延时，从而影响业务读取。</p></li></ol><a id="more"></a><p>Percona-Toolkit 源自 Maatkit 和 Aspersa 工具，这两个工具是管理 MySQL 的最有名的工具，但 Maatkit 已经不维护了，全部归并到 Percona-Toolkit。Percona Toolkit 是一组高级的命令行工具，用来管理 MySQL 和系统任务，主要包括以下功能：</p><ol><li><p>验证主节点和复制数据的一致性</p></li><li><p>有效的对记录行进行归档</p></li><li><p>找出重复的索引</p></li><li><p>总结 MySQL 服务器</p></li><li><p>从日志和 tcpdump 中分析查询</p></li><li><p>问题发生时收集重要的系统信息</p></li><li><p>在线修改表结构</p></li></ol><p>pt-online-schema-change 是 Percona-Toolkit 工具集中的一个组件，很多 DBA 在使用 Percona-Toolkit 时第一个使用的工具就是它，同时也是使用最频繁的一个工具。它可以做到在修改表结构的同时（即进行 DDL 操作）不阻塞数据库表 DML 的进行，这样降低了对生产环境数据库的影响。</p><p>在 MySQL 5.6.7 之前是不支持 Online DDL 特性的，即使在添加二级索引的时候有 FIC 特性，但是在修改表字段的时候还是会有锁表并阻止表的 DML 操作。这样对于 DBA 来说是非常痛苦的，好在有 pt-online-schema-change 工具在没有 Online DDL 时解决了这一问题，pt-online-schema-change 其主要特点就是在数据库结构修改过程中不会造成读写阻塞。</p><h2 id="pt-online-schema-change-安装">pt-online-schema-change 安装</h2><p>pt-online-schema-change 安装非常简单，官方已经为我们准备好了各主流平台的安装包，只需下载对应版本安装即可。目前最新版本是 3.1.0，这里我们以 CentOS 7 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装相关依赖包</span><br><span class="line">$ yum install perl-DBI perl-DBD-MySQL perl-Time-HiRes perl-IO-Socket-SSL</span><br><span class="line">$ wget https:&#x2F;&#x2F;www.percona.com&#x2F;downloads&#x2F;percona-toolkit&#x2F;3.1.0&#x2F;binary&#x2F;redhat&#x2F;7&#x2F;x86_64&#x2F;percona-toolkit-3.1.0-2.el7.x86_64.rpm</span><br><span class="line">$ rpm -ivh percona-toolkit-3.1.0-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>更多平台的安装包可以直接在官网地址下载：<a href="https://www.percona.com/downloads/percona-toolkit/LATEST/" target="_blank" rel="noopener">https://www.percona.com/downloads/percona-toolkit/LATEST/</a></p><h2 id="pt-online-schema-change-语法说明">pt-online-schema-change 语法说明</h2><ol><li>常用选项说明</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line">$ pt-online-schema-change [OPTIONS] DSN</span><br><span class="line"></span><br><span class="line">--alter</span><br><span class="line">变更结构选项，不需要ALTER TABLE关键字，如果表有多个变更可以使用逗号分隔。</span><br><span class="line"></span><br><span class="line">限制：</span><br><span class="line"></span><br><span class="line">1.在绝大部分情况下表都需要有主键或者是唯一索引。因为这个工具会在运行的时候创建一个DELETE触发器，这是为了保证在变更中新表能够与旧表保持更新一致性。值得注意的是，如果在需要变更的列上创建主键或是唯一索引时，则会以这些列创建触发器；</span><br><span class="line">2.不能使用RENAME子句为表进行重命名；</span><br><span class="line">3.字段不能通过删除再重添加的方式进行重命名，这种方式是不会拷贝原字段的数到新字段上；</span><br><span class="line">4.如果新增 NOT NULL 的列并且没有指定 default 值，工具就会执行失败，它并不会指定默认值；</span><br><span class="line">5.涉及到删除外键时，需要指定 _constraint_name，工具会在新表上创建一个前面加了下划线的外键名称，这个外键名称与原致。如需要删除外键 fk_foo，则指定 &#39;--alter &quot;DROP FOREIGN KEY _fk_foo&quot;&#39;。</span><br><span class="line"></span><br><span class="line">--alter-foreign-keys-method</span><br><span class="line">采用何种方式修改外键以便关联到新表上。有外键约束的表需要被特殊处理，为了确保外键依然能够关联到正确的表上。当工具重命名外键关联的父表时，确保外键也必须关联到重命名后的父表。</span><br><span class="line"></span><br><span class="line">主要有以下几种方式：</span><br><span class="line"></span><br><span class="line">auto：让工具自动选择使用。优先选择 rebuild_constraints，如果不成功，则选择 drop_swap；</span><br><span class="line">rebuild_constraints：这种方式使用 ALTER TABLE 先删除然后重建外键关联到新父表。这是首选的方式，如果一张或多张子表过大会导致 ALTER 需要很长时间，子表会被阻塞；</span><br><span class="line">drop_swap：禁用外键约束 (FOREIGN_KEY_CHECKS&#x3D;0) ，在进行重命名新父表之前删除原父表，这与常规转换旧表与新表的方式不同，这个 RENAME 操作是原子性的并且对应用客户端无感知。</span><br><span class="line"></span><br><span class="line">这种方式更快速并且不会阻塞，但是也有隐患：</span><br><span class="line"></span><br><span class="line">1.删除原父表以及重命名新表这段时间很短，如果这段时间更改子表有可能会报错；</span><br><span class="line">2.如果重命名新表发生失败，而原父表已经永久删除了，这时就需要人工进行干预了。</span><br><span class="line"></span><br><span class="line">这种方式强制使用选项 &#39;--no-swap-tables&#39; 和 &#39;--no-drop-old-table&#39;。</span><br><span class="line"></span><br><span class="line">none：这种方式类似于 drop_swap，不同在于不进行 swap 原父表。子表有任何外键关联父表都将变成关联一张不存在的表，这会使得子表的外键约束失效，可以通过 SHOW ENGINE INNODB STATUS 查看。</span><br><span class="line"></span><br><span class="line">--[no]analyze-before-swap</span><br><span class="line">默认值：yes</span><br><span class="line">在新表与旧表完成转换之前对新表执行 ANALYZE TABLE 操作，默认会在 MySQL 5.6 及之后版本并且开启 innodb_stats_persistent 的情况下执行。</span><br><span class="line"></span><br><span class="line">--ask-pass</span><br><span class="line">命令行提示密码输入，保护密码安全，前提需安装模块 perl-TermReadKey。</span><br><span class="line"></span><br><span class="line">--[no]check-alter</span><br><span class="line">默认值：yes</span><br><span class="line"></span><br><span class="line">解析变更选项的内容，发出表变更警告，主要警告项为：</span><br><span class="line"></span><br><span class="line">1.字段重命名</span><br><span class="line"></span><br><span class="line">在工具的早期版本中，通过指定 CHANGE COLUMN name new_name 进行字段重命名会导致数据库的丢失，现在的版本已经通过代码解决了数据一致性问题。但这段代码并不能保证能够确保数据的不丢失。所以当涉及到字段名变更时应通过添加选项 &#39;--dry-run&#39; 和 &#39;--print&#39; 查看变更是否可以正确执行。</span><br><span class="line"></span><br><span class="line">2.删除主键</span><br><span class="line"></span><br><span class="line">如果 &#39;--alter&#39; 选项中包含 DROP PRIMARY KEY 删除主键的操作，除非指定选项 &#39;--dry-run&#39;，否则工具将退出。变更表的主键是十分危险的，工具变更时建立的触发器，尤其是 DELETE 触发器，是基于主键的，在做主键变更前先添加选项 &#39;--dry-run&#39; 和 &#39;--print&#39; 验证触发器是可用的。</span><br><span class="line"></span><br><span class="line">--[no]check-replication-filters</span><br><span class="line">默认值：yes</span><br><span class="line">如果服务器指定了任何主从复制过滤选项，该工具会查询是否有复制过滤选项，一旦发现，工具都会中止并报错。</span><br><span class="line"></span><br><span class="line">--check-slave-lag</span><br><span class="line">指定暂停旧表与新表的数据拷贝直到主从复制小于选项 &#39;--max-lag&#39; 指定的值。</span><br><span class="line"></span><br><span class="line">--skip-check-slave-lag</span><br><span class="line">DSN 类型，可重复使用</span><br><span class="line">指定 DSN 连接从库时跳过主从延迟检查，可以指定多个从库检查。</span><br><span class="line"></span><br><span class="line">--check-interval</span><br><span class="line">默认值：1s</span><br><span class="line">指定因为选项 &#39;--max-lag&#39; 检查之间休眠时间。</span><br><span class="line"></span><br><span class="line">--chunk-index</span><br><span class="line">指定使用哪个索引对表进行 chunk 分块操作。默认情况下会选择最优的索引，工具会在 SQL 语句中添加 FORCE INDEX 子句。</span><br><span class="line"></span><br><span class="line">--chunk-index-columns</span><br><span class="line">指定使用选项 &#39;--chunk-index&#39; 的索引使用最左前缀几个索引字段，只适用于复合索引。</span><br><span class="line"></span><br><span class="line">--chunk-size</span><br><span class="line">默认值：1000</span><br><span class="line">指定表分块的 chunk 大小，每个 chunk 需要拷贝的表行数，允许的后缀单位为 k、M、G。</span><br><span class="line">当指定了这个选项会覆盖工具默认动态调整 chunk 块大小以便在选项 &#39;--chunk-time&#39; 指定时间内完成行拷贝的行为。</span><br><span class="line"></span><br><span class="line">--chunk-time</span><br><span class="line">默认值：0.5</span><br><span class="line">动态调整每个 chunk 的大小使相应的表行数都在指定的时间内完成拷贝查询。如果该选项值设置为 0，则不会动态调整 chunk 的大小，就有可能造成每次拷贝查询的时间不同，但每个 chunk 大小还是一致的。</span><br><span class="line"></span><br><span class="line">--host，-h</span><br><span class="line">指定连接的数据库 IP 地址。</span><br><span class="line"></span><br><span class="line">--port，-P</span><br><span class="line">指定连接的数据库 Port 端口。</span><br><span class="line"></span><br><span class="line">--user，-u</span><br><span class="line">指定连接的数据库用户。</span><br><span class="line"></span><br><span class="line">--password，-p</span><br><span class="line">指定连接的数据库用户密码。</span><br><span class="line"></span><br><span class="line">--database，-D</span><br><span class="line">指定连接的数据库。</span><br><span class="line"></span><br><span class="line">--charset，-A</span><br><span class="line">指定连接字符集。</span><br><span class="line"></span><br><span class="line">--max-lag</span><br><span class="line">默认值：1s</span><br><span class="line">指定允许主从复制延迟时长的最大值，单位秒。如果在每次拷贝查询之后主从延迟超过指定的值，则操作将暂停执行，暂停休眠时间为选项 &#39;--check-interval&#39; 指定的值。待休眠时间结束之后再次检查主从延迟时长，检查方法是通过从库查询的 &#39;Seconds_Behind_Master&#39; 值来确定。如果主从复制延迟一直大于该参数指定值或者从库停止复制，则操作将一直等待直到从库重新启动并且延迟小于该参数指定值。</span><br><span class="line"></span><br><span class="line">--max-load</span><br><span class="line">数组类型，默认值：Threads_running &#x3D; 25</span><br><span class="line">在变更拷贝完每个 chunk 数据之后，运行 SHOW GLOBAL STATUS 检查所指定变量值高于该参数指定变量的阈值时将暂停操作。如果有多个变量阈值，可以用 &#39;,&#39;(逗号)进行分隔，参数指定型式可以为变量名 &#x3D;MAX_VALUE 或变量名 :MAX_VALUE。</span><br><span class="line">如果只是指定变量名，没有为其指定阈值，则检查当前值并增加 20% 作为阈值。如：</span><br><span class="line">    --max-load&#x3D;Threads_running：没有指定具体值，以当前查询值增加 20% 作为阈值，如当前为 100，阈值为 120；</span><br><span class="line">    --max-load&#x3D;Threads_running:10：以当前指定值为阈值。</span><br><span class="line"></span><br><span class="line">--critical-load</span><br><span class="line">数组类型，默认值：Threads_running &#x3D; 50</span><br><span class="line">指定需中止操作的状态变量阈值。用法可以参考选项 &#39;--max-load&#39;。</span><br><span class="line"></span><br><span class="line">--preserve-triggers 指定保留旧表的触发器。</span><br><span class="line"></span><br><span class="line">从 MySQL 5.7.2 起开始支持在同一张给定的表上定义具有相同触发事件和触发时间的多个触发器。这意味着如果表原来已有触发器，那么工具所需的触发器也可以创建成功。如果指定了该选项，则工具将旧表上所有的触发器复制到新表上，然后再进行表数据行的拷贝操作。</span><br><span class="line"></span><br><span class="line">限制：</span><br><span class="line"></span><br><span class="line">1.如果旧表上的触发器引用了将被工具删除的字段，则触发器失效；</span><br><span class="line">2.该选项不能与选项 &#39;--no-drop-triggers&#39;、&#39;--no-drop-old-table&#39; 和 &#39;--no-swap-tables&#39; 一起使用，因为该选项需要删除旧表的触发器并在新表上重新创建，因为表不可能有多个同名的触发器。</span><br><span class="line"></span><br><span class="line">--null-to-not-null</span><br><span class="line">指定可以将允许NULL的字段转换为 NOT NULL 字段。其中如有包含 NULL 行的字段值转换为字段默认值，如果没有字段值，则根字段类型来分配默认值。如：字符串类型为 &#39;&#39;(空字符串)，数值类型为 0。</span><br><span class="line"></span><br><span class="line">--new-table-name</span><br><span class="line">字符串类型，默认值：%T_new</span><br><span class="line">指定旧表和新表交换之前新表的名称。%T会替换为旧表名称。</span><br><span class="line"></span><br><span class="line">--[no]drop-new-table</span><br><span class="line">默认值：yes</span><br><span class="line">指定如果拷贝旧表数据到新表时失败，则删除新表。</span><br><span class="line">如果指定选项 &#39;--no-drop-new-table&#39; 以及 &#39;--no-swap-tables&#39; 将保留一份变更后的副本，但不会对旧表进行修改。</span><br><span class="line"></span><br><span class="line">限制：当选项 &#39;--alter-foreign-keys-method&#39; 指定的方式为 drop_swap 时，选项 &#39;--no-drop-new-table&#39; 不生效。</span><br><span class="line"></span><br><span class="line">--[no]drop-old-table</span><br><span class="line">默认值：yes</span><br><span class="line">指定在完成旧表与新表交换重命名之后删除旧表。如果之间发生了错误，则会保留旧表。指定选项 &#39;--no-swap-tables&#39; 同样不会删除旧表。</span><br><span class="line"></span><br><span class="line">--[no]drop-triggers</span><br><span class="line">默认值：yes</span><br><span class="line">指定旧表上删除触发器。如果指定了选项 &#39;--no-drop-triggers&#39; 就会强制指定 &#39;--no-drop-old-table&#39;。</span><br><span class="line"></span><br><span class="line">--[no]swap-tables</span><br><span class="line">默认值：yes</span><br><span class="line">指定变更交换旧表和新表。</span><br><span class="line">如果指定选项 &#39;--no-swap-tables&#39; 也会运行整个过程，只是最后不进行旧表与新表的交换，并且删除新表。</span><br><span class="line"></span><br><span class="line">--dry-run</span><br><span class="line">指定创建和变更新表，但是不创建触发器，也不拷贝数据和变更原始表。</span><br><span class="line"></span><br><span class="line">--execute</span><br><span class="line">指定需要执行真正的变更操作。当确定要执行变更操作时必须指定该选项，如果不指定该选项，则工具会进行安全检查之后退出。</span><br><span class="line"></span><br><span class="line">--[no]check-unique-key-change</span><br><span class="line">默认值：yes</span><br><span class="line">当工具要进行添加唯一索引的变更时停止运行。因为工具使用语句 INSERT IGNORE 从旧表进行数据拷贝插入新表，如果插入的值违返唯一性约束，数据插入不会明确提示失败但这样会造成数据丢失。</span><br><span class="line"></span><br><span class="line">--recursion-method</span><br><span class="line">默认值：processlist，hosts</span><br><span class="line">指定获取从库的方式。</span><br><span class="line">METHOD       USES</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;  &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">processlist  SHOW PROCESSLIST   </span><br><span class="line">hosts        SHOW SLAVE HOSTS   </span><br><span class="line">dsn&#x3D;DSN      DSNs from a table</span><br><span class="line">none         Do not find slaves</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">processlist：通过SHOW PROCESSLIST方式找到 slave，为默认方式，当 SHOW SLAVE HOSTS 不可用时。一旦实例运行在非 3306 端口上时，hosts 方式就会变为默认方式；</span><br><span class="line">hosts：通过 SHOW SLAVE HOSTS 方式找到 slave，hosts 方式要求从库配置 &#39;--report_host&#39; 和 &#39;--report_port&#39; 这两个参数；</span><br><span class="line">dsn：通过读取表中从库的 DSN 信息进行连接。</span><br><span class="line"></span><br><span class="line">--recurse</span><br><span class="line">指定搜寻从库的层级，默认无限级。</span><br><span class="line"></span><br><span class="line">--set-vars</span><br><span class="line">默认：</span><br><span class="line">    wait_timeout&#x3D;10000</span><br><span class="line">    innodb_lock_wait_timeout&#x3D;1</span><br><span class="line">    lock_wait_timeout&#x3D;60</span><br><span class="line">运行检查时指定参数值，如有多个用&#39;,&#39;(逗号)分隔。如 &#96;--set-vars&#x3D;wait_timeout&#x3D;5000&#96;。</span><br><span class="line"></span><br><span class="line">--sleep</span><br><span class="line">默认值：0s</span><br><span class="line">指定表变更拷贝数据时的间隔时间。</span><br><span class="line"></span><br><span class="line">--print</span><br><span class="line">打印工具执行过程中的语句到 STDOUT。可以结合 &#39;--dry-run&#39;一起使用。</span><br><span class="line"> </span><br><span class="line">--progress</span><br><span class="line">打印工具执行过程的进度提示到 STDERR。选项值有两部分组成，用逗号进行分隔，第一部分为百分比，时间和迭代。第二部分为根据第一部分数据更新频率，也分为百分比，时间和迭代。</span><br><span class="line"></span><br><span class="line">--quiet，-q</span><br><span class="line">不打印工具执行过程的信息到 STDOUT (禁用&#39;--progress&#39;)。但错误和警告还是打印到 STDERR。</span><br><span class="line"></span><br><span class="line">--statistics</span><br><span class="line">打印内部计数的统计信息。</span><br><span class="line"></span><br><span class="line">--version</span><br><span class="line">显示工具的版本并退出。</span><br><span class="line"></span><br><span class="line">--[no]version-check</span><br><span class="line">默认值：yes</span><br><span class="line">检查 Percona Toolkit、MySQL 和其他程序的最新版本。</span><br></pre></td></tr></table></figure><ol start="2"><li>DSN 选项(DSN)</li></ol><p>可以使用 DSN 方式来连接数据库，DSN 选项为 key=value 方式，在等号的两侧不能有空格出现，并且区分大小写，多个选项之前以’,’(逗号)隔开，主要选项如下：</p><ul><li><p>A 指定字符集</p></li><li><p>D 指定变更表所在数据库</p></li><li><p>t 指定需要变更的表</p></li><li><p>h 指定要连接的 HOST</p></li><li><p>P 指定要连接的 PORT</p></li><li><p>S 指定连接所使用的 SOCKET 文件(Unix systems)</p></li><li><p>u 指定连接的用户名</p></li><li><p>p 指定连接的用户名密码</p></li></ul><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees</span><br></pre></td></tr></table></figure><h2 id="pt-online-schema-change-使用限制">pt-online-schema-change 使用限制</h2><ol><li><p>要求需要执行变更的表有主键 (Primary key) 或唯一索引 (Unique index)，否则工具会执行失败，参考选项 --alter 说明；</p></li><li><p>如果检测到表有外键约束 (Foreign key)，工具除非选项 --alter-foreign-keys-method，否则不会执行变更；</p></li><li><p>如果检测到主从复制中存在过滤，则工具不会执行，参考选项 --[no]check-replication-filters 说明；</p></li><li><p>如果检测到主从复制有延迟，则工具有可能会暂停数据拷贝，参考选项 --max-lag 说明；</p></li><li><p>如果检测到连接当前服务器负载过高，则工具有可能暂停执行或中止退出，参考选项 --max-load 各 --critical-load 说明。</p></li></ol><h2 id="pt-online-schema-change-使用实例">pt-online-schema-change 使用实例</h2><ol><li>测试数据准备</li></ol><p>本文基于 MySQL 官方示例数据库 employee：Example Databases 进行测试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">-- employees：</span><br><span class="line">mysql root@localhost:employees&gt; show create table employees\G;</span><br><span class="line">***************************[ 1. row ]***************************</span><br><span class="line">Table        | employees</span><br><span class="line">Create Table | CREATE TABLE &#96;employees&#96; (</span><br><span class="line">  &#96;emp_no&#96; int(11) NOT NULL,</span><br><span class="line">  &#96;birth_date&#96; date NOT NULL,</span><br><span class="line">  &#96;first_name&#96; varchar(14) NOT NULL,</span><br><span class="line">  &#96;last_name&#96; varchar(16) NOT NULL,</span><br><span class="line">  &#96;gender&#96; enum(&#39;M&#39;,&#39;F&#39;) NOT NULL,</span><br><span class="line">  &#96;hire_date&#96; date NOT NULL,</span><br><span class="line">  PRIMARY KEY (&#96;emp_no&#96;),</span><br><span class="line">  KEY &#96;idx_first_last&#96; (&#96;first_name&#96;,&#96;last_name&#96;),</span><br><span class="line">  KEY &#96;idx_birth_hire&#96; (&#96;birth_date&#96;,&#96;hire_date&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.008s</span><br><span class="line"></span><br><span class="line">-- dept_emp：</span><br><span class="line">mysql root@localhost:employees&gt; show create table dept_emp\G;</span><br><span class="line">***************************[ 1. row ]***************************</span><br><span class="line">Table        | dept_emp</span><br><span class="line">Create Table | CREATE TABLE &#96;dept_emp&#96; (</span><br><span class="line">  &#96;emp_no&#96; int(11) NOT NULL,</span><br><span class="line">  &#96;dept_no&#96; char(4) NOT NULL,</span><br><span class="line">  &#96;from_date&#96; date NOT NULL,</span><br><span class="line">  &#96;to_date&#96; date NOT NULL,</span><br><span class="line">  PRIMARY KEY (&#96;emp_no&#96;,&#96;dept_no&#96;),</span><br><span class="line">  KEY &#96;dept_no&#96; (&#96;dept_no&#96;),</span><br><span class="line">  CONSTRAINT &#96;dept_emp_ibfk_1&#96; FOREIGN KEY (&#96;emp_no&#96;) REFERENCES &#96;employees&#96; (&#96;emp_no&#96;) ON DELETE CASCADE,</span><br><span class="line">  CONSTRAINT &#96;dept_emp_ibfk_2&#96; FOREIGN KEY (&#96;dept_no&#96;) REFERENCES &#96;departments&#96; (&#96;dept_no&#96;) ON DELETE CASCADE</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.010s</span><br><span class="line"></span><br><span class="line">-- departments：</span><br><span class="line">mysql root@localhost:employees&gt; show create table departments\G;</span><br><span class="line">***************************[ 1. row ]***************************</span><br><span class="line">Table        | departments</span><br><span class="line">Create Table | CREATE TABLE &#96;departments&#96; (</span><br><span class="line">  &#96;dept_no&#96; char(4) NOT NULL,</span><br><span class="line">  &#96;dept_name&#96; varchar(40) NOT NULL,</span><br><span class="line">  PRIMARY KEY (&#96;dept_no&#96;),</span><br><span class="line">  UNIQUE KEY &#96;dept_name&#96; (&#96;dept_name&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.012s</span><br><span class="line"></span><br><span class="line">mysql root@localhost:employees&gt; select count(*) from employees;</span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">| 300024   |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.342s</span><br><span class="line">mysql root@localhost:employees&gt; select count(*) from dept_emp;</span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">| 331603   |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.306s</span><br><span class="line">mysql root@localhost:employees&gt; select count(*) from departments;</span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">| 9        |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.050s</span><br></pre></td></tr></table></figure><ol start="2"><li>添加一个字段</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;add comment varchar(50) not null default &#39;pt-osc&#39;&quot; --charset&#x3D;utf8</span><br></pre></td></tr></table></figure><p>因为 employees 表中的 emp_no 字段被其他表外建关联，以下命令执行时会报如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">You did not specify --alter-foreign-keys-method, but there are foreign keys that reference the table. Please read the tool&#39;s documentation carefully.</span><br></pre></td></tr></table></figure><p>根据报错信息的提示，加入选项 <code>--alter-foreign-keys-method</code> 重新执行并通过选项 <code>--dry-run</code> 查看执行过程主要信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;add comment varchar(50) not null default &#39;pt-osc&#39;&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --dry-run</span><br><span class="line">Enter MySQL password:</span><br><span class="line"></span><br><span class="line">Operation, tries, wait:</span><br><span class="line">  analyze_table, 10, 1</span><br><span class="line">  copy_rows, 10, 0.25</span><br><span class="line">  create_triggers, 10, 1</span><br><span class="line">  drop_triggers, 10, 1</span><br><span class="line">  swap_tables, 10, 1</span><br><span class="line">  update_foreign_keys, 10, 1</span><br><span class="line">Child tables:</span><br><span class="line">  &#96;employees&#96;.&#96;dept_emp&#96; (approx. 331143 rows)</span><br><span class="line">  &#96;employees&#96;.&#96;dept_manager&#96; (approx. 24 rows)</span><br><span class="line">Will automatically choose the method to update foreign keys.</span><br><span class="line">Starting a dry run.  &#96;employees&#96;.&#96;employees&#96; will not be altered.  Specify --execute instead of --dry-run to alter the table.</span><br><span class="line">Creating new table...</span><br><span class="line">Created new table employees._employees_new OK.</span><br><span class="line">Altering new table...</span><br><span class="line">Altered &#96;employees&#96;.&#96;_employees_new&#96; OK.</span><br><span class="line">Not creating triggers because this is a dry run.</span><br><span class="line">Not copying rows because this is a dry run.</span><br><span class="line">Not determining the method to update foreign keys because this is a dry run.</span><br><span class="line">Not swapping tables because this is a dry run.</span><br><span class="line">Not updating foreign key constraints because this is a dry run.</span><br><span class="line">Not dropping old table because this is a dry run.</span><br><span class="line">Not dropping triggers because this is a dry run.</span><br><span class="line">2019-03-25T13:30:05 Dropping new table...</span><br><span class="line">2019-03-25T13:30:05 Dropped new table OK.</span><br><span class="line">Dry run complete.  &#96;employees&#96;.&#96;employees&#96; was not altered.</span><br><span class="line"></span><br><span class="line">-- 确保信息无误之后可以真正执行变更操作</span><br><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;add comment varchar(50) not null default &#39;pt-osc&#39;&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br><span class="line"></span><br><span class="line">……省略……</span><br><span class="line">Will automatically choose the method to update foreign keys.</span><br><span class="line">Altering &#96;employees&#96;.&#96;employees&#96;...</span><br><span class="line">Creating new table...</span><br><span class="line">Created new table employees._employees_new OK.</span><br><span class="line">Altering new table...</span><br><span class="line">Altered &#96;employees&#96;.&#96;_employees_new&#96; OK.</span><br><span class="line">2019-03-25T13:35:25 Creating triggers...</span><br><span class="line">2019-03-25T13:35:25 Created triggers OK.</span><br><span class="line">2019-03-25T13:35:25 Copying approximately 299512 rows...</span><br><span class="line">2019-03-25T13:35:31 Copied rows OK.</span><br><span class="line">2019-03-25T13:35:31 Max rows for the rebuild_constraints method: 99266</span><br><span class="line">Determining the method to update foreign keys...</span><br><span class="line">2019-03-25T13:35:31   &#96;employees&#96;.&#96;dept_emp&#96;: too many rows: 331143; must use drop_swap</span><br><span class="line">2019-03-25T13:35:31 Drop-swapping tables...</span><br><span class="line">2019-03-25T13:35:31 Analyzing new table...</span><br><span class="line">2019-03-25T13:35:31 Dropped and swapped tables OK.</span><br><span class="line">Not dropping old table because --no-drop-old-table was specified.</span><br><span class="line">2019-03-25T13:35:31 Dropping triggers...</span><br><span class="line">2019-03-25T13:35:31 Dropped triggers OK.</span><br><span class="line">Successfully altered &#96;employees&#96;.&#96;employees&#96;.</span><br></pre></td></tr></table></figure><ol start="3"><li>修改一个字段</li></ol><p>将表 employees 的 comment 字段的字符集修改为 utf8mb4。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;modify column comment varchar(50) character set utf8mb4&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="4"><li>删除字段</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;drop column comment&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="5"><li>添加索引</li></ol><p>为表 dept_emp 的字段 from_date 和 to_date 创建复合索引 idx_fr_to_date。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;dept_emp --user&#x3D;admin --ask-pass --alter &quot;add index idx_fr_to_date(from_date,to_date)&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="6"><li>删除索引</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;dept_emp --user&#x3D;admin --ask-pass --alter &quot;drop index idx_fr_to_date&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="7"><li>修改字段允许 NULL</li></ol><p>将表 dept_emp 的字段 to_date 指定为允许 NULL。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;dept_emp --user&#x3D;admin --ask-pass --alter &quot;modify column to_date date null&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="8"><li>修改字段不允许 NULL (NOT NULL)</li></ol><p>为表 employees 添加字段 ptosc_num 并允许 NULL，字段类型为 int，没有指定默认值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;add ptosc_num int null&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><p>修改字段 ptosc_num 为不允许 NULL (NOT NULL)，需要通过指定选项 <code>--null-to-not-null</code>，否则会报错。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;modify column ptosc_num int not null&quot; --alter-foreign-keys-method&#x3D;auto --null-to-not-null --charset&#x3D;utf8 --execute</span><br><span class="line"></span><br><span class="line">-- 因为字段ptosc_num没有指定默认值，字段类型为int，所以默认值为0</span><br><span class="line">mysql root@localhost:employees&gt; select * from employees limit 5;</span><br><span class="line">+--------+------------+------------+-----------+--------+------------+-----------+</span><br><span class="line">| emp_no | birth_date | first_name | last_name | gender | hire_date  | ptosc_num |</span><br><span class="line">+--------+------------+------------+-----------+--------+------------+-----------+</span><br><span class="line">| 10001  | 1953-09-02 | Georgi     | Facello   | M      | 1986-06-26 | 0         |</span><br><span class="line">| 10002  | 1964-06-02 | Bezalel    | Simmel    | F      | 1985-11-21 | 0         |</span><br><span class="line">| 10003  | 1959-12-03 | Parto      | Bamford   | M      | 1986-08-28 | 0         |</span><br><span class="line">| 10004  | 1954-05-01 | Chirstian  | Koblick   | M      | 1986-12-01 | 0         |</span><br><span class="line">| 10005  | 1955-01-21 | Kyoichi    | Maliniak  | M      | 1989-09-12 | 0         |</span><br><span class="line">+--------+------------+------------+-----------+--------+------------+-----------+</span><br><span class="line">5 rows in set</span><br><span class="line">Time: 0.022s</span><br></pre></td></tr></table></figure><ol start="9"><li>删除外键</li></ol><p>需要为外键指定名称为 _forigen_key，因为在创建新表时候默认为新表上的外键创建这样的名称，如果没这样指定则无法删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;dept_emp --user&#x3D;admin --ask-pass --alter &quot;drop foreign key _dept_emp_ibfk_1&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="10"><li>重建表</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees --user&#x3D;admin --ask-pass --alter &quot;engine&#x3D;InnoDB&quot; --alter-foreign-keys-method&#x3D;auto --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><ol start="11"><li>变更后保留旧表</li></ol><p>如果是涉及外键关联的父表进行变更，则建议选项 <code>--alter-foreign-keys-method=rebuild_constraints</code>，这样在子表中会重命名外键约束名，如果选项 <code>--alter-foreign-keys-method</code> 有可能取值 drop_swap 时，则会强制使用选项 <code>--no-swap-tables</code> 和<code>--no-drop-old-table</code>，其中 <code>--no-swap-tables</code> 并不会有旧表的产生，就不存在保留之说了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;dept_emp --user&#x3D;admin --ask-pass --alter &quot;add comment varchar(50) notnull default &#39;pt-osc&#39;&quot; --no-drop-old-table --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><p>以上语句执行完成后会在数据库中生成名为 _dept_emp_old 的表，即变更之前的旧表。</p><ol start="12"><li>变更后保留新表</li></ol><p>顾名思义，就是先做一次完整的表变更操作，但是不进行旧表与新表的交换，也不删除变更之后的新表，通过指定选项 <code>--no-drop-new-table</code> 和 <code>--no-swap-tables</code> 实现，可以通过选项 <code>--new-table-name</code> 指定新表名，当选项 <code>--alter-foreign-keys-method=drop_swap</code> 时，<code>--no-drop-new-table</code> 不生效，与保留旧表的情形一致。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;dept_emp --user&#x3D;admin --ask-pass --alter &quot;add comment varchar(50) notnull default &#39;pt-osc&#39;&quot; --no-drop-new-table --no-swap-tables --new-table-name&#x3D;&#39;dept_emp_bak&#39; --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><p>以上语句执行完成后会在数据库中生成名为 dept_emp_bak 的表，即变更之后的新表，但对旧表不会做任何修改。</p><ol start="13"><li>添加主键</li></ol><p>如果是 <code>InnoDB</code> 表没有主键，真的不敢想像啊，但还是要进行测式下。这里测试基于 employees 表创建 employees_ptosc 表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql root@localhost:employees&gt; create table employees_ptosc as select * from employees;</span><br><span class="line">Query OK, 300024 rows affected</span><br><span class="line">Time: 2.010s</span><br><span class="line">mysql root@localhost:employees&gt; show create table employees_ptosc;</span><br><span class="line">+-----------------+--------------------------------------+</span><br><span class="line">| Table           | Create Table                         |</span><br><span class="line">+-----------------+--------------------------------------+</span><br><span class="line">| employees_ptosc | CREATE TABLE &#96;employees_ptosc&#96; (     |</span><br><span class="line">|                 |   &#96;emp_no&#96; int(11) NOT NULL,         |</span><br><span class="line">|                 |   &#96;birth_date&#96; date NOT NULL,        |</span><br><span class="line">|                 |   &#96;first_name&#96; varchar(14) NOT NULL, |</span><br><span class="line">|                 |   &#96;last_name&#96; varchar(16) NOT NULL,  |</span><br><span class="line">|                 |   &#96;gender&#96; enum(&#39;M&#39;,&#39;F&#39;) NOT NULL,   |</span><br><span class="line">|                 |   &#96;hire_date&#96; date NOT NULL          |</span><br><span class="line">|                 | ) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 |</span><br><span class="line">+-----------------+--------------------------------------+</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.022s</span><br></pre></td></tr></table></figure><p>对 employees_ptosc 表添加主键：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">-- 如果 employees_ptosc 表没有任何索引和约束会报如下信息，工具执行失败</span><br><span class="line">Cannot chunk the original table &#96;employees&#96;.&#96;employees_ptosc&#96;: There is no good index and the table is oversized. at &#x2F;usr&#x2F;bin&#x2F;pt-online-schema-change line 5882.</span><br><span class="line"></span><br><span class="line">-- 先为 employees_ptosc 表创建基于 first_name 的索引 idx_first_name，再次执行添加主键</span><br><span class="line">mysql root@localhost:employees&gt; create index idx_first_name on employees_ptosc(first_name);</span><br><span class="line">Query OK, 0 rows affected</span><br><span class="line">Time: 1.175s</span><br><span class="line"></span><br><span class="line">-- 如果没有加选项 --no-check-unique-key-change 会报如下信息</span><br><span class="line">……省略……</span><br><span class="line">Altering &#96;employees&#96;.&#96;employees_ptosc&#96;...</span><br><span class="line">&#96;employees&#96;.&#96;employees_ptosc&#96; was not altered.</span><br><span class="line">You are trying to add an unique key. This can result in data loss if the data is not unique.</span><br><span class="line">Please read the documentation for the --check-unique-key-change parameter.</span><br><span class="line">You can check if the column(s) contain duplicate content by running this&#x2F;these query&#x2F;queries:</span><br><span class="line"></span><br><span class="line">SELECT IF(COUNT(DISTINCT emp_no) &#x3D; COUNT(*),</span><br><span class="line">       &#39;Yes, the desired unique index currently contains only unique values&#39;,</span><br><span class="line">       &#39;No, the desired unique index contains duplicated values. There will be data loss&#39;</span><br><span class="line">) AS IsThereUniqueness FROM &#96;employees&#96;.&#96;employees_ptosc&#96;;</span><br><span class="line"></span><br><span class="line">Keep in mind that these queries could take a long time and consume a lot of resources</span><br><span class="line"></span><br><span class="line">大致意思就是工具无法确定需要创建主键基于的字段值是否唯一，一旦有重复值出现，在数据拷贝的时候容易出现数据丢失，并给出了检查的语句。</span><br><span class="line"></span><br><span class="line">mysql root@localhost:employees&gt; SELECT IF(COUNT(DISTINCT emp_no) &#x3D; COUNT(*),</span><br><span class="line">                                       &#39;Yes, the desired unique index currently contains only unique values&#39;,</span><br><span class="line">                                       &#39;No, the desired unique index contains duplicated values. There will be data loss&#39;</span><br><span class="line">                                ) AS IsThereUniqueness FROM &#96;employees&#96;.&#96;employees_ptosc&#96;;</span><br><span class="line"></span><br><span class="line">+---------------------------------------------------------------------+</span><br><span class="line">| IsThereUniqueness                                                   |</span><br><span class="line">+---------------------------------------------------------------------+</span><br><span class="line">| Yes, the desired unique index currently contains only unique values |</span><br><span class="line">+---------------------------------------------------------------------+</span><br><span class="line">1 row in set</span><br><span class="line">Time: 0.274s</span><br></pre></td></tr></table></figure><p>使用选项 <code>--no-check-unique-key-change</code> 再次执行添加主键操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># pt-online-schema-change h&#x3D;192.168.58.3,P&#x3D;3306,D&#x3D;employees,t&#x3D;employees_ptosc --user&#x3D;admin --ask-pass --alter &quot;add primary key(emp_no)&quot; --charset&#x3D;utf8 --no-check-unique-key-change --charset&#x3D;utf8 --execute</span><br></pre></td></tr></table></figure><h2 id="pt-online-schema-change-工作流程">pt-online-schema-change 工作流程</h2><p>为了了解 pt-online-schema-change 工具是如何做到不阻塞 DML 的，还是通过 General log 来了解。</p><p>以添加字段的执行语句获得的 General log 为例说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line">-- 初始的一些检查数据库参数、负载信息这里不再细说。</span><br><span class="line">…………省略…………</span><br><span class="line"></span><br><span class="line">-- 查看需要执行变更的表状态</span><br><span class="line">200 Query   SHOW TABLES FROM &#96;employees&#96; LIKE &#39;employees&#39;</span><br><span class="line">200 Query   SELECT VERSION()</span><br><span class="line"></span><br><span class="line">-- 查看表是否存在触发器</span><br><span class="line">200 Query   SHOW TRIGGERS FROM &#96;employees&#96; LIKE &#39;employees&#39;</span><br><span class="line"></span><br><span class="line">-- 查看表的建表语句</span><br><span class="line">200 Query   &#x2F;*!40101 SET @OLD_SQL_MODE :&#x3D; @@SQL_MODE, @@SQL_MODE :&#x3D; &#39;&#39;, @OLD_QUOTE :&#x3D; @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; 1 *&#x2F;</span><br><span class="line">200 Query   USE &#96;employees&#96;</span><br><span class="line">200 Query   SHOW CREATE TABLE &#96;employees&#96;.&#96;employees&#96;</span><br><span class="line">200 Query   &#x2F;*!40101 SET @@SQL_MODE :&#x3D; @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; @OLD_QUOTE *&#x2F;</span><br><span class="line"></span><br><span class="line">-- 查询表的执行计划，确定表是否有外键关联</span><br><span class="line">200 Query   EXPLAIN SELECT * FROM &#96;employees&#96;.&#96;employees&#96; WHERE 1&#x3D;1</span><br><span class="line">200 Query   SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema&#x3D;&#39;employees&#39; AND referenced_table_name&#x3D;&#39;employees&#39;</span><br><span class="line">200 Query   EXPLAIN SELECT * FROM &#96;employees&#96;.&#96;dept_emp&#96; WHERE 1&#x3D;1</span><br><span class="line">200 Query   EXPLAIN SELECT * FROM &#96;employees&#96;.&#96;dept_manager&#96; WHERE 1&#x3D;1</span><br><span class="line">200 Query   SHOW VARIABLES LIKE &#39;wsrep_on&#39;</span><br><span class="line">200 Query   &#x2F;*!40101 SET @OLD_SQL_MODE :&#x3D; @@SQL_MODE, @@SQL_MODE :&#x3D; &#39;&#39;, @OLD_QUOTE :&#x3D; @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; 1 *&#x2F;</span><br><span class="line"></span><br><span class="line">-- 创建&#39;_&#39;(下划线)开头相同表结构的新表，并先在新表上执行变更操作</span><br><span class="line">200 Query   USE &#96;employees&#96;</span><br><span class="line">200 Query   SHOW CREATE TABLE &#96;employees&#96;.&#96;employees&#96;</span><br><span class="line">200 Query   &#x2F;*!40101 SET @@SQL_MODE :&#x3D; @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; @OLD_QUOTE *&#x2F;</span><br><span class="line">200 Query   CREATE TABLE &#96;employees&#96;.&#96;_employees_new&#96; (</span><br><span class="line">  &#96;emp_no&#96; int(11) NOT NULL,</span><br><span class="line">  &#96;birth_date&#96; date NOT NULL,</span><br><span class="line">  &#96;first_name&#96; varchar(14) NOT NULL,</span><br><span class="line">  &#96;last_name&#96; varchar(16) NOT NULL,</span><br><span class="line">  &#96;gender&#96; enum(&#39;M&#39;,&#39;F&#39;) NOT NULL,</span><br><span class="line">  &#96;hire_date&#96; date NOT NULL,</span><br><span class="line">  PRIMARY KEY (&#96;emp_no&#96;),</span><br><span class="line">  KEY &#96;idx_first_last&#96; (&#96;first_name&#96;,&#96;last_name&#96;),</span><br><span class="line">  KEY &#96;idx_birth_hire&#96; (&#96;birth_date&#96;,&#96;hire_date&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8</span><br><span class="line">200 Query   ALTER TABLE &#96;employees&#96;.&#96;_employees_new&#96; add comment varchar(50) not null default &#39;pt-osc&#39;</span><br><span class="line"></span><br><span class="line">-- 在原表上分别创建 DELETE、UPDATE、INSERT 三个触发器</span><br><span class="line">200 Query   &#x2F;*!40101 SET @OLD_SQL_MODE :&#x3D; @@SQL_MODE, @@SQL_MODE :&#x3D; &#39;&#39;, @OLD_QUOTE :&#x3D; @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; 1 *&#x2F;</span><br><span class="line">200 Query   USE &#96;employees&#96;</span><br><span class="line">200 Query   SHOW CREATE TABLE &#96;employees&#96;.&#96;_employees_new&#96;</span><br><span class="line">200 Query   &#x2F;*!40101 SET @@SQL_MODE :&#x3D; @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; @OLD_QUOTE *&#x2F;</span><br><span class="line"></span><br><span class="line">……省略……</span><br><span class="line"></span><br><span class="line">200 Query   CREATE TRIGGER &#96;pt_osc_employees_employees_del&#96; AFTER DELETE ON &#96;employees&#96;.&#96;employees&#96; FOR EACH ROW DELETE IGNORE FROM &#96;employees&#96;.&#96;_employees_new&#96; WHERE &#96;employees&#96;.&#96;_employees_new&#96;.&#96;emp_no&#96; &lt;&#x3D;&gt; OLD.&#96;emp_no&#96;</span><br><span class="line">200 Query   CREATE TRIGGER &#96;pt_osc_employees_employees_upd&#96; AFTER UPDATE ON &#96;employees&#96;.&#96;employees&#96; FOR EACH ROW BEGIN DELETE IGNORE FROM &#96;employees&#96;.&#96;_employees_new&#96; WHERE !(OLD.&#96;emp_no&#96; &lt;&#x3D;&gt; NEW.&#96;emp_no&#96;) AND &#96;employees&#96;.&#96;_employees_new&#96;.&#96;emp_no&#96; &lt;&#x3D;&gt; OLD.&#96;emp_no&#96;;REPLACE INTO &#96;employees&#96;.&#96;_employees_new&#96; (&#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96;) VALUES (NEW.&#96;emp_no&#96;, NEW.&#96;birth_date&#96;, NEW.&#96;first_name&#96;, NEW.&#96;last_name&#96;, NEW.&#96;gender&#96;, NEW.&#96;hire_date&#96;);END</span><br><span class="line">200 Query   CREATE TRIGGER &#96;pt_osc_employees_employees_ins&#96; AFTER INSERT ON &#96;employees&#96;.&#96;employees&#96; FOR EACH ROW REPLACE INTO &#96;employees&#96;.&#96;_employees_new&#96; (&#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96;) VALUES (NEW.&#96;emp_no&#96;, NEW.&#96;birth_date&#96;, NEW.&#96;first_name&#96;, NEW.&#96;last_name&#96;, NEW.&#96;gender&#96;, NEW.&#96;hire_date&#96;)</span><br><span class="line"></span><br><span class="line">-- 根据执行计划判断 chunk 包含的行数，以 chunk 数为单位拷贝数据，为在拷贝过程中为这些行加共享读锁</span><br><span class="line">200 Query   EXPLAIN SELECT * FROM &#96;employees&#96;.&#96;employees&#96; WHERE 1&#x3D;1</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) ORDER BY &#96;emp_no&#96; LIMIT 1 &#x2F;*first lower boundary*&#x2F;</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX (&#96;PRIMARY&#96;) WHERE &#96;emp_no&#96; IS NOT NULL ORDER BY &#96;emp_no&#96; LIMIT 1 &#x2F;*key_len*&#x2F;</span><br><span class="line">200 Query   EXPLAIN SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; * FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX (&#96;PRIMARY&#96;) WHERE &#96;emp_no&#96; &gt;&#x3D; &#39;10001&#39; &#x2F;*key_len*&#x2F;</span><br><span class="line">200 Query   EXPLAIN SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;10001&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 999, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;10001&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 999, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   EXPLAIN SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;10001&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;11000&#39;)) LOCK IN SHARE MODE &#x2F;*explain pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   INSERT LOW_PRIORITY IGNORE INTO &#96;employees&#96;.&#96;_employees_new&#96; (&#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96;) SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;10001&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;11000&#39;)) LOCK IN SHARE MODE &#x2F;*pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line"></span><br><span class="line">-- 每次拷贝完 chunk 中数据后，查看是否有警告，查看服务器的负载情况，这是在每个 chunk 拷贝完成后进行的</span><br><span class="line">200 Query   SHOW WARNINGS</span><br><span class="line">200 Query   SHOW GLOBAL STATUS LIKE &#39;Threads_running&#39;</span><br><span class="line">200 Query   EXPLAIN SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;11001&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 12909, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;11001&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 12909, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   EXPLAIN SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;11001&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;23910&#39;)) LOCK IN SHARE MODE &#x2F;*explain pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   INSERT LOW_PRIORITY IGNORE INTO &#96;employees&#96;.&#96;_employees_new&#96; (&#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96;) SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;11001&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;23910&#39;)) LOCK IN SHARE MODE &#x2F;*pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   SHOW WARNINGS</span><br><span class="line">200 Query   SHOW GLOBAL STATUS LIKE &#39;Threads_running&#39;</span><br><span class="line">200 Query   EXPLAIN SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;23911&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 19857, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;23911&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 19857, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   EXPLAIN SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;23911&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;43768&#39;)) LOCK IN SHARE MODE &#x2F;*explain pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   INSERT LOW_PRIORITY IGNORE INTO &#96;employees&#96;.&#96;_employees_new&#96; (&#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96;) SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;23911&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;43768&#39;)) LOCK IN SHARE MODE &#x2F;*pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   SHOW WARNINGS</span><br><span class="line">200 Query   SHOW GLOBAL STATUS LIKE &#39;Threads_running&#39;</span><br><span class="line"></span><br><span class="line">……省略……</span><br><span class="line"></span><br><span class="line">200 Query   EXPLAIN SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;480121&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 26664, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;480121&#39;)) ORDER BY &#96;emp_no&#96; LIMIT 26664, 2 &#x2F;*next chunk boundary*&#x2F;</span><br><span class="line">200 Query   SELECT &#x2F;*!40001 SQL_NO_CACHE *&#x2F; &#96;emp_no&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) ORDER BY &#96;emp_no&#96; DESC LIMIT 1 &#x2F;*last upper boundary*&#x2F;</span><br><span class="line">200 Query   EXPLAIN SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;480121&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;499999&#39;)) LOCK IN SHARE MODE &#x2F;*explain pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   INSERT LOW_PRIORITY IGNORE INTO &#96;employees&#96;.&#96;_employees_new&#96; (&#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96;) SELECT &#96;emp_no&#96;, &#96;birth_date&#96;, &#96;first_name&#96;, &#96;last_name&#96;, &#96;gender&#96;, &#96;hire_date&#96; FROM &#96;employees&#96;.&#96;employees&#96; FORCE INDEX(&#96;PRIMARY&#96;) WHERE ((&#96;emp_no&#96; &gt;&#x3D; &#39;480121&#39;)) AND ((&#96;emp_no&#96; &lt;&#x3D; &#39;499999&#39;)) LOCK IN SHARE MODE &#x2F;*pt-online-schema-change 31797 copy nibble*&#x2F;</span><br><span class="line">200 Query   SHOW WARNINGS</span><br><span class="line">200 Query   SHOW GLOBAL STATUS LIKE &#39;Threads_running&#39;</span><br><span class="line"></span><br><span class="line">-- 当拷贝数据完成之后，及时分析表进行统计信息的收集</span><br><span class="line">200 Query   EXPLAIN SELECT * FROM &#96;employees&#96;.&#96;dept_emp&#96; WHERE 1&#x3D;1</span><br><span class="line">200 Query   SHOW VARIABLES LIKE &#39;version%&#39;</span><br><span class="line">200 Query   SHOW ENGINES</span><br><span class="line">200 Query   SHOW VARIABLES LIKE &#39;innodb_version&#39;</span><br><span class="line">200 Query   ANALYZE TABLE &#96;employees&#96;.&#96;_employees_new&#96; &#x2F;* pt-online-schema-change *&#x2F;</span><br><span class="line"></span><br><span class="line">-- 完成旧表与新表的交换，主要受选项 --alter-foreign-keys-method 取值不同来进行</span><br><span class="line">&#39;</span><br><span class="line">当 --alter-foreign-keys-method&#x3D;drop_swap 时，先禁用外键约束检查，删除旧表，将临时表重命名为原旧表名，完成变更</span><br><span class="line">&#39;</span><br><span class="line">200 Query   SET foreign_key_checks&#x3D;0</span><br><span class="line">200 Query   DROP TABLE IF EXISTS &#96;employees&#96;.&#96;employees&#96;</span><br><span class="line">200 Query   RENAME TABLE &#96;employees&#96;.&#96;_employees_new&#96; TO &#96;employees&#96;.&#96;employees&#96;</span><br><span class="line"></span><br><span class="line">&#39;</span><br><span class="line">当 --alter-foreign-keys-method&#x3D;rebuild_constraints 时，做一个原子性的交换重命名表的操作，删除旧表的操作在删除触发器时一并操作</span><br><span class="line">&#39;</span><br><span class="line">203 Query     ANALYZE TABLE &#96;employees&#96;.&#96;_employees_new&#96; &#x2F;* pt-online-schema-change *&#x2F;</span><br><span class="line">203 Query     RENAME TABLE &#96;employees&#96;.&#96;employees&#96; TO &#96;employees&#96;.&#96;_employees_old&#96;, &#96;employees&#96;.&#96;_employees_new&#96; TO &#96;employees&#96;.&#96;employees&#96;</span><br><span class="line"></span><br><span class="line">-- 删除 3 个触发器</span><br><span class="line">&#39;</span><br><span class="line">当 --alter-foreign-keys-method&#x3D;drop_swap 时，直接删除。</span><br><span class="line">&#39;</span><br><span class="line">200 Query   DROP TRIGGER IF EXISTS &#96;employees&#96;.&#96;pt_osc_employees_employees_del&#96;</span><br><span class="line">200 Query   DROP TRIGGER IF EXISTS &#96;employees&#96;.&#96;pt_osc_employees_employees_upd&#96;</span><br><span class="line">200 Query   DROP TRIGGER IF EXISTS &#96;employees&#96;.&#96;pt_osc_employees_employees_ins&#96;</span><br><span class="line">200 Query   SHOW TABLES FROM &#96;employees&#96; LIKE &#39;\_employees\_new&#39;</span><br><span class="line">201 Quit    </span><br><span class="line">200 Quit</span><br><span class="line"></span><br><span class="line">&#39;</span><br><span class="line">当 --alter-foreign-keys-method&#x3D;rebuild_constraints 时，对于关联的外键表执行重建外键操作，删除旧表，完成变更。</span><br><span class="line">&#39;</span><br><span class="line">203 Query     USE &#96;employees&#96;</span><br><span class="line">203 Query     SHOW CREATE TABLE &#96;employees&#96;.&#96;dept_emp&#96;</span><br><span class="line">203 Query     &#x2F;*!40101 SET @@SQL_MODE :&#x3D; @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; @OLD_QUOTE *&#x2F;</span><br><span class="line">203 Query     ALTER TABLE &#96;employees&#96;.&#96;dept_emp&#96; DROP FOREIGN KEY &#96;_dept_emp_ibfk_1&#96;, ADD CONSTRAINT &#96;__dept_emp_ibfk_1&#96; FOREIGN KEY (&#96;emp_no&#96;) REFERENCES &#96;employees&#96;.&#96;employees&#96; (&#96;emp_no&#96;) ON DELETE CASCADE</span><br><span class="line">203 Query     &#x2F;*!40101 SET @OLD_SQL_MODE :&#x3D; @@SQL_MODE, @@SQL_MODE :&#x3D; &#39;&#39;, @OLD_QUOTE :&#x3D; @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; 1 *&#x2F;</span><br><span class="line"></span><br><span class="line">203 Query     USE &#96;employees&#96;</span><br><span class="line">203 Query     SHOW CREATE TABLE &#96;employees&#96;.&#96;dept_manager&#96;</span><br><span class="line">203 Query     &#x2F;*!40101 SET @@SQL_MODE :&#x3D; @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE :&#x3D; @OLD_QUOTE *&#x2F;</span><br><span class="line">203 Query     ALTER TABLE &#96;employees&#96;.&#96;dept_manager&#96; DROP FOREIGN KEY &#96;__dept_manager_ibfk_1&#96;, ADD CONSTRAINT &#96;dept_manager_ibfk_1&#96; FOREIGN KEY (&#96;emp_no&#96;) REFERENCES &#96;employees&#96;.&#96;employees&#96; (&#96;emp_no&#96;) ON DELETE CASCADE</span><br><span class="line"></span><br><span class="line">203 Query     DROP TABLE IF EXISTS &#96;employees&#96;.&#96;_employees_old&#96;</span><br><span class="line">203 Query     DROP TRIGGER IF EXISTS &#96;employees&#96;.&#96;pt_osc_employees_employees_del&#96;</span><br><span class="line">203 Query     DROP TRIGGER IF EXISTS &#96;employees&#96;.&#96;pt_osc_employees_employees_upd&#96;</span><br><span class="line">203 Query     DROP TRIGGER IF EXISTS &#96;employees&#96;.&#96;pt_osc_employees_employees_ins&#96;</span><br><span class="line">203 Query     SHOW TABLES FROM &#96;employees&#96; LIKE &#39;\_employees\_new&#39;</span><br><span class="line">204 Quit</span><br><span class="line">203 Quit</span><br></pre></td></tr></table></figure><p>整个工作流程总结如下：</p><ol><li><p>查询当前数据库服务器信息，包括参数设置，负载信息等，判断表是否有存在触发器，是否有外键关联；</p></li><li><p>创建一张与旧表结构相同的新表，表名为_旧表名；</p></li><li><p>在新创建的表上做变更操作；</p></li><li><p>旧表上创建 DELETE、UPDATE、INSERT 3 个触发器；</p></li><li><p>拷贝旧表数据到新表上，以 chunk 为单位进行，拷贝期间涉及的行会持有共享读锁；</p></li><li><p>拷贝期间如果旧表如有 DML 操作，则通过触发器更新同步到新表上；</p></li><li><p>当拷贝数据完成之后旧表与新表进行重命名；</p></li><li><p>如果有涉及到外键，根据工具指定选项进行外键处理；</p></li><li><p>删除旧表；</p></li><li><p>删除旧表上触发器。</p></li></ol><h2 id="总结">总结</h2><p>当业务量较大时，修改操作会等待没有数据修改后，执行最后的 rename 操作。因此，在修改表结构时，应该尽量选择在业务相对空闲时，至少修改表上的数据操作较低时，执行较为妥当。由于可能存在一定的风险，在操作之前，建议对数据表进行备份，可以使得操作更安全、可靠。</p><p>pt-online-schema-change 工具对于任意的 DDL 语句都是通过创新表拷贝数据来进行，期间都支持 DML，而 Online DDL 根据 DDL 类型的来区分是否需要对表进行 COPY TABLE 操作，有点类似于工具的创建临时表进行变更，而不需要 COPY TABLE 操作的 DDL 语句在执行期间支持DML。</p><p>关于在对表进行 DDL 时使用 MySQL 原生的 Online DDL 特性还是使用 pt-online-schema-change 工具，通过以上对工具使用的说明与用法测试可以总结如下：</p><ol><li><p>如果 MySQL 版本不支持 Online DDL 特性，比如早于 5.6 版本的 MySQL，则使用 pt-online-schema-change 工具；</p></li><li><p>如果 MySQL 版本支持 Online DDL 特性，则优先考虑使用 Online DDL，因为毕竟原生的支持较好，同时不容易产生不可预知的错误；</p></li><li><p>如果 DDL 语句在使用 Online DDL 时需要进行 COPY TABLE 操作，建议使用 pt-online-schema-change 工具，因为期间支持 DML 操作。</p></li><li><p>如果表存在触发器的情况下，优先使用 Online DDL，对于 MySQL 5.7.2 之后版本则可以 pt-online-schema-change 工具并通过指定选项 --preserve-triggers；</p></li><li><p>如果涉及外键关联的表，优先考虑使用 Online DDL。</p></li></ol><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="http://einverne.github.io/post/2018/03/pt-online-schema-change-mysql-alter-table.html" target="_blank" rel="noopener">http://einverne.github.io/post/2018/03/pt-online-schema-change-mysql-alter-table.html</a></p></li><li><p><a href="https://www.cnblogs.com/dbabd/p/10605629.html" target="_blank" rel="noopener">https://www.cnblogs.com/dbabd/p/10605629.html</a></p></li><li><p><a href="https://www.cnblogs.com/xinysu/p/6758170.html" target="_blank" rel="noopener">https://www.cnblogs.com/xinysu/p/6758170.html</a></p></li><li><p><a href="https://sanyuesha.com/2017/10/19/mysql-online-migration-program-and-tool-compare/" target="_blank" rel="noopener">https://sanyuesha.com/2017/10/19/mysql-online-migration-program-and-tool-compare/</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;众所周知，很多互联网业务都面临着无法停机，需要在线变更数据库结构的情况。但是在线修改数据量较大的表，可能对线上业务产生较大影响，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在线修改大表的表结构执行时间往往不可预估，一般时间较长。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由于修改表结构是表级锁，因此在修改表结构时，影响表写入操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果长时间的修改表结构，中途修改失败，由于修改表结构是一个事务，因此失败后会还原表结构，在这个过程中表都是锁着不可写入。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;修改大表结构容易导致数据库 CPU、IO 等性能消耗，使 MySQL 服务器性能降低。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在线修改大表结构容易导致主从延时，从而影响业务读取。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="MySQL" scheme="https://www.hi-linux.com/categories/MySQL/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="MySQL" scheme="https://www.hi-linux.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>初识 Knative</title>
    <link href="https://www.hi-linux.com/posts/29770.html"/>
    <id>https://www.hi-linux.com/posts/29770.html</id>
    <published>2020-05-23T02:17:00.000Z</published>
    <updated>2020-05-23T14:58:59.776Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-knative">什么是 Knative？</h2><p>Knative 是谷歌开源的 Serverless 架构方案，旨在提供一套简单易用的 Serverless 方案，把 Serverless 标准化。目前参与的公司主要是 Google、Pivotal、IBM、Red Hat，2018 年 7 月 24 日对外发布，当前还处于快速发展的阶段。</p><p>这是 Google Cloud Platform 宣布 knative 时给出的介绍：</p><blockquote><p>Developed in close partnership with Pivotal, IBM, Red Hat, and SAP, Knative pushes Kubernetes-based computing forward by providing the building blocks you need to build and deploy modern, container-based serverless applications.</p></blockquote><p>可以看出，Knative 是为了解决容器为核心的 Serverless 应用的构建、部署和运行的问题。</p><blockquote><p>项目地址：<a href="https://github.com/knative" target="_blank" rel="noopener">https://github.com/knative</a></p></blockquote><p>Serverless 的概念已经出现蛮久了，为了理解 Serverless, 可以从应用开发者的角度来看，使用 Serverless 框架之后，应用开发者的整个操作流程就变成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">~ # 编写 code 和 configuration 文件</span><br><span class="line"></span><br><span class="line">~ # faascli build</span><br><span class="line">~ # faascli deploy</span><br><span class="line">~ # curl http:&#x2F;&#x2F;myapp.com&#x2F;hello</span><br><span class="line">hello, world from Awesome FaaS App!</span><br></pre></td></tr></table></figure><p>可以看到用户只需要编写代码（或者函数），以及配置文件（如何 Build、运行以及访问等声明式信息），然后运行 Build 和 Deploy 就能把应用自动部署到集群（可以是公有云，也可以是私有的集群）。</p><p>其他事情都是 Serverless 平台（比如: 这里的 Knative）自动处理的，这些事情包括：</p><ul><li><p>自动完成代码到容器的构建</p></li><li><p>把应用（或者函数）和特定的事件进行绑定：当事件发生时，自动触发应用（或者函数）</p></li><li><p>网络的路由和流量控制</p></li><li><p>应用的自动伸缩</p></li><li><p>和标准化的 FaaS 不同（只运行特定标准的 Function 代码），Knative 期望能够运行所有的 Workload : Traditional Application、Function、Container。</p></li></ul><p>Knative 建立在 Kubernetes 和 Istio 平台之上，使用 Kubernetes 提供的容器管理能力（Deployment、Replicaset、和 Pods 等），以及 Istio 提供的网络管理功能（Ingress、LB、Dynamic Route 等）。</p><p><img src="https://tva1.sinaimg.cn/large/006tNc79ly1g1qxs8g0vej30qt09smxr.jpg" alt=""></p><a id="more"></a><h2 id="knative-核心概念和原理">Knative 核心概念和原理</h2><p>为了实现 Serverless 应用的管理，Knative 把整个系统分成了三个部分：</p><ul><li><p>Build：构建系统，把用户定义的函数和应用 Build 成容器镜像</p></li><li><p>Serving：服务系统，用来配置应用的路由、升级策略、自动扩缩容等功能</p></li><li><p>Eventing：事件系统，用来自动完成事件的绑定和触发</p></li></ul><h3 id="build-构建系统">Build 构建系统</h3><p>Build 的功能是把用户的代码自动化构建成容器镜像，初次听起来很奇怪，有了 Docker 之后有一个 Dockerfile 不就能构建容器了吗？为什么还需要一个新的 Build 系统？</p><p>Knative 的特别之处在于两点：一是它的构建完全是在 Kubernetes 中进行的，和整个 Kubernetes 生态结合更紧密；另外，它旨在提供一个通用的标准化的构建组件，可以作为其他更大系统中的一部分。</p><p>正如官方文档中的说的那样，是为了定义标准化、可移植、可重用、性能高效的构建方法：</p><blockquote><p>The goal of a Knative build is to provide a standard, portable, reusable, and performance optimized method for defining and running on-cluster container image builds.</p></blockquote><p>Knative 提供了 Build CRD 对象，让用户可以通过 YAML 文件定义构建过程。一个典型的 Build 配置文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: build.knative.dev&#x2F;v1alpha1</span><br><span class="line">kind: Build</span><br><span class="line">metadata:</span><br><span class="line">  name: example-build</span><br><span class="line">spec:</span><br><span class="line">  serviceAccountName: build-auth-example</span><br><span class="line">  source:</span><br><span class="line">    git:</span><br><span class="line">      url: https:&#x2F;&#x2F;github.com&#x2F;example&#x2F;build-example.git</span><br><span class="line">      revision: master</span><br><span class="line">  steps:</span><br><span class="line">  - name: ubuntu-example</span><br><span class="line">    image: ubuntu</span><br><span class="line">    args: [&quot;ubuntu-build-example&quot;, &quot;SECRETS-example.md&quot;]</span><br><span class="line">  steps:</span><br><span class="line">  - image: gcr.io&#x2F;example-builders&#x2F;build-example</span><br><span class="line">    args: [&#39;echo&#39;, &#39;hello-example&#39;, &#39;build&#39;]</span><br></pre></td></tr></table></figure><p>其中，<code>serviceAccountName</code> 是构建过程中需要用到的密码和认证信息（比如连接到 <code>Git Repo</code> 的 <code>SSH Keys</code>、Push 镜像到 Registry 的用户名和密码等）；</p><p>source 是代码信息，比如这里的 <code>Git</code> 地址和分支；steps 是真正运行过程中的各个步骤。</p><p>这个示例中的步骤只是作为 Demo，真正的构建过程一般是 Pull 代码、 Build 镜像和 Push 镜像到 Registry 等逻辑。</p><p>因为大部分的构建过程都是一致的，因此 Knative 还提供了 <code>Build Template</code> 的概念，<code>Build Template</code> 封装了预先定义好的构建过程（就是封装了上面的 steps 过程），并提供了非常简单的配置参数来使用。</p><p>使用 <code>Build Template</code> 构建容器镜像就更简单了，只需要提供代码的地址和镜像名字即可。比如：下面是使用 <code>Google Kaniko</code> 模板构建 Github 源码的 YAML 文件（需要在代码根目录存在 Dockerfile 文件）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: build.knative.dev&#x2F;v1alpha1</span><br><span class="line">kind: Build</span><br><span class="line">metadata:</span><br><span class="line">  name: kaniko-build</span><br><span class="line">spec:</span><br><span class="line">  serviceAccountName: build-bot</span><br><span class="line">  source:</span><br><span class="line">    git:</span><br><span class="line">      url: https:&#x2F;&#x2F;github.com&#x2F;my-user&#x2F;my-repo</span><br><span class="line">      revision: master</span><br><span class="line">  template:</span><br><span class="line">    name: kaniko</span><br><span class="line">    arguments:</span><br><span class="line">    - name: IMAGE</span><br><span class="line">      value: us.gcr.io&#x2F;my-project&#x2F;my-app</span><br></pre></td></tr></table></figure><h3 id="serving服务系统">Serving：服务系统</h3><p>Serving 的核心功能是让应用运行起来提供服务。</p><p>虽然听起来很简单，但这里包括了很多的事情：</p><ul><li><p>自动化启动和销毁容器</p></li><li><p>根据名字生成网络访问相关的 service、ingress 等对象</p></li><li><p>监控应用的请求，并自动扩缩容</p></li><li><p>支持蓝绿发布、回滚功能，方便应用发布流程</p></li></ul><p>Knative Serving 功能是基于 <code>Kubernetes</code> 和 <code>Istio</code> 开发的，它使用 <code>Kubernetes</code> 来管理容器（Deployment、Pod），<code>Istio</code> 来管理网络路由（VirtualService、DestinationRule）。</p><p>因为 Kubernetes 和 Istio 本身的概念非常多，理解和管理起来比较困难，Knative 在此之上提供了更高一层的抽象（这些对应是基于 Kubernetes 的 CRD 实现的）。这些抽象出来的概念对应的关系如下图：</p><p><img src="https://tva1.sinaimg.cn/large/006tNc79ly1g1qxu9218oj31ck0qmwgu.jpg" alt=""></p><ul><li><p>Configuration：应用的最新配置，也就是应用目前期望的状态，对应了 Kubernetes 的容器管理（Deployment）。每次应用升级都会更新 Configuration，而 Knative 也会保留历史版本的记录（图中的 Revision），结合流量管理，Knative 可以让多个不同的版本共同提供服务，方便蓝绿发布和滚动升级</p></li><li><p>Route：应用的路由规则，也就是进来的流量如何访问应用，对应了 Istio 的流量管理（VirtualService）</p></li><li><p>Service：注意这里不是 Kubernetes 中提供服务发现的那个 Service，而是 Knative 自定义的 CRD，它的全称目前是 Services.Serving.Knative.Dev 。单独控制 Route 和 Configuration 就能实现 Serving 的所有功能，但 Knative 更推荐使用 Service 来管理，因为它会自动帮你管理 Route 和 Configuration</p></li></ul><p>一个 hello world 的 Serving 配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: serving.knative.dev&#x2F;v1alpha1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: helloworld-go</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  runLatest:</span><br><span class="line">    configuration:</span><br><span class="line">      revisionTemplate:</span><br><span class="line">        spec:</span><br><span class="line">          container:</span><br><span class="line">            image: docker.io&#x2F;&#123;username&#125;&#x2F;helloworld-go</span><br><span class="line">            env:</span><br><span class="line">            - name: TARGET</span><br><span class="line">              value: &quot;Go Sample v1&quot;</span><br></pre></td></tr></table></figure><p>看起来和 Kubernetes 的 Pod 定义非常类似，但是它会帮你管理 Deployment、Ingress、Service Discovery、Auto Scaling…… 从这个角度来看，可以认为 Knative 提供了更高的抽象，自动帮你封装掉了 Kubernetes 和 Istio 的实现细节。</p><p>下面这张图介绍了 Knative Serving 各组件之间的关系：</p><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1fum2swzqebj31j00to41f.jpg" alt=""></p><ul><li><p>可以看到，每个 Revision 对应了一组 Deployment 管理的 Pod</p></li><li><p>Pod 会自动汇报 Metrics 数据到 Autoscaler，Autoscaler 会根据请求量和资源使用情况修改 Deployment 的 Replicas 数量，从而实现自动扩缩容。Serverless 一个重要的特定是它会 Scale to 0 的，也就是当应用没有流量访问时，它会自动销毁所有的 Pod</p></li><li><p>Activator 比较有趣，它是为了处理 Scale to 0 而出现的。当某个 Revision 后面的 Pod 缩容到 0 时，Route 的流量会指向 Activator，Activator 接收到请求之后会自动拉起 Pod，然后把流量转发过去</p></li><li><p>Route 对象对应了 Istio 的 DestinationRoute 和 VirtualService，决定了访问应用的流量如何路由</p></li></ul><h3 id="eventing事件系统">Eventing：事件系统</h3><p>Serving 系统实现的功能是让应用/函数能够运行起来，并且自动伸缩，那什么时候才会调用应用呢？除了我们熟悉的正常应用调用之外，Serverless 最重要的是基于事件的触发机制，也就是说当某件事发生时，就触发某个特定的函数。</p><p>事件概念的出现，让函数和具体的调用方能够解耦。函数部署出来不用关心谁会调用它，而事件源触发也不用关心谁会处理它。</p><blockquote><p>Note：目前 Serverless 的产品和平台很多，每个地方支持的事件来源以及对事件的定义都是不同的（比如 AWS Lambda 支持很多自己产品的事件源）。Knative 自然也会定义自己的事件类型，除此之外，Knative 还联合 CNCF 在做事件标准化的工作，目前的产出是 CloudEvents 这个项目。</p></blockquote><p>为了让整个事件系统更有扩展性和通用性，Knative 定义了很多事件相关的概念。我们先来介绍一下：</p><ul><li><p>EventSource：事件源，能够产生事件的外部系统</p></li><li><p>Feed：把某种类型的 EventType 和 EventSource 和对应的 Channel 绑定到一起</p></li><li><p>Channel：对消息实现的一层抽象，后端可以使用 <code>Kafka</code>、<code>RabbitMQ</code>、<code>Google PubSub</code> 作为具体的实现。<code>Channel Name</code> 类似于消息集群中的 <code>Topic</code>，可以用来解耦事件源和函数。事件发生后 <code>Sink</code> 到某个 <code>Channel</code> 中，然后 <code>Channel</code> 中的数据会被后端的函数消费</p></li><li><p>Subscription：把 <code>Channel</code> 和后端的函数绑定的一起，一个 <code>Channel</code> 可以绑定到多个 <code>Knative Service</code></p></li></ul><p>它们之间的关系流程图如下：</p><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1fum30a10ynj31jm0v2dkq.jpg" alt=""></p><p>Bus 是 Knative 内部的事件存储层，用户可以选择自己感兴趣的实现，目前支持的方式有：Stub（在内存中实现的简单消息系统）、<code>Kafka</code>、<code>Google PubSub</code>。如果想要事件能够正常运行，必须在 Knative 集群中安装其中一个 Bus 实现方式。</p><p>有了 Bus 之后，我们就可以监听外部的事件了。目前支持的事件源有三个：<code>Github</code>（比如 Merge 事件，Push 事件等），Kubernetes（Events），Google PubSub（消息系统），后面还会不断接入更多的事件源。</p><p>如果要想监听对应的事件源，需要在 Knative 中部署一个 Source Adaptor 的 Pod，它负责从外部的系统中读取事件。</p><p>读取后的事件，会根据用户配置的 Feed 对象（里面包括了事件源和 Channel 的对应关系），找到对应的 Channel，然后把消息发送到这个 Channel 中（Channel 的消息最终是存储在后端的 Bus 系统里的）。</p><p>然后，Knative 会根据 Subscription 的配置，不断从 Channel 中读取事件，然后把事件作为参数调用对应的函数，从而完成了整个事件的流程。</p><h2 id="knative-项目进展">Knative 项目进展</h2><p>Knative 是 2018 年 7 月对外开放，虽然内部已经开发一段时间，但是目前还处于非常早前的阶段，各个版本间的变化也比较大。</p><p>Knative 也是脱产于 Google 和 CNCF，因此整个社区运行方式和目标与之前的 Kubernetes 以及 Istio 非常相似。社区根据组件分成多个 Working Group，每个 Group 独立负责自己的功能，所有的开源活动（文档、视频、代码）都是开放的。另外，CloudEvents 作为 Knative 依赖的标准，目标也是成为 CRI、CNI、CSI 这种类似的标准。</p><p>Knative 社区目前非常活跃，从下面发行版本的速度也可以看得出来，而且入门的文档和教程都已经非常全面。Knative 各版本具体发行时间节点如下：</p><ul><li><p>2018-07-19 v0.1.0 版本发布</p></li><li><p>2018-10-31 v0.2.0 版本发布</p></li><li><p>2018-01-09 v0.3.0 版本发布</p></li><li><p>2019-02-20 v0.4.0 版本发布</p></li><li><p>2019-04-03 v0.5.0 版本发布</p></li><li><p>2019-05-14 v0.6.0 版本发布</p></li><li><p>2019-06-25 v0.7.0 版本发布</p></li><li><p>2019-08-07 v0.8.0 版本发布</p></li><li><p>2019-09-17 v0.9.0 版本发布</p></li></ul><h2 id="knative-应用场景和思考">Knative 应用场景和思考</h2><p>Knative 基于 Kubernetes 和 Istio 的 Serverless 开源实现，目标是提供更高层次的抽象，让开发者无需关注基础设施（虚拟机或者容器，网络配置，容量规划），而专注于业务代码即可。更多关于 Knative 的使用场景可以参考 AWS Lambda 或者其他相关的文档，这里不再赘述，主要讲讲 Knative 目前的局限性或者问题：</p><h3 id="1-性能问题">1. 性能问题</h3><p>性能问题一直是 Serverless 被人诟病的一点，也是目前它不能广泛用于应用服务上的决定性原因。互联网的应用大多数有高并发、高性能的要求，Serverless 整个网络链路很长，容器启停需要额外的时间，还无法满足互联网应用的要求。</p><p>针对这一点，很多 Serverless 框架也在不断地做改进，比如不断精简容器的启动时间、容器启动之后会做缓存等，比如 Nuclio 就宣称自己的平台比 AWS Lambda 要快 10 倍以上。</p><p>相信随着 Serverless 的不断演进，性能问题会不断优化，至于能不能达到互联网应用的要求，还要时间给我们答案。</p><h3 id="2-是否需要-istio-这一层">2. 是否需要 Istio 这一层？</h3><p>基于 Kubernetes 的 Serverless 组件非常多，比如 Kubeless。但是基于 Kubernetes 同时又基于 Istio，目前 Knative 还是第一个这么做的。</p><p>有些人的疑问在于，Knative 真的有必要基于 Istio 来做吗？对于这个问题，我个人的看法是必要的。</p><p>Istio 作为集群基础设施通用网络层的地位已经开始显露，相信在未来的发展中接受度会越来越大，并逐渐巩固自己的地位。虽然现阶段来说，很多人并不非常熟悉 Istio 的情况，但是从长远角度来看，这一点将是 Knative 的一个优势所在。</p><p>另外，基于 Istio 构建自己的 Serverless 服务，也符合目前软件行业不要重复造轮子的思路。Istio 在集群的网络管理方面非常优秀（智能路由、负载均衡、蓝绿发布等），基于 Istio 来做可以让 Knative 不用重复工作就能直接使用 Istio 提供的网络通用功能。</p><h3 id="3-系统复杂度">3. 系统复杂度</h3><p>这一点和上面类似，Knative 下面已经有两个非常复杂的平台：<code>Kubernetes</code> 和 <code>Istio</code>。这两个平台的理解、构建、运维本身就很复杂，如今又加上 <code>Knative</code> 整个平台，需要了解的概念都要几十个，更不要提落地过程中会遇到的各种问题。</p><p>对于公有云来说，<code>Kubernetes</code> 和 <code>Istio</code> 这些底层平台可以交给云供应商来维护（比如 Google Function），但是对于内部构建来说，这无疑提高了整个技术门槛，对系统管理人员的要求更高。</p><p>如何安装部署整个集群？如何对集群做升级？出现问题怎么调试和追踪？怎么更好地和内部的系统对接？这些系统的最佳实践是什么？怎么做性能优化？所有这些问题都需要集群管理人员思考并落实。</p><h3 id="4-函数的可运维性">4. 函数的可运维性？</h3><p>相对于编写微服务来说，单个函数的复杂度已经非常低，但是当非常多的函数需要共同工作的时候，如何管理这些函数就成了一个必须解决的问题。</p><ul><li><p>如何快速找到某个函数？</p></li><li><p>如何知道一个函数的功能是什么？接受的参数是什么？</p></li><li><p>怎么保证函数的升级不会破坏原有的功能？升级之后如何回滚？怎么记录函数的历史版本方面追溯？</p></li><li><p>当有多个函数需要同时工作的时候，怎么定义它们之间的关系？</p></li><li><p>函数出现问题的时候如何调试？</p></li><li><p>对于函数的运维，一般的 Serverless 平台（包括 Knative）都提供了 <code>Logging</code>、<code>Metrics</code>、<code>Tracing</code> 三个方面的功能。默认情况下，Knative 使用 EFK（<code>Elasticsearch</code>、<code>Fluent</code>、<code>Kibana</code>）来收集、查找和分析日志；使用 <code>Prometheus</code> + <code>Grafana</code> 来收集和索引、展示 <code>Metrics</code> 数据；使用 <code>Jaeger</code> 来进行调用关系的 <code>Tracing</code>。</p></li></ul><p>针对 <code>Serverless</code> 衍生出来的运维工具和平台还不够多，如何调试线上问题还没有看到非常好的解决方案。</p><h3 id="5-knative-成熟度">5. Knative 成熟度</h3><ul><li><p>最后一点是关于 Knative 成熟度的，前面已经提到，Knative 目前刚出现不久。虽然整个框架和设计都已经搭好了，但是很多实现都比较初级。这里提几点来说：</p></li><li><p>为了实现 Autoscaling，Knative 在每个 Pod 中添加一个叫做 <code>Queue Proxy</code> 的代理，它会自动把请求的 <code>Metrics</code> 发送给 <code>Autoscaler</code> 组件作为参考。这样一来，整个网络链路上又多了一层，对整个性能势必会有影响，未来的打算是直接使用 <code>Envoy Sidecar</code> 来替换掉 <code>Queue Proxy</code></p></li><li><p>支持的事件源和消息系统还很有限，外部事件只支持 <code>Github</code>、<code>Kubernetes</code> 和 <code>Google PubSub</code>。 这个问题可以慢慢扩展，Knative 本身会实现很常用的事件类型，自定义的事件源用户可以自己实现</p></li><li><p>目前还没有函数的 <code>Pipeline</code> 管理（类似 <code>AWS Lambda Step Functions</code>），多个函数如何协作并没有自己处理。虽然没有在官方文档中看到这方面的 <code>Roadmap</code>，但是以后一定会有这方面的功能（不管是 Knative 本身来做，还是社区作为工具补充来实现）</p></li></ul><p>这方面的问题都不是大事情，随着 Knative 版本的迭代，在很快的时间都能够解决。</p><h1 id="参考资料">参考资料</h1><ol><li><p>Google Cloud Platform 宣布 Knative 发布的博客文章： Google Cloud Platform Blog: Bringing the best of serverless to you</p></li><li><p>the Newstack 上非常好的科普文章： Knative Enables Portable Serverless Platforms on Kubernetes, for Any Cloud - The New Stack</p></li><li><p>Serving 的设计理念：<a href="https://docs.google.com/presentation/d/1CbwVC7W2JaSxRyltU8CS1bIsrIXu1RrZqvnlMlDaaJE/edit#slide=id.g32c674a9d1_0_5" target="_blank" rel="noopener">https://docs.google.com/presentation/d/1CbwVC7W2JaSxRyltU8CS1bIsrIXu1RrZqvnlMlDaaJE/edit#slide=id.g32c674a9d1_0_5</a></p></li><li><p>knative 官方文档：GitHub - knative/docs: Documentation for users of Knative components</p></li><li><p>Google Cloud Next 2018 大会上宣布 knative 的视频 presentation： Kubernetes, Serverless, and You (Cloud Next ’18) - YouTube</p></li><li><p>Google Cloud Knative 产品页面，目前只有最简单的介绍和文档链接</p></li><li><p>什么是 istio</p></li></ol><blockquote><p>来源：Cizixs Blog</p><p>原文：<a href="https://url.cn/5vuvX3Z" target="_blank" rel="noopener">https://url.cn/5vuvX3Z</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Knative？&quot;&gt;什么是 Knative？&lt;/h2&gt;
&lt;p&gt;Knative 是谷歌开源的 Serverless 架构方案，旨在提供一套简单易用的 Serverless 方案，把 Serverless 标准化。目前参与的公司主要是 Google、Pivotal、IBM、Red Hat，2018 年 7 月 24 日对外发布，当前还处于快速发展的阶段。&lt;/p&gt;
&lt;p&gt;这是 Google Cloud Platform 宣布 knative 时给出的介绍：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Developed in close partnership with Pivotal, IBM, Red Hat, and SAP, Knative pushes Kubernetes-based computing forward by providing the building blocks you need to build and deploy modern, container-based serverless applications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以看出，Knative 是为了解决容器为核心的 Serverless 应用的构建、部署和运行的问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/knative&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/knative&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Serverless 的概念已经出现蛮久了，为了理解 Serverless, 可以从应用开发者的角度来看，使用 Serverless 框架之后，应用开发者的整个操作流程就变成了：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;~ # 编写 code 和 configuration 文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;~ # faascli build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;~ # faascli deploy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;~ # curl http:&amp;#x2F;&amp;#x2F;myapp.com&amp;#x2F;hello&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hello, world from Awesome FaaS App!&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以看到用户只需要编写代码（或者函数），以及配置文件（如何 Build、运行以及访问等声明式信息），然后运行 Build 和 Deploy 就能把应用自动部署到集群（可以是公有云，也可以是私有的集群）。&lt;/p&gt;
&lt;p&gt;其他事情都是 Serverless 平台（比如: 这里的 Knative）自动处理的，这些事情包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;自动完成代码到容器的构建&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把应用（或者函数）和特定的事件进行绑定：当事件发生时，自动触发应用（或者函数）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;网络的路由和流量控制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用的自动伸缩&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;和标准化的 FaaS 不同（只运行特定标准的 Function 代码），Knative 期望能够运行所有的 Workload : Traditional Application、Function、Container。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Knative 建立在 Kubernetes 和 Istio 平台之上，使用 Kubernetes 提供的容器管理能力（Deployment、Replicaset、和 Pods 等），以及 Istio 提供的网络管理功能（Ingress、LB、Dynamic Route 等）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNc79ly1g1qxs8g0vej30qt09smxr.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Knative" scheme="https://www.hi-linux.com/tags/Knative/"/>
    
  </entry>
  
  <entry>
    <title>初识 GitOps</title>
    <link href="https://www.hi-linux.com/posts/54495.html"/>
    <id>https://www.hi-linux.com/posts/54495.html</id>
    <published>2020-05-23T02:16:00.000Z</published>
    <updated>2020-05-23T14:58:59.772Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>GitOps 的概念最初来源于 Weaveworks 的联合创始人 Alexis 在 2017 年 8 月发表的一篇博客 GitOps - Operations by Pull Request。文章介绍了 Weaveworks 的工程师如何以 Git 作为事实的唯一真实来源，部署、管理和监控基于 Kubernetes 的 SaaS 应用。</p><p>随后，Weaveworks 在其网站上发表了一系列介绍 GitOps 应用案例和最佳实践的文章，对 GitOps 进行推广。同时，市场上也出现了一批拥抱 GitOps 模式的工具和产品，如 Jenkins X、Argo CD、Weave Flux 等。而 KubeCon EU 2019 中关于 GitOps 的讨论 GitOps and Best Practices for Cloud Native CICD，则让 GitOps 进入到了更多人的视野当中。</p><p>本文将以上述资料为基础，重点介绍如下内容：</p><ol><li>什么是 GitOps？</li><li>推模式和拉模式</li><li>GitOps 的主要优势</li><li>GitOps 关键工具</li></ol><h2 id="什么是-gitops">什么是 GitOps？</h2><p>GitOps 是一种快速、安全的方法，可供开发或运维人员维护和更新运行在 Kubernetes 或其他声明式编排框架中的复杂应用。</p><h3 id="gitops-四项原则">GitOps 四项原则</h3><h4 id="以声明的方式描述整个系统">以声明的方式描述整个系统</h4><p>借助 Kubernetes、Terraform 等工具，我们只需要声明系统想要达到的目标状态，工具会驱动系统向目标状态逼近。声明意味着系统状态由一组事实而不是一组指令保证，方便进行维护。当我们将声明信息存储在 Git 中后，系统状态便具备了唯一的事实来源。这样，我们可以轻松地部署和回滚应用。更重要的是，当灾难发生时，群集的基础架构也能够可靠且快速地再现。</p><h4 id="系统的目标状态通过-git-进行版本控制">系统的目标状态通过 Git 进行版本控制</h4><p>通过将系统的目标状态存储在具有版本控制功能的系统中，并作为唯一的事实来源，我们能够从中派生和驱动一切。</p><ol><li>通过 pull request 发起对目标状态的变更申请，状态变化清晰呈现，变更 review 简单明了。</li><li>系统的每一次变更都对应着一条 git commit，变更行为可审计。</li><li>回滚操作只需要使用git revert命令把目标状态恢复到前一个状态。</li></ol><a id="more"></a><h4 id="对目标状态的变更批准后将自动应用到系统">对目标状态的变更批准后将自动应用到系统</h4><p>一旦将声明的状态保存在 Git 中，下一步就是允许对该状态的任何变更都能自动地应用于系统，这样可以极大地提升产品交付速度。更重要的是，GitOps 采用拉模式更新系统状态，将做什么和怎么做分开，这样能够更加有效地划分出系统的安全边界。</p><h4 id="驱动收敛-amp-上报偏离">驱动收敛 &amp; 上报偏离</h4><p>GitOps 中包含一个操作的反馈和控制循环。它将持续地比较系统的实际状态和 Git 中的目标状态，如果在预期时间内状态仍未收敛，便会触发告警并上报差异。同时，该循环让系统具备了自愈能力。自愈不仅仅意味着节点或 pod 失败， 这些由 Kubernetes 处理，在更广泛的角度，它能修正一些非预期的操作造成的系统状态偏离。下图展示了 GitOps 按控制论思想构建的闭环控制系统。</p><p><img src="https://i.loli.net/2019/08/07/t9gWsdfxYypeH8i.png" alt=""></p><h3 id="gitops-的简洁定义">GitOps 的简洁定义</h3><p>进一步，可以将 GitOps 总结成以下两点：</p><blockquote><ol><li><p>An operating model for Kubernetes and other cloud native technologies, providing a set of best practices that unify deployment, management and monitoring for containerized clusters and applications.</p></li><li><p>A path towards a developer experience for managing applications; where end-to-end CICD pipelines and git workflows are applied to both operations, and development.</p></li></ol></blockquote><h2 id="推模式和拉模式">推模式和拉模式</h2><p>本章将介绍交付流水线中的推模式和拉模式，并解释为何 GitOps 选用拉模式来构建流水线。</p><h3 id="cicd-流水线">CI/CD 流水线</h3><p>目前大多数 CI/CD 工具都基于推模式建交付流水线。代码被合并到主分支后会触发 CI 系统进行构建和一系列的测试，并将新生成的镜像推送至镜像仓库，最后再通过 kubectl set image、helm upgrade、ksonnet apply 等方式将新版本直接应用到系统，整个流程如下图所示。</p><p><img src="https://i.loli.net/2019/08/07/kZQe7SMJgYDh1Xr.png" alt=""></p><p>虽然这样的方式自动化程度很高，但对它进行审视后会发现如下问题：</p><ol><li><p>跨越安全边界共享秘钥 - 在推模式下，为了让 CI 系统能够自动地部署应用，需要将集群的访问秘钥共享给它。虽然可以通过一些措施进行防护，但毕竟还是将秘钥暴露在了可信度较低的安全上下文中。这种做法扩大了攻击面，会给系统带来潜在的安全风险。</p></li><li><p>回滚操作复杂 - 如果通过 CI 任务完成一次部署后，系统出现异常，你将如何知道应该回滚到哪一个版本？你可能需要仔细查看构建日志才能找到答案。</p></li><li><p>难以快速重建集群 - 在集群完全崩溃的情况下进行重建，如何确定需要部署的每个应用的版本？你可能需要重新跑一遍 CI 任务。</p></li></ol><h3 id="gitops-流水线">GitOps 流水线</h3><p>GitOps 基于拉模式构建交付流水线。此时，开发人员发布一个新功能的流程如下：</p><ol><li><p>通过 pull request 向主分支提交包含新功能的代码。</p></li><li><p>代码审核通过后将被合并至主分支。</p></li><li><p>合并行为将触发 CI 系统进行构建和一系列的测试，并将新生成的镜像推送至镜像仓库。</p></li><li><p>GitOps 检测到有新的镜像，会提取最新的镜像标记，然后同步到 Git 配置仓库的清单中。</p></li><li><p>GitOps 检测到集群状态过期，会从配置仓库中拉取更新后的清单，并将包含新功能的镜像部署到集群里。</p></li></ol><p>通过为不同的集群创建各自的子目录或分支，可以轻松地将该模式拓展到多集群环境。</p><p><img src="https://i.loli.net/2019/08/07/6Azp5f4UXLKbxyI.png" alt=""></p><p>接下来让我们看看 GitOps 流水线如何解决推式流水线中存在的那些问题。</p><ol><li><p>部署在集群内部的 GitOps 模块负责更新集群，这样就避免了集群 API 和秘钥的跨边界暴露。更重要的是，流水线中每个逻辑单元的写操作都被限定在了安全边界以内，职责划分清晰。</p></li><li><p>由于每一次变更都对应着一条 git commit，回滚操作只需要简单的把目标状态恢复到前一个状态。</p></li><li><p>由于在 Git 的配置仓库中保留了集群的目标状态，如果集群完全崩溃，可以基于仓库中的清单快速重建集群。</p></li></ol><h2 id="gitops-的主要优势">GitOps 的主要优势</h2><p>经过上面两章的介绍，可以将 GitOps 的优势总结如下：</p><ol><li><p>提高生产力 - 采用集成了反馈控制循环的持续部署流水线可以大大提升新功能的发布速度。</p></li><li><p>提升开发者体验 - 开发者可以使用熟悉的工具 Git 去发布新功能，而无需了解复杂的部署交付流程。新入职的员工可以在几天内快速上手，从而提高工作效率。</p></li><li><p>行为可审计 - 使用 Git 工作流管理集群，天然能够获得所有变更的审计日志，满足合规性需求，提升系统的安全与稳定性。</p></li><li><p>更高的可靠性 - 借助 Git 的还原（revert）、分叉（fork）功能，可以实现稳定且可重现的回滚。由于整个系统的描述都存放在 Git 中，我们有了唯一的真实来源，这能大大缩短集群完全崩溃后的恢复时间。</p></li><li><p>一致性和标准化 - 由于 GitOps 为基础设置、应用程序、Kubernetes 插件的部署变更提供了统一的模型，因此我们可以在整个组织中实现一致的端到端工作流。不仅仅是 CI/CD 流水线由 pull request 驱动，运维任务也可以通过 Git 完全重现。</p></li><li><p>更强的安全保证 - 得益于 Git 内置的安全特性，保障了存放在 Git 中的集群目标状态声明的安全性。</p></li></ol><h2 id="gitops-关键工具">GitOps 关键工具</h2><p>GitOps 的概念来源于 Weaveworks，但它并没有和特定的公司或工具绑定。下面列出了一些实现 GitOps 模式可选用的工具。</p><ul><li><p>Infrastructure as Code &amp; Configuration as Code</p><ul><li>Terraform</li><li>CloudFormation</li><li>ROS</li><li>Kubernetes</li><li>Chef</li><li>Ansible</li></ul></li><li><p>版本控制工具</p><ul><li>GitLab</li><li>Bitbucket</li></ul></li><li><p>敏感信息管理</p><ul><li>Sealed Secrets</li><li>SOPS</li><li>Vault</li></ul></li><li><p>状态比较工具</p><ul><li>Kubediff</li></ul></li><li><p>交付流水线</p><ul><li>Jenkins X</li><li>Argo CD</li><li>Weave Flux</li><li>Spinnaker</li></ul></li></ul><h2 id="总结">总结</h2><p>Flickr 的工程师 John Allspaw 和 Paul Hammond 在 Velocity Conf 2009 上发表的演讲 10+ Deploys Per Day: Dev and Ops Cooperation at Flickr 开启了 DevOps 时代的序幕。它是人们追求以更高的频率发布高质量的软件的必然产物。</p><p>进入云原生时代后，产品的基础设施、系统架构和运维方式都发生了很大变化。为此，GitOps 对 DevOps 理念进行了扩展，它吸收了 DevOps 文化中协作、试验、快速反馈、持续改进等思想，并以 Git 作为事实的来源和链接的桥梁，旨在简化云原生时代基础设施和应用程序的部署与管理方式，实现产品更快、更频繁、更稳定的交付。</p><h2 id="参考资料">参考资料</h2><ol><li>GitOps - Operations by Pull Request</li><li>Feedback and Control - an Essential GitOps Component</li><li>What DevOps is to the Cloud, GitOps is to Cloud Native</li></ol><blockquote><p>来源：segmentfault</p><p>原文：<a href="http://t.cn/AiTLDq6K" target="_blank" rel="noopener">http://t.cn/AiTLDq6K</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GitOps 的概念最初来源于 Weaveworks 的联合创始人 Alexis 在 2017 年 8 月发表的一篇博客 GitOps - Operations by Pull Request。文章介绍了 Weaveworks 的工程师如何以 Git 作为事实的唯一真实来源，部署、管理和监控基于 Kubernetes 的 SaaS 应用。&lt;/p&gt;
&lt;p&gt;随后，Weaveworks 在其网站上发表了一系列介绍 GitOps 应用案例和最佳实践的文章，对 GitOps 进行推广。同时，市场上也出现了一批拥抱 GitOps 模式的工具和产品，如 Jenkins X、Argo CD、Weave Flux 等。而 KubeCon EU 2019 中关于 GitOps 的讨论 GitOps and Best Practices for Cloud Native CICD，则让 GitOps 进入到了更多人的视野当中。&lt;/p&gt;
&lt;p&gt;本文将以上述资料为基础，重点介绍如下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;什么是 GitOps？&lt;/li&gt;
&lt;li&gt;推模式和拉模式&lt;/li&gt;
&lt;li&gt;GitOps 的主要优势&lt;/li&gt;
&lt;li&gt;GitOps 关键工具&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;什么是-GitOps？&quot;&gt;什么是 GitOps？&lt;/h2&gt;
&lt;p&gt;GitOps 是一种快速、安全的方法，可供开发或运维人员维护和更新运行在 Kubernetes 或其他声明式编排框架中的复杂应用。&lt;/p&gt;
&lt;h3 id=&quot;GitOps-四项原则&quot;&gt;GitOps 四项原则&lt;/h3&gt;
&lt;h4 id=&quot;以声明的方式描述整个系统&quot;&gt;以声明的方式描述整个系统&lt;/h4&gt;
&lt;p&gt;借助 Kubernetes、Terraform 等工具，我们只需要声明系统想要达到的目标状态，工具会驱动系统向目标状态逼近。声明意味着系统状态由一组事实而不是一组指令保证，方便进行维护。当我们将声明信息存储在 Git 中后，系统状态便具备了唯一的事实来源。这样，我们可以轻松地部署和回滚应用。更重要的是，当灾难发生时，群集的基础架构也能够可靠且快速地再现。&lt;/p&gt;
&lt;h4 id=&quot;系统的目标状态通过-Git-进行版本控制&quot;&gt;系统的目标状态通过 Git 进行版本控制&lt;/h4&gt;
&lt;p&gt;通过将系统的目标状态存储在具有版本控制功能的系统中，并作为唯一的事实来源，我们能够从中派生和驱动一切。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过 pull request 发起对目标状态的变更申请，状态变化清晰呈现，变更 review 简单明了。&lt;/li&gt;
&lt;li&gt;系统的每一次变更都对应着一条 git commit，变更行为可审计。&lt;/li&gt;
&lt;li&gt;回滚操作只需要使用git revert命令把目标状态恢复到前一个状态。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="GitOps" scheme="https://www.hi-linux.com/tags/GitOps/"/>
    
  </entry>
  
  <entry>
    <title>浅谈 HTTPS 工作原理</title>
    <link href="https://www.hi-linux.com/posts/7040.html"/>
    <id>https://www.hi-linux.com/posts/7040.html</id>
    <published>2020-05-23T02:15:00.000Z</published>
    <updated>2020-05-23T14:58:59.775Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>随着 HTTPS 建站的成本下降，现在大部分的网站都已经开始用上 HTTPS 协议。大家都知道 HTTPS 比 HTTP 安全，也听说过与 HTTPS 协议相关的概念有 SSL 、非对称加密、 CA证书等，但对于以下灵魂三拷问可能就答不上了：</p><ol><li><p>为什么用了 HTTPS 就是安全的？</p></li><li><p>HTTPS 的底层原理如何实现？</p></li><li><p>用了 HTTPS 就一定安全吗？</p></li></ol><p>本文将层层深入，从原理上把 HTTPS 的安全性讲透。</p><h2 id="https-的实现原理">HTTPS 的实现原理</h2><p>大家可能都听说过 HTTPS 协议之所以是安全的是因为 HTTPS 协议会对传输的数据进行加密，而加密过程是使用了非对称加密实现。但其实，HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段。</p><p>HTTPS的整体过程分为证书验证和数据传输阶段，具体的交互过程如下：</p><p><img src="https://static.blog.leapmie.com/2019/11/1378987910.png" alt=""></p><ol><li>证书验证阶段</li></ol><ul><li><p>浏览器发起 HTTPS 请求</p></li><li><p>服务端返回 HTTPS 证书</p></li><li><p>客户端验证证书是否合法，如果不合法则提示告警</p></li></ul><ol start="2"><li>数据传输阶段</li></ol><ul><li><p>当证书验证合法后，在本地生成随机数</p></li><li><p>通过公钥加密随机数，并把加密后的随机数传输到服务端</p></li><li><p>服务端通过私钥对随机数进行解密</p></li><li><p>服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输</p></li></ul><a id="more"></a><h2 id="为什么数据传输是用对称加密">为什么数据传输是用对称加密？</h2><p>首先，非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的；</p><p>另外，在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。</p><h2 id="为什么需要-ca-认证机构颁发证书">为什么需要 CA 认证机构颁发证书？</h2><p>HTTP 协议被认为不安全是因为传输过程容易被监听者勾线监听、伪造服务器，而 HTTPS 协议主要解决的便是网络传输的安全性问题。</p><p>首先我们假设不存在认证机构，任何人都可以制作证书，这带来的安全风险便是经典的“中间人攻击”问题。<br>“中间人攻击”的具体过程如下：</p><p><img src="https://static.blog.leapmie.com/2019/11/2410496311.png" alt=""></p><p>过程原理：</p><ol><li><p>本地请求被劫持（如DNS劫持等），所有请求均发送到中间人的服务器</p></li><li><p>中间人服务器返回中间人自己的证书</p></li><li><p>客户端创建随机数，通过中间人证书的公钥对随机数加密后传送给中间人，然后凭随机数构造对称加密对传输内容进行加密传输</p></li><li><p>中间人因为拥有客户端的随机数，可以通过对称加密算法进行内容解密</p></li><li><p>中间人以客户端的请求内容再向正规网站发起请求</p></li><li><p>因为中间人与服务器的通信过程是合法的，正规网站通过建立的安全通道返回加密后的数据</p></li><li><p>中间人凭借与正规网站建立的对称加密算法对内容进行解密</p></li><li><p>中间人通过与客户端建立的对称加密算法对正规内容返回的数据进行加密传输</p></li><li><p>客户端通过与中间人建立的对称加密算法对返回结果数据进行解密</p></li></ol><p>由于缺少对证书的验证，所以客户端虽然发起的是 HTTPS 请求，但客户端完全不知道自己的网络已被拦截，传输内容被中间人全部窃取。</p><h2 id="浏览器是如何确保-ca-证书的合法性">浏览器是如何确保 CA 证书的合法性？</h2><ol><li>证书包含什么信息？</li></ol><p>颁发机构信息<br>公钥<br>公司信息<br>域名<br>有效期<br>指纹<br>…</p><ol start="2"><li>证书的合法性依据是什么？</li></ol><p>首先，权威机构是要有认证的，不是随便一个机构都有资格颁发证书，不然也不叫做权威机构。另外，证书的可信性基于信任制，权威机构需要对其颁发的证书进行信用背书，只要是权威机构生成的证书，我们就认为是合法的。所以权威机构会对申请者的信息进行审核，不同等级的权威机构对审核的要求也不一样，于是证书也分为免费的、便宜的和贵的。</p><ol start="3"><li>浏览器如何验证证书的合法性？</li></ol><p>浏览器发起 HTTPS 请求时，服务器会返回网站的 SSL 证书，浏览器需要对证书做以下验证：</p><ul><li><p>验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；</p></li><li><p>判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；</p></li></ul><p><img src="https://static.blog.leapmie.com/2019/11/1148530856.png" alt=""></p><ul><li><p>判断证书是否被篡改。需要与 CA 服务器进行校验；</p></li><li><p>判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率</p></li></ul><p>以上任意一步都满足的情况下浏览器才认为证书是合法的。</p><blockquote><p>这里插一个我想了很久的但其实答案很简单的问题：</p><p>既然证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？</p><p>其实这就是非加密对称中公私钥的用处，虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。</p></blockquote><ol start="4"><li>只有认证机构可以生成证书吗？</li></ol><p>如果需要浏览器不提示安全风险，那只能使用认证机构签发的证书。但浏览器通常只是提示安全风险，并不限制网站不能访问，所以从技术上谁都可以生成证书，只要有证书就可以完成网站的 HTTPS 传输。例如早期的 12306 采用的便是手动安装私有证书的形式实现 HTTPS 访问。</p><p><img src="https://static.blog.leapmie.com/2019/11/1504265182.png" alt=""></p><h2 id="本地随机数被窃取怎么办">本地随机数被窃取怎么办？</h2><p>证书验证是采用非对称加密实现，但是传输过程是采用对称加密，而其中对称加密算法中重要的随机数是由本地生成并且存储于本地的，HTTPS 如何保证随机数不会被窃取？</p><p>其实 HTTPS 并不包含对随机数的安全保证，HTTPS 保证的只是传输过程安全，而随机数存储于本地，本地的安全属于另一安全范畴，应对的措施有安装杀毒软件、反木马、浏览器升级修复漏洞等。</p><h2 id="用了-https-会被抓包吗">用了 HTTPS 会被抓包吗？</h2><p>HTTPS 的数据是加密的，常规下抓包工具代理请求后抓到的包内容是加密状态，无法直接查看。</p><p>但是，正如前文所说，浏览器只会提示安全风险，如果用户授权仍然可以继续访问网站，完成请求。因此，只要客户端是我们自己的终端，我们授权的情况下，便可以组建中间人网络，而抓包工具便是作为中间人的代理。通常 HTTPS 抓包工具的使用方法是会生成一个证书，用户需要手动把证书安装到客户端中，然后终端发起的所有请求通过该证书完成与抓包工具的交互，然后抓包工具再转发请求到服务器，最后把服务器返回的结果在控制台输出后再返回给终端，从而完成整个请求的闭环。</p><p>既然 HTTPS 不能防抓包，那 HTTPS 有什么意义？</p><p>HTTPS 可以防止用户在不知情的情况下通信链路被监听，对于主动授信的抓包操作是不提供防护的，因为这个场景用户是已经对风险知情。要防止被抓包，需要采用应用级的安全防护，例如采用私有的对称加密，同时做好移动端的防反编译加固，防止本地算法被破解。</p><h2 id="总结">总结</h2><p>以下用简短的 Q&amp;A 形式进行全文总结：</p><ul><li>Q: HTTPS 为什么安全？</li></ul><p>A: 因为 HTTPS 保证了传输安全，防止传输过程被监听、防止数据被窃取，可以确认网站的真实性。</p><ul><li>Q: HTTPS 的传输过程是怎样的？</li></ul><p>A: 客户端发起 HTTPS 请求，服务端返回证书，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数，通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。</p><ul><li>Q: 为什么需要证书？</li></ul><p>A: 防止”中间人“攻击，同时可以为网站提供身份证明。</p><ul><li>Q: 使用 HTTPS 会被抓包吗？</li></ul><p>A: 会被抓包，HTTPS 只防止用户在不知情的情况下通信被监听，如果用户主动授信，是可以构建“中间人”网络，代理软件可以对传输内容进行解密。</p><p>最后顺手分享一张学习 HTTPS  的过程图。</p><p><img src="https://static.blog.leapmie.com/2019/11/3247911170.jpg" alt=""></p><blockquote><p>本文转载自：「leapMie 的博客 」，原文：<a href="https://url.cn/5lThTrI%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5lThTrI，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着 HTTPS 建站的成本下降，现在大部分的网站都已经开始用上 HTTPS 协议。大家都知道 HTTPS 比 HTTP 安全，也听说过与 HTTPS 协议相关的概念有 SSL 、非对称加密、 CA证书等，但对于以下灵魂三拷问可能就答不上了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为什么用了 HTTPS 就是安全的？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HTTPS 的底层原理如何实现？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用了 HTTPS 就一定安全吗？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文将层层深入，从原理上把 HTTPS 的安全性讲透。&lt;/p&gt;
&lt;h2 id=&quot;HTTPS-的实现原理&quot;&gt;HTTPS 的实现原理&lt;/h2&gt;
&lt;p&gt;大家可能都听说过 HTTPS 协议之所以是安全的是因为 HTTPS 协议会对传输的数据进行加密，而加密过程是使用了非对称加密实现。但其实，HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段。&lt;/p&gt;
&lt;p&gt;HTTPS的整体过程分为证书验证和数据传输阶段，具体的交互过程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.blog.leapmie.com/2019/11/1378987910.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;证书验证阶段&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;浏览器发起 HTTPS 请求&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务端返回 HTTPS 证书&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;客户端验证证书是否合法，如果不合法则提示告警&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;数据传输阶段&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;当证书验证合法后，在本地生成随机数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过公钥加密随机数，并把加密后的随机数传输到服务端&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务端通过私钥对随机数进行解密&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="HTTPS" scheme="https://www.hi-linux.com/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>5 分钟读透 HTTP 的前世今生</title>
    <link href="https://www.hi-linux.com/posts/49917.html"/>
    <id>https://www.hi-linux.com/posts/49917.html</id>
    <published>2020-05-23T02:14:00.000Z</published>
    <updated>2020-05-23T14:37:23.949Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>HTTP (Hypertext transfer protocol) 翻译成中文是超文本传输协议，是互联网上重要的一个协议。由欧洲核子研究委员会 CERN 的英国工程师 Tim Berners-Lee v 发明的，同时他也是 WWW 的发明人，最初的主要是用于传递通过 HTML 封装过的数据。在 1991 年发布了 HTTP 0.9 版，在 1996 年发布 1.0 版。1997 年是 1.1 版，1.1 版也是到今天为止传输最广泛的版本（初始 RFC 2068 在 1997 年发布， 然后在 1999 年被 RFC 2616 取代，再在 2014 年被 RFC 7230/7231/7232/7233/7234/7235 取代）。2015 年发布了 2.0 版，其极大的优化了 HTTP/1.1 的性能和安全性，而 2018 年发布的 3.0 版，继续优化 HTTP/2，激进地使用 UDP 取代 TCP 协议。目前，HTTP/3 在 2019 年 9 月 26 日 被 Chrome、Firefox、和 Cloudflare 支持。所以我想写下这篇文章，简单地说一下 HTTP 的前世今生，让大家学到一些知识，并希望可以在推动一下 HTTP 标准协议的发展。</p><h2 id="http-09-10">HTTP 0.9 / 1.0</h2><p>0.9 和 1.0 这两个版本，就是最传统的 Request – Response 的模式了。HTTP 0.9 版本的协议简单到极点，请求时不支持请求头，只支持 GET 方法，没了。HTTP 1.0 扩展了 0.9 版，其中主要增加了几个变化：</p><ul><li><p>在请求中加入了 HTTP 版本号，如：GET /coolshell/index.html HTTP/1.0</p></li><li><p>HTTP 开始有 Header了，不管是 Request 还是 Response 都有 Header 了。</p></li><li><p>增加了 HTTP Status Code 标识相关的状态码。</p></li><li><p>还有 Content-Type 可以传输其它的文件了。</p></li></ul><p>我们可以看到，HTTP 1.0 开始让这个协议变得很文明了，一种工程文明。因为：</p><ul><li><p>一个协议有没有版本管理，是一个工程化的象征。</p></li><li><p>Header 可以说是把元数据和业务数据解耦，也可以说是控制逻辑和业务逻辑的分离。</p></li><li><p>Status Code 的出现可以让请求双方以及第三方的监控或管理程序有了统一的认识。最关键是还是控制错误和业务错误的分离。</p></li></ul><blockquote><p>注：国内很多公司 HTTP 无论对错只返回 200，这种把 HTTP Status Code 全部抹掉完全是一种工程界的倒退</p></blockquote><p>但是，HTTP 1.0 性能上有一个很大的问题，那就是每请求一个资源都要新建一个 TCP 链接。而且是串行请求，所以就算网络变快了，打开网页的速度也还是很慢。所以，HTTP 1.0 应该是一个必须要淘汰的协议了。</p><a id="more"></a><h2 id="http11">HTTP/1.1</h2><p>HTTP/1.1 主要解决了 HTTP 1.0 的网络性能的问题，以及增加了一些新的东西：</p><ul><li><p>可以设置 Keepalive 来让 HTTP 重用 TCP 链接，重用 TCP 链接可以省了每次请求都要在广域网上进行的 TCP 的三次握手的巨大开销。这是所谓的 “<strong>HTTP 长链接</strong>” 或是 “<strong>请求响应式的 HTTP 持久链接</strong>”。英文叫 HTTP Persistent Connection.</p></li><li><p>然后支持 Pipeline 网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。（注：非幂等的 POST 方法或是有依赖的请求是不能被 Pipeline 化的）</p></li><li><p>支持 Chunked Responses，也就是说，在 Response 的时候，不必说明 Content-Length 这样，客户端就不能断连接，直到收到服务端的 EOF 标识。这种技术又叫 “<strong>服务端 Push 模型</strong>”，或是 “<strong>服务端 Push 式的 HTTP 持久链接</strong>”</p></li><li><p>还增加了 Cache Control 机制。</p></li><li><p>协议头注增加了 Language、Encoding、Type 等等头，让客户端可以跟服务器端进行更多的协商。</p></li><li><p>还正式加入了一个很重要的头 —— HOST 这样的话，服务器就知道你要请求哪个网站了。因为可以有多个域名解析到同一个 IP 上，要区分用户是请求的哪个域名，就需要在 HTTP 的协议中加入域名的信息，而不是被 DNS 转换过的 IP 信息。</p></li><li><p>正式加入了 OPTIONS 方法，其主要用于 CORS – Cross Origin Resource Sharing 应用。</p></li></ul><p>HTTP/1.1 应该分成两个时代，一个是 2014 年前，一个是 2014 年后。因为 2014 年 HTTP/1.1 有了一组 RFC（7230 /7231/7232/7233/7234/7235），这组 RFC 又叫 “HTTP/2 预览版”。其中影响 HTTP 发展的是两个大的需求：</p><ul><li><p>一个需要是加大了 HTTP 的安全性，这样就可以让 HTTP 应用得广泛。比如，使用 TLS 协议。</p></li><li><p>另一个是让 HTTP 可以支持更多的应用，在 HTTP/1.1 下，HTTP 已经支持四种网络协议：</p><ul><li><p>传统的短链接。</p></li><li><p>可重用 TCP 的的长链接模型。</p></li><li><p>服务端 Push 的模型。</p></li><li><p>WebSocket 模型。</p></li></ul></li></ul><p>自从 2005 年以来，整个世界的应用 API 越来多，这些都造就了整个世界在推动 HTTP 的前进。我们可以看到，<strong>自 2014 的 HTTP/1.1 以来，这个世界基本的应用协议的标准基本上都是向 HTTP 看齐了。也许 2014 年前，还有一些专用的 RPC 协议。但是 2014 年以后，HTTP 协议的增强，让我们实在找不出什么理由不向标准靠拢，还要重新发明轮子了。</strong></p><h2 id="http2">HTTP/2</h2><p>虽然 HTTP/1.1 已经开始变成应用层通讯协议的一等公民了，但是还是有性能问题，虽然 HTTP/1.1 可以重用 TCP 链接，但是请求还是一个一个串行发的，需要保证其顺序。然而，大量的网页请求中都是些资源类的东西，这些东西占了整个 HTTP 请求中最多的传输数据量。所以，理论上来说，如果能够并行这些请求，那就会增加更大的网络吞吐和性能。</p><p>另外，HTTP/1.1 传输数据时，是以文本的方式。借助耗 CPU 的 Zip 压缩的方式减少网络带宽，但是耗了前端和后端的 CPU。这也是为什么很多 RPC 协议诟病 HTTP 的一个原因，就是数据传输的成本比较大。</p><p>其实，在 2010 年时，Google 就在搞一个实验型的协议，这个协议叫 SPDY。这个协议成为了 HTTP/2 的基础（也可以说成 HTTP/2 就是 SPDY 的复刻）。HTTP/2 基本上解决了之前的这些性能问题，其和 HTTP/1.1 最主要的不同是：</p><ul><li><p>HTTP/2 是一个二进制协议，增加了数据传输的效率。</p></li><li><p>HTTP/2 是可以在一个 TCP 链接中并发请求多个 HTTP 请求，移除了 HTTP/1.1 中的串行请求。</p></li><li><p>HTTP/2 会压缩头，如果你同时发出多个请求，他们的头是一样的或是相似的。那么，协议会帮你消除重复的部分。这就是所谓的 HPACK 算法（参看 RFC 7541 附录 A）</p></li><li><p>HTTP/2 允许服务端在客户端放 Cache，又叫服务端 Push，也就是说，你没有请求的东西，我服务端可以先送给你放在你的本地缓存中。比如，你请求 X，我服务端知道 X 依赖于 Y，虽然你没有的请求 Y，但我把 Y 跟着 X 的请求一起返回客户端。</p></li></ul><p>对于这些性能上的改善，在 Medium 上有篇文章 “ HTTP/2: the difference between HTTP/1.1, benefits and how to use it (<a href="https://url.cn/5Ij0hXz" target="_blank" rel="noopener">https://url.cn/5Ij0hXz</a>) ” 你可看一下相关的细节说明和测试。</p><p>当然，还需要注意到的是 HTTP/2 的协议复杂度比之前所有的 HTTP 协议的复杂度都上升了许多许多。其内部还有很多看不见的东西，比如其需要维护一个 “优先级树” 来用于来做一些资源和请求的调度和控制。如此复杂的协议，自然会产生一些不同的声音，或是降低协议的可维护和可扩展性。所以也有一些争议。尽管如此，HTTP/2 还是很快地被世界所采用。</p><p>HTTP/2 是 2015 年推出的。其发布后，Google 宣布移除对 SPDY 的支持，拥抱标准的 HTTP/2。过了一年后，就有 8.7% 的网站开启了 HTTP/2，根据这份报告 (<a href="https://url.cn/5YOuflM" target="_blank" rel="noopener">https://url.cn/5YOuflM</a>)  ，截止至本文发布时（2019 年 10 月 1 日）， 在全世界范围内已经有 41% 的网站开启了 HTTP/2。</p><p>HTTP/2 的官方组织在 Github 上维护了一份各种语言对 HTTP/2 的实现列表，大家可以去看看。</p><p>我们可以看到，HTTP/2 在性能上对 HTTP 有质的提高。所以，HTTP/2 被采用的也很快。<strong>如果你在你的公司内负责架构的话，HTTP/2 是你一个非常重要的需要推动的一个事。除了因为性能上的问题，推动标准落地也是架构师的主要职责。因为，你企业内部的架构越标准，你可以使用到开源软件，或是开发方式就会越有效率。跟随着工业界的标准的发展，你的企业会非常自然的享受到标准所带来的红利。</strong></p><h2 id="http3">HTTP/3</h2><p>然而，这个世界没有完美的解决方案。HTTP/2 也不例外，其主要的问题是：若干个 HTTP 的请求在复用一个 TCP 的连接，底层的 TCP 协议是不知道上层有多少个 HTTP 的请求的。所以，一旦发生丢包，造成的问题就是所有的 HTTP 请求都必需等待这个丢了的包被重传回来，哪怕丢的那个包不是我这个 HTTP 请求的。因为 TCP 底层是没有这个知识了。</p><p>这个问题又叫 Head-of-Line Blocking 问题，这也是一个比较经典的流量调度的问题。这个问题最早主要的发生的交换机上。下图来自 Wikipedia。</p><p><img src="https://coolshell.cn/wp-content/uploads/2019/10/HOL_blocking.png" alt=""></p><p>图中，左边的是输入队列。其中的 1、2、3、4 表示四个队列，四个队列中的 1、2、3、4 要去右边的 Output 的端口号。此时，第一个队列和第三个队列都要写右边的第四个端口。然后，一个时刻只能处理一个包。所以，一个队列只能在那等另一个队列写完。其此时的 3 号或 1 号端口是空闲的，而队列中的要去 1 和 3 号端口号的数据，被第四号端口给 Block 住了。这就是所谓的 HOL Blocking 问题。</p><p>HTTP/1.1 中的 Pipeline 中如果有一个请求 Block 了，那么队列后请求也统统被 Block 住了；HTTP/2 多请求复用一个 TCP 连接，一旦发生丢包就会 Block 住所有的 HTTP 请求。这样的问题很讨厌。好像基本无解了。</p><p>是的 TCP 是无解了，但是 UDP 是有解的 ！<strong>于是 HTTP/3 破天荒地把 HTTP 底层的 TCP 协议改成了 UDP！</strong></p><p>然后又是 Google 家的协议进入了标准 – QUIC （Quick UDP Internet Connections）。接下来是 QUIC 协议的几个重要的特性，为了讲清楚这些特性，我需要带着问题来讲（注：下面的网络知识，如果你看不懂的话，你需要学习一下 《TCP/IP 详解》 一书（ 在我写 Blog 的这 15 年里，这本书推荐了无数次了），或是看一下本站的 《 TCP 的那些事》。）：</p><ul><li><p>首先是上面的 Head-of-Line Blocking 问题，在 UDP 的世界中，这个就没了。这个应该比较好理解，因为 UDP 不管顺序，不管丢包（当然，QUIC 的一个任务是要像 TCP 的一个稳定，所以 QUIC 有自己的丢包重传的机制）</p></li><li><p>TCP 是一个无私的协议，也就是说，如果网络上出现拥塞，大家都会丢包，于是大家都会进入拥塞控制的算法中。这个算法会让所有人都 “冷静” 下来，然后进入一个 “慢启动” 的过程，包括在 TCP 连接建立时，这个慢启动也在，所以导致 TCP 性能迸发地比较慢。QUIC 基于 UDP，使用更为激进的方式。同时，QUIC 有一套自己的丢包重传和拥塞控制的协议，一开始 QUIC 是重新实现 TCP 的 CUBIC 算法。但是随着 BBR 算法的成熟（BBR 也在借鉴 CUBIC 算法的数学模型），QUIC 也可以使用 BBR 算法。这里，多说几句，**从模型来说，以前的 TCP 的拥塞控制算法玩的是数学模型，而新型的 TCP 拥塞控制算法是以 BBR 为代表的测量模型。**理论上来说，后者会更好，但 QUIC 的团队在一开始觉得 BBR 不如 CUBIC 的算法好，所以没有用。现在的 BBR 2.x 借鉴了 CUBIC 数学模型让拥塞控制更公平。这里有文章大家可以一读 “TCP BBR : Magic dust for network performance.” (<a href="https://url.cn/5awu1ey" target="_blank" rel="noopener">https://url.cn/5awu1ey</a>)</p></li><li><p>接下来，现在要建立一个 HTTPS 的连接。先是 TCP 的三次握手，然后是 TLS 的三次握手，要整出六次网络交互，一个连接才建好。虽说 HTTP/1.1 和 HTTP/2 的连接复用解决这个问题，但是基于 UDP 后，UDP 也得要实现这个事。于是 QUIC 直接把 TCP 的和 TLS 的合并成了三次握手（对此，在 HTTP/2 的时候，是否默认开启 TLS 业内是有争议的。反对派说，TLS 在一些情况下是不需要的，比如企业内网的时候。而支持派则说，TLS 的那些开销，什么也不算了）。</p></li></ul><p><img src="https://coolshell.cn/wp-content/uploads/2019/10/http-request-over-quic@2x.png" alt=""></p><p>所以，QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。</p><p>但是对于 UDP 还是有一些挑战的，这个挑战主要来自互联网上的各种网络设备。这些设备根本不知道是什么 QUIC，他们看 QUIC 就只能看到的就是 UDP，所以，在一些情况下，UDP 就是有问题的。</p><ul><li><p>比如在 NAT 的环境下，如果是 TCP 话，NAT 路由或是代理服务器，可以通过记录 TCP 的四元组（源地址、源端口、目标地址、目标端口）来做连接映射的。然而，在 UDP 的情况下不行了。于是，QUIC 引入了个叫 Connection ID 的不透明的 ID 来标识一个链接，用这种业务 ID 很爽的一个事是，如果你从你的 3G/4G 的网络切到 WiFi网络（或是反过来），你的链接不会断，因为我们用的是 Connection ID，而不是四元组。</p></li><li><p>然而就算引用了 Connection ID，也还是会有问题，比如一些不够 “聪明” 的等价路由交换机。这些交换机会通过四元组来做 Hash 把你的请求的 IP 转到后端的实际的服务器上。然而，他们不懂 Connection ID，只懂四元组。这么导致属于同一个 Connection ID 但是四元组不同的网络包就转到了不同的服务器上，这就是导致数据不能传到同一台服务器上，数据不完整，链接只能断了。所以，你需要更聪明的算法（可以参看 Facebook 的 Katran 开源项目 ）</p></li></ul><p>好了，就算搞定上面的东西，还有一些业务层的事没解。这个事就是 HTTP/2 的头压缩算法 HPACK，HPACK 需要维护一个动态的字典表来分析请求的头中哪些是重复的，HPACK 的这个数据结构需要在 Encoder 和 Decoder 端同步这个东西。在 TCP 上，这种同步是透明的，然而在 UDP 上这个事不好干了。所以，这个事也必需要重新设计了，基于 QUIC 的 QPACK 就出来了，利用两个附加的 QUIC Steam，一个用来发送这个字典表的更新给对方，另一个用来 Ack 对方发过来的 Update。</p><p>目前看下来，HTTP/3 目前看上去没有太多的协议业务逻辑上的东西，更多是 HTTP/2 + QUIC 协议。但 HTTP/3 因为动到了底层协议，所以，在普及方面上可能会比 HTTP/2 要慢的多的多。但是，可以看到 QUIC 协议的强大。细思及恐，QUIC 这个协议真对 TCP 是个威胁，如果 QUIC成熟了，TCP 是不是会有可能成为历史呢？</p><p>未来十年，让我们看看 UDP 是否能够逆袭 TCP……</p><blockquote><p>来源：酷壳</p><p>原文：<a href="https://url.cn/56Z548W" target="_blank" rel="noopener">https://url.cn/56Z548W</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HTTP (Hypertext transfer protocol) 翻译成中文是超文本传输协议，是互联网上重要的一个协议。由欧洲核子研究委员会 CERN 的英国工程师 Tim Berners-Lee v 发明的，同时他也是 WWW 的发明人，最初的主要是用于传递通过 HTML 封装过的数据。在 1991 年发布了 HTTP 0.9 版，在 1996 年发布 1.0 版。1997 年是 1.1 版，1.1 版也是到今天为止传输最广泛的版本（初始 RFC 2068 在 1997 年发布， 然后在 1999 年被 RFC 2616 取代，再在 2014 年被 RFC 7230/7231/7232/7233/7234/7235 取代）。2015 年发布了 2.0 版，其极大的优化了 HTTP/1.1 的性能和安全性，而 2018 年发布的 3.0 版，继续优化 HTTP/2，激进地使用 UDP 取代 TCP 协议。目前，HTTP/3 在 2019 年 9 月 26 日 被 Chrome、Firefox、和 Cloudflare 支持。所以我想写下这篇文章，简单地说一下 HTTP 的前世今生，让大家学到一些知识，并希望可以在推动一下 HTTP 标准协议的发展。&lt;/p&gt;
&lt;h2 id=&quot;HTTP-0-9-1-0&quot;&gt;HTTP 0.9 / 1.0&lt;/h2&gt;
&lt;p&gt;0.9 和 1.0 这两个版本，就是最传统的 Request – Response 的模式了。HTTP 0.9 版本的协议简单到极点，请求时不支持请求头，只支持 GET 方法，没了。HTTP 1.0 扩展了 0.9 版，其中主要增加了几个变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在请求中加入了 HTTP 版本号，如：GET /coolshell/index.html HTTP/1.0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HTTP 开始有 Header了，不管是 Request 还是 Response 都有 Header 了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加了 HTTP Status Code 标识相关的状态码。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有 Content-Type 可以传输其它的文件了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以看到，HTTP 1.0 开始让这个协议变得很文明了，一种工程文明。因为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一个协议有没有版本管理，是一个工程化的象征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Header 可以说是把元数据和业务数据解耦，也可以说是控制逻辑和业务逻辑的分离。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Status Code 的出现可以让请求双方以及第三方的监控或管理程序有了统一的认识。最关键是还是控制错误和业务错误的分离。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;注：国内很多公司 HTTP 无论对错只返回 200，这种把 HTTP Status Code 全部抹掉完全是一种工程界的倒退&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是，HTTP 1.0 性能上有一个很大的问题，那就是每请求一个资源都要新建一个 TCP 链接。而且是串行请求，所以就算网络变快了，打开网页的速度也还是很慢。所以，HTTP 1.0 应该是一个必须要淘汰的协议了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="HTTP" scheme="https://www.hi-linux.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>全平台去广告神器 AdGuard Home 使用指南</title>
    <link href="https://www.hi-linux.com/posts/55203.html"/>
    <id>https://www.hi-linux.com/posts/55203.html</id>
    <published>2020-05-23T02:13:00.000Z</published>
    <updated>2020-05-23T14:37:23.954Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-adguard-home">什么是 AdGuard Home</h2><p><code>AdGuard Home</code> 是一款全网广告拦截与反跟踪软件，<code>AdGuard Home</code> 项目是著名广告拦截器提供商 <code>AdGuard</code> 开源的一个 <code>DNS Server</code> 版本。<code>AdGuard Home</code> 可以将广告与追踪相关的域名屏蔽，同时你不再需要安装任何客户端软件。<code>AdGuard Home</code> 的工作原理是在 <code>DNS</code> 的域名解析过程里拦截网页上的广告。</p><p>简单来说 <code>AdGuard Home</code> 是一个支持广告过滤和家长控制的开源公共 <code>DNS</code> 服务，如同 Google 的公共 DNS 服务 8.8.8.8。<code>AdGuard Home</code> 同时也支持 <code>DNS over TLS</code> 和 <code>DNS over HTTPS</code>。</p><blockquote><p>项目地址：<a href="https://github.com/AdguardTeam/AdGuardHome" target="_blank" rel="noopener">https://github.com/AdguardTeam/AdGuardHome</a></p></blockquote><p><strong>AdGuard Home 的主要功能介绍</strong></p><ul><li>拦截随处可见的广告</li><li>注重隐私保护</li><li>家庭保护模式</li><li>自定义过滤规则</li></ul><p>在继续讲解前，我们先来看一看 <code>AdGuard Home</code> 强大的功能演示和管理后台。</p><p><img src="https://camo.githubusercontent.com/5e2bfa17c27773b70ca99ddd3b70995f15d24b62/68747470733a2f2f63646e2e616467756172642e636f6d2f7075626c69632f416467756172642f436f6d6d6f6e2f616467756172645f686f6d652e676966" alt=""></p><a id="more"></a><h2 id="安装-adguard-home">安装 AdGuard Home</h2><p><code>AdGuard Home</code> 使用 <code>Golang</code> 开发，具有良好的原生跨平台性。它可以部署在 <code>X86</code> 架构的各种操作系统上，也可以部署在树莓派上，甚至你还可以借助 <code>Docker</code> 部署在群晖 <code>NAS</code> 上。</p><h3 id="使用预编译的二进制版本安装">使用预编译的二进制版本安装</h3><p>这里我们以 <code>Linux</code> 系统为例，其它系统可参考官方帮助文档：<a href="https://github.com/AdguardTeam/AdGuardHome/wiki/Getting-Started#installation" target="_blank" rel="noopener">https://github.com/AdguardTeam/AdGuardHome/wiki/Getting-Started#installation</a> 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 下载并解压 AdGuard Home</span><br><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;AdguardTeam&#x2F;AdGuardHome&#x2F;releases&#x2F;download&#x2F;v0.98.1&#x2F;AdGuardHome_linux_amd64.tar.gz</span><br><span class="line">$ tar -zxvf AdGuardHome_linux_amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 为了方便使用，我们将二进制文件拷贝到 PATH 所包含的位置</span><br><span class="line">$ cd AdGuardHome_linux_amd64</span><br><span class="line">$ cp .&#x2F;AdGuardHome &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br><span class="line"></span><br><span class="line"># 启动 AdGuard Home</span><br><span class="line">$ AdGuardHome</span><br></pre></td></tr></table></figure><p>上面的方法，很显然是在前台运行的。前台运行必然还是存在一些弊端的，比如：当前 <code>SHELL</code> 中断必然会引起程序中断等。如果你想长期稳定的运行 <code>AdGuard Home</code>，最后好方法必然是将 <code>AdGuard Home</code> 运行成一个服务。要想将 <code>AdGuard Home</code> 在各平台部署为服务也是很简单的，只需运行下面这一条命令就可实现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Linux 下使用的服务管理器是 systemd 、Upstart 或 SysV，macOS 下使用的服务管理器是 Launchd。</span><br><span class="line">$ AdGuardHome -s install</span><br></pre></td></tr></table></figure><p><code>AdGuard Home</code> 服务安装后好，你可以使用以下命令来管理它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 启动 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s start</span><br><span class="line"></span><br><span class="line"># 停止 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s stop</span><br><span class="line"></span><br><span class="line"># 重启 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s restart</span><br><span class="line"></span><br><span class="line"># 查看 AdGuardHome 服务状态</span><br><span class="line">$ AdGuardHome -s status</span><br><span class="line"></span><br><span class="line"># 卸载 AdGuardHome 服务</span><br><span class="line">$ AdGuardHome -s uninstall</span><br></pre></td></tr></table></figure><h3 id="使用-docker-来安装">使用 Docker 来安装</h3><p>如果你会一点点 <code>Docker</code> 知识的话，我们当然还是建议你直接使用 <code>Docker</code> 来安装。虽然通过预编译的二进制版本安装已经很简单了，但如果使用 <code>Docker</code> 来安装，你会发现仅仅只需一条指令就可以搞定了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull adguard&#x2F;adguardhome</span><br><span class="line"># -v 参数后面指定的宿主机上的目录主要用作永久保存 AdGuard Home 的数据文件和配置文件，可自行根据实际情况修改。</span><br><span class="line">$ docker run --name adguardhome -v &#x2F;home&#x2F;mike&#x2F;workdir:&#x2F;opt&#x2F;adguardhome&#x2F;work -v &#x2F;home&#x2F;mike&#x2F;confdir:&#x2F;opt&#x2F;adguardhome&#x2F;conf -p 53:53&#x2F;tcp -p 53:53&#x2F;udp -p 67:67&#x2F;udp -p 68:68&#x2F;tcp -p 68:68&#x2F;udp -p 80:80&#x2F;tcp -p 443:443&#x2F;tcp -p 853:853&#x2F;tcp -p 3000:3000&#x2F;tcp -d adguard&#x2F;adguardhome</span><br></pre></td></tr></table></figure><p>你可能会发现上面一共是两条指令，前面不是说好了是一条指令的吗？是不是发现被骗了，我怎么可能骗你呢，这绝对是不可能的！其实这两条指令，你只需直接执行第 2 条指令就可以完成所有安装操作了。这里分开写出来仅仅是为了完整演示 <code>Docker</code> 整个运行过程，能让一些还不会 <code>Docker</code> 的同学能更容易理解一些。前面既然啰嗦了这么多，这里就再延伸说一点 <code>Docker</code> 容器的基本管理操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 启动 AdGuard Home 容器</span><br><span class="line">$ docker start adguardhome</span><br><span class="line"># 停止 AdGuard Home 容器</span><br><span class="line">$ docker stop adguardhome</span><br><span class="line"># 删除 AdGuard Home 容器</span><br><span class="line">$ docker rm adguardhome</span><br></pre></td></tr></table></figure><h2 id="使用-adguard-home">使用 AdGuard Home</h2><h3 id="使用默认配置来设置-adguard-home">使用默认配置来设置 AdGuard Home</h3><p>运行 <code>AdGuard Home</code> 后，我们需要通过浏览器打开 <code>http://IP:3000</code> 对 <code>AdGuard Home</code> 进行初始化设置。首次初始化会要求设置服务运行端口、账号、密码等信息，配置过程中设置的密码一定请牢记，下次登录管理后台时需要使用。</p><p><img src="https://i.loli.net/2019/09/23/NVETKdawnmg6GPu.png" alt=""></p><p>首先，我们点击 “开始配置” ，来设定网页管理界面和 <code>DNS</code> 服务的端口。</p><p><img src="https://i.loli.net/2019/09/23/FSiKwDLA7ChbJfk.png" alt=""></p><p>其次，点击 “下一步” 后，为 <code>AdGuard Home</code> 网页管理界面设置一个用户名和密码。</p><p><img src="https://i.loli.net/2019/09/23/V2KAUfmzZuqpbwD.png" alt=""></p><p>最后，点击 “下一步” 后，<code>AdGuard Home</code> 会展示以上配置的汇总信息。</p><p><img src="https://i.loli.net/2019/09/23/PLgy2jYkM6SzQRf.png" alt=""></p><p>至此，使用 <code>AdGuard Home</code> 默认配置的设置就算大功告成了。</p><p><img src="https://i.loli.net/2019/09/23/jY15gNKiPO7Lm6U.png" alt=""></p><p>使用 <code>AdGuard Home</code> 默认配置设置完成后，我们可以在「仪表盘」上看到 <code>DNS</code> 查询次数、被过滤器封锁的网站、查询 <code>DNS</code> 请求的客户端 <code>IP</code> 地址等等信息。</p><p><img src="https://i.loli.net/2019/09/23/3EM9k7nOCfRPxFz.png" alt=""></p><h3 id="adguard-home-配置进阶">AdGuard Home 配置进阶</h3><p><code>AdGuard Home</code> 默认的配置比较简单，为了更强力地拦截广告，我们可以对 <code>AdGuard Home</code> 配置进行一些优化。</p><ol><li>常规设置</li></ol><p><code>AdGuard Home</code> 默认配置的情况下只勾选了「使用过滤器和 Hosts 文件以拦截指定域名」这一个选项，你可以根据自身情况决定是否启用「使用 AdGuard 浏览安全网页服务」、「使用 AdGuard 家长控制服务」和「强制安全搜索」等特性。</p><p>不仅如此，你还可以很方便的屏蔽一些比较流行的网站。当然这些网站本来对我们都是不可用的，也就不用多此一举进行设置了，哈哈！</p><p><img src="https://i.loli.net/2019/09/23/lLYJex6vNqcI4V3.png" alt=""></p><ol start="2"><li>设置上游 DNS</li></ol><p><code>AdGuard Home</code> 默认使用 <code>Cloudflare</code> 的 <code>DNS over HTTPS</code> 作为上游服务器。如果你在国内使用 <code>Cloudflare DNS</code> 做为上游 <code>DNS</code>，可能延迟会比较高。</p><p>我们可以设置为国内的公共 <code>DNS</code>，如：腾讯的 <code>119.29.29.29</code>、阿里的 <code>223.5.5.5</code> 和 <code>114.114.114.114</code> 等，但坏处是这些国内公共 <code>DNS</code> 暂时不支持 <code>DNS over TLS</code>。</p><p>这里有一个比较折中的解决方法就是通过启用 「通过同时查询所有上游服务器以使用并行查询加速解析」选项来在每次查询的时候对所有的上游 <code>DNS</code> 同时查询，以加速解析速度。</p><p><img src="https://i.loli.net/2019/09/23/1wTb4msXYcCGudM.png" alt=""></p><ol start="3"><li>过滤器</li></ol><p>虽然 <code>AdGuard Home</code> 本身内置了比较知名的 <code>AdGuard</code>、<code>AdAway</code> 广告过滤规则，但这些规则在国内显然有点水土不服。如果你想要更完美的实现广告屏蔽还需要自己添加规则，比较幸运的是 <code>AdGuard Home</code> 是可以兼容 <code>Adblock</code> 过滤规则语法的。这样，你就可以很方便的使用一些比较知名的 <code>Adblock</code> 过滤规则，比如：由 <code>Adblock Plus</code> 团队维护的 <code>EasyList</code>。</p><p><img src="https://i.loli.net/2019/09/23/5n8tdDEMjAkwNPa.png" alt=""></p><p><img src="https://i.loli.net/2019/09/23/OGxDdmcSplTyn8M.png" alt=""></p><p>目前好用的广告过滤规则还是有很多的，它们都针对不同的用途。下面推荐一些比较常用的：</p><blockquote><ol><li>EasyList China : 国内网站广告过滤的主规则。</li></ol><p>链接：<a href="https://easylist-downloads.adblockplus.org/easylistchina.txt" target="_blank" rel="noopener">https://easylist-downloads.adblockplus.org/easylistchina.txt</a></p><ol start="2"><li>EasyPrivacy : EasyPrivacy 是隐私保护，不被跟踪。</li></ol><p>链接：<a href="https://easylist-downloads.adblockplus.org/easyprivacy.txt" target="_blank" rel="noopener">https://easylist-downloads.adblockplus.org/easyprivacy.txt</a></p><ol start="3"><li>CJX’s Annoyance List : 过滤烦人的自我推广，并补充 EasyPrivacy 隐私规则。</li></ol><p>链接：<a href="https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt" target="_blank" rel="noopener">https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt</a></p><ol start="4"><li>广告净化器规则 : 支持国内大部分视频网站的广告过滤。</li></ol><p>链接：<a href="http://tools.yiclear.com/ChinaList2.0.txt" target="_blank" rel="noopener">http://tools.yiclear.com/ChinaList2.0.txt</a></p><ol start="5"><li>I don’t care about cookies : 我不关心 Cookie 的问题，屏蔽网站的 cookies 相关的警告。</li></ol><p>链接：<a href="https://www.i-dont-care-about-cookies.eu/abp/" target="_blank" rel="noopener">https://www.i-dont-care-about-cookies.eu/abp/</a></p></blockquote><p>除了使用已有的过滤规则外，当然你也可以根据自己的需求自定义过滤规则，要自定义过滤规则其实也很简单。</p><p><img src="https://i.loli.net/2019/09/23/FmdDSCTjuae5I41.png" alt=""></p><p>下面是自定义过滤规则的一些语法说明。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">||example.org^ – 拦截 example.org 域名及其所有子域名</span><br><span class="line">@@||example.org^ – 放行 example.org 及其所有子域名</span><br><span class="line">127.0.0.1 example.org – 将会把 example.org（但不包括它的子域名）解析到 127.0.0.1。</span><br><span class="line">! 注释符号，表示这是一行注释</span><br><span class="line"># 这也是注释符号，同样表示这是一行注释</span><br><span class="line">&#x2F;REGEX&#x2F; – 正则表达式模式</span><br></pre></td></tr></table></figure><p>更多规则可以参考官方帮助文档：<a href="https://kb.adguard.com/en/general/dns-filtering-syntax" target="_blank" rel="noopener">https://kb.adguard.com/en/general/dns-filtering-syntax</a></p><ol start="4"><li>查询日志</li></ol><p><code>AdGuard Home</code> 管理界面中也为我们提供了 <code>DNS</code> 请求日志查询功能，在这里，我们不但能看见所有设备最近 5000 条的 <code>DNS</code> 请求日志记录。你还可以根据 <code>DNS</code> 请求日志记录来针对某个域名进行快速的拦截和放行操作。</p><p><img src="https://i.loli.net/2019/09/23/POtxW5feJ13rYuI.png" alt=""></p><ol start="5"><li>调整配置参数，以提升 QPS 能力</li></ol><p><code>AdGuard Home</code> 所有的配置参数都保存在一个名为 <code>AdGuardHome.yaml</code> 的配置文件中。这个配置文件默认路径通常为 <code>AdGuard Home</code> 二进制文件 <code>AdGuardHome</code> 所在的目录，比如：<code>/usr/local/bin/AdGuardHome.yaml</code>。</p><p>这里我们只需调整以下两个参数，就是可以明显提升 <code>AdGuard Home</code> 的 <code>QPS</code>  能力。</p><ul><li><p>ratelimit : <code>DDoS</code> 保护，客户端每秒接收的数据包数。默认值是 20，建议禁用该参数（将值改为 0）。</p></li><li><p>blocked_response_ttl : <code>TTL</code> 缓存时间，默认值是 10，建议设置为 60 。</p></li></ul><p>这里在把 <code>AdGuard Home</code> 的配置文件完整版本也展示一下，有兴趣的同学可以自行研究下其它参数的用途哟！。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">$ cat AdGuardHome.yaml</span><br><span class="line"></span><br><span class="line">bind_host: 0.0.0.0</span><br><span class="line">bind_port: 80</span><br><span class="line">auth_name: mike</span><br><span class="line">auth_pass: &quot;123456&quot;</span><br><span class="line">language: zh-cn</span><br><span class="line">rlimit_nofile: 0</span><br><span class="line">dns:</span><br><span class="line">  bind_host: 0.0.0.0</span><br><span class="line">  port: 53</span><br><span class="line">  protection_enabled: true</span><br><span class="line">  filtering_enabled: true</span><br><span class="line">  blocking_mode: nxdomain</span><br><span class="line">  blocked_response_ttl: 60</span><br><span class="line">  querylog_enabled: true</span><br><span class="line">  ratelimit: 0</span><br><span class="line">  ratelimit_whitelist: []</span><br><span class="line">  refuse_any: true</span><br><span class="line">  bootstrap_dns:</span><br><span class="line">  - 1.1.1.1:53</span><br><span class="line">  - 1.0.0.1:53</span><br><span class="line">  all_servers: true</span><br><span class="line">  allowed_clients: []</span><br><span class="line">  disallowed_clients: []</span><br><span class="line">  blocked_hosts: []</span><br><span class="line">  parental_block_host: &quot;&quot;</span><br><span class="line">  safebrowsing_block_host: &quot;&quot;</span><br><span class="line">  blocked_services: []</span><br><span class="line">  parental_sensitivity: 13</span><br><span class="line">  parental_enabled: true</span><br><span class="line">  safesearch_enabled: true</span><br><span class="line">  safebrowsing_enabled: true</span><br><span class="line">  resolveraddress: &quot;&quot;</span><br><span class="line">  rewrites: []</span><br><span class="line">  upstream_dns:</span><br><span class="line">  - https:&#x2F;&#x2F;1.1.1.1&#x2F;dns-query</span><br><span class="line">  - https:&#x2F;&#x2F;1.0.0.1&#x2F;dns-query</span><br><span class="line">  - 119.29.29.29</span><br><span class="line">  - 223.5.5.5</span><br><span class="line">tls:</span><br><span class="line">  enabled: false</span><br><span class="line">  server_name: &quot;&quot;</span><br><span class="line">  force_https: false</span><br><span class="line">  port_https: 443</span><br><span class="line">  port_dns_over_tls: 853</span><br><span class="line">  certificate_chain: &quot;&quot;</span><br><span class="line">  private_key: &quot;&quot;</span><br><span class="line">filters:</span><br><span class="line">- enabled: true</span><br><span class="line">  url: https:&#x2F;&#x2F;adguardteam.github.io&#x2F;AdGuardSDNSFilter&#x2F;Filters&#x2F;filter.txt</span><br><span class="line">  name: AdGuard Simplified Domain Names filter</span><br><span class="line">  id: 1</span><br><span class="line">- enabled: false</span><br><span class="line">  url: https:&#x2F;&#x2F;adaway.org&#x2F;hosts.txt</span><br><span class="line">  name: AdAway</span><br><span class="line">  id: 2</span><br><span class="line">- enabled: false</span><br><span class="line">  url: https:&#x2F;&#x2F;hosts-file.net&#x2F;ad_servers.txt</span><br><span class="line">  name: hpHosts - Ad and Tracking servers only</span><br><span class="line">  id: 3</span><br><span class="line">- enabled: false</span><br><span class="line">  url: https:&#x2F;&#x2F;www.malwaredomainlist.com&#x2F;hostslist&#x2F;hosts.txt</span><br><span class="line">  name: MalwareDomainList.com Hosts List</span><br><span class="line">  id: 4</span><br><span class="line">- enabled: true</span><br><span class="line">  url: https:&#x2F;&#x2F;easylist-downloads.adblockplus.org&#x2F;easylistchina.txt</span><br><span class="line">  name: EasyList China</span><br><span class="line">  id: 1569209532</span><br><span class="line">user_rules:</span><br><span class="line">- &#39;@@mps.ts&#39;</span><br><span class="line">dhcp:</span><br><span class="line">  enabled: false</span><br><span class="line">  interface_name: &quot;&quot;</span><br><span class="line">  gateway_ip: &quot;&quot;</span><br><span class="line">  subnet_mask: &quot;&quot;</span><br><span class="line">  range_start: &quot;&quot;</span><br><span class="line">  range_end: &quot;&quot;</span><br><span class="line">  lease_duration: 86400</span><br><span class="line">  icmp_timeout_msec: 1000</span><br><span class="line">clients: []</span><br><span class="line">log_file: &quot;&quot;</span><br><span class="line">verbose: false</span><br><span class="line">schema_version: 4</span><br></pre></td></tr></table></figure><h3 id="设置客户端-dns">设置客户端 DNS</h3><p>所有以上设置完成后，最后当然是修改所有客户端的 <code>DNS</code> 设置，来享用 <code>AdGuard Home</code> 带来的强大的去广告功能。</p><p>这个其实真的不用写，我想聪明的你应该都知道这个怎么设置。写这个标题仅仅是为了保持文档完整性，如果你真的不会设置，那就请自行使用「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247488197&amp;idx=1&amp;sn=1f722503d5f18ab8c6f4d9ba768d983b&amp;chksm=eac533ecddb2bafa6044ce24599ebd20b6fd1cd083a31b53d16730f35daaaffbbb902fc8d449&amp;token=614394592&amp;lang=zh_CN#rd" target="_blank" rel="noopener">一些好用</a>」的搜索引擎搜索相关方法吧！</p><h2 id="总结">总结</h2><p><code>AdGuard Home</code> 不但支持了 <code>macOS</code>、<code>Windows</code>、<code>Linux</code>、树莓派等多个系统平台，也提供了二进制和 <code>Docker</code> 的部署方式，让安装变得非常简单。<code>AdGuard Home</code> 自身提供的强大和直观的管理和统计系统，让它使用起来也是非常方便的。如果你打算自建一个支持去广告功能的公共 <code>DNS</code>，<code>AdGuard Home</code> 是非常值得一试的不二选择。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/56804257" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56804257</a></p></li><li><p><a href="https://www.xiaoz.me/archives/12318" target="_blank" rel="noopener">https://www.xiaoz.me/archives/12318</a></p></li><li><p><a href="https://www.yangcs.net/posts/adguard-home/" target="_blank" rel="noopener">https://www.yangcs.net/posts/adguard-home/</a></p></li><li><p><a href="https://github.com/AdguardTeam/AdGuardHome#getting-started" target="_blank" rel="noopener">https://github.com/AdguardTeam/AdGuardHome#getting-started</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-AdGuard-Home&quot;&gt;什么是 AdGuard Home&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AdGuard Home&lt;/code&gt; 是一款全网广告拦截与反跟踪软件，&lt;code&gt;AdGuard Home&lt;/code&gt; 项目是著名广告拦截器提供商 &lt;code&gt;AdGuard&lt;/code&gt; 开源的一个 &lt;code&gt;DNS Server&lt;/code&gt; 版本。&lt;code&gt;AdGuard Home&lt;/code&gt; 可以将广告与追踪相关的域名屏蔽，同时你不再需要安装任何客户端软件。&lt;code&gt;AdGuard Home&lt;/code&gt; 的工作原理是在 &lt;code&gt;DNS&lt;/code&gt; 的域名解析过程里拦截网页上的广告。&lt;/p&gt;
&lt;p&gt;简单来说 &lt;code&gt;AdGuard Home&lt;/code&gt; 是一个支持广告过滤和家长控制的开源公共 &lt;code&gt;DNS&lt;/code&gt; 服务，如同 Google 的公共 DNS 服务 8.8.8.8。&lt;code&gt;AdGuard Home&lt;/code&gt; 同时也支持 &lt;code&gt;DNS over TLS&lt;/code&gt; 和 &lt;code&gt;DNS over HTTPS&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/AdguardTeam/AdGuardHome&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/AdguardTeam/AdGuardHome&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;AdGuard Home 的主要功能介绍&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拦截随处可见的广告&lt;/li&gt;
&lt;li&gt;注重隐私保护&lt;/li&gt;
&lt;li&gt;家庭保护模式&lt;/li&gt;
&lt;li&gt;自定义过滤规则&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在继续讲解前，我们先来看一看 &lt;code&gt;AdGuard Home&lt;/code&gt; 强大的功能演示和管理后台。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/5e2bfa17c27773b70ca99ddd3b70995f15d24b62/68747470733a2f2f63646e2e616467756172642e636f6d2f7075626c69632f416467756172642f436f6d6d6f6e2f616467756172645f686f6d652e676966&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具" scheme="https://www.hi-linux.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="AdGuard" scheme="https://www.hi-linux.com/tags/AdGuard/"/>
    
  </entry>
  
  <entry>
    <title>你不可错过的 GitHub 万星大厂技术面试宝典</title>
    <link href="https://www.hi-linux.com/posts/62964.html"/>
    <id>https://www.hi-linux.com/posts/62964.html</id>
    <published>2020-05-23T02:12:00.000Z</published>
    <updated>2020-05-23T14:37:23.953Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近，GitHub 上有一个很火的项目，截止目前，该项目已获得 17000+ Star。该项目主要介绍了阿里巴巴、华为、百度、腾讯、美团、字节跳动、滴滴、京东等知名互联网公司的技术面试题。</p><p>项目地址：<a href="https://github.com/0voice/interview_internal_reference" target="_blank" rel="noopener">https://github.com/0voice/interview_internal_reference</a></p><p><img src="https://i.loli.net/2019/08/13/eVwcFCO2GyQaBl6.png" alt=""></p><p>这份面试题库共分为 20 个篇章，其中第一部分(前面 8 章)是以公司为区分，总结了各大互联网公司的技术面试题和答案，第二部分是按照面试题的知识点进行了专题总结。</p><p><img src="https://i.loli.net/2019/08/13/OEMTDy3q9vgHoYc.png" alt=""></p><a id="more"></a><p>在第一部分，我们可以看到这些知名互联网公司的面试题。以排在最前面的阿里巴巴为例子，我们可以看到这里面收集了 37 个面试题。</p><p><img src="https://i.loli.net/2019/08/13/XWd3HFr9afBp2EM.png" alt=""></p><p>打开这些面试题，我们不仅可以能看到题目，而且还能看到对应出题人和参考答案。如：打开第一题：「如何实现一个高效的单向链表逆序输出？」，我们看到的内容如下：</p><p><img src="https://i.loli.net/2019/08/13/hO1PZCYojliyk7n.png" alt=""></p><p>第二部分分为了 12 个技术专题，分别是 MySQL 篇、Redis 篇、MongDB 篇、Zookeeper 篇、Nginx 篇、算法篇、内存篇、CPU 篇、磁盘篇、网络通信篇、安全篇和并发篇。这里面针对每个专题，整理了一些经常会遇到的面试题。</p><p>例如：MySQL 篇包含的题目如下：</p><p><img src="https://i.loli.net/2019/08/13/TQFAOmVLlgBSvKo.png" alt=""></p><p>和上面一样，这里也同样给出了题目和对应的参考答案。打开上图的第一个题目，我们可以看到如下内容：</p><p><img src="https://i.loli.net/2019/08/13/nixwrBMXPOkGA65.png" alt=""></p><p>虽然这只是一个非常简单的概念题，但由此我们也可以看到，这份题库给出的答案非常详细，不仅对问题中提出的概念进行了解释，还用具体的例子进行了说明，方便大家容易理解和记忆。</p><p>更多详细内容此处不再赘述，还在等什么呢？一分耕耘一分收获，有兴趣的读者赶快收藏起这份资源开始学习吧！</p><blockquote><p>来源：雷锋网</p><p>原文：<a href="http://t.cn/AiHU2MuN" target="_blank" rel="noopener">http://t.cn/AiHU2MuN</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，GitHub 上有一个很火的项目，截止目前，该项目已获得 17000+ Star。该项目主要介绍了阿里巴巴、华为、百度、腾讯、美团、字节跳动、滴滴、京东等知名互联网公司的技术面试题。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/0voice/interview_internal_reference&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/0voice/interview_internal_reference&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/08/13/eVwcFCO2GyQaBl6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这份面试题库共分为 20 个篇章，其中第一部分(前面 8 章)是以公司为区分，总结了各大互联网公司的技术面试题和答案，第二部分是按照面试题的知识点进行了专题总结。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/08/13/OEMTDy3q9vgHoYc.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>GitHub Actions 入门教程</title>
    <link href="https://www.hi-linux.com/posts/59009.html"/>
    <id>https://www.hi-linux.com/posts/59009.html</id>
    <published>2020-05-23T02:11:00.000Z</published>
    <updated>2020-05-23T14:37:23.951Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>GitHub Actions 是 GitHub 的持续集成服务，于 2018 年 10 月推出。</p><p>这些天，我一直在试用，觉得它非常强大，有创意，比 Travis CI 玩法更多。</p><p>本文是一个简单教程，演示如何使用 GitHub Actions 自动发布一个 React 应用到 GitHub Pages。</p><h2 id="github-actions-是什么">GitHub Actions 是什么？</h2><p>大家知道，持续集成由很多操作组成，比如抓取代码、运行测试、登录远程服务器，发布到第三方服务等等。GitHub 把这些操作就称为 actions。</p><p>很多操作在不同项目里面是类似的，完全可以共享。GitHub 注意到了这一点，想出了一个很妙的点子，允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。</p><p>如果你需要某个 action，不必自己写复杂的脚本，直接引用他人写好的 action 即可，整个持续集成过程，就变成了一个 actions 的组合。这就是 GitHub Actions 最特别的地方。</p><p>GitHub 做了一个官方市场，可以搜索到他人提交的 actions。另外，还有一个 awesome actions 的仓库，也可以找到不少 action。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091105.jpg" alt=""></p><p>上面说了，每个 action 就是一个独立脚本，因此可以做成代码仓库，使用 userName/repoName 的语法引用 action。比如，actions/setup-node 就表示 <a href="http://github.com/actions/setup-node" target="_blank" rel="noopener">github.com/actions/setup-node</a> 这个仓库，它代表一个 action，作用是安装 Node.js。事实上，GitHub 官方的 actions 都放在 <a href="http://github.com/actions" target="_blank" rel="noopener">github.com/actions</a> 里面。</p><p>既然 actions 是代码仓库，当然就有版本的概念，用户可以引用某个具体版本的 action。下面都是合法的 action 引用，用的就是 Git 的指针概念，详见官方文档。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">actions&#x2F;setup-node@74bc508 # 指向一个 commit</span><br><span class="line">actions&#x2F;setup-node@v1.0    # 指向一个标签</span><br><span class="line">actions&#x2F;setup-node@master  # 指向一个分支</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="基本概念">基本概念</h2><p>GitHub Actions 有一些自己的术语。</p><p>（1）workflow （工作流程）：持续集成一次运行的过程，就是一个 workflow。</p><p>（2）job （任务）：一个 workflow 由一个或多个 jobs 构成，含义是一次持续集成的运行，可以完成多个任务。</p><p>（3）step（步骤）：每个 job 由多个 step 构成，一步步完成。</p><p>（4）action （动作）：每个 step 可以依次执行一个或多个命令（action）。</p><h2 id="workflow-文件">workflow 文件</h2><p>GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的 .github/workflows 目录。</p><p>workflow 文件采用 YAML 格式，文件名可以任意取，但是后缀名统一为 .yml，比如 foo.yml。一个库可以有多个 workflow 文件。GitHub 只要发现 .github/workflows 目录里面有 .yml 文件，就会自动运行该文件。</p><p>workflow 文件的配置字段非常多，详见官方文档。下面是一些基本字段。</p><p><strong>（1）name</strong></p><p>name 字段是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name: GitHub Actions Demo</span><br></pre></td></tr></table></figure><p><strong>（2）on</strong></p><p>on 字段指定触发 workflow 的条件，通常是某些事件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">on: push</span><br></pre></td></tr></table></figure><p>上面代码指定，push 事件触发 workflow。</p><p>on 字段也可以是事件的数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">on: [push, pull_request]</span><br></pre></td></tr></table></figure><p>上面代码指定，push 事件或 pull_request 事件都可以触发 workflow。</p><p>完整的事件列表，请查看官方文档。除了代码库事件，GitHub Actions 也支持外部事件触发，或者定时运行。</p><p><strong>（3）on.&lt;push|pull_request&gt;.&lt;tags|branches&gt;</strong></p><p>指定触发事件时，可以限定分支或标签。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">on:</span><br><span class="line">  push:</span><br><span class="line">    branches:    </span><br><span class="line">      - master</span><br></pre></td></tr></table></figure><p>上面代码指定，只有 master 分支发生 push 事件时，才会触发 workflow。</p><p><strong>（4）jobs.&lt;job_id&gt;.name</strong></p><p>workflow 文件的主体是 jobs 字段，表示要执行的一项或多项任务。</p><p>jobs 字段里面，需要写出每一项任务的 job_id，具体名称自定义。job_id 里面的 name 字段是任务的说明。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  my_first_job:</span><br><span class="line">    name: My first job</span><br><span class="line">  my_second_job:</span><br><span class="line">    name: My second job</span><br></pre></td></tr></table></figure><p>上面代码的 jobs 字段包含两项任务，job_id 分别是 my_first_job 和 my_second_job。</p><p><strong>（5）jobs.&lt;job_id&gt;.needs</strong></p><p>needs 字段指定当前任务的依赖关系，即运行顺序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  job1:</span><br><span class="line">  job2:</span><br><span class="line">    needs: job1</span><br><span class="line">  job3:</span><br><span class="line">    needs: [job1, job2]</span><br></pre></td></tr></table></figure><p>上面代码中，job1 必须先于 job2 完成，而 job3 等待 job1 和 job2 的完成才能运行。因此，这个 workflow 的运行顺序依次为：job1、job2、job3。</p><p><strong>（6）jobs.&lt;job_id&gt;.runs-on</strong></p><p>runs-on 字段指定运行所需要的虚拟机环境。它是必填字段。目前可用的虚拟机如下。</p><ul><li><p>ubuntu-latest，ubuntu-18.04 或 ubuntu-16.04</p></li><li><p>windows-latest，windows-2019 或 windows-2016</p></li><li><p>macOS-latest 或 macOS-10.14</p></li></ul><p>下面代码指定虚拟机环境为 ubuntu-18.04。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runs-on: ubuntu-18.04</span><br></pre></td></tr></table></figure><p><strong>（7）jobs.&lt;job_id&gt;.steps</strong></p><p>steps 字段指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定以下三个字段。</p><ul><li><p>jobs.&lt;job_id&gt;.steps.name：步骤名称。</p></li><li><p>jobs.&lt;job_id&gt;.steps.run：该步骤运行的命令或者 action。</p></li><li><p>jobs.&lt;job_id&gt;.steps.env：该步骤所需的环境变量。</p></li></ul><p>下面是一个完整的 workflow 文件的范例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">name: Greeting from Mona</span><br><span class="line">on: push</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  my-job:</span><br><span class="line">    name: My Job</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">    - name: Print a greeting</span><br><span class="line">      env:</span><br><span class="line">        MY_VAR: Hi there! My name is</span><br><span class="line">        FIRST_NAME: Mona</span><br><span class="line">        MIDDLE_NAME: The</span><br><span class="line">        LAST_NAME: Octocat</span><br><span class="line">      run: |</span><br><span class="line">        echo $MY_VAR $FIRST_NAME $MIDDLE_NAME $LAST_NAME.</span><br></pre></td></tr></table></figure><p>上面代码中，steps 字段只包括一个步骤。该步骤先注入四个环境变量，然后执行一条 Bash 命令。</p><h2 id="实例react-项目发布到-github-pages">实例：React 项目发布到 GitHub Pages</h2><p>下面是一个实例，通过 GitHub Actions 构建一个 React 项目，并发布到 GitHub Pages。最终代码都在这个仓库里面，发布后的参考网址为 <a href="http://ruanyf.github.io/github-actions-demo%E3%80%82" target="_blank" rel="noopener">ruanyf.github.io/github-actions-demo。</a></p><p>第一步，GitHub Actions 目前还处在测试阶段，需要到这个网址申请测试资格。申请以后，可能需要几天才能通过。据说，2019 年 11 月就会放开。</p><p>获得资格后，仓库顶部的菜单会出现 Actions 一项。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091106.jpg" alt=""></p><p>第二步，这个示例需要将构建成果发到 GitHub 仓库，因此需要 GitHub 密钥。按照官方文档，生成一个密钥。然后，将这个密钥储存到当前仓库的 Settings/Secrets 里面。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091107.jpg" alt=""></p><p>上图是储存秘密的环境变量的地方。环境变量的名字可以随便起，这里用的是 ACCESS_TOKEN。如果你不用这个名字，后面脚本里的变量名也要跟着改。</p><p>第三步，本地计算机使用 create-react-app，生成一个标准的 React 应用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ npx create-react-app github-actions-demo</span><br><span class="line">$ cd github-actions-demo</span><br></pre></td></tr></table></figure><p>第四步，在这个仓库的 .github/workflows 目录，生成一个 workflow 文件，名字可以随便取，这个示例是 ci.yml。</p><p>我们选用一个别人已经写好的 action：JamesIves/github-pages-deploy-action，它提供了 workflow 的范例文件，直接拷贝过来就行了（查看源码）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">name: GitHub Actions Build and Deploy Demo</span><br><span class="line">on:</span><br><span class="line">  push:</span><br><span class="line">    branches:</span><br><span class="line">      - master</span><br><span class="line">jobs:</span><br><span class="line">  build-and-deploy:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">    - name: Checkout</span><br><span class="line">      uses: actions&#x2F;checkout@master</span><br><span class="line"></span><br><span class="line">    - name: Build and Deploy</span><br><span class="line">      uses: JamesIves&#x2F;github-pages-deploy-action@master</span><br><span class="line">      env:</span><br><span class="line">        ACCESS_TOKEN: $&#123;&#123; secrets.ACCESS_TOKEN &#125;&#125;</span><br><span class="line">        BRANCH: gh-pages</span><br><span class="line">        FOLDER: build</span><br><span class="line">        BUILD_SCRIPT: npm install &amp;&amp; npm run build</span><br></pre></td></tr></table></figure><p>上面这个 workflow 文件的要点如下。</p><ol><li><p>整个流程在 master 分支发生 push 事件时触发。</p></li><li><p>只有一个 job，运行在虚拟机环境 ubuntu-latest。</p></li><li><p>第一步是获取源码，使用的 action 是actions/checkout。</p></li><li><p>第二步是构建和部署，使用的 action 是JamesIves/github-pages-deploy-action。</p></li><li><p>第二步需要四个环境变量，分别为 GitHub 密钥、发布分支、构建成果所在目录、构建脚本。其中，只有 GitHub 密钥是秘密变量，需要写在双括号里面，其他三个都可以直接写在文件里。</p></li></ol><p>第五步，保存上面的文件后，将整个仓库推送到 GitHub。</p><p>GitHub 发现了 workflow 文件以后，就会自动运行。你可以在网站上实时查看运行日志，日志默认保存 30 天。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091108.jpg" alt=""></p><p>等到 workflow 运行结束，访问 GitHub Page，会看到构建成果已经发上网了。</p><p><img src="https://www.wangbase.com/blogimg/asset/201909/bg2019091109.jpg" alt=""></p><p>以后，每次修改后推送源码，GitHub Actions 都会自动运行，将构建产物发布到网页。</p><h2 id="参考链接">参考链接</h2><ol><li><p>GitHub Pages 官方文档</p></li><li><p>Github Actions for web apps, Luke Boyle</p></li><li><p>My First Week With GitHub Actions, Adam Zolyak</p></li></ol><blockquote><p>来源：阮一峰的网络日志</p><p>原文：<a href="https://tinyurl.com/y3zfap8m" target="_blank" rel="noopener">https://tinyurl.com/y3zfap8m</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GitHub Actions 是 GitHub 的持续集成服务，于 2018 年 10 月推出。&lt;/p&gt;
&lt;p&gt;这些天，我一直在试用，觉得它非常强大，有创意，比 Travis CI 玩法更多。&lt;/p&gt;
&lt;p&gt;本文是一个简单教程，演示如何使用 GitHub Actions 自动发布一个 React 应用到 GitHub Pages。&lt;/p&gt;
&lt;h2 id=&quot;GitHub-Actions-是什么？&quot;&gt;GitHub Actions 是什么？&lt;/h2&gt;
&lt;p&gt;大家知道，持续集成由很多操作组成，比如抓取代码、运行测试、登录远程服务器，发布到第三方服务等等。GitHub 把这些操作就称为 actions。&lt;/p&gt;
&lt;p&gt;很多操作在不同项目里面是类似的，完全可以共享。GitHub 注意到了这一点，想出了一个很妙的点子，允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。&lt;/p&gt;
&lt;p&gt;如果你需要某个 action，不必自己写复杂的脚本，直接引用他人写好的 action 即可，整个持续集成过程，就变成了一个 actions 的组合。这就是 GitHub Actions 最特别的地方。&lt;/p&gt;
&lt;p&gt;GitHub 做了一个官方市场，可以搜索到他人提交的 actions。另外，还有一个 awesome actions 的仓库，也可以找到不少 action。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.wangbase.com/blogimg/asset/201909/bg2019091105.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面说了，每个 action 就是一个独立脚本，因此可以做成代码仓库，使用 userName/repoName 的语法引用 action。比如，actions/setup-node 就表示 &lt;a href=&quot;http://github.com/actions/setup-node&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github.com/actions/setup-node&lt;/a&gt; 这个仓库，它代表一个 action，作用是安装 Node.js。事实上，GitHub 官方的 actions 都放在 &lt;a href=&quot;http://github.com/actions&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github.com/actions&lt;/a&gt; 里面。&lt;/p&gt;
&lt;p&gt;既然 actions 是代码仓库，当然就有版本的概念，用户可以引用某个具体版本的 action。下面都是合法的 action 引用，用的就是 Git 的指针概念，详见官方文档。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;actions&amp;#x2F;setup-node@74bc508 # 指向一个 commit&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;actions&amp;#x2F;setup-node@v1.0    # 指向一个标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;actions&amp;#x2F;setup-node@master  # 指向一个分支&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="GitHub" scheme="https://www.hi-linux.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>推荐几个 Linux 下快速分析内存占用的工具</title>
    <link href="https://www.hi-linux.com/posts/42797.html"/>
    <id>https://www.hi-linux.com/posts/42797.html</id>
    <published>2020-05-23T02:10:00.000Z</published>
    <updated>2020-05-23T14:23:04.843Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>一个经常被问到的 <code>Linux</code> 问题：为啥 <code>Linux</code> 系统没运行多少程序，显示的可用内存这么少？</p><p>其实 <code>Linux</code> 与 <code>Windows</code> 的内存管理不同，会尽量缓存内存以提高读写性能，通常叫做 <code>Cache Memory</code>。</p><p>比较老的资料都会介绍 <code>Linux</code> 的 <code>Cache</code> 占用很多并没有关系，因为 <code>Linux</code> 会尽可能利用内存进行缓存。但是缓存的回收也是需要资源的，比较好的一篇文章是 Poor Zorro 写的 <code>Linux</code> 内存中的 Cache 真的能被回收么？。</p><p>虽然大部分情况下我们看到 <code>Cache</code> 占用很高时是没有问题的，但是我们还是想弄清楚到底是哪个程序把 <code>Cache</code> 弄的那么高，这居然不是一件容易的事。</p><p>内核的模块在分配资源的时候，为了提高效率和资源的利用率，都是透过 <code>Slab</code> 来分配的。<code>Slab</code> 为结构性缓存占用内存，该项也经常占用很大的内存。不过借助 <code>slabtop</code> 工具，我们可以很方便的显示内核片缓存信息，该工具可以更直观的显示 <code>/proc/slabinfo</code> 下的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 显示了一台机器缓存中占用对象的情况</span><br><span class="line">$ slabtop -s c </span><br><span class="line">Active &#x2F; Total Objects (% used)    : 856448 &#x2F; 873737 (98.0%)</span><br><span class="line"> Active &#x2F; Total Slabs (% used)      : 19737 &#x2F; 19737 (100.0%)</span><br><span class="line"> Active &#x2F; Total Caches (% used)     : 67 &#x2F; 89 (75.3%)</span><br><span class="line"> Active &#x2F; Total Size (% used)       : 141806.80K &#x2F; 145931.33K (97.2%)</span><br><span class="line"> Minimum &#x2F; Average &#x2F; Maximum Object : 0.01K &#x2F; 0.17K &#x2F; 8.00K</span><br><span class="line">  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ&#x2F;SLAB CACHE SIZE NAME</span><br><span class="line">416949 416949 100%    0.10K  10691 39     42764K buffer_head</span><br><span class="line">  5616   5545  98%    2.00K    351 16     11232K kmalloc-2048</span><br><span class="line">  9114   8990  98%    1.02K    294 31 9408K ext4_inode_cache</span><br><span class="line"> 12404  12404 100%    0.57K    443 28 7088K radix_tree_node</span><br><span class="line"> 10800  10731  99%    0.58K    400 27 6400K inode_cache</span><br><span class="line"> 31290  29649  94%    0.19K    745 42 5960K dentry</span><br><span class="line">  3552   3362  94%    1.00K    111 32 3552K kmalloc-1024</span><br><span class="line">  1100   1055  95%    2.84K    100 11 3200K task_struct</span><br><span class="line">  1649   1481  89%    1.88K     97 17 3104K TCP</span><br><span class="line"> 27000  27000 100%    0.11K    750 36 3000K sysfs_dir_cache</span><br><span class="line">  1380   1269  91%    2.06K     92 15 2944K sighand_cache</span><br></pre></td></tr></table></figure><p>虽然上面的命令显示了 <code>Cache</code> 中 <code>Slab</code> 的情况，但是还是没有显示什么程序占用的 <code>Cache</code>。</p><a id="more"></a><h2 id="方案一使用-pcstat-来实现">方案一：使用 Pcstat 来实现</h2><p>经过搜索，发现 <code>linux-ftools</code> 这个工具可以显示某个文件占用的 <code>Cache</code> 的情况, <code>fincore</code> 只是它其中的一个工具。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ fincore [options] files...</span><br><span class="line">  --pages&#x3D;false      Do not print pages</span><br><span class="line">  --summarize        When comparing multiple files, print a summary report</span><br><span class="line">  --only-cached      Only print stats for files that are actually in cache.</span><br><span class="line">https:&#x2F;&#x2F;colobu.com&#x2F;2017&#x2F;03&#x2F;07&#x2F;what-is-in-linux-cached&#x2F;root@xxxxxx:&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;blogindex# fincore --pages&#x3D;false --summarize --only-cached * </span><br><span class="line">stats for CLUSTER_LOG_2010_05_21.MYI: file size&#x3D;93840384 , total pages&#x3D;22910 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;0.004365 </span><br><span class="line">stats for CLUSTER_LOG_2010_05_22.MYI: file size&#x3D;417792 , total pages&#x3D;102 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;0.980392 </span><br><span class="line">stats for CLUSTER_LOG_2010_05_23.MYI: file size&#x3D;826368 , total pages&#x3D;201 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;0.497512 </span><br><span class="line">stats for CLUSTER_LOG_2010_05_24.MYI: file size&#x3D;192512 , total pages&#x3D;47 , cached pages&#x3D;1 , cached size&#x3D;4096, cached perc&#x3D;2.127660 </span><br><span class="line">stats for CLUSTER_LOG_2010_06_03.MYI: file size&#x3D;345088 , total pages&#x3D;84 , cached pages&#x3D;43 , cached size&#x3D;176128, cached perc&#x3D;51.190476 </span><br><span class="line">stats for CLUSTER_LOG_2010_06_04.MYD: file size&#x3D;1478552 , total pages&#x3D;360 , cached pages&#x3D;97 , cached size&#x3D;397312, cached perc&#x3D;26.944444 </span><br><span class="line">stats for CLUSTER_LOG_2010_06_04.MYI: file size&#x3D;205824 , total pages&#x3D;50 , cached pages&#x3D;29 , cached size&#x3D;118784, cached perc&#x3D;58.000000 </span><br><span class="line">stats for COMMENT_CONTENT_2010_06_03.MYI: file size&#x3D;100051968 , total pages&#x3D;24426 , cached pages&#x3D;10253 , cached size&#x3D;41996288, cached perc&#x3D;41.975764 </span><br><span class="line">stats for COMMENT_CONTENT_2010_06_04.MYD: file size&#x3D;716369644 , total pages&#x3D;174894 , cached pages&#x3D;79821 , cached size&#x3D;326946816, cached perc&#x3D;45.639645 </span><br><span class="line">stats for COMMENT_CONTENT_2010_06_04.MYI: file size&#x3D;56832000 , total pages&#x3D;13875 , cached pages&#x3D;5365 , cached size&#x3D;21975040, cached perc&#x3D;38.666667 </span><br><span class="line">stats for FEED_CONTENT_2010_06_03.MYI: file size&#x3D;1001518080 , total pages&#x3D;244511 , cached pages&#x3D;98975 , cached size&#x3D;405401600, cached perc&#x3D;40.478751 </span><br><span class="line">stats for FEED_CONTENT_2010_06_04.MYD: file size&#x3D;9206385684 , total pages&#x3D;2247652 , cached pages&#x3D;1018661 , cached size&#x3D;4172435456, cached perc&#x3D;45.321117 </span><br><span class="line">stats for FEED_CONTENT_2010_06_04.MYI: file size&#x3D;638005248 , total pages&#x3D;155763 , cached pages&#x3D;52912 , cached size&#x3D;216727552, cached perc&#x3D;33.969556 </span><br><span class="line">stats for FEED_CONTENT_2010_06_04.frm: file size&#x3D;9840 , total pages&#x3D;2 , cached pages&#x3D;3 , cached size&#x3D;12288, cached perc&#x3D;150.000000 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_03.MYI: file size&#x3D;1035290624 , total pages&#x3D;252756 , cached pages&#x3D;108563 , cached size&#x3D;444674048, cached perc&#x3D;42.951700 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_04.MYD: file size&#x3D;55619712720 , total pages&#x3D;13579031 , cached pages&#x3D;6590322 , cached size&#x3D;26993958912, cached perc&#x3D;48.533080 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_04.MYI: file size&#x3D;659397632 , total pages&#x3D;160985 , cached pages&#x3D;54304 , cached size&#x3D;222429184, cached perc&#x3D;33.732335 </span><br><span class="line">stats for PERMALINK_CONTENT_2010_06_04.frm: file size&#x3D;10156 , total pages&#x3D;2 , cached pages&#x3D;3 , cached size&#x3D;12288, cached perc&#x3D;150.000000 </span><br><span class="line">---</span><br><span class="line">total cached size: 32847278080</span><br></pre></td></tr></table></figure><p><code>fincore</code> 的工作原理是将指定文件的相应 <code>Inode Data</code> 与 <code>Kernel</code> 的 <code>Page Cache Table</code> 做对比，如果 <code>Page Cache Table</code> 有这个 <code>Inode</code> 信息，就找到该 <code>Inode</code> 对应的 <code>Data Block</code> 的大小。</p><p>因为 <code>Kernel</code> 的 <code>Page Cache Table</code> 只存储 <code>Data Block</code> 的引用而不是文件名，即文件的 <code>Inode</code> 信息。所以并没有任何一个工具运行一次就可以找出所有的文件使用缓存的情况。所以使用 <code>linux-fincore</code> 这个工具也只能加文件名来判断该文件是否被缓存，如果缓存，大小是多少。问题是你不能随便猜哪个文件是否被缓存吧。</p><p><code>Shanker</code> 提供了一个脚本来解决此问题，那就是查看哪些进程使用的物理内存最多，就找到该进程打开的文件，然后用 <code>fincore</code> 来查看这些文件的缓存使用率。</p><p>这个办法在大部分情况下都可以找到占用 <code>Cache</code> 较多的程序和进程。脚本内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#Author: Shanker</span><br><span class="line">#Time: 2016&#x2F;06&#x2F;08</span><br><span class="line">#set -e</span><br><span class="line">#set -u</span><br><span class="line"></span><br><span class="line">#you have to install linux-fincore</span><br><span class="line">if [ ! -f &#x2F;usr&#x2F;local&#x2F;bin&#x2F;linux-fincore ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;You haven&#39;t installed linux-fincore yet&quot;</span><br><span class="line">    exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#find the top 10 processs&#39; cache file</span><br><span class="line">ps -e -o pid,rss|sort -nk2 -r|head -10 |awk &#39;&#123;print $1&#125;&#39;&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">#find all the processs&#39; cache file</span><br><span class="line">#ps -e -o pid&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.files ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.files is exist, removing now &quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.files</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">    lsof -p $line 2&gt;&#x2F;dev&#x2F;null|awk &#39;&#123;print $9&#125;&#39; &gt;&gt;&#x2F;tmp&#x2F;cache.files </span><br><span class="line">done&lt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.fincore ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.fincore is exist, removing now&quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.fincore</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for i in &#96;cat &#x2F;tmp&#x2F;cache.files&#96;</span><br><span class="line">do</span><br><span class="line">    if [ -f $i ]</span><br><span class="line">    then</span><br><span class="line">        echo $i &gt;&gt;&#x2F;tmp&#x2F;cache.fincore</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">linux-fincore -s  &#96;cat &#x2F;tmp&#x2F;cache.fincore&#96;</span><br><span class="line">rm -f &#x2F;tmp&#x2F;cache.&#123;pids,files,fincore&#125;</span><br></pre></td></tr></table></figure><p>比较遗憾的是，<code>linux-ftools</code> 目前已经不再维护了。在新版本的操作系统上没法编译好这个程序，所以这个方法失效了。</p><p>再次通过万能的 <code>Google</code> 搜索，后来我找到了 <code>pcstat</code> 这个工具，<code>pcstat</code> 使用 Go 语言开发，功能基本和 <code>linux-ftools</code> 一样 。</p><blockquote><p>项目地址：<a href="https://github.com/tobert/pcstat" target="_blank" rel="noopener">https://github.com/tobert/pcstat</a></p></blockquote><p>然后我修改了 <code>Shanker</code> 的脚本，让它使用 <code>pcstat</code> 来进行处理，这样就可以很好的找到 <code>Cache</code> 所占用的情况。修改后的脚本如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">#you have to install pcstat</span><br><span class="line">if [ ! -f &#x2F;data0&#x2F;brokerproxy&#x2F;pcstat ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;You haven&#39;t installed pcstat yet&quot;</span><br><span class="line">    echo &quot;run \&quot;go get github.com&#x2F;tobert&#x2F;pcstat\&quot; to install&quot;</span><br><span class="line">    exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#find the top 10 processs&#39; cache file</span><br><span class="line">ps -e -o pid,rss|sort -nk2 -r|head -10 |awk &#39;&#123;print $1&#125;&#39;&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">#find all the processs&#39; cache file</span><br><span class="line">#ps -e -o pid&gt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.files ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.files is exist, removing now &quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.files</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">    lsof -p $line 2&gt;&#x2F;dev&#x2F;null|awk &#39;&#123;print $9&#125;&#39; &gt;&gt;&#x2F;tmp&#x2F;cache.files </span><br><span class="line">done&lt;&#x2F;tmp&#x2F;cache.pids</span><br><span class="line"></span><br><span class="line">if [ -f &#x2F;tmp&#x2F;cache.pcstat ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;the cache.pcstat is exist, removing now&quot;</span><br><span class="line">    rm -f &#x2F;tmp&#x2F;cache.pcstat</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for i in &#96;cat &#x2F;tmp&#x2F;cache.files&#96;</span><br><span class="line">do</span><br><span class="line">    if [ -f $i ]</span><br><span class="line">    then</span><br><span class="line">        echo $i &gt;&gt;&#x2F;tmp&#x2F;cache.pcstat</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">&#x2F;data0&#x2F;brokerproxy&#x2F;pcstat  &#96;cat &#x2F;tmp&#x2F;cache.pcstat&#96;</span><br><span class="line">rm -f &#x2F;tmp&#x2F;cache.&#123;pids,files,pcstat&#125;</span><br></pre></td></tr></table></figure><p>脚本运行成功后的显示结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+------------------------------------------+----------------+------------+-----------+---------+</span><br><span class="line">| Name                                     | Size (bytes)   | Pages      | Cached    | Percent |</span><br><span class="line">|------------------------------------------+----------------+------------+-----------+---------|</span><br><span class="line">| &#x2F;data0&#x2F;abcasyouknow&#x2F;0307&#x2F;abc             | 10060771       | 2457       | 2457      | 100.000 |</span><br><span class="line">| &#x2F;data0&#x2F;abcasyouknow&#x2F;0307&#x2F;logs&#x2F;abc.log    | 1860           | 1          | 1         | 100.000 |</span><br><span class="line">| &#x2F;data0&#x2F;abcasyouknow&#x2F;0307&#x2F;logs&#x2F;uuid.log   | 326326364      | 79670      | 79670     | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;bin&#x2F;bash                            | 960384         | 235        | 194       | 082.553 |</span><br><span class="line">| &#x2F;usr&#x2F;lib&#x2F;locale&#x2F;locale-archive           | 106065056      | 25895      | 211       | 000.815 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libnss_files-2.17.so          | 58288          | 15         | 15        | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libc-2.17.so                  | 2107760        | 515        | 336       | 065.243 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libdl-2.17.so                 | 19512          | 5          | 5         | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;libtinfo.so.5.9               | 174520         | 43         | 42        | 097.674 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;ld-2.17.so                    | 164336         | 41         | 41        | 100.000 |</span><br><span class="line">| &#x2F;usr&#x2F;lib64&#x2F;gconv&#x2F;gconv-modules.cache     | 26254          | 7          | 7         | 100.000 |</span><br><span class="line">+------------------------------------------+----------------+------------+-----------+---------+</span><br></pre></td></tr></table></figure><p>从结果我们可以看到 <code>uuid.log</code> 占用 <code>Cache</code> 比较多。这个文件是打开的，程序一直在往里面写日志，Linux 应该是把它缓存了。</p><h2 id="方案二使用-vmtouch-来实现">方案二：使用 Vmtouch 来实现</h2><p>除了上面提到的 <code>pcstat</code> 工具外，你还可以使用 <code>vmtouch</code> 来实现同样的目的。<code>vmtouch</code> 是一个可以查询到缓存的文件和目录，并且能把文件推入缓存或者驱逐出缓存的工具。</p><blockquote><p>项目地址：<a href="https://github.com/hoytech/vmtouch" target="_blank" rel="noopener">https://github.com/hoytech/vmtouch</a></p></blockquote><h3 id="安装-vmtouch">安装 Vmtouch</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;hoytech&#x2F;vmtouch</span><br><span class="line">$ cd vmtouch</span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure><h3 id="使用-vmtouch">使用 Vmtouch</h3><ol><li>vmtouch 命令语法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch</span><br><span class="line">vmtouch: no files or directories specified</span><br><span class="line"></span><br><span class="line">vmtouch v1.0.2 - the Virtual Memory Toucher by Doug Hoyte</span><br><span class="line">Portable file system cache diagnostics and control</span><br><span class="line"></span><br><span class="line">Usage: vmtouch [OPTIONS] ... FILES OR DIRECTORIES ...</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -t touch pages into memory</span><br><span class="line">  -e evict pages from memory</span><br><span class="line">  -l lock pages in physical memory with mlock(2)</span><br><span class="line">  -L lock pages in physical memory with mlockall(2)</span><br><span class="line">  -d daemon mode</span><br><span class="line">  -m max file size to touch</span><br><span class="line">  -p use the specified portion instead of the entire file</span><br><span class="line">  -f follow symbolic links</span><br><span class="line">  -h also count hardlinked copies</span><br><span class="line">  -w wait until all pages are locked (only useful together with -d)</span><br><span class="line">  -v verbose</span><br><span class="line">  -q quiet</span><br></pre></td></tr></table></figure><ol start="2"><li>一些使用的例子</li></ol><p>由于 <code>vmtouch</code> 直接支持目录级查询，所以使用起来简单得多了。</p><ul><li>查看 /tmp 目录在内存中的缓存</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch &#x2F;tmp&#x2F;</span><br><span class="line">vmtouch: WARNING: skipping non-regular file: &#x2F;tmp&#x2F;ssh-GgJnCEkWMQC2&#x2F;agent.1068</span><br><span class="line"></span><br><span class="line">           Files: 17</span><br><span class="line">     Directories: 7</span><br><span class="line">  Resident Pages: 4780&#x2F;4780  18M&#x2F;18M  100%</span><br><span class="line">         Elapsed: 0.001006 seconds</span><br></pre></td></tr></table></figure><p>如果需要查看更详细信息，可以使用 <code>-v</code> 参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -v &#x2F;tmp&#x2F;</span><br></pre></td></tr></table></figure><ul><li>查看一个文件被缓存了多少</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -v ~&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb </span><br><span class="line">&#x2F;home&#x2F;neo&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb</span><br><span class="line">[                                            ] 0&#x2F;132</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">  Resident Pages: 0&#x2F;132  0&#x2F;528K  0%</span><br><span class="line">         Elapsed: 0.000117 seconds</span><br></pre></td></tr></table></figure><ul><li>把指定的文件缓存起来</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -vt ~&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb </span><br><span class="line">&#x2F;home&#x2F;neo&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb</span><br><span class="line">[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO] 132&#x2F;132</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">   Touched Pages: 132 (528K)</span><br><span class="line">         Elapsed: 0.007935 seconds</span><br></pre></td></tr></table></figure><ul><li>把缓存中指定的数据驱逐出去</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vmtouch -ve ~&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb </span><br><span class="line">Evicting &#x2F;home&#x2F;neo&#x2F;Downloads&#x2F;phoronix-test-suite_6.0.1_all.deb</span><br><span class="line"></span><br><span class="line">           Files: 1</span><br><span class="line">     Directories: 0</span><br><span class="line">   Evicted Pages: 132 (528K)</span><br><span class="line">         Elapsed: 0.000109 seconds</span><br></pre></td></tr></table></figure><p>更多关于 <code>vmtouch</code> 使用的具体信息，你可以参考官网：<a href="https://hoytech.com/vmtouch/" target="_blank" rel="noopener">https://hoytech.com/vmtouch/</a> 。</p><p>如果你还有更多 <code>Linux</code> 下查看 <code>Cache</code> 或 <code>Buffer</code> 占用的方法，请直接留言告诉我们哟！</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://colobu.com/2017/03/07/what-is-in-linux-cached/" target="_blank" rel="noopener">https://colobu.com/2017/03/07/what-is-in-linux-cached/</a></li><li><a href="https://www.cnblogs.com/langdashu/p/5953222.html" target="_blank" rel="noopener">https://www.cnblogs.com/langdashu/p/5953222.html</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一个经常被问到的 &lt;code&gt;Linux&lt;/code&gt; 问题：为啥 &lt;code&gt;Linux&lt;/code&gt; 系统没运行多少程序，显示的可用内存这么少？&lt;/p&gt;
&lt;p&gt;其实 &lt;code&gt;Linux&lt;/code&gt; 与 &lt;code&gt;Windows&lt;/code&gt; 的内存管理不同，会尽量缓存内存以提高读写性能，通常叫做 &lt;code&gt;Cache Memory&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;比较老的资料都会介绍 &lt;code&gt;Linux&lt;/code&gt; 的 &lt;code&gt;Cache&lt;/code&gt; 占用很多并没有关系，因为 &lt;code&gt;Linux&lt;/code&gt; 会尽可能利用内存进行缓存。但是缓存的回收也是需要资源的，比较好的一篇文章是 Poor Zorro 写的 &lt;code&gt;Linux&lt;/code&gt; 内存中的 Cache 真的能被回收么？。&lt;/p&gt;
&lt;p&gt;虽然大部分情况下我们看到 &lt;code&gt;Cache&lt;/code&gt; 占用很高时是没有问题的，但是我们还是想弄清楚到底是哪个程序把 &lt;code&gt;Cache&lt;/code&gt; 弄的那么高，这居然不是一件容易的事。&lt;/p&gt;
&lt;p&gt;内核的模块在分配资源的时候，为了提高效率和资源的利用率，都是透过 &lt;code&gt;Slab&lt;/code&gt; 来分配的。&lt;code&gt;Slab&lt;/code&gt; 为结构性缓存占用内存，该项也经常占用很大的内存。不过借助 &lt;code&gt;slabtop&lt;/code&gt; 工具，我们可以很方便的显示内核片缓存信息，该工具可以更直观的显示 &lt;code&gt;/proc/slabinfo&lt;/code&gt; 下的内容。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 显示了一台机器缓存中占用对象的情况&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ slabtop -s c &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Active &amp;#x2F; Total Objects (% used)    : 856448 &amp;#x2F; 873737 (98.0%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Active &amp;#x2F; Total Slabs (% used)      : 19737 &amp;#x2F; 19737 (100.0%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Active &amp;#x2F; Total Caches (% used)     : 67 &amp;#x2F; 89 (75.3%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Active &amp;#x2F; Total Size (% used)       : 141806.80K &amp;#x2F; 145931.33K (97.2%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; Minimum &amp;#x2F; Average &amp;#x2F; Maximum Object : 0.01K &amp;#x2F; 0.17K &amp;#x2F; 8.00K&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ&amp;#x2F;SLAB CACHE SIZE NAME&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;416949 416949 100%    0.10K  10691	 39     42764K buffer_head&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  5616   5545  98%    2.00K    351	 16     11232K kmalloc-2048&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  9114   8990  98%    1.02K    294	 31	 9408K ext4_inode_cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 12404  12404 100%    0.57K    443	 28	 7088K radix_tree_node&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 10800  10731  99%    0.58K    400	 27	 6400K inode_cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 31290  29649  94%    0.19K    745	 42	 5960K dentry&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  3552   3362  94%    1.00K    111	 32	 3552K kmalloc-1024&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1100   1055  95%    2.84K    100	 11	 3200K task_struct&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1649   1481  89%    1.88K     97	 17	 3104K TCP&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 27000  27000 100%    0.11K    750	 36	 3000K sysfs_dir_cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  1380   1269  91%    2.06K     92	 15	 2944K sighand_cache&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;虽然上面的命令显示了 &lt;code&gt;Cache&lt;/code&gt; 中 &lt;code&gt;Slab&lt;/code&gt; 的情况，但是还是没有显示什么程序占用的 &lt;code&gt;Cache&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>分享几种终端下快速获取公网 IP 地址的技巧</title>
    <link href="https://www.hi-linux.com/posts/62581.html"/>
    <id>https://www.hi-linux.com/posts/62581.html</id>
    <published>2020-05-23T02:09:00.000Z</published>
    <updated>2020-05-23T14:23:04.830Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>在排除网络问题，建立新连接或配置防火墙时，了解设备的 IP 地址很重要。</p><p>IP 地址可以分为两类，公用和私有(专用)。公用 IP 是唯一的 IP 地址，可以从 Internet 访问。专用 IP 地址保留供您专用网络内部使用，而不会直接暴露给 Internet。此外，有两种类型的 IP 地址，即 IP 版本4（IPv4）和 IP 版本6（IPv6）。</p><p>本文将介绍几种确定 Linux 系统的公共 IP 地址和私有 IP 地址的不同方法。</p><h2 id="查找你的私有-ip-地址">查找你的私有 IP 地址</h2><p>专用 IP 地址不可通过 Internet 路由，并且只能在本地网络内工作。通常，专用 IP 地址是由路由器分配给本地网络中的每个设备的。这为本地网络中的设备（例如电话、笔记本电脑、智能电视、打印机、媒体中心等）提供了唯一的 IP 地址。本地网络上的设备通过 NAT（网络地址转换）连接到 Internet。</p><p>以下 IPv4 地址范围是为专用网络保留的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br></pre></td></tr></table></figure><p>你可以通过使用诸如 <code>ip</code>、<code>ifconfig</code> 或 <code>hostname</code> 命令查询网络堆栈确定系统的私有 IP 地址。</p><p>在 Linux 中，用于显示和配置网络接口的标准工具是 <code>ip</code>。</p><p>要显示所有网络接口和关联的 IP 地址的列表，请键入以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip addr</span><br></pre></td></tr></table></figure><p>输出如下所示。专用 IP 地址突出显示。</p><p><img src="https://linuxize.com/post/how-to-find-ip-address-linux/private-ip.jpg" alt=""></p><p>你还可以使用以下命令来显示私有 IP 地址：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hostname -I</span><br><span class="line"></span><br><span class="line">$ ifconfig</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="查找你的公共-ip-地址">查找你的公共 IP 地址</h2><p>公共 IP 地址是分配给网络设备的全球可路由 IP 地址，它允许直接访问 Internet。它们由其 ISP 分配给设备，并且每个设备都有唯一的公共 IP 地址。公用 IP 地址由家庭路由器、Web 服务器、邮件服务器等使用。</p><p>确定公共 IP 地址可以通过 <code>HTTP/HTTPS</code> 或 <code>DNS</code> 协议联系远程服务器，并从远程服务器响应中获取 IP 地址。</p><p>如果你是在没有 GUI 的 Linux 服务器上获取你分配到的公网 IP 地址，你可以使用命令行工具 <code>dig</code>、<code>curl</code> 和 <code>wget</code> 等来获取。</p><p>大多数 DNS 提供商（例如：OpenDNS 和 Google）都允许你查询其服务器并获取你的公共 IP 地址。你可以使用以下任何命令来获取公网 IP：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ dig ANY +short @resolver2.opendns.com myip.opendns.com</span><br><span class="line"></span><br><span class="line">$ dig ANY +short @resolver2.opendns.com myip.opendns.com</span><br><span class="line"></span><br><span class="line">$ dig ANY +short @ns1-1.akamaitech.net ANY whoami.akamai.net</span><br></pre></td></tr></table></figure><p>另外，有许多在线 <code>HTTP/HTTPS</code> 服务可以返回你的公共 IP 地址。这里是其中的一些：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ curl -s http://tnx.nl/ip</span><br><span class="line"></span><br><span class="line">$ curl -s https://checkip.amazonaws.com</span><br><span class="line"></span><br><span class="line">$ curl -s api.infoip.io/ip</span><br><span class="line"></span><br><span class="line">$ curl -s ip.appspot.com</span><br><span class="line"></span><br><span class="line">$ wget -O - -q https://icanhazip.com/</span><br></pre></td></tr></table></figure><p>为了方便使用，你还可以创建一个别名来方便查询。例如，你可以在 <code>~/.bashrc</code> 和 <code>~/.zshrc</code> 中添加以下别名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> pubip=<span class="string">'dig ANY +short @resolver2.opendns.com myip.opendns.com'</span></span><br></pre></td></tr></table></figure><p>现在，你要查找公共 IP 时，只需键入 <code>pubip</code> 命令即可。</p><h2 id="结论">结论</h2><p>至此，我们向你展示了通过几种不同的命令和在线服来查找私有和公共 IP 地址的方法，希望对你有所帮助！</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://url.cn/5eJaO9n" target="_blank" rel="noopener">https://url.cn/5eJaO9n</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在排除网络问题，建立新连接或配置防火墙时，了解设备的 IP 地址很重要。&lt;/p&gt;
&lt;p&gt;IP 地址可以分为两类，公用和私有(专用)。公用 IP 是唯一的 IP 地址，可以从 Internet 访问。专用 IP 地址保留供您专用网络内部使用，而不会直接暴露给 Internet。此外，有两种类型的 IP 地址，即 IP 版本4（IPv4）和 IP 版本6（IPv6）。&lt;/p&gt;
&lt;p&gt;本文将介绍几种确定 Linux 系统的公共 IP 地址和私有 IP 地址的不同方法。&lt;/p&gt;
&lt;h2 id=&quot;查找你的私有-IP-地址&quot;&gt;查找你的私有 IP 地址&lt;/h2&gt;
&lt;p&gt;专用 IP 地址不可通过 Internet 路由，并且只能在本地网络内工作。通常，专用 IP 地址是由路由器分配给本地网络中的每个设备的。这为本地网络中的设备（例如电话、笔记本电脑、智能电视、打印机、媒体中心等）提供了唯一的 IP 地址。本地网络上的设备通过 NAT（网络地址转换）连接到 Internet。&lt;/p&gt;
&lt;p&gt;以下 IPv4 地址范围是为专用网络保留的：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;10.0.0.0/8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.0.0/12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192.168.0.0/16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;你可以通过使用诸如 &lt;code&gt;ip&lt;/code&gt;、&lt;code&gt;ifconfig&lt;/code&gt; 或 &lt;code&gt;hostname&lt;/code&gt; 命令查询网络堆栈确定系统的私有 IP 地址。&lt;/p&gt;
&lt;p&gt;在 Linux 中，用于显示和配置网络接口的标准工具是 &lt;code&gt;ip&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;要显示所有网络接口和关联的 IP 地址的列表，请键入以下命令：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ip addr&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;输出如下所示。专用 IP 地址突出显示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://linuxize.com/post/how-to-find-ip-address-linux/private-ip.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;你还可以使用以下命令来显示私有 IP 地址：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hostname -I&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ ifconfig&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="终端" scheme="https://www.hi-linux.com/tags/%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>几种 Docker 和 Kubernetes 镜像源不可用的解决方法</title>
    <link href="https://www.hi-linux.com/posts/3814.html"/>
    <id>https://www.hi-linux.com/posts/3814.html</id>
    <published>2020-05-23T02:08:00.000Z</published>
    <updated>2020-05-23T14:23:04.828Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>由于众所周知的原因， Docker 官方镜像仓库和 Google 镜像仓库在国内访问速度很慢或者不可用。这样就给我们在部署和使用 Kubernetes 时带来了极大的不便。今天我们就来介绍几种方法，可以让你愉快的解决该问题。</p><p>既然是网络方面的问题，解决该问题的思路就很简单了，当然是使用国内可用的镜像源。这里为大家推荐两个好用的国内镜像源：Azure 中国镜像源和中科大镜像源。</p><p><strong>Azure 中国镜像源</strong></p><ul><li><p>Azure 中国镜像源地址：<a href="http://mirror.azure.cn/" target="_blank" rel="noopener">http://mirror.azure.cn/</a></p></li><li><p>Azure 中国镜像源 Github 地址：<a href="https://github.com/Azure/container-service-for-azure-china" target="_blank" rel="noopener">https://github.com/Azure/container-service-for-azure-china</a></p></li><li><p>镜像源配置说明：<a href="http://mirror.azure.cn/help/gcr-proxy-cache.html" target="_blank" rel="noopener">http://mirror.azure.cn/help/gcr-proxy-cache.html</a></p></li></ul><p><strong>中科大镜像源</strong></p><ul><li><p>中科大镜像源地址：<a href="http://mirrors.ustc.edu.cn/" target="_blank" rel="noopener">http://mirrors.ustc.edu.cn/</a></p></li><li><p>中科大镜像源 Github 地址：<a href="https://github.com/ustclug/mirrorrequest" target="_blank" rel="noopener">https://github.com/ustclug/mirrorrequest</a></p></li><li><p>镜像源配置说明：<a href="https://github.com/ustclug/mirrorrequest/issues/187" target="_blank" rel="noopener">https://github.com/ustclug/mirrorrequest/issues/187</a></p></li></ul><a id="more"></a><h2 id="使用镜像源加速-dockerio-镜像仓库">使用镜像源加速 <a href="http://Docker.io" target="_blank" rel="noopener">Docker.io</a> 镜像仓库</h2><p><a href="http://hub.docker.com" target="_blank" rel="noopener">hub.docker.com</a> 是 Docker 官方镜像仓库，也是我们平时在使用 Docker 过程使用最多的一个镜像仓库。该镜像仓库平时拉取速度通常就只有几十 Kb，非常的慢，使用起来严重影响了工作效率。</p><p>既然现在国内有镜像源可用，我们当然直接使国内镜像源便可。下面分别对其使用方法进行介绍。</p><ul><li>如果在 Docker 官方仓库拉取的是官方镜像</li></ul><p>拉取方法类似如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull xxx:yyy</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;library&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;library&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><ul><li>如果在 Docker 官方仓库拉取的镜像是私有仓库</li></ul><p>拉取方法类似如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull xxx&#x2F;yyy:zz</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;xxx&#x2F;yyy:zz</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;xxx&#x2F;yyy:zz</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 mysql:5.7 和 360cloud/wayne 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;library&#x2F;mysql:5.7</span><br><span class="line">$ docker pull docker.mirrors.ustc.edu.cn&#x2F;360cloud&#x2F;wayne</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;library&#x2F;mysql:5.7</span><br><span class="line">$ docker pull dockerhub.azk8s.cn&#x2F;360cloud&#x2F;wayne</span><br></pre></td></tr></table></figure><blockquote><p>注：首次拉取时可能会有 <code>Error:image library/mysql:5.7 not found</code> 类似报错，这说明镜像源中没有缓存该镜像。这个属于正常现像，因为加速镜像都是先从官方镜像仓库进行拉取的，然后缓存到本地。遇到这种情况，你可以尝试多拉取几次即可。</p></blockquote><h2 id="使用镜像源加速-gcrio-镜像仓库">使用镜像源加速 <a href="http://gcr.io" target="_blank" rel="noopener">gcr.io</a> 镜像仓库</h2><ul><li>如果拉取的 Google 镜像仓库中容器镜像类似如下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.io&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.azk8s.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 <a href="http://gcr.io/kubernetes-helm/tiller:v2.9.1" target="_blank" rel="noopener">gcr.io/kubernetes-helm/tiller:v2.9.1</a> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;kubernetes-helm&#x2F;tiller:v2.9.1</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull gcr.azk8s.cn&#x2F;kubernetes-helm&#x2F;tiller:v2.9.1</span><br></pre></td></tr></table></figure><h2 id="使用镜像源加速-k8sgcrio-镜像仓库">使用镜像源加速 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a> 镜像仓库</h2><p>部署或使用 Kubernetes 时我们会使用到很多相关的镜像，而这些镜像通常会使用 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a> 这个镜像仓库。</p><p>其实 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a> 就是 <a href="http://gcr.io/google-containers" target="_blank" rel="noopener">gcr.io/google-containers</a> 下面的容器镜像，这样我们也可以使用中科大镜像源或者 Azure 中国镜像源来对此进行加速。</p><ul><li>如果我们拉取的 Kubernetes 所需容器镜像类似以下形式：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull k8s.gcr.io&#x2F;xxx:yyy</span><br><span class="line"></span><br><span class="line"># 相当于</span><br><span class="line">$ docker pull gcr.io&#x2F;google-containers&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;google-containers&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull gcr.azk8s.cn&#x2F;google-containers&#x2F;xxx:yyy</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 <a href="http://k8s.gcr.io/addon-resizer:1.8.3" target="_blank" rel="noopener">k8s.gcr.io/addon-resizer:1.8.3</a> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull gcr.mirrors.ustc.edu.cn&#x2F;google-containers&#x2F;addon-resizer:1.8.3</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull gcr.azk8s.cn&#x2F;google-containers&#x2F;addon-resizer:1.8.3</span><br></pre></td></tr></table></figure><h2 id="使用镜像源加速-quayio-镜像仓库">使用镜像源加速 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 镜像仓库</h2><p>部署或使用 Kubernetes 相关周边组件或生态时我们经常会从 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 镜像仓库拉取镜像。<a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 默认情况下在国内也是不可用的，同样我们也可以通过中科大镜像源和 Azure 中国镜像源进行加速访问。</p><ul><li>如果我们拉取的 <a href="http://quay.io" target="_blank" rel="noopener">quay.io</a> 下所需容器镜像类似以下形式：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull quay.io&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用中科大镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull quay.mirrors.ustc.edu.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><p>使用 Azure 中国镜像源，应该类似这样拉取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull quay.azk8s.cn&#x2F;xxx&#x2F;yyy:zzz</span><br></pre></td></tr></table></figure><ul><li>演示一个使用镜像源拉取的实例</li></ul><p>下面我们以拉取 <a href="http://quay.io/coreos/kube-state-metrics:v1.5.0" target="_blank" rel="noopener">quay.io/coreos/kube-state-metrics:v1.5.0</a> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用中科大镜像源 </span><br><span class="line">$ docker pull quay.mirrors.ustc.edu.cn&#x2F;coreos&#x2F;kube-state-metrics:v1.5.0</span><br><span class="line"></span><br><span class="line"># 使用 Azure 中国镜像源</span><br><span class="line">$ docker pull quay.azk8s.cn&#x2F;coreos&#x2F;kube-state-metrics:v1.5.0</span><br></pre></td></tr></table></figure><h2 id="一些自动化工具">一些自动化工具</h2><p>上面我们讲解和演示了如何使用中科大和 Azure 中国镜像源加速拉取镜像的方法。不过这些方法都是手动的，还不够方便。下面将介绍两个小工具，让你可以更加方便和快速的使用这些镜像源。</p><h3 id="docker-wrapper">docker-wrapper</h3><p>一个 Python 编写的工具脚本，可以替代系统的 Docker 命令，自动从 Azure 中国拉取镜像并自动 Tag 为目标镜像和删除 Azure 镜像，一气呵成。</p><p>项目地址：<a href="https://github.com/silenceshell/docker_wrapper" target="_blank" rel="noopener">https://github.com/silenceshell/docker_wrapper</a></p><p><strong>docker-wrapper 安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;silenceshell&#x2F;docker-wrapper.git</span><br><span class="line">$ sudo cp docker-wrapper&#x2F;docker-wrapper.py &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p><strong>docker-wrapper 使用</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker-wrapper pull k8s.gcr.io&#x2F;kube-apiserver:v1.14.1</span><br><span class="line">$ docker-wrapper pull gcr.io&#x2F;google_containers&#x2F;kube-apiserver:v1.14.1</span><br><span class="line">$ docker-wrapper pull nginx</span><br><span class="line">$ docker-wrapper pull silenceshell&#x2F;godaddy:0.0.2</span><br></pre></td></tr></table></figure><h3 id="azk8spull">azk8spull</h3><p>一个 Shell 编写的脚本，这个脚本功能和 docker-wrapper 类似。同样可以自动从 Azure 中国拉取镜像并自动 Tag 为目标镜像和删除 Azure 镜像。</p><p>项目地址：<a href="https://github.com/xuxinkun/littleTools#azk8spull" target="_blank" rel="noopener">https://github.com/xuxinkun/littleTools#azk8spull</a></p><p><strong>azk8spull 安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;xuxinkun&#x2F;littleTools</span><br><span class="line">$ cd littleTools</span><br><span class="line">$ chmod +x install.sh</span><br><span class="line">$ .&#x2F;install.sh</span><br></pre></td></tr></table></figure><p><strong>azk8spull 使用</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ azk8spull quay.io&#x2F;kubernetes-ingress-controller&#x2F;nginx-ingress-controller:0.24.1</span><br><span class="line">$ azk8spull k8s.gcr.io&#x2F;pause-amd64:3.1</span><br></pre></td></tr></table></figure><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://ieevee.com/tech/2019/03/02/azure-gcr-proxy.html" target="_blank" rel="noopener">https://ieevee.com/tech/2019/03/02/azure-gcr-proxy.html</a></p></li><li><p><a href="https://www.cnblogs.com/xuxinkun/p/11025020.html" target="_blank" rel="noopener">https://www.cnblogs.com/xuxinkun/p/11025020.html</a></p></li><li><p><a href="https://www.ilanni.com/?p=14534" target="_blank" rel="noopener">https://www.ilanni.com/?p=14534</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;由于众所周知的原因， Docker 官方镜像仓库和 Google 镜像仓库在国内访问速度很慢或者不可用。这样就给我们在部署和使用 Kubernetes 时带来了极大的不便。今天我们就来介绍几种方法，可以让你愉快的解决该问题。&lt;/p&gt;
&lt;p&gt;既然是网络方面的问题，解决该问题的思路就很简单了，当然是使用国内可用的镜像源。这里为大家推荐两个好用的国内镜像源：Azure 中国镜像源和中科大镜像源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Azure 中国镜像源&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Azure 中国镜像源地址：&lt;a href=&quot;http://mirror.azure.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirror.azure.cn/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Azure 中国镜像源 Github 地址：&lt;a href=&quot;https://github.com/Azure/container-service-for-azure-china&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/Azure/container-service-for-azure-china&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;镜像源配置说明：&lt;a href=&quot;http://mirror.azure.cn/help/gcr-proxy-cache.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirror.azure.cn/help/gcr-proxy-cache.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;中科大镜像源&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;中科大镜像源地址：&lt;a href=&quot;http://mirrors.ustc.edu.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirrors.ustc.edu.cn/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;中科大镜像源 Github 地址：&lt;a href=&quot;https://github.com/ustclug/mirrorrequest&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/ustclug/mirrorrequest&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;镜像源配置说明：&lt;a href=&quot;https://github.com/ustclug/mirrorrequest/issues/187&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/ustclug/mirrorrequest/issues/187&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款 Github 命令行管理神器 Hub</title>
    <link href="https://www.hi-linux.com/posts/28689.html"/>
    <id>https://www.hi-linux.com/posts/28689.html</id>
    <published>2020-05-23T02:07:00.000Z</published>
    <updated>2020-05-23T14:23:04.839Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>对于大多数使用 <code>Git</code> 作为版本管理的技术人员来说，应该都接触过 <code>GitHub</code>。 <code>GitHub</code> 就像技术人员的淘宝一样，里面充满了好东西，时时刻刻都可能给你惊喜！</p><p>很多人可能不仅在 <code>GitHub</code> 上寻找合适的车轮子，还可能会为造车轮子贡献自己的力量，往往会使用一些基本操作来完成，典型的为：</p><ul><li><p>Fork</p></li><li><p>PR (pull request)</p></li></ul><p>当然，如果你是项目的维护者，还会使用 <code>Merge</code> 等操作。</p><p>但是，我想很少人会使用过 <code>GitHub</code> 的命令行接口 <code>Hub</code>， 通常的操作我们都可以通过友好的 <code>Web</code> 界面，点几个按钮来完成，简单实用！所以很少有需求会迫切需要一个命令行工具来完成这些操作，但是如果需要批量操作时 (比如：清除多个 <code>Repositories</code> 的时候)，你会发现一个一个在 Web 上来操作的确不够高效。这时如果有命令行工具可以快速进行批量操作，那就是极好的。</p><p>今天就给大家推荐一个 <code>GitHub</code> 的命令行工具 <code>Hub</code>，其官方主页上是这样介绍的：</p><blockquote><p>git + hub = github</p></blockquote><p><code>Hub</code> 命令是对 <code>Git</code> 命令的一层封装，利用 <code>GitHub</code> 的 <code>API</code> 可以轻松的扩展 <code>Git</code> 的能力，比如常见的 <code>Pull Requests</code> 都可以通过命令行来实现。</p><blockquote><p>项目地址：<a href="https://github.com/github/hub" target="_blank" rel="noopener">https://github.com/github/hub</a></p></blockquote><a id="more"></a><h2 id="安装-hub">安装 Hub</h2><p><code>Hub</code> 的安装很简单，基本上所有的主流平台上都支持一键安装。</p><p><img src="https://i.loli.net/2019/10/30/ENKUdWsF7COuqLx.png" alt=""></p><blockquote><p>由于 <code>Hub</code> 是对 <code>Git</code> 命令的封装，安装前请保证机器上的 <code>Git</code> 版本在 <code>1.7.3</code> 或以上。</p></blockquote><p>如果你使用平台不在上面列表中，你也可以直接在官方项目的 <a href="https://github.com/github/hub/releases" target="_blank" rel="noopener">Releases 页面</a>下载 <code>Hub</code> 的二进制包进行安装。</p><p>为了快速实现通过二进制包安装，你还可以使用下面这个脚本来简化操作步骤。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里以 Linux 平台为例，如果是其它版本或平台，只需简单替换 VERSION 变量和对应文件名前缀即可。</span></span><br><span class="line">VERSION=<span class="string">"2.12.8"</span></span><br><span class="line">wget https://github.com/github/hub/releases/download/v<span class="variable">$VERSION</span>/hub-linux-amd64-<span class="variable">$VERSION</span>.tgz</span><br><span class="line">tar xzvf hub-linux-amd64-<span class="variable">$VERSION</span>.tgz</span><br><span class="line">sudo ./hub-linux-amd64-<span class="variable">$VERSION</span>/install</span><br></pre></td></tr></table></figure><h2 id="配置-hub">配置 Hub</h2><p>当第一次和 <code>GitHub</code> 有交互时会弹出用户名和密码用来生成 <code>OAuth Token</code>，<code>Token</code> 保存在 <code>~/.config/hub</code> 文件中。或者你也可以通过 <code>GITHUB_TOKEN</code> 环境变量来进行授权，其值是拥有 <code>Repo</code> 权限的 <code>Access Token</code>。</p><p>如果你使用的是 <code>ZSH</code>，还可以给 <code>Hub</code> 配置一个自动完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup autocomplete for zsh:</span></span><br><span class="line">mkdir -p ~/.zsh/completions</span><br><span class="line">cp ./hub-linux-amd64-<span class="variable">$VERSION</span>/etc/hub.zsh_completion ~/.zsh/completions/_hub</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"fpath=(~/.zsh/completions <span class="variable">$fpath</span>)"</span> &gt;&gt; ~/.zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"autoload -U compinit &amp;&amp; compinit"</span> &gt;&gt; ~/.zshrc</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"eval "</span>$(hub <span class="built_in">alias</span> -s)<span class="string">""</span> &gt;&gt; ~/.zshrc</span><br></pre></td></tr></table></figure><h2 id="使用-hub">使用 Hub</h2><h3 id="常用命令介绍">常用命令介绍</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">usage: git [--version] [--<span class="built_in">help</span>] [-C &lt;path&gt;] [-c name=value]</span><br><span class="line">           [--<span class="built_in">exec</span>-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]</span><br><span class="line">           [-p | --paginate | --no-pager] [--no-replace-objects] [--bare]</span><br><span class="line">           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]</span><br><span class="line">           &lt;<span class="built_in">command</span>&gt; [&lt;args&gt;]</span><br><span class="line"></span><br><span class="line">These are common Git commands used <span class="keyword">in</span> various situations:</span><br><span class="line"></span><br><span class="line">start a working area (see also: git <span class="built_in">help</span> tutorial)</span><br><span class="line">   <span class="built_in">clone</span>      Clone a repository into a new directory <span class="comment"># 使用 hub clone 命令，可以省去指定 GitHub 端仓库的部分。</span></span><br><span class="line">   init       Create an empty Git repository or reinitialize an existing one</span><br><span class="line"></span><br><span class="line">work on the current change (see also: git <span class="built_in">help</span> everyday)</span><br><span class="line">   add        Add file contents to the index</span><br><span class="line">   mv         Move or rename a file, a directory, or a symlink</span><br><span class="line">   reset      Reset current HEAD to the specified state</span><br><span class="line">   rm         Remove files from the working tree and from the index</span><br><span class="line"></span><br><span class="line">examine the <span class="built_in">history</span> and state (see also: git <span class="built_in">help</span> revisions)</span><br><span class="line">   bisect     Use binary search to find the commit that introduced a bug</span><br><span class="line">   grep       Print lines matching a pattern</span><br><span class="line">   <span class="built_in">log</span>        Show commit logs</span><br><span class="line">   show       Show various types of objects</span><br><span class="line">   status     Show the working tree status</span><br><span class="line"></span><br><span class="line">grow, mark and tweak your common <span class="built_in">history</span></span><br><span class="line">   branch     List, create, or delete branches</span><br><span class="line">   checkout   Switch branches or restore working tree files</span><br><span class="line">   commit     Record changes to the repository</span><br><span class="line">   diff       Show changes between commits, commit and working tree, etc</span><br><span class="line">   merge      Join two or more development histories together</span><br><span class="line">   rebase     Reapply commits on top of another base tip</span><br><span class="line">   tag        Create, list, delete or verify a tag object signed with GPG</span><br><span class="line"></span><br><span class="line">collaborate (see also: git <span class="built_in">help</span> workflows)</span><br><span class="line">   fetch      Download objects and refs from another repository</span><br><span class="line">   pull       Fetch from and integrate with another repository or a <span class="built_in">local</span> branch</span><br><span class="line">   push       Update remote refs along with associated objects   <span class="comment"># hub push 命令支持通知向多个远程仓库进行 push 操作。</span></span><br><span class="line"></span><br><span class="line"><span class="string">'git help -a'</span> and <span class="string">'git help -g'</span> list available subcommands and some</span><br><span class="line">concept guides. See <span class="string">'git help &lt;command&gt;'</span> or <span class="string">'git help &lt;concept&gt;'</span></span><br><span class="line">to <span class="built_in">read</span> about a specific subcommand or concept.</span><br><span class="line"></span><br><span class="line">These GitHub commands are provided by hub:</span><br><span class="line"></span><br><span class="line">   browse         Open a GitHub page <span class="keyword">in</span> the default browser</span><br><span class="line">   ci-status      Show the CI status of a commit</span><br><span class="line">   compare        Open a compare page on GitHub</span><br><span class="line">   create         Create this repository on GitHub and add GitHub as origin <span class="comment"># hub create 命令适用于本地已经创建仓库，但 GitHub 端没有创建仓库的情况。</span></span><br><span class="line">   fork           Make a fork of a remote repository on GitHub and add as remote <span class="comment"># hub fork 命令的功能与 GitHub 页面的 Fork 按钮相同。</span></span><br><span class="line">   issue          List or create issues</span><br><span class="line">   pr             Work with pull requests</span><br><span class="line">   pull-request   Open a pull request on GitHub <span class="comment"># hub  pull-request 命令为我们提供了创建 Pull Request 的功能，利用这个命令可以在不访问 GitHub 页面的情况下创建 Pull Request。</span></span><br><span class="line">   release        List or create releases</span><br></pre></td></tr></table></figure><h3 id="使用实例">使用实例</h3><p>这里以一个开源项目贡献者的身份为例，你可以使用命令来拉取代码、浏览页面、<code>Fork Repos</code> 和提交 <code>Pull Requests</code> 等等。</p><ol><li>Fork 一个项目</li></ol><p>要在 <code>GitHub</code> 上进行开发，往往会基于一个已有的开源项目，所以首先需要 <code>Fork</code> 这个项目。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ hub <span class="built_in">clone</span> github/hub</span><br><span class="line">Cloning into <span class="string">'hub'</span>...</span><br><span class="line">remote: Counting objects: 10646, <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (24/24), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 10646 (delta 4), reused 0 (delta 0)</span><br><span class="line">Receiving objects: 100% (10646/10646), 3.25 MiB | 58.00 KiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (6302/6302), <span class="keyword">done</span>.</span><br><span class="line">Checking connectivity... <span class="keyword">done</span>.</span><br><span class="line">$ <span class="built_in">cd</span> hub/</span><br><span class="line">$ hub fork</span><br><span class="line">Updating chengweiv5</span><br><span class="line">From git://github.com/github/hub</span><br><span class="line"> * [new branch]      1.11-stable -&gt; chengweiv5/1.11-stable</span><br><span class="line"> * [new branch]      1.12-stable -&gt; chengweiv5/1.12-stable</span><br><span class="line"> * [new branch]      gh-pages   -&gt; chengweiv5/gh-pages</span><br><span class="line"> * [new branch]      master     -&gt; chengweiv5/master</span><br><span class="line"> * [new branch]      skip_completion_script_for_windows -&gt; chengweiv5/skip_completion_script_for_windows</span><br><span class="line">new remote: chengweiv5</span><br></pre></td></tr></table></figure><p>这里和 <code>Web</code> 上的操作有点不同，从 <code>Web</code> 上是首先找到一个项目，然后点击一下 <code>Fork</code>， 然后会在自己的空间内创建这个项目。</p><p>而使用 <code>Hub</code>, 则首先是 <code>Clone</code> 下来原有的项目（以 <code>hub</code> 项目为例，<code>hub clone github/hub</code>），然后再执行 <code>Fork</code> 子命令。完成后，可以看到本地添加了一个 <code>Remote</code>，而且通过 <code>Web</code> 页面也可以看到自己的空间里已经添加了一个叫 <code>hub</code> 的项目，<code>Fork</code> 自 <code>github/hub</code>。</p><ol start="2"><li>PR (Pull Request)</li></ol><p>在本地完成一些开发后，可能想要将 <code>Patch</code> 提交给 <code>Upstream</code> 项目，在 <code>GitHub</code> 中，向上游提交 <code>Patch</code> 通过 <code>PR</code> 来完成。下面我们以 <code>sb2nov/mac-setup</code> 为例，来看一看整体过程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ hub <span class="built_in">clone</span> sb2nov/mac-setup</span><br><span class="line">Cloning into <span class="string">'mac-setup'</span>...</span><br><span class="line">remote: Counting objects: 1635, <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (49/49), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 1635 (delta 33), reused 0 (delta 0)</span><br><span class="line">Receiving objects: 100% (1635/1635), 3.69 MiB | 59.00 KiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (941/941), <span class="keyword">done</span>.</span><br><span class="line">Checking connectivity... <span class="keyword">done</span>.</span><br><span class="line">$ <span class="built_in">cd</span> mac-setup</span><br><span class="line">$ hub fork</span><br></pre></td></tr></table></figure><p>完成 <code>Fork</code> 后，将文档进行一个小修改，<code>diff</code> 如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ git diff</span><br><span class="line">diff --git a/SystemPreferences/README.md b/SystemPreferences/README.md</span><br><span class="line">index a148d74..a7ff953 100644</span><br><span class="line">--- a/SystemPreferences/README.md</span><br><span class="line">+++ b/SystemPreferences/README.md</span><br><span class="line">@@ -1,7 +1,7 @@</span><br><span class="line"> <span class="comment"># System Preferences</span></span><br><span class="line"> </span><br><span class="line"> First thing you need to <span class="keyword">do</span>, on any OS actually, is update the system! For that: **Apple Icon &gt; Software Update.**</span><br><span class="line">-Also upgrade your OS incase you want to work on the latest OS. Mavericks is a free upgrade so please check that.</span><br><span class="line">+Also upgrade your OS incase you want to work on the latest OS. Yosemite is a free upgrade so please check that.</span><br><span class="line"> </span><br><span class="line"> If this is a new computer, there are a couple tweaks you would like to make to the System Preferences. Feel free to follow these, or to ignore them, depending on your personal preferences.</span><br></pre></td></tr></table></figure><p><code>git pull-request</code> 会检查你在 <code>GitHub</code> 上的自己的项目和上游项目相应的 <code>Branch</code> 是否有不同。所以，首先将这个修改提交到自己的项目中，<code>Push</code> 就行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ git commit -asm <span class="string">"Yosemite is the latest Mac OS X now"</span></span><br><span class="line">$ git push chengweiv5</span><br><span class="line">Counting objects: 4, <span class="keyword">done</span>.</span><br><span class="line">Delta compression using up to 4 threads.</span><br><span class="line">Compressing objects: 100% (3/3), <span class="keyword">done</span>.</span><br><span class="line">Writing objects: 100% (4/4), 391 bytes | 0 bytes/s, <span class="keyword">done</span>.</span><br><span class="line">Total 4 (delta 2), reused 0 (delta 0)</span><br><span class="line">To git@github.com:chengweiv5/mac-setup.git</span><br><span class="line">   16df764..e25031f  master -&gt; master</span><br></pre></td></tr></table></figure><p>然后，提交 <code>PR</code>，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hub pull-request </span><br><span class="line">https://github.com/sb2nov/mac-setup/pull/27</span><br></pre></td></tr></table></figure><blockquote><p>注：为了统一命令操作，你可以直接将 <code>Hub</code> 命令设置为 <code>Git</code> 命令的别名，让执行 <code>Git</code> 操作的时候实际上是在执行 <code>Hub</code> 命令。别名设置方法如下：<code>eval &quot;$(hub alias -s)&quot;</code> 。</p></blockquote><p>除了以上例子外，<code>Hub</code> 还有许多有用的命令，比如：打开浏览器查看项目、<code>Merge PR</code>，新建 <code>Repo</code> 等等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># open the current project's issues page</span></span><br><span class="line">$ hub browse -- issues</span><br><span class="line">→ open https://github.com/github/hub/issues</span><br><span class="line"></span><br><span class="line"><span class="comment"># open another project's wiki</span></span><br><span class="line">$ hub browse mojombo/jekyll wiki</span><br><span class="line">→ open https://github.com/mojombo/jekyll/wiki</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new repository</span></span><br><span class="line">$ hub create sinatra/recipes</span><br><span class="line">[ repo created <span class="keyword">in</span> GitHub organization ]</span><br><span class="line">&gt; git remote add -f origin git@github.com:sinatra/recipes.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete an existing repository</span></span><br><span class="line">$ hub delete sinatra/recipes</span><br><span class="line">[ repo deleted <span class="keyword">in</span> GitHub organization ]</span><br></pre></td></tr></table></figure><p>这里就不再一一介绍了， 感兴趣的读者可以参考 <code>Hub</code> 官方文档进一步探索更多好玩好用的高级功能。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://www.jianshu.com/p/10b6e8d9420f" target="_blank" rel="noopener">https://www.jianshu.com/p/10b6e8d9420f</a></p></li><li><p><a href="http://www.chengweiyang.cn/2015/01/24/learn-github-hub/" target="_blank" rel="noopener">http://www.chengweiyang.cn/2015/01/24/learn-github-hub/</a></p></li><li><p><a href="http://einverne.github.io/post/2018/10/use-hub-command-to-interact-with-github.html" target="_blank" rel="noopener">http://einverne.github.io/post/2018/10/use-hub-command-to-interact-with-github.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于大多数使用 &lt;code&gt;Git&lt;/code&gt; 作为版本管理的技术人员来说，应该都接触过 &lt;code&gt;GitHub&lt;/code&gt;。 &lt;code&gt;GitHub&lt;/code&gt; 就像技术人员的淘宝一样，里面充满了好东西，时时刻刻都可能给你惊喜！&lt;/p&gt;
&lt;p&gt;很多人可能不仅在 &lt;code&gt;GitHub&lt;/code&gt; 上寻找合适的车轮子，还可能会为造车轮子贡献自己的力量，往往会使用一些基本操作来完成，典型的为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Fork&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PR (pull request)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然，如果你是项目的维护者，还会使用 &lt;code&gt;Merge&lt;/code&gt; 等操作。&lt;/p&gt;
&lt;p&gt;但是，我想很少人会使用过 &lt;code&gt;GitHub&lt;/code&gt; 的命令行接口 &lt;code&gt;Hub&lt;/code&gt;， 通常的操作我们都可以通过友好的 &lt;code&gt;Web&lt;/code&gt; 界面，点几个按钮来完成，简单实用！所以很少有需求会迫切需要一个命令行工具来完成这些操作，但是如果需要批量操作时 (比如：清除多个 &lt;code&gt;Repositories&lt;/code&gt; 的时候)，你会发现一个一个在 Web 上来操作的确不够高效。这时如果有命令行工具可以快速进行批量操作，那就是极好的。&lt;/p&gt;
&lt;p&gt;今天就给大家推荐一个 &lt;code&gt;GitHub&lt;/code&gt; 的命令行工具 &lt;code&gt;Hub&lt;/code&gt;，其官方主页上是这样介绍的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;git + hub = github&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Hub&lt;/code&gt; 命令是对 &lt;code&gt;Git&lt;/code&gt; 命令的一层封装，利用 &lt;code&gt;GitHub&lt;/code&gt; 的 &lt;code&gt;API&lt;/code&gt; 可以轻松的扩展 &lt;code&gt;Git&lt;/code&gt; 的能力，比如常见的 &lt;code&gt;Pull Requests&lt;/code&gt; 都可以通过命令行来实现。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/github/hub&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/github/hub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="虚拟化" scheme="https://www.hi-linux.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
</feed>
