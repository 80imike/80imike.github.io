<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维之美</title>
  
  <subtitle>种一棵树最好的时间是十年前，其次是现在。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hi-linux.com/"/>
  <updated>2020-05-22T04:50:00.598Z</updated>
  <id>https://www.hi-linux.com/</id>
  
  <author>
    <name>Mike</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何优雅的在 Docker 容器中指定用户及组权限的三种方式</title>
    <link href="https://www.hi-linux.com/posts/44367.html"/>
    <id>https://www.hi-linux.com/posts/44367.html</id>
    <published>2020-05-22T01:00:00.000Z</published>
    <updated>2020-05-22T04:50:00.598Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>如果平常有在玩 Docker 的用户肯定知道透过 <code>docker command</code> 启动的容器预设是使用 <code>root</code> 用户来当作预设使用者及群组的。这样就会遇到一个问题，当主机环境你拥有 root 权限时就没有此问题。如果你没有 root 权限，又有需求在 Docker 容器內挂上 Volume，会发现产生出来的文件皆会是 root 权限，这时候在主机完全是无法写入的。本篇文章将教大家三种方式来设定容器使用者权限，以解决上述遇到的问题。</p><h2 id="使用-docker-指令时指定使用者">使用 docker 指令时指定使用者</h2><p>以进入一个 Ubuntu 容器为例，通过以下指令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -ti ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>这时候我们可以通过 <code>-u</code> 方式将使用者 <code>uid</code> 及群组 <code>gid</code> 传入容器内。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir tmp</span><br><span class="line">$ docker run -ti -v $PWD&#x2F;tmp:&#x2F;test \</span><br><span class="line">  -u uid:gid ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>如何找到目前使用者 uid 及 gid 呢，可以通过下面的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ id -u</span><br><span class="line">$ id -g</span><br></pre></td></tr></table></figure><p>为了更加方便，上述指令可以改成:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -ti -v $PWD&#x2F;tmp:&#x2F;test \</span><br><span class="line">  -u $(id -u):$(id -g) ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="使用-dockerfile-指定使用者">使用 Dockerfile 指定使用者</h2><p>除了在 Docker 命令行指定外，你也可以在 <code>dockerfile</code> 内直接指定使用者。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">USER 1000:1000</span><br></pre></td></tr></table></figure><p>我个人不是很推荐这方式，除非是在 <code>container</code> 内独立建立使用者，并且指定权限。</p><h3 id="通过-docker-compose-指定权限">通过 docker-compose 指定权限</h3><p>通过 <code>docker-compose</code> 可以一次启动多个服务。用 <code>user</code> 可以指定使用者权限来写入特定的 volume。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">services:</span><br><span class="line">  agent:</span><br><span class="line">    image: xxxxxxxx</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - proxy</span><br><span class="line">    logging:</span><br><span class="line">      options:</span><br><span class="line">        max-size: &quot;100k&quot;</span><br><span class="line">        max-file: &quot;3&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - $&#123;STORAGE_PATH&#125;:&#x2F;data</span><br><span class="line">    user: $&#123;CURRENT_UID&#125;</span><br></pre></td></tr></table></figure><p>接着可以通过 .env 来指定变量的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">STORAGE_PATH&#x3D;&#x2F;home&#x2F;deploy&#x2F;xxxx</span><br><span class="line">CURRENT_UID&#x3D;1001:1001</span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>以上场景通常会发生在有挂载主机 Volume 进入容器内，但是你又没有 root 用户权限时。如果此时不指定使用者权限，这样生成出来的文件都会是 root 权限，一般用户无法写入，只能读取。</p><p>如果你觉得以上方法都过于麻烦，最后在提供一个终极解决方案，那就是使用 <code>Podman</code>。具体使用方法可以参考 「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247488720&amp;idx=1&amp;sn=56a3f0c46d3272f103216cf8330cf6af&amp;chksm=eac535f9ddb2bcefc5347ac1db0d290d384847ef3ef602522721a3308c8c7240b1ddb58533cf&amp;token=2039868521&amp;lang=zh_CN#rd" target="_blank" rel="noopener">再见 Docker，是时候拥抱下一代容器工具了</a>」 一文。</p><blockquote><p>来源：小恶魔</p><p>原文：<a href="https://url.cn/5KhaLSm" target="_blank" rel="noopener">https://url.cn/5KhaLSm</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果平常有在玩 Docker 的用户肯定知道透过 &lt;code&gt;docker command&lt;/code&gt; 启动的容器预设是使用 &lt;code&gt;root&lt;/code&gt; 用户来当作预设使用者及群组的。这样就会遇到一个问题，当主机环境你拥有 root 权限时就没有此问题。如果你没有 root 权限，又有需求在 Docker 容器內挂上 Volume，会发现产生出来的文件皆会是 root 权限，这时候在主机完全是无法写入的。本篇文章将教大家三种方式来设定容器使用者权限，以解决上述遇到的问题。&lt;/p&gt;
&lt;h2 id=&quot;使用-docker-指令时指定使用者&quot;&gt;使用 docker 指令时指定使用者&lt;/h2&gt;
&lt;p&gt;以进入一个 Ubuntu 容器为例，通过以下指令:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ docker run -ti ubuntu &amp;#x2F;bin&amp;#x2F;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这时候我们可以通过 &lt;code&gt;-u&lt;/code&gt; 方式将使用者 &lt;code&gt;uid&lt;/code&gt; 及群组 &lt;code&gt;gid&lt;/code&gt; 传入容器内。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ mkdir tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ docker run -ti -v $PWD&amp;#x2F;tmp:&amp;#x2F;test \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  -u uid:gid ubuntu &amp;#x2F;bin&amp;#x2F;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如何找到目前使用者 uid 及 gid 呢，可以通过下面的方式。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ id -u&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ id -g&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了更加方便，上述指令可以改成:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ docker run -ti -v $PWD&amp;#x2F;tmp:&amp;#x2F;test \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  -u $(id -u):$(id -g) ubuntu &amp;#x2F;bin&amp;#x2F;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://www.hi-linux.com/categories/docker/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://www.hi-linux.com/tags/Docker/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你 3 个 Linux 中快速检测端口的小技巧</title>
    <link href="https://www.hi-linux.com/posts/27009.html"/>
    <id>https://www.hi-linux.com/posts/27009.html</id>
    <published>2020-05-21T01:00:00.000Z</published>
    <updated>2020-05-21T06:46:20.557Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>无论是要解决网络连接问题还是配置防火墙，第一件事是要检查系统实际打开了哪些端口。</p><p>本文介绍了几种快速查找 <code>Linux</code> 系统上哪些端口向外部开放的方法。</p><a id="more"></a><h2 id="什么是开放端口">什么是开放端口</h2><p>监听端口是应用程序监听的网络端口。你要得到的监听端口名单通常可以通过如 <code>ss</code>、<code>netstat</code> 或 <code>lsof</code> 命令查询系统上网络堆栈。每个监听端口都可以使用防火墙打开或关闭（过滤）。</p><p>一般而言，开放端口是一个网络端口，它接受来自远程位置的传入数据包。</p><p>例如：如果你正在运行的监听端口 80、443 的 <code>Web</code> 服务器，并把这些端口在防火墙上对任何人开放。使用浏览器将能够访问托管在 Web 服务器上的网站。在这种情况下，80 和 443 都是开放端口。</p><p>开放端口可能会带来安全风险，因为攻击者可以使用每个开放端口来利用漏洞或执行任何其他类型的攻击。您应该只公开应用程序功能所需的端口，然后关闭所有其他端口。</p><h2 id="使用-nmap-命令检查开放端口">使用 Nmap 命令检查开放端口</h2><p>Nmap 是功能强大的网络扫描工具，可以扫描单个主机和大型网络。它主要用于安全审核和渗透测试。</p><p>Nmap 是端口扫描的首选工具。除端口扫描外，Nmap 还可以检测 Mac 地址、操作系统类型、内核版本等。</p><p>从控制台发出以下命令确定哪些端口正在监听来自网络的 TCP 连接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nmap -sT -p- 10.10.8.8</span><br></pre></td></tr></table></figure><p><code>-sT</code> 选项告诉 Nmap 扫描 TCP 端口， <code>-p-</code> 扫描所有端口（65535 个）。如果不使用 <code>-p-</code>，<code>Nmap</code> 将仅扫描 1000 个端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Starting Nmap 7.60 ( https:&#x2F;&#x2F;nmap.org ) at 2019-07-09 23:10 CEST</span><br><span class="line">Nmap scan report for 10.10.8.8</span><br><span class="line">Host is up (0.0012s latency).</span><br><span class="line">Not shown: 998 closed ports</span><br><span class="line">PORT   STATE SERVICE</span><br><span class="line">22&#x2F;tcp open  ssh</span><br><span class="line">80&#x2F;tcp open  http</span><br><span class="line">MAC Address: 08:00:27:05:49:23 (Oracle VirtualBox virtual NIC)</span><br><span class="line"></span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 0.41 seconds</span><br></pre></td></tr></table></figure><p>以上显示，只有端口 22、80 以及 8069 在目标系统上打开。</p><p>要扫描 UDP 端口，请使用 <code>-sU</code> 代替 <code>-sT</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nmap -sU -p- 10.10.8.8</span><br></pre></td></tr></table></figure><p>有关更多信息，请访问 Nmap 手册页，并了解此工具的所有其他强大功能。</p><h2 id="使用-netcat-命令检查开放端口">使用 Netcat 命令检查开放端口</h2><p>Netcat（或nc）是一种命令行工具，可以使用 <code>TCP</code> 或 <code>UDP</code> 协议跨网络连接读取和写入数据。</p><p>使用 netcat 可以扫描单个端口或端口范围。</p><p>例如，要扫描 IP 地址为 10.10.8.8 的远程计算机上端口范围为 20-80 之间打开的 TCP 端口，你可以使用以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v 10.10.8.8 20-80</span><br></pre></td></tr></table></figure><p><code>-z</code> 选项指示 <code>nc</code> 仅扫描打开的端口，而不发送任何数据，并且 <code>-v</code> 用于获取更多详细信息。</p><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nc: connect to 10.10.8.8 port 20 (tcp) failed: Connection refused</span><br><span class="line">nc: connect to 10.10.8.8 port 21 (tcp) failed: Connection refused</span><br><span class="line">Connection to 10.10.8.8 22 port [tcp&#x2F;ssh] succeeded!</span><br><span class="line">...</span><br><span class="line">Connection to 10.10.8.8 80 port [tcp&#x2F;http] succeeded!</span><br></pre></td></tr></table></figure><p>如果只希望将以上开放端口的行打印在屏幕上，则可以使用 <code>grep</code> 命令过滤结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v 10.10.8.8 20-80 2&gt;&amp;1 | grep succeeded</span><br><span class="line"></span><br><span class="line">Connection to 10.10.8.8 22 port [tcp&#x2F;ssh] succeeded!</span><br><span class="line">Connection to 10.10.8.8 80 port [tcp&#x2F;http] succeeded!</span><br></pre></td></tr></table></figure><p>要扫描 <code>UDP</code> 端口，请将 <code>-u</code> 选项传递给 nc 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -z -v -u 10.10.8.8 20-80 2&gt;&amp;1 | grep succeeded</span><br></pre></td></tr></table></figure><h2 id="使用-bash-伪设备检查打开的端口">使用 Bash 伪设备检查打开的端口</h2><p>检查某个端口是打开还是关闭的另一种方法是使用 <code>Bash Shell</code> 检查 <code>/dev/tcp/..</code> 或 <code>/dev/udp/..</code> 下的伪设备。</p><p>在 <code>/dev/$PROTOCOL/$HOST/$IP</code> 伪设备上执行命令时，<code>Bash</code> 将在指定端口上打开到指定主机的 <code>TCP</code> 或 <code>UDP</code> 连接。</p><p>以下 <code>if..else</code> 语句将检查端口 443 在 <code>kernel.org</code> 是否打开：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if timeout 5 bash -c &#39;&lt;&#x2F;dev&#x2F;tcp&#x2F;kernel.org&#x2F;443 &amp;&gt;&#x2F;dev&#x2F;null&#39;</span><br><span class="line">then</span><br><span class="line">  echo &quot;Port is open&quot;</span><br><span class="line">else</span><br><span class="line">  echo &quot;Port is closed&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Port is open</span><br></pre></td></tr></table></figure><h3 id="上面的代码如何工作">上面的代码如何工作？</h3><p>使用伪设备连接到端口时的默认超时时间非常长，因此我们使用 <code>timeout</code> 命令在 <code>5</code> 秒后终止测试命令。如果建立了 <code>kernel.org</code> 端口连接，则 <code>443</code> 测试命令将返回 true。你也可以使用 <code>for</code> 循环来检查指定的端口范围：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for PORT in &#123;20..80&#125;; do</span><br><span class="line">  timeout 1 bash -c &quot;&lt;&#x2F;dev&#x2F;tcp&#x2F;10.10.8.8&#x2F;$PORT &amp;&gt;&#x2F;dev&#x2F;null&quot; &amp;&amp;  echo &quot;port $PORT is open&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>输出将如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">port 22 is open</span><br><span class="line">port 80 is open</span><br></pre></td></tr></table></figure><h2 id="结论">结论</h2><p>我们为你展示了几种如何使用扫描开放端口的工具，当然你也可以使用其它工具来达到同样的目的，例如：<code>Python Socket</code> 模块、<code>Curl</code>、<code>Telnet</code> 或 <code>Wget</code>。</p><blockquote><p>来源：myfreax</p><p>原文：<a href="https://url.cn/52WWOOH" target="_blank" rel="noopener">https://url.cn/52WWOOH</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;无论是要解决网络连接问题还是配置防火墙，第一件事是要检查系统实际打开了哪些端口。&lt;/p&gt;
&lt;p&gt;本文介绍了几种快速查找 &lt;code&gt;Linux&lt;/code&gt; 系统上哪些端口向外部开放的方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>实战 Btrfs 文件系统之 Subvolume 与 Snapshot</title>
    <link href="https://www.hi-linux.com/posts/25994.html"/>
    <id>https://www.hi-linux.com/posts/25994.html</id>
    <published>2020-05-20T01:00:00.000Z</published>
    <updated>2020-05-20T05:02:06.187Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>对于大部分文件系统来说，在磁盘上创建好文件系统，然后再挂载到系统中去就完事了。但对于 Btrfs 来说，除了在格式化和挂载的时候指定不同的参数外，还支持很多其他的功能。比如：管理多块硬盘、支持 LVM 和 RAID 等，具体的可以参考它的「官方文档」或者「Linux 下常见文件系统对比」。</p><blockquote><p>Btrfs 是 Oracle 07 年基于 GPL 协议开源的 Linux 文件系统，其目的是替换传统的 Ext3、Ext4 系列文件系统。Ext 系列文件系统存在着诸多问题，比如反删除能力有限等；而 Btrfs 在解决问题同时提供了更加强大的高级特性。</p></blockquote><p><strong>Btrfs 特性</strong></p><p>Btrfs 在文件系统级别支持写时复制 (COW) 机制，并且支持快照 (增量快照)、支持对单个文件快照；同时支持单个超大文件、文件检查、内建 RAID；支持 B 树子卷 (组合多个物理卷，多卷支持) 等。具体如下：</p><p>Btrfs 核心特性：</p><ul><li><p>多物理卷支持：Btrfs 可有多个物理卷组成 (类似 LVM)；支持 RAID 以及联机 添加、删除、修改</p></li><li><p>写时复制更新机制 (COW)：复制、更新、替换指针，而非传统意义上的覆盖</p></li><li><p>支持数据及元数据校验码：Checksum 机制</p></li><li><p>支持创建子卷：Subvolume 机制，同时可多层创建</p></li><li><p>支持快照：基于 COW 实现快照，并且相对于 LVM 可以实现快照的快照 (增量快照)</p></li><li><p>支持透明压缩：后台自动压缩文件(消耗一定 CPU)，对前端程序透明</p></li></ul><a id="more"></a><p>Btrfs 是 Linux 下大家公认的将会替代 ext4 的下一代文件系统，功能非常强大。本篇不会介绍 Btrfs 的原理，也不会介绍 Btrfs 的所有功能，只是挑了其中的 Subvolume 和 Snapshot 这两个特性来进行介绍。</p><p>本篇所有例子都在 Ubuntu-Server-X86_64 16.04 下执行通过。</p><h2 id="准备环境">准备环境</h2><p>先创建一个虚拟的硬盘，然后将它格式化成 Btrfs，最后将它挂载到目录 /mnt/btrfs 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 为了简单起见，这里只使用一块硬盘来做测试（Btrf s可以管理多块硬盘或分区）。</span><br><span class="line"># 新建一个文件，用来虚拟一块硬盘。</span><br><span class="line">dev@ubuntu:~$ fallocate -l 512M &#x2F;tmp&#x2F;btrfs.img</span><br><span class="line"></span><br><span class="line"># 在上面创建 Btrfs 文件系统</span><br><span class="line">dev@ubuntu:~$ mkfs.btrfs &#x2F;tmp&#x2F;btrfs.img</span><br><span class="line">btrfs-progs v4.4</span><br><span class="line">See http:&#x2F;&#x2F;btrfs.wiki.kernel.org for more information.</span><br><span class="line"></span><br><span class="line">Label:              (null)</span><br><span class="line">UUID:               fd5efcd3-adc2-406b-a684-e6c87dde99a1</span><br><span class="line">Node size:          16384</span><br><span class="line">Sector size:        4096</span><br><span class="line">Filesystem size:    512.00MiB</span><br><span class="line">Block group profiles:</span><br><span class="line">  Data:             single            8.00MiB</span><br><span class="line">  Metadata:         DUP              40.00MiB</span><br><span class="line">  System:           DUP              12.00MiB</span><br><span class="line">SSD detected:       no</span><br><span class="line">Incompat features:  extref, skinny-metadata</span><br><span class="line">Number of devices:  1</span><br><span class="line">Devices:</span><br><span class="line">   ID        SIZE  PATH</span><br><span class="line">    1   512.00MiB  &#x2F;tmp&#x2F;btrfs.img</span><br><span class="line"></span><br><span class="line"># 创建文件夹并挂载</span><br><span class="line">dev@ubuntu:~$ sudo mkdir &#x2F;mnt&#x2F;btrfs</span><br><span class="line">dev@ubuntu:~$ sudo mount &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;btrfs</span><br><span class="line"></span><br><span class="line"># 修改权限，这样后面的部分操作就不再需要 sudo</span><br><span class="line">dev@ubuntu:~$ sudo chmod 777 &#x2F;mnt&#x2F;btrfs</span><br></pre></td></tr></table></figure><h2 id="subvolume">Subvolume</h2><p>可以把 Subvolume 理解为一个虚拟的设备，由 Btrfs 管理，创建好了之后就自动挂载到了 Btrfs 文件系统的一个目录上，所以我们在文件系统里面看到的 Subvolume 就是一个目录，但它是一个特殊的目录，具有挂载点的一些属性。</p><p>新创建的 Btrfs 文件系统会创建一个路径为 “/” 的默认 Subvolume，即 Root Subvolume。其 ID 为 5（别名为 0），这是一个 ID 和目录都预设好的 Subvolume。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 这里从 mount 的参数 “subvolid&#x3D;5,subvol&#x3D;&#x2F;” 就可以看出来默认的 Root Subvolume 的 id 为 5，路径为 “&#x2F;” 。</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ mount|grep btrfs</span><br><span class="line">&#x2F;dev&#x2F;loop1 on &#x2F;mnt&#x2F;btrfs type btrfs (rw,relatime,space_cache,subvolid&#x3D;5,subvol&#x3D;&#x2F;)</span><br></pre></td></tr></table></figure><h3 id="创建-subvolume">创建 Subvolume</h3><p>这里我们将会利用 Btrfs 提供的工具创建两个新 Subvolume 和两个文件夹，来看看他们之间的差别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">dev@ubuntu:~$ cd &#x2F;mnt&#x2F;btrfs</span><br><span class="line"># btrfs 命令是 Btrfs 提供的应用层工具，可以用来管理 Btrfs。</span><br><span class="line"># 这里依次创建两个 Subvolume，创建完成之后会自动在当前目录下生成两个目录。</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs subvolume create sub1</span><br><span class="line">Create subvolume &#39;.&#x2F;sub1&#39;</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs subvolume create sub2</span><br><span class="line">Create subvolume &#39;.&#x2F;sub2&#39;</span><br><span class="line"></span><br><span class="line"># 创建两个文件夹</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ mkdir dir1 dir2</span><br><span class="line"></span><br><span class="line"># 在sub1、sub2 和 dir1 中分别创建一个文件</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch dir1&#x2F;dir1-01.txt</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch sub1&#x2F;sub1-01.txt</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch sub2&#x2F;sub2-01.txt</span><br><span class="line"></span><br><span class="line"># 最后看看目录结构，是不是看起来 sub1 和 dir1 没什么区别？</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">├── dir2</span><br><span class="line">├── sub1</span><br><span class="line">│   └── sub1-01.txt</span><br><span class="line">└── sub2</span><br><span class="line">    └── sub2-01.txt</span><br></pre></td></tr></table></figure><p>不过由于每个 Subvolume 都是一个单独的虚拟设备，所以无法跨 Subvolume 建立硬链接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 虽然 sub1 和 sub2 属于相同的 Btrfs 文件系统，并且在一块物理硬盘上。但由于他们属于不同的 Subvolume，所以在它们之间建立硬链接失败。</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ ln .&#x2F;sub1&#x2F;sub1-01.txt .&#x2F;sub2&#x2F;</span><br><span class="line">ln: failed to create hard link &#39;.&#x2F;sub2&#x2F;sub1-01.txt&#39; &#x3D;&gt; &#39;.&#x2F;sub1&#x2F;sub1-01.txt&#39;: Invalid cross-device link</span><br></pre></td></tr></table></figure><h3 id="删除-subvolume">删除 Subvolume</h3><p>Subvolume 不能用 rm 命令来删除的，只能通过 btrfs 命令来删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 普通的目录通过 rm 命令就可以被删除</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ rm -r dir2</span><br><span class="line"></span><br><span class="line"># 通过 rm 命令删除 Subvolume 就会失败</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo rm -r sub2</span><br><span class="line">rm: cannot remove &#39;sub2&#39;: Operation not permitted</span><br><span class="line"></span><br><span class="line"># 需要通过 btrfs 命令才能删除，删除 sub2 成功（就算 Subvolume 里面有文件也能被删除）</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del sub2</span><br><span class="line">Delete subvolume (no-commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;sub2&#39;</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line">    └── sub1-01.txt</span><br></pre></td></tr></table></figure><p>上面删除的时候可以看到这样的提示： Delete subvolume (no-commit)，表示 Subvolume 被删除了，但没有提交。意思是在内存里面生效了，但磁盘上的内容还没删，意味着如果这个时候系统 Crash 掉，这个 Subvolume 有可能还会回来。Btrfs 这样做的好处是删除速度很快，不会影响使用，缺点是有可能在后台 Commit 的过程中系统挂掉，导致 Commit 失败。</p><p>为了确保 Subvolume 里的数据被真正的从磁盘上移除掉，可以在删除 Subvolume 的时候指定 -c 参数，这样 btrfs命令会等提交完成之后再返回。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del -c sub2</span><br><span class="line">Delete subvolume (commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;sub2&#39;</span><br></pre></td></tr></table></figure><h3 id="挂载-subvolume">挂载 Subvolume</h3><p>Subvolume 可以直接通过 mount 命令进行挂载，和挂载其它设备没什么区别，具体的挂载参数请查看参考官方文档。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个用于挂载点的目录</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ sudo mkdir &#x2F;mnt&#x2F;sub1</span><br><span class="line"></span><br><span class="line"># 先查看待挂载的 Subvolume 的 id</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list &#x2F;mnt&#x2F;btrfs&#x2F;</span><br><span class="line">ID 256 gen 9 top level 5 path sub1</span><br><span class="line"></span><br><span class="line"># 通过 -o 参数来指定要挂载的 Subvolume 的 ID</span><br><span class="line"># 通过路径来挂载也是一样的效果：sudo mount -o subvol&#x3D;&#x2F;sub1 &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo mount -o subvolid&#x3D;256 &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree &#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">&#x2F;mnt&#x2F;sub1&#x2F;</span><br><span class="line">└── sub1-01.txt</span><br></pre></td></tr></table></figure><h3 id="设置-subvolume-只读">设置 Subvolume 只读</h3><p>Subvolume 可以被设置成只读状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 通过 btrfs property 可以查看和修改 Subvolume 的只读状态</span><br><span class="line"># 默认情况下，Subvolume 的只读属性为 false，即允许写</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property get -ts .&#x2F;sub1&#x2F;</span><br><span class="line">ro&#x3D;false</span><br><span class="line"></span><br><span class="line"># 将 sub1 的只读属性设置成 true</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property set -ts .&#x2F;sub1&#x2F; ro true</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property get -ts .&#x2F;sub1</span><br><span class="line">ro&#x3D;true</span><br><span class="line"></span><br><span class="line"># 写文件失败，提示文件系统只读</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ touch .&#x2F;sub1&#x2F;sub1-02.txt</span><br><span class="line">touch: cannot touch &#39;.&#x2F;sub1&#x2F;sub1-02.txt&#39;: Read-only file system</span><br><span class="line"></span><br><span class="line"># 将sub1的状态改回去，以免影响后续测试</span><br><span class="line">dev@ubuntu:&#x2F;mnt&#x2F;btrfs$ btrfs property set -ts .&#x2F;sub1&#x2F; ro false</span><br></pre></td></tr></table></figure><h2 id="snapshot">Snapshot</h2><p>可以在 Subvolume 的基础上制作快照，几点需要注意：</p><ul><li><p>默认情况下 Subvolume 的快照是可写的</p></li><li><p>快照是特殊的 Subvolume，具有 Subvolume 的属性。所以快照也可以通过 mount 挂载，也可以通过 btrfs property 命令设置只读属性</p></li><li><p>由于快照的本质就是一个 Subvolume ，所以可以在快照上面再做快照</p></li></ul><p>在 Subvolume 上做了快照后，Subvolume 和快照就会共享所有的文件。只有当文件更新的时候，才会触发 COW（copy on write），所以创建快照很快，基本不花时间。并且 Btrfs 的 COW 机制很高效，就算多个快照共享一个文件，更新这个文件也和更新一个普通文件差不多的速度。</p><p>如果用过 Git 的话，就能很容易理解 Btrfs 里的快照，可以把 Subvolume 理解为 Git 里面的 master 分支，而快照就是从 master checkout 出来的新分支，于是快照跟 Git 里的分支有类似的特点：</p><ul><li><p>创建快照几乎没有开销</p></li><li><p>可以在快照的基础上再创建快照</p></li><li><p>当前快照里面的修改不会影响其它快照</p></li><li><p>快照可以被删除</p></li></ul><p>当然 Subvolume 也可以像 Git 里的 master 一样被删除。</p><h3 id="创建快照">创建快照</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 在 Root Subvolume 的基础上创建一个快照</span><br><span class="line"># 默认情况下快照是可写的，如果要创建只读快照，需要加上 -r 参数</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume snapshot .&#x2F; .&#x2F;snap-root</span><br><span class="line">Create a snapshot of &#39;.&#x2F;&#39; in &#39;.&#x2F;snap-root&#39;</span><br><span class="line"></span><br><span class="line"># 创建完成后，可以看到我们已经有了两个 Subvolume</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list .&#x2F;</span><br><span class="line">ID 256 gen 11 top level 5 path sub1</span><br><span class="line">ID 257 gen 13 top level 5 path snap-root</span><br><span class="line"></span><br><span class="line"># 我们可以通过指定 -s 参数来只列出快照</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list -s .&#x2F;</span><br><span class="line">ID 257 gen 10 cgen 10 top level 5 otime 2017-03-05 21:46:03 path snap-root</span><br><span class="line"></span><br><span class="line"># 再来看看快照 snap-root 中的文件，可以看到有 dir1 及下面的文件，但看不到 sub1 下的文件，那是因为 sub1 是一个subvolume。在做一个 Subvolume 的快照的时候，不会将它里面的 Subvolume 也做快照</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree .&#x2F;snap-root</span><br><span class="line">.&#x2F;snap-root</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line"></span><br><span class="line"># 创建 sub1 的一个快照，可以看到 sub1 里面的文件出现在了快照里面</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume snapshot .&#x2F;sub1&#x2F; .&#x2F;snap-sub1</span><br><span class="line">Create a snapshot of &#39;.&#x2F;sub1&#x2F;&#39; in &#39;.&#x2F;snap-sub1&#39;</span><br><span class="line"></span><br><span class="line"># 然后在 sub1 和它的快照 snap-sub1 下面各自创建一个文件，会发现它们之间不受影响</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ touch snap-sub1&#x2F;snap-sub1-01.txt</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ touch sub1&#x2F;sub1-02.txt</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">├── snap-root</span><br><span class="line">│   ├── dir1</span><br><span class="line">│   │   └── dir1-01.txt</span><br><span class="line">│   └── sub1</span><br><span class="line">├── snap-sub1</span><br><span class="line">│   ├── snap-sub1-01.txt</span><br><span class="line">│   └── sub1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line">    ├── sub1-01.txt</span><br><span class="line">    └── sub1-02.txt</span><br></pre></td></tr></table></figure><h3 id="删除快照">删除快照</h3><p>删除快照和删除 Subvolume 是一样的，没有区别。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del snap-root</span><br><span class="line">Delete subvolume (no-commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;snap-root&#39;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume del snap-sub1</span><br><span class="line">Delete subvolume (no-commit): &#39;&#x2F;mnt&#x2F;btrfs&#x2F;snap-sub1&#39;</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree</span><br><span class="line">.</span><br><span class="line">├── dir1</span><br><span class="line">│   └── dir1-01.txt</span><br><span class="line">└── sub1</span><br><span class="line">    ├── sub1-01.txt</span><br><span class="line">    └── sub1-02.txt</span><br></pre></td></tr></table></figure><h2 id="default-subvolume">Default Subvolume</h2><p>可以设置 Btrfs 分区的默认 Subvolume，即在挂载磁盘的时候，可以只让分区中的指定 Subvolume 对用户可见。看下面的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 查看 sub1 的ID</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume list .&#x2F;</span><br><span class="line">ID 256 gen 14 top level 5 path sub1</span><br><span class="line"></span><br><span class="line"># 将 sub1 设置为当前 Btrfs 文件系统的默认 Subvolume</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume set-default 256 &#x2F;mnt&#x2F;btrfs&#x2F;</span><br><span class="line"></span><br><span class="line"># 重新将虚拟硬盘挂载到一个新目录</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo mkdir &#x2F;mnt&#x2F;btrfs1</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo mount &#x2F;tmp&#x2F;btrfs.img &#x2F;mnt&#x2F;btrfs1&#x2F;</span><br><span class="line"></span><br><span class="line"># 这里将只能看到 sub1 下的文件</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ tree &#x2F;mnt&#x2F;btrfs1</span><br><span class="line">&#x2F;mnt&#x2F;btrfs1</span><br><span class="line">├── sub1-01.txt</span><br><span class="line">└── sub1-02.txt</span><br><span class="line"></span><br><span class="line"># 由于 Btrfs 原来的默认 Subvolume 是 Root Subvolume，其 ID 是5（也可以通过 0 来标识），所以我们可以通过同样的命令将默认 Subvolume 再改回去</span><br><span class="line">dev@debian:&#x2F;mnt&#x2F;btrfs$ sudo btrfs subvolume set-default 0 &#x2F;mnt&#x2F;btrfs&#x2F;</span><br></pre></td></tr></table></figure><h3 id="default-subvolume-有什么用呢">Default Subvolume 有什么用呢？</h3><p>利用 Snapshot 和 Default Subvolume，可以很方便的实现不同系统版本的切换。比如将系统安装在一个 Subvolume 下面，当要做什么危险操作的时候，先在 Subvolume 的基础上做一个快照 A。如果操作成功，那么什么都不用做（或者把 A 删掉），继续用原来的 Subvolume，A 不被删掉也没关系，多一个快照在那里也不占空间。如果操作失败，那么可以将 A 设置成 Default Subvolume，并将原来的 Subvolume 删除，这样就相当于系统回滚。</p><p>有了这样的功能后，Linux 的每次操作都能回滚，养成在修改操作前做 Snapshot 的习惯，就再也不用担心 rm 误删文件了。</p><p>现在有些发行版已经有了类似的功能，如 Ubuntu，将安装工具 Apt 和 Btrfs 结合，自动的在安装软件之前打一个 Snapshot。然后安装软件，如果成功，删除新的 Snapshot，如果失败，修改 Default Subvolume 为新的 Snapshot，删除掉原来的 Snapshot，这样对系统没有任何影响，并且所有操作对用户是透明的。</p><p>随着 Btrfs 的成熟和普及，相信会改变一些我们使用 Linux 的习惯。</p><h2 id="延伸阅读">延伸阅读</h2><h3 id="btrfs-相关命令">btrfs 相关命令</h3><p>管理 btrfs 使用 btrfs 命令，该命令包含诸多子命令已完成不同的功能管理，常用命令如下：</p><ul><li><p>btrfs 文件系统属性查看： <code>btrfs filesystem show</code></p></li><li><p>调整文件系统大小： <code>btrfs filesystem resize +10g MOUNT_POINT</code></p></li><li><p>添加硬件设备： <code>btrfs filesystem add DEVICE MOUNT_POINT</code></p></li><li><p>均衡文件负载： <code>btrfs blance status|start|pause|resume|cancel MOUNT_POINT</code></p></li><li><p>移除物理卷(联机、自动移动)： <code>btrfs device delete DEVICE MOUNT_POINT</code></p></li><li><p>动态调整数据存放机制： <code>btrfs balance start -dconvert=RAID MOUNT_POINT</code></p></li><li><p>动态调整元数据存放机制： <code>btrfs balance start -mconvert=RAID MOUNT_POINT</code></p></li><li><p>动态调整文件系统数据数据存放机制： <code>btrfs balance start -sconvert=RAID MOUNT_POINT</code></p></li><li><p>创建子卷： <code>btrfs subvolume create MOUNT_POINT/DIR</code></p></li><li><p>列出所有子卷： <code>btrfs subvolume list MOUNT_POINT</code></p></li><li><p>显示子卷详细信息： <code>btrfs subvolume show MOUNT_POINT</code></p></li><li><p>删除子卷： <code>btrfs subvolume delete MOUNT_POIN/DIR</code></p></li><li><p>创建子卷快照(子卷快照必须存放与当前子卷的同一父卷中)： <code>btrfs subvolume snapshot SUBVOL PARVOL</code></p></li><li><p>删除快照同删除子卷一样： <code>btrfs subvolume delete MOUNT_POIN/DIR</code></p></li></ul><h2 id="相关阅读链接">相关阅读链接</h2><ol><li><p>Btrfs 官方文档：<a href="https://btrfs.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener">https://btrfs.wiki.kernel.org/index.php/Main_Page</a></p></li><li><p>Linux 下常见文件系统对比 ：<a href="https://segmentfault.com/a/1190000008481493" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008481493</a></p></li><li><p>Btrfs 官方挂载硬盘文档：<a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs(5)#MOUNT_OPTIONS" target="_blank" rel="noopener">https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs(5)#MOUNT_OPTIONS</a></p></li></ol><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://segmentfault.com/a/1190000008605135" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008605135</a></p></li><li><p><a href="https://mritd.me/2017/03/20/btrfs-note/" target="_blank" rel="noopener">https://mritd.me/2017/03/20/btrfs-note/</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于大部分文件系统来说，在磁盘上创建好文件系统，然后再挂载到系统中去就完事了。但对于 Btrfs 来说，除了在格式化和挂载的时候指定不同的参数外，还支持很多其他的功能。比如：管理多块硬盘、支持 LVM 和 RAID 等，具体的可以参考它的「官方文档」或者「Linux 下常见文件系统对比」。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Btrfs 是 Oracle 07 年基于 GPL 协议开源的 Linux 文件系统，其目的是替换传统的 Ext3、Ext4 系列文件系统。Ext 系列文件系统存在着诸多问题，比如反删除能力有限等；而 Btrfs 在解决问题同时提供了更加强大的高级特性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Btrfs 特性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Btrfs 在文件系统级别支持写时复制 (COW) 机制，并且支持快照 (增量快照)、支持对单个文件快照；同时支持单个超大文件、文件检查、内建 RAID；支持 B 树子卷 (组合多个物理卷，多卷支持) 等。具体如下：&lt;/p&gt;
&lt;p&gt;Btrfs 核心特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;多物理卷支持：Btrfs 可有多个物理卷组成 (类似 LVM)；支持 RAID 以及联机 添加、删除、修改&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;写时复制更新机制 (COW)：复制、更新、替换指针，而非传统意义上的覆盖&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持数据及元数据校验码：Checksum 机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持创建子卷：Subvolume 机制，同时可多层创建&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持快照：基于 COW 实现快照，并且相对于 LVM 可以实现快照的快照 (增量快照)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持透明压缩：后台自动压缩文件(消耗一定 CPU)，对前端程序透明&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Btrfs" scheme="https://www.hi-linux.com/tags/Btrfs/"/>
    
  </entry>
  
  <entry>
    <title>微软出品 Kubernetes 最新学习指南 v3.0，需要的赶紧下载吧！</title>
    <link href="https://www.hi-linux.com/posts/61882.html"/>
    <id>https://www.hi-linux.com/posts/61882.html</id>
    <published>2020-05-19T01:00:00.000Z</published>
    <updated>2020-05-19T08:49:55.567Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><code>Kubernetes</code> 正在席卷应用开发世界，这是一个不争的事实。预计到 <code>2022</code> 年，全球有超过 <code>75％</code> 的组织将在生产环境中运行容器化应用程序。</p><p><code>Kubernetes</code> 正在塑造应用程序开发和管理的未来，微软希望今天帮助您开始使用它。为了你能更快的掌握 <code>Kubernetes</code>，微软出品了一个 <code>Kubernetes</code> 的学习路径指南。</p><p><img src="https://www.hi-linux.com/img/linux/ms-kubernetes-01.png" alt=""></p><p>该指南适用于有兴趣进一步了解 <code>Kubernetes</code> 的任何人。通过本指南你可以在短短 <code>50</code> 天内，了解 <code>Kubernetes</code> 的基础知识，并获得有关其各种组件，功能和解决方案。</p><p><img src="https://www.hi-linux.com/img/linux/ms-kubernetes-02.png" alt=""></p><a id="more"></a><p>「50 days from zero to hero with Kubernetes」大纲如下：</p><ul><li>为什么你需要关心容器</li><li>理解 Kubernetes 中的 Serverless</li><li>Kubernetes 的使用场景</li><li>Kubernetes 是如何工作的</li><li>Kubernetes 是如何调度任务的</li><li>Kubernetes 内的 Volume</li><li>Kubernetes 是如何部署服务的</li><li>Kubernetes CI/CD</li><li>Kubernetes 上有状态服务管理</li><li>Kubernetes Secret</li><li>准备把服务放在生产环境</li><li>监控与告警</li><li>Kubernetes 内的配置管理</li><li>Kubernetes 内的微服务是如何工作的</li><li>Kubernetes 中 Pod 与 Pod 的生命周期</li><li>理解基于角色的访问控制</li><li>通过 Operator 管理应用程序</li><li>…</li></ul><p>看上去，是不是很不错呢？<strong>只需在公众号对话框内回复 「<code>ms-kubernetes</code>」，即可获取「微软最新版 Kubernetes 学习指南 v3.0」PDF 版。</strong> PDF 能做得如此精美，交互也能做得如此好还是头一次见呢！</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt; 正在席卷应用开发世界，这是一个不争的事实。预计到 &lt;code&gt;2022&lt;/code&gt; 年，全球有超过 &lt;code&gt;75％&lt;/code&gt; 的组织将在生产环境中运行容器化应用程序。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt; 正在塑造应用程序开发和管理的未来，微软希望今天帮助您开始使用它。为了你能更快的掌握 &lt;code&gt;Kubernetes&lt;/code&gt;，微软出品了一个 &lt;code&gt;Kubernetes&lt;/code&gt; 的学习路径指南。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/ms-kubernetes-01.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;该指南适用于有兴趣进一步了解 &lt;code&gt;Kubernetes&lt;/code&gt; 的任何人。通过本指南你可以在短短 &lt;code&gt;50&lt;/code&gt; 天内，了解 &lt;code&gt;Kubernetes&lt;/code&gt; 的基础知识，并获得有关其各种组件，功能和解决方案。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/ms-kubernetes-02.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款支持 微信/QQ/TIM 消息防撤回神器 RevokeMsgPatcher</title>
    <link href="https://www.hi-linux.com/posts/30034.html"/>
    <id>https://www.hi-linux.com/posts/30034.html</id>
    <published>2020-05-19T01:00:00.000Z</published>
    <updated>2020-05-20T05:10:57.908Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>现在的社交软件都有一种 「后悔药」，学名叫 「消息撤回功能」。我们用的最多的应该是微信。在微信当中，不管你是消息发错了还是后悔了，只要长按消息内容点击 「撤回」，对方没看到的话，就永远看不到了！</p><p>当你看到别人撤回了一堆消息后，是不是很好奇 <code>Ta</code> 说了啥？但是当你再问 <code>Ta</code> 到底撤回了什么时候，基本上 <code>Ta</code> 是不会告诉你的，要不然也不会撤回了，对不对呀？既然消息已经发送过来一次了，难道我们不能做点什么让它撤回不了嘛？</p><p>今天我们就给大家推荐一个神器来解决这个千年难题。不论对方怎么骚操作，都可以让 <code>Ta</code> 发送过的消息留在聊天记录里，永远无法撤回！</p><p><img src="http://www.immidu.com/usr/uploads/2019/08/2390070843.jpg" alt=""></p><p>说了这么多，到底这神器是什么呢？是时候揭开它的神秘面纱了，它就是 <code>RevokeMsgPatcher</code>。<code>RevokeMsgPatcher</code> 是一款 <code>Windows</code> 下 PC 版的微信防撤回补丁。它除了支持微信，而且还支持 <code>QQ</code> 和 <code>TIM</code> 哟！</p><blockquote><p>项目地址：<a href="https://github.com/huiyadanli/RevokeMsgPatcher" target="_blank" rel="noopener">https://github.com/huiyadanli/RevokeMsgPatcher</a></p></blockquote><a id="more"></a><h2 id="安装-revokemsgpatcher">安装 RevokeMsgPatcher</h2><p><code>RevokeMsgPatcher</code> 的安装非常简单，只需在官方仓库 <code>Releases</code> 页面直接下载各平台对应的版本，解压后即可使用。</p><blockquote><p>注意：你的系统必须是 <code>Windows 7</code> 或更高版本，另外系统必须安装 <code>.NET Framework 4.5</code> 或更高版本。</p></blockquote><p><strong>RevokeMsgPatcher 目前支持的版本</strong></p><ul><li>支持的最新版本</li></ul><p><img src="https://i.loli.net/2019/11/13/LXw3lvqpftRokx2.png" alt=""></p><ul><li>支持的历史版本</li></ul><p><img src="https://i.loli.net/2019/11/13/FDO1cCJKIwB6beR.png" alt=""></p><p><strong>RevokeMsgPatcher 安装方法</strong></p><p><img src="https://raw.githubusercontent.com/huiyadanli/RevokeMsgPatcher/master/Images/screenshot.png" alt=""></p><ol><li><p><code>RevokeMsgPatcher</code> 使用和大多补丁程序类似，你肯定需要先关闭 <code>微信/QQ/TIM</code>。</p></li><li><p>以管理员权限运行程序，并点击工具界面上的「<code>...</code>」按钮后选择 <code>微信/QQ/TIM</code> 的安装路径。</p></li><li><p>点击工具界面上的「<code>点我防撤回</code>」按钮后，即可安装成功。</p></li></ol><blockquote><p>注意：</p><ol><li><p>缺省情况下会自动从注册表中获取安装路径，如果你使用的是绿色版可能需要手动选择一下安装路径。</p></li><li><p>工具界面此时可能会出现短暂的无响应，请耐心等待。另：因为补丁修改了微信的 <code>WeChatWin.dll</code> 文件、<code>QQ/TIM</code> 的 <code>IM.dll</code> 文件，如果杀毒软件弹出警告，你需要放行一下哟！</p></li></ol></blockquote><h2 id="使用-revokemsgpatcher">使用 RevokeMsgPatcher</h2><p>无论是 <code>微信/QQ/TIM</code> 上，对方进行撤回消息操作后，你在聊天界面仍旧能看到对方撤回的消息。下面是一个演示效果图：</p><p><img src="https://www.hi-linux.com/img/linux/unnamed-file-18.gif" alt=""></p><p>是不是，很惊喜，很意外呢。哈哈!</p><blockquote><p><code>RevokeMsgPatcher</code> 实现原理非常简单，其本质就是一个十六进制编辑器，可以对指定文件指定位置的字节进行编辑，把原先需要人工操作的地方自动化。</p></blockquote><p>赶紧用起来吧，从今以后你再也不会不知道你女朋友的小秘密了，哈哈！</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://xiaoma.me/778.html" target="_blank" rel="noopener">https://xiaoma.me/778.html</a></p></li><li><p><a href="http://www.immidu.com/index.php/archives/22/" target="_blank" rel="noopener">http://www.immidu.com/index.php/archives/22/</a></p></li><li><p><a href="https://mp.weixin.qq.com/s/pFl8fflWQYThwWAejR9G-g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/pFl8fflWQYThwWAejR9G-g</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在的社交软件都有一种 「后悔药」，学名叫 「消息撤回功能」。我们用的最多的应该是微信。在微信当中，不管你是消息发错了还是后悔了，只要长按消息内容点击 「撤回」，对方没看到的话，就永远看不到了！&lt;/p&gt;
&lt;p&gt;当你看到别人撤回了一堆消息后，是不是很好奇 &lt;code&gt;Ta&lt;/code&gt; 说了啥？但是当你再问 &lt;code&gt;Ta&lt;/code&gt; 到底撤回了什么时候，基本上 &lt;code&gt;Ta&lt;/code&gt; 是不会告诉你的，要不然也不会撤回了，对不对呀？既然消息已经发送过来一次了，难道我们不能做点什么让它撤回不了嘛？&lt;/p&gt;
&lt;p&gt;今天我们就给大家推荐一个神器来解决这个千年难题。不论对方怎么骚操作，都可以让 &lt;code&gt;Ta&lt;/code&gt; 发送过的消息留在聊天记录里，永远无法撤回！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.immidu.com/usr/uploads/2019/08/2390070843.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;说了这么多，到底这神器是什么呢？是时候揭开它的神秘面纱了，它就是 &lt;code&gt;RevokeMsgPatcher&lt;/code&gt;。&lt;code&gt;RevokeMsgPatcher&lt;/code&gt; 是一款 &lt;code&gt;Windows&lt;/code&gt; 下 PC 版的微信防撤回补丁。它除了支持微信，而且还支持 &lt;code&gt;QQ&lt;/code&gt; 和 &lt;code&gt;TIM&lt;/code&gt; 哟！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/huiyadanli/RevokeMsgPatcher&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/huiyadanli/RevokeMsgPatcher&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="工具" scheme="https://www.hi-linux.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="微信" scheme="https://www.hi-linux.com/tags/%E5%BE%AE%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>U 盘多系统安装盘制作神器 YUMI 使用教程</title>
    <link href="https://www.hi-linux.com/posts/23035.html"/>
    <id>https://www.hi-linux.com/posts/23035.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.539Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>通常我们一个 U 盘只能制作成一个系统安装盘，比如制作好一个 <code>Windows 10</code> 安装盘，日后想要用到 <code>Linux</code>、<code>WinPE</code> 等安装盘时，只能重新制作一遍，非常浪费时间。而且现在 U 盘容量都很大，如果只放一个系统，同样就会白白浪费 U 盘剩余的空间。</p><p>今天，我们就给大家推荐一个可以让你的 U 盘制作成多系统安装盘的神器 <code>YUMI</code>。</p><p><code>YUMI</code> (<code>Your Universal Multiboot Integrator</code>) 是一款免费便携的 <code>USB</code> 多合一启动盘制作工具！它可以让你轻松将多款不同操作系统 <code>ISO</code> 镜像装到一个 U 盘里，制作出支持 <code>Multiboot</code> (多系统引导启动) 的多合一系统引导安装盘。</p><p><code>YUMI</code> 几乎支持全系列的 <code>Windows</code> 和 <code>Linux</code> 操作系统。比如 <code>Windows 10</code>、<code>Windows 7</code>、<code>WinPE</code>、<code>Windows To Go</code> 以及 <code>Linux</code> 的各种发行版。</p><blockquote><p>官网：<a href="https://www.pendrivelinux.com/yumi-multiboot-usb-creator/" target="_blank" rel="noopener">https://www.pendrivelinux.com/yumi-multiboot-usb-creator/</a></p></blockquote><a id="more"></a><h2 id="安装-yumi">安装 YUMI</h2><p><code>YUMI</code> 目前只支持 <code>Windows</code> 和 <code>Linux</code> 平台，共分为 <code>Legacy</code> 和 <code>UEFI</code> 两个版本，请根据自己 <code>BIOS</code> 实际引导情况选择下载。</p><ol><li>Windows 平台</li></ol><p><code>Windows</code> 安装非常简单，基本开箱即用，这里就不多赘述了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Legacy 版本下载地址</span><br><span class="line">https:&#x2F;&#x2F;www.pendrivelinux.com&#x2F;downloads&#x2F;YUMI&#x2F;YUMI-2.0.6.9.exe</span><br><span class="line"></span><br><span class="line"># UEFI 版本下载地址</span><br><span class="line">https:&#x2F;&#x2F;www.pendrivelinux.com&#x2F;downloads&#x2F;YUMI&#x2F;YUMI-UEFI-0.0.1.9.exe</span><br></pre></td></tr></table></figure><ol start="2"><li>Linux 平台</li></ol><p><code>Linux</code> 下安装相对就比较麻烦了，具体可以参考下官方文档。如果没什么必要，还是建议直接在 <code>Windows</code> 平台上使用。怎么简单怎么来嘛，反正平时用得也不多，哈哈！。</p><blockquote><p><a href="https://www.pendrivelinux.com/yumi-multiboot-usb-creator#HowTo" target="_blank" rel="noopener">https://www.pendrivelinux.com/yumi-multiboot-usb-creator#HowTo</a></p></blockquote><h2 id="使用-yumi-制作多系统启动盘">使用 YUMI 制作多系统启动盘</h2><p>使用 <code>YUMI</code> 制作多合一系统安装盘非常简单。插上 U  盘，运行 <code>YUMI</code> 软件后。制作系统安装盘一共只要以下 4 步：</p><ul><li><p>第一步：选择需要制作 U 盘的盘符。</p></li><li><p>第二步：选择你将要制作安装盘系统的名称。</p></li><li><p>第三步：选择你事先下载好的该系统对应的 <code>ISO</code> 镜像的安装文件。</p></li><li><p>第四步：最后，按下 「<code>Create</code>」后即开始制作。</p></li></ul><p><img src="https://i.loli.net/2019/10/25/cxpo3CA8ETsDRKw.png" alt=""></p><blockquote><p>注意: <code>YUMI</code> 每次只能制作一个系统的安装盘，如果你要制作多个系统，只需重复执行多次上述的步骤来增加其它操作系统即可。</p></blockquote><h2 id="使用-yumi-引导多系统">使用 YUMI 引导多系统</h2><p>系统安装盘制作完成后，在电脑 <code>BIOS</code> 设置 U 盘为开机启动后，就能直接进入 <code>YUMI</code> 的 <code>Miltiboot</code> 引导界面。</p><p><img src="https://www.pendrivelinux.com/wp-content/uploads/YUMI-Boot-Menu.png" alt=""></p><p>然后，你只需要选择自己需要的系统就可以开始安装。</p><h2 id="删除已制作好的操作系统">删除已制作好的操作系统</h2><p>按上述的步骤制作好多重启动盘之后，如果你需要删除其中的一个或者多个系统，那么你只需重新运行 <code>YUMI</code>，然后勾选右上方的「<code>You're in Uninstaller Model</code>」即可在下方列表中看到当前 U 盘里的系统。</p><p><img src="https://i.loli.net/2019/10/25/yPiRChIwKEoaQcs.png" alt=""></p><p>接下来，你只需在列表中选择不想要的操作系统后，点击「Remove」就可以删除它了。如需删除多个系统，重复多遍以上操作即可。</p><h2 id="总结">总结</h2><p>对于经常需要装机、制作系统安装盘的同学来说，<code>YUMI</code> 无疑是一个相当强大好用的工具。如果你想要制作一个集 <code>Windows 10</code>、<code>WinPE</code> 和 <code>Linux</code> 系统于一身、方便用于维护和装机的多合一系统安装盘，那么操作如此简单的 <code>YUMI</code> 值得你拥有！</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://www.iplaysoft.com/yumi.html" target="_blank" rel="noopener">https://www.iplaysoft.com/yumi.html</a></p></li><li><p><a href="https://blog.shiyunhong.com/3012.html" target="_blank" rel="noopener">https://blog.shiyunhong.com/3012.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通常我们一个 U 盘只能制作成一个系统安装盘，比如制作好一个 &lt;code&gt;Windows 10&lt;/code&gt; 安装盘，日后想要用到 &lt;code&gt;Linux&lt;/code&gt;、&lt;code&gt;WinPE&lt;/code&gt; 等安装盘时，只能重新制作一遍，非常浪费时间。而且现在 U 盘容量都很大，如果只放一个系统，同样就会白白浪费 U 盘剩余的空间。&lt;/p&gt;
&lt;p&gt;今天，我们就给大家推荐一个可以让你的 U 盘制作成多系统安装盘的神器 &lt;code&gt;YUMI&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YUMI&lt;/code&gt; (&lt;code&gt;Your Universal Multiboot Integrator&lt;/code&gt;) 是一款免费便携的 &lt;code&gt;USB&lt;/code&gt; 多合一启动盘制作工具！它可以让你轻松将多款不同操作系统 &lt;code&gt;ISO&lt;/code&gt; 镜像装到一个 U 盘里，制作出支持 &lt;code&gt;Multiboot&lt;/code&gt; (多系统引导启动) 的多合一系统引导安装盘。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YUMI&lt;/code&gt; 几乎支持全系列的 &lt;code&gt;Windows&lt;/code&gt; 和 &lt;code&gt;Linux&lt;/code&gt; 操作系统。比如 &lt;code&gt;Windows 10&lt;/code&gt;、&lt;code&gt;Windows 7&lt;/code&gt;、&lt;code&gt;WinPE&lt;/code&gt;、&lt;code&gt;Windows To Go&lt;/code&gt; 以及 &lt;code&gt;Linux&lt;/code&gt; 的各种发行版。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;官网：&lt;a href=&quot;https://www.pendrivelinux.com/yumi-multiboot-usb-creator/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.pendrivelinux.com/yumi-multiboot-usb-creator/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="YUMI" scheme="https://www.hi-linux.com/tags/YUMI/"/>
    
  </entry>
  
  <entry>
    <title>史上最全的高性能代理服务器 Envoy 中文实战教程</title>
    <link href="https://www.hi-linux.com/posts/57326.html"/>
    <id>https://www.hi-linux.com/posts/57326.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.543Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-envoy">什么是 Envoy</h2><p><code>Envoy</code> 是一款 <code>CNCF</code> 旗下的开源项目，由 <code>Lyft</code> 开源。<code>Envoy</code> 采用 C++ 实现，是面向 <code>Service Mesh</code> 的高性能网络代理服务。它与应用程序并行运行，通过以平台无关的方式提供通用功能来抽象网络。当基础架构中的所有服务流量都通过 Envoy 网格时，通过一致的可观测性，很容易地查看问题区域，调整整体性能。</p><p><code>Envoy</code> 也是 <code>Istio Service Mesh</code> 中默认的 <code>Data Plane</code>，本文我们将讲解 <code>Envoy</code> 的一些基本概念，并采用一些实例来介绍如何在本地环境中快速使用 <code>Envoy</code> 作为 <code>Service Mesh</code> 的数据平面，以帮助读者理解 <code>Istio</code> 的 <code>Data Panel</code> 层实现。</p><blockquote><p>官网：<a href="https://www.envoyproxy.io" target="_blank" rel="noopener">https://www.envoyproxy.io</a></p></blockquote><h3 id="envoy-特性">Envoy 特性</h3><ol><li>整体架构</li></ol><p><img src="https://ws1.sinaimg.cn/large/4483e99egy1ftn7wet57fj233f1utag1.jpg" alt=""></p><ol start="2"><li>进程无关架构</li></ol><p><code>Envoy</code> 是一个自组织的模块，与应用 <code>Server</code> 并无直接依赖。所有的 <code>Envoy</code> 构建了一个透明的服务网格 <code>Service Mesh</code>，处于其中的应用只需要简单的与本地的 <code>Envoy</code> 进行收发信息，并不需要关注整个网络拓扑。这种架构对于应用通信有两大好处：</p><ul><li><p><code>Envoy</code> 可以让任何的编程语言编写的服务通信，协同工作，<code>Envoy</code> 帮你屏蔽了服务之间的沟壑。</p></li><li><p>任何曾经在大型微服务开发中工作过的人都知道发布一个库更新是多么的痛苦。<code>Envoy</code> 可以以一种透明的方式快速的发布更新整个基础架构中的版本。</p></li></ul><a id="more"></a><ol start="3"><li>高级负载均衡</li></ol><p>分布式系统中不同模块间的负载均衡是一个复杂的问题。因为 <code>Envoy</code> 是一个自组织的代理，所以它能在一个地方实现高级负载均衡技术并使他们可被访问。当前 <code>Envoy</code> 支持自动重试、断路器、全局限速、阻隔请求、异常检测，将来还会支持按计划进行请求速率控制。</p><ol start="4"><li>动态配置</li></ol><p><code>Envoy</code> 提供了可选的一系列的分层的动态配置 <code>API</code>，使用这些 <code>API</code> 可以构建出复杂的集中式部署管理。</p><ol start="5"><li>正向代理支持</li></ol><p>虽然 <code>Envoy</code> 设计初衷是服务和服务之间通信系统，得益于其监视、管理、服务发现和负载均衡算法的实现，<code>Enovy</code> 包含了足够多的特性为绝大多数 <code>Web</code> 服务做正向代理。</p><p>除了这些之外还有对 <code>HTTP/2</code> 的支持，<code>L3</code>、<code>L4</code>、<code>L7</code> 代理，可以实现 <code>TCP Proxy</code>、<code>HTTP Proxy</code> 等功能。</p><ol start="6"><li>线程模型</li></ol><p><code>Envoy</code> 使用单进程多线程架构，其中一个扮演主线程的控制各种协调任务，而一些工作线程负责监听、过滤和转发。一旦某个链接被监听器 <code>Listener</code> 接受，那么这个链接将会剩余的生命周期绑定在这个 <code>Woker</code> 线程。这种架构会使得大部分工作工作在单线程的情况下，只有少量的工作会涉及到线程间通信，<code>Envoy</code> 代码是 100% 非阻塞的。</p><ol start="7"><li>Listener 监听器</li></ol><ul><li><p>一个 <code>Envoy</code> 进程可以设置多个不同的 <code>Listener</code>，建议一台机器只使用一个 <code>Envoy</code> 实例。</p></li><li><p>每一个 <code>Listener</code> 的网络层 <code>L3/L4</code> 过滤器是独立配置的。并且一个 <code>Listener</code> 是可以通过配置来完成多种任务的，比如：访问限制、TLS 客户端校验、HTTP 链接管理等。</p></li><li><p><code>Listener</code> 也有自己的非网络层过滤器，它可以修改链接的 <code>Metadata</code> 信息，通常用来影响接下来链接是如何被网络层过滤器处理的。</p></li><li><p>无论网络层过滤器还是 <code>Listener</code> 过滤器都可以提前终止后续的过滤器链的执行。</p></li></ul><ol start="8"><li>HTTP 连接管理器</li></ol><ul><li><p><code>Envoy</code> 是完整支持 <code>HTTP/1.1</code>、<code>Websockets</code> 和 <code>HTTP/2</code>，不支持 <code>SPDY</code>。</p></li><li><p>这层过滤器主要是将原始的传递数据转变成 <code>HTTP</code> 层级的信息和事件，如收到 <code>Headers</code>、收到 <code>Body</code> 数据，同样它也可以做接入日志、<code>Request ID</code> 生成和追踪、<code>Req/Res</code> 头部修改工作、路由表管理、统计分析。</p></li><li><p>每一个 <code>HTTP</code> 链接管理器有一个相匹配的路由表，路由表可以静态指定，也可以动态地通过 <code>RDS API</code> 来设置 <code>route-dynamic</code>。</p></li><li><p>其内部还有 <code>HTTP</code> 过滤器，可以支持在 <code>HTTP</code> 层级。在无需关注使用什么协议 (<code>HTTP/1.1</code> 或 <code>HTTP/2</code>) 实现的情况下进行操作 <code>HTTP</code> 内容，支持 <code>Encode</code>、<code>Decode</code>、<code>Encode/Decode</code> 三种不同类型过滤器。</p></li></ul><ol start="9"><li>HTTP 路由器</li></ol><ul><li><p>经常用在做边缘/反向代理和构建内部 <code>Envoy Mesh</code> 发挥巨大作用。</p></li><li><p><code>HTTP</code> 路由器可以支持请求重试配置：最大重试次数和设置重试条件，比如某些 <code>5XX</code> 错误和具有幂等性操作的 <code>4XX</code> 错误。</p></li><li><p><code>Envoy</code> 自己使用 <code>HTTP/2</code> 链接管理器实现了 <code>gRPC</code> 协议，将原来官方的 <code>Google gRPC</code> 内置的很多功能，比如重试、超时、<code>Endpoint</code> 发现、负载均衡、负载报告、健康检查等功能都实现了。将来除非特殊特性必须，都可以使用 <code>Envoy gRPC</code> 来实现。</p></li></ul><ol start="10"><li>Cluster 管理器</li></ol><p><code>Cluster</code> 管理器暴露 <code>API</code> 给过滤器，并允许过滤器可以得到链接到上游集群的 <code>L3/L4</code> 链接或者维持一个抽象的 <code>HTTP</code> 连接池用来链接上游集群（上游主机支持 <code>HTTP 1.1</code> 还是 <code>HTTP 2</code> 都是被隐藏的）。过滤器决定是使用 <code>L3/L4</code> 链接还是 <code>HTTP Stream</code> 来链接上游集群。而对于集群管理器来说，它负责所有集群内主机的可用性、负载均衡、健康度、线程安全的上游链接数据，上游链接类型 <code>TCP/UP</code>、<code>UDS</code>，上游可接受的协议 <code>HTTP 1.1/2</code>。</p><p><code>Cluster</code> 管理器既可以静态配置，也可以使用 <code>CDS-Cluster-Discovery-Service API</code> 来动态配置。 集群在正式使用之前有一个 “加热” <code>Warming</code> 的过程：先做服务发现必要的初始化，比如 <code>DNS</code> 记录更新、<code>EDS</code> 更新，然后进行健康检查，当进行完上述的过程，会进入<code>Becoming available</code> 状态，这个阶段 <code>Envoy</code> 不会把流量指向它们; 在更新集群时，也不会把正在处理流量的集群处理掉，而是用新的去替换老的那些还未进行任何流量的集群。</p><ol start="11"><li>与 Nginx 的区别</li></ol><ul><li><p><code>Envoy</code> 对 <code>HTTP/2</code> 的支持比 <code>Nginx</code> 更好，支持包括 <code>upstream</code> 和 <code>downstream</code> 在内的双向通信，而 <code>Nginx</code> 只支持 <code>downstream</code> 的连接。</p></li><li><p>高级负载均衡功能是免费的，<code>Nginx</code> 的高级负载均衡功能则需要付费的 <code>Nginx Plus</code> 支持。</p></li><li><p><code>Envoy</code> 支持热更新，<code>Nginx</code> 配置更新之后需要 <code>Reload</code>。</p></li><li><p><code>Envoy</code> 更贴近 <code>Service Mesh</code> 的使用习惯，<code>Nginx</code> 更贴近传统服务的使用习惯。</p></li></ul><h3 id="envoy-术语">Envoy 术语</h3><p>要深入理解 <code>Envoy</code>，首先需要先了解一下 <code>Envoy</code> 中的一些术语。</p><p><img src="https://ws1.sinaimg.cn/large/4483e99egy1fto85kdq0wj20lo0b2wej.jpg" alt=""></p><ul><li><p><code>Host</code>：能够进行网络通信的实体（如服务器上的应用程序）。</p></li><li><p><code>Downstream</code>：下游主机连接到 <code>Envoy</code>，发送请求并接收响应。</p></li><li><p><code>Upstream</code>：上游主机接收来自 <code>Envoy</code> 连接和请求并返回响应。</p></li><li><p><code>Listener</code>：可以被下游客户端连接的命名网络（如端口、<code>Unix</code> 套接字）。一般是每台主机运行一个 <code>Envoy</code>，使用单进程运行，但是每个进程中可以启动任意数量的 <code>Listener</code>（监听器），每个监听器都独立配置一定数量的（ <code>L3/L4</code> ）网络过滤器。</p></li><li><p><code>Cluster</code>：<code>Envoy</code> 连接到的一组逻辑上相似的上游主机。</p></li><li><p><code>Mesh</code>：以提供一致的网络拓扑的一组主机。</p></li><li><p><code>Runtime Configuration</code>：与 <code>Envoy</code> 一起部署的外置实时配置系统。</p></li><li><p><code>Listener Filter</code>：<code>Listener</code> 使用 <code>Listener Filter</code>（监听器过滤器）来操作链接的元数据，它的作用是在不更改 <code>Envoy</code> 的核心功能的情况下添加更多的集成功能。</p></li><li><p><code>Http Route Table</code>：<code>HTTP</code> 的路由规则，例如请求的域名，<code>Path</code> 符合什么规则，转发给哪个 <code>Cluster</code>。</p></li></ul><h2 id="部署-envoy">部署 Envoy</h2><p>官方提供了 <code>Envoy</code> 的 <code>Docker</code> 镜像，直接下载对应镜像即可使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull envoyproxy&#x2F;envoy:latest</span><br></pre></td></tr></table></figure><p>镜像中已经将 Envoy 安装到 <code>/usr/local/bin</code> 目录下，可以先看看 <code>Envoy</code> 进程的帮助信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --help</span><br><span class="line">USAGE: </span><br><span class="line">   &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy  [--disable-hot-restart] [--max-obj-name-len</span><br><span class="line">                         &lt;uint64_t&gt;] [--max-stats &lt;uint64_t&gt;] [--mode</span><br><span class="line">                         &lt;string&gt;] [--parent-shutdown-time-s &lt;uint32_t&gt;]</span><br><span class="line">                         [--drain-time-s &lt;uint32_t&gt;]</span><br><span class="line">                         [--file-flush-interval-msec &lt;uint32_t&gt;]</span><br><span class="line">                         [--service-zone &lt;string&gt;] [--service-node</span><br><span class="line">                         &lt;string&gt;] [--service-cluster &lt;string&gt;]</span><br><span class="line">                         [--hot-restart-version] [--restart-epoch</span><br><span class="line">                         &lt;uint32_t&gt;] [--log-path &lt;string&gt;] [--log-format</span><br><span class="line">                         &lt;string&gt;] [-l &lt;string&gt;]</span><br><span class="line">                         [--local-address-ip-version &lt;string&gt;]</span><br><span class="line">                         [--admin-address-path &lt;string&gt;] [--v2-config-only]</span><br><span class="line">                         [--config-yaml &lt;string&gt;] [-c &lt;string&gt;]</span><br><span class="line">                         [--concurrency &lt;uint32_t&gt;] [--base-id &lt;uint32_t&gt;]</span><br><span class="line">                         [--] [--version] [-h]</span><br></pre></td></tr></table></figure><p><code>Envoy</code> 进程启动的时候需要指定一些参数，其中最重要的是 <code>--config-yaml</code> 参数，用于指定 <code>Envoy</code> 进程启动的时候需要读取的配置文件地址。<code>Docker</code> 中配置文件默认是放在 <code>/etc/envoy</code> 目录下，配置文件的文件名是 <code>envoy.yaml</code>。所以我们在启动容器的时候需要将自定义的 <code>envoy.yaml</code> 配置文件挂载到指定目录下替换掉默认的配置文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy -c &lt;path to config&gt;.&#123;json,yaml,pb,pb_text&#125; --v2-config-only</span><br></pre></td></tr></table></figure><blockquote><p>注意：<code>Envoy</code> 默认的日志级别是 <code>info</code>，对于开发阶段需要进行调试的话，调整日志级别到 <code>Debug</code> 是非常有用的。你可以在启动参数中添加 <code>-l debug</code> 来将日志级别进行切换。</p></blockquote><h2 id="编写-envoy-配置文件">编写 Envoy 配置文件</h2><p>在介绍 <code>Envoy</code> 的配置文件之前，先介绍一下 <code>Envoy</code> 的 <code>API</code>。<code>Envoy</code> 提供了两个版本的 <code>API</code>，<code>V1</code> 和 <code>V2</code> 版本 <code>API</code>。现阶段 <code>V1</code> 版本已经不建议使用了，通常都是使用 <code>V2</code> 的 <code>API</code>。</p><p><code>V2</code> 的 <code>API</code> 提供了两种方式的访问，一种是 <code>HTTP Rest</code> 的方式访问，还有一种 <code>GRPC</code> 的访问方式。关于 <code>GRPC</code> 的介绍可以参考官方文档，在后面的文章中只实现了 <code>GRPC</code> 的 <code>API</code>。</p><p><code>Envoy</code> 的启动配置文件分为两种方式：静态配置和动态配置。</p><p>静态配置是将所有信息都放在配置文件中，启动的时候直接加载。</p><p>动态配置需要提供一个 <code>Envoy</code> 的服务端，用于动态生成 <code>Envoy</code> 需要的服务发现接口，这里叫 <code>XDS</code> ，通过发现服务来动态的调整配置信息，<code>Istio</code> 就是实现了 <code>V2</code> 的 <code>API</code>。</p><h3 id="静态配置">静态配置</h3><p>以一个最简化的静态配置来做示例，体验一下 <code>Envoy</code>。</p><p>下面是 <code>envoy.yaml</code>配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 127.0.0.1, port_value: 9901 &#125;</span><br><span class="line"></span><br><span class="line">static_resources:</span><br><span class="line">  listeners:</span><br><span class="line">  - name: listener_0</span><br><span class="line">    address:</span><br><span class="line">      socket_address: &#123; address: 0.0.0.0, port_value: 10000 &#125;</span><br><span class="line">    filter_chains:</span><br><span class="line">    - filters:</span><br><span class="line">      - name: envoy.http_connection_manager</span><br><span class="line">        config:</span><br><span class="line">          stat_prefix: ingress_http</span><br><span class="line">          codec_type: AUTO</span><br><span class="line">          route_config:</span><br><span class="line">            name: local_route</span><br><span class="line">            virtual_hosts:</span><br><span class="line">            - name: local_service</span><br><span class="line">              domains: [&quot;*&quot;]</span><br><span class="line">              routes:</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;&quot; &#125;</span><br><span class="line">                route: &#123; cluster: some_service &#125;</span><br><span class="line">          http_filters:</span><br><span class="line">          - name: envoy.router</span><br><span class="line">  clusters:</span><br><span class="line">  - name: some_service</span><br><span class="line">    connect_timeout: 0.25s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts: [&#123; socket_address: &#123; address: 127.0.0.1, port_value: 80 &#125;&#125;]</span><br></pre></td></tr></table></figure><p>在此基础上启动两个容器，<code>envoyproxy</code> 容器和 <code>nginx</code> 容器，<code>nginx</code> 容器共享 <code>envoyproxy</code> 容器的网络，以此来模拟 <code>Sidecar</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d -p 10000:10000 -v &#96;pwd&#96;&#x2F;envoy.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy envoyproxy&#x2F;envoy:latest</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy --name nginx nginx</span><br></pre></td></tr></table></figure><p>根据配置文件的规则，<code>Envoy</code> 监听在 <code>10000</code> 端口，同时该端口也在宿主机的 <code>10000</code> 端口上暴露出来。当有请求到达监听上后，<code>Envoy</code> 会对所有请求路由到 <code>some_service</code> 这个 <code>Cluster</code> 上，而该 <code>Cluster</code> 的 <code>Upstream</code> 指向本地的 <code>80</code> 端口，也就是 <code>Nginx</code> 服务上。</p><p><img src="https://upload-images.jianshu.io/upload_images/12196676-5550ffdbe14a2d0c.png" alt=""></p><h3 id="动态配置">动态配置</h3><p>动态配置可以实现全动态，即实现 <code>LDS</code> (<code>Listener Discovery Service</code>)、<code>CDS</code> (<code>Cluster Discovery Service</code>)、<code>RDS</code> (<code>Route Discovery Service</code>)、<code>EDS</code> (<code>Endpoint Discovery Service</code>)，以及 <code>ADS</code> (<code>Aggregated Discovery Service</code>)。</p><p><code>ADS</code> 不是一个实际意义上的 <code>XDS</code>，它提供了一个汇聚的功能，以实现需要多个同步 <code>XDS</code> 访问的时候可以在一个 <code>Stream</code> 中完成的作用。</p><p>下面的图通过在静态配置的基础上，比较直观的表示出各个发现服务所提供的信息。</p><p><img src="https://upload-images.jianshu.io/upload_images/12196676-1927da1e7ee7bb65.png" alt=""></p><p>由此，典型的动态配置文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 127.0.0.1, port_value: 9901 &#125;</span><br><span class="line"></span><br><span class="line">dynamic_resources:</span><br><span class="line">  cds_config:</span><br><span class="line">    ads: &#123;&#125;</span><br><span class="line">  lds_config:</span><br><span class="line">    ads: &#123;&#125;</span><br><span class="line">  ads_config:</span><br><span class="line">    api_type: GRPC</span><br><span class="line">    cluster_names: [xds_cluster]</span><br><span class="line"></span><br><span class="line">static_resources:</span><br><span class="line">  clusters:</span><br><span class="line">  - name: xds_cluster</span><br><span class="line">    connect_timeout: 0.25s</span><br><span class="line">    type: STRICT_DNS</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    http2_protocol_options: &#123;&#125;</span><br><span class="line">    hosts: [&#123; socket_address: &#123; address: envoy-server, port_value: 50051 &#125;&#125;]</span><br></pre></td></tr></table></figure><blockquote><p>注意：动态配置和静态配置最大的区别在于，启动的时候一定要指定 <code>cluster</code> 和 <code>id</code>，这两个参数表示该 Envoy 进程属于哪个 <code>Cluster</code>，<code>id</code> 要求在相同的 <code>Cluster</code> 下唯一，以表示不同的指向发现服务的连接信息。这两个参数可以在 <code>Envoy</code> 的启动命令中添加<code>--service-cluster</code> 和 <code>--service-node</code> 来指定，也可以在 <code>envoy.yaml</code> 配置文件中指定 <code>node.cluster</code> 和 <code>node.id</code>。</p></blockquote><h2 id="envoy-使用实例">Envoy 使用实例</h2><h3 id="入门实例">入门实例</h3><p>了解一个开源软件，从官方实例入手再好不过了，因此下面的例子将会围绕官方仓库中的实例展开。所以在开始之前，你需要安装并配置以下工具：</p><ul><li><code>Docker</code></li><li><code>Docker Compose</code></li><li><code>Git</code></li><li><code>Curl</code></li></ul><p>我们将会使用 <code>Docker</code> 和 <code>Docker Compose</code> 来构建和运行几个 <code>Envoy</code> 示例服务，并用 <code>Curl</code> 来检测 <code>Envoy</code> 示例服务是否在运行。</p><h4 id="运行-envoy">运行 Envoy</h4><p>首先克隆 <code>Envoy</code> 官方仓库到本地,并定位到 <code>envoy/examples/front-proxy</code> 文件夹。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;envoyproxy&#x2F;envoy</span><br><span class="line">$ cd envoy&#x2F;examples&#x2F;front-proxy</span><br></pre></td></tr></table></figure><p><code>front-proxy</code> 文件夹中的服务是一个用 <code>Flask</code> 实现的后端服务，入口文件在 <code>service.py</code> 文件里面。<code>Envoy</code> 作为一个 <code>Sidecar</code> 部件，将与 <code>service.py</code> 在同一个容器中运行，并由 <code>docker-compose,.yaml</code> 文件配置。</p><p>前端代理比后端服务更简单，它使用配置文件 <code>front-envoy.yaml</code> 来运行 <code>Envoy</code>。<code>Dockerfile-frontenvoy</code> 文件则是 <code>front-envoy</code> 的 <code>Dockerfile</code>。</p><p>如果你之前没有接触过 <code>Docker</code> 的话，你可以使用以下命令在本地构建并运行 <code>front-proxy</code> 的 <code>Docker</code> 镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd &#x2F;path&#x2F;to&#x2F;envoy&#x2F;examples&#x2F;front-proxy</span><br><span class="line">$ docker-compose up --build -d</span><br></pre></td></tr></table></figure><p>其中的 <code>--build</code> 表示构建镜像， <code>-d</code> 表示在后台运行所有 <code>docker-compose</code> 配置文件中定义的镜像，具体可参考 <code>Docker</code> 相关文档。</p><p>命令运行成功后，将会启动一个前端代理和两个服务实例：<code>service1</code> 和 <code>service2</code>。你可以通过以下命令来验证容器是否正常运行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose ps</span><br></pre></td></tr></table></figure><p>正常的话会返回以下内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ front-proxy git:(master) docker-compose ps</span><br><span class="line">          Name                         Command               State                            Ports</span><br><span class="line">----------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">front-proxy_front-envoy_1   &#x2F;usr&#x2F;bin&#x2F;dumb-init -- &#x2F;bin ...   Up      10000&#x2F;tcp, 0.0.0.0:8000-&gt;80&#x2F;tcp, 0.0.0.0:8001-&gt;8001&#x2F;tcp</span><br><span class="line">front-proxy_service1_1      &#x2F;bin&#x2F;sh -c &#x2F;usr&#x2F;local&#x2F;bin&#x2F; ...   Up      10000&#x2F;tcp, 80&#x2F;tcp</span><br><span class="line">front-proxy_service2_1      &#x2F;bin&#x2F;sh -c &#x2F;usr&#x2F;local&#x2F;bin&#x2F; ...   Up      10000&#x2F;tcp, 80&#x2F;tcp</span><br></pre></td></tr></table></figure><h4 id="测试服务是否连通">测试服务是否连通</h4><p>你可以使用 <code>curl</code> 或者浏览器来测试服务是否在正常运行</p><p>浏览器中输入 <code>http://localhost:8000/service/1</code> 或者使用以下命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl http:&#x2F;&#x2F;localhost:8000&#x2F;service&#x2F;1</span><br></pre></td></tr></table></figure><p>如果返回结果是像下面这样，则表示 <code>service1</code> 的 <code>Envoy</code> 服务正常运行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello from behind Envoy (service 1)! hostname: a841ffceafd0 resolvedhostname: 172.18.0.4</span><br></pre></td></tr></table></figure><p>你也可以用同样的方法测试 <code>service 2</code> 的服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl http:&#x2F;&#x2F;localhost:8000&#x2F;service&#x2F;2</span><br></pre></td></tr></table></figure><p>返回的结果和 <code>service 1</code> 类似。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello from behind Envoy (service 2)! hostname: e83b35c6f4fe resolvedhostname: 172.18.0.3 。</span><br></pre></td></tr></table></figure><h4 id="envoy-配置">Envoy 配置</h4><p>下面我们先简单看一下 <code>Envoy</code> 的静态配置信息，之后再继续看 <code>Demo</code> 中的动态配置信息。</p><p>我们先从 <code>front-envoy.yml</code> 入手。打开文件之后，我们会发现这个 <code>yaml</code> 有两个最高的层级，分别是 <code>static_resources</code> 和 <code>admin</code> 。<code>admin</code> 的内容相对比较简单，总共只有六行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">   access_log_path: &quot;&#x2F;dev&#x2F;null&quot;</span><br><span class="line">   address:</span><br><span class="line">     socket_address:</span><br><span class="line">       address: 0.0.0.0</span><br><span class="line">       port_value: 8001</span><br></pre></td></tr></table></figure><p>其中 <code>access_log_path</code> 字段值是 <code>/dev/null</code>，其含义是 <code>admin</code> 服务的请求日志将不会被保存。生产环境中可自行将目标目录指定到需要的地方。<code>address</code> 和 <code>port_value</code> 字段分别表示 <code>admin server</code> 运行的 <code>IP</code> 端口。</p><p><code>static_resource</code> 的内容定义了非动态管理的集群（<code>Cluster</code>）和监听器（<code>Listener</code>）相关配置。集群是 <code>Envoy</code> 连接到的一组逻辑上相似的上游主机，一个集群是一组被定义的 <code>ip/port</code> 集合，<code>Envoy</code> 将借此实现负载均衡。监听器是一组被定义的网络地址，它是可以由下游客户端连接的命名网络位置（例如，端口、<code>Unix</code> 域套接字等）。监听器是服务(程序)监听者，就是真正干活的，客户端可借此连接至服务。</p><p><code>front proxy</code> 中只有一个监听器，监听器中除了 <code>socket_address</code> 之外还有一个字段是 <code>filter_chains</code>，<code>Envoy</code> 通过此字段来管理 <code>HTTP</code> 的连接和过滤。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">listeners:</span><br><span class="line">- address:</span><br><span class="line">    socket_address:</span><br><span class="line">      address: 0.0.0.0</span><br><span class="line">      port_value: 80</span><br><span class="line">  filter_chains:</span><br><span class="line">  - filters:</span><br><span class="line">    - name: envoy.http_connection_manager</span><br><span class="line">      config:</span><br><span class="line">        codec_type: auto</span><br><span class="line">        stat_prefix: ingress_http</span><br><span class="line">        route_config:</span><br><span class="line">          name: local_route</span><br></pre></td></tr></table></figure><p>其中有个配置选项是 <code>virtual_hosts</code>，该选项在 <code>HTTP</code> 连接管理过滤器中用作定义虚拟主机，并通过正则过滤允许访问服务的域名。路由也在其中配置，例子中将 <code>/service/1</code> 和 <code>/service/2</code> 的请求分别转发到了其相应的集群中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">virtual_hosts:</span><br><span class="line">- name: backend</span><br><span class="line">  domains:</span><br><span class="line">  - &quot;*&quot;</span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      prefix: &quot;&#x2F;service&#x2F;1&quot;</span><br><span class="line">    route:</span><br><span class="line">      cluster: service1</span><br><span class="line">  - match:</span><br><span class="line">      prefix: &quot;&#x2F;service&#x2F;2&quot;</span><br><span class="line">    route:</span><br><span class="line">      cluster: service2</span><br></pre></td></tr></table></figure><p>接下来我们继续看静态集群的配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">clusters:</span><br><span class="line">- name: service1</span><br><span class="line">  connect_timeout: 0.25s</span><br><span class="line">  type: strict_dns</span><br><span class="line">  lb_policy: round_robin</span><br><span class="line">  http2_protocol_options: &#123;&#125;</span><br><span class="line">  hosts:</span><br><span class="line">  - socket_address:</span><br><span class="line">      address: service1</span><br><span class="line">      port_value: 80</span><br><span class="line">- name: service2</span><br><span class="line">  connect_timeout: 0.25s</span><br><span class="line">  type: strict_dns</span><br><span class="line">  lb_policy: round_robin</span><br><span class="line">  http2_protocol_options: &#123;&#125;</span><br><span class="line">  hosts:</span><br><span class="line">  - socket_address:</span><br><span class="line">      address: service2</span><br><span class="line">      port_value: 80</span><br></pre></td></tr></table></figure><p>在静态集群的配置内容中，我们可以配置超时时间、熔断器、服务发现等等内容。集群由一系列端点 (<code>Endpoints</code>) 组成，端点就是一组服务集群中可以响应访问请求的网络地址。在上面的例子中，端点标准定义成 <code>DNS</code> ，除此之外，端点可以直接被定义成 <code>Socket</code> 地址，或者是可动态读取的服务发现机制。</p><p><strong>尝试动手修改配置</strong></p><p>我们可以在本地尝试自己修改配置，重建镜像，测试修改后的配置。监听过滤器是 <code>Envoy</code> 为监听器提供的附加功能。比方说，想要增加访问日志到我们的 <code>HTTP</code> 过滤器中，只要增加 <code>access_log</code> 字段到配置文件中即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- filters:</span><br><span class="line">  - name: envoy.http_connection_manager</span><br><span class="line">    config:</span><br><span class="line">      codec_type: auto</span><br><span class="line">      stat_prefix: ingress_http</span><br><span class="line">      access_log:</span><br><span class="line">        - name: envoy.file_access_log</span><br><span class="line">          config:</span><br><span class="line">            path: &quot;&#x2F;var&#x2F;log&#x2F;access.log&quot;</span><br><span class="line">      route_config:</span><br></pre></td></tr></table></figure><p>修改之后，先通过 <code>docker-compose down</code> 命令关闭 <code>docker-compose</code> 容器组，然后使用 <code>docker-compose up --build -d</code> 命令重新构建镜像并运行容器组即可。</p><p>为了验证我们新增的 <code>access_log</code> 字段是否生效，我们可以模拟几次请求。然后通过命令 <code>docker-compose exec front-envoy /bin/bash</code> 手动进入容器内部查看访问日志是否在相应的目录中，你会看到 <code>/var/log/access.log</code> 文件记录着你的请求结果。</p><h4 id="管理页面">管理页面</h4><p>Envoy 的一大特色是内置了管理页面，你可以通过 <code>http://localhost:8001</code> 访问。管理页面中 <code>/cluster</code> 菜单展示了上游 (<code>Upstream</code>) 集群端口的统计内容，<code>stats</code> 菜单则显示了更多端口的统计内容。</p><p><img src="https://i.loli.net/2019/10/23/TowFauBL4Ae6Yz8.png" alt=""></p><p>更多管理页面的内容你可以直接访问帮助页面 <code>http://localhost:8001/help</code> 来查看。</p><h3 id="请求处理流程">请求处理流程</h3><p><code>Envoy</code> 中对访问请求的处理流程大致如下，先将请求数据预处理，转成 <code>Envoy</code> 中的 <code>Filter</code>， 读写请求的 <code>filter</code> 分别是 <code>ReadFilter</code> 和 <code>WriteFiler</code>，对每个网络层也有各自的 <code>filter</code> ，<code>TCP</code> 的是 <code>TcpProxyFilter</code>, <code>HTTP</code> 的是 <code>ConnectionManager</code>，都由读 <code>filter ReadFilter</code> 继承而来。各个 <code>filter</code> 预处理完成之后就会组织成上面示例配置文件中有提到的 <code>FilterChain</code>， 收到 <code>FilterChain</code> 之后会将其路由到指定的集群中，并根据负载均衡获取到相应的地址，然后将请求转发出去。</p><h3 id="进阶实例">进阶实例</h3><p>接下来的实验主要以动态配置的方式来实现一个简单的需求，首先描述一下需求场景：有两个微服务，一个是 <code>envoy-web</code>，一个 <code>envoy-server</code>。</p><ul><li><p><code>envoy-web</code> 相当于下图中的 <code>front-envoy</code> 作为对外访问的入口。</p></li><li><p><code>envoy-server</code> 相当于下图中的 <code>service_1</code> 和 <code>service_2</code>，是内部的一个微服务，部署 <code>2</code> 个实例。</p></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/12196676-2a45b1388924b33a.png" alt=""></p><p><code>envoy-server</code> 有 3 个 <code>API</code>，分别是 <code>/envoy-server/hello</code>、<code>/envoy-server/hi</code>、<code>/envoy-server/self</code>，目的是测试 <code>Envoy</code> 对于流入 <code>envoy-server</code> 的流量控制，对外只允许访问 <code>/envoy-server/hello</code> 和 <code>/envoy-server/hi</code> 两个 <code>API</code>，<code>/envoy-server/self</code> 不对外暴露服务。</p><p><code>envoy-web</code> 也有 3 个 <code>API</code>，分别是 <code>/envoy-web/hello</code>、<code>/envoy-web/hi</code>、<code>/envoy-web/self</code>，目的是测试 <code>Envoy</code> 对于流出 <code>envoy-web</code> 的流量控制，出口流量只允许 <code>/envoy-web/hello</code> 和 <code>/envoy-web/self</code> 两个访问出去。</p><p>最终的实验：外部只能访问 <code>envoy-web</code> 暴露的接口</p><ul><li><p>当访问 <code>/envoy-web/hello</code> 接口时返回 <code>envoy-server</code> 的 <code>/hello</code> 接口的数据，表示 <code>envoy-web</code> 作为客户端访问 <code>envoy-server</code> 返回服务响应的结果。</p></li><li><p>当访问 <code>/envoy-web/hi</code> 接口时，<code>envoy-web</code> 的 <code>envoy</code> 拦截住出口流量，限制 <code>envoy-web</code> 向 <code>envoy-server</code> 发送请求，对于前端用户返回 <code>mock</code> 数据。</p></li><li><p>当访问 <code>/envoy-web/self</code> 接口时，<code>envoy-web</code> 出口流量可以到达 <code>envoy-server</code> 容器，但是 <code>envoy-server</code> 在入口流量处控制住了此次请求，拒绝访问 <code>envoy-server</code>服务，对于前端用户返回 <code>mock</code> 数据。</p></li></ul><h3 id="静态配置">静态配置</h3><p>首先，以静态配置的方式先实现功能。</p><h4 id="编写服务代码">编写服务代码</h4><p>服务代码分为 <code>envoy-web</code> 和 <code>envoy-server</code> 两个服务，采用 <code>SpringBoot</code> 的方式，下面记录一些重要的代码片段。</p><ul><li>envoy-server</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class HelloRest &#123;</span><br><span class="line">    private static final Logger LOGGER &#x3D; LoggerFactory.getLogger(HelloRest.class);</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-server&#x2F;hello&quot;)</span><br><span class="line">    public String hello() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request from remote, send response, say hello&quot;);</span><br><span class="line">        return &quot;hello&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-server&#x2F;hi&quot;)</span><br><span class="line">    public String hi() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request from remote, send response, say hi&quot;);</span><br><span class="line">        return &quot;hi&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-server&#x2F;self&quot;)</span><br><span class="line">    public String self() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request from remote, send response, say self&quot;);</span><br><span class="line">        return &quot;self&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>envoy-web</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    private static final Logger LOGGER &#x3D; LoggerFactory.getLogger(HelloController.class);</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private RestTemplate template;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;local&quot;)</span><br><span class="line">    public String sayLocal() &#123;</span><br><span class="line">        LOGGER.info(&quot;get request, send response&quot;);</span><br><span class="line">        return &quot;local&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;hello&quot;)</span><br><span class="line">    public String sayHello() &#123;</span><br><span class="line">        String url &#x3D; &quot;http:&#x2F;&#x2F;127.0.0.1:10000&#x2F;envoy-server&#x2F;hello&quot;;</span><br><span class="line">        LOGGER.info(&quot;get request, send rest template to &#123;&#125;&quot;, url);</span><br><span class="line">        return getRemote(url, &quot;mock value for hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;hi&quot;)</span><br><span class="line">    public String sayHi() &#123;</span><br><span class="line">        String url &#x3D; &quot;http:&#x2F;&#x2F;127.0.0.1:10000&#x2F;envoy-server&#x2F;hi&quot;;</span><br><span class="line">        LOGGER.info(&quot;get request, send rest template to &#123;&#125;&quot;, url);</span><br><span class="line">        return getRemote(url, &quot;mock value for hi&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;&#x2F;envoy-web&#x2F;self&quot;)</span><br><span class="line">    public String saySelf() &#123;</span><br><span class="line">        String url &#x3D; &quot;http:&#x2F;&#x2F;127.0.0.1:10000&#x2F;envoy-server&#x2F;self&quot;;</span><br><span class="line">        LOGGER.info(&quot;get request, send rest template to &#123;&#125;&quot;, url);</span><br><span class="line">        return getRemote(url, &quot;mock value for self&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private String getRemote(String url, String mock) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            ResponseEntity&lt;String&gt; response &#x3D; template.getForEntity(url, String.class);</span><br><span class="line">            return response.getBody();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            LOGGER.error(&quot;error happens: &#123;&#125;&quot;, e);</span><br><span class="line">            return mock;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注：为简化起见，代码只是介绍对出入流量的控制，直接在 <code>envoy-web</code> 上访问了本地的 <code>Envoy</code> 端口进行转发流量，实际代码中可以用服务名:服务端口号访问，而此时为了使得 <code>Envoy</code> 仍然可以拦截入和出的流量，可以配置 <code>Iptables</code>（<code>Istio</code> 的实现中也是使用了 <code>Iptables</code>）。</p></blockquote><h4 id="编写配置文件">编写配置文件</h4><p>针对不同的服务，也配置了两份 <code>envoy.yaml</code> 配置文件。</p><ul><li>envoy-server</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 0.0.0.0, port_value: 9900 &#125;</span><br><span class="line">static_resources:</span><br><span class="line">  listeners:</span><br><span class="line">  - name: listener_ingress</span><br><span class="line">    address:</span><br><span class="line">      socket_address: &#123; address: 0.0.0.0, port_value: 10000 &#125;</span><br><span class="line">    filter_chains:</span><br><span class="line">    - filters:</span><br><span class="line">      - name: envoy.http_connection_manager</span><br><span class="line">        config:</span><br><span class="line">          stat_prefix: ingress_http</span><br><span class="line">          codec_type: AUTO</span><br><span class="line">          route_config:</span><br><span class="line">            name: local_route</span><br><span class="line">            virtual_hosts:</span><br><span class="line">            - name: local_service</span><br><span class="line">              domains: [&quot;*&quot;]</span><br><span class="line">              routes:</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;hello&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_server &#125;</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;hi&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_server &#125;</span><br><span class="line">          http_filters:</span><br><span class="line">          - name: envoy.router</span><br><span class="line">  clusters:</span><br><span class="line">  - name: cluster_server</span><br><span class="line">    connect_timeout: 0.5s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts: </span><br><span class="line">    - &#123; socket_address: &#123; address: 127.0.0.1, port_value: 8081 &#125;&#125;</span><br></pre></td></tr></table></figure><ul><li>envoy-web</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: &#x2F;tmp&#x2F;admin_access.log</span><br><span class="line">  address:</span><br><span class="line">    socket_address: &#123; address: 0.0.0.0, port_value: 9900 &#125;</span><br><span class="line">static_resources:</span><br><span class="line">  listeners:</span><br><span class="line">  - name: listener_ingress</span><br><span class="line">    address:</span><br><span class="line">      socket_address: &#123; address: 0.0.0.0, port_value: 10000 &#125;</span><br><span class="line">    filter_chains:</span><br><span class="line">    - filters:</span><br><span class="line">      - name: envoy.http_connection_manager</span><br><span class="line">        config:</span><br><span class="line">          stat_prefix: ingress_http</span><br><span class="line">          codec_type: AUTO</span><br><span class="line">          route_config:</span><br><span class="line">            name: local_route</span><br><span class="line">            virtual_hosts:</span><br><span class="line">            - name: local_service</span><br><span class="line">              domains: [&quot;*&quot;]</span><br><span class="line">              routes:</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-web&#x2F;&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_ingress &#125;</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;hello&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_egress &#125;</span><br><span class="line">              - match: &#123; prefix: &quot;&#x2F;envoy-server&#x2F;self&quot; &#125;</span><br><span class="line">                route: &#123; cluster: cluster_egress &#125;</span><br><span class="line">          http_filters:</span><br><span class="line">          - name: envoy.router</span><br><span class="line">  clusters:</span><br><span class="line">  - name: cluster_ingress</span><br><span class="line">    connect_timeout: 0.5s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts:</span><br><span class="line">    - &#123; socket_address: &#123; address: 127.0.0.1, port_value: 8080 &#125;&#125;</span><br><span class="line">  - name: cluster_egress</span><br><span class="line">    connect_timeout: 0.5s</span><br><span class="line">    type: STATIC</span><br><span class="line">    lb_policy: ROUND_ROBIN</span><br><span class="line">    hosts:</span><br><span class="line">    - &#123; socket_address: &#123; address: 172.17.0.2, port_value: 10000 &#125;&#125;</span><br><span class="line">    - &#123; socket_address: &#123; address: 172.17.0.3, port_value: 10000 &#125;&#125;</span><br></pre></td></tr></table></figure><h4 id="启动测试">启动测试</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># envoy-server1</span><br><span class="line">$ docker run -d -v &#96;pwd&#96;&#x2F;envoy-server.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy-server1 envoyproxy&#x2F;envoy:latest &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --service-cluster envoy-server --service-node 1 -c &#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --v2-config-only</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy-server1 --name envoy-server1 envoy-server:1.1</span><br><span class="line"></span><br><span class="line"># envoy-server2</span><br><span class="line">$ docker run -d -v &#96;pwd&#96;&#x2F;envoy-server.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy-server2 envoyproxy&#x2F;envoy:latest &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --service-cluster envoy-server --service-node 2 -c &#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --v2-config-only</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy-server2 --name envoy-server2 envoy-server:1.1</span><br><span class="line"></span><br><span class="line"># envoy-web</span><br><span class="line">$ docker run -d -p 10000:10000 -v &#96;pwd&#96;&#x2F;envoy-web.yaml:&#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --name envoyproxy-web envoyproxy&#x2F;envoy:latest &#x2F;usr&#x2F;local&#x2F;bin&#x2F;envoy --service-cluster envoy-web --service-node 1 -c &#x2F;etc&#x2F;envoy&#x2F;envoy.yaml --v2-config-only</span><br><span class="line">$ docker run -d --network&#x3D;container:envoyproxy-web --name envoy-web envoy-web:1.1</span><br></pre></td></tr></table></figure><p>当容器部署完毕之后，可以直接访问以下 3 个 URL ，其中 hi 和 self 的访问返回的是 mock 数据，虽然同为 mock 数据，但是这两个 <code>URL</code> 其实是不相同的，一个是在 <code>Envoy</code> 出口流量处做的控制，一个是在 <code>Envoy</code> 入口流量处做的控制，其中的细节可以再去品味品味。</p><p><img src="https://upload-images.jianshu.io/upload_images/12196676-83ac7de7c28ad6a1.png" alt=""></p><h3 id="动态配置">动态配置</h3><p>动态配置需要实现发现服务，通过 <code>GRPC</code> 的方式获取相应。</p><p>动态的配置文件在前面的内容中已经有过介绍，最重要的是需要提供一个发现服务，对外提供 <code>XDS</code> 服务，下面以其中的一个 <code>LDS</code> 作为介绍，其他 <code>XDS</code> 实现类似。</p><p>服务端：既然作为服务，就需要对外提供接口服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">public class GrpcService &#123;</span><br><span class="line">    private Server server;</span><br><span class="line">    private static final int PORT &#x3D; 50051;</span><br><span class="line"></span><br><span class="line">    private void start() throws IOException &#123;</span><br><span class="line">        server &#x3D; ServerBuilder.forPort(PORT)</span><br><span class="line">                .addService(new LdsService())</span><br><span class="line">                .addService(new CdsService())</span><br><span class="line">                .addService(new RdsService())</span><br><span class="line">                .addService(new EdsService())</span><br><span class="line">                .addService(new AdsService())</span><br><span class="line">                .build()</span><br><span class="line">                .start();</span><br><span class="line">        System.err.println(&quot;Server started, listening on &quot; + PORT);</span><br><span class="line">        Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123;</span><br><span class="line">            System.err.println(&quot;*** shutting down gRPC server since JVM is shutting down&quot;);</span><br><span class="line">            GrpcService.this.stop();</span><br><span class="line">            System.err.println(&quot;*** server shut down&quot;);</span><br><span class="line">        &#125;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private void stop() &#123;</span><br><span class="line">        if (server !&#x3D; null) &#123;</span><br><span class="line">            server.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private void blockUntilShutdown() throws InterruptedException &#123;</span><br><span class="line">        if (server !&#x3D; null) &#123;</span><br><span class="line">            server.awaitTermination();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws IOException, InterruptedException &#123;</span><br><span class="line">        final GrpcService server &#x3D; new GrpcService();</span><br><span class="line">        server.start();</span><br><span class="line">        server.blockUntilShutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>XDS</code> 通过 <code>GRPC</code> 生成服务端的 <code>stub</code> 文件，实现 <code>LdsServer</code> 继承自 <code>ListenerDiscoveryServiceGrpc.ListenerDiscoveryServiceImplBase</code>，需要实现 <code>streamListeners</code> 方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public class LdsService extends ListenerDiscoveryServiceGrpc.ListenerDiscoveryServiceImplBase &#123;</span><br><span class="line">    private static final Logger LOGGER &#x3D; LogManager.getLogger();</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public StreamObserver&lt;Discovery.DiscoveryRequest&gt; streamListeners(StreamObserver&lt;Discovery.DiscoveryResponse&gt; responseObserver) &#123;</span><br><span class="line">        return new StreamObserver&lt;Discovery.DiscoveryRequest&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void onNext(Discovery.DiscoveryRequest request) &#123;</span><br><span class="line">                XdsHelper.getInstance().buildAndSendResult(request, responseObserver);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onError(Throwable throwable) &#123;</span><br><span class="line">                LOGGER.warn(&quot;Error happens&quot;, throwable);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onCompleted() &#123;</span><br><span class="line">                LOGGER.info(&quot;LdsService completed&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>至此，我们就基本介绍完 <code>Envoy</code> 使用的一些常见的使用方法，在实现的时候也会有其他一些细节需要注意。比如，<code>Envoy</code> 作为一个服务之间网络请求的代理，如何拦截全部的入和出流量？</p><p><code>Istio</code> 给了一个很好的解决方案，就是通过 <code>Iptables</code>。它会使用一个特定的 <code>uid</code>（默认 1337）用户运行 <code>Envoy</code> 进程，<code>Iptables</code> 对于 <code>1337</code> 用户的流量不做拦截。下面就是参考 <code>Istio</code> 的 <code>iptables.sh</code> 做的一个实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">uname&#x3D;envoy</span><br><span class="line">uid&#x3D;1337</span><br><span class="line">iptalbes -t nat -F</span><br><span class="line">iptables -t nat -I PREROUTING -p tcp -j REDIRECT --to-ports 10000</span><br><span class="line">iptables -t nat -N ENVOY_OUTPUT</span><br><span class="line">iptables -t nat -A OUTPUT -p tcp -j ENVOY_OUTPUT</span><br><span class="line">iptables -t nat -A ENVOY_OUTPUT -p tcp -d 127.0.0.1&#x2F;32 -j RETURN</span><br><span class="line">iptables -t nat -A ENVOY_OUTPUT -m owner --uid-owner $&#123;uid&#125; -j RETURN</span><br><span class="line">iptables -t nat -A ENVOY_OUTPUT -p tcp -j REDIRECT --to-ports 10000</span><br></pre></td></tr></table></figure><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://holajiawei.com/envoy/" target="_blank" rel="noopener">https://holajiawei.com/envoy/</a></p></li><li><p><a href="https://www.lijiaocn.com/soft/envoy/" target="_blank" rel="noopener">https://www.lijiaocn.com/soft/envoy/</a></p></li><li><p><a href="https://www.jianshu.com/p/90f9ee98ce70" target="_blank" rel="noopener">https://www.jianshu.com/p/90f9ee98ce70</a></p></li><li><p><a href="https://github.com/wellls/blog/issues/47" target="_blank" rel="noopener">https://github.com/wellls/blog/issues/47</a></p></li><li><p><a href="https://jimmysong.io/posts/envoy-as-front-proxy/" target="_blank" rel="noopener">https://jimmysong.io/posts/envoy-as-front-proxy/</a></p></li><li><p><a href="https://www.yangcs.net/posts/run-envoy-on-your-laptop/" target="_blank" rel="noopener">https://www.yangcs.net/posts/run-envoy-on-your-laptop/</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Envoy&quot;&gt;什么是 Envoy&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 是一款 &lt;code&gt;CNCF&lt;/code&gt; 旗下的开源项目，由 &lt;code&gt;Lyft&lt;/code&gt; 开源。&lt;code&gt;Envoy&lt;/code&gt; 采用 C++ 实现，是面向 &lt;code&gt;Service Mesh&lt;/code&gt; 的高性能网络代理服务。它与应用程序并行运行，通过以平台无关的方式提供通用功能来抽象网络。当基础架构中的所有服务流量都通过 Envoy 网格时，通过一致的可观测性，很容易地查看问题区域，调整整体性能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 也是 &lt;code&gt;Istio Service Mesh&lt;/code&gt; 中默认的 &lt;code&gt;Data Plane&lt;/code&gt;，本文我们将讲解 &lt;code&gt;Envoy&lt;/code&gt; 的一些基本概念，并采用一些实例来介绍如何在本地环境中快速使用 &lt;code&gt;Envoy&lt;/code&gt; 作为 &lt;code&gt;Service Mesh&lt;/code&gt; 的数据平面，以帮助读者理解 &lt;code&gt;Istio&lt;/code&gt; 的 &lt;code&gt;Data Panel&lt;/code&gt; 层实现。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;官网：&lt;a href=&quot;https://www.envoyproxy.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.envoyproxy.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Envoy-特性&quot;&gt;Envoy 特性&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;整体架构&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/4483e99egy1ftn7wet57fj233f1utag1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;进程无关架构&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 是一个自组织的模块，与应用 &lt;code&gt;Server&lt;/code&gt; 并无直接依赖。所有的 &lt;code&gt;Envoy&lt;/code&gt; 构建了一个透明的服务网格 &lt;code&gt;Service Mesh&lt;/code&gt;，处于其中的应用只需要简单的与本地的 &lt;code&gt;Envoy&lt;/code&gt; 进行收发信息，并不需要关注整个网络拓扑。这种架构对于应用通信有两大好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 可以让任何的编程语言编写的服务通信，协同工作，&lt;code&gt;Envoy&lt;/code&gt; 帮你屏蔽了服务之间的沟壑。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任何曾经在大型微服务开发中工作过的人都知道发布一个库更新是多么的痛苦。&lt;code&gt;Envoy&lt;/code&gt; 可以以一种透明的方式快速的发布更新整个基础架构中的版本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Envoy" scheme="https://www.hi-linux.com/tags/Envoy/"/>
    
  </entry>
  
  <entry>
    <title>如何通过 Alertmanager 有效的给 Prometheus 添加一个警报系统</title>
    <link href="https://www.hi-linux.com/posts/23179.html"/>
    <id>https://www.hi-linux.com/posts/23179.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.545Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>警报是监控系统中必不可少的一块, 当然了, 也是最难搞的一块. 我们乍一想, 警报似乎很简单一件事:</p><blockquote><p>假如发生了异常情况, 发送或邮件/消息通知给某人或某频道</p></blockquote><p>一把梭搞起来之后, 就不免有一些小麻烦:</p><ul><li><p>这个啊…一天中总有那么几次波动, 也难修难查了, 算了算了不看了</p></li><li><p>警报太多了, 实在看不过来, 屏蔽/归档/放生吧…</p></li><li><p>有毒吧, 这个阈值也太低了</p></li><li><p>卧槽, 这些警报啥意思啊, 发给我干嘛啊?</p></li><li><p>卧槽卧槽卧槽, 怎么一下子几十百来条警报, 哦…原来网络出问题了全崩了</p></li></ul><p>到最后我们还能总结出一个奇怪的规律:</p><blockquote><p>这世界上只有两种警报，一种是疯狂报警但是没有卵用完全没人看的警报，一种是非常有效大家都想看但在用户反馈前从来都报不出来的警报。—— 鲁迅(</p></blockquote><p>玩笑归玩笑，但至少我们能看出，警报不是一个简单的计算+通知系统。只是，”做好警报”这件事本身是个综合问题，代码能解决的也只是其中的一小部分，更多的事情要在组织、人事和管理上去做。我掰不出那么有深度的文章，这篇文章就专注一点，只讲代码部分里的通知，也就是 Prometheus 生态中的 Alertmanager 这个组件。</p><a id="more"></a><h2 id="为什么要-alertmanager">为什么要 Alertmanager？</h2><p>我们先介绍一点背景知识，Prometheus 生态中的警报是在 Prometheus Server 中计算警报规则(Alert Rule)并产生的，而所谓计算警报规则，其实就是周期性地执行一段 PromQL，得到的查询结果就是警报，比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node_load5 &gt; 20</span><br></pre></td></tr></table></figure><p>这个 PromQL 会查出所有”在最近一次采样中，5分钟平均 Load 大于 20”的时间序列。这些序列带上它们的标签就被转化为警报。</p><p>只是，当 Prometheus Server 计算出一些警报后，它自己并没有能力将这些警报通知出去，只能将警报推给 Alertmanager，由 Alertmanager 进行发送。</p><p>这个切分，一方面是出于单一职责的考虑，让 Prometheus “do one thing and do it well”, 另一方面则是因为警报发送确实不是一件”简单”的事，需要一个专门的系统来做好它。可以这么说，Alertmanager 的目标不是简单地”发出警报”，而是”发出高质量的警报”。它提供的高级功能包括但不限于：</p><ul><li><p>Go Template 渲染警报内容；</p></li><li><p>管理警报的重复提醒时机与消除后消除通知的发送；</p></li><li><p>根据标签定义警报路由，实现警报的优先级、接收人划分，并针对不同的优先级和接收人定制不同的发送策略；</p></li><li><p>将同类型警报打包成一条通知发送出去，降低警报通知的频率；</p></li><li><p>支持静默规则: 用户可以定义一条静默规则，在一段时间内停止发送部分特定的警报，比如已经确认是搜索集群问题，在修复搜索集群时，先静默掉搜索集群相关警报；</p></li><li><p>支持”抑制”规则(Inhibition Rule): 用户可以定义一条”抑制”规则，规定在某种警报发生时，不发送另一种警报，比如在”A 机房网络故障”这条警报发生时，不发送所有”A 机房中的警报”；</p></li></ul><p>假如你很忙，那么读到这里就完全 OK 了，反正这类文章最大的作用就是让我们”知道有 X 这回事，大概了解有啥特性，当有需求匹配时，能想到试试看 X 合不合适“，其中 X = Alertmanager。当然，假如你是个好奇宝宝，那么还可以看看下面的解析。</p><h2 id="alertmanager-内部架构">Alertmanager 内部架构</h2><p>先看官方文档中的架构图：</p><p><img src="https://aleiwu.com/img/alertmanager/alertmanager.png" alt=""></p><ol><li><p>从左上开始，Prometheus 发送的警报到 Alertmanager;</p></li><li><p>警报会被存储到 AlertProvider 中，Alertmanager 的内置实现就是包了一个 map，也就是存放在本机内存中，这里可以很容易地扩展其它 Provider;</p></li><li><p>Dispatcher 是一个单独的 goroutine，它会不断到 AlertProvider 拉新的警报，并且根据 YAML 配置的 Routing Tree 将警报路由到一个分组中;</p></li><li><p>分组会定时进行 flush (间隔为配置参数中的 group_interval), flush 后这组警报会走一个 Notification Pipeline 链式处理;</p></li><li><p>Notification Pipeline 为这组警报确定发送目标，并执行抑制逻辑，静默逻辑，去重逻辑，发送与重试逻辑，实现警报的最终投递;</p></li></ol><p>下面就分开讲一讲核心的两块：</p><ol><li><p>Dispatcher 中的 Routing Tree 的实现与设计意图</p></li><li><p>Notification Pipeline 的实现与设计意图</p></li></ol><h3 id="routing-tree">Routing Tree</h3><p>Routing Tree 的是一颗多叉树，节点的数据结构定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 节点包含警报的路由逻辑</span><br><span class="line">type Route struct &#123;</span><br><span class="line">    &#x2F;&#x2F; 父节点</span><br><span class="line">    parent *Route</span><br><span class="line">    &#x2F;&#x2F; 节点的配置，下文详解</span><br><span class="line">    RouteOpts RouteOpts</span><br><span class="line">    &#x2F;&#x2F; Matchers 是一组匹配规则，用于判断 Alert 与当前节点是否匹配</span><br><span class="line">    Matchers types.Matchers</span><br><span class="line">    &#x2F;&#x2F; 假如为 true, 那么 Alert 在匹配到一个节点后，还会继续往下匹配</span><br><span class="line">    Continue bool</span><br><span class="line">    &#x2F;&#x2F; 子节点</span><br><span class="line">    Routes []*Route</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体的处理代码很简单，深度优先搜索：警报从 root 开始匹配（root 默认匹配所有警报），然后根据节点中定义的 Matchers 检测警报与节点是否匹配，匹配则继续往下搜索，默认情况下第一个”最深”的 match (也就是 DFS 回溯之前的最后一个节点)会被返回。特殊情况就是节点配置了 Continue=true，这时假如这个节点匹配上了，那不会立即返回，而是继续搜索，用于支持警报发送给多方这种场景（比如”抄送”)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 深度优先搜索</span><br><span class="line">func (r *Route) Match(lset model.LabelSet) []*Route &#123;</span><br><span class="line">    if !r.Matchers.Match(lset) &#123;</span><br><span class="line">    return nil</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    var all []*Route</span><br><span class="line">    for _, cr :&#x3D; range r.Routes &#123;</span><br><span class="line">        &#x2F;&#x2F; 递归调用子节点的 Match 方法</span><br><span class="line">        matches :&#x3D; cr.Match(lset)</span><br><span class="line"></span><br><span class="line">        all &#x3D; append(all, matches...)</span><br><span class="line"></span><br><span class="line">        if matches !&#x3D; nil &amp;&amp; !cr.Continue &#123;</span><br><span class="line">          break</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 假如没有任何节点匹配上，那就匹配根节点</span><br><span class="line">    if len(all) &#x3D;&#x3D;0 &#123;</span><br><span class="line">        all &#x3D; append(all, r)</span><br><span class="line">    &#125;</span><br><span class="line">    return all</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么要设计一个复杂的 Routing Tree 逻辑呢？我们看看 Prometheus 官方的配置例子： 为了简化编写，Alertmanager 的设计是根节点的所有参数都会被子节点继承（除非子节点重写了这个参数）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">route:</span><br><span class="line">  # 根节点的警报会发送给默认的接收组</span><br><span class="line">  # 该节点中的警报会按’cluster’和’alertname’做 Group，每个分组中最多每5分钟发送一条警报，同样的警报最多4小时发送一次</span><br><span class="line">  receiver:’default-receiver’</span><br><span class="line">  group_wait: 30s</span><br><span class="line">  group_interval: 5m</span><br><span class="line">  repeat_interval: 4h</span><br><span class="line">  group_by: [cluster, alertname]</span><br><span class="line">  # 没有匹配到子节点的警报，会默认匹配到根节点上</span><br><span class="line">  # 接下来是子节点的配置：</span><br><span class="line">  routes:</span><br><span class="line">    # 所有 service 字段为 mysql 或 cassandra 的警报，会发送到’database-pager’这个接收组</span><br><span class="line">    # 由于继承逻辑，这个节点中的警报仍然是按’cluster’和’alertname’做 Group 的</span><br><span class="line">  - receiver:’database-pager’</span><br><span class="line">    group_wait: 10s</span><br><span class="line">    match_re:</span><br><span class="line">    service: mysql|cassandra</span><br><span class="line">    # 所有 team 字段为 fronted 的警报，会发送到’frontend-pager’这个接收组</span><br><span class="line">    # 很重要的一点是，这个组中的警报是按’product’和’environment’做分组的，因为’frontend’面向用户，更关心哪个’产品’的什么’环境’出问题了</span><br><span class="line">  - receiver:’frontend-pager’</span><br><span class="line">    group_by: [product, environment]</span><br><span class="line">    match:</span><br><span class="line">    team: frontend</span><br></pre></td></tr></table></figure><p>总结一下，Routing Tree 的设计意图是让用户能够非常自由地给警报归类，然后根据归类后的类别来配置要发送给谁以及怎么发送：</p><ul><li><p>发送给谁？上面已经做了很好的示例，’数据库警报’和’前端警报’都有特定的接收组，都没有匹配上那么就是’默认警报’, 发送给默认接收组</p></li><li><p>怎么发送？对于一类警报，有个多个字段来配置发送行为：</p><ul><li><p>group_by：决定了警报怎么分组，每个 group 只会定时产生一次通知，这就达到了降噪的效果，而不同的警报类别分组方式显然是不一样的，举个例子：</p><ul><li><p>配置中的 ‘数据库警报’ 是按 ‘集群’ 和 ‘规则名’ 分组的，这表明对于数据库警报，我们关心的是“哪个集群的哪个规则出问题了”，比如一个时间段内，’华东’集群产生了10条 ‘API响应时间过长’ 警报，这些警报就会聚合在一个通知里发出来；</p></li><li><p>配置中的 ‘前端警报’ 是按 ‘产品’ 和 ‘环境’ 分组的， 这表明对于前端警报，我们关心的是“哪个产品的哪个环境出问题了”</p></li></ul></li><li><p>group_interval 和 group_wait: 控制分组的细节，不细谈，其中 group_interval 控制了这个分组最快多久执行一次 Notification Pipeline</p></li><li><p>repeat_interval: 假如一个相同的警报一直 FIRING，Alertmanager 并不会一直发送警报，而会等待一段时间，这个等待时间就是 repeat_interval，显然，不同类型警报的发送频率也是不一样的</p></li></ul></li></ul><p>group_interval 和 repeat_interval 的区别会在下文中详述</p><h3 id="notification-pipeline">Notification Pipeline</h3><p>由 Routing Tree 分组后的警报会触发 Notification Pipeline:</p><ul><li><p>当一个 AlertGroup 新建后，它会等待一段时间（group_wait 参数)，再触发第一次 Notification Pipeline</p></li><li><p>假如这个 AlertGroup 持续存在，那么之后每隔一段时间（group_interval 参数)，都会触发一次 Notification Pipeline</p></li></ul><p>每次触发 Notification Pipeline，AlertGroup 都会将组内所有的 Alert 作为一个列表传进 Pipeline, Notification Pipeline 本身是一个按照责任链模式设计的接口，MultiStage 这个实现会链式执行所有的 Stage：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; A Stage processes alerts under the constraints of the given context.</span><br><span class="line">type Stage interface &#123;</span><br><span class="line">    Exec(ctx context.Context, l log.Logger, alerts …*types.Alert) (context.Context, []*types.Alert, error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; A MultiStage executes a series of stages sequencially.</span><br><span class="line">type MultiStage []Stage</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Exec implements the Stage interface.</span><br><span class="line">func (ms MultiStage) Exec(ctx context.Context, l log.Logger, alerts …*types.Alert) (context.Context, []*types.Alert, error) &#123;</span><br><span class="line">    var err error</span><br><span class="line">    for _, s :&#x3D; range ms &#123;</span><br><span class="line">        if len(alerts) &#x3D;&#x3D;0&#123;</span><br><span class="line">            return ctx, nil, nil</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ctx, alerts, err &#x3D; s.Exec(ctx, l, alerts…)</span><br><span class="line">        if err !&#x3D; nil &#123;</span><br><span class="line">            return ctx, nil, err</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return ctx, alerts, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MultiStage 里塞的就是开头架构图里画的 InhibitStage、SilenceStage…这么一条链式处理的流程，这里要提一下，官方的架构图画错了，RoutingStage 其实处在整个 Pipeline 的首位，不过这个顺序并不影响逻辑。 要重点说的是DedupStage和NotifySetStage它俩协同负责去重工作，具体做法是：</p><ul><li><p>NotifySetStage 会为发送成功的警报记录一条发送通知，key 是’接收组名字’+’GroupKey 的 key 值’，value 是当前 Stage 收到的 []Alert (这个列表和最开始进入 Notification Pipeline 的警报列表有可能是不同的，因为其中有些 Alert 可能在前置 Stage 中已经被过滤掉了)</p></li><li><p>DedupStage 中会以’接收组名字’+’GroupKey 的 key 值’为 key 查询通知记录，假如：</p><ul><li><p>查询无结果，那么这条通知没发过，为这组警报发送一条通知；</p></li><li><p>查询有结果，那么查询得到已经发送过的一组警报 S，判断当前的这组警报 A 是否为 S 的子集：</p><ul><li><p>假如 A 是 S 的子集，那么表明 A 和 S 重复，这时候要根据 repeat_interval 来决定是否再次发送：</p><ul><li><p>距离 S 的发送时间已经过去了足够久（repeat_interval)，那么我们要再发送一遍；</p></li><li><p>距离 S 的发送时间还没有达到 repeat_interval，那么为了降低警报频率，触发去重逻辑，这次我们就不发了；</p></li></ul></li><li><p>假如 A 不是 S 的子集，那么 A 和 S 不重复，需要再发送一次； 上面的表述可能有些抽象，最后表现出来的结果是：</p></li></ul></li></ul></li><li><p>假如一个 AlertGroup 里的警报一直发生变化，那么虽然每次都是新警报，不会被去重，但是由于 group_interval （假设是5分钟）存在，这个 AlertGroup 最多 5 分钟触发一次 Notification Pipeline，因此最多也只会 5 分钟发送一条通知；</p></li><li><p>假如一个 AlertGroup 里的警报一直不变化，就是那么几条一直 FIRING 着，那么虽然每个 group_interval 都会触发 Notification Pipeline，但是由于 repeate_interval（假设是1小时）存在，因此最多也只会每 1 小时为这个重复的警报发送一条通知； 再说一下 Silence 和 Inhibit，两者都是基于用户主动定义的规则的：</p></li><li><p>Silence Rule：静默规则用来关闭掉部分警报的通知，比如某个性能问题已经修复了，但需要排期上线，那么在上线前就可以把对应的警报静默掉来减少噪音；</p></li><li><p>Inhibit Rule：抑制规则用于在某类警报发生时，抑制掉另一类警报，比如某个机房宕机了，那么会影响所有上层服务，产生级联的警报洪流，反而会掩盖掉根本原因，这时候抑制规则就有用了； 因此 Notification Pipeline 的设计意图就很明确了：通过一系列逻辑（如抑制、静默、去重）来获得更高的警报质量，由于警报质量的维度很多（剔除重复、类似的警报，静默暂时无用的警报，抑制级联警报），因此 Notification Pipeline 设计成了责任链模式，以便于随时添加新的环节来优化警报质量</p></li></ul><h2 id="一个-prometheus-报警处理实例">一个 Prometheus 报警处理实例</h2><p>最近又被问到了 Prometheus 为啥不报警，恰好回忆起之前经常解答相关问题，不妨写一篇文章来解决下面两个问题：</p><ul><li><p>我的 Prometheus 为啥报警？</p></li><li><p>我的 Prometheus 为啥不报警？</p></li></ul><h3 id="从-for-参数开始">从 for 参数开始</h3><p>我们首先需要一些背景知识：Prometheus 是如何计算并产生警报的？</p><p>看一条简单的警报规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- alert: KubeAPILatencyHigh</span><br><span class="line">  annotations:</span><br><span class="line">    message: The API server has a 99th percentile latency of &#123;&#123; $value &#125;&#125; seconds</span><br><span class="line">      for &#123;&#123; $labels.verb &#125;&#125; &#123;&#123; $labels.resource &#125;&#125;.</span><br><span class="line">  expr: |</span><br><span class="line">    cluster_quantile:apiserver_request_latencies:histogram_quantile&#123;job&#x3D;&quot;apiserver&quot;,quantile&#x3D;&quot;0.99&quot;,subresource!&#x3D;&quot;log&quot;&#125; &gt; 4</span><br><span class="line">  for: 10m</span><br><span class="line">  labels:</span><br><span class="line">    severity: critical</span><br></pre></td></tr></table></figure><p>这条警报的<em>大致</em>含义是，假如 kube-apiserver 的 P99 响应时间大于 4 秒，并持续 10 分钟以上，就产生报警。</p><p>首先要注意的是由 <code>for</code> 指定的 Pending Duration。这个参数主要用于降噪，很多类似响应时间这样的指标都是有抖动的，通过指定 Pending Duration，我们可以 过滤掉这些瞬时抖动，让 on-call 人员能够把注意力放在真正有持续影响的问题上。</p><p>那么显然，下面这样的状况是不会触发这条警报规则的，因为虽然指标已经达到了警报阈值，但持续时间并不够长：</p><p><img src="https://aleiwu.com/prometheus-peaks.png" alt=""></p><p>但偶尔我们也会碰到更奇怪的事情。</p><h3 id="为什么不报警">为什么不报警？</h3><p><img src="https://aleiwu.com/no-alert.jpg" alt=""></p><p>类似上面这样持续超出阈值的场景，为什么有时候会不报警呢？</p><h3 id="为什么报警">为什么报警？</h3><p><img src="https://aleiwu.com/why-alert.jpg" alt=""></p><p>类似上面这样并未持续超出阈值的场景，为什么有时又会报警呢？</p><h3 id="采样间隔">采样间隔</h3><p>这其实都源自于 Prometheus 的数据存储方式与计算方式。</p><p>首先，Prometheus 按照配置的抓取间隔(<code>scrape_interval</code>)定时抓取指标数据，因此存储的是形如 (timestamp, value) 这样的采样点。</p><p>对于警报， Prometheus 会按固定的时间间隔重复计算每条警报规则，因此警报规则计算得到的只是稀疏的采样点，而警报持续时间是否大于 <code>for</code> 指定的 Pending Duration 则是由这些稀疏的采样点决定的。</p><p>而在 Grafana 渲染图表时，Grafana 发送给 Prometheus 的是一个 Range Query，其执行机制是从时间区间的起始点开始，每隔一定的时间点（由 Range Query 的 <code>step</code> 请求参数决定） 进行一次计算采样。</p><p>这些结合在一起，就会导致警报规则计算时“看到的内容”和我们在 Grafana 图表上观察到的内容不一致，比如下面这张示意图：</p><p><img src="https://aleiwu.com/alert-firing.jpg" alt=""></p><p>上面图中，圆点代表原始采样点：</p><ul><li><p>40s 时，第一次计算，低于阈值</p></li><li><p>80s 时，第二次计算，高于阈值，进入 Pending 状态</p></li><li><p>120s 时，第三次计算，仍然高于阈值，90s 处的原始采样点虽然低于阈值，但是警报规则计算时并没有”看到它“</p></li><li><p>160s 时，第四次计算，高于阈值，Pending 达到 2 分钟，进入 firing 状态</p></li><li><p>持续高于阈值</p></li><li><p>直到 360s 时，计算得到低于阈值，警报消除</p></li></ul><p>由于采样是稀疏的，部分采样点会出现被跳过的状况，而当 Grafana 渲染图表时，取决于 Range Query 中采样点的分布，图表则有可能捕捉到 被警报规则忽略掉的”低谷“（图三)或者也可能无法捕捉到警报规则碰到的”低谷“（图二）。如此这般，我们就被”图表“给蒙骗过去，质疑起警报来了。</p><h3 id="如何应对">如何应对</h3><p>首先嘛， Prometheus 作为一个指标系统天生就不是精确的——由于指标本身就是稀疏采样的，事实上所有的图表和警报都是”估算”，我们也就不必 太纠结于图表和警报的对应性，能够帮助我们发现问题解决问题就是一个好监控系统。当然，有时候我们也得证明这个警报确实没问题，那可以看一眼 <code>ALERTS</code> 指标。<code>ALERTS</code> 是 Prometheus 在警报计算过程中维护的内建指标，它记录每个警报从 Pending 到 Firing 的整个历史过程，拉出来一看也就清楚了。</p><p>但有时候 ALERTS 的说服力可能还不够，因为它本身并没有记录每次计算出来的值到底是啥，而在我们回头去考证警报时，又无法选取出和警报计算过程中一模一样的计算时间点， 因此也就无法还原警报计算时看到的计算值究竟是啥。这时候终极解决方案就是把警报所要计算的指标定义成一条 Recording Rule，计算出一个新指标来记录计算值，然后针对这个 新指标做阈值报警。kube-prometheus 的警报规则中就大量采用了这种技术。</p><h3 id="到此为止了吗">到此为止了吗？</h3><p>Prometheus 警报不仅包含 Prometheus 本身，还包含用于警报治理的 Alertmanager，我们可以看一看上面那张指标计算示意图的全图：</p><p><img src="https://aleiwu.com/alert-overview.jpg" alt=""></p><p>在警报产生后，还要经过 Alertmanager 的分组、抑制处理、静默处理、去重处理和降噪处理最后再发送给接收者。而这个过程也有大量的因素可能会导致警报产生了却最终没有进行通知。</p><h2 id="结语">结语</h2><p>Alertmanager 整体的设计意图就是奔着治理警报（通知）去的，首先它用 Routing Tree 来帮助用户定义警报的归类与发送逻辑，然后再用 Notification Pipeline 来做抑制、静默、去重以提升警报质量。这些功能虽然不能解决”警报”这件事中所有令人头疼的问题，但确实为我们着手去解决”警报质量”相关问题提供了趁手的工具。</p><blockquote><p>本文转载自：「Aylei’s Blog」，原文：1.<a href="https://url.cn/5Gp0VLq%E3%80%812.https://url.cn/5MEMY8K%EF%BC%8C%E7%89%88%E6%9D%83%E5%BD%92%E5%8E%9F%E4%BD%9C%E8%80%85%E6%89%80%E6%9C%89%E3%80%82%E6%AC%A2%E8%BF%8E%E6%8A%95%E7%A8%BF%EF%BC%8C%E6%8A%95%E7%A8%BF%E9%82%AE%E7%AE%B1:" target="_blank" rel="noopener">https://url.cn/5Gp0VLq、2.https://url.cn/5MEMY8K，版权归原作者所有。欢迎投稿，投稿邮箱:</a> <code>editor@hi-linux.com</code> 。</p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;警报是监控系统中必不可少的一块, 当然了, 也是最难搞的一块. 我们乍一想, 警报似乎很简单一件事:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假如发生了异常情况, 发送或邮件/消息通知给某人或某频道&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一把梭搞起来之后, 就不免有一些小麻烦:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;这个啊…一天中总有那么几次波动, 也难修难查了, 算了算了不看了&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;警报太多了, 实在看不过来, 屏蔽/归档/放生吧…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有毒吧, 这个阈值也太低了&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;卧槽, 这些警报啥意思啊, 发给我干嘛啊?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;卧槽卧槽卧槽, 怎么一下子几十百来条警报, 哦…原来网络出问题了全崩了&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;到最后我们还能总结出一个奇怪的规律:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这世界上只有两种警报，一种是疯狂报警但是没有卵用完全没人看的警报，一种是非常有效大家都想看但在用户反馈前从来都报不出来的警报。—— 鲁迅(&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;玩笑归玩笑，但至少我们能看出，警报不是一个简单的计算+通知系统。只是，”做好警报”这件事本身是个综合问题，代码能解决的也只是其中的一小部分，更多的事情要在组织、人事和管理上去做。我掰不出那么有深度的文章，这篇文章就专注一点，只讲代码部分里的通知，也就是 Prometheus 生态中的 Alertmanager 这个组件。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/categories/Prometheus/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Prometheus" scheme="https://www.hi-linux.com/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款让所有终端程序轻松支持 SOCKS5 代理的神器 graftcp</title>
    <link href="https://www.hi-linux.com/posts/13318.html"/>
    <id>https://www.hi-linux.com/posts/13318.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.547Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>你是否经常有在终端下通过一些实用程序进行工作的需求呢，比如：Git 等。但是由于这些终端程序默认并不支持 Socks 5 代理或 HTTP 代理，在访问一些需要科学上网的网络服务时速度或许会非常的慢。</p><p>通常我们的解决方法就是使用环境变量 <code>export ALL_PROXY=socks5://proxyAddress:port</code> 或者 <code>export http_proxy=http://proxyAddress:port</code> 给所有终端程序配置一个全局代理，这样做虽然有效但并不是最佳解决方案。</p><p>今天就给大家介绍一款神器 <code>graftcp</code>，<code>graftcp</code> 可以把任何指定的终端程序的 TCP 连接重定向到 SOCKS5 或 HTTP 代理，并且不会影响其它的终端程序。是不是很好的解决了你的痛点呢？</p><h2 id="简介">简介</h2><p><code>graftcp</code> 可以把任何指定程序（应用程序、脚本、shell 等）的 TCP 连接重定向到 SOCKS5 或 HTTP 代理。</p><p>对比 <a href="https://linux.die.net/man/8/tsocks" target="_blank" rel="noopener">tsocks</a>、<a href="http://proxychains.sourceforge.net/" target="_blank" rel="noopener">proxychains</a> 或 <a href="https://github.com/rofl0r/proxychains-ng" target="_blank" rel="noopener">proxychains-ng</a>，<code>graftcp</code> 并不使用 <a href="https://stackoverflow.com/questions/426230/what-is-the-ld-preload-trick" target="_blank" rel="noopener">LD_PRELOAD 技巧</a>来劫持共享库的 connect()、getaddrinfo()<br>等系列函数达到重定向目的，这种方法只对使用动态链接编译的程序有效，对于静态链接编译出来的程序，例如<a href="https://golang.org/cmd/link/" target="_blank" rel="noopener">默认选项编译的 Go 程序</a>，<a href="https://github.com/rofl0r/proxychains-ng/issues/199" target="_blank" rel="noopener">proxychains-ng 就无效了</a>。<code>graftcp</code> 使用 <a href="https://en.wikipedia.org/wiki/Ptrace" target="_blank" rel="noopener"><code>ptrace(2)</code></a> 系统调用跟踪或修改任意指定程序的 connect 信息，对任何程序都有效。<a href="#principles">工作原理</a>后面将会解释。</p><blockquote><p>项目地址：<a href="https://github.com/hmgle/graftcp" target="_blank" rel="noopener">https://github.com/hmgle/graftcp</a></p></blockquote><a id="more"></a><h2 id="安装">安装</h2><p><code>graftcp</code> 在 Linux 系统内运行。 <code>graftcp-local</code> 使用 Go 编写, <a href="https://golang.org/doc/install" target="_blank" rel="noopener">Go</a> 环境是必需的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/hmgle/graftcp.git</span><br><span class="line">$ <span class="built_in">cd</span> graftcp</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure><p>make 执行完后，即可运行 <code>graftcp-local/graftcp-local</code> 和 <code>./graftcp</code>。你也可以把它们都安装进系统：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure><p>之后 <code>graftcp-local</code> 会随着系统启动而自动运行。</p><!-- more --><h2 id="用法参数">用法参数</h2><p><code>graftcp-local</code>:</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> graftcp-local/graftcp-local -h</span></span><br><span class="line">Usage of graftcp-local/graftcp-local:</span><br><span class="line">  -config string</span><br><span class="line">        Path to the configuration file</span><br><span class="line">  -http_proxy string</span><br><span class="line">        http proxy address, e.g.: 127.0.0.1:8080</span><br><span class="line">  -listen string</span><br><span class="line">        Listen address (default ":2233")</span><br><span class="line">  -logfile string</span><br><span class="line">        Write logs to file</span><br><span class="line">  -loglevel value</span><br><span class="line">        Log level (0-6) (default 1)</span><br><span class="line">  -pipepath string</span><br><span class="line">        Pipe path for graftcp to send address info (default "/tmp/graftcplocal.fifo")</span><br><span class="line">  -select_proxy_mode string</span><br><span class="line">        Set the mode for select a proxy [auto | random | only_http_proxy | only_socks5] (default "auto")</span><br><span class="line">  -service string</span><br><span class="line">        Control the system service: ["start" "stop" "restart" "install" "uninstall"]</span><br><span class="line">  -socks5 string</span><br><span class="line">        SOCKS5 address (default "127.0.0.1:1080")</span><br><span class="line">  -syslog</span><br><span class="line">        Send logs to the local system logger (Eventlog on Windows, syslog on Unix)</span><br></pre></td></tr></table></figure><p><code>graftcp</code>:</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> graftcp -h</span></span><br><span class="line">Usage: graftcp [options] prog [prog-args]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -a --local-addr=&lt;graftcp-local-IP-addr&gt;</span><br><span class="line">                    graftcp-local's IP address. Default: localhost</span><br><span class="line">  -p --local-port=&lt;graftcp-local-port&gt;</span><br><span class="line">                    Which port is graftcp-local listening? Default: 2233</span><br><span class="line">  -f --local-fifo=&lt;fifo-path&gt;</span><br><span class="line">                    Path of fifo to communicate with graftcp-local.</span><br><span class="line">                    Default: /tmp/graftcplocal.fifo</span><br><span class="line">  -b --blackip-file=&lt;black-ip-file-path&gt;</span><br><span class="line">                    The IP in black-ip-file will connect direct</span><br><span class="line">  -w --whiteip-file=&lt;white-ip-file-path&gt;</span><br><span class="line">                    Only redirect the connect that destination ip in the</span><br><span class="line">                    white-ip-file to SOCKS5</span><br><span class="line">  -n --not-ignore-local</span><br><span class="line">                    Connecting to local is not changed by default, this</span><br><span class="line">                    option will redirect it to SOCKS5</span><br><span class="line">  -h --help</span><br><span class="line">                    Display this help and exit</span><br></pre></td></tr></table></figure><h2 id="使用示例">使用示例</h2><p>假设你正在运行默认地址 “localhost:1080” 的 SOCKS5 代理，首先启动 <code>graftcp-local</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ graftcp-local/graftcp-local</span><br></pre></td></tr></table></figure><p>通过 <code>graftcp</code> 安装来自 <a href="http://golang.org" target="_blank" rel="noopener">golang.org</a> 的 Go 包:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./graftcp go get -v golang.org/x/net/proxy</span><br></pre></td></tr></table></figure><p>通过 <code>graftcp</code> 打开 <code>Chromium</code> / <code>Chrome</code> / <code>Firefox</code> 浏览器，网页的所有请求都会重定向到 SOCKS5 代理：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./graftcp chromium-browser</span><br></pre></td></tr></table></figure><p>通过 <code>graftcp</code> 启动 <code>Bash</code> / <code>Zsh</code> / <code>Fish</code>，在这个新开的 shell 里面执行的任何新命令产生的 TCP 连接都会重定向到 SOCKS5 代理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">% ./graftcp bash</span><br><span class="line">$ wget https://www.google.com</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hmgle/graftcp/master/demo.gif" alt="demo"></p><h2 id="工作原理">工作原理</h2><p>要达到重定向一个 app 发起的的 TCP 连接到其他目标地址并且该 app 本身对此毫无感知的目的，大概需要这些条件：</p><ul><li><code>fork(2)</code> 一个新进程，通过 <code>execve(2)</code> 启动该 app，并使用 <code>ptrace(2)</code> 进行跟踪，在 app 执行每一次 TCP 连接前，捕获并拦截这次 <code>connect(2)</code> 系统调用，获取目标地址的参数，并通过管道传给 <code>graftcp-local</code>。</li><li>修改这次 <code>connect(2)</code> 系统调用的目标地址参数为 <code>graftcp-local</code> 的地址，然后恢复执行被中断的系统调用。返回成功后，这个程序以为自己连的是原始的地址，但其实连的是 <code>graftcp-local</code> 的地址。这个就叫“移花接木”。</li><li><code>graftcp-local</code> 根据连接信息和目标地址信息，与 SOCKS5 proxy 建立连接，把 app 的请求的数据重定向到 SOCKS5 proxy。</li></ul><p>这里可能有个疑问：既然可以修改任何系统调用的参数，那么通过修改 app 的 <code>write(2)</code> / <code>send(2)</code> 的参数，直接往 <code>buffer</code> 里面附加原始目标地址信息给 <code>graftcp-local</code> 不是更简单吗？答案是这无法做到。如果直接往运行在子进程的被跟踪程序的 <code>buffer</code> 添加信息，可能会造成缓冲区溢出，造成程序崩溃或者覆盖了其他数据。<br>另外，<a href="http://man7.org/linux/man-pages/man2/execve.2.html" target="_blank" rel="noopener"><code>execve(2)</code> 会分离所有的共享内存</a>，所以也不能通过共享内存的方式让被跟踪的 app 的 <code>write</code> buffer 携带更多的数据，因此这里采用管道方式给 <code>graftcp-local</code> 传递原始的目标地址信息。</p><p>简单的流程如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+---------------+             +---------+         +--------+         +------+</span><br><span class="line">|   graftcp     |  dest host  |         |         |        |         |      |</span><br><span class="line">|   (tracer)    +---PIPE-----&gt;|         |         |        |         |      |</span><br><span class="line">|      ^        |  info       |         |         |        |         |      |</span><br><span class="line">|      | ptrace |             |         |         |        |         |      |</span><br><span class="line">|      v        |             |         |         |        |         |      |</span><br><span class="line">|  +---------+  |             |         |         |        |         |      |</span><br><span class="line">|  |         |  |  connect    |         | connect |        | connect |      |</span><br><span class="line">|  |         +---------------&gt;| graftcp +--------&gt;| SOCKS5 +--------&gt;| dest |</span><br><span class="line">|  |         |  |             | -local  |         |  or    |         | host |</span><br><span class="line">|  |  app    |  |  req        |         |  req    | HTTP   |  req    |      |</span><br><span class="line">|  |(tracee) +---------------&gt;|         +--------&gt;| proxy  +--------&gt;|      |</span><br><span class="line">|  |         |  |             |         |         |        |         |      |</span><br><span class="line">|  |         |  |  resp       |         |  resp   |        |  resp   |      |</span><br><span class="line">|  |         |&lt;---------------+         |&lt;--------+        |&lt;--------+      |</span><br><span class="line">|  +---------+  |             |         |         |        |         |      |</span><br><span class="line">+---------------+             +---------+         +--------+         +------+</span><br></pre></td></tr></table></figure><h2 id="常见问题解答及技巧">常见问题解答及技巧</h2><h3 id="有哪些重定向-tcp-连接的方式">有哪些重定向 TCP 连接的方式？</h3><p>主要有： 全局式、设置环境变量式和仅针对程序（或进程）式。</p><p>全局式：比如使用 <code>iptables</code> + <code>RedSocks</code> 可以把系统符合一定规则的流量转换为 SOCKS5 流量。这种方式的优点是全局有效；缺点是所有满足该规则的流量都被重定向了，影响范围较大。</p><p>设置环境变量方式：一些程序启动时会读取 proxy 相关的环境变量来决定是否将自己的数据转换为对应代理协议的流量，比如 <code>curl</code> 会<a href="https://curl.haxx.se/libcurl/c/CURLOPT_PROXY.html" target="_blank" rel="noopener">读取 <code>http_proxy</code>, <code>ftp_proxy</code>, <code>all_proxy</code> 环境变量并根据请求 scheme 来决定转换为哪种代理流量</a>。这种方法只有程序本身实现了转换的功能才有效，局限性较大。</p><p>仅针对程序方式： 这种方式可以仅针对特定的程序执行重定向，比如 <code>tsocks</code> 或 <code>proxychains</code>。如前面提到，它们之前都是使用 <code>LD_PRELOAD</code> 劫持动态库方式实现，对 <code>Go</code> 之类默认静态链接编译的程序就无效了。<code>graftcp</code> 改进了这一点，能够重定向任何程序的 TCP 连接。</p><h3 id="如果应用程序连接的目标地址是本机使用-graftcp-会把该连接重定向到-socks5-代理吗">如果应用程序连接的目标地址是本机，使用 <code>graftcp</code> 会把该连接重定向到 SOCKS5 代理吗？</h3><p>不会。默认会忽略目标地址为本地的连接，如果想重定向所有地址的话，可以使用 <code>-n</code>选项。如果想忽略更多的地址，可以把它们加入黑名单 IP 文件；如果想仅重定向某些 IP 地址，可以把这些地址加入白名单 IP 文件。使用 <code>graftcp --help</code> 获取设置参数。</p><h3 id="我的-dns-请求受到污染graftcp-会处理-dns-请求吗">我的 DNS 请求受到污染，<code>graftcp</code> 会处理 DNS 请求吗？</h3><p>不会。<code>graftcp</code> 目前仅处理 TCP 连接。建议使用 <code>dnscrypt-proxy</code> 或 <code>ChinaDNS</code> 等方式解决 DNS 污染问题。</p><h3 id="clone2-参数有个叫-clone_untraced-的标志位可以避免让父进程跟踪到自己graftcp-是如何做到强制跟踪的"><code>clone(2)</code> 参数有个叫 <code>CLONE_UNTRACED</code> 的标志位，可以避免让父进程跟踪到自己，<code>graftcp</code> 是如何做到强制跟踪的？</h3><p><code>graftcp</code> 在子进程调用 <code>clone(2)</code> 之前会把它拦截，清除这个 <code>CLONE_UNTRACED</code> 标志位，所以被跟踪的子进程最终还是难逃被跟踪的命运。另外，这个 <code>CLONE_UNTRACED</code> 标志位本意是给内核使用的，普通程序不应该去设置它。</p><p>Linux 提供了一种限制被 <code>ptrace(2)</code> 跟踪的方法：设置 <a href="https://www.kernel.org/doc/Documentation/security/Yama.txt" target="_blank" rel="noopener"><code>/proc/sys/kernel/yama/ptrace_scope</code></a> 的值，若 <code>ptrace(2)</code> 失效，请检查该值是否被修改过。</p><h3 id="支持-macos-吗">支持 macOS 吗？</h3><p>不。macOS 的 <a href="http://polarhome.com/service/man/?qf=ptrace&amp;af=0&amp;sf=0&amp;of=Darwin&amp;tf=2" target="_blank" rel="noopener"><code>ptrace(2)</code></a> 是个半残品。<s>不过理论上参考 DTrace那一套也能实现</s>，见<a href="https://github.com/hmgle/graftcp/issues/12" target="_blank" rel="noopener">issue 12</a>。或许有兴趣的同学可以趟下这趟浑水。</p><h2 id="参考文档">参考文档</h2><ol><li><p><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></p></li><li><p><a href="https://github.com/hmgle/graftcp" target="_blank" rel="noopener">https://github.com/hmgle/graftcp</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;你是否经常有在终端下通过一些实用程序进行工作的需求呢，比如：Git 等。但是由于这些终端程序默认并不支持 Socks 5 代理或 HTTP 代理，在访问一些需要科学上网的网络服务时速度或许会非常的慢。&lt;/p&gt;
&lt;p&gt;通常我们的解决方法就是使用环境变量 &lt;code&gt;export ALL_PROXY=socks5://proxyAddress:port&lt;/code&gt; 或者 &lt;code&gt;export http_proxy=http://proxyAddress:port&lt;/code&gt; 给所有终端程序配置一个全局代理，这样做虽然有效但并不是最佳解决方案。&lt;/p&gt;
&lt;p&gt;今天就给大家介绍一款神器 &lt;code&gt;graftcp&lt;/code&gt;，&lt;code&gt;graftcp&lt;/code&gt; 可以把任何指定的终端程序的 TCP 连接重定向到 SOCKS5 或 HTTP 代理，并且不会影响其它的终端程序。是不是很好的解决了你的痛点呢？&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;graftcp&lt;/code&gt; 可以把任何指定程序（应用程序、脚本、shell 等）的 TCP 连接重定向到 SOCKS5 或 HTTP 代理。&lt;/p&gt;
&lt;p&gt;对比 &lt;a href=&quot;https://linux.die.net/man/8/tsocks&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;tsocks&lt;/a&gt;、&lt;a href=&quot;http://proxychains.sourceforge.net/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;proxychains&lt;/a&gt; 或 &lt;a href=&quot;https://github.com/rofl0r/proxychains-ng&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;proxychains-ng&lt;/a&gt;，&lt;code&gt;graftcp&lt;/code&gt; 并不使用 &lt;a href=&quot;https://stackoverflow.com/questions/426230/what-is-the-ld-preload-trick&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;LD_PRELOAD 技巧&lt;/a&gt;来劫持共享库的 connect()、getaddrinfo()&lt;br&gt;
等系列函数达到重定向目的，这种方法只对使用动态链接编译的程序有效，对于静态链接编译出来的程序，例如&lt;a href=&quot;https://golang.org/cmd/link/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;默认选项编译的 Go 程序&lt;/a&gt;，&lt;a href=&quot;https://github.com/rofl0r/proxychains-ng/issues/199&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;proxychains-ng 就无效了&lt;/a&gt;。&lt;code&gt;graftcp&lt;/code&gt; 使用 &lt;a href=&quot;https://en.wikipedia.org/wiki/Ptrace&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;ptrace(2)&lt;/code&gt;&lt;/a&gt; 系统调用跟踪或修改任意指定程序的 connect 信息，对任何程序都有效。&lt;a href=&quot;#principles&quot;&gt;工作原理&lt;/a&gt;后面将会解释。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/hmgle/graftcp&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/hmgle/graftcp&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Graftcp" scheme="https://www.hi-linux.com/tags/Graftcp/"/>
    
  </entry>
  
  <entry>
    <title>使用 Telepresence 在本地调试 Kubernetes 微服务</title>
    <link href="https://www.hi-linux.com/posts/35104.html"/>
    <id>https://www.hi-linux.com/posts/35104.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T07:48:06.548Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>微服务作为一种全新的软件架构现在正变得越来越火。基本原因我觉得有两点：一方面软件系统越做越复杂，通过拆分将一个大系统解耦成一个个独立的子系统，我们就降低了整个系统的复杂性。另一方面，Kubernetes 的出现使得编排这么多子系统变得简单，可以说 Kubernetes 是目前为止微服务最好的载体。</p><p>Kubernetes 解决了微服务运行时的环境问题，但对开发环境就不那么友好了。比方说如果我们要在本地开发调试一个服务 A，但服务 A 可能依赖服务B、C，而服务 B 又有一层依赖 D，我们就需要在本地把服务 B、C、D 都搭建起来才能调试服务 A。这显然是一个很痛苦的过程。</p><p><img src="https://i.loli.net/2019/11/06/OXPumiy1AWHr3v9.png" alt=""></p><p>业界有朋友用 <code>docker-compose</code> 来模拟集群中的场景。这个方案的不足之处在于它需要把 <code>Kubernetes</code> 的那一套逻辑用 <code>docker-compose.yml</code> 文件重写一遍，这给我们带来了维护成本。另一方面，有的时候依赖树太大，本地机器完全无法同时运行这么多服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">ratesvc:</span><br><span class="line">  image: kubeapps&#x2F;ratesvc:latest</span><br><span class="line">  environment:</span><br><span class="line">    - JWT_KEY&#x3D;secret  # &lt;------------------------ 手工维护</span><br><span class="line">  command:</span><br><span class="line">    - &#x2F;ratesvc</span><br><span class="line">    - --mongo-url&#x3D;mongodb:&#x2F;&#x2F;root@mongodb  # &lt;---- 手工维护</span><br><span class="line">    - --mongo-database&#x3D;ratesvc</span><br><span class="line"></span><br><span class="line">mongodb:</span><br><span class="line">  image: bitnami&#x2F;mongodb:3</span><br><span class="line">  environment:</span><br><span class="line">    - MONGODB_ROOT_PASSWORD&#x3D;password123</span><br><span class="line"></span><br><span class="line">auth:</span><br><span class="line">  image: kubeapps&#x2F;oauth2-bitnami:latest</span><br><span class="line">  volumes:</span><br><span class="line">    - .&#x2F;config.yaml:&#x2F;config&#x2F;monocular.yaml  # &lt;-- 手工维护</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">volumnes:  # &lt;----------------------------------- 手工维护</span><br><span class="line">  monocular-data:</span><br></pre></td></tr></table></figure><p>另一种解决方案就是我这里要介绍的 <code>Telepresence</code> 了，它能够在不修改程序代码的情况下，让本地应用程序无感的接入到 <code>Kubernetes</code> 集群中，这样你就可以直接在本地开发调试微服务了。</p><h2 id="telepresence-简介">Telepresence 简介</h2><p><code>Telepresence</code> 是一个 <code>CNCF</code> 基金会下的项目。它的工作原理是在本地和 <code>Kubernetes</code> 集群中搭建一个透明的双向代理，这使得我们可以在本地用熟悉的 <code>IDE</code> 和调试工具来运行一个微服务，同时该服务还可以无缝的与 <code>Kubernetes</code> 集群中的其他服务进行交互，好像它就运行在这个集群中一样。</p><p>这是一个 <code>Telepresence</code> 工作原理图，它将集群中的数据卷、环境变量、网络都代理到了本地（除了数据卷外，其他两个对应用程序来说都是透明的）：</p><p><img src="https://i.loli.net/2019/11/06/79IMTeOFfJ8p5wb.png" alt=""></p><p>有了这些代理之后：</p><ol><li><p>本地的服务就可以完整的访问到远程集群中的其他服务。</p></li><li><p>本地的服务直接访问到 Kubernetes 里的各种资源，包括环境变量、Secrets、Config map 等。</p></li><li><p>甚至集群中的服务还能直接访问到本地暴露出来的接口。</p></li></ol><h2 id="telepresence-安装">Telepresence 安装</h2><p>这里只说一下如何在 <code>macOS</code> 下进行安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ brew cask install osxfuse  <span class="comment"># required by sshfs to mount the pod's filesystem</span></span><br><span class="line">$ brew install datawire/blackbird/telepresence</span><br></pre></td></tr></table></figure><blockquote><p>其他平台请参考：<a href="https://www.telepresence.io/reference/install" target="_blank" rel="noopener">https://www.telepresence.io/reference/install</a></p></blockquote><p>如果官方的安装包没有覆盖到你的平台，其实也可以从源代码安装，因为它本身就是用 <code>Python 3</code> 写的，熟悉 <code>Python</code> 的朋友安装这个程序应该不难，我自己就在 <code>CentOS 7</code> 上安装成功了。</p><a id="more"></a><h2 id="telepresence-使用场景">Telepresence 使用场景</h2><p>假设我们有两个服务 A 和 B，服务 A 是依赖于服务 B 的。下面分两个场景来看看如何用 Telepresence 来调试 A 和 B。</p><p><img src="https://i.loli.net/2019/11/06/Pgp2NtCk8IGvoX3.png" alt=""></p><h3 id="调试服务-a">调试服务 A</h3><p>服务 A 在本地运行，服务 B 运行在远端集群中。借助 <code>Telepresence</code> 搭建的代理，A 就能直接访问到 B。比方说我们的服务 B 是这样一个程序，它监听在 8000 端口上。每当有人访问时它就返回 <code>Hello, world!</code> 。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run service-b --image=datawire/hello-world --port=8000 --expose</span><br><span class="line">$ kubectl get service service-b</span><br><span class="line">NAME        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">service-b   10.0.0.12    &lt;none&gt;        8000/TCP   1m</span><br></pre></td></tr></table></figure><p>现在在本地用默认参数启动 <code>Telepresence</code> ，等它连接好集群：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ telepresence</span><br><span class="line">T: Starting proxy with method <span class="string">'vpn-tcp'</span>, <span class="built_in">which</span> has the following limitations: All processes are affected, only one telepresence can run per machine, and you</span><br><span class="line">T: can<span class="string">'t use other VPNs. You may need to add cloud hosts and headless services with --also-proxy. For a full list of method limitations see</span></span><br><span class="line"><span class="string">T: https://telepresence.io/reference/methods.html</span></span><br><span class="line"><span class="string">T: Volumes are rooted at $TELEPRESENCE_ROOT. See https://telepresence.io/howto/volumes.html for details.</span></span><br><span class="line"><span class="string">T: Starting network proxy to cluster using new Deployment telepresence-1566230249-7112632-14485</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">T: No traffic is being forwarded from the remote Deployment to your local machine. You can use the --expose option to specify which ports you want to</span></span><br><span class="line"><span class="string">T: forward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">T: Setup complete. Launching your command.</span></span><br><span class="line"><span class="string">@test_cluster|bash-4.2#</span></span><br></pre></td></tr></table></figure><p>这时候就可以开始调试服务 A 了，因为服务 B 暴露出来的接口本地已经可以直接访问到：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://service-b:8000/</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure><p>这里要说明一下这背后发生的事情：</p><ol><li><p>当运行 <code>Telepresence</code> 命令的时候，它创建了一个 <code>Deployment</code>，这个 <code>Deployment</code> 又创建了一个用来做代理的 <code>Pod</code> ，我们可以这样查看到它 <code>kubectl get pod -l telepresence</code>。</p></li><li><p>同时它还在本地创建了一个全局的 <code>VPN</code>，使得本地的所有程序都可以访问到集群中的服务。 <code>Telepresence</code> 其实还支持其他的网络代理模式（使用 <code>--method</code> 切换），<code>vpn-tcp</code> 是默认的方式，其他的好像用处不大，<code>inject-tcp</code> 甚至要在后续的版本中取消掉。</p></li><li><p>当本地的 <code>curl</code> 访问 <code>http://service-b:8000/</code> 时，对应的 <code>DNS</code> 查询和 <code>HTTP</code> 请求都被 <code>VPN</code> 路由到集群中刚刚创建的 <code>Pod</code> 去处理。</p></li></ol><p>除此之外 <code>Telepresence</code> 还将远端的文件系统通过 <code>sshfs</code> 挂载到本地 <code>$TELEPRESENCE_ROOT</code> 下面（你也可以用参数 <code>--mount &lt;MOUNT_PATH&gt;</code> 指定挂载的路径）。这样，我们的应用程序就可以在本地访问到远程的文件系统：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls <span class="variable">$TELEPRESENCE_ROOT</span>/var/run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">ca.crt  namespace  token</span><br></pre></td></tr></table></figure><p>如果我们退出 <code>Telepresence</code> 对应的 Shell，它也会做一些清理工作，比如取消本地 <code>VPN</code>、删除刚刚创建的 <code>Deployment</code> 等。</p><h3 id="调试服务-b">调试服务 B</h3><p>服务 B 与刚才的不同之处在于，它是被别人访问的，要调试它，首先得要有真实的访问流量。我们如何才能做到将别人对它的访问路由到本地来，从而实现在本地捕捉到集群中的流量呢？</p><p>Telepresence 提供这样一个参数，<code>--swap-deployment &lt;DEPLOYMENT_NAME[:CONTAINER]&gt;</code>，用来将集群中的一个 <code>Deployment</code> 替换为本地的服务。对于上面的 <code>service-b</code>，我们可以这样替换：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ telepresence --swap-deployment service-b --expose 8000:8000</span><br></pre></td></tr></table></figure><p>这个时候集群中的服务 A 再想访问服务 B 的 8000 端口时，<code>Telepresence</code> 就会将这个请求转发到本地的 8000 端口。它的工作原理就是将集群中的 <code>service-b</code> 替换为 <code>Telepresence</code> 创建的 Proxy ，然后这个 Proxy 再将请求转发到本地客户端。</p><p>即，将原始的网络：</p><p><img src="https://i.loli.net/2019/11/06/x6NvdWSFQK4HXCJ.png" alt=""></p><p>替换为这个结构：</p><p><img src="https://i.loli.net/2019/11/06/ATgkiv1X3jGy8Wn.png" alt=""></p><p>这样我们就有机会在本地查看具体的请求数据，调试逻辑，以及生成新的回复。</p><h2 id="总结">总结</h2><p>这篇文章里我先提出了微服务开发中一个常见的问题，然后介绍了 <code>Telepresence</code> 项目，并且举例说明了怎样用它来调试两种常见的微服务场景。当然，Telepresence 还在不断的演进，本文中使用的是 v0.101 版本，后续版本很可能有些不一样的地方，也欢迎大家不断指正。</p><blockquote><p>来源：喵叔没话说</p><p>原文：<a href="https://url.cn/5SnZHs3" target="_blank" rel="noopener">https://url.cn/5SnZHs3</a></p><p>题图：来自谷歌图片搜索</p><p>版权：本文版权归原作者所有</p><p>投稿：欢迎投稿，邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a></p></blockquote></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;微服务作为一种全新的软件架构现在正变得越来越火。基本原因我觉得有两点：一方面软件系统越做越复杂，通过拆分将一个大系统解耦成一个个独立的子系统，我们就降低了整个系统的复杂性。另一方面，Kubernetes 的出现使得编排这么多子系统变得简单，可以说 Kubernetes 是目前为止微服务最好的载体。&lt;/p&gt;
&lt;p&gt;Kubernetes 解决了微服务运行时的环境问题，但对开发环境就不那么友好了。比方说如果我们要在本地开发调试一个服务 A，但服务 A 可能依赖服务B、C，而服务 B 又有一层依赖 D，我们就需要在本地把服务 B、C、D 都搭建起来才能调试服务 A。这显然是一个很痛苦的过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/06/OXPumiy1AWHr3v9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;业界有朋友用 &lt;code&gt;docker-compose&lt;/code&gt; 来模拟集群中的场景。这个方案的不足之处在于它需要把 &lt;code&gt;Kubernetes&lt;/code&gt; 的那一套逻辑用 &lt;code&gt;docker-compose.yml&lt;/code&gt; 文件重写一遍，这给我们带来了维护成本。另一方面，有的时候依赖树太大，本地机器完全无法同时运行这么多服务。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ratesvc:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  image: kubeapps&amp;#x2F;ratesvc:latest&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  environment:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - JWT_KEY&amp;#x3D;secret  # &amp;lt;------------------------ 手工维护&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  command:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - &amp;#x2F;ratesvc&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - --mongo-url&amp;#x3D;mongodb:&amp;#x2F;&amp;#x2F;root@mongodb  # &amp;lt;---- 手工维护&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - --mongo-database&amp;#x3D;ratesvc&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mongodb:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  image: bitnami&amp;#x2F;mongodb:3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  environment:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - MONGODB_ROOT_PASSWORD&amp;#x3D;password123&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;auth:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  image: kubeapps&amp;#x2F;oauth2-bitnami:latest&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  volumes:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - .&amp;#x2F;config.yaml:&amp;#x2F;config&amp;#x2F;monocular.yaml  # &amp;lt;-- 手工维护&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  ...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;volumnes:  # &amp;lt;----------------------------------- 手工维护&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  monocular-data:&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;另一种解决方案就是我这里要介绍的 &lt;code&gt;Telepresence&lt;/code&gt; 了，它能够在不修改程序代码的情况下，让本地应用程序无感的接入到 &lt;code&gt;Kubernetes&lt;/code&gt; 集群中，这样你就可以直接在本地开发调试微服务了。&lt;/p&gt;
&lt;h2 id=&quot;Telepresence-简介&quot;&gt;Telepresence 简介&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Telepresence&lt;/code&gt; 是一个 &lt;code&gt;CNCF&lt;/code&gt; 基金会下的项目。它的工作原理是在本地和 &lt;code&gt;Kubernetes&lt;/code&gt; 集群中搭建一个透明的双向代理，这使得我们可以在本地用熟悉的 &lt;code&gt;IDE&lt;/code&gt; 和调试工具来运行一个微服务，同时该服务还可以无缝的与 &lt;code&gt;Kubernetes&lt;/code&gt; 集群中的其他服务进行交互，好像它就运行在这个集群中一样。&lt;/p&gt;
&lt;p&gt;这是一个 &lt;code&gt;Telepresence&lt;/code&gt; 工作原理图，它将集群中的数据卷、环境变量、网络都代理到了本地（除了数据卷外，其他两个对应用程序来说都是透明的）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/06/79IMTeOFfJ8p5wb.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;有了这些代理之后：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;本地的服务就可以完整的访问到远程集群中的其他服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;本地的服务直接访问到 Kubernetes 里的各种资源，包括环境变量、Secrets、Config map 等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;甚至集群中的服务还能直接访问到本地暴露出来的接口。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Telepresence-安装&quot;&gt;Telepresence 安装&lt;/h2&gt;
&lt;p&gt;这里只说一下如何在 &lt;code&gt;macOS&lt;/code&gt; 下进行安装。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ brew cask install osxfuse  &lt;span class=&quot;comment&quot;&gt;# required by sshfs to mount the pod&#39;s filesystem&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ brew install datawire/blackbird/telepresence&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;其他平台请参考：&lt;a href=&quot;https://www.telepresence.io/reference/install&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.telepresence.io/reference/install&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果官方的安装包没有覆盖到你的平台，其实也可以从源代码安装，因为它本身就是用 &lt;code&gt;Python 3&lt;/code&gt; 写的，熟悉 &lt;code&gt;Python&lt;/code&gt; 的朋友安装这个程序应该不难，我自己就在 &lt;code&gt;CentOS 7&lt;/code&gt; 上安装成功了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Telepresence" scheme="https://www.hi-linux.com/tags/Telepresence/"/>
    
  </entry>
  
  <entry>
    <title>一文读懂 Kubernetes 应用部署工具 Kustomize 和 Helm 的优劣势</title>
    <link href="https://www.hi-linux.com/posts/46223.html"/>
    <id>https://www.hi-linux.com/posts/46223.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T08:23:22.749Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>本文将记录为什么最终没有采用 <code>Helm</code> 而是选择了 <code>Kustomize</code> 作为 <code>Kubernetes</code> 应用的部署工具。</p><h2 id="使用各种项目管理之前的情况">使用各种项目管理之前的情况</h2><p>首先说说之前的痛点。我们虽然不是个大公司，可是这代码也是越敲越多，服务也是越做越全。零零总总也有十几个项目要管理了。然后我们同样有多套部署环境：内网环境，预生产环境，生产环境。那么针对每一个环境几乎都要有一套 <code>Kubernetes</code> 的 YAML 文件，但是各个仅仅是稍有不同。</p><p>然后我们自己的 <code>CI</code> 是将构建好的 <code>Docker</code> 镜像放到 <code>Registry</code> 里面。</p><p>那么，每次更新的镜像之后就是通过人手工去部署一下，绝大多数情况就是修改一下镜像的 <code>Tag</code>，但是由于每个环境的 YAML 略有区别，那么如果我需要在不同环境切换的时候就需要来回修改这些 YAML 文件，一不小心写错了就只能怪自己手残。然而这种部署方式虽然在 <code>Kubernetes</code> 之下就是改改 YAML 就好了，但是依然感觉很是原始。</p><h2 id="希望有什么改善">希望有什么改善</h2><p>仔细想想，自己的需求就是这么几个：</p><ol><li>有一个统一的模板可以管理一个项目的 <code>Kubernetes</code> 部署结构</li><li>有某种方式可以管理不同环境之间微小的差异</li><li>每次更新基本就是修改镜像的标签然后部署，那么有没有什么简单的办法实现之，而不是让我每次都去修改 YAML 文件</li></ol><h2 id="针对-helm-的调研">针对 Helm 的调研</h2><p>既然都说 <code>Helm</code> 是 <code>Kubernetes</code> 的包管理工具，那么我就先去尝试了一下 <code>Helm</code>。</p><p><img src="https://i.loli.net/2019/08/14/4bFXOTAy3ILzWQ1.jpg" alt=""></p><blockquote><p>Helm 是 Deis 开发的一个用于 Kubernetes 应用的包管理工具，主要用来管理 Charts。有点类似于 Ubuntu 中的 APT 或 CentOS 中的 YUM。</p><p>Helm Chart 是用来封装 Kubernetes 原生应用程序的一系列 YAML 文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。</p><p>对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。</p><p>对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。</p></blockquote><p>更多 <code>Helm</code> 的介绍可参考 「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247486154&amp;idx=1&amp;sn=becd5dd0fadfe0b6072f5dfdc6fdf786&amp;chksm=eac52be3ddb2a2f555b8b1028db97aa3e92d0a4880b56f361e4b11cd252771147c44c08c8913&amp;token=2022032653&amp;lang=zh_CN#rd" target="_blank" rel="noopener">Helm 入门指南</a>」 一文。</p><p>简单的看了看，<code>Helm</code> 给我一种大而无当的感觉：它真的是一个做包管理工具的，复杂的 <code>Go Template</code> 体系以及需要单独存放的 <code>Charts</code> 让我感觉其更适合对标 <code>Ubuntu</code> 的 <code>APT</code> 或者 <code>macOS</code> 的 <code>Brew</code>。它更像是对外提供一个复杂的可以依据各种配置信息生成适合于不同环境的软件发布包，而不是用于我们这种轻量级的部署配置管理的。所以我就放弃使用 <code>Helm</code> 了。</p><a id="more"></a><h2 id="针对-kustomize-的调研">针对 Kustomize 的调研</h2><p>在这个时候我想起来了在之前 <code>Github Trending</code> 看到的另外一个用户做 <code>Kubernetes</code> 配置的工具 <code>Kustomize</code>。简单的说，它就是一个简化 <code>Kubernetes</code> YAML 编写的工具。它提供了两个重要的功能恰好满足了我的需求。</p><blockquote><p>Kustomize 是一个新晋选手，只有一个 CLI 工具。在 Kubernetes 1.14 之后，甚至这唯一的工具也成为 kubectl 的一部分。</p><p>Kustomize 放弃了对模板的要求，改用 Base + Overlay 的方式对应用的原始 YAML 进行派生。Overlay，顾名思义，就是覆盖。Kustomize 的 Overlay 可以在 Base 的基础上，通过对 resource、generator、transformer 等的定义，形成新的应用定义，不论 Base 还是 Overlay，都可以通过 kustomize build 生成有效的 YAML。</p></blockquote><h3 id="kustomize-的特色">Kustomize 的特色</h3><ol><li>功能简单清晰，kubectl 直接支持。</li><li>不考虑派生，仅作为应用的 YAML 组织方式也很有帮助。</li><li>自身支持插件。</li></ol><h3 id="继承和-patch">继承和 Patch</h3><p><code>Kustomize</code> 可以设置如下的层次：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">├── base</span><br><span class="line">│   ├── deployment.yaml</span><br><span class="line">│   ├── kustomization.yaml</span><br><span class="line">│   └── service.yaml</span><br><span class="line">└── overlays</span><br><span class="line">    └── stg</span><br><span class="line">        ├── ingress.yaml</span><br><span class="line">        └── kustomization.yaml</span><br></pre></td></tr></table></figure><p>其中 base 里保存各个环境所有的公有配置 <code>base/kustomization.yaml</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">resources:</span><br><span class="line">- deployment.yaml</span><br><span class="line">- service.yaml</span><br></pre></td></tr></table></figure><p>然后在 overlays 中可以定义子环境 <code>overlays/stg/kustomization.yaml</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bases:</span><br><span class="line">- ..&#x2F;..&#x2F;base</span><br><span class="line"></span><br><span class="line">resources:</span><br><span class="line">- ingress.yaml</span><br></pre></td></tr></table></figure><p>可以看到 stg 下继承了 base 的配置，并且添加了 ingress.yaml 配置。同时，<code>Kustomize</code> 不仅仅支持文件级别的 patch，还支持对一个文件某些字段的 patch。</p><p>如下图所示，replica_count.yaml 只包含了有关 replicas 的部分即可，在执行 <code>kustomize build</code> 之后就可以将这部分覆盖默认的配置。</p><p><img src="https://i.loli.net/2019/08/14/cFlArJSXfEj67Kp.jpg" alt=""></p><h3 id="edit-命令">edit 命令</h3><p><code>Kustomize</code> 提供了一个命令行方法对镜像 Tag 进行修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kustomize edit set imagetag xxx:94c269ec</span><br></pre></td></tr></table></figure><p>如果想更方便的使用，你还可以这么做：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export NEWTAG&#x3D;94c269ec</span><br><span class="line">$ kustomize edit set imagetag xxx:$NEWTAG</span><br></pre></td></tr></table></figure><p>那么每次都去 <code>ctrl-r</code> 修改这个 <code>export</code> 然后再 <code>ctrl-r</code> 找到第二条命令执行一下就好了。虽然它还是修改了 kustomization.yaml 但是我觉得比打开编辑器改要舒服一些。</p><h2 id="kustomize-额外加分项">Kustomize 额外加分项</h2><h3 id="轻量级">轻量级</h3><p>相对 <code>Helm</code>，<code>Kustomize</code> 依然保留了对 <code>kubectl apply -f</code> 命令的支持，仅仅作为一个命令行工具；不像 <code>Helm</code> 还需要在 <code>K8s</code> 里面部署一个 <code>Tiller</code> 可谓是非常的轻量级了。</p><h3 id="对-secret-和-configmap-的支持">对 Secret 和 Configmap 的支持</h3><p>分别举例说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">bases:</span><br><span class="line">- ..&#x2F;..&#x2F;base</span><br><span class="line"></span><br><span class="line">configMapGenerator:</span><br><span class="line">- literals:</span><br><span class="line">  - STORAGE.DATASETUPLOADURL&#x3D;https:&#x2F;&#x2F;xxx&#x2F;files&#x2F;datasets</span><br><span class="line">  - STORAGE.CODEUPLOADURL&#x3D;https:&#x2F;&#x2F;xxx&#x2F;files&#x2F;codes</span><br><span class="line">  - LIVELOG_PREFIX&#x3D;https:&#x2F;&#x2F;xxx&#x2F;jobs</span><br><span class="line">  name: storage-server</span><br><span class="line"></span><br><span class="line">resources:</span><br><span class="line">- ingress.yaml</span><br><span class="line"></span><br><span class="line">imageTags:</span><br><span class="line">- name: xxx</span><br><span class="line">  newTag: dc12c4d7</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">resources:</span><br><span class="line">- deployment.yaml</span><br><span class="line"></span><br><span class="line">secretGenerator:</span><br><span class="line">- name: notification-service</span><br><span class="line">  commands:</span><br><span class="line">    SHORT_MESSAGE_API_KEY: &quot;bash -c &#39;echo -n $SHORT_MESSAGE_API_KEY&#39;&quot;</span><br><span class="line">    MG_API_KEY: &quot;bash -c &#39;echo -n $MG_API_KEY&#39;&quot;</span><br><span class="line">  type: Opaque</span><br><span class="line"></span><br><span class="line">generatorOptions:</span><br><span class="line">  disableNameSuffixHash: true</span><br></pre></td></tr></table></figure><p><code>secretGenerator</code> 和 <code>configMapGenerator</code> 可以以更灵活的方式生成 <code>configmap</code> 和 <code>secret</code>，相对来说更方便吧。</p><p>然后注意看我 <code>configMapGenerator</code> 的例子，<code>echo -n $xxx</code> 是会有问题的，一定要使用 <code>&quot;bash -c 'echo -n $SHORT_MESSAGE_API_KEY'&quot;</code> 的命令。</p><h2 id="kustomize-和-helm-的区别">Kustomize 和 Helm 的区别</h2><p>我认为他们的区别主要在工作流程上：</p><ol><li><p>Helm 的基础流程比较瀑布：定义 Chart-&gt;填充-&gt;运行，在 Chart 中没有定义的内容是无法更改的；</p></li><li><p>Kustomize 的用法比较迭代：Base 和 Overlay 都是可以独立运作的，增加新对象，或者对编写 Base 时未预料的内容进行变更，都不在话下。</p></li></ol><p>例如：我们定义了一个很基础的应用，由 Deployment + Service 组成，如果后续部署中需要完成两个变更：新建 Ingress 对象和修改镜像地址/名称/TAG。</p><ol><li>使用 Helm 你需要的步骤：</li></ol><ul><li>在 Chart 中加入对 Ingress 的定义</li><li>用变量控制 Ingress 是否进行渲染</li><li>Ingress 模板应该包含特定的主机名、注解等变量</li><li>把镜像也定义成变量</li><li>在 Values.yaml 中对这些变量进行赋值。</li></ul><ol start="2"><li>使用 Kustomize 你需要的步骤：</li></ol><ul><li>无需对 Base 进行修改</li><li>直接在新的 Overlay 中写入 Ingress Resource</li><li>使用内置的 image transformer 替换原有镜像</li></ul><h2 id="结论">结论</h2><p>要公开发布一个较为复杂的应用，编写良好的 Chart 能给用户很大帮助，用户通过对 values.yaml 的阅读，就能对这种复杂的部署产生一个较为深入的认识。</p><p>如果是常见的业务应用，因为不同部署之间的差异不大，用 Kustomize 可能会是一个更好的选择。</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://aisensiy.github.io/2018/11/27/helm-and-kustomize/" target="_blank" rel="noopener">https://aisensiy.github.io/2018/11/27/helm-and-kustomize/</a></li><li><a href="https://blog.fleeto.us/post/helm-vs-kustomize/" target="_blank" rel="noopener">https://blog.fleeto.us/post/helm-vs-kustomize/</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录为什么最终没有采用 &lt;code&gt;Helm&lt;/code&gt; 而是选择了 &lt;code&gt;Kustomize&lt;/code&gt; 作为 &lt;code&gt;Kubernetes&lt;/code&gt; 应用的部署工具。&lt;/p&gt;
&lt;h2 id=&quot;使用各种项目管理之前的情况&quot;&gt;使用各种项目管理之前的情况&lt;/h2&gt;
&lt;p&gt;首先说说之前的痛点。我们虽然不是个大公司，可是这代码也是越敲越多，服务也是越做越全。零零总总也有十几个项目要管理了。然后我们同样有多套部署环境：内网环境，预生产环境，生产环境。那么针对每一个环境几乎都要有一套 &lt;code&gt;Kubernetes&lt;/code&gt; 的 YAML 文件，但是各个仅仅是稍有不同。&lt;/p&gt;
&lt;p&gt;然后我们自己的 &lt;code&gt;CI&lt;/code&gt; 是将构建好的 &lt;code&gt;Docker&lt;/code&gt; 镜像放到 &lt;code&gt;Registry&lt;/code&gt; 里面。&lt;/p&gt;
&lt;p&gt;那么，每次更新的镜像之后就是通过人手工去部署一下，绝大多数情况就是修改一下镜像的 &lt;code&gt;Tag&lt;/code&gt;，但是由于每个环境的 YAML 略有区别，那么如果我需要在不同环境切换的时候就需要来回修改这些 YAML 文件，一不小心写错了就只能怪自己手残。然而这种部署方式虽然在 &lt;code&gt;Kubernetes&lt;/code&gt; 之下就是改改 YAML 就好了，但是依然感觉很是原始。&lt;/p&gt;
&lt;h2 id=&quot;希望有什么改善&quot;&gt;希望有什么改善&lt;/h2&gt;
&lt;p&gt;仔细想想，自己的需求就是这么几个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有一个统一的模板可以管理一个项目的 &lt;code&gt;Kubernetes&lt;/code&gt; 部署结构&lt;/li&gt;
&lt;li&gt;有某种方式可以管理不同环境之间微小的差异&lt;/li&gt;
&lt;li&gt;每次更新基本就是修改镜像的标签然后部署，那么有没有什么简单的办法实现之，而不是让我每次都去修改 YAML 文件&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;针对-Helm-的调研&quot;&gt;针对 Helm 的调研&lt;/h2&gt;
&lt;p&gt;既然都说 &lt;code&gt;Helm&lt;/code&gt; 是 &lt;code&gt;Kubernetes&lt;/code&gt; 的包管理工具，那么我就先去尝试了一下 &lt;code&gt;Helm&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/08/14/4bFXOTAy3ILzWQ1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Helm 是 Deis 开发的一个用于 Kubernetes 应用的包管理工具，主要用来管理 Charts。有点类似于 Ubuntu 中的 APT 或 CentOS 中的 YUM。&lt;/p&gt;
&lt;p&gt;Helm Chart 是用来封装 Kubernetes 原生应用程序的一系列 YAML 文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。&lt;/p&gt;
&lt;p&gt;对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。&lt;/p&gt;
&lt;p&gt;对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;更多 &lt;code&gt;Helm&lt;/code&gt; 的介绍可参考 「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247486154&amp;amp;idx=1&amp;amp;sn=becd5dd0fadfe0b6072f5dfdc6fdf786&amp;amp;chksm=eac52be3ddb2a2f555b8b1028db97aa3e92d0a4880b56f361e4b11cd252771147c44c08c8913&amp;amp;token=2022032653&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Helm 入门指南&lt;/a&gt;」 一文。&lt;/p&gt;
&lt;p&gt;简单的看了看，&lt;code&gt;Helm&lt;/code&gt; 给我一种大而无当的感觉：它真的是一个做包管理工具的，复杂的 &lt;code&gt;Go Template&lt;/code&gt; 体系以及需要单独存放的 &lt;code&gt;Charts&lt;/code&gt; 让我感觉其更适合对标 &lt;code&gt;Ubuntu&lt;/code&gt; 的 &lt;code&gt;APT&lt;/code&gt; 或者 &lt;code&gt;macOS&lt;/code&gt; 的 &lt;code&gt;Brew&lt;/code&gt;。它更像是对外提供一个复杂的可以依据各种配置信息生成适合于不同环境的软件发布包，而不是用于我们这种轻量级的部署配置管理的。所以我就放弃使用 &lt;code&gt;Helm&lt;/code&gt; 了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Helm" scheme="https://www.hi-linux.com/tags/Helm/"/>
    
      <category term="Kustomize" scheme="https://www.hi-linux.com/tags/Kustomize/"/>
    
  </entry>
  
  <entry>
    <title>使用 Velero 快速备份和迁移 Kubernetes 集群应用以及持久化数据</title>
    <link href="https://www.hi-linux.com/posts/60858.html"/>
    <id>https://www.hi-linux.com/posts/60858.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T08:44:56.284Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="什么是-velero">什么是 Velero？</h2><p><img src="https://raw.githubusercontent.com/heptio/velero/master/site/docs/master/img/velero.png" alt=""></p><p><code>Heptio Velero</code> ( 以前的名字为 ARK) 是一款用于 <code>Kubernetes</code> 集群资源和持久存储卷（PV）的备份、迁移以及灾难恢复等的开源工具。</p><p><strong>Velero 特性</strong></p><p><code>Velero</code> 目前包含以下特性：</p><ul><li><p>支持 <code>Kubernetes</code> 集群数据备份和恢复</p></li><li><p>支持复制当前 <code>Kubernetes</code> 集群的资源到其它 <code>Kubernetes</code> 集群</p></li><li><p>支持复制生产环境到开发以及测试环境</p></li></ul><p><strong>Velero 组件</strong></p><p><code>Velero</code> 组件一共分两部分，分别是服务端和客户端。服务端运行在你 <code>Kubernetes</code> 的集群中，客户端是一些运行在本地的命令行的工具。</p><p><strong>Velero 支持的备份存储</strong></p><ul><li><p>AWS S3 以及兼容 S3 的存储，比如：Minio</p></li><li><p>Azure BloB 存储</p></li><li><p>Google Cloud 存储</p></li></ul><blockquote><p>项目地址：<a href="https://github.com/heptio/velero" target="_blank" rel="noopener">https://github.com/heptio/velero</a></p></blockquote><a id="more"></a><p><strong>与 Etcd 备份的区别</strong></p><p>与 Etcd 备份相比，直接备份 <code>Etcd</code> 是将集群的全部资源备份起来。而 <code>Velero</code> 就是可以对 <code>Kubernetes</code> 集群内对象级别进行备份。除了对 <code>Kubernetes</code> 集群进行整体备份外，<code>Velero</code> 还可以通过对 <code>Type</code>、<code>Namespace</code>、<code>Label</code> 等对象进行分类备份或者恢复。</p><blockquote><p>注意: 备份过程中创建的对象是不会被备份的。</p></blockquote><h2 id="velero-架构">Velero 架构</h2><h3 id="velero-备份过程">Velero 备份过程</h3><p><img src="https://qiniu.li-rui.top/velero.png" alt=""></p><ol><li><p>本地 <code>Velero</code> 客户端发送备份指令。</p></li><li><p><code>Kubernetes</code> 集群内就会创建一个 <code>Backup</code> 对象。</p></li><li><p><code>BackupController</code> 监测 <code>Backup</code> 对象并开始备份过程。</p></li><li><p><code>BackupController</code> 会向 <code>API Server</code> 查询相关数据。</p></li><li><p><code>BackupController</code> 将查询到的数据备份到远端的对象存储。</p></li></ol><p><code>Velero</code> 在 <code>Kubernetes</code> 集群中创建了很多 <code>CRD</code> 以及相关的控制器，进行备份恢复等操作实质上是对相关 <code>CRD</code> 的操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Velero 在 Kubernetes 集群中创建的 CRD</span><br><span class="line">$ kubectl -n velero get crds -l component&#x3D;velero</span><br><span class="line">NAME                                CREATED AT</span><br><span class="line">backups.velero.io                   2019-08-28T03:19:56Z</span><br><span class="line">backupstoragelocations.velero.io    2019-08-28T03:19:56Z</span><br><span class="line">deletebackuprequests.velero.io      2019-08-28T03:19:56Z</span><br><span class="line">downloadrequests.velero.io          2019-08-28T03:19:56Z</span><br><span class="line">podvolumebackups.velero.io          2019-08-28T03:19:56Z</span><br><span class="line">podvolumerestores.velero.io         2019-08-28T03:19:56Z</span><br><span class="line">resticrepositories.velero.io        2019-08-28T03:19:56Z</span><br><span class="line">restores.velero.io                  2019-08-28T03:19:56Z</span><br><span class="line">schedules.velero.io                 2019-08-28T03:19:56Z</span><br><span class="line">serverstatusrequests.velero.io      2019-08-28T03:19:56Z</span><br><span class="line">volumesnapshotlocations.velero.io   2019-08-28T03:19:56Z</span><br></pre></td></tr></table></figure><p><strong>如何保证数据一致性</strong></p><p>对象存储的数据是唯一的数据源，也就是说 <code>Kubernetes</code> 集群内的控制器会检查远程的 <code>OSS</code> 存储，发现有备份就会在集群内创建相关 <code>CRD</code> 。如果发现远端存储没有当前集群内的 <code>CRD</code> 所关联的存储数据，那么就会删除当前集群内的 <code>CRD</code>。</p><p><strong>Velero 支持的后端存储</strong></p><p><code>Velero</code> 支持两种关于后端存储的 <code>CRD</code>，分别是 <code>BackupStorageLocation</code> 和 <code>VolumeSnapshotLocation</code>。</p><ol><li>BackupStorageLocation</li></ol><p><code>BackupStorageLocation</code> 主要用来定义 <code>Kubernetes</code> 集群资源的数据存放位置，也就是集群对象数据，不是 <code>PVC</code> 的数据。主要支持的后端存储是 <code>S3</code> 兼容的存储，比如：<code>Mino</code> 和阿里云 <code>OSS</code> 等。</p><ul><li>使用 Minio</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: velero.io&#x2F;v1</span><br><span class="line">kind: BackupStorageLocation</span><br><span class="line">metadata:</span><br><span class="line">  name: default</span><br><span class="line">  namespace: velero</span><br><span class="line">spec:</span><br><span class="line"># 只有 aws gcp azure</span><br><span class="line">  provider: aws</span><br><span class="line">  # 存储主要配置</span><br><span class="line">  objectStorage:</span><br><span class="line">  # bucket 的名称</span><br><span class="line">    bucket: myBucket</span><br><span class="line">    # bucket内的</span><br><span class="line">    prefix: backup</span><br><span class="line"># 不同的 provider 不同的配置</span><br><span class="line">  config:</span><br><span class="line">    #bucket地区</span><br><span class="line">    region: us-west-2</span><br><span class="line">    # s3认证信息</span><br><span class="line">    profile: &quot;default&quot;</span><br><span class="line">    # 使用 Minio 的时候加上，默认为 false</span><br><span class="line">    # AWS 的 S3 可以支持两种 Url Bucket URL</span><br><span class="line">    # 1 Path style URL： http:&#x2F;&#x2F;s3endpoint&#x2F;BUCKET</span><br><span class="line">    # 2 Virtual-hosted style URL： http:&#x2F;&#x2F;oss-cn-beijing.s3endpoint 将 Bucker Name 放到了 Host Header中</span><br><span class="line">    # 3 阿里云仅仅支持 Virtual hosted 如果下面写上 true, 阿里云 OSS 会报错 403</span><br><span class="line">    s3ForcePathStyle: &quot;false&quot;</span><br><span class="line">    # s3的地址，格式为 http:&#x2F;&#x2F;minio:9000</span><br><span class="line">    s3Url: http:&#x2F;&#x2F;minio:9000</span><br></pre></td></tr></table></figure><ul><li>使用阿里云的 OSS</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: velero.io&#x2F;v1</span><br><span class="line">kind: BackupStorageLocation</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    component: velero</span><br><span class="line">  name: default</span><br><span class="line">  namespace: velero</span><br><span class="line">spec:</span><br><span class="line">  config:</span><br><span class="line">    region: oss-cn-beijing</span><br><span class="line">    s3Url: http:&#x2F;&#x2F;oss-cn-beijing.aliyuncs.com</span><br><span class="line">    s3ForcePathStyle: &quot;false&quot;</span><br><span class="line">  objectStorage:</span><br><span class="line">    bucket: build-jenkins</span><br><span class="line">    prefix: &quot;&quot;</span><br><span class="line">  provider: aws</span><br></pre></td></tr></table></figure><ol start="2"><li>VolumeSnapshotLocation</li></ol><p>VolumeSnapshotLocation 主要用来给 PV 做快照，需要云提供商提供插件。阿里云已经提供了插件，这个需要使用 CSI 等存储机制。你也可以使用专门的备份工具 <code>Restic</code>，把 PV 数据备份到阿里云 OSS 中去(安装时需要自定义选项)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 安装时需要自定义选项</span><br><span class="line">--use-restic</span><br><span class="line"></span><br><span class="line"># 这里我们存储 PV 使用的是 OSS 也就是 BackupStorageLocation，因此不用创建 VolumeSnapshotLocation 对象</span><br><span class="line">--use-volume-snapshots&#x3D;false</span><br></pre></td></tr></table></figure><blockquote><p>Restic 是一款 GO 语言开发的数据加密备份工具，顾名思义，可以将本地数据加密后传输到指定的仓库。支持的仓库有 Local、SFTP、Aws S3、Minio、OpenStack Swift、Backblaze B2、Azure BS、Google Cloud storage、Rest Server。</p><p>项目地址：<a href="https://github.com/restic/restic" target="_blank" rel="noopener">https://github.com/restic/restic</a></p></blockquote><p>本文中，我们将使用 <code>Restic</code> 来对 <code>PV</code> 进行备份，不过现阶段通过 <code>Restic</code> 备份会有一些限制。</p><ul><li>不支持备份 hostPath</li><li>备份数据标志只能通过 Pod 来识别</li><li>单线程操作大量文件比较慢</li></ul><h2 id="安装-velero">安装 Velero</h2><p><code>Velero</code> 提供了一个命令行用来初始化服务端和进行常用的备份和恢复操作。该命令行和 <code>Kubernetes</code> 集群交互(和 Kubectl 的方式类似)，也是通过寻找 <code>kubeconfig</code> 的相关配置来访问集群。<code>kubeconfig</code> 主要是通过 <code>KUBECONFIG</code> 环境变量和 <code>~/.kube/config</code> 文件以及选项 <code>–-kubeconfig</code> 来指定。</p><p>本次安装将会使用阿里云的 OSS 和 <code>Restic</code> 来作为后端存储。</p><h3 id="安装前的准备">安装前的准备</h3><ol><li><p>开通阿里云的 OSS 并获取相关认证信息。</p></li><li><p><code>Restic</code> 需要 <code>Docker</code> 进程开通 <code>Mount</code> 传播，需要在 <code>Docker</code> 启动的 <code>Systemd</code> 文件内加入 <code>MountFlags=shared</code></p></li></ol><p>MountFlags：Docker 服务的 Mount Namespace 配置，会影响进程上下文中挂载点的信息。即服务是否会继承主机上已有挂载点，以及如果服务运行执行了挂载或卸载设备的操作，是否会真实地在主机上产生效果。可选值为 <code>shared</code>、<code>slaved</code> 或 <code>private</code> 。</p><ul><li><p>shared：服务与主机共用一个 <code>Mount Namespace</code>，继承主机挂载点，且服务挂载或卸载设备会真实地反映到主机上。</p></li><li><p>slave：服务使用独立的 <code>Mount Namespace</code>，它会继承主机挂载点，但服务对挂载点的操作只有在自己的 <code>Namespace</code> 内生效，不会反映到主机上。</p></li><li><p>private：服务使用独立的 <code>Mount Namespace</code>，它在启动时没有任何挂载点，服务对挂载点的操作也不会反映到主机上。</p></li></ul><p>更多 <code>Systemd</code> 服务管理可参考：<a href="https://blog.mallux.me/2017/02/13/systemd/" target="_blank" rel="noopener">https://blog.mallux.me/2017/02/13/systemd/</a></p><h3 id="安装-velero">安装 Velero</h3><ol><li>安装 Velero 客户端工具</li></ol><p>下载最新版 <code>Velero</code>，并解压。这里以 Linux 平台为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;github.com&#x2F;heptio&#x2F;velero&#x2F;releases&#x2F;download&#x2F;v1.1.0&#x2F;velero-v1.1.0-linux-amd64.tar.gz</span><br><span class="line">$ tar xzvf velero-v1.1.0-linux-amd64.tar.gz</span><br><span class="line">$ cp velero-v1.1.0-linux-amd64\velero \usr\local\bin</span><br></pre></td></tr></table></figure><p>更多平台可以在官方 Releases 页面下载：<a href="https://github.com/heptio/velero/releases/" target="_blank" rel="noopener">https://github.com/heptio/velero/releases/</a> 。</p><p>安装完成成后，可以加载下 <code>Shell</code> 自动完成功能，方便使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ velero completion bash</span><br></pre></td></tr></table></figure><ol start="2"><li>启动 Velero 服务端</li></ol><p>2.1 准备 credentials-velero 文件</p><p>credentials-velero 文件内容为阿里云 OSS 的认证信息，会用于在集群中创建密钥。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim credentials-velero</span><br><span class="line"></span><br><span class="line"># default 和 BackupStorageLocation 对象中 profile 字段的值要对应</span><br><span class="line">[default]</span><br><span class="line">aws_access_key_id &#x3D; xxx</span><br><span class="line">aws_secret_access_key &#x3D; xxx</span><br></pre></td></tr></table></figure><p>2.2 启动 Velero 服务端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ velero install \</span><br><span class="line">    --image gcr.azk8s.cn&#x2F;heptio-images&#x2F;velero:v1.1.0 \</span><br><span class="line">    --provider aws \</span><br><span class="line">    --bucket xxx \</span><br><span class="line">    --prefix xxx \</span><br><span class="line">    --namespace velero \</span><br><span class="line">    --secret-file .&#x2F;credentials-velero \</span><br><span class="line">    --velero-pod-cpu-request 200m \</span><br><span class="line">    --velero-pod-mem-request 200Mi \</span><br><span class="line">    --velero-pod-cpu-limit 200m \</span><br><span class="line">    --velero-pod-mem-limit 200Mi \</span><br><span class="line">    --use-volume-snapshots&#x3D;false \</span><br><span class="line">    --use-restic \</span><br><span class="line">    --restic-pod-cpu-request 200m \</span><br><span class="line">    --restic-pod-mem-request 200Mi \</span><br><span class="line">    --restic-pod-cpu-limit 200m \</span><br><span class="line">    --restic-pod-mem-limit 200Mi \</span><br><span class="line">    --backup-location-config region&#x3D;oss-cn-beijing,s3ForcePathStyle&#x3D;&quot;false&quot;,s3Url&#x3D;http:&#x2F;&#x2F;oss-cn-beijing.aliyuncs.com</span><br></pre></td></tr></table></figure><h2 id="使用-velero-进行数据备份和恢复">使用 Velero 进行数据备份和恢复</h2><h3 id="给-pod-加注解">给 Pod 加注解</h3><p>使用 <code>Restic</code> 给带有 <code>PVC</code> 的 <code>Pod</code> 进行备份，必须先给 <code>Pod</code> 加上注解。</p><p>先看一看基本语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n YOUR_POD_NAMESPACE annotate pod&#x2F;YOUR_POD_NAME backup.velero.io&#x2F;backup-volumes&#x3D;YOUR_VOLUME_NAME_1,YOUR_VOLUME_NAME_2,...</span><br></pre></td></tr></table></figure><p>在来看一个实例，这里使用一个 <code>Elasticsearch</code> 的 <code>Pod</code> 为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n elasticsearch annotate pod elasticsearch-master-0 backup.velero.io&#x2F;backup-volumes&#x3D;elasticsearch-master</span><br><span class="line">$ kubectl get pod -n elasticsearch elasticsearch-master-0 -o jsonpath&#x3D;&#39;&#123;.metadata.annotations&#125;&#39;</span><br><span class="line">map[backup.velero.io&#x2F;backup-volumes:elasticsearch-master]</span><br></pre></td></tr></table></figure><h3 id="创建备份数据">创建备份数据</h3><ol><li>基本命令语法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ velero create backup NAME [flags]</span><br><span class="line"></span><br><span class="line"># 剔除 namespace</span><br><span class="line">--exclude-namespaces stringArray                  namespaces to exclude from the backup</span><br><span class="line"></span><br><span class="line"># 剔除资源类型</span><br><span class="line">--exclude-resources stringArray                   resources to exclude from the backup, formatted as resource.group, such as storageclasses.storage.k8s.io</span><br><span class="line"></span><br><span class="line"># 包含集群资源类型 </span><br><span class="line">--include-cluster-resources optionalBool[&#x3D;true]   include cluster-scoped resources in the backup</span><br><span class="line"></span><br><span class="line"># 包含 namespace</span><br><span class="line">--include-namespaces stringArray                  namespaces to include in the backup (use &#39;*&#39; for all namespaces) (default *)</span><br><span class="line"></span><br><span class="line"># 包含 namespace 资源类型</span><br><span class="line">--include-resources stringArray                   resources to include in the backup, formatted as resource.group, such as storageclasses.storage.k8s.io (use &#39;*&#39; for all resources)</span><br><span class="line"></span><br><span class="line"># 给这个备份加上标签</span><br><span class="line">--labels mapStringString                          labels to apply to the backup</span><br><span class="line">-o, --output string                               Output display format. For create commands, display the object but do not send it to the server. Valid formats are &#39;table&#39;, &#39;json&#39;, and &#39;yaml&#39;. &#39;table&#39; is not valid for the install command.</span><br><span class="line"></span><br><span class="line"># 对指定标签的资源进行备份</span><br><span class="line">-l, --selector labelSelector                      only back up resources matching this label selector (default &lt;none&gt;)</span><br><span class="line"></span><br><span class="line"># 对 PV 创建快照</span><br><span class="line">--snapshot-volumes optionalBool[&#x3D;true]            take snapshots of PersistentVolumes as part of the backup</span><br><span class="line"></span><br><span class="line"># 指定备份的位置</span><br><span class="line">--storage-location string                         location in which to store the backup</span><br><span class="line"></span><br><span class="line"># 备份数据多久删掉</span><br><span class="line"></span><br><span class="line">--ttl duration                                    how long before the backup can be garbage collected (default 720h0m0s)</span><br><span class="line"></span><br><span class="line"># 指定快照的位置，也就是哪一个公有云驱动</span><br><span class="line">--volume-snapshot-locations strings               list of locations (at most one per provider) where volume snapshots should be stored</span><br></pre></td></tr></table></figure><ol start="2"><li>创建一个备份</li></ol><p>这里同样以上面提到的 <code>elasticsearch</code> 为例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ velero create backup es --include-namespaces&#x3D;elasticsearch</span><br></pre></td></tr></table></figure><blockquote><p>注 Restic 会使用 Path Style，而阿里云禁止 Path style 需要使用 Virtual-Hosted，所以暂时备份没有办法备份 PV 到 OSS。</p></blockquote><p>备份创建成功后会创建一个名为 <code>backups.velero.io</code> 的 CRD 对象。</p><h3 id="恢复一个备份数据">恢复一个备份数据</h3><ol><li>基本命令语法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ velero restore create [RESTORE_NAME] [--from-backup BACKUP_NAME | --from-schedule SCHEDULE_NAME] [flags]</span><br><span class="line"></span><br><span class="line">      --exclude-namespaces stringArray                  namespaces to exclude from the restore</span><br><span class="line">      --exclude-resources stringArray                   resources to exclude from the restore, formatted as resource.group, such as storageclasses.storage.k8s.io</span><br><span class="line">      --from-backup string                              backup to restore from</span><br><span class="line">      --from-schedule string                            schedule to restore from</span><br><span class="line">  -h, --help                                            help for create</span><br><span class="line">      --include-cluster-resources optionalBool[&#x3D;true]   include cluster-scoped resources in the restore</span><br><span class="line">      --include-namespaces stringArray                  namespaces to include in the restore (use &#39;*&#39; for all namespaces) (default *)</span><br><span class="line">      --include-resources stringArray                   resources to include in the restore, formatted as resource.group, such as storageclasses.storage.k8s.io (use &#39;*&#39; for all resources)</span><br><span class="line">      --label-columns stringArray                       a comma-separated list of labels to be displayed as columns</span><br><span class="line">      --labels mapStringString                          labels to apply to the restore</span><br><span class="line">      --namespace-mappings mapStringString              namespace mappings from name in the backup to desired restored name in the form src1:dst1,src2:dst2,...</span><br><span class="line">  -o, --output string                                   Output display format. For create commands, display the object but do not send it to the server. Valid formats are &#39;table&#39;, &#39;json&#39;, and &#39;yaml&#39;. &#39;table&#39; is not valid for the install command.</span><br><span class="line">      --restore-volumes optionalBool[&#x3D;true]             whether to restore volumes from snapshots</span><br><span class="line">  -l, --selector labelSelector                          only restore resources matching this label selector (default &lt;none&gt;)</span><br><span class="line">      --show-labels                                     show labels in the last column</span><br><span class="line">  -w, --wait</span><br></pre></td></tr></table></figure><ol start="2"><li>恢复一个备份数据</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ velero restore create back --from-backup es</span><br></pre></td></tr></table></figure><p>恢复成功后，同样也会创建一个 <code>restores.velero.io</code> CRD 对象。</p><h2 id="使用-velero-进行集群数据迁移">使用 Velero 进行集群数据迁移</h2><p>首先，在集群 1 中创建备份（默认 TTL 是 30 天，你可以使用 --ttl 来修改）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ velero backup create &lt;BACKUP-NAME&gt;</span><br></pre></td></tr></table></figure><p>然后，为集群 2 配置 BackupStorageLocations 和 VolumeSnapshotLocations，指向与集群 1 相同的备份和快照路径，并确保 BackupStorageLocations 是只读的（使用 --access-mode=ReadOnly）。接下来，稍微等一会（默认的同步时间为 1 分钟），等待 Backup 对象创建成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># The default sync interval is 1 minute, so make sure to wait before checking.</span><br><span class="line"># You can configure this interval with the --backup-sync-period flag to the Velero server.</span><br><span class="line">$ velero backup describe &lt;BACKUP-NAME&gt;</span><br></pre></td></tr></table></figure><p>最后，执行数据恢复：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ velero restore create --from-backup &lt;BACKUP-NAME&gt;</span><br><span class="line">$ velero restore get</span><br><span class="line">$ velero restore describe &lt;RESTORE-NAME-FROM-GET-COMMAND&gt;</span><br></pre></td></tr></table></figure><blockquote><p>本文在 「集群备份工具 Velero 使用 」一文基础上修改而成。</p></blockquote><h2 id="参考文档">参考文档</h2><ol><li><p><a href="http://www.google.com" target="_blank" rel="noopener">http://www.google.com</a></p></li><li><p><a href="http://t.cn/AiRQWtIe" target="_blank" rel="noopener">http://t.cn/AiRQWtIe</a></p></li><li><p><a href="https://velero.io/docs/master/restic/" target="_blank" rel="noopener">https://velero.io/docs/master/restic/</a></p></li><li><p><a href="https://www.cnblogs.com/rongfengliang/p/11095330.html" target="_blank" rel="noopener">https://www.cnblogs.com/rongfengliang/p/11095330.html</a></p></li><li><p><a href="https://feisky.gitbooks.io/kubernetes/practice/backup.html" target="_blank" rel="noopener">https://feisky.gitbooks.io/kubernetes/practice/backup.html</a></p></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是-Velero？&quot;&gt;什么是 Velero？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heptio/velero/master/site/docs/master/img/velero.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Heptio Velero&lt;/code&gt; ( 以前的名字为 ARK) 是一款用于 &lt;code&gt;Kubernetes&lt;/code&gt; 集群资源和持久存储卷（PV）的备份、迁移以及灾难恢复等的开源工具。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Velero 特性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Velero&lt;/code&gt; 目前包含以下特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;支持 &lt;code&gt;Kubernetes&lt;/code&gt; 集群数据备份和恢复&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持复制当前 &lt;code&gt;Kubernetes&lt;/code&gt; 集群的资源到其它 &lt;code&gt;Kubernetes&lt;/code&gt; 集群&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持复制生产环境到开发以及测试环境&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Velero 组件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Velero&lt;/code&gt; 组件一共分两部分，分别是服务端和客户端。服务端运行在你 &lt;code&gt;Kubernetes&lt;/code&gt; 的集群中，客户端是一些运行在本地的命令行的工具。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Velero 支持的备份存储&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AWS S3 以及兼容 S3 的存储，比如：Minio&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Azure BloB 存储&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Google Cloud 存储&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/heptio/velero&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/heptio/velero&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Velero" scheme="https://www.hi-linux.com/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>巧用 SSLH 实现 HTTPS 和 SSH 共享同一端口</title>
    <link href="https://www.hi-linux.com/posts/26290.html"/>
    <id>https://www.hi-linux.com/posts/26290.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T08:44:56.292Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>一些互联网服务提供商或公司可能已经阻止了大多数网络端口，并且只允许使用少数特定端口（如：80 和 443）来进行服务访问，以加强其安全性。在这种情况下，如果我们需要将更多的服务暴露在公网上，我们该怎么办呢？这时你别无选择，只有为多个程序共用相同的端口，比如：共用 HTTPS 的端口 443。</p><p>那怎么样才能实现不同程序复用相同端口呢，这时你就需要 SSLH 这款神器。</p><blockquote><p>SSLH 是一款采用 C 语言编写的开源端口复用软件，目前支持 HTTP、SSL、SSH、OpenVPN、Tinc、XMPP 等多种协议识别。它主要运行于 *nix 环境，源代码托管在 GitHub 上。</p></blockquote><p>项目地址：<a href="https://github.com/yrutschle/sslh" target="_blank" rel="noopener">https://github.com/yrutschle/sslh</a></p><p>更简单地说，SSLH 允许我们在 Linux 系统上的同一端口上运行多个程序/服务。因此，您可以用同一端口来同时使用两种服务。如果你遇到大多数端口被防火墙阻止的情况，SSLH 就可以帮你派上大用场。下面我们就来看一个 SSL 和 SSH 同时复用同一端口的实例。</p><h2 id="安装-sslh">安装 SSLH</h2><p>SSLH 适用于大多数 Linux 发行版，因此您可以使用默认包管理器进行安装。</p><ul><li>在 Debian / Ubuntu 上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install sslh</span><br></pre></td></tr></table></figure><ul><li>在 RHEL / CentOS 上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 需要先安装 EPEL 仓库</span><br><span class="line">$ sudo yum install epel-release</span><br><span class="line">$ sudo yum install sslh</span><br></pre></td></tr></table></figure><h2 id="配置-web-服务器">配置 Web 服务器</h2><p>首先，我们需要安装一个 Web 服务器，并且配置它接受 HTTPS 请求。确保这个服务只监听在 localhost，当然也可以配置它监听在非标准端口，如：2443。这里我们以 Nginx 为例：</p><h3 id="安装-nginx">安装 Nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># RHEL &#x2F; CentOS </span><br><span class="line">$ yum install nginx</span><br><span class="line"></span><br><span class="line"># Debian &#x2F; Ubuntu</span><br><span class="line">$ apt install nginx</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="配置-nginx">配置 Nginx</h3><p>修改配置让其只监听 localhost 接口，即：<code>127.0.0.1:443</code> 或 <code>localhost：443</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vim nginx.conf</span><br><span class="line"></span><br><span class="line"># 找到如下行内容</span><br><span class="line">listen 443 ssl;</span><br><span class="line"></span><br><span class="line"># 并将其更改为以下内容</span><br><span class="line">listen 127.0.0.1:443 ssl;</span><br></pre></td></tr></table></figure><h2 id="配置-sslh">配置 SSLH</h2><p>接下来，我们需要修改 SSLH 的配置文件的如下几处。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi &#x2F;etc&#x2F;default&#x2F;sslh</span><br><span class="line"></span><br><span class="line"># 找到以下行：</span><br><span class="line">Run&#x3D;no</span><br><span class="line"></span><br><span class="line"># 并将其更改为：</span><br><span class="line">Run&#x3D;yes</span><br><span class="line"></span><br><span class="line"># 修改以下行以允许 SSLH 在所有可用接口上侦听端口 443。</span><br><span class="line">DAEMON_OPTS&#x3D;&quot;--user sslh --listen 0.0.0.0:443 --ssh 127.0.0.1:22 --ssl 127.0.0.1:443 --pidfile &#x2F;var&#x2F;run&#x2F;sslh&#x2F;sslh.pid&quot;</span><br></pre></td></tr></table></figure><p>修改完成后，记得保存并关闭配置文件。这里在简单说下几个选项的含义</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-–user sslh : 用此指定的用户名运行 SSLH。</span><br><span class="line">-–listen 0.0.0.0:443 : 指定 SSLH 在所有接口上监听 443 端口。</span><br><span class="line">-–sshs 127.0.0.1:22 : 将 SSH 流量转发到 localhost 上的 22 端口。</span><br><span class="line">-–ssl 127.0.0.1:443 : 将 HTTPS&#x2F;SSL 流量转发到 localhost 上的 443 端口。</span><br></pre></td></tr></table></figure><h2 id="启动-sslh-服务">启动 SSLH 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl enable sslh</span><br><span class="line">$ sudo systemctl start sslh</span><br></pre></td></tr></table></figure><h2 id="测试-sslh-服务">测试 SSLH 服务</h2><p>验证 SSLH 守护程序是否正在侦听 443 端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ps -ef | grep sslh </span><br><span class="line">sslh 2746 1 0 15:51 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;sslh --foreground --user sslh --listen 0.0.0.0 443 --ssh 127.0.0.1 22 --ssl 127.0.0.1 443 --pidfile &#x2F;var&#x2F;run&#x2F;sslh&#x2F;sslh.pid</span><br><span class="line">sslh 2747 2746 0 15:51 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;sslh --foreground --user sslh --listen 0.0.0.0 443 --ssh 127.0.0.1 22 --ssl 127.0.0.1 443 --pidfile &#x2F;var&#x2F;run&#x2F;sslh&#x2F;sslh.pid</span><br><span class="line">sk 2754 1432 0 15:51 pts&#x2F;0 00:00:00 grep --color&#x3D;auto sslh</span><br></pre></td></tr></table></figure><p>最后，我们来验证下使用 443 端口进行 SSH 和 HTTPS 访问。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -p 443 sk@192.168.43.2</span><br><span class="line">sk@192.168.43.2&#39;s password: </span><br><span class="line">Welcome to Ubuntu 16.04.1 LTS (GNU&#x2F;Linux 4.4.0-89-generic x86_64)</span><br><span class="line"></span><br><span class="line"> * Documentation: https:&#x2F;&#x2F;help.ubuntu.com</span><br><span class="line"> * Management: https:&#x2F;&#x2F;landscape.canonical.com</span><br><span class="line"> * Support: https:&#x2F;&#x2F;ubuntu.com&#x2F;advantage</span><br><span class="line"></span><br><span class="line">Last login: Mon Aug 14 15:52:20 2017 from 192.168.43.192</span><br><span class="line">sk@ubuntuserver:~$</span><br></pre></td></tr></table></figure><p>同时使用浏览器访问 <code>https://SERVER_NAME</code> 这个地址也是可以正确访问的。</p><p>至此，我们就验证了 SSLH 确实可以在同一端口提供多种服务。</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://linux.cn/article-11247-1.html" target="_blank" rel="noopener">https://linux.cn/article-11247-1.html</a></li><li><a href="https://www.ostechnix.com/sslh-share-port-https-ssh/" target="_blank" rel="noopener">https://www.ostechnix.com/sslh-share-port-https-ssh/</a></li><li><a href="https://huataihuang.gitbooks.io/cloud-atlas/service/ssh/sslh_multi_service_in_one_port.html" target="_blank" rel="noopener">https://huataihuang.gitbooks.io/cloud-atlas/service/ssh/sslh_multi_service_in_one_port.html</a></li><li><a href="https://it.baiked.com/linux/linuxcommon/4525.html" target="_blank" rel="noopener">https://it.baiked.com/linux/linuxcommon/4525.html</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一些互联网服务提供商或公司可能已经阻止了大多数网络端口，并且只允许使用少数特定端口（如：80 和 443）来进行服务访问，以加强其安全性。在这种情况下，如果我们需要将更多的服务暴露在公网上，我们该怎么办呢？这时你别无选择，只有为多个程序共用相同的端口，比如：共用 HTTPS 的端口 443。&lt;/p&gt;
&lt;p&gt;那怎么样才能实现不同程序复用相同端口呢，这时你就需要 SSLH 这款神器。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;SSLH 是一款采用 C 语言编写的开源端口复用软件，目前支持 HTTP、SSL、SSH、OpenVPN、Tinc、XMPP 等多种协议识别。它主要运行于 *nix 环境，源代码托管在 GitHub 上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/yrutschle/sslh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/yrutschle/sslh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更简单地说，SSLH 允许我们在 Linux 系统上的同一端口上运行多个程序/服务。因此，您可以用同一端口来同时使用两种服务。如果你遇到大多数端口被防火墙阻止的情况，SSLH 就可以帮你派上大用场。下面我们就来看一个 SSL 和 SSH 同时复用同一端口的实例。&lt;/p&gt;
&lt;h2 id=&quot;安装-SSLH&quot;&gt;安装 SSLH&lt;/h2&gt;
&lt;p&gt;SSLH 适用于大多数 Linux 发行版，因此您可以使用默认包管理器进行安装。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 Debian / Ubuntu 上&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ sudo apt-get install sslh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;在 RHEL / CentOS 上&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 需要先安装 EPEL 仓库&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ sudo yum install epel-release&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ sudo yum install sslh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;配置-Web-服务器&quot;&gt;配置 Web 服务器&lt;/h2&gt;
&lt;p&gt;首先，我们需要安装一个 Web 服务器，并且配置它接受 HTTPS 请求。确保这个服务只监听在 localhost，当然也可以配置它监听在非标准端口，如：2443。这里我们以 Nginx 为例：&lt;/p&gt;
&lt;h3 id=&quot;安装-Nginx&quot;&gt;安装 Nginx&lt;/h3&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# RHEL &amp;#x2F; CentOS &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ yum install nginx&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Debian &amp;#x2F; Ubuntu&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ apt install nginx&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="HTTPS" scheme="https://www.hi-linux.com/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>在 Kubernetes 上使用 Tekton 快速实现应用自动发布</title>
    <link href="https://www.hi-linux.com/posts/27392.html"/>
    <id>https://www.hi-linux.com/posts/27392.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T08:44:56.293Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Tekton 是一个功能强大且灵活的 Kubernetes 原生开源框架，用于创建持续集成和交付（CI/CD）系统。通过抽象底层实现细节，用户可以跨多云平台和本地系统进行构建、测试和部署。</p><p><img src="https://static.geekbang.org/infoq/5c93359665d11.png" alt=""></p><p>Tekton 提供的开源组件可以跨供应商，Tekton 提供的管道、版本、工作流程和其他 CI/CD 组件的行业规范一致，可以和你现有的 CI/CD 工具（例如：Jenkins、Jenkins X、Skaffold 和 Knative 等）配合使用。</p><p><img src="https://static.geekbang.org/infoq/5c9337c34200d.png" alt=""></p><p>Tekton 和其它几种 CI/CD 工具的比较</p><p><img src="https://user-gold-cdn.xitu.io/2019/8/19/16ca90bd97da7f1c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p><p>使用 Tekton 的内置最佳实践可以快速创建云原生 CI / CD 管道，目标是让开发人员创建和部署不可变镜像，管理基础架构的版本控制或执行更简单的回滚。 还可以利用 Tekton 的滚动部署，蓝 / 绿部署，金丝雀部署或 GitOps 工作流等高级部署模式。</p><p><img src="https://static.geekbang.org/infoq/5c9341655e5d6.png" alt=""></p><p>使用 Tekton 可跨多个环境（例如：VM、无服务器、Kubernetes 或 Firebase）进行构建，测试和部署。你还可以使用 Tekton 管道跨多云平台或混合环境进行部署。</p><p><img src="https://static.geekbang.org/infoq/5c93423576184.png" alt=""></p><p>Tekton 提供了最大的灵活性，让你可以使用自己喜欢的 CI/CD 工具构建强大的管道。</p><p><img src="https://static.geekbang.org/infoq/5c9342c97323c.png" alt=""></p><blockquote><p>项目地址：<a href="https://github.com/tektoncd/pipeline" target="_blank" rel="noopener">https://github.com/tektoncd/pipeline</a></p></blockquote><p>下面来看一个基于阿里云 Kubernetes 服务部署 Tekton Pipeline 的实例，部署完成后我们使用它来完成源码拉取、应用打包、镜像推送和应用部署。</p><p><img src="https://tva1.sinaimg.cn/large/006Xmmmggy1g6e4xs926jj32bd0qqq91.jpg" alt=""></p><p>Tekton Pipeline 中有 5 类对象，核心理念是通过定义 YAML 定义构建过程，构建任务的状态存放在 status 字段中。</p><p>其中 5 类对象分别是：PipelineResouce、Task、TaskRun、Pipeline、PipelineRun。</p><p>Task 是单个任务的构建过程，需要通过定义 TaskRun 任务去运行 Task。</p><p>Pipeline 包含多个 Task，并在此基础上定义 input 和 output，input 和 output 以 PipelineResource 作为交付。</p><p>PipelineResource 是可用于 input 和 output 的对象集合。</p><p>同样地,需要定义 PipelineRun 才会运行 Pipeline。</p><a id="more"></a><h2 id="在阿里云-kubernetes-集群中部署-tekton-pipeline">在阿里云 Kubernetes 集群中部署 Tekton Pipeline</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply --filename https:&#x2F;&#x2F;storage.googleapis.com&#x2F;tekton-releases&#x2F;latest&#x2F;release.yaml</span><br></pre></td></tr></table></figure><p>查看Tekton Pipelines组件是否运行正常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines get po</span><br><span class="line">NAME                                                     READY   STATUS      RESTARTS   AGE</span><br><span class="line">tekton-pipelines-controller-6bcd7ff5d6-vzmrh             1&#x2F;1     Running     0          25h</span><br><span class="line">tekton-pipelines-webhook-6856cf9c47-l6nj6                1&#x2F;1     Running     0          25h</span><br></pre></td></tr></table></figure><h2 id="创建-git-resource-和-registry-resource">创建 Git Resource 和 Registry Resource</h2><ol><li>编辑 git-pipeline-resource.yaml 文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># git repo 的分支名称为 tekton</span><br><span class="line">apiVersion: tekton.dev&#x2F;v1alpha1</span><br><span class="line">kind: PipelineResource</span><br><span class="line">metadata:</span><br><span class="line">  name: git-pipeline-resource</span><br><span class="line">spec:</span><br><span class="line">  type: git</span><br><span class="line">  params:</span><br><span class="line">    - name: revision</span><br><span class="line">      value: tekton</span><br><span class="line">    - name: url</span><br><span class="line">      value: https:&#x2F;&#x2F;code.aliyun.com&#x2F;haoshuwei&#x2F;jenkins-demo.git</span><br></pre></td></tr></table></figure><ol start="2"><li>编辑 registry-pipeline-resource.yaml 文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 容器镜像仓库地址为 registry.cn-hangzhou.aliyuncs.com&#x2F;haoshuwei&#x2F;tekton-demo， 标签为 latest</span><br><span class="line">apiVersion: tekton.dev&#x2F;v1alpha1</span><br><span class="line">kind: PipelineResource</span><br><span class="line">metadata:</span><br><span class="line">  name: registry-pipeline-resource</span><br><span class="line">spec:</span><br><span class="line">  type: image</span><br><span class="line">  params:</span><br><span class="line">    - name: url</span><br><span class="line">      value: registry.cn-hangzhou.aliyuncs.com&#x2F;haoshuwei&#x2F;tekton-demo</span><br></pre></td></tr></table></figure><ol start="3"><li>创建 pipeline resource</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines create -f git-pipeline-resource.yaml</span><br><span class="line">$ kubectl -n tekton-pipelines create -f registry-pipeline-resource.yaml</span><br></pre></td></tr></table></figure><ol start="4"><li>查看已创建的 pipeline resource 资源</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines get PipelineResource</span><br><span class="line">NAME                         AGE</span><br><span class="line">git-pipeline-resource        2h</span><br><span class="line">registry-pipeline-resource   2h</span><br></pre></td></tr></table></figure><h2 id="创建-git-repo-docker-registry-authentication">创建 Git Repo / Docker Registry Authentication</h2><p>拉取私有 Git 源码项目需要配置使用 Git Repo Authentication，拉取和推送 Docker 镜像需要配置 Docker Registry Authentication。</p><p>在 Tekton Pipeline 中，Git Repo / Docker Registry Authentication 会被定义成ServiceAccount来使用。</p><ol><li>编辑 secret tekton-basic-user-pass-git.yaml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: tekton-basic-user-pass-git</span><br><span class="line">  annotations:</span><br><span class="line">    tekton.dev&#x2F;git-0: https:&#x2F;&#x2F;code.aliyun.com</span><br><span class="line">type: kubernetes.io&#x2F;basic-auth</span><br><span class="line">stringData:</span><br><span class="line">  username: &lt;cleartext non-encoded&gt;</span><br><span class="line">  password: &lt;cleartext non-encoded&gt;</span><br></pre></td></tr></table></figure><ol start="2"><li>编辑 secret tekton-basic-user-pass-registry.yaml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: tekton-basic-user-pass-registry</span><br><span class="line">  annotations:</span><br><span class="line">    tekton.dev&#x2F;docker-0: https:&#x2F;&#x2F;registry.cn-hangzhou.aliyuncs.com</span><br><span class="line">type: kubernetes.io&#x2F;basic-auth</span><br><span class="line">stringData:</span><br><span class="line">  username: &lt;cleartext non-encoded&gt;</span><br><span class="line">  password: &lt;cleartext non-encoded&gt;</span><br></pre></td></tr></table></figure><ol start="3"><li>编辑 serviceaccount tekton-git-and-registry.yaml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: tekton-git-and-registry</span><br><span class="line">secrets:</span><br><span class="line">  - name: tekton-basic-user-pass-git</span><br><span class="line">  - name: tekton-basic-user-pass-registry</span><br></pre></td></tr></table></figure><ol start="4"><li>创建 serviceaccount</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines create -f tekton-basic-user-pass-git.yaml</span><br><span class="line">$ kubectl -n tekton-pipelines create -f tekton-basic-user-pass-registry.yaml</span><br><span class="line">$ kubectl -n tekton-pipelines create -f tekton-git-and-registry.yaml</span><br></pre></td></tr></table></figure><ol start="5"><li>查看 secret 以及 sa</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines get secret</span><br><span class="line">NAME                                      TYPE                                  DATA   AGE</span><br><span class="line">default-token-pwncj                       kubernetes.io&#x2F;service-account-token   3      25h</span><br><span class="line">tekton-basic-user-pass-git                kubernetes.io&#x2F;basic-auth              2      151m</span><br><span class="line">tekton-basic-user-pass-registry           kubernetes.io&#x2F;basic-auth              2      151m</span><br><span class="line">tekton-git-and-registry-token-tr95m       kubernetes.io&#x2F;service-account-token   3      151m</span><br><span class="line">tekton-pipelines-controller-token-lc2fv   kubernetes.io&#x2F;service-account-token   3      25h  </span><br><span class="line">webhook-certs                             Opaque                                3      25h</span><br><span class="line"></span><br><span class="line">$  kubectl -n tekton-pipelines get sa</span><br><span class="line">NAME                          SECRETS   AGE</span><br><span class="line">default                       1         25h</span><br><span class="line">tekton-git-and-registry       3         152m</span><br><span class="line">tekton-pipelines-controller   1         25h</span><br></pre></td></tr></table></figure><h2 id="配置-serviceaccount">配置 serviceaccount</h2><p>配置一个 tekton-git-and-registry 帐号以获取命名空间 tekton-pipelines 的管理权限，用于部署应用。</p><ol><li>创建 ClusterRoleBinding tekton-cluster-admin</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: tekton-cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: tekton-git-and-registry</span><br><span class="line">    namespace: tekton-pipelines</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure><h2 id="创建一个-task">创建一个 Task</h2><ol><li>创建 task build-app.yaml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: tekton.dev&#x2F;v1alpha1</span><br><span class="line">kind: Task</span><br><span class="line">metadata:</span><br><span class="line">  name: build-app</span><br><span class="line">spec:</span><br><span class="line">  inputs:</span><br><span class="line">    resources:</span><br><span class="line">      - name: java-demo</span><br><span class="line">        type: git</span><br><span class="line">    params:</span><br><span class="line">      - name: pathToDockerFile</span><br><span class="line">        description: The path to the dockerfile to build</span><br><span class="line">        default: &#x2F;workspace&#x2F;java-demo&#x2F;Dockerfile</span><br><span class="line">      - name: pathToContext</span><br><span class="line">        description: The build context used by Kaniko</span><br><span class="line">        default: &#x2F;workspace&#x2F;java-dem</span><br><span class="line">      - name: pathToYaml</span><br><span class="line">        description: The path to teh manifest to apply</span><br><span class="line">  outputs:</span><br><span class="line">    resources:</span><br><span class="line">      - name: builtImage</span><br><span class="line">        type: image</span><br><span class="line">  steps:</span><br><span class="line">    - name: build-mvn-package</span><br><span class="line">      image: registry.cn-beijing.aliyuncs.com&#x2F;acs-sample&#x2F;jenkins-slave-maven:3.3.9-jdk-8-alpine</span><br><span class="line">      workingDir: &#x2F;workspace&#x2F;java-demo</span><br><span class="line">      command:</span><br><span class="line">        - mvn</span><br><span class="line">      args:</span><br><span class="line">        - package</span><br><span class="line">        - -B</span><br><span class="line">        - -DskipTests</span><br><span class="line">    - name: build-docker-image</span><br><span class="line">      image: registry.cn-beijing.aliyuncs.com&#x2F;acs-sample&#x2F;jenkins-slave-kaniko:0.6.0</span><br><span class="line">      command:</span><br><span class="line">        - kaniko</span><br><span class="line">      args:</span><br><span class="line">        - --dockerfile&#x3D;$&#123;inputs.params.pathToDockerFile&#125;</span><br><span class="line">        - --destination&#x3D;$&#123;outputs.resources.builtImage.url&#125;</span><br><span class="line">        - --context&#x3D;$&#123;inputs.params.pathToContext&#125;</span><br><span class="line">    - name: deploy-app</span><br><span class="line">      image: registry.cn-beijing.aliyuncs.com&#x2F;acs-sample&#x2F;jenkins-slave-kubectl:1.11.5</span><br><span class="line">      command:</span><br><span class="line">        - kubectl</span><br><span class="line">      args:</span><br><span class="line">        - apply</span><br><span class="line">        - -f</span><br><span class="line">        - $&#123;inputs.params.pathToYaml&#125;</span><br></pre></td></tr></table></figure><h2 id="创建-taskrun-运行任务">创建 TaskRun 运行任务</h2><ol><li>创建 taskrun build-app-task-run.yaml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: tekton.dev&#x2F;v1alpha1</span><br><span class="line">kind: TaskRun</span><br><span class="line">metadata:</span><br><span class="line">  name: build-app-task-run</span><br><span class="line">spec:</span><br><span class="line">  serviceAccount: tekton-git-and-registry</span><br><span class="line">  taskRef:</span><br><span class="line">    name: build-app</span><br><span class="line">  trigger:</span><br><span class="line">    type: manual</span><br><span class="line">  inputs:</span><br><span class="line">    resources:</span><br><span class="line">      - name: java-demo</span><br><span class="line">        resourceRef:</span><br><span class="line">          name: git-pipeline-resource</span><br><span class="line">    params:</span><br><span class="line">      - name: pathToDockerFile</span><br><span class="line">        value: Dockerfile</span><br><span class="line">      - name: pathToContext</span><br><span class="line">        value: &#x2F;workspace&#x2F;java-demo</span><br><span class="line">      - name: pathToYaml</span><br><span class="line">        value: &#x2F;workspace&#x2F;java-demo&#x2F;deployment.yaml</span><br><span class="line">  outputs:</span><br><span class="line">    resources:</span><br><span class="line">      - name: builtImage</span><br><span class="line">        resourceRef:</span><br><span class="line">          name: registry-pipeline-resource</span><br></pre></td></tr></table></figure><h2 id="查看构建状态以及日志">查看构建状态以及日志</h2><ol><li>查看 taskrun 状态</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines get taskrun</span><br><span class="line">NAME                 SUCCEEDED   REASON    STARTTIME   COMPLETIONTIME</span><br><span class="line">build-app-task-run   Unknown     Pending   4s</span><br></pre></td></tr></table></figure><ol start="2"><li>查看构建日志</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines get po</span><br><span class="line">NAME                                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">build-app-task-run-pod-b8f890                  3&#x2F;5     Running   0          75s</span><br><span class="line">tekton-pipelines-controller-6bcd7ff5d6-vzmrh   1&#x2F;1     Running   0          25h</span><br><span class="line">tekton-pipelines-webhook-6856cf9c47-l6nj6      1&#x2F;1     Running   0          25h</span><br><span class="line"></span><br><span class="line">$ kubectl -n tekton-pipelines logs -f build-app-task-run-pod-b8f890</span><br><span class="line">Error from server (BadRequest): a container name must be specified for pod build-app-task-run-pod-b8f890, choose one of:   [build-step-git-source-git-pipeline-resource-77l5v build-step-build-mvn-package build-step-build-docker-image build-step-deploy-app nop] or one of the init containers: [build-step-credential-initializer-8dsnm build-step-place-tools]</span><br></pre></td></tr></table></figure><ul><li>MVN Build 的日志</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines logs -f build-app-task-run-pod-b8f890 -c build-step-build-mvn-package</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building jenkins-demo-web 1.0.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Downloading: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;plugins&#x2F;maven-resources-plugin&#x2F;2.6&#x2F;maven-resources-plugin-2.6.pom</span><br><span class="line">[INFO] Downloaded: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;plugins&#x2F;maven-resources-plugin&#x2F;2.6&#x2F;maven-resources-plugin-2.6.pom (8 KB at 7.3 KB&#x2F;sec)</span><br><span class="line">[INFO] Downloading: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;plugins&#x2F;maven-plugins&#x2F;23&#x2F;maven-plugins-23.pom</span><br><span class="line">[INFO] Downloaded: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;plugins&#x2F;maven-plugins&#x2F;23&#x2F;maven-plugins-23.pom (9 KB at 26.7 KB&#x2F;sec)</span><br><span class="line">[INFO] Downloading: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;maven-parent&#x2F;22&#x2F;maven-parent-22.pom</span><br><span class="line">[INFO] Downloaded: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;maven-parent&#x2F;22&#x2F;maven-parent-22.pom (30 KB at 61.3 KB&#x2F;sec)</span><br><span class="line">[INFO] Downloading: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;apache&#x2F;11&#x2F;apache-11.pom</span><br><span class="line">[INFO] Downloaded: https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;apache&#x2F;11&#x2F;apache-11.pom (15 KB at 45.3 KB&#x2F;sec)</span><br><span class="line">....</span><br></pre></td></tr></table></figure><ul><li>Docker Build 的日志</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines logs -f build-app-task-run-pod-b8f890 -c build-step-build-docker-image</span><br><span class="line">INFO[0000] Downloading base image tomcat</span><br><span class="line">2019&#x2F;05&#x2F;06 11:58:46 No matching credentials were found, falling back on anonymous</span><br><span class="line">INFO[0003] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;builder&#x2F;home, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;builder&#x2F;tools, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;dev, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;kaniko, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;proc, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;sys, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;var&#x2F;run, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Skipping paths under &#x2F;workspace, as it is a whitelisted directory</span><br><span class="line">INFO[0003] Using files from context: [&#x2F;workspace&#x2F;java-demo&#x2F;target&#x2F;demo.war]</span><br><span class="line">INFO[0003] ADD target&#x2F;demo.war &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps&#x2F;demo.war</span><br><span class="line">INFO[0003] Taking snapshot of files...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><ul><li>app-deploy 的日志</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines logs -f build-app-task-run-pod-637855 -c build-step-deploy-app</span><br><span class="line">deployment.extensions&#x2F;jenkins-java-demo created</span><br><span class="line">service&#x2F;jenkins-java-demo created</span><br></pre></td></tr></table></figure><ol start="3"><li>taskrun 的完成状态为 True 则构建部署过程完成</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n tekton-pipelines get taskrun</span><br><span class="line">NAME                 SUCCEEDED   REASON   STARTTIME   COMPLETIONTIME</span><br><span class="line">build-app-task-run   True                 4m          2m</span><br></pre></td></tr></table></figure><h2 id="小结">小结</h2><p>Tekton Pipeline 中的任务模板可以拿来复用，而不需要重复定义，另外通过 CRD 重新定义 CI/CD 是一大亮点。</p><h2 id="参考文档">参考文档</h2><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="https://www.infoq.cn/article/tZ6E1_lhsWeh26C9xUJf" target="_blank" rel="noopener">https://www.infoq.cn/article/tZ6E1_lhsWeh26C9xUJf</a></li><li><a href="https://yq.aliyun.com/articles/701368?utm_content=g_1000055966" target="_blank" rel="noopener">https://yq.aliyun.com/articles/701368?utm_content=g_1000055966</a></li><li><a href="https://juejin.im/post/5d5a612a6fb9a06b2d77d39a" target="_blank" rel="noopener">https://juejin.im/post/5d5a612a6fb9a06b2d77d39a</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Tekton 是一个功能强大且灵活的 Kubernetes 原生开源框架，用于创建持续集成和交付（CI/CD）系统。通过抽象底层实现细节，用户可以跨多云平台和本地系统进行构建、测试和部署。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.geekbang.org/infoq/5c93359665d11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Tekton 提供的开源组件可以跨供应商，Tekton 提供的管道、版本、工作流程和其他 CI/CD 组件的行业规范一致，可以和你现有的 CI/CD 工具（例如：Jenkins、Jenkins X、Skaffold 和 Knative 等）配合使用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.geekbang.org/infoq/5c9337c34200d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Tekton 和其它几种 CI/CD 工具的比较&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/8/19/16ca90bd97da7f1c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;使用 Tekton 的内置最佳实践可以快速创建云原生 CI / CD 管道，目标是让开发人员创建和部署不可变镜像，管理基础架构的版本控制或执行更简单的回滚。 还可以利用 Tekton 的滚动部署，蓝 / 绿部署，金丝雀部署或 GitOps 工作流等高级部署模式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.geekbang.org/infoq/5c9341655e5d6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;使用 Tekton 可跨多个环境（例如：VM、无服务器、Kubernetes 或 Firebase）进行构建，测试和部署。你还可以使用 Tekton 管道跨多云平台或混合环境进行部署。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.geekbang.org/infoq/5c93423576184.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Tekton 提供了最大的灵活性，让你可以使用自己喜欢的 CI/CD 工具构建强大的管道。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.geekbang.org/infoq/5c9342c97323c.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/tektoncd/pipeline&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/tektoncd/pipeline&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面来看一个基于阿里云 Kubernetes 服务部署 Tekton Pipeline 的实例，部署完成后我们使用它来完成源码拉取、应用打包、镜像推送和应用部署。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006Xmmmggy1g6e4xs926jj32bd0qqq91.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Tekton Pipeline 中有 5 类对象，核心理念是通过定义 YAML 定义构建过程，构建任务的状态存放在 status 字段中。&lt;/p&gt;
&lt;p&gt;其中 5 类对象分别是：PipelineResouce、Task、TaskRun、Pipeline、PipelineRun。&lt;/p&gt;
&lt;p&gt;Task 是单个任务的构建过程，需要通过定义 TaskRun 任务去运行 Task。&lt;/p&gt;
&lt;p&gt;Pipeline 包含多个 Task，并在此基础上定义 input 和 output，input 和 output 以 PipelineResource 作为交付。&lt;/p&gt;
&lt;p&gt;PipelineResource 是可用于 input 和 output 的对象集合。&lt;/p&gt;
&lt;p&gt;同样地,需要定义 PipelineRun 才会运行 Pipeline。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/categories/kubernetes/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="Kubernetes" scheme="https://www.hi-linux.com/tags/Kubernetes/"/>
    
      <category term="Tekton" scheme="https://www.hi-linux.com/tags/Tekton/"/>
    
  </entry>
  
  <entry>
    <title>史上最全的 Linux 运维工程师面试题</title>
    <link href="https://www.hi-linux.com/posts/20287.html"/>
    <id>https://www.hi-linux.com/posts/20287.html</id>
    <published>2020-05-17T01:00:00.000Z</published>
    <updated>2020-05-17T08:52:57.298Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h3 id="linux-基础知识篇">Linux 基础知识篇</h3><p>这一套题算是简单的，考的内容基本是 Linux 基本原理、查找命令、计划命令、防火墙设置等，以上这四点基本算是初级内容。</p><ol><li>说说 Linux 启动大致过程？</li></ol><p>加载 BIOS–&gt;读取 MBR–&gt;Boot Loader–&gt;加载内核–&gt;用户层 Init 依据 Inittab 文件来设定系统运行的等级(一般 3 或者 5，3 是多用户命令行，5 是图形界面)–&gt;Init 进程执行 rc.syninit–&gt;启动内核模块–&gt;执行不同级别运行的脚本程序–&gt;执行 /etc/rc.d/rc.local (本地运行服务)–&gt;执行 /bin/login,就可以登录了。</p><p>基本看过 「鸟哥 Linux 私房菜」的就能知道，这是第五章管理员的第一个内容。</p><p>这道题可以扩展一下：Init 系统运行等级一共有几种，每一种都是什么？</p><p>0：关机，只要是0就不能开机<br>1：单用户模式，不能被远程登陆<br>2：多用户不能上网模式<br>3：多用户可以上网模式<br>4：未使用<br>5：有图形的 Linux<br>6：重启，只要是 6 就会不断的重启,子子孙孙无穷匮焉的重启</p><a id="more"></a><ol start="2"><li>Linux 系统是由那些部分组成？</li></ol><p>Linux 由系统内核，Shell，文件系统和应用程序四部分组成。</p><ol start="3"><li>Apache 有几种工作模式，分别简述其工作模式及其优缺点？</li></ol><p>Apache 主要有两种工作模式：Prefork (Apache 的默认安装模式)和 Worker( 可以在编译的时候添加 --with-mpm=worker 选项来指定)</p><p>Prefork 的特点是：预派生</p><ul><li>这种模式可以不必在请求到来时再产生新的进程，从而减小了系统开销</li><li>可以防止意外的内存泄漏</li><li>在服务器负载下降的时候会自动减少子进程数</li></ul><p>Worker的特点是：支持混合的多线程多进程的多路处理模块</p><p>如果对于一个高流量的 HTTP 服务器，Worker MPM 是一个比较好的选择，因为 Worker MPM 占用的内存要比 Prefork 更小。</p><ol start="4"><li>说说 LVS 三种工作模式的工作过程？</li></ol><p>LVS 就是 Linux Virtual Server，Linux 虚拟服务器。</p><ul><li>NAT (Network Address Translation) 模式。LB 收到用户请求包后，LB 将请求包中虚拟服务器的 IP 地址转换为某个选定 RS 的 IP 地址，转发给 RS；RS 将应答包发给 LB，LB 将应答包中 RS 的 IP 转为虚拟服务器的 IP 地址，回送给用户。</li><li>IP 隧道 (IP Tunneling)模式。LB 收到用户请求包后，根据 IP 隧道协议封装该包，然后传给某个选定的 RS；RS 解出请求信息，直接将应答内容传给用户。此时要求 RS 和 LB 都要支持 IP 隧道协议。</li><li>DR (Direct Routing) 模式。LB 收到请求包后，将请求包中目标 MAC 地址转换为某个选定 RS 的 MAC 地址后将包转发出去，RS 收到请求包后 ,可直接将应答内容传给用户。此时要求 LB 和所有 RS 都必须在一个物理段内,且 LB 与 RS 群共享一个虚拟 IP。</li></ul><ol start="5"><li>列出 Linux 常见打包工具并写相应解压缩参数(至少三种)？</li></ol><p>Tar 命令就是打包工具，对应的解压缩参数 tar -cvf、 tar -zcvf、 tar -jcvf 是对应拆包解压什么文件的要对应记住，不要记混。</p><ol start="6"><li>一个 EXT3 的文件分区，当用 touch 新建文件时报错，错误信息是磁盘已满，但是使用 df -H 查看分区信息时只使用了 50%，请分析具体原因？</li></ol><p>两种情况：一种是磁盘配额问题，另外一种就是 EXT3 文件系统的设计不适合很多小文件跟大文件的一种文件格式，出现很多小文件时，容易导致 Inode 耗尽了。</p><ol start="7"><li>请使用 Linux 系统命令统计出 establish 状态的连接数有多少?</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -an |grep ESTABLISHED |wc -l</span><br></pre></td></tr></table></figure><p>netstat命令 -a 参数是显示所有链接，-n 是不要域名解析，即都是以数字 IP 的显示。</p><p>现实生产系统的时候，如果服务器维持的链接是成千上万的话，少用 netstat，多用 ss。</p><ol start="8"><li>如何统计出一台 Web Server 上的各个状态（ESTABLISHED / SYN_SENT / SYN_RECV 等）的个数？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -antl|grep ESTABLISTHED|wc -l</span><br><span class="line">$ netstat -antl|grep SYN_SENT|wc -l</span><br><span class="line">$ netstat -antl|grep SYN_RECV|wc -l</span><br></pre></td></tr></table></figure><p>netstat 命令的 -t 参数是查询 TCP 协议的链接,-l 参数是查询 Listen 状态下的链接。</p><p>netstat -an 的话会出现大概三个部分的内容，一部分是 TCP 协议内容，一部分是 UDP 协议的内容，还有一部分是 Unix Socket 方面的链接，Active UNIX domain sockets (servers and established)。</p><ol start="9"><li>查找 /usr/local/apache/logs 目录最后修改时间大于 30 天的文件并删除</li></ol><p>find 命令以及相关搭配命令是笔试中的重点，因为在现实中运用的情况最多，所以必考必考必考！！！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ find &#x2F;usr&#x2F;local&#x2F;apache&#x2F;logs -type f -mtime +30 -ok rm &#123;&#125; \;</span><br></pre></td></tr></table></figure><p>使用 mtime +30 来描述修改时间大于 30 天，使用 -type -f 来描述文件，然后使用 -ok 命令将所有满足的文件都执行下一步操作。</p><p>这里是删除文件，所以比较人性化的用 ok，删之前询问一下，如果简单暴力就可以直接 -exec，直接枪毙掉。用了 -exec 的话是不用 -f 的，多此一举。</p><ol start="10"><li>编写个 Shell 脚本将 /usr/local/test 目录下大于 100K 的文件转移到 /tmp 目录</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">touch AAA.sh</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">find &#x2F;usr&#x2F;local&#x2F;test&#x2F; -size +100K -exec mv &#123;&#125; &#x2F;tmp \;</span><br></pre></td></tr></table></figure><p>注：-exec and -ok 后面的花括号里面的内容就是使用 find 命令查找出来的文件名。</p><ol start="11"><li>添加一条到 192.168.3.0/24 的路由，网关为 192.168.1.254？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ route add -net 192.168.3.0 netmask 255.255.255.0 gw 192.168.1.254  或者  route add -net 192.168.3.0&#x2F;24 gw 192.168.1.254</span><br></pre></td></tr></table></figure><p>注：route 命令是临时性的增加路由，如果需要永久性的添加路由方法如下：</p><p>方法一</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc&#x2F;rc.local</span><br><span class="line">route add -net 192.168.3.0&#x2F;24 gw 192.168.1.254。</span><br></pre></td></tr></table></figure><p>方法二</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc&#x2F;sysconfig&#x2F;network </span><br><span class="line">GATEWAY&#x3D;192.168.1.254</span><br></pre></td></tr></table></figure><ol start="12"><li>在每周 6 的凌晨 3:15 执行 /home/shell/collect.pl，并将标准输出和标准错误输出到 /dev/null 设备，请写出 crontab 中的语句？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15 3 * * 6 sh &#x2F;home&#x2F;shell&#x2F;collect.pl  &gt; &#x2F;dev&#x2F;null  2&gt;&amp;1</span><br></pre></td></tr></table></figure><p>注：每一个命令的执行肯定都会有成功或者失败，系统默认 1 是 stdout 标准输出，2 是 stderr 标准错误，&amp; 的含义是等同。2&gt;&amp;1 的意思就是将错误的信息重定向输出的地方跟 1 一样，都是去空设备文件。</p><ol start="13"><li>在 11 月份内，每天的早上 6 点到 12 点中，每隔 2 小时执行一次 /usr/bin/httpd.sh 怎么实现 ?</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br><span class="line">1 6-12&#x2F;2 * 11 *  bash &#x2F;usr&#x2F;bin&#x2F;httpd.sh</span><br></pre></td></tr></table></figure><p>crontab、at 这种计划任务命令也是面试高频题目，crontab 一共有 5个 <code>*</code>，分别表示 “分钟”、“小时”，“日期”、“月份”、“星期几”。</p><p>基本的结构要明白，而且 “当大数有条件，小数任意” 的情况下，小数不要用 <code>*</code>，用 0 or 1。</p><p>如果这道题写成 <code>* 6-12/2 * 11 * bash /usr/bin/httpd.sh</code>，你的 Apache会很爽，它会在满足条件的情况下每一分钟都启动一下。</p><ol start="14"><li>匹配 AAA 文本中的 key 并打印出该行及下面的 5 行？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep -A 5 key AAA</span><br></pre></td></tr></table></figure><p>注：-A 是查找关键词下面的行，-B 是查找关键词上面的行，-C 是上下的行，注意这里是 grep，而不是 find。</p><ol start="15"><li>查询 AAA 文件里以 abc 结尾的行？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep &quot;abc$&quot; AAA</span><br></pre></td></tr></table></figure><p>注：这里不是 grep “abc$” | AAA，这里没有 “|” 的，要注意。</p><ol start="16"><li>打印出 AAA 文件第 1 到第 3 行？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ head -3 AAA</span><br></pre></td></tr></table></figure><p>也可以用 sed 命令来实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sed -n &#39;1,3p&#39; AAA</span><br></pre></td></tr></table></figure><ol start="17"><li>查询 AAA 里面空行的所在行号？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep -n &quot;^$&quot; AAA</span><br></pre></td></tr></table></figure><p>注意: grep -n 和 cat -n 这两个输出结果的区别。</p><ol start="18"><li>利用 sed 命令将 test.txt 中所有的回车替换成空格？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sed -e &quot;s&#x2F;\n&#x2F; &#x2F;g&quot; test.txt</span><br></pre></td></tr></table></figure><p>注：sed的 -e 参数是指多重编辑，也就是说可以 <code>sed -e ... -e .... -e....</code> 一次性完成三个动作。</p><ol start="19"><li>使用 ab 命令进行 100000 次请求，同时每秒 40 次并发的频率访问 <a href="http://www.123.com/AAA.txt" target="_blank" rel="noopener">http://www.123.com/AAA.txt</a></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ab -n 100000 -c 40 http:&#x2F;&#x2F;www.123.com&#x2F;AAA.txt</span><br></pre></td></tr></table></figure><p>注： ab 命令是 Apache 自带的，同一个 IP 地址并发的访问网站的同一个内容其实是一个隐患。但是现在用路由器上网的情况满地走，所以优化网页的内容是码农的责任，但是适当的缩小准许并发范围是运维人员应该掌握的。</p><ol start="20"><li>按照以下要求配置一个防火墙规则</li></ol><p>a. 对所有地址开放本服务器的80端口、22端口、10~21端口。<br>b. 其他机器可以用ping命令来探测本服务器的链接情况<br>c. 其他没有被准许的端口将禁止访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -I INPUT -p tcp -dport 80 -j ACCEPT</span><br><span class="line">$ iptables -I INPUT -p tcp -dport 22 -j ACCEPT</span><br><span class="line">$ iptables -I INPUT -P tcp -dport 10:21 -i ACCEPT</span><br><span class="line">$ iptables -I INPUT -p icmp -j ACCEPT</span><br><span class="line">$ iptables -I INPUT -j REJECT</span><br></pre></td></tr></table></figure><p>iptables 也是面试考察的一个重点内容。</p><p>iptables 的内容主要包括 “四表+五链”，不过具体问道哪四表哪五链的可能性很小，倒是这种结合实际情况直接让写一连串的规则考题蛮常见的。这道题很基础，写 iptables 有点在 CCNP 里写 ACL 控制访问列表的意思。</p><ol start="21"><li>top 和 ps 命令在进程占有资源率的统计方式有什么不同？</li></ol><p>ps 命令是显示在执行 ps 这个命令时刻所有进程的情况，而 top 是动态的监控进程的情况。</p><p>top 命令显示系统总的统计信息，比如时间、CPU 情况、 内存状态和分区信息等等。</p><p>ps -ef 这个是一个比较常见的搭配方式，-e 是所有进程，-f 是文件之间的关系。</p><p>ps -aux 也是很常用的，意思是显示包含其他使用者的进程。ps 命令也可以搭配 -more 和管道符使用，也可以搭配输出重定向。</p><p>top -n 2 指的是更新两次之后就停；top -d 3 指的是更新周期是三秒；top -p 574 指的是显示 pid 为 574 的进程。top 状态下按 b 是显示高亮。</p><ol start="22"><li>inode 存储了哪些东西？目录名，文件名存在哪里？</li></ol><p>inode 存储了文件大小、user id、group id、文件的读写执行权限、软连接硬链接被引用的次数、时间戳、block 的位置。唯独没有文件名！！！</p><p>目录名、文件名存在目录项里。</p><p>ls -i 这个是显示 inode 号码的查询方法。</p><p>stat 命令这个可以查询 inode 信息，使用方法为 stat AAA 即可。</p><ol start="23"><li>如何查看 HTTP 的并发请求数与其 TCP 连接状态</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -n | awk &#39;&#x2F;^tcp&#x2F; &#123;++b[$NF]&#125; END &#123;for(a in b) print a, b[a]&#125;&#39;</span><br></pre></td></tr></table></figure><ol start="24"><li>如何用嗅探 80 端口的访问最多的 IP</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#39;&#123;print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4&#125;&#39; | sort | uniq -c | sort -nr |head -10</span><br></pre></td></tr></table></figure><ol start="25"><li>如何查看当前系统每个 IP 的连接数</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -n | awk &#39;&#x2F;^tcp&#x2F; &#123;print $5&#125;&#39;| awk -F: &#39;&#123;print $1&#125;&#39; | sort | uniq -c | sort -rn</span><br></pre></td></tr></table></figure><ol start="26"><li>ps aux 命令中的 VSZ 代表什么意思？ RSS 代表什么意思？</li></ol><p>VSZ：虚拟内存集，进程所占用的虚拟内存的大小<br>RSS：实际内存集，进程所占用的实际内存的大小</p><ol start="27"><li>符号链接与硬链接的区别</li></ol><p>硬链接是复制，享用同一个 inode，不能跨分区，不能连目录，a 变 b 也变，但是 a 删 b 不删。<br>符号链接就是 -s，不享用同一个 inode，可以跨分区可以连目录，等于快捷方式。</p><p>28 如何检测并修复 /dev/hda5</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ e2fsck -p &#x2F;dev&#x2F;hda5</span><br></pre></td></tr></table></figure><p>如果要求是检查 /dev/hda5 是否正常，如果有异常便自动修复，并且设定若有问答均回答[是]，那么语句就是 e2fsck -a -y /dev/hda5</p><ol start="29"><li>显示 /etc/inittab 中以 # 开头，且后面跟了一个或者多个空白字符，而后又跟了任意非空白字符的行</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep &#39;^# \&#123;1,\&#125;[^ ]&#39; &#x2F;etc&#x2F;inittab</span><br></pre></td></tr></table></figure><ol start="30"><li>显示 /etc/inittab 中包含了 : 一个数字 :(即两个冒号中间一个数字)的行</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep &#39;\:[1-9]\&#123;1\&#125;\:&#39; &#x2F;etc&#x2F;inittab</span><br></pre></td></tr></table></figure><ol start="31"><li>统计 /data/mysql 目录里的普通文件个数</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ find &#x2F;data&#x2F;mysql&#x2F; -type f|wc -l</span><br></pre></td></tr></table></figure><ol start="32"><li>写一个脚本，实现批量添加 20 个用户，用户名为 user1-20，密码为 user 后面跟 5 个随机字符</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#description: useradd</span><br><span class="line">for i in &#96;seq -f&quot;%02g&quot; 1 20&#96;;do</span><br><span class="line">    useradd user$i</span><br><span class="line">    echo &quot;user$i-&#96;echo $RANDOM|md5sum|cut -c 1-5&#96;&quot;|passwd –stdinuser$i &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ol start="33"><li>写一个脚本，实现判断 192.168.1.0/24 网络里，当前在线的IP有哪些</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">for ip in &#96;seq 1 255&#96;</span><br><span class="line">  do</span><br><span class="line">    &#123;</span><br><span class="line">     ping -c 1 192.168.1.$ip &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br><span class="line">     if [ $? -eq 0 ]; then</span><br><span class="line">          echo 192.168.1.$ip UP</span><br><span class="line">     else</span><br><span class="line">          echo 192.168.1.$ip DOWN</span><br><span class="line">     fi</span><br><span class="line">   &#125;&amp;                    #多进程启动</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ol start="34"><li>写一个脚本，判断一个指定的脚本是否是语法错误；如果有错误，则提醒用户键入 Q 或者 q 无视错误并退出其它任何键可以通过 vim 打开这个指定的脚本</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">read -p &quot;please input check script-&gt;&quot; file</span><br><span class="line">if [ -f $file ]; then</span><br><span class="line">    sh -n $file &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">    read -p “You input $file syntax error,[Type q to exit or Type vim toedit]” answer</span><br><span class="line">    case $answer in</span><br><span class="line">        q | Q)</span><br><span class="line">            exit 0;;</span><br><span class="line">        *）</span><br><span class="line">            vim $file;;</span><br><span class="line">    esac</span><br></pre></td></tr></table></figure><ol start="35"><li>如何执行历史记录里的第 505 条命令</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ !505</span><br></pre></td></tr></table></figure><ol start="36"><li>文件系统 ext2、ext3、ext4 的区别是啥？</li></ol><p>ext3 和 ext2 的主要区别在于 ext3 引入Journal。<br>ext2 和 ext3 的格式完全相同，只是在 ext 3 硬盘最后面有一部分空间用来存放 Journal（日志）的记录；<br>在 ext2  中，写资料到硬盘中时，先将资料写入缓存中，当缓存写满时才会写入硬盘中；<br>在 ext3 中，写资料到硬盘中时，先将资料写入缓存中，待缓存写满时系统先通知 Journal，再将资料写入硬盘，完成后再通知 Journal，资料已完成写入工作；<br>在 ext3 中，也就是有 Journal 机制里，系统开机时检查 Journal 的资料，来查看是否有错误产生，这样就快了很多；</p><p>ext4 和 ext3 的主要区别在于:首先 ext4 与 ext3 兼容,ext3 只支持 32000 个子目录，而 ext4 支持无限数量的子目录；ext3 所支持的 16TB 文件系统和最大的 2TB 的文件，而 ext4 分别支持 1EB（1,048,576TB，1EB=1024PB，1PB=1024TB）的文件系统，以及 16TB 的文件;ext3 的数据块分配策略是尽快分配，而 ext4 是尽可能地延迟分配，直到文件在 Cache 中写完才开始分配数据块并写入磁盘;ext4 允许关闭日志，以便某些有特殊需求的用户可以借此进一步提升性能等等等等。</p><ol start="37"><li>如何杀死指定的进程？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps -ef |grep 进程名 |grep -v grep|awk  &#39;&#123;print $2&#125;&#39; |xargs kill -9</span><br></pre></td></tr></table></figure><p>注意：这里 awk 后面是单引号不是双引号。</p><h3 id="linux-服务器篇">Linux 服务器篇</h3><ol><li>请写出 Web 服务器的调优要点，以 Nginx 为例。</li></ol><ul><li>尽可能的少用 HTTP，因为 HTTP 是有开销的；</li><li>尽可能的使用 CDN；</li><li>添加 Expire/Cache-Control 头，这个头是缓存用的，可以缓存图片和 Flash 那样不轻易更改的文件，减少访问时间；</li><li>启动 Gzip 压缩，这个没啥好说的了；</li><li>尽可能少的重定向，重定向是需要时间的，增加一次重定向就会多一次 Web需求；</li><li>如果可以，把 Ajax也做缓存；</li><li>减少 DNS 查询，很多网页会有外站的广告，这些广告也是会启动 DNS 查询的，所以如果不缺钱，减少这种广告；</li><li>调好服务器里的 TCP 协议栈，这个无论是 Web 服务器还是应用服务器都是必须的；</li></ul><ol start="2"><li>编写一个 Nginx 的访问控制规则，要求只准许 192.168.3.29/24 、10.1.20.6/16 、34.26.157.0/24 这些机器访问，除此之外的机器不准许访问。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location&#x2F;&#123;</span><br><span class="line">access 192.168.3.29&#x2F;24;</span><br><span class="line">access 10.1.20.6&#x2F;16;</span><br><span class="line">access 34.26.157.0&#x2F;24;</span><br><span class="line">deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>如何在 Nginx 中给 favicon.ico 和 robots.txt 设置过期时间。</li></ol><p>这里为 favicon.ico 为 99 天，robots.txt 为 7 天并不记录 404 错误日志。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">location ~(favicon.ico) &#123;</span><br><span class="line">    log_not_found off;</span><br><span class="line">    expires 99d;</span><br><span class="line">    break;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location ~(robots.txt) &#123;</span><br><span class="line">    log_not_found off;</span><br><span class="line">    expires 7d;</span><br><span class="line">    break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="4"><li>如何在 Nginx 中设定某个文件的浏览器缓存过期时间为 600 秒，并不记录访问日志</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">location ^~ &#x2F;html&#x2F;scripts&#x2F;loadhead_1.js &#123;</span><br><span class="line">    access_log off;</span><br><span class="line">    expires 600;</span><br><span class="line">    break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li>如何在 Nginx 中只允许固定 IP 访问网站，并加上密码。</li></ol><p>设定账号是 james,密码是 123456。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">printf &quot;james:$(openssl passwd -crypt 123456)\n&quot; &gt;&gt;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;passwd</span><br><span class="line">location \ &#123;</span><br><span class="line">    allow 22.27.164.25; #允许的ipd</span><br><span class="line">    deny all;</span><br><span class="line">    auth_basic “KEY”; #登陆该网页的时候，会有这个“KEY”的提示,提示只能是英文，中文不识别。</span><br><span class="line">    auth_basic_user_file &#x2F;conf&#x2F;htpasswd;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="6"><li>Web 服务器为 Nginx，如果访问服务器的 IP 地址是 203.46.97.124 的话，给他展现的主页是 /123.html,其他人就展现 index.html。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">location &#x2F; &#123;</span><br><span class="line">        if （$remote_addr &#x3D; 203.46.97.124 ) &#123;</span><br><span class="line">            rewrite ^.*$ &#x2F;123.html;</span><br><span class="line">                &#125;</span><br><span class="line">        root &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html;</span><br><span class="line">        index index.html;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><ol start="7"><li>讲述一下 cookie 和 session 的区别</li></ol><p>Cookie 机制采用的是在客户端保持状态的方案，而 Session 机制采用的是在服务器端保持状态的方案。</p><p>Cookie 不是很安全，别人可以分析存放在本地的 Cookie 并进行 Cookie 欺骗,考虑到安全应当使用 Session。</p><p>Session 会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用 COOKIE。</p><p>单个 Cookie 保存的数据不能超过 4K，很多浏览器都限制一个站点最多保存 20 个 Cookie。</p><p>Cookie 如果没有设置生存时间，那么关闭浏览器的瞬间，Cookie 就会消失，下一次登陆依旧要输入账号密码，Cookie 默认是存储在硬盘里而不是内存里，如果是设置了生存时间，那么就会保存在内存里，下一次继续使用。</p><p>Session 有一个 Session ID，要是服务器能查询的到 ID，就会按这个 ID 号的内容体现数据，如果查询不到就会新建一个 ID，Session ID 是可以用 Cookie 的形式保存的。</p><ol start="8"><li>写一个脚本自动备份 MySQL 并删除 30 天前的备份文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#Description:Auto backup mysql</span><br><span class="line">MYSQLDB&#x3D;Test1</span><br><span class="line">MYSQLUSR&#x3D;Username</span><br><span class="line">MYSQLPW&#x3D;PASSWORD    #定义账号、密码和需要备份的数据库名</span><br><span class="line">BAKDIR&#x3D;&#x2F;data&#x2F;backup&#x2F;mysql&#x2F;$(date +%Y-%m-%d)   </span><br><span class="line">if[ $UID -ne 0 ];then    #UID是USERID的意思，0 是ROOT的ID号</span><br><span class="line">    echo This script must use administrator or root user ,please exit!    </span><br><span class="line">#提示当前账户不是ROOT，需要切换成ROOT用户</span><br><span class="line">    sleep 2  </span><br><span class="line">exit 0  </span><br><span class="line">fi  </span><br><span class="line"></span><br><span class="line">if [ ! -d $BAKDIR ];then  </span><br><span class="line">mkdir -p $BAKDIR  </span><br><span class="line">else  </span><br><span class="line">echo This is $BAKDIR exists ,please exit ….  </span><br><span class="line">sleep 2  </span><br><span class="line">exit  </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;mysqldump -u$MYSQLUSR -p$MYSQLPW -d $MYSQLDB &gt;&#x2F;data&#x2F;backup&#x2F;mysql&#x2F;&#96;date +%Y-%m-%d&#96;&#x2F;www_db.sql  </span><br><span class="line">cd $BAKDIR ; tar -czf  www_mysql_db.tar.gz *.sql  </span><br><span class="line">cd $BAKDIR ;find  . -name &quot;*.sql&quot; |xargs rm -rf[ $? -eq 0 ]&amp;&amp;echo &quot;This &#96;date +%Y-%m-%d&#96; RESIN BACKUP is SUCCESS&quot;</span><br><span class="line">cd &#x2F;data&#x2F;backup&#x2F;mysql&#x2F; ;find . -mtime +30 |xargs rm -rf</span><br></pre></td></tr></table></figure><ol start="9"><li>SELECT id,name FROM test1 和 SELECT id name FROM test1 这两个语句有什么区别？</li></ol><p>第一个语句会出现两个列，第二个只有一个列，列的内容是 id 的内容，但是列的名称是 name，也就是说第二句话其实就是 “SELECT id AS name FROM test1”。</p><ol start="10"><li>如果想把 test1 表格里满足 age 大于等于 30 的 username 都迁移到 test2 表格里的 username 列，需要什么命令？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT test2(username) SELECT username FROM test1 WHERE age &gt;&#x3D;30;</span><br></pre></td></tr></table></figure><p>注： 这种方法要注意，新表/旧表有更新的时候，旧表/新表不随之更新。因为没有链接，仅仅是一个一次性的复制而已。</p><ol start="11"><li>列举出 A 表里满足价格 (price) 大于 A 表里所有货品平均价格的 id,name,age。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT id,name,age FROM A WHERE &gt; (SELECT AVG(price) FROM A)</span><br></pre></td></tr></table></figure><ol start="12"><li>请根据你的理解，简述负载均衡的实现方式</li></ol><p>负载均衡主要分为两种：硬件（F5）和软件（NGINX、Haproxy、LVS），硬件效果比较牛逼，它是把 4-7 层的负载均衡功能做到一个硬件里面，但是价格昂贵最近用的越来越少了。<br>软件的负载均衡又分两种：四层和七层：四层是在 IP/TCP 协议栈上把网络包的 IP 地址和端口进行修改，达到转发的目的；七层就是在应用层里把 HTTP 请求、URL 等具体的应用数据发送到具体的服务器上。四层的效率比七层的高，四层一般安排在架构的前端，七层一般就是在具体服务器的前端。软件负载均衡比较常见的几个调度分配方式如下：</p><ul><li>轮询：访问请求依序分发给后端服务器；</li><li>加权轮询：访问请求依序分发后端服务器，服务器权重越高被分发的几率也越大；</li><li>最小连接数：将访问请求分发给当前连接数最小的一台后端服务器，服务器权重越高被分发的几率也越大。</li></ul><ol start="13"><li>HTTP 一般是无状态的，怎么让它变成有状态的？</li></ol><p>HTTP 协议跟 IP 协议、UDP 协议一样都是无状态的，HTTP 的无状态意思是每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况。补充一下，TCP 是有状态的，它的请求并不独立，它通过包头的一些控制字段来分别包的关系，这里可以自行脑补一下三次握手的图。</p><p>那么 HTTP 是无状态的这一点是无法改变的，那么要变得有状态，就需要引入 Cookie 和 Session，通过这两个机制去实现一个有状态的 Web 应用。用一个表达式可以这么理解：Web 应用 = HTTP 协议+ Session、Cookies 等状态机制+其他辅助的机制。</p><ol start="14"><li>多进程和多线程的区别，你更喜欢用哪一个，为什么？</li></ol><p>多进程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个子进程与客户端建立连接开始交互，每一个子进程之间互相独立不受干扰，完成任务就收回资源，内存等也会被回收；<br>多线程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个线程与客户端建立连接开始交互,多个线程位于同一个进程内，可以互相访问同样的内存等资源，彼此之间会有影响；</p><p>我个人更喜欢多进程，因为简单粗暴！</p><ol start="14"><li>LVS 脑裂如何解决，为什么会产生双 Master？</li></ol><p>产生双 Master 的原因：1）服务器开启了 Iptables 防火墙，阻碍了心跳信息传输；2）服务器心跳网卡等信息写错了，导致心跳信息发送失败；3）心跳方式不搭配，心跳广播冲突；4）软件出 Bug 了；</p><p>要排除脑裂问题，第一步是检查 Iptables,很可能是由于 Iptables 把心跳信息隔断了，重要的话不说三遍也重要！</p><ol start="15"><li>为什么 TCP 比 UDP 的信息更加可靠？详细说说 TCP 滑动窗口原理，窗口的大小如何确定。</li></ol><p>TCP 可靠性由三个机制保证：1. 序号（TCP报文的序号）2. 确认（ACK机制）3. 重传（超时或者冗余的 ACK）</p><p>TCP 在传输的时候，因为接受方 B 能力有限，不可能一口气吃下所有发送方 A 所有的数据流信息，所以 B 要限制 A 每次发送的字节数量，并且一一确认，确认了之后 A 才可以继续发。这样的话，A 的在发送数据流的时候就会有四种形态：</p><p>1).已发送已确认；<br>2).已发送但没被确认；<br>3).未发送但是接受方已经准备好空间来接收；<br>4).未发送但是接受方尚未准备好空间来接收；</p><p>随着数据流的传输，这个形态是会时刻发生变化的，通过接受方 B 返回的确认信息来改变 2 的大小，同时 B 也会根据一次关于发送方A要发送多少字节确认自己的空间来改变 3 的大小。</p><ol start="16"><li>简单说说 CDN 的工作原理？</li></ol><p>CDN 的工作原理：通过权威 DNS 服务器来实现优质节点的选择，通过缓存来减少源站的压力。</p><p>IT界有个很有名的比喻，正向代理是找马云借钱，反向代理是给 10086 打电话，而反向代理就是 CDN 的实现原理雏形的一部分。</p><ol start="17"><li>请描述 DNS 查询的过程，为什么要有 CNAME 而不是直接返回一个 CDN 边缘节点的 IP。</li></ol><p>DNS 主要是基于 UDP 协议的。DNS 查询的过程以 <a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a> 为例：</p><ul><li>在浏览器键入 <a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a>,其实真正 DNS 协议里用到的是 <a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a>. 最后还有一个点，可能是因为美观等原因，一般都不显示;</li><li>查询本地缓存（host 文件或者是浏览器的缓存）中有没有该域名对应的记录，有的话就直接用了;</li><li>向运营商的 DNS 服务器发起 DNS 解析的请求，一般称运营商的 DNS 服务器为 Local DNS;</li><li>Local DNS 会查询本地的缓存，Local DNS 设置的缓存时间是有讲究的，过长过短都不好。</li><li>Local DNS 如果没有缓存，会把域名从右往左扫描，依次请求对应的服务器，例如对于域名 <a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a>.，先去问负责 . 的根域名服务器，就是传说中全球只有几台的那些服务器，他们会答复 .com 是谁管理的，然后 Local DNS 又去找管理 .com 的服务器（假设名字为 S1），去问问taobao.com是谁管，一般来说，在S1查到的记录是一条cname记录（阿里毕竟大公司，自己管理自己旗下的域名），然后就转到了阿里自己的DNS服务器上来了，一般称之为权威服务器；</li><li>权威服务器是阿里自己建的，然后根据公司内部的一些配置查到 <a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a>. 对应的服务器是谁，返回一个IP地址；</li><li>Local DNS 缓存这个 IP 地址，并且回复浏览器；</li><li>浏览器和对应的 IP 地址的服务器建立 TCP 连接，发送 HTTP 报文；</li></ul><p><a href="https://rorschachchan.github.io/images/cdnyuanli.png" target="_blank" rel="noopener">https://rorschachchan.github.io/images/cdnyuanli.png</a></p><p>DNS 查询过程图解</p><p>至于说为什么不返回 CDN 边缘节点 IP，是因为使用 CNAME 记录可以很方便地变更 IP 地址，毕竟服务商掌握着 IP 的生杀大权，哪一天需要换 IP 了，在这方面很不方便。</p><ol start="18"><li>什么是乐观锁，什么是悲观锁？</li></ol><p>悲观锁 Pessimistic Lock, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。这样别人想拿这个数据就会 block 直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。</p><p>乐观锁 Optimistic Lock, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition 机制的其实都是提供的乐观锁。</p><p>两种锁各有优缺点，不可认为一种好于另一种。像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行 Retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。</p><ol start="19"><li>什么是脏读、不可重复读、幻读？</li></ol><p>脏读又称无效数据的读出，是指在数据库访问中，事务 T1 将某一值修改，然后事务 T2 读取该值，此后 T1 因为某种原因撤销对该值的修改，这就导致了 T2 所读取到的数据是无效的。</p><p>不可重复读是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。比如事务 T1 读取某一数据，事务 T2 读取并修改了该数据，T1 为了对读取值进行检验而再次读取该数据，便得到了不同的结果。</p><p>幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。</p><ol start="20"><li>简述一下 A 记录与 NS 记录的区别</li></ol><ul><li>A 记录是名称解析的重要记录，它用于将特定的主机名映射到对应主机的 IP 地址上。你可以在 DNS 服务器中手动创建或通过 DNS 客户端动态更新来创建。</li><li>NS 记录此记录指定负责此 DNS 区域的权威名称服务器。</li><li>A 记录和 NS 记录的区别是，A 记录直接给出目的 IP，NS 记录将 DNS 解析任务交给特定的服务器，NS 记录中记录的 IP 即为该特定服务器的 IP 地址。</li><li>NS 记录优先于 A 记录，A 记录优先于 CNAME 记录。</li></ul><ol start="21"><li>MySQL 的 BinLog 有几种形式？</li></ol><p>MySQL 的 BinLog 有以下几种模式：</p><ul><li>Statement Level模式</li></ul><p>简介：每一条会修改数据的 SQL 都会记录到 Master 的 Bin-Log 中。Slave 在复制的时候 SQL 线程会解析成和原来 Master 端执行过的相同语句来执行。<br>优点：不需要记录每一行数据的变化，减少 Bin-Log 的日志量，节约 IO 以提高性能。因为他只记录在 Master 上所执行语句的细节，以及执行语句时候的上下文的信息。<br>缺点：很多新功能的加入在复制的时候容易导致出现问题。</p><ul><li>Row Level模式</li></ul><p>简介:日志中会记录成每一行数据被修改的模式，然后再 Slave 端在对相同的数据进行修改。<br>优点：在 Row Level模式下，Bin-Log中可以不记录执行的 SQL 语句的上下文相关的信息。仅仅只需要记录那一条记录被修改了。所以 Row Level 的日志内容会非常清楚记录下每一行数据修改的细节，非常容易理解。而且不会出现某些特点情况下的存储过程，或 Function 以及Triggeer 的调用和触发无法被正确复制的问题。<br>缺点：所有执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，可能会产生大量的日志。</p><ul><li>Mixed(前两种的混合模式)</li></ul><p>根据执行的每一条具体的 SQL 语句来区分对待记录日志的形式，即 MySQL 决定什么时候写 Statement 格式的，什么时候写 Row 格式的 Binlog。</p><ol start="22"><li>如何在线正确清理 MySQL 的 Binlog？</li></ol><ul><li>手动删除方法</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 首先查看主从库正在使用的binlog文件名称 </span><br><span class="line">show master(slave) status\G</span><br><span class="line"># 删除之前一定要备份</span><br><span class="line">purge master logs before&#39;2017-09-01 00:00:00&#39;; </span><br><span class="line"># 删除指定时间前的日志</span><br><span class="line">purge master logs to&#39;mysql-bin.000001&#39;;</span><br></pre></td></tr></table></figure><ul><li>自动删除的方法</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 通过设置 binlog 的过期时间让系统自动删除日志</span><br><span class="line"># 查看过期时间与设置过期时间</span><br><span class="line">show variables like &#39;expire_logs_days&#39;; </span><br><span class="line">set global expire_logs_days &#x3D; 30;</span><br></pre></td></tr></table></figure><p>Binlog 记录了数据中的数据变动，便于对数据的基于时间点和基于位置的恢复。但是也要定时清理，不然越来越大。</p><ol start="23"><li>简述 MySQL 主从复制原理及配置主从的完整步骤。</li></ol><p>MySQL 主从是一个异步过程（网络条件上佳的话，同步效果几乎是实时），原理就是从库得到主库的 BinLog，然后执行这个 BinLog 的内容，达到两边数据库数据一致的目的。具体工作步骤如下：</p><ul><li>主mysql服务器将数据库更新记录到binlog中，使用自己的log dump线程将binlog先读取然后加锁，再发送到从库，在从库当读取完成，甚至在发动给从节点之前，锁会被释放；</li><li>当从库上执行start slave命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的binlog。I/O线程接收到主节点binlog dump进程发来的更新之后，保存在本地relay log中。</li><li>从库此时还有一个SQL线程，它负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。</li></ul><p><a href="https://rorschachchan.github.io/images/mysql-sock9.png" target="_blank" rel="noopener">https://rorschachchan.github.io/images/mysql-sock9.png</a></p><p>切记！在从库上使用 show slave status\G；看到结果里的 Slave_IO_Running:Yes 和 Slave_SQL_Running:Yes，才算是同步成功，两个 YES 缺一不可。</p><p>注意： MySQL 只读实例的 Binlog 日志是没有记录更新信息的，所以它的 Binlog 无法使用。</p><ol start="24"><li>如何理解 MySQL 里最大连接数和请求数之间的关系</li></ol><p>假设某个数据库的最大连接数是 1000，并不是指最多只能支持 1000 个访问。因为数据库与应用之间肯定会隔着中间件，这个中间件的连接池会管理链接，一般如果代码写的好、事物控制得当，一个事物完成连接会被连接池收回重复利用。所以不是说一个用户登录你的系统或网站就一直占用着，一个连接也可以包含多次请求。</p><ol start="25"><li>MySQL 出现 IOPS 过高，应该如何处理？</li></ol><p>IOPS (Input/Output Operations Per Second)，即每秒进行读写（I/O）操作的次数。IOPS 是指存储每秒可接受多少次主机发出的访问，主机的一次 IO 需要多次访问存储才可以完成。IOPS 过高比较普遍的原因是实例内存满足不了缓存数据或排序等需要，导致产生大量的物理 IO 或者是查询执行效率低，扫描过多数据行。</p><ol start="26"><li>Sort_Buffer_Size 是什么参数？设置它对服务器性能有何影响？</li></ol><p>Sort_Buffer_Size 是一个 connection 级参数，在每个 connection 第一次需要使用这个 Buffer 的时候，一次性分配设置的内存。Sort_Buffer_Size 并不是越大越好，由于是 Connection 级的参数，过大的设置+高并发可能会耗尽系统内存资源。Sort_Buffer_Size 超过 256KB 的时候，MySQL 就会使用 mmap() 而不是 malloc() 来进行内存分配，导致性能损耗、效率降低。</p><p>如果列长度大于 max_length_for_sort_data 的参数值的话，iowait 会增加, 响应时间明显变长。此时通过 show processlist 查看,发现有很多 session 在处理 sort 操作,此时需要适当调大 max_length_for_sort_data 的参数值。</p><ol start="27"><li>如何从 MySQL 全库备份中恢复某个库和某张表</li></ol><p>主要用到的参数是 –one-database 简写 -o 的参数，举个例子：</p><p>全库备份</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -uroot -p --single-transaction -A --master-data&#x3D;2 &gt;dump.sql</span><br></pre></td></tr></table></figure><p>只还原 erp 库的内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -uroot -pMANAGER erp --one-database &lt;dump.sql</span><br></pre></td></tr></table></figure><p>从全库备份中抽取出 t 表的表结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sed -e&#39;&#x2F;.&#x2F;&#123;H;$!d;&#125;&#39; -e &#39;x;&#x2F;CREATE TABLE &#96;t&#96;&#x2F;!d;q&#39; dump.sql</span><br></pre></td></tr></table></figure><p>从全库备份中抽取出 t 表的内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep&#39;INSERT INTO &#96;t&#96;&#39; dump.sql</span><br></pre></td></tr></table></figure><ol start="28"><li>你们数据库是否支持 Emoji 表情，如果不支持，如何操作？</li></ol><p>如果是 utf8 字符集的话，需要升级至 utf8_mb4 方可支持。</p><ol start="29"><li>mysqldump 备份时，-–master-data 选项的作用是什么？还用过其他的参数么？</li></ol><p>–master-data 选项的作用就是将二进制的信息写入到输出文件中，即写入备份的 SQL 文件中。</p><ul><li>–master-data=2 表示在 dump 过程中记录主库的 Binlog 和 Pos 点，并在 dump 文件中注释掉这一行；</li><li>–master-data=1 表示在 dump 过程中记录主库的 Binlog 和 Pos 点，并在 dump 文件中不注释掉这一行，即恢复时会执行；</li><li>–dump-slave=2 表示在 dump 过程中，在从库 dump，mysqldump 进程也要在从库执行，记录当时主库的 Binlog 和 Pos 点，并在 dump 文件中注释掉这一行；</li><li>–dump-slave=1 表示在 dump 过程中，在从库 dump，mysqldump 进程也要在从库执行，记录当时主库的 Binlog 和 Pos 点，并在 dump 文件中不注释掉这一行；</li></ul><p>注意：在从库上执行备份时，即 –dump-slave=2，这时整个 dump 过程都是 stop io_thread 的状态。加了 --single-transaction 就能保证 innodb 的数据是完全一致的，而 MyIsam 引擎无法保证（因为 MyIsam 压根就不支持事务），要保证 MyIsam 引擎数据一致必须加 --lock-all-tables。</p><ol start="30"><li>什么是数据库事务，事务有哪些特性？</li></ol><p>一个数据库事务通常包含对数据库进行读或写的一个操作序列。它的存在包含有以下两个目的：</p><ul><li>为数据库操作提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。</li><li>当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。</li></ul><p>它的特性如下：</p><ul><li>原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。</li><li>一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。</li><li>隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。</li><li>持久性（Durability）：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。</li></ul><p>事务的原子性与一致性缺一不可。</p><ol start="31"><li>数据表 student 有 id,name,score,city 字段，其中 name 中的名字可有重复，需要消除重复行,请写 SQL 语句。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select distinct name from student</span><br></pre></td></tr></table></figure><p>注意：单独的 distinct只能放在开头，否则就报语法错误。</p><ol start="32"><li>在 Nginx 中，如何使用未定义的服务器名称来阻止处理请求?</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Server &#123;</span><br><span class="line">listen 80;</span><br><span class="line">server_name &quot; &quot;;</span><br><span class="line">return 444;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，服务器名被保留为一个空字符串，它将在没有主机头字段的情况下匹配请求，而一个特殊的 Nginx 的非标准代码 444 被返回，从而终止连接。</p><ol start="33"><li>Nginx 中如何实现 http 跳转 https？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen [::]:80;#支持ipv6</span><br><span class="line">    server_name www.test.com;</span><br><span class="line">    return 301 https:&#x2F;&#x2F;$server_name$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="34"><li>在 Nginx 中如果想配置指定域为信任，其他的域名被排除，应该如何配置？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name b.com;</span><br><span class="line">    location &#x2F;&#123;</span><br><span class="line">                if ( $http_referer ~* (a.com|b.com|c.com)  ) &#123; </span><br><span class="line">        Access-Control-Allow-Origin: *</span><br><span class="line">                &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>35 CDN 缓存命中率下降的因素有哪些？</p><ul><li>客户是否刷新过缓存？</li></ul><p>如果刷新缓存，有可能会短时间表现命中率下降。特别说明下：CDN 的 URL 或者目录刷新是清除 CDN 缓存的动作（这个比较容易理解偏差）</p><ul><li>带宽是否突增？并且访问的都是新的 URL？</li></ul><p>带宽突增或者访问的新 URL 较多，会导致 CDN 节点回源较多，命中率会表现有下降趋势。</p><ul><li>源站是否有新内容发布？</li></ul><p>CDN 节点访问新内容，导致 CDN 节点回源较多，命中率会表现有下降趋势。</p><ul><li><p>源站是否出现过异常导致 5XX 和 4XX 增加，由于 5XX 和 4XX 不缓存，会表现命中率下降。</p></li><li><p>源站的访问 URL 的 Header 参数，或者在 CDN 控制管理后台的缓存配置规则是否改变过？</p></li></ul><p>缓存时长的调整，有可能会带来命中率的变化。</p><ol start="36"><li>Docker 的 exec 与 attach 命令有啥区别？</li></ol><p>attach 开启一个和正在运行的进程交互的终端，如果该进程结束，原 docker container 的进程也会结束。<br>exec 可以开启多个终端实例，exec -i /bin/bash，由此可见 exec 其实是在运行中的容器中执行一个命令。</p><ol start="37"><li>Docker 的 CMD 与 ENTRYPOINT 命令有啥区别？</li></ol><p>CMD 的命令会被 Docker run 里的命令覆盖，而 ENTRYPOINT命令不会。<br>如果要覆盖 ENTRYPOINT，则在 Docker run 里添加 --entrypoint 标签来覆盖即可。<br>如果 Dockerfile 里指定了 WORKDIR，那么无论是 CMD 还是 ENTRYPOINT 命令都是在这个 WORKDIR 目录里执行。</p><ol start="38"><li>Docker 的 kill 和 stop 命令有啥区别？</li></ol><p>stop 是优雅退出，先发送 SIGTERM 信号，在一段时间之后（10s）再发送 SIGKILL 信号。Docker 内部的应用程序可以接收 SIGTERM 信号，然后做一些退出前工作，比如保存状态、处理当前请求等。<br>kill 是暴力退出，即发送 SIGKILL 信号，应用程序直接退出。</p><ol start="39"><li>假设有一个 AAA 的容器，现在需要备份它的挂载卷 /DATA 里的数据，请问如何操作？</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --volumes-form A -v &#x2F;tmp:&#x2F;backup --name BACKUP ubuntu tar cvf &#x2F;backup&#x2F;A.tar &#x2F;DATA</span><br></pre></td></tr></table></figure><p>上面这个语句新建立一个叫 BACKUP 的容器，它与 A 容器挂载情况相同（即都是挂载 /DATA）同时将本地的 /tmp 挂载到容器的 /backup。在容器生成的时候，执行了tar cvf /backup/A.tar /DATA 将 DATA 文件夹的内容进行了打包，又由于 /tmp 已经与 /backup 挂载，所以就可以直接从宿主机上的 /tmp 里得到 A.tar 了。</p><h3 id="参考文档">参考文档</h3><ol><li><a href="http://t.cn/Ai93uIum" target="_blank" rel="noopener">http://t.cn/Ai93uIum</a></li><li><a href="http://t.cn/Ai91yzEt" target="_blank" rel="noopener">http://t.cn/Ai91yzEt</a></li><li><a href="http://t.cn/Ai91tykl" target="_blank" rel="noopener">http://t.cn/Ai91tykl</a></li><li><a href="http://t.cn/Ai91x5ik" target="_blank" rel="noopener">http://t.cn/Ai91x5ik</a></li><li><a href="http://t.cn/Ai91pxxs" target="_blank" rel="noopener">http://t.cn/Ai91pxxs</a></li><li><a href="http://t.cn/Ai9r1DvO" target="_blank" rel="noopener">http://t.cn/Ai9r1DvO</a></li><li><a href="http://t.cn/Ai9douNc" target="_blank" rel="noopener">http://t.cn/Ai9douNc</a></li><li><a href="http://t.cn/Ai9dHvb9" target="_blank" rel="noopener">http://t.cn/Ai9dHvb9</a></li><li><a href="http://t.cn/Ai9dnJ2z" target="_blank" rel="noopener">http://t.cn/Ai9dnJ2z</a></li><li><a href="http://t.cn/Ai9d1sJN" target="_blank" rel="noopener">http://t.cn/Ai9d1sJN</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Linux-基础知识篇&quot;&gt;Linux 基础知识篇&lt;/h3&gt;
&lt;p&gt;这一套题算是简单的，考的内容基本是 Linux 基本原理、查找命令、计划命令、防火墙设置等，以上这四点基本算是初级内容。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;说说 Linux 启动大致过程？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;加载 BIOS–&amp;gt;读取 MBR–&amp;gt;Boot Loader–&amp;gt;加载内核–&amp;gt;用户层 Init 依据 Inittab 文件来设定系统运行的等级(一般 3 或者 5，3 是多用户命令行，5 是图形界面)–&amp;gt;Init 进程执行 rc.syninit–&amp;gt;启动内核模块–&amp;gt;执行不同级别运行的脚本程序–&amp;gt;执行 /etc/rc.d/rc.local (本地运行服务)–&amp;gt;执行 /bin/login,就可以登录了。&lt;/p&gt;
&lt;p&gt;基本看过 「鸟哥 Linux 私房菜」的就能知道，这是第五章管理员的第一个内容。&lt;/p&gt;
&lt;p&gt;这道题可以扩展一下：Init 系统运行等级一共有几种，每一种都是什么？&lt;/p&gt;
&lt;p&gt;0：关机，只要是0就不能开机&lt;br&gt;
1：单用户模式，不能被远程登陆&lt;br&gt;
2：多用户不能上网模式&lt;br&gt;
3：多用户可以上网模式&lt;br&gt;
4：未使用&lt;br&gt;
5：有图形的 Linux&lt;br&gt;
6：重启，只要是 6 就会不断的重启,子子孙孙无穷匮焉的重启&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="运维" scheme="https://www.hi-linux.com/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>Linux 爱好者周刊 ( 第 1 期 )</title>
    <link href="https://www.hi-linux.com/posts/43626.html"/>
    <id>https://www.hi-linux.com/posts/43626.html</id>
    <published>2020-05-16T01:00:00.000Z</published>
    <updated>2020-05-16T04:33:24.280Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。</p><p>欢迎投稿或推荐你自己的项目，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a> 。如果你对周刊有什么建议和意见，或者想与大家一起讨论技术问题，也可以戳「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247487968&amp;idx=2&amp;sn=476c03c6edfae6907020c23094496791&amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;token=1973230270&amp;lang=zh_CN#rd" target="_blank" rel="noopener">这里</a>」加入技术交流群。</p><h3 id="业界资讯">业界资讯</h3><p>1、<a href="https://www.williamlong.info/archives/5747.html" target="_blank" rel="noopener">中国设立互联网根服务器</a></p><p>近日，中国工信部官网一篇题为 “工业和信息化部关于同意中国互联网络信息中心设立域名根服务器（F、I、K、L根镜像服务器）及域名根服务器运行机构的批复” 的文章引起外界广泛关注。工信部当天的消息称，同意中国互联网络信息中心设立域名根服务器（F、I、K、L根镜像服务器）及成为域名根服务器运行机构，负责运行、维护和管理相关域名根服务器。</p><p>链接：<a href="https://www.williamlong.info/archives/5747.html" target="_blank" rel="noopener">https://www.williamlong.info/archives/5747.html</a></p><p>2、<a href="https://www.solidot.org/story?sid=61096" target="_blank" rel="noopener">微软正式发布 Windows Terminal 预览版</a></p><p>微软在 Microsoft Store 发布了 Windows Terminal 的预览版。</p><p>Windows Terminal 是微软上个月在开发者大会上宣布的新命令行终端，源代码发布在 GitHub 上。Windows Terminal 支持多标签、Unicode 和 UTF-8 字符、GPU 加速 DirectWrite/DirectX 文本渲染引擎，定制主题、样式和配置。更多特性详细介绍可参考<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247487033&amp;idx=1&amp;sn=2cc918c4a2f9ddf7da341e7996183872&amp;chksm=eac52f10ddb2a606ee40e98646dc8eb8b4409ef88169c6172f5b42ead00c866c4693d7a3387f&amp;token=1817029934&amp;lang=zh_CN#rd" target="_blank" rel="noopener">这里</a> 。</p><p>下载安装 Windows Terminal  需要 Windows 10 version 18362.0 及更新版本。</p><p>链接：<a href="https://www.solidot.org/story?sid=61096" target="_blank" rel="noopener">https://www.solidot.org/story?sid=61096</a></p><p><img src="https://i.loli.net/2019/07/29/5d3ebfc2aaafd80489.jpg" alt=""></p><p>3、<a href="https://www.oschina.net/news/107833/dns-over-https-ga" target="_blank" rel="noopener">谷歌宣布 DNS Over HTTPS 服务普遍可用</a></p><p>谷歌于 2009 年推出 Google Public DNS，并于 2016 年在此基础上推出 DNS Over HTTPS，这是一项实验性服务，旨在加强 DNS 的安全性，此前的服务入口是 <a href="http://dns.google.com/experimental%E3%80%82" target="_blank" rel="noopener">dns.google.com/experimental。</a></p><p>现在谷歌宣布 DoH 已经正式普遍可用，并且完全支持 RFC 8484 文档，同时继续提供对 2016 年推出的 JSON API 的支持。用户可以使用 dns.google 域中的 DoH 解析 DNS，其中包含与常规 DNS 服务相同的任播地址，如 8.8.8.8。新的访问入口是：<a href="https://dns.google/dns-query" target="_blank" rel="noopener">https://dns.google/dns-query</a> ((RFC 8484) 和 <a href="https://dns.google/resolve" target="_blank" rel="noopener">https://dns.google/resolve</a> (JSON API)。</p><p>链接：<a href="https://www.oschina.net/news/107833/dns-over-https-ga" target="_blank" rel="noopener">https://www.oschina.net/news/107833/dns-over-https-ga</a></p><p><img src="https://oscimg.oschina.net/oscnet/fe994bc0e5e401523320b7953a92696045f.jpg" alt=""></p><p>4、<a href="http://news.51cto.com/art/201906/598801.htm" target="_blank" rel="noopener">Mozilla 发布下一代移动浏览器 Firefox Preview</a></p><p>Mozilla 已于近日在 Google Play 正式上架面向 Android 的全新移动浏览器 Firefox Preview。</p><p>与现已推出与大多数浏览器所采用的 Bink 渲染引擎不同，Firefox Preview 的渲染引擎 GeckoView 由 Mozilla 自己开发，这种独立性一定程度上避免了互联网被单一的科技巨头控制。</p><p>虽然已经公开发布，不过 Mozilla 表示 Firefox Preview 仍处于测试阶段，真正的大招会憋到今年秋季再放，届时将提供更丰富的功能和更精美的界面。</p><p>链接：<a href="http://news.51cto.com/art/201906/598801.htm" target="_blank" rel="noopener">http://news.51cto.com/art/201906/598801.htm</a></p><p><img src="https://s4.51cto.com/oss/201907/01/da021001f2e94c283777ac8f67a880b8.jpg-wh_651x-s_2719880675.jpg" alt=""></p><p>5、<a href="https://www.infoq.cn/article/I_Wfu4eIJY7c52Prqoop" target="_blank" rel="noopener">OpenJDK Docker 镜像存在错误版本漏洞</a></p><p>OpenJDK 邮件列表确认，OpenJDK 的官方 Docker 镜像中包含错误标记版本号，这表明部分 JRE 应包含的安全补丁实际上并不存在。</p><p>该问题已经通过 OpenJDK 和 Debian 间的跨社区协作得以解决。该 “官方” 版本是由 Docker 和其他方制作的，因为 OpenJDK 社区没有创建镜像或生成构建。该 Docker 镜像已被下载超过一千万次。</p><p>链接：<a href="https://www.infoq.cn/article/I_Wfu4eIJY7c52Prqoop" target="_blank" rel="noopener">https://www.infoq.cn/article/I_Wfu4eIJY7c52Prqoop</a></p><p>6、<a href="https://www.oschina.net/news/107663/v-lang-source-code-released" target="_blank" rel="noopener">安全的全新编程语言 V 发布首个可用版本</a></p><p>日前，一种新的静态类型编程语言 V 语言正式开源了，并发布了首个可用版本。</p><p>据了解，V 语言全名叫：Vlang。V 语言是一个结合 Go 语言的简洁以及 Rust 的安全特性的新语言，其提供了方便、快捷、安全的编程语言和工具包，还能够很好地服务于区块链技术。</p><p>链接：<a href="https://www.oschina.net/news/107663/v-lang-source-code-released" target="_blank" rel="noopener">https://www.oschina.net/news/107663/v-lang-source-code-released</a></p><p><img src="https://raw.githubusercontent.com/vlang/v/master/examples/tetris/screenshot.png" alt=""></p><a id="more"></a><h3 id="趣站酷软">趣站酷软</h3><p>1、<a href="https://github.com/Eugeny/terminus" target="_blank" rel="noopener">Terminus</a></p><p>Terminus 是一个高度可配置的终端模拟器，适用于 Windows、macOS 和 Linux。</p><p>项目地址: <a href="https://github.com/Eugeny/terminus" target="_blank" rel="noopener">https://github.com/Eugeny/terminus</a></p><p><img src="https://raw.githubusercontent.com/Eugeny/terminus/master/docs/readme.png" alt=""></p><p>2、<a href="https://github.com/ovity/octotree" target="_blank" rel="noopener">Octotree</a></p><p>一个浏览器插件，可以将 GitHub 的仓库变成文件浏览器，提供便于查看的树状文件结构。</p><p>项目地址: <a href="https://github.com/ovity/octotree" target="_blank" rel="noopener">https://github.com/ovity/octotree</a></p><p><img src="https://raw.githubusercontent.com/ovity/octotree/v3/docs/chrome-github.png" alt=""></p><p>3、<a href="https://github.com/Peltoche/lsd" target="_blank" rel="noopener">LSD</a></p><p>文件列表命令 ls 的替代品。</p><p>项目地址: <a href="https://github.com/Peltoche/lsd" target="_blank" rel="noopener">https://github.com/Peltoche/lsd</a></p><p><img src="https://raw.githubusercontent.com/Peltoche/lsd/assets/screen_lsd.png" alt=""></p><p>4、<a href="https://github.com/marcenacp/kubeasy" target="_blank" rel="noopener">Kubeasy</a></p><p>一个用来管理 Kubernetes 集群的 CLI 工具，提供了沉浸式的命令行界面。</p><p>项目地址: <a href="https://github.com/marcenacp/kubeasy" target="_blank" rel="noopener">https://github.com/marcenacp/kubeasy</a></p><p><img src="https://raw.githubusercontent.com/marcenacp/kubeasy/master/public/kubeasy.gif" alt=""></p><p>5、<a href="https://github.com/wercker/stern" target="_blank" rel="noopener">Stern</a></p><p>Stern 是 Kubernetes 下多容器日志查看工具，如果你有需求一次看多个 Pod 的日志，Stern 这个工具可以将日志从多个 Pod 中拉出来，非常方便实用。</p><p>Stern 支持正则表达式，只需以 Pod 部署名称开头就可以跟踪所有部署 Pod 中的日志，并不需要知道每个 Pod 的确切名称。</p><p>项目地址: <a href="https://github.com/wercker/stern" target="_blank" rel="noopener">https://github.com/wercker/stern</a></p><p><img src="https://static001.infoq.cn/resource/image/b4/8a/b4b4400dc8666b0c4176871d829dcf8a.png" alt=""></p><p>6、<a href="https://github.com/wfxr/tmux-fzf-url" target="_blank" rel="noopener">tmux-fzf-url</a></p><p>tmux-fzf-url 是一个Tmux 插件，可以帮助你解放鼠标，提高工作效率的 CLI 工具。它可以从终端快速打开屏幕中的 URL，当 URL 有多个的时候，还可以通过 FZF 进行交互式地筛选，同时打开所有选中的链接，全程无需使用鼠标。（ 配合浏览器插件 cVim、Surfingkeys 等使用更佳）</p><p>项目地址: <a href="https://github.com/wfxr/tmux-fzf-url" target="_blank" rel="noopener">https://github.com/wfxr/tmux-fzf-url</a></p><p><img src="https://raw.githubusercontent.com/wfxr/i/master/tmux-fzf-url.gif" alt=""></p><p>7、<a href="https://github.com/jiansiting/Decryption-Tools" target="_blank" rel="noopener">Decryption-Tools</a></p><p>一个勒索病毒解密工具的仓库，上面收集了各种勒索病毒解密工具, 希望对大家有用。</p><p>项目地址: <a href="https://github.com/jiansiting/Decryption-Tools" target="_blank" rel="noopener">https://github.com/jiansiting/Decryption-Tools</a></p><h3 id="技术文章">技术文章</h3><p>1、<a href="https://tonybai.com/2019/06/25/using-git-with-svn-repo/" target="_blank" rel="noopener">使用 Git 操作 SVN 仓库</a></p><p>如今，虽然 Git 已经大行其道，但是仍有很多 IT 公司和组织依旧在使用集中式的版本控制系统 Subversion，尤其是一些传统软件公司，他们倾向于集中式的联网开发。</p><p>如果你是一个 Git Fans，并且你要是遇到代码仓库依旧是使用 Subversion 进行版本控制的情况，你又该如何施展呢？</p><p>本文将介绍一种如何优雅的使用 Git 对 Subversion 仓库进行操作的方法。</p><p>链接：<a href="https://tonybai.com/2019/06/25/using-git-with-svn-repo/" target="_blank" rel="noopener">https://tonybai.com/2019/06/25/using-git-with-svn-repo/</a></p><p>2、<a href="http://dockone.io/article/8832" target="_blank" rel="noopener">容器发展简史</a></p><p>在过去四年中（2015-2019），云以及分布式计算成为最受欢迎的技术之一，它们从小众技能逐渐变成更被雇主看重的突出技能。容器化技术是云经济和 IT 生态系统中最新潮的技术之一。这篇文章可能会帮助您理解有关 Docker 和容器的一些令人困惑的概念。我们还将看到容器化生态系统在 2019 年的现状以及演变方向。</p><p>链接：<a href="http://dockone.io/article/8832" target="_blank" rel="noopener">http://dockone.io/article/8832</a></p><p>3、<a href="https://zhuanlan.zhihu.com/p/69554144" target="_blank" rel="noopener">怎样去理解 Linux 用户态和内核态？</a></p><p>在 Linux 技术讨论中经常会用户态和内核态术语脱口而出，可你们想过吗？用户态和内核态代表是什么？本片文章，就来谈一谈这个话题。</p><p>链接：<a href="https://zhuanlan.zhihu.com/p/69554144" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/69554144</a></p><p>4、<a href="https://www.sysgeek.cn/configure-dns-over-https-in-firefox/" target="_blank" rel="noopener">如何为 Firefox 浏览器配置 DNS Over HTTPS 支持</a></p><p>DNS 查询在当今互联网上扮演着不可或缺的重要角色，当您在浏览器地址栏中输入域名访问网站时，就是由 DNS 服务进行名称查询并解析为对应服务端的 IP 地址，这些由客户端自动发起的 DNS 查询通常都没有任何形式的加密、防偷窥或防篡改措施。</p><p>DNS over HTTPS 是一项相对较新的安全新功能，它可以提高 DNS 查询的隐私性、安全性和连接可靠性，主要由 Google、Cloudflare 和 Mozilla 等领先技术的科技公司在产品中使用。</p><p>本文将介绍如何在 Firefox 浏览器中启用 DNS Over HTTPS 的方法。</p><p>链接 1：<a href="https://www.sysgeek.cn/configure-dns-over-https-in-firefox/" target="_blank" rel="noopener">https://www.sysgeek.cn/configure-dns-over-https-in-firefox/</a><br>链接 2：<a href="https://zhuanlan.zhihu.com/p/42468805" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42468805</a></p><p>5、<a href="https://www.oschina.net/news/107847/geckoview-in-2019" target="_blank" rel="noopener">聊聊 Firefox Preview 背后的渲染引擎 GeckoView</a></p><p>通过将 GeckoView 引擎与 Firefox 应用程序相分离，开发团队创建了一种更新、更快和更容易维护的方式来开发 Android 应用程序。这种方法利用了 Gecko 卓越的性能、隐私和对最新 Web 标准的支持。</p><p>本文将介绍一些关于 GeckoView 的特性和应用案例。</p><p>链接：<a href="https://www.oschina.net/news/107847/geckoview-in-2019" target="_blank" rel="noopener">https://www.oschina.net/news/107847/geckoview-in-2019</a></p><h3 id="每周观点">每周观点</h3><p>1、钓鱼的两个原则：一是在有鱼的地方钓鱼，二是不要忘记第一条原则。投资的道理也是一样的。在一些地方，无论你是多好的渔夫，你也不可能钓到很多鱼。生活是一场持久的比赛，接受生活，竭尽全力地做事。如果你能够活到很大的年纪，你会获得很多机遇，可能总共是两种机遇，但抓住其中一个机遇就好啦。—— 查理∙芒格</p><p>2、向那些狂妄之徒致敬。那些特立独行的，桀骜不驯的，那些惹是生非的，格格不入的。那些喜欢另辟蹊径，绝不墨守成规，从不安于现状的家伙。你可以赞美他们，引述他们，反对他们，质疑他们，颂扬或是诋毁他们，却惟独不能忽视他们，因为他们改变了事物。他们发明，想象，治愈，他们探索，创造，启迪，他们推动人类进步。他们或有不得不疯狂的理由。你能于白纸之上看到美妙的画作么？你能于寂静之中听见动人的乐声么？你能于星空之中想到神奇的太空轮么？我们为这些家伙制造良机。别人看到的或为疯子，我们看到的却是天才。因为，只有那些疯狂到以为自己能够改变世界的人，才能真正地改变世界。——「Think Different，1997 年 Apple 广告」</p><p>3、想换个方式喜欢你了，不追逐、不逢迎、无风雨、无喜悲。——德卡先生的信箱</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。&lt;/p&gt;
&lt;p&gt;欢迎投稿或推荐你自己的项目，投稿邮箱: &lt;a href=&quot;mailto:editor@hi-linux.com&quot;&gt;editor@hi-linux.com&lt;/a&gt; 。如果你对周刊有什么建议和意见，或者想与大家一起讨论技术问题，也可以戳「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247487968&amp;amp;idx=2&amp;amp;sn=476c03c6edfae6907020c23094496791&amp;amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;amp;token=1973230270&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;」加入技术交流群。&lt;/p&gt;
&lt;h3 id=&quot;业界资讯&quot;&gt;业界资讯&lt;/h3&gt;
&lt;p&gt;1、&lt;a href=&quot;https://www.williamlong.info/archives/5747.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;中国设立互联网根服务器&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;近日，中国工信部官网一篇题为 “工业和信息化部关于同意中国互联网络信息中心设立域名根服务器（F、I、K、L根镜像服务器）及域名根服务器运行机构的批复” 的文章引起外界广泛关注。工信部当天的消息称，同意中国互联网络信息中心设立域名根服务器（F、I、K、L根镜像服务器）及成为域名根服务器运行机构，负责运行、维护和管理相关域名根服务器。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.williamlong.info/archives/5747.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.williamlong.info/archives/5747.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;https://www.solidot.org/story?sid=61096&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微软正式发布 Windows Terminal 预览版&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;微软在 Microsoft Store 发布了 Windows Terminal 的预览版。&lt;/p&gt;
&lt;p&gt;Windows Terminal 是微软上个月在开发者大会上宣布的新命令行终端，源代码发布在 GitHub 上。Windows Terminal 支持多标签、Unicode 和 UTF-8 字符、GPU 加速 DirectWrite/DirectX 文本渲染引擎，定制主题、样式和配置。更多特性详细介绍可参考&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247487033&amp;amp;idx=1&amp;amp;sn=2cc918c4a2f9ddf7da341e7996183872&amp;amp;chksm=eac52f10ddb2a606ee40e98646dc8eb8b4409ef88169c6172f5b42ead00c866c4693d7a3387f&amp;amp;token=1817029934&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;下载安装 Windows Terminal  需要 Windows 10 version 18362.0 及更新版本。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.solidot.org/story?sid=61096&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.solidot.org/story?sid=61096&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/29/5d3ebfc2aaafd80489.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;https://www.oschina.net/news/107833/dns-over-https-ga&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;谷歌宣布 DNS Over HTTPS 服务普遍可用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;谷歌于 2009 年推出 Google Public DNS，并于 2016 年在此基础上推出 DNS Over HTTPS，这是一项实验性服务，旨在加强 DNS 的安全性，此前的服务入口是 &lt;a href=&quot;http://dns.google.com/experimental%E3%80%82&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;dns.google.com/experimental。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;现在谷歌宣布 DoH 已经正式普遍可用，并且完全支持 RFC 8484 文档，同时继续提供对 2016 年推出的 JSON API 的支持。用户可以使用 dns.google 域中的 DoH 解析 DNS，其中包含与常规 DNS 服务相同的任播地址，如 8.8.8.8。新的访问入口是：&lt;a href=&quot;https://dns.google/dns-query&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dns.google/dns-query&lt;/a&gt; ((RFC 8484) 和 &lt;a href=&quot;https://dns.google/resolve&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dns.google/resolve&lt;/a&gt; (JSON API)。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/107833/dns-over-https-ga&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/107833/dns-over-https-ga&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/fe994bc0e5e401523320b7953a92696045f.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;http://news.51cto.com/art/201906/598801.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mozilla 发布下一代移动浏览器 Firefox Preview&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mozilla 已于近日在 Google Play 正式上架面向 Android 的全新移动浏览器 Firefox Preview。&lt;/p&gt;
&lt;p&gt;与现已推出与大多数浏览器所采用的 Bink 渲染引擎不同，Firefox Preview 的渲染引擎 GeckoView 由 Mozilla 自己开发，这种独立性一定程度上避免了互联网被单一的科技巨头控制。&lt;/p&gt;
&lt;p&gt;虽然已经公开发布，不过 Mozilla 表示 Firefox Preview 仍处于测试阶段，真正的大招会憋到今年秋季再放，届时将提供更丰富的功能和更精美的界面。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;http://news.51cto.com/art/201906/598801.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://news.51cto.com/art/201906/598801.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s4.51cto.com/oss/201907/01/da021001f2e94c283777ac8f67a880b8.jpg-wh_651x-s_2719880675.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;https://www.infoq.cn/article/I_Wfu4eIJY7c52Prqoop&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenJDK Docker 镜像存在错误版本漏洞&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenJDK 邮件列表确认，OpenJDK 的官方 Docker 镜像中包含错误标记版本号，这表明部分 JRE 应包含的安全补丁实际上并不存在。&lt;/p&gt;
&lt;p&gt;该问题已经通过 OpenJDK 和 Debian 间的跨社区协作得以解决。该 “官方” 版本是由 Docker 和其他方制作的，因为 OpenJDK 社区没有创建镜像或生成构建。该 Docker 镜像已被下载超过一千万次。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.infoq.cn/article/I_Wfu4eIJY7c52Prqoop&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.infoq.cn/article/I_Wfu4eIJY7c52Prqoop&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6、&lt;a href=&quot;https://www.oschina.net/news/107663/v-lang-source-code-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;安全的全新编程语言 V 发布首个可用版本&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;日前，一种新的静态类型编程语言 V 语言正式开源了，并发布了首个可用版本。&lt;/p&gt;
&lt;p&gt;据了解，V 语言全名叫：Vlang。V 语言是一个结合 Go 语言的简洁以及 Rust 的安全特性的新语言，其提供了方便、快捷、安全的编程语言和工具包，还能够很好地服务于区块链技术。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/107663/v-lang-source-code-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/107663/v-lang-source-code-released&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/vlang/v/master/examples/tetris/screenshot.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="周刊" scheme="https://www.hi-linux.com/tags/%E5%91%A8%E5%88%8A/"/>
    
  </entry>
  
  <entry>
    <title>Linux 爱好者周刊 ( 第 2 期 )</title>
    <link href="https://www.hi-linux.com/posts/43609.html"/>
    <id>https://www.hi-linux.com/posts/43609.html</id>
    <published>2020-05-16T01:00:00.000Z</published>
    <updated>2020-05-16T04:44:06.740Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。</p><p>欢迎投稿或推荐你自己的项目，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a> 。如果你想我们一起交流，也可以戳「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247487968&amp;idx=2&amp;sn=476c03c6edfae6907020c23094496791&amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;token=1973230270&amp;lang=zh_CN#rd" target="_blank" rel="noopener">这里</a>」加入技术交流群。</p><h3 id="业界资讯">业界资讯</h3><p>1、<a href="https://www.cnbeta.com/articles/soft/862853.htm" target="_blank" rel="noopener">GitHub 官方中文文档上线</a></p><p>GitHub 推出官方中文帮助文档，这是继日文版之后第二个非英语语种的帮助文档。GitHub 希望借此能够帮助中文开发者更好的理解 GitHub 操作规范，更加熟悉对 GitHub 的操作。</p><p>链接：<a href="https://www.cnbeta.com/articles/soft/862853.htm" target="_blank" rel="noopener">https://www.cnbeta.com/articles/soft/862853.htm</a></p><p><img src="https://static.cnbetacdn.com/article/2019/0701/81c468f1fc60c58.jpeg" alt=""></p><p>2、<a href="https://github.com/microsoft/WSL2-Linux-Kernel" target="_blank" rel="noopener">微软正式开源 WSL 2 内核源码</a></p><p>微软在今年 5 月举办的 Build 2019 上宣布了第二代 Windows 的 Linux 子系统 WSL 2。与第一代相比，WSL 2 重新设计了架构，使用真正的 Linux 内核，支持在 Windows 上运行 ELF64 Linux 二进制文件。</p><p>近日，微软正式开源了 WSL 2 的内核源码，并将代码托管在 GitHub 上。</p><p>链接：<a href="https://github.com/microsoft/WSL2-Linux-Kernel" target="_blank" rel="noopener">https://github.com/microsoft/WSL2-Linux-Kernel</a></p><p><img src="https://www.hi-linux.com/img/linux/wsl2.jpeg" alt=""></p><p>3、<a href="https://www.oschina.net/news/107948/gitlab-will-removing-mysql-support-in-12-1" target="_blank" rel="noopener">Gitlab 从 12.1 版本开始将不再支持 MySQL</a></p><p>Gitlab 官方宣布，将从 12.1 版本开始不再支持 MySQL 数据库。</p><p>链接：<a href="https://www.oschina.net/news/107948/gitlab-will-removing-mysql-support-in-12-1" target="_blank" rel="noopener">https://www.oschina.net/news/107948/gitlab-will-removing-mysql-support-in-12-1</a></p><p><img src="https://about.gitlab.com/images/blogimages/gitlab-blog-cover.png" alt=""></p><p>4、<a href="https://www.oschina.net/news/108045/debian-10-released" target="_blank" rel="noopener">Debian 10 Buster 正式发布</a></p><p>经历了 25 个月的开发后，Debian 团队于 2019 年 7 月 6 日正式宣布推出代号为 「Buster」 的 Debian 10 稳定版。</p><p>Debian 10 是一个主要版本，带来了许多更新的组件和许多新功能和改进。此版本将在未来 5 年获得由 Debian 安全团队和 Debian 长期支持团队提供的技术支持。</p><p>链接：<a href="https://www.oschina.net/news/108045/debian-10-released" target="_blank" rel="noopener">https://www.oschina.net/news/108045/debian-10-released</a></p><p><img src="https://static.oschina.net/uploads/space/2019/0707/142126_FSUH_2720166.png" alt=""></p><p>5、<a href="https://www.leikeji.com/article/27315" target="_blank" rel="noopener">Chrome 代码出现广告拦截功能，谷歌或将治理网页广告乱象</a></p><p>几乎每一个网民都逃不开广告的影响，它已经深刻地进入到我们的生活之中。无论是刷新信息流还是访问某个具体的内容，广告都会在那里出现，从不在乎你是否想看到。有一部分广告明显影响到了访问网页时的体验，有的会让内容难以查看，有的则会大幅占用系统资源，甚至让电脑操作变慢。</p><p>作为当前市场占有率最大的浏览器 Chrome 打算为用户分担一部分烦恼。根据 9to5google 的报道，Chrome 浏览器的开源代码中出现了内置广告拦截功能的踪影，这项功能将帮用户屏蔽掉部分广告。</p><p>根据页面相关描述，Chrome 会对广告对系统资源的占用进行分析，然后找出那些使用了太多带宽或者 CPU 能力的广告并屏蔽掉它们。最后用户只会看到广告被屏蔽后 “该广告已经移除” 提示。</p><p>链接：<a href="https://www.leikeji.com/article/27315" target="_blank" rel="noopener">https://www.leikeji.com/article/27315</a></p><p><img src="https://www.hi-linux.com/img/linux/chrome.png" alt=""></p><p>6、<a href="https://www.oschina.net/news/108120/ibm-closes-acquisition-of-red-hat" target="_blank" rel="noopener">IBM 340 亿美元红帽收购案完成：定义混合云的开放未来</a></p><p>7 月 9 日晚，IBM 宣布以 340 亿美元（约合人民币 2340 亿）正式收购红帽。早在去年 10 月 29 日，IBM 和红帽就共同宣布两家公司已达成最终协议。根据协议，IBM 将收购红帽所有已发行的普通股，每股 190 美元，总企业价值约 340 亿美元。现在，这次庞大的收购终于完成。</p><p>IBM 表示，本次收购重新定义了企业级云市场。红帽开放的混合云技术，与 IBM 广泛且深入的创新和行业洞察，以及在超过 175 个国家和地区领先的销售能力相结合，通过提供下一代混合多云平台，将共同加速企业创新。基于 Linux 和 Kubernetes 等开源技术，该平台可以使企业在本地、私有云以及多个公有云平台上安全部署、运行、管理数据及应用。</p><p>链接：<a href="https://www.oschina.net/news/108120/ibm-closes-acquisition-of-red-hat" target="_blank" rel="noopener">https://www.oschina.net/news/108120/ibm-closes-acquisition-of-red-hat</a></p><p><img src="https://oscimg.oschina.net/oscnet/30975bdc2ed93d5937c918fca2f46814f05.jpg" alt=""></p><a id="more"></a><h3 id="趣站酷软">趣站酷软</h3><p>1、<a href="https://github.com/IBM/kui" target="_blank" rel="noopener">Kui</a></p><p>Kui 是一款由 IBM 开源的用来管理 Kubernetes 集群的 CLI 工具，Kui 使用 Electron 提供 GUI 能力。</p><p>Kui 结合了原有 CLI 的强大功能，并提供一种可视化的方式，方便我们对 Kubernetes 中 YAML 或者 JSON 格式数据的处理。</p><p>项目地址: <a href="https://github.com/IBM/kui" target="_blank" rel="noopener">https://github.com/IBM/kui</a></p><p><img src="https://raw.githubusercontent.com/IBM/kui/master/docs/readme/images/kubectl-examples.jpg" alt=""></p><p>2、<a href="https://github.com/sentialx/multrin" target="_blank" rel="noopener">Multrin</a></p><p>Multrin 是一个基于 Electron、React、样式组件与 TypeScript 的应用，它可以将不同应用组织在一个 tab 标签下，大大提高生产力。</p><p>目前支持 Windows 与 macOS，Linux 支持正在开发中。</p><p>项目地址: <a href="https://github.com/sentialx/multrin" target="_blank" rel="noopener">https://github.com/sentialx/multrin</a></p><p><img src="https://github.com/sentialx/multrin/raw/master/screenshots/screen1.gif" alt=""></p><p>3、<a href="https://github.com/huangjianke/Gitter" target="_blank" rel="noopener">Gitter</a></p><p>一个 GitHub 的微信小程序客户端，可能是目前颜值最高的。</p><p>项目地址: <a href="https://github.com/huangjianke/Gitter" target="_blank" rel="noopener">https://github.com/huangjianke/Gitter</a></p><p><img src="https://raw.githubusercontent.com/huangjianke/Gitter/master/images/img00.png" alt=""></p><p>4、<a href="https://github.com/derailed/popeye" target="_blank" rel="noopener">Popeye</a></p><p>Popeye 是一个 Kubernetes 集群资源清理的实用程序，它可以实时扫描 Kubernetes 集群并报告已部署资源和配置的潜在问题。</p><p>Popeye 根据部署的内容而不是磁盘上的内容来清理群集。 通过扫描您的群集，它可以检测到错误配置并确保最佳实践，从而防止潜在问题发生。</p><p>Popeye 是一个只读工具，它不会以任何方式改变你的任何 Kubernetes 资源。</p><p>项目地址: <a href="https://github.com/derailed/popeye" target="_blank" rel="noopener">https://github.com/derailed/popeye</a></p><p><img src="https://github.com/derailed/popeye/raw/master/assets/a_score.png" alt=""></p><p>5、<a href="https://github.com/hiroppy/fusuma" target="_blank" rel="noopener">Fusuma</a></p><p>Fusuma 是一个简单方便的使用 Markdown 创建幻灯片的工具。</p><p>你只需要写好想要作为幻灯片展示的 Markdown，并按照顺序整理好目录结构，再写好需要的 CSS 文件之后，这个项目就能够让你简单的使用浏览器展示它们，或者是把它整体导出为一个 PDF 文件。</p><p>项目地址: <a href="https://github.com/hiroppy/fusuma" target="_blank" rel="noopener">https://github.com/hiroppy/fusuma</a></p><p><img src="https://raw.githubusercontent.com/hiroppy/fusuma/master/site/docs/assets/live-mode-comments.png" alt=""></p><p>6、<a href="https://github.com/jesseduffield/lazydocker" target="_blank" rel="noopener">LazyDocker</a></p><p>这是一个为了能在终端中更方便管理 Docker 和 Docker-Compose 的简单终端 UI 工具。</p><p>作者表示记住 Docker 命令很难，并且在多个终端窗口中跟踪容器几乎是不可能的。LazyDocker 正是为了解决这种问题而产生的，它可以在一个终端窗口中拥有所需的所有信息，并且每个 Docker 常用命令都可以绑定快捷键，同时可以添加自定义命令。</p><p>项目地址: <a href="https://github.com/jesseduffield/lazydocker" target="_blank" rel="noopener">https://github.com/jesseduffield/lazydocker</a></p><p><img src="https://oscimg.oschina.net/oscnet/4ad1a013236976fa04761509d03d4fbeecf.jpg" alt=""></p><h3 id="技术文章">技术文章</h3><p>1、<a href="https://www.cnblogs.com/xuxinkun/p/11025020.html" target="_blank" rel="noopener">Docker/Kubernetes 国内镜像源解决方式</a></p><p>本文整理了国内的一些 Docker/Kubernetes 可用的镜像源，非常实用。</p><p>链接：<a href="https://www.cnblogs.com/xuxinkun/p/11025020.html" target="_blank" rel="noopener">https://www.cnblogs.com/xuxinkun/p/11025020.html</a></p><p>2、<a href="https://free.com.tw/mojave-dark-menu-bar-dock/" target="_blank" rel="noopener">如何让 macOS Mojave 只有菜单列和 Dock 使用深色模式？</a></p><p>你可能觉得 macOS 浅色介面有点刺眼，但 Mojave 深色模式又太过深邃？</p><p>至少我使用起来并不是那么愉快，反而花更多时间在辨识不太清楚的文字或图标，甚至有点怀念更早之前的暗色选单（Mojave 以后已经没有这个选项），如果你跟我一样，或许可以考虑透过一个小设定来为现在的 macOS Mojave 开启深色菜单和 Dock 功能。</p><p>链接：<a href="https://free.com.tw/mojave-dark-menu-bar-dock/" target="_blank" rel="noopener">https://free.com.tw/mojave-dark-menu-bar-dock/</a></p><p>3、<a href="https://www.jianshu.com/p/68384978c0a3" target="_blank" rel="noopener">对运维开发工作的一些思考</a></p><p>运维开发这个岗位与普通的业务开发不同，与日常的运维工作也不同，要求兼顾开发与运维两种能力。既要掌握不弱于业务开发的开发技术，又要负责 SRE 同学日常的运维能力。上线之前，还要像 QA 同学一样，对自己的服务进行测试和分级变更。本文将针对运维领域「自动化平台开发」的工作对 DevOPS 进行探讨。</p><p>链接：<a href="https://www.jianshu.com/p/68384978c0a3" target="_blank" rel="noopener">https://www.jianshu.com/p/68384978c0a3</a></p><p>4、<a href="http://blog.ihipop.info/2019/07/5212.html" target="_blank" rel="noopener">记录一次磁盘镜像的 LVM 分区缩小调整过程</a></p><p>本文将分享一些 LVM 分区大小调整的技巧。</p><p>链接：<a href="http://blog.ihipop.info/2019/07/5212.html" target="_blank" rel="noopener">http://blog.ihipop.info/2019/07/5212.html</a></p><p>5、使用斐讯 N1 作为 Prometheus 监控服务器</p><p>新出的树莓派 4，性能方面可以说对于老的 3B+ 的版本可以说是有全面的提升。但价格方面 4G 内存配置的就已经需要 50$，已经逼近台 x86 的准系统。同时因为树莓派是裸板，如果想要在生产环境使用，后面还需要自己增加存储、外壳等，全套上去其实性价比已经不高。</p><p>本文作者另辟蹊径采用斐讯的 N1 来部署了一个 Prometheus 监控服务器。</p><p>链接：<a href="https://www.gracecode.com/posts/3184.html" target="_blank" rel="noopener">https://www.gracecode.com/posts/3184.html</a></p><p><img src="https://friable.rocks/_/2019_07_01/1561965398165370.png" alt=""></p><h3 id="每周观点">每周观点</h3><p>1、梦想可以天花乱坠，理想是我们一步一个脚印踩出来的坎坷道路。—— 三毛<br>2、没事早点睡，有空多挣钱。—— 佚名<br>3、在你我生命中，都不需要完美。做自己的萤火，温暖少数人就足够了。—— 佚名<br>4、人生就是一列开往坟墓的列车，路途上会有很多站，很难有人可以至始至终陪着走完，当陪你的人要下车时，即使不舍，也该心存感激，然后挥手道别。—— 宫崎骏「千与千寻」</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。&lt;/p&gt;
&lt;p&gt;欢迎投稿或推荐你自己的项目，投稿邮箱: &lt;a href=&quot;mailto:editor@hi-linux.com&quot;&gt;editor@hi-linux.com&lt;/a&gt; 。如果你想我们一起交流，也可以戳「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247487968&amp;amp;idx=2&amp;amp;sn=476c03c6edfae6907020c23094496791&amp;amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;amp;token=1973230270&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;」加入技术交流群。&lt;/p&gt;
&lt;h3 id=&quot;业界资讯&quot;&gt;业界资讯&lt;/h3&gt;
&lt;p&gt;1、&lt;a href=&quot;https://www.cnbeta.com/articles/soft/862853.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub 官方中文文档上线&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub 推出官方中文帮助文档，这是继日文版之后第二个非英语语种的帮助文档。GitHub 希望借此能够帮助中文开发者更好的理解 GitHub 操作规范，更加熟悉对 GitHub 的操作。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.cnbeta.com/articles/soft/862853.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnbeta.com/articles/soft/862853.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.cnbetacdn.com/article/2019/0701/81c468f1fc60c58.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;https://github.com/microsoft/WSL2-Linux-Kernel&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微软正式开源 WSL 2 内核源码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;微软在今年 5 月举办的 Build 2019 上宣布了第二代 Windows 的 Linux 子系统 WSL 2。与第一代相比，WSL 2 重新设计了架构，使用真正的 Linux 内核，支持在 Windows 上运行 ELF64 Linux 二进制文件。&lt;/p&gt;
&lt;p&gt;近日，微软正式开源了 WSL 2 的内核源码，并将代码托管在 GitHub 上。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://github.com/microsoft/WSL2-Linux-Kernel&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/microsoft/WSL2-Linux-Kernel&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/wsl2.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;https://www.oschina.net/news/107948/gitlab-will-removing-mysql-support-in-12-1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Gitlab 从 12.1 版本开始将不再支持 MySQL&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gitlab 官方宣布，将从 12.1 版本开始不再支持 MySQL 数据库。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/107948/gitlab-will-removing-mysql-support-in-12-1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/107948/gitlab-will-removing-mysql-support-in-12-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://about.gitlab.com/images/blogimages/gitlab-blog-cover.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;https://www.oschina.net/news/108045/debian-10-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Debian 10 Buster 正式发布&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;经历了 25 个月的开发后，Debian 团队于 2019 年 7 月 6 日正式宣布推出代号为 「Buster」 的 Debian 10 稳定版。&lt;/p&gt;
&lt;p&gt;Debian 10 是一个主要版本，带来了许多更新的组件和许多新功能和改进。此版本将在未来 5 年获得由 Debian 安全团队和 Debian 长期支持团队提供的技术支持。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108045/debian-10-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108045/debian-10-released&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2019/0707/142126_FSUH_2720166.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;https://www.leikeji.com/article/27315&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Chrome 代码出现广告拦截功能，谷歌或将治理网页广告乱象&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;几乎每一个网民都逃不开广告的影响，它已经深刻地进入到我们的生活之中。无论是刷新信息流还是访问某个具体的内容，广告都会在那里出现，从不在乎你是否想看到。有一部分广告明显影响到了访问网页时的体验，有的会让内容难以查看，有的则会大幅占用系统资源，甚至让电脑操作变慢。&lt;/p&gt;
&lt;p&gt;作为当前市场占有率最大的浏览器 Chrome 打算为用户分担一部分烦恼。根据 9to5google 的报道，Chrome 浏览器的开源代码中出现了内置广告拦截功能的踪影，这项功能将帮用户屏蔽掉部分广告。&lt;/p&gt;
&lt;p&gt;根据页面相关描述，Chrome 会对广告对系统资源的占用进行分析，然后找出那些使用了太多带宽或者 CPU 能力的广告并屏蔽掉它们。最后用户只会看到广告被屏蔽后 “该广告已经移除” 提示。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.leikeji.com/article/27315&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.leikeji.com/article/27315&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/chrome.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;6、&lt;a href=&quot;https://www.oschina.net/news/108120/ibm-closes-acquisition-of-red-hat&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;IBM 340 亿美元红帽收购案完成：定义混合云的开放未来&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;7 月 9 日晚，IBM 宣布以 340 亿美元（约合人民币 2340 亿）正式收购红帽。早在去年 10 月 29 日，IBM 和红帽就共同宣布两家公司已达成最终协议。根据协议，IBM 将收购红帽所有已发行的普通股，每股 190 美元，总企业价值约 340 亿美元。现在，这次庞大的收购终于完成。&lt;/p&gt;
&lt;p&gt;IBM 表示，本次收购重新定义了企业级云市场。红帽开放的混合云技术，与 IBM 广泛且深入的创新和行业洞察，以及在超过 175 个国家和地区领先的销售能力相结合，通过提供下一代混合多云平台，将共同加速企业创新。基于 Linux 和 Kubernetes 等开源技术，该平台可以使企业在本地、私有云以及多个公有云平台上安全部署、运行、管理数据及应用。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108120/ibm-closes-acquisition-of-red-hat&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108120/ibm-closes-acquisition-of-red-hat&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/30975bdc2ed93d5937c918fca2f46814f05.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="周刊" scheme="https://www.hi-linux.com/tags/%E5%91%A8%E5%88%8A/"/>
    
  </entry>
  
  <entry>
    <title>Linux 爱好者周刊 ( 第 3 期 )</title>
    <link href="https://www.hi-linux.com/posts/27209.html"/>
    <id>https://www.hi-linux.com/posts/27209.html</id>
    <published>2020-05-16T01:00:00.000Z</published>
    <updated>2020-05-16T04:52:42.443Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。</p><p>欢迎投稿或推荐你自己的项目，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a> 。如果你对周刊有什么建议和意见，或者想与大家一起讨论技术问题，也可以戳「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247487968&amp;idx=2&amp;sn=476c03c6edfae6907020c23094496791&amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;token=1973230270&amp;lang=zh_CN#rd" target="_blank" rel="noopener">这里</a>」加入技术交流群。</p><h2 id="业界资讯">业界资讯</h2><p>1、<a href="https://www.cnbeta.com/articles/soft/865277.htm" target="_blank" rel="noopener">Linux Kernel 5.2 正式版发布，代号为 Bobtail Squid</a></p><p>经历了 7 个 RC 候选版本之后，Linus Torvalds 正式宣布了 Linux Kernel 5.2 正式版。本次主要版本更新在改进驱动程序和核心组件之外，还引入了一些有趣的特性和增强功能。不过需要注意的是 Linux Kernel 5.2 并非长期支持（LTS）分支，因此推荐注重稳定的用户还是使用当前的 LTS 内核。</p><p>链接：<a href="https://www.cnbeta.com/articles/soft/865277.htm" target="_blank" rel="noopener">https://www.cnbeta.com/articles/soft/865277.htm</a></p><p><img src="https://static.cnbetacdn.com/thumb/article/2019/0708/1cb25fe820d7a25.jpg" alt=""></p><p>2、<a href="https://www.cnbeta.com/articles/tech/865885.htm" target="_blank" rel="noopener">知名 DNS 解析服务商 CloudXNS 将停止免费服务</a></p><p>国内知名 DNS 解析服务商「CloudXNS」发布了 “关于停止免费用户解析服务的公告”。该公告表示：“为贯彻国家网络安全政策法规，加强监管力度，更好地服务于 VIP 客户，CloudXNS 将停止免费用户使用 CloudXNS 的解析服务。”</p><p>链接：<a href="https://www.cnbeta.com/articles/tech/865885.htm" target="_blank" rel="noopener">https://www.cnbeta.com/articles/tech/865885.htm</a></p><p>3、<a href="https://www.leiphone.com/news/201907/rPrJiMyrHkOxiFdn.html" target="_blank" rel="noopener">Google 开源 robots.txt 解析器，推动 REP 标准化</a></p><p>Google 在其博客上发布了一个重要消息，它宣布 Google 开源了存储 robots.txt 解析器的 C++ 库，以便推动 REP（Robots Exclusion Protocol，也称爬虫协议、机器人协议）成为互联网标准。</p><p>链接：<a href="https://www.leiphone.com/news/201907/rPrJiMyrHkOxiFdn.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201907/rPrJiMyrHkOxiFdn.html</a></p><p><img src="https://static.leiphone.com/uploads/new/images/20190702/5d1b31955ff60.png" alt=""></p><p>4、<a href="https://www.infoq.cn/article/lmpwEtgNKUCF_u9JgktC" target="_blank" rel="noopener">阿里云 PHP Composer 全量镜像正式上线</a></p><p>阿里云正式上线 PHP Composer 全量镜像，所有 PHP 开发者都可以通过我们的开发者社区 <a href="http://developer.aliyun.com/composer" target="_blank" rel="noopener">developer.aliyun.com/composer</a> 加速 Composer 安装器。</p><p>这款镜像工具的最大优势是快，几乎实现与 PHP Packagist 官方实时同步，每隔 30 秒刷新全国 CDN 缓存。它基于阿里云的对象存储 OSS 和 CDN 研发同步系统，通过任务分发，实现同步的快速和稳定。</p><p>链接：<a href="https://www.infoq.cn/article/lmpwEtgNKUCF_u9JgktC" target="_blank" rel="noopener">https://www.infoq.cn/article/lmpwEtgNKUCF_u9JgktC</a></p><p>5、 <a href="https://www.oschina.net/news/108197/coredns-1-5-2-released" target="_blank" rel="noopener">CoreDNS v1.5.2 发布</a></p><p>CoreDNS 1.5.2 发布了，该版本包含一些小的 Bug 修复。在此版本中，一个重要的变更便是移除掉了 upstream 插件相关的所有文档和说明。在此次变更之后， upstream 配置行便可直接移除。</p><p>链接：<a href="https://www.oschina.net/news/108197/coredns-1-5-2-released" target="_blank" rel="noopener">https://www.oschina.net/news/108197/coredns-1-5-2-released</a></p><p><img src="https://www.hi-linux.com/img/linux/coredns.jpeg" alt=""></p><a id="more"></a><h2 id="趣站酷软">趣站酷软</h2><p>1、<a href="https://browserframe.com/" target="_blank" rel="noopener">BrowserFrame</a></p><p>「BrowserFrame」是一个很好用的在线工具，可以将截图或任何图片加上浏览器外框。</p><p>BrowserFrame 提供了两种方式来生成截图，分别是上传本地截图和输入网址生成截图。后者输入网址生产截图由于会受到网页加载速度的影响，生成速度可能会比较慢，容易出现「生成失败」的情况，建议选择直接上传本地截图的方法。</p><p>BrowserFrame 支持多种平台的多款浏览器样式，包括 Google Chrome、Firefox、Safari、Opera、IE 和 Edge 等。你不仅可以根据自己喜好选择不同的样式，还可以自定义一些细节设置，比如：窗口顏色、宽度、高度或间距等等。</p><p>项目地址: <a href="https://browserframe.com/" target="_blank" rel="noopener">https://browserframe.com/</a></p><p><img src="https://www.hi-linux.com/img/linux/BrowserFrame.jpeg" alt=""></p><p>2、<a href="https://github.com/thegreatjavascript/FakeScreenshot" target="_blank" rel="noopener">FakeScreenshot</a></p><p>这是一个可以伪造微博、知乎、豆瓣、简书等网站界面截图的项目，该项目能够非常简单的生成一个能够以假乱真的截图。</p><p>实际上想要做一张假截图是很简单的事情，不管是模仿还是干脆 PS 合成一个，导致很多时候这些截图会被拿去传播谣言。这个项目的意义在于告诉人们看到任何截图的时候都应该保持怀疑。</p><p>项目地址: <a href="https://github.com/thegreatjavascript/FakeScreenshot" target="_blank" rel="noopener">https://github.com/thegreatjavascript/FakeScreenshot</a></p><p><img src="https://openingsource.org/wp-content/uploads/2019/06/473-1.png" alt=""></p><p>3、<a href="https://mdnice.com/" target="_blank" rel="noopener">Markdown Nice</a></p><p>Markdown Nice 是一个开源的专门针对微信公众号文章排版而设计的 Markdown 在线编辑器。编写完成即排版完成，复制到公众号文章编辑器即可，非常好用。</p><p>Markdown Nice 还有很多特色功能，比如：支持自定义样式、浏览器中实时保存和预览内容样式、支持零配置图床、脚注、代码、公式等。</p><p>项目地址: <a href="https://mdnice.com/" target="_blank" rel="noopener">https://mdnice.com/</a></p><p><img src="https://www.hi-linux.com/img/linux/mdnice.jpeg" alt=""></p><p>4、<a href="https://sm.ms" target="_blank" rel="noopener">SM.MS</a></p><p><a href="http://SM.MS" target="_blank" rel="noopener">SM.MS</a> 是由 V2EX 的 Showfom 自建的一个免费图床，图床速度还不错，已经运行四年多了。该图床免注册且永久存储，且无外链、无流量限制，支持 HTTPS。</p><p>图床图片上传限制：每个图片最大 5M，每次最多上传 10 张。</p><p>项目地址：<a href="https://sm.ms" target="_blank" rel="noopener">https://sm.ms</a></p><p><img src="https://www.hi-linux.com/img/linux/smms.jpeg" alt=""></p><p>5、<a href="https://github.com/Molunerfinn/PicGo" target="_blank" rel="noopener">PicGo</a></p><p>PicGo 是一款开源跨平台的免费图片上传工具以及图床相册管理软件，支持 Windows、macOS 和 Linux 系统。</p><p>PicGo 使用非常简单，它能帮你快速地将图片上传到微博、又拍云、阿里云 OSS、腾讯云 COS、七牛、GitHub、<a href="http://sm.ms" target="_blank" rel="noopener">sm.ms</a>、Imgur 等常见的免费图床网站或云存储服务上，并自动复制图片的链接到剪贴板里，使用上非常高效便捷。</p><p>项目地址：<a href="https://github.com/Molunerfinn/PicGo" target="_blank" rel="noopener">https://github.com/Molunerfinn/PicGo</a></p><p><img src="https://i.loli.net/2019/05/08/5cd2dc258f927.png" alt=""></p><p>6、<a href="https://www.pexels.com" target="_blank" rel="noopener">Pexels</a></p><p>Pexels 堪称最值得推荐的免费图库之一，它的特色是将许多大大小小图库及素材来源整合在同一网站，加入搜索、分类及标签等功能，让使用者在找图片时更快更准确。</p><p>Pexels 提供各种尺寸的相片，甚至有 HD 高画质的原始图片，无须注册就能下载，更棒的是还能依照使用者需求，设定尺寸后自动在线上裁剪，节省下载后必须自行编辑所耗费的时间。</p><p>项目地址：<a href="https://www.pexels.com/" target="_blank" rel="noopener">https://www.pexels.com/</a></p><p><img src="https://www.hi-linux.com/img/linux/Pexels.jpeg" alt=""></p><p>7、<a href="https://github.com/sxfad/porter" target="_blank" rel="noopener">Porter</a></p><p>Porter 是一款数据同步中间件，主要用于解决同构/异构数据库之间的表级别数据同步问题。</p><p>Porter 是一个插件友好型的数据聚合、分发中间件，提供源端、目标端、数据过滤等插件自定义开发的能力，能够根据场景需要轻松定制同步任务。</p><p>项目地址：<a href="https://github.com/sxfad/porter" target="_blank" rel="noopener">https://github.com/sxfad/porter</a></p><p><img src="https://raw.githubusercontent.com/sxfad/porter/master/doc/img/Home.png" alt=""></p><h2 id="技术文章">技术文章</h2><p>1、<a href="https://cloud.tencent.com/developer/article/1448440" target="_blank" rel="noopener">如何在 MySQL 8.0.16 在组复制中启用成员自动重新加入</a></p><p>随着 MySQL 8.0.16 的发布，MGR 添加了一些功能以增强其高可用性。其中一个功能是能够在某些情况下启用已离开组的成员自动重新加入，而无需用户干预。本文将介绍这一新特性所带来的变化。</p><p>链接：<a href="https://cloud.tencent.com/developer/article/1448440" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1448440</a></p><p>2、<a href="https://www.yichya.dev/dns-poisoning-and-countering/" target="_blank" rel="noopener">DNS 污染和攻击</a></p><p>DNS 污染极为简单易行且效果极佳，这篇文章将介绍一下常见的 DNS 投毒现象，以及几种避免 DNS 攻击的解决方案。</p><p>链接：<a href="https://www.yichya.dev/dns-poisoning-and-countering/" target="_blank" rel="noopener">https://www.yichya.dev/dns-poisoning-and-countering/</a></p><p>3、<a href="https://arkingc.github.io/2018/12/11/2018-12-11-docker-storage-persist" target="_blank" rel="noopener">Docker 容器数据持久化</a></p><p>本文介绍了三种常用的 Docker 数据持久化的使用方法和适用的场景。</p><p>链接：<a href="https://arkingc.github.io/2018/12/11/2018-12-11-docker-storage-persist/" target="_blank" rel="noopener">https://arkingc.github.io/2018/12/11/2018-12-11-docker-storage-persist/</a></p><p>4、<a href="https://sspai.com/post/55703" target="_blank" rel="noopener">如何在 macOS Mojave 中将 U 盘格式化成通用格式</a></p><p>本文将介绍如何在 macOS Mojave 中将 APFS 格式的 U 盘在系统自带的磁盘工具中格式化成通用格式的方法。</p><p>链接：<a href="https://sspai.com/post/55703" target="_blank" rel="noopener">https://sspai.com/post/55703</a></p><h2 id="每周观点">每周观点</h2><p>1、人生重要的不是所站的位置，而是所朝的方向。—— 李嘉诚</p><p>2、如果不继续成长，就会开始走向死亡。—— 华特·迪士尼</p><p>3、这个世界如此美好，值得为它奋战。—— 海明威</p><p>4、这世界不缺少发现，而是缺少发现后的思考。—— 牛根生</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。&lt;/p&gt;
&lt;p&gt;欢迎投稿或推荐你自己的项目，投稿邮箱: &lt;a href=&quot;mailto:editor@hi-linux.com&quot;&gt;editor@hi-linux.com&lt;/a&gt; 。如果你对周刊有什么建议和意见，或者想与大家一起讨论技术问题，也可以戳「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247487968&amp;amp;idx=2&amp;amp;sn=476c03c6edfae6907020c23094496791&amp;amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;amp;token=1973230270&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;」加入技术交流群。&lt;/p&gt;
&lt;h2 id=&quot;业界资讯&quot;&gt;业界资讯&lt;/h2&gt;
&lt;p&gt;1、&lt;a href=&quot;https://www.cnbeta.com/articles/soft/865277.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Linux Kernel 5.2 正式版发布，代号为 Bobtail Squid&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;经历了 7 个 RC 候选版本之后，Linus Torvalds 正式宣布了 Linux Kernel 5.2 正式版。本次主要版本更新在改进驱动程序和核心组件之外，还引入了一些有趣的特性和增强功能。不过需要注意的是 Linux Kernel 5.2 并非长期支持（LTS）分支，因此推荐注重稳定的用户还是使用当前的 LTS 内核。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.cnbeta.com/articles/soft/865277.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnbeta.com/articles/soft/865277.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.cnbetacdn.com/thumb/article/2019/0708/1cb25fe820d7a25.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;https://www.cnbeta.com/articles/tech/865885.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;知名 DNS 解析服务商 CloudXNS 将停止免费服务&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;国内知名 DNS 解析服务商「CloudXNS」发布了 “关于停止免费用户解析服务的公告”。该公告表示：“为贯彻国家网络安全政策法规，加强监管力度，更好地服务于 VIP 客户，CloudXNS 将停止免费用户使用 CloudXNS 的解析服务。”&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.cnbeta.com/articles/tech/865885.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnbeta.com/articles/tech/865885.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;https://www.leiphone.com/news/201907/rPrJiMyrHkOxiFdn.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Google 开源 robots.txt 解析器，推动 REP 标准化&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google 在其博客上发布了一个重要消息，它宣布 Google 开源了存储 robots.txt 解析器的 C++ 库，以便推动 REP（Robots Exclusion Protocol，也称爬虫协议、机器人协议）成为互联网标准。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.leiphone.com/news/201907/rPrJiMyrHkOxiFdn.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.leiphone.com/news/201907/rPrJiMyrHkOxiFdn.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://static.leiphone.com/uploads/new/images/20190702/5d1b31955ff60.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;https://www.infoq.cn/article/lmpwEtgNKUCF_u9JgktC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿里云 PHP Composer 全量镜像正式上线&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;阿里云正式上线 PHP Composer 全量镜像，所有 PHP 开发者都可以通过我们的开发者社区 &lt;a href=&quot;http://developer.aliyun.com/composer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;developer.aliyun.com/composer&lt;/a&gt; 加速 Composer 安装器。&lt;/p&gt;
&lt;p&gt;这款镜像工具的最大优势是快，几乎实现与 PHP Packagist 官方实时同步，每隔 30 秒刷新全国 CDN 缓存。它基于阿里云的对象存储 OSS 和 CDN 研发同步系统，通过任务分发，实现同步的快速和稳定。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.infoq.cn/article/lmpwEtgNKUCF_u9JgktC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.infoq.cn/article/lmpwEtgNKUCF_u9JgktC&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5、 &lt;a href=&quot;https://www.oschina.net/news/108197/coredns-1-5-2-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CoreDNS v1.5.2 发布&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CoreDNS 1.5.2 发布了，该版本包含一些小的 Bug 修复。在此版本中，一个重要的变更便是移除掉了 upstream 插件相关的所有文档和说明。在此次变更之后， upstream 配置行便可直接移除。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108197/coredns-1-5-2-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108197/coredns-1-5-2-released&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.hi-linux.com/img/linux/coredns.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="周刊" scheme="https://www.hi-linux.com/tags/%E5%91%A8%E5%88%8A/"/>
    
  </entry>
  
  <entry>
    <title>Linux 爱好者周刊 ( 第 4 期 )</title>
    <link href="https://www.hi-linux.com/posts/43583.html"/>
    <id>https://www.hi-linux.com/posts/43583.html</id>
    <published>2020-05-16T01:00:00.000Z</published>
    <updated>2020-05-16T07:21:30.148Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。</p><p>欢迎投稿或推荐你自己的项目，投稿邮箱: <a href="mailto:editor@hi-linux.com">editor@hi-linux.com</a> 。如果你对周刊有什么建议和意见，或者想与大家一起讨论技术问题，也可以戳「<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;mid=2247487968&amp;idx=2&amp;sn=476c03c6edfae6907020c23094496791&amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;token=1973230270&amp;lang=zh_CN#rd" target="_blank" rel="noopener">这里</a>」加入技术交流群。</p><h2 id="业界资讯">业界资讯</h2><p>1、<a href="https://www.williamlong.info/archives/5771.html" target="_blank" rel="noopener">谷歌确认回归中国的 Dragonfly 计划彻底终止</a></p><p>近日，谷歌副总裁巴提亚（Karan Bhatia）出席美国参议院司法委员会举行的听证会时确认谷歌已经终止了在中国推出审查搜索引擎的 “蜻蜓计划”，该计划原打算推出中国定制版、通过中国法律审查的搜索引擎。</p><p>链接：<a href="https://www.williamlong.info/archives/5771.html" target="_blank" rel="noopener">https://www.williamlong.info/archives/5771.html</a></p><p><img src="https://i.loli.net/2019/07/22/5d355ee15057b67703.jpg" alt=""></p><p>2、<a href="https://www.oschina.net/news/108368/microsoft-is-exploring-to-use-rust-as-more-secure-code" target="_blank" rel="noopener">微软计划将 Rust 作为 C 和 C++ 的安全替代品</a></p><p>微软正在探索使用 Rust 编程语言作为 C、C++ 和其他语言的替代方案，以此来改善应用程序的安全状况。</p><p>链接：<a href="https://www.oschina.net/news/108368/microsoft-is-exploring-to-use-rust-as-more-secure-code" target="_blank" rel="noopener">https://www.oschina.net/news/108368/microsoft-is-exploring-to-use-rust-as-more-secure-code</a></p><p><img src="https://oscimg.oschina.net/oscnet/a6c6690735238bf57e020b1beb346f77686.jpg" alt=""></p><p>3、<a href="https://www.oschina.net/news/108462/develop-with-python-on-windows" target="_blank" rel="noopener">微软官方上线 Python 配置教程</a></p><p>微软近日上线了一套 Python 配置教程 《Develop with Python on Windows》，文档内容包括设置 Python 开发环境、在 Windows 与 WSL 子系统中安装相应开发工具，以及集成 VS Code 与 Git 工具并进行开发等。</p><p>链接：<a href="https://www.oschina.net/news/108462/develop-with-python-on-windows" target="_blank" rel="noopener">https://www.oschina.net/news/108462/develop-with-python-on-windows</a></p><p><img src="https://i.loli.net/2019/07/23/5d36cacdacd2d91648.jpg" alt=""></p><p>4、<a href="https://www.oschina.net/news/108481/docker-ce-19-03-0-released" target="_blank" rel="noopener">Docker CE 19.03 正式发布，无需 root 权限</a></p><p>Docker CE 19.03 和 EE 3.0 都已经正式发布，19.03 主要内容包括无需 root 权限、支持 GPU 的增强功能和 CLI 插件更新等等。Docker CE 19.03 现在是允许非 root 用户运行守护程序，启用 Rootless 模式可以防止攻击者夺取主机的 root 权限，即使 Docker 存在漏洞或设置错误。</p><p>链接：<a href="https://www.oschina.net/news/108481/docker-ce-19-03-0-released" target="_blank" rel="noopener">https://www.oschina.net/news/108481/docker-ce-19-03-0-released</a></p><p>5、<a href="https://www.oschina.net/news/108474/huawei-will-opensource-gaussdb" target="_blank" rel="noopener">华为将开源全球首个 AI 原生数据库 GaussDB 内核</a></p><p>日前，华为在正在进行的鲲鹏计算产业论坛上宣布将开源其内部大规模使用的 GaussDB 数据库内核。该内核具备超越现有开源 MySQL、PostgreSQL 的极致性能，在鲲鹏 920 服务器上 TPC-C 性能能够达到 150 万 TPMC。并具备业内最快的故障恢复时间，完全满足各种高端企业用户的 Oracle 替代需求。</p><p>链接：<a href="https://www.oschina.net/news/108474/huawei-will-opensource-gaussdb" target="_blank" rel="noopener">https://www.oschina.net/news/108474/huawei-will-opensource-gaussdb</a></p><a id="more"></a><h2 id="趣站酷软">趣站酷软</h2><p>1、<a href="https://github.com/guanpengchn/markdown-resume" target="_blank" rel="noopener">Markdown-Resume</a></p><p>Markdown-Resume 是一个支持 Markdown 和富文本的在线简历排版工具，如果你想快速的制作一个好用又好看的简历，不妨试试哟~</p><p>项目地址: <a href="https://github.com/guanpengchn/markdown-resume" target="_blank" rel="noopener">https://github.com/guanpengchn/markdown-resume</a></p><p><img src="https://www.hi-linux.com/img/linux/markdown-resume.jpeg" alt=""></p><p>2、<a href="https://github.com/joeblau/gitignore.io" target="_blank" rel="noopener">gitignore.io</a></p><p>项目地址: <a href="https://github.com/joeblau/gitignore.io" target="_blank" rel="noopener">https://github.com/joeblau/gitignore.io</a></p><p>这是由 Uber 一名工程师 joeblau 所开发的 .gitignore 文件快速生成工具，开发者只需要在网站上搜索当前正在使用的操作系统、IDE、编程语言，它便会自动生成一个特定的 .gitignore 配置文件。</p><p>如果你不想用网站进行搜索，还可以安装下它的命令行工具。安装完成后，就可以使用 gi 命令来快速生成 .gitignore 配置文件啦，超级方便！</p><p><img src="https://www.hi-linux.com/img/linux/gitignore.jpeg" alt=""></p><p>3、<a href="https://github.com/crossoverJie/blog.toolbox/" target="_blank" rel="noopener">blog.toolbox</a></p><p>这是一个图床搬家工具，可以很方便的帮你将图片批量的从失效的图床搬到新的图床中。</p><p>项目地址: <a href="https://github.com/crossoverJie/blog.toolbox/" target="_blank" rel="noopener">https://github.com/crossoverJie/blog.toolbox/</a></p><p><img src="https://www.hi-linux.com/img/linux/blog-toolbox.gif" alt=""></p><p>4、<a href="https://iplist.cc" target="_blank" rel="noopener">IPList</a></p><p>IPList 是一个在线 IP、Hostname 查询工具，支持 IPv4、IPv6。只要输入查询内容就会显示出相关信息，也可看到打开网站你目前的 IP 地址。</p><p>IPList 实际上一个免费的 IP 信息查询 API，可供开发者快速取得某个 IP 或 Hostname 的信息，只要把查询的对象拼接在 <a href="https://iplist.cc/api/" target="_blank" rel="noopener">https://iplist.cc/api/</a> 网址后面就会得到结果。</p><p>项目地址: <a href="https://iplist.cc/" target="_blank" rel="noopener">https://iplist.cc/</a></p><p><img src="https://www.hi-linux.com/img/linux/iplist.jpeg" alt=""></p><p>5、<a href="https://github.com/ziishaned/learn-regex" target="_blank" rel="noopener">Learn-Regex</a></p><p>这个项目是一个关于正则表达式的教程，不仅收录了学习资料，还提供了一个在线的学习网站帮助巩固所学，在实操中多练习一下能够让你更快的达到不需要每次使用的时候都翻开教程的境界，熟能生巧，这种东西还是全记下来用的才方便。</p><p>项目地址: <a href="https://github.com/ziishaned/learn-regex" target="_blank" rel="noopener">https://github.com/ziishaned/learn-regex</a></p><p><img src="https://www.hi-linux.com/img/linux/Learn-Regex.png" alt=""></p><p>6、<a href="https://github.com/chubin/cheat.sh" target="_blank" rel="noopener">cheat.sh</a></p><p>一个在线查询 Linux 命令快速使用方法的网站。比如要查询 tar 命令的用法， 只需要执行 curl <a href="http://cht.sh/tar" target="_blank" rel="noopener">cht.sh/tar</a> 就可以很快得到 tar 命令的常用方法，结果比 man 命令简洁实用得多。</p><p>项目地址: <a href="https://github.com/chubin/cheat.sh" target="_blank" rel="noopener">https://github.com/chubin/cheat.sh</a></p><p><img src="https://www.hi-linux.com/img/linux/cheat.jpeg" alt=""></p><p>7、<a href="https://virtual-kubelet.io/" target="_blank" rel="noopener">Virtual Kubelet</a></p><p>Virtual Kubelet 是一个开源的 Kubernetes Kubelet 实现。它伪装成 Kubelet，目的是将 Kubernetes 连接到其他 API，这允许节点得到其他服务(如 ACI、AWS Fargate、IoT Edge 等)的支持。Virtual Kubelet 的主要场景是将Kubernetes API 扩展到无服务器的容器平台（如 ACI 和 Fargate ）。</p><p>Virtual Kubelet 提供一个库，开发者可以在项目中使用这个库来构建自定义 Kubernetes 节点代理。</p><p>项目地址: <a href="https://virtual-kubelet.io/" target="_blank" rel="noopener">https://virtual-kubelet.io/</a></p><p><img src="https://www.hi-linux.com/img/linux/Virtual-Kubelet.png" alt=""></p><p>8、<a href="https://github.com/eryajf/magic-of-sysuse-scripts" target="_blank" rel="noopener">magic-of-sysuse-scripts</a></p><p>一个可快速初始化服务器环境和安装常用软件环境的运维小工具。(@李启龙 投稿)</p><p>项目地址: <a href="https://github.com/eryajf/magic-of-sysuse-scripts" target="_blank" rel="noopener">https://github.com/eryajf/magic-of-sysuse-scripts</a></p><p><img src="https://i.loli.net/2019/07/23/5d36c5cada13b68380.gif" alt=""></p><h2 id="技术文章">技术文章</h2><p>1、<a href="https://github.com/aCoder2013/blog/issues/35" target="_blank" rel="noopener">API 网关从入门到放弃</a></p><p>本文将以电商平台为例讲解设计 API 网关的要点和 API 网关的优劣势。</p><p>链接：<a href="https://github.com/aCoder2013/blog/issues/35" target="_blank" rel="noopener">https://github.com/aCoder2013/blog/issues/35</a></p><p><img src="https://www.hi-linux.com/img/linux/api-gateway.jpeg" alt=""></p><p>2、<a href="https://github.com/caicloud/kube-ladder" target="_blank" rel="noopener">Kubernetes 学习路径</a></p><p>本文由才云科技（Caicloud）于 2019 年内部推出，现以开源的形式进行维护。文档旨在为广大从业者提供一个 Kubernetes 学习路径，为大家提供一定的指引。我们最终的目标是让所有人剥茧抽丝般地了解 Kubernetes，不仅仅知道怎么用 Kubernetes，还知道 Kubernetes 各个功能是如何设计的。</p><p>链接：<a href="https://github.com/caicloud/kube-ladder" target="_blank" rel="noopener">https://github.com/caicloud/kube-ladder</a></p><p>3、<a href="https://github.com/blueboay/ceph-study" target="_blank" rel="noopener">Ceph-Study</a></p><p>Ceph 是一个可靠、自动均衡、自动恢复的分布式存储系统，通常可用于对象存储，块设备存储和文件系统存储。Ceph-Study 是网友整理的一份 Ceph 学习指南，写的十分详细，欢迎初学者浏览学习。</p><p>链接：<a href="https://github.com/blueboay/ceph-study" target="_blank" rel="noopener">https://github.com/blueboay/ceph-study</a></p><p><img src="https://i.loli.net/2019/07/22/5d356ee51461d56865.png" alt=""></p><p>4、<a href="https://github.com/jwasham/coding-interview-university" target="_blank" rel="noopener">Coding Interview University</a></p><p>这份指南里面包含 Google 相关的介绍视频、面试过程、教学资源，同时也有数据结构、算法、密码学等计算机专业的知识讲解。</p><p>链接：<a href="https://github.com/jwasham/coding-interview-university" target="_blank" rel="noopener">https://github.com/jwasham/coding-interview-university</a></p><p>为了便于国内开发者查看，掘金翻译团队已将该指南译为中文。</p><p>链接：<a href="https://github.com/jwasham/coding-interview-university/blob/master/translations/README-cn.md" target="_blank" rel="noopener">https://github.com/jwasham/coding-interview-university/blob/master/translations/README-cn.md</a></p><p><img src="https://i.loli.net/2019/07/23/5d366e052e79a91004.jpg" alt=""></p><p>5、<a href="https://github.com/selfteaching/the-craft-of-selfteaching" target="_blank" rel="noopener">自学是门手艺</a></p><blockquote><p>没有自学能力的人没有未来。</p></blockquote><p>「自学是门手艺」是李笑来开源的一本电子书，介绍了掌握自学能力的重要性，并以学习 Python 编程为例子讲解如何进行有效的自学的方法。</p><p>链接：<a href="https://github.com/selfteaching/the-craft-of-selfteaching" target="_blank" rel="noopener">https://github.com/selfteaching/the-craft-of-selfteaching</a></p><p>在线版链接：<a href="http://the-craft-of-selfteaching.surge.sh" target="_blank" rel="noopener">http://the-craft-of-selfteaching.surge.sh</a></p><h2 id="每周观点">每周观点</h2><p>1、美妙人生的关键在于你能迷上什么东西。——「球状闪电」</p><p>2、工作上的执着，实际上是人的一种意志。—— 张近东</p><p>3、生活是属于每个人自己的感受，不属于任何别人的看法。——「活着」</p><p>4、人生的某些障碍，你是逃不掉的。与其费尽周折绕过去，不如勇敢的地攀越，或许这会铸就你人生的高点。—— 宫崎骏「龙猫」</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里将分享一些最新运维相关技术和业界资讯的精彩内容，每周五发布。&lt;/p&gt;
&lt;p&gt;欢迎投稿或推荐你自己的项目，投稿邮箱: &lt;a href=&quot;mailto:editor@hi-linux.com&quot;&gt;editor@hi-linux.com&lt;/a&gt; 。如果你对周刊有什么建议和意见，或者想与大家一起讨论技术问题，也可以戳「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247487968&amp;amp;idx=2&amp;amp;sn=476c03c6edfae6907020c23094496791&amp;amp;chksm=eac530c9ddb2b9dfa28b928a36b38c24dc40969accffc6e634592e97f7f9c85bfa0d30bb1a55&amp;amp;token=1973230270&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;」加入技术交流群。&lt;/p&gt;
&lt;h2 id=&quot;业界资讯&quot;&gt;业界资讯&lt;/h2&gt;
&lt;p&gt;1、&lt;a href=&quot;https://www.williamlong.info/archives/5771.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;谷歌确认回归中国的 Dragonfly 计划彻底终止&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;近日，谷歌副总裁巴提亚（Karan Bhatia）出席美国参议院司法委员会举行的听证会时确认谷歌已经终止了在中国推出审查搜索引擎的 “蜻蜓计划”，该计划原打算推出中国定制版、通过中国法律审查的搜索引擎。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.williamlong.info/archives/5771.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.williamlong.info/archives/5771.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/22/5d355ee15057b67703.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;https://www.oschina.net/news/108368/microsoft-is-exploring-to-use-rust-as-more-secure-code&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微软计划将 Rust 作为 C 和 C++ 的安全替代品&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;微软正在探索使用 Rust 编程语言作为 C、C++ 和其他语言的替代方案，以此来改善应用程序的安全状况。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108368/microsoft-is-exploring-to-use-rust-as-more-secure-code&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108368/microsoft-is-exploring-to-use-rust-as-more-secure-code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/a6c6690735238bf57e020b1beb346f77686.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;https://www.oschina.net/news/108462/develop-with-python-on-windows&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微软官方上线 Python 配置教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;微软近日上线了一套 Python 配置教程 《Develop with Python on Windows》，文档内容包括设置 Python 开发环境、在 Windows 与 WSL 子系统中安装相应开发工具，以及集成 VS Code 与 Git 工具并进行开发等。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108462/develop-with-python-on-windows&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108462/develop-with-python-on-windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/23/5d36cacdacd2d91648.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;https://www.oschina.net/news/108481/docker-ce-19-03-0-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Docker CE 19.03 正式发布，无需 root 权限&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Docker CE 19.03 和 EE 3.0 都已经正式发布，19.03 主要内容包括无需 root 权限、支持 GPU 的增强功能和 CLI 插件更新等等。Docker CE 19.03 现在是允许非 root 用户运行守护程序，启用 Rootless 模式可以防止攻击者夺取主机的 root 权限，即使 Docker 存在漏洞或设置错误。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108481/docker-ce-19-03-0-released&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108481/docker-ce-19-03-0-released&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;https://www.oschina.net/news/108474/huawei-will-opensource-gaussdb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;华为将开源全球首个 AI 原生数据库 GaussDB 内核&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;日前，华为在正在进行的鲲鹏计算产业论坛上宣布将开源其内部大规模使用的 GaussDB 数据库内核。该内核具备超越现有开源 MySQL、PostgreSQL 的极致性能，在鲲鹏 920 服务器上 TPC-C 性能能够达到 150 万 TPMC。并具备业内最快的故障恢复时间，完全满足各种高端企业用户的 Oracle 替代需求。&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.oschina.net/news/108474/huawei-will-opensource-gaussdb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oschina.net/news/108474/huawei-will-opensource-gaussdb&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="工具" scheme="https://www.hi-linux.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="周刊" scheme="https://www.hi-linux.com/tags/%E5%91%A8%E5%88%8A/"/>
    
  </entry>
  
  <entry>
    <title>Android Pie 私人 DNS 使用教程</title>
    <link href="https://www.hi-linux.com/posts/32399.html"/>
    <id>https://www.hi-linux.com/posts/32399.html</id>
    <published>2020-05-16T01:00:00.000Z</published>
    <updated>2020-05-16T07:51:58.394Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>最近手机更新到了最新的 Android Pie (9.0) 系统，随着系统的更新，就可以体验到 Android Pie 带来了一系列的新特性。比如：全新设计的导航栏以及多任务界面、数字应用、安全和隐私等新功能。其中有一项更新是非常实用的，该功能可以提升用户上网过程中的安全性，它就是：DNS over TLS，在 Android 里叫做 Private DNS（私人 DNS）。</p><p><img src="https://cdn.laod.wang/wp-content/uploads/2018/11/tls.png" alt=""></p><p>默认情况下，如果网络的 DNS 服务器支持，设备会自动使用 DNS over TLS，但如果用户不希望使用 DNS over TLS，可选择将其关闭。</p><p>Android Pie 的 新功能简化了在 Android 配置自定义安全的 DNS 解析程序。当网站提供 DNS 服务时，客户端和网站服务器就会自动进行加密，第三方无法窥视 DNS 查询。因为 Android 9 内置对 DNS over TLS 的支持。同时该 TLS 还负责自动默认 HTTPS 访问网站，在地址栏可看到绿色安全锁图标。这可确保不会被 ISP、移动运营商以及客户端与 DNS 解析程序之间的第三方篡改内容或无法解析。</p><p>在讲这个功能之前先来了解一下什么是 DNS 和 DNS 污染。</p><a id="more"></a><h3 id="原理">原理</h3><p>既然说起 DNS 和其污染问题，就不得不先看看 DNS 系统是如何工作的。</p><p>互联网所有通信都是建立在 TCP/IP 的基础上，如果想访问目标网络，就必须知道目标 IP。不过 IP 的数量有限，还有 IP 是由一串数字或十六进制组成的，不是那么好记，所以有了域名。域名本身不具有访问性，它如果想被访问，必须绑定一个或多个 IP，一个 IP 可以绑定一个或多个域名。这时候就有一个问题，如何知道域名指向的是哪个 IP。所以需要一项服务，它记载着所有域名和IP的关系，需要的时候询问它就可以了，这就是 DNS（域名系统）。</p><p>以访问 Wikipedia 网站为例。</p><p><img src="https://kyle.ai/blog/wp-content/uploads/2017/09/563px-An_example_of_theoretical_DNS_recursion.svg_.png" alt=""></p><p>DNS 解析流程图</p><p>图中可以看到我们的 ISP 的 DNS 服务器在图中叫做 DNS Recurser，在解析一个域名的时候，总共经过了以下的步骤：</p><ol><li>向 root 服务器获取该 gTLD 的管辖服务器，图中为 org 结尾的域名。</li><li>root 服务器返回 org 的管辖服务器。</li><li>向 org 的管辖服务器查询，谁来负责解析 <a href="http://wikipedia.org" target="_blank" rel="noopener">wikipedia.org</a> 这个域名的。</li><li>org 的管辖服务器返回解析 <a href="http://wikipedia.org" target="_blank" rel="noopener">wikipedia.org</a> 的服务器 IP 地址。</li><li>向 <a href="http://wikipedia.org" target="_blank" rel="noopener">wikipedia.org</a> 的解析服务器发出查询，解析 <a href="http://www.wikipedia.org" target="_blank" rel="noopener">www.wikipedia.org</a> 的 IP 地址。</li><li>拿到最终要的 IP 地址。</li></ol><p>从上面的 DNS 解析流程可以看出，解析一个域名一共要经历 6 个步骤。</p><p>由于 DNS 的数据是以明文传输，所以 DNS 服务器返回的数据在传输的过程中是有可能被篡改的，导致域名指向错误的 IP，引导用户访问错误或恶意的网站。比如：在最后一次查询的时候，有人假冒了 <a href="http://wikipedia.org" target="_blank" rel="noopener">wikipedia.org</a> 的解析服务器，则可以在中间进行欺骗攻击，致使用户最后得到的 IP 地址不是真实的地址。如图所示，</p><p><img src="https://kyle.ai/blog/wp-content/uploads/2017/09/563px-An_example_of_theoretical_DNS_recursion.svg_1.png" alt=""></p><p>解析请求被劫持</p><h3 id="为什么要使用私有-dns">为什么要使用私有 DNS？</h3><p>从上面的例子我们可以看出，DNS 是存在被劫持和污染的风险的。为了保护用户的上网安全，一些 DNS 加密查询技术因此应运而生。常见的有：DNS over HTTPS、DNSCrypt 和 DNS over TLS。这三种的技术原理大致一样，都是通过一些手段加密用户与 DNS 服务器之间的通信，避免 DNS 污染。</p><blockquote><p>TLS (Transport Layer Security，传输层安全协议)，TLS 是 IETF（Internet Engineering Task Force，Internet 工程任务组）制定的一种新的协议。TLS 是在其前身 SSL （Secure Sockets Layer，安全套接层）的基础上发展来的。SSL 也是一种安全协议，其目的是为互联网通信提供安全及数据完整性保障。TLS 它建立在 SSL 3.0 协议规范之上，是 SSL 3.0 的后续版本，可以理解为 SSL 3.1。TLS 协议由两层组成：TLS 记录层（TLS Record）和 TLS 传输层（TLS Handshake）。较低的层为 TLS 记录层协议，位于某个可靠的传输协议（例如：TCP）上面。记录层协议确定传输层数据的封装格式。传输层安全协议使用 X.509 认证，之后利用非对称加密演算来对通信方做身份认证，之后交换对称密钥作为会谈密钥（Session key）。这个会谈密钥是用来将通信两方交换的数据做加密，保证两个应用间通信的保密性和可靠性，使客户与服务器应用之间的通信不被攻击者窃听。</p></blockquote><p>目前支持 DNS over TLS 的平台不多， Android Pie 就是其中这一。如果你的系统暂时不支持 DNS over TLS，你可以暂时使用 SmartDNS 这个程序来作为本地 DNS 服务器，它支持将 DNS over TLS 作为 DNS 上游服务器。</p><p>SmartDNS 项目地址：<a href="https://github.com/pymumu/smartdns" target="_blank" rel="noopener">https://github.com/pymumu/smartdns</a></p><h3 id="在-android-pie-上启用-dns-over-tls">在 Android Pie 上启用  DNS over TLS</h3><p>在 Android Pie 上启用  DNS over TLS 的方法非常简单。下面以一加 5 为例，大概需要如下步骤：</p><ol><li>打开 [设置] → [WLAN 和互联网] → [私人 DNS] → [私人 DNS 提供商主机名] → 输入 DNS over TLS 提供商提供的主机名 → 保存。</li></ol><p>保存以后，如果私人 DNS 下方显示主机名代表配置成功。</p><blockquote><ol><li><p>私有 DNS 字段并不接受类似 1.1.1.1 这样简单的 IP 地址，而是需要一个主机名。如：dns.google。Google 之所以要求私有 DNS 字段是主机名而非 IP 地址，这是因为考虑到移动运营商需要兼顾 IPv4 和 IPv6 共存的问题。</p></li><li><p>如果你使用原生 Android Pie 可使用 [设置] → [网络和互联网] → [高级] → [私人 DNS] 。</p></li></ol></blockquote><p>验证是否生效</p><ul><li><p>如果你使用的是 Cloudflare 提供的私人 DNS，可以访问 <a href="https://1.1.1.1/help" target="_blank" rel="noopener">https://1.1.1.1/help</a> 进行验证。如果 “使用 DNS over TLS（DoT）” 显示为 “是” 就表示配置成功了。</p></li><li><p>你也可以访问 <a href="https://whoer.net/zh" target="_blank" rel="noopener">https://whoer.net/zh</a> 这个网站来测试 DNS 匿名性。</p></li></ul><p>一些可用的 DNS over TLS 提供商</p><blockquote><p>Google: dns.google</p><p>Cloudflare: <a href="http://1dot1dot1dot1.cloudflare-dns.com" target="_blank" rel="noopener">1dot1dot1dot1.cloudflare-dns.com</a></p><p>Quad9: <a href="http://dns.quad9.net" target="_blank" rel="noopener">dns.quad9.net</a></p><p>CleanBrowsing: <a href="http://security-filter-dns.cleanbrowsing.org" target="_blank" rel="noopener">security-filter-dns.cleanbrowsing.org</a></p><p>红鱼 DNS: <a href="http://dns.rubyfish.cn" target="_blank" rel="noopener">dns.rubyfish.cn</a></p></blockquote><p>祝大家早日吃上 Andorid Pie。最后我们来搞个小投票，看看大家所使用的手机品牌和系统。</p><h3 id="参考文档">参考文档</h3><ol><li><a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com</a></li><li><a href="http://t.cn/EicGa97" target="_blank" rel="noopener">http://t.cn/EicGa97</a></li><li><a href="http://t.cn/EiVVF4K" target="_blank" rel="noopener">http://t.cn/EiVVF4K</a></li><li><a href="http://t.cn/EiVfk7i" target="_blank" rel="noopener">http://t.cn/EiVfk7i</a></li><li><a href="http://t.cn/EiVc5Uf" target="_blank" rel="noopener">http://t.cn/EiVc5Uf</a></li><li><a href="http://t.cn/E2m0Ytz" target="_blank" rel="noopener">http://t.cn/E2m0Ytz</a></li></ol></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "10135-1588830050631-449",        "name": "「奇妙的 Linux 世界」",        "qrcode": "https://www.hi-linux.com/img/wechat/mp_qrcode_12.jpg",        "keyword": "VIP"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近手机更新到了最新的 Android Pie (9.0) 系统，随着系统的更新，就可以体验到 Android Pie 带来了一系列的新特性。比如：全新设计的导航栏以及多任务界面、数字应用、安全和隐私等新功能。其中有一项更新是非常实用的，该功能可以提升用户上网过程中的安全性，它就是：DNS over TLS，在 Android 里叫做 Private DNS（私人 DNS）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.laod.wang/wp-content/uploads/2018/11/tls.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;默认情况下，如果网络的 DNS 服务器支持，设备会自动使用 DNS over TLS，但如果用户不希望使用 DNS over TLS，可选择将其关闭。&lt;/p&gt;
&lt;p&gt;Android Pie 的 新功能简化了在 Android 配置自定义安全的 DNS 解析程序。当网站提供 DNS 服务时，客户端和网站服务器就会自动进行加密，第三方无法窥视 DNS 查询。因为 Android 9 内置对 DNS over TLS 的支持。同时该 TLS 还负责自动默认 HTTPS 访问网站，在地址栏可看到绿色安全锁图标。这可确保不会被 ISP、移动运营商以及客户端与 DNS 解析程序之间的第三方篡改内容或无法解析。&lt;/p&gt;
&lt;p&gt;在讲这个功能之前先来了解一下什么是 DNS 和 DNS 污染。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.hi-linux.com/tags/Linux/"/>
    
      <category term="技巧" scheme="https://www.hi-linux.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Android" scheme="https://www.hi-linux.com/tags/Android/"/>
    
  </entry>
  
</feed>
